{"question": "What is Amazon MQ?", "answer": "Amazon MQ is a managed message broker service for Apache ActiveMQ and RabbitMQ that makes it easy to set up and operate message brokers in the cloud. It allows users to access the ActiveMQ console, RabbitMQ console, and industry standard APIs and protocols for messaging.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T15:48:48.356109"}}
{"question": "How does Amazon MQ assist in managing message brokers?", "answer": "Amazon MQ manages the process of setting up a message broker, provisioning the infrastructure, and the open-source broker engine software. It also handles ongoing software upgrades, security updates, fault detection, and recovery, reducing the operational burden for users.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T15:48:48.357251"}}
{"question": "What are the key features of Amazon MQ compared to traditional message broker management?", "answer": "Amazon MQ offers several key features compared to traditional message broker management, including automatic management of nodes in a multi-AZ deployment, data replication for high availability, regular patch deployments, integration with AWS services, visibility of important metrics, and support for broker engine version upgrades.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T15:48:48.357477"}}
{"question": "What are some administration tasks that Amazon MQ handles for users?", "answer": "Amazon MQ handles administration tasks such as broker provisioning, security patching, setup, configuration, broker version upgrades, and recovery for users.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T15:48:53.988425"}}
{"question": "Why might a user choose Amazon MQ over running a message broker on Amazon EC2?", "answer": "A user might choose Amazon MQ over running a message broker on Amazon EC2 if they want to offload operational overhead and associated costs, as Amazon MQ manages various administration tasks that would otherwise need to be performed manually on EC2.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T15:48:53.988686"}}
{"question": "How does Amazon MQ's approach to inter-node data transfer for RabbitMQ compare to that of a self-managed cluster?", "answer": "Amazon MQ does not charge for inter-node data transfer for RabbitMQ brokers, while a self-managed cluster may incur high costs for inter-node data transfer depending on the use case.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T15:48:53.989090"}}
{"question": "What version of ActiveMQ can you specify when creating a new broker in Amazon MQ?", "answer": "You can specify the ActiveMQ version, such as ActiveMQ 5.17.6, when creating a new broker via the AWS Management Console or the CreateBroker API.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T15:49:02.002313"}}
{"question": "What happens when you enable automatic minor version upgrades for your Amazon MQ broker?", "answer": "When you turn on automatic minor version upgrades, Amazon MQ will upgrade your broker to the latest supported patch version during the next maintenance window.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T15:49:02.002630"}}
{"question": "How do the durability optimized brokers differ from throughput optimized brokers in Amazon MQ?", "answer": "Durability optimized brokers use Amazon Elastic File System (Amazon EFS) for high durability and replication across multiple Availability Zones, while throughput optimized brokers use Amazon Elastic Block Store (EBS) for high throughput suitable for high-volume applications.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T15:49:02.002793"}}
{"question": "What feature does Amazon MQ for ActiveMQ use to connect multiple brokers?", "answer": "Amazon MQ for ActiveMQ uses the 'network of brokers' feature that is part of Apache ActiveMQ to connect multiple brokers in a mesh.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T15:49:08.664515"}}
{"question": "Why would one choose to use a network of brokers in Amazon MQ?", "answer": "One would choose to use a network of brokers in Amazon MQ if they require high availability with fast reconnection in the case of broker failure, or if they need the ability to scale horizontally.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T15:49:08.664877"}}
{"question": "How does the handling of RabbitMQ versions in Amazon MQ differ from the management of ActiveMQ brokers?", "answer": "Amazon MQ supports RabbitMQ version 3.13 by default and will continually add support for new RabbitMQ versions based on the open-source maintainers' releases. In contrast, ActiveMQ brokers can be configured as active-standby or single-instance, with unique message stores replicated across availability zones, and they require manual upgrades or automatic minor version upgrades for maintenance.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T15:49:08.665370"}}
{"question": "What types of AWS compute services can use Amazon MQ?", "answer": "Any application that runs on an AWS compute service, such as Amazon EC2, Amazon ECS, or AWS Lambda, can use Amazon MQ.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T15:49:16.165452"}}
{"question": "How does Amazon MQ handle version upgrades for RabbitMQ?", "answer": "Amazon MQ will upgrade all brokers on the version to the next supported version after it reaches end of support. Users can manually upgrade their broker at any time to the next supported major or minor version. When automatic minor version upgrades are turned on, Amazon MQ will upgrade the broker to the latest supported patch version during the next maintenance window. From RabbitMQ version 3.13 onwards, Amazon MQ will manage the patch version for you and ensure all brokers are on the latest patch version of the minor version.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T15:49:16.165749"}}
{"question": "What is the relationship between supported RabbitMQ versions and backward compatibility?", "answer": "All supported RabbitMQ versions today are backward compatible with each other, which means that applications running on one supported version can work with another supported version without issues.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T15:49:16.166335"}}
{"question": "What types of broker deployments are available for ActiveMQ in Amazon MQ?", "answer": "For ActiveMQ in Amazon MQ, you can choose from an Active-Standby deployment or a mesh network of brokers.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T15:49:23.440759"}}
{"question": "What is the purpose of AWS Key Management Service (AWS KMS) in Amazon MQ?", "answer": "The AWS Key Management Service (AWS KMS) is used in Amazon MQ to create and manage keys for at-rest encryption of your data. When creating a broker, you can select from different KMS key options for encrypting your data.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T15:49:23.441106"}}
{"question": "How does the visibility of EC2 instances differ when using Amazon MQ compared to general EC2 usage?", "answer": "When using Amazon MQ, EC2 instances are not visible in your EC2 account because they are managed by the Amazon MQ service. However, some networking resources like elastic network interfaces (ENIs) and VPC endpoints are visible in your Amazon EC2 account to facilitate connection to the broker.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T15:49:23.441589"}}
{"question": "What are the charges associated with using Amazon MQ?", "answer": "With Amazon MQ, you are charged for broker instance usage, storage usage, and standard data transfer fees.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-04T15:49:29.364077"}}
{"question": "What options do new AWS customers have regarding the AWS Free Tier when signing up?", "answer": "New AWS customers can choose between a free plan and a paid plan at account sign-up. The free plan is available for 6 months after account creation, and any remaining Free Tier credit balance will automatically apply to AWS bills if the customer upgrades to a paid plan.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-04T15:49:29.364320"}}
{"question": "How does Amazon MQ's pricing model differ from reserved instance pricing?", "answer": "Amazon MQ does not offer reserved instance pricing, which means that users are charged only for what they use without the option to reserve instances for a lower cost.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-04T15:49:29.364711"}}
{"question": "What are the main components of AWS Amplify?", "answer": "AWS Amplify consists of a set of tools, including an open source framework, a visual development environment, and a console, as well as services for web app and static website hosting.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T15:49:35.248359"}}
{"question": "How does Amplify Studio enhance the development experience compared to the Amplify CLI?", "answer": "Amplify Studio simplifies the configuration of backends and frontend UIs with a visual point-and-click experience, whereas the Amplify CLI provides a command line interface for building app backends and integrating with various apps. Studio's visual approach makes it easier for users who prefer a graphical interface.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T15:49:35.248690"}}
{"question": "What is the difference between AWS Amplify's hosting service and AWS Device Farm?", "answer": "AWS Amplify's hosting service is a fully managed solution for hosting front-end web apps and static websites, allowing users to create/delete backend environments and set up CI/CD. In contrast, AWS Device Farm is a service for testing apps on real iOS devices, Android devices, and web browsers, focusing on app testing rather than hosting.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T15:49:35.249178"}}
{"question": "What components are included in AWS Amplify's framework?", "answer": "AWS Amplify's framework includes tools such as libraries, UI components, and a CLI, along with Amplify Studio, the console, and a static web hosting service.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-04T15:49:41.273339"}}
{"question": "How does AWS Amplify's static web hosting service enhance the deployment process when using the Amplify CLI?", "answer": "AWS Amplify's static web hosting service enhances the deployment process by provisioning or updating backend resources prior to deploying the front end on each check-in when using the Amplify CLI.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-04T15:49:41.273693"}}
{"question": "What types of applications can the Amplify libraries support, and how do they integrate with web apps?", "answer": "The Amplify libraries support iOS, Android, Web, Flutter, and React Native apps. For web apps, there is deep integration with frameworks such as React, Ionic, Angular, and Vue.js.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-04T15:49:41.273861"}}
{"question": "What features are organized based on use cases in Amplify?", "answer": "Amplify features are organized based on use cases such as offline data, multi-factor authentication, analytics, and others.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T15:49:46.442924"}}
{"question": "How does Amplify CLI or Amplify Studio assist in configuring app features?", "answer": "When you configure features using the Amplify CLI or Amplify Studio, the necessary AWS cloud services are provisioned for you, and the configuration is persisted in CloudFormation templates that can be checked into source control and shared with other developers.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T15:49:46.443283"}}
{"question": "What is the difference between Amplify Studio and the AWS console for managing app content?", "answer": "Amplify Studio is a visual interface that allows for configuring and maintaining app backends and creating frontend UIs outside the AWS console, enabling both developers and non-developers to manage app content and users, while the AWS console does not provide this simplified access for non-developers.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T15:49:46.443867"}}
{"question": "What features can you manage using the AWS Amplify console?", "answer": "In the AWS Amplify console, you can manage features such as setting up web hosting, full-stack CI/CD, adding a custom domain, cloning or deleting multiple backend environments, and navigating to underlying AWS service consoles.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T15:49:53.655069"}}
{"question": "How does Amplify Studio differ from the Amplify console in terms of functionality?", "answer": "Amplify Studio is used for configuring and maintaining the app backend by adding features such as authentication, data, and functions, whereas the Amplify console focuses on managing the front-end and backend environments and hosting services.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T15:49:53.655306"}}
{"question": "What is the relationship between AWS Amplify's static web hosting service and continuous deployment?", "answer": "AWS Amplify's static web hosting service supports continuous deployment, allowing developers to deploy updates to their web app every time there is a code commit to their Git repository. When the build succeeds, the app is automatically deployed and hosted on an amplifyapp.com subdomain.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T15:49:53.655718"}}
{"question": "What is the process to get started with AWS Amplify?", "answer": "To get started with AWS Amplify, you need to go to AWS Amplify in the AWS console and connect your source repository.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T15:49:59.634949"}}
{"question": "How does continuous deployment benefit software releases in AWS Amplify?", "answer": "Continuous deployment is a DevOps strategy that benefits software releases in AWS Amplify by automatically releasing every code commit to a production or staging environment. This practice reduces the time to market by ensuring that your hosted web app is always a reflection of the latest code in your repository.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T15:49:59.635274"}}
{"question": "What is the difference between environment variables and access tokens in AWS Amplify?", "answer": "Environment variables in AWS Amplify are configurations required by apps at runtime, such as database connection details and API keys, and are encrypted to prevent unauthorized access. In contrast, access tokens are fetched from the source provider when authorizing AWS Amplify for repository access, but are permanently discarded after the token is used for communication with the GitHub API.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T15:49:59.635830"}}
{"question": "What specifications does the temporary compute container created by AWS Amplify have?", "answer": "The temporary compute container created by AWS Amplify has 4 vCPUs and 7GB of RAM.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-04T15:50:06.944372"}}
{"question": "How does AWS Amplify utilize Git's branching model in the development process?", "answer": "AWS Amplify leverages Git's branching model to create new environments every time a developer pushes code to a new branch. Typically, developers deploy their 'master' branch to production, keep the 'dev' branch as staging, and create feature branches for new functionality. This allows developers to work in sandbox environments and use Git to merge code and resolve conflicts.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-04T15:50:06.944664"}}
{"question": "What are the differences between atomic deployments and traditional deployments in AWS Amplify?", "answer": "Atomic deployments in AWS Amplify ensure that the web app is only updated once the entire deploy has finished, eliminating maintenance windows. This means the site is ready to view immediately after deployment without needing to invalidate CDN caches, whereas traditional deployments may require maintenance windows or cache invalidation before the new version is available to users.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-04T15:50:06.945074"}}
{"question": "What pricing information is provided for AWS Amplify's build & deploy feature?", "answer": "The price per build minute for the build & deploy feature is $0.01.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T15:50:12.746469"}}
{"question": "How does AWS Amplify handle SSL certificates for domains managed by Route53?", "answer": "AWS Amplify automatically enables free HTTPS on all sites and manages SSL certificates for Route53-managed domains by generating them through Amazon Certificate Manager, which includes wildcard domain support.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T15:50:12.746821"}}
{"question": "What is the difference between a redirect and a rewrite in AWS Amplify's web hosting?", "answer": "A redirect is a client-side request that updates the URL in the browser to point to another URL, while a rewrite is a server-side operation that changes the URL without updating what the user sees in the browser.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T15:50:12.747264"}}
{"question": "Are prices consistent across different AWS regions?", "answer": "Yes, prices are the same across all regions.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-04T15:50:16.452778"}}
{"question": "What does it mean for prices to be the same across all regions in AWS?", "answer": "It means that regardless of the region you choose to deploy your services or resources in AWS, the cost for those services or resources will not vary; they remain uniform across all locations.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-04T15:50:16.453103"}}
{"question": "How do AWS pricing structures differ when comparing regions?", "answer": "There are no differences in AWS pricing structures when comparing regions, as prices are the same across all regions.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-04T15:50:16.453601"}}
{"question": "What services can Amazon API Gateway connect to for accessing data and functionality?", "answer": "Amazon API Gateway can connect to back-end services such as applications running on Amazon Elastic Compute Cloud (Amazon EC2), Amazon Elastic Container Service (Amazon ECS), AWS Elastic Beanstalk, code running on AWS Lambda, or any web application.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T15:50:23.407808"}}
{"question": "How does Amazon API Gateway manage high volumes of API calls?", "answer": "Amazon API Gateway handles all tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, which includes traffic management, authorization and access control, monitoring, and API version management.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T15:50:23.408141"}}
{"question": "What are the cost differences between HTTP APIs, REST APIs, and WebSocket APIs in Amazon API Gateway?", "answer": "For HTTP APIs and REST APIs, you pay only for the API calls you receive and the amount of data transferred out. In contrast, for WebSocket APIs, you pay only for messages sent and received and for the time a user/device is connected to the WebSocket API.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T15:50:23.408574"}}
{"question": "What is the main purpose of Amazon API Gateway?", "answer": "The main purpose of Amazon API Gateway is to provide developers with a simple, flexible, fully managed, pay-as-you-go service that handles all aspects of creating and operating robust APIs for application back ends. It allows users to launch new services faster and with reduced investment, enabling them to focus on building their core business services.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T15:50:31.032601"}}
{"question": "How does API Gateway enhance the security of APIs?", "answer": "API Gateway enhances the security of APIs by providing multiple tools to authorize access and control service operation access. It allows users to leverage AWS administration and security tools, such as AWS Identity and Access Management (IAM) and Amazon Cognito, to authorize access. Additionally, API Gateway can verify signed API calls and can use custom authorizers written as AWS Lambda functions to verify incoming bearer tokens, thus removing authorization concerns from backend code.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T15:50:31.032969"}}
{"question": "What are the differences in functionality between API Gateway's metering and operations monitoring features?", "answer": "API Gateway's metering functionality focuses on defining plans that meter and restrict third-party developer access to APIs, including configuring throttling and quota limits on a per API key basis, and automatically metering traffic to extract utilization data for each API key. In contrast, operations monitoring provides a metrics dashboard to monitor calls to services after an API is published, integrating with Amazon CloudWatch to deliver backend performance metrics such as API calls, latency data, and error rates, along with enabling detailed metrics and logs.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T15:50:31.033471"}}
{"question": "What capabilities does API Gateway provide for developers?", "answer": "API Gateway allows developers to quickly create APIs and assign static content for their responses. This reduces cross-team development effort and time-to-market for applications, enabling teams that depend on the APIs to begin development while the backend processes are still being built.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-04T15:50:41.142181"}}
{"question": "How does API Gateway facilitate real-time communication for applications?", "answer": "API Gateway facilitates real-time communication by enabling the building of two-way communication applications, such as chat apps, streaming dashboards, and notifications, without the need to run or manage any servers. It maintains a persistent connection between connected users, allowing for message transfer between them.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-04T15:50:41.142535"}}
{"question": "In what ways do the functionalities of API Gateway for developers and real-time communication differ?", "answer": "The functionalities of API Gateway for developers focus on quickly creating APIs and reducing development time by allowing teams to begin work on their applications while backend processes are still being developed. In contrast, the real-time communication functionalities of API Gateway are centered on enabling the creation of real-time applications that facilitate two-way communication without server management, maintaining persistent connections for message transfer.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-04T15:50:41.142940"}}
{"question": "What are the two options offered by Amazon API Gateway for creating RESTful APIs?", "answer": "Amazon API Gateway offers two options for creating RESTful APIs: HTTP APIs and REST APIs.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-04T15:50:53.510894"}}
{"question": "What is the main difference between HTTP APIs and REST APIs in terms of features?", "answer": "HTTP APIs are optimized for building APIs that proxy to AWS Lambda functions or HTTP backends and do not offer API management functionality. In contrast, REST APIs provide API proxy functionality along with API management features such as usage plans, API keys, publishing, and monetizing APIs.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-04T15:50:53.511899"}}
{"question": "How do WebSocket APIs differ from HTTP APIs and REST APIs in terms of communication?", "answer": "WebSocket APIs maintain a persistent connection between connected clients to enable real-time message communication, whereas HTTP APIs and REST APIs do not focus on real-time communication and instead are designed for request-response interactions.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-04T15:50:53.512159"}}
{"question": "What are the primary use cases for HTTP APIs in Amazon API Gateway?", "answer": "HTTP APIs are ideal for building proxy APIs for AWS Lambda or any HTTP endpoint, building modern APIs equipped with OIDC and OAuth 2 authorization, handling workloads that are likely to grow very large, and for APIs that are latency sensitive.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-04T15:51:01.521664"}}
{"question": "How do HTTP APIs differ from REST APIs in terms of features and use cases?", "answer": "HTTP APIs are optimized for serverless workloads and are cheaper and faster than REST APIs, but they do not support API management functionality. In contrast, REST APIs are intended for use cases that require API proxy functionality and API management features in a single solution, making them suitable for customers looking for an all-inclusive set of features at a single price point.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-04T15:51:01.522001"}}
{"question": "What steps should you follow to migrate from a REST API to an HTTP API in Amazon API Gateway?", "answer": "To migrate from a REST API to an HTTP API in Amazon API Gateway, you should first check that all the features you need are available in HTTP by visiting the documentation. Then, export the OpenAPI definition from your REST API, import that OpenAPI definition into your HTTP API, test the API functions to ensure they work as expected, and finally, update your clients with the new URL. Be aware that you may need to review the Info, Warning, and Error fields from the Import operation to identify any missing features.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-04T15:51:01.522508"}}
{"question": "What must you do first before importing the OpenAPI definition into your HTTP API?", "answer": "First, you need to export the OpenAPI definition from your REST API before importing it into your HTTP API.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T15:51:07.047529"}}
{"question": "What features might be missing after importing an OpenAPI definition into an HTTP API?", "answer": "After importing the OpenAPI definition, you may notice some missing features, which can be identified by reviewing the Info, Warning, and Error fields from the Import operation.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T15:51:07.047810"}}
{"question": "How does Amazon API Gateway handle endpoint security for APIs compared to HTTP endpoints?", "answer": "All APIs created with Amazon API Gateway expose HTTPS endpoints only and do not support unencrypted (HTTP) endpoints, ensuring a higher level of security for data in transit.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T15:51:07.048293"}}
{"question": "What types of SDKs does API Gateway generate for mobile app development?", "answer": "API Gateway generates custom SDKs for mobile app development with Android and iOS, specifically in Swift and Objective-C.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-04T15:51:13.401772"}}
{"question": "What is the purpose of usage plans in API Gateway?", "answer": "Usage plans in API Gateway help declare plans for third-party developers that restrict access to certain APIs, define throttling and request quota limits, and associate them with API keys. They also allow you to extract utilization data on a per-API key basis to analyze API usage and generate billing documents.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-04T15:51:13.402122"}}
{"question": "How do REST APIs and HTTP APIs differ in terms of SDK generation in API Gateway?", "answer": "Client SDKs are only generated for REST APIs in Amazon API Gateway, while the context does not specify any SDK generation capabilities for HTTP APIs.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-04T15:51:13.402597"}}
{"question": "What is the purpose of stages in Amazon API Gateway?", "answer": "Stages in Amazon API Gateway are meant to help with the development lifecycle of an API. They allow you to deploy APIs to different environments, such as a development stage or a production stage, facilitating the transition from development to production.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T15:51:20.679498"}}
{"question": "How do stage variables function in Amazon API Gateway?", "answer": "Stage variables in Amazon API Gateway allow you to define key/value pairs of configuration values associated with a stage. These values can be used in your API configuration, similar to environment variables, enabling you to use a different endpoint or configuration for each stage without hardcoding it. They are also accessible in mapping templates for passing parameters to backends.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T15:51:20.679841"}}
{"question": "How do stages and Resource Policies differ in their functions within Amazon API Gateway?", "answer": "Stages in Amazon API Gateway are primarily used to manage different environments for API deployment, such as development or production, and define the paths through which the API is accessible. In contrast, Resource Policies are JSON documents attached to an API that control access permissions, determining who can invoke the API and under what conditions. While stages focus on deployment management, Resource Policies focus on security and access control.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T15:51:20.680208"}}
{"question": "What tool can be used to import Swagger API definitions into Amazon API Gateway?", "answer": "You can use the open source Swagger importer tool to import your Swagger API definitions into Amazon API Gateway.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-04T15:51:24.935839"}}
{"question": "How does API Gateway support documentation inheritance?", "answer": "API Gateway supports documentation inheritance by allowing you to define a documentation string once and then use it in multiple places. This simplifies the process of defining API documentation and can be converted to the standard representation when exporting the API as a Swagger file.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-04T15:51:24.936171"}}
{"question": "What are the differences in authorization methods that can be applied to API methods in Amazon API Gateway?", "answer": "In Amazon API Gateway, you can set your API methods to require authorization using either AWS Signature Version 4 or Lambda authorizers, which allows you to support your own bearer token authentication strategy.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-04T15:51:24.936583"}}
{"question": "What are AWS credentials used for in relation to API Gateway?", "answer": "AWS credentials, specifically access and secret keys, are used to sign requests to your service and authorize access to it, similar to how other AWS services operate.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-04T15:51:30.503623"}}
{"question": "Why is it not recommended to use API keys for authorization in API Gateway?", "answer": "It is not recommended to use API keys for authorization because API keys should be used to monitor usage by third-party developers, while a stronger mechanism for authorization, such as signed API calls or OAuth, should be leveraged.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-04T15:51:30.503931"}}
{"question": "How does API Gateway handle authorization through Lambda authorizers compared to using API keys?", "answer": "API Gateway uses Lambda authorizers to implement various authorization strategies, such as bearer token auth strategies like OAuth, which return IAM policies to authorize requests. In contrast, API keys are primarily used for monitoring usage and are not recommended for authorization. Lambda authorizers provide a more robust and secure method of authorizing access compared to API keys.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-04T15:51:30.504366"}}
{"question": "What integration does Amazon API Gateway have to provide an auditable history of changes to REST APIs?", "answer": "Amazon API Gateway is integrated with AWS CloudTrail to give you a full auditable history of the changes to your REST APIs.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T15:51:36.757172"}}
{"question": "What features does Amazon API Gateway provide for securing access to Private APIs?", "answer": "Amazon API Gateway allows you to apply a Resource Policy to restrict access to a specific Amazon VPC or VPC endpoint. Additionally, you can grant access to a Private API from an Amazon VPC or VPC endpoint in a different account using a Resource Policy.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T15:51:36.757531"}}
{"question": "How does monitoring and logging differ between Amazon API Gateway and Amazon CloudWatch for REST APIs?", "answer": "Amazon API Gateway logs API calls, latency, and error rates to Amazon CloudWatch. While API Gateway provides metrics at a REST API level by default, you can optionally enable detailed metrics for each method in your REST API, which are also logged to CloudWatch and charged at CloudWatch rates.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T15:51:36.757730"}}
{"question": "What logging features does Amazon API Gateway offer?", "answer": "Amazon API Gateway integrates with Amazon CloudWatch Logs, allowing you to optionally enable logging for each stage in your API. For each method in your REST APIs, you can set the verbosity of the logging and choose whether full request and response data should be logged. Logs, alarms, error rates, and other metrics are stored in Amazon CloudWatch and are available near real time.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-04T15:51:43.680622"}}
{"question": "How does throttling work in Amazon API Gateway?", "answer": "Throttling in Amazon API Gateway ensures that API traffic is controlled to help backend services maintain performance and availability. It provides throttling at multiple levels, including global and by service call. API owners can set throttling limits for standard rates and bursts, such as a rate limit of 1,000 requests per second for a specific method and a burst limit of 2,000 requests per second for a few seconds. Any requests exceeding the limit will receive a 429 HTTP response, and client SDKs (except Javascript) automatically retry calls when faced with this response.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-04T15:51:43.680991"}}
{"question": "What is the order of applying throttling settings in Amazon API Gateway?", "answer": "Throttling settings in Amazon API Gateway are applied in the following order: 1) per-client per-method throttling limits set for an API stage in a usage plan, 2) per-client throttling limits set in a usage plan, 3) default per-method limits and individual per-method limits set in API stage settings, and 4) account-level throttling per region.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-04T15:51:43.681405"}}
{"question": "What is the purpose of provisioning an API Gateway cache?", "answer": "The purpose of provisioning an API Gateway cache is to improve performance and reduce the traffic sent to your back end by storing responses for API calls. It allows you to control the cache key and the time-to-live (TTL) of the data stored for each method.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-04T15:51:49.790303"}}
{"question": "How does caching in API Gateway affect the performance of APIs?", "answer": "Caching in API Gateway affects the performance of APIs by allowing the service to return cached responses for duplicate requests within a customizable time frame, thus reducing the load on the backend service. This ensures optimal performance for the applications that the APIs support, particularly when requests are under configured throttling limits.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-04T15:51:49.790659"}}
{"question": "What happens to requests if caching is not enabled and throttling limits are not applied in API Gateway?", "answer": "If caching is not enabled and throttling limits are not applied, all requests will pass through to the backend service until the account-level throttling limits are reached. Once those limits are reached, Amazon API Gateway will start shedding requests, sending only the defined limit to the backend service.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-04T15:51:49.790868"}}
{"question": "What two metrics are used for billing in Amazon API Gateway WebSocket APIs?", "answer": "The two metrics used for billing in Amazon API Gateway WebSocket APIs are Connection minutes and Messages. Connection minutes refer to the total number of minutes that clients or devices are connected to the WebSocket connection, rounded to the nearest minute, while Messages refer to the total number of messages sent to and received from connected clients, charged in increments of 32KB.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-04T15:51:56.996753"}}
{"question": "How does WebSocket routing work in Amazon API Gateway?", "answer": "WebSocket routing in Amazon API Gateway is used to route messages to a specific integration. This is done by specifying a routing key and the integration backend to invoke when defining your WebSocket API. The routing key is an attribute found in the message body, and a default integration can also be set for any non-matching routing keys.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-04T15:51:56.996969"}}
{"question": "What happens to messages that fail authentication or authorization in a WebSocket connection compared to successfully authenticated messages?", "answer": "Messages on the WebSocket connection that fail authentication or authorization do not count toward your API usage bill, whereas messages that are successfully authenticated and authorized do count toward the billing metrics based on the total number of messages sent and received.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-04T15:51:56.997124"}}
{"question": "What is Amazon AppFlow?", "answer": "Amazon AppFlow is a fully managed integration service that enables users to securely transfer data between Software-as-a-Service (SaaS) applications, such as Salesforce, Marketo, Slack, and ServiceNow, and AWS services like Amazon S3 and Amazon Redshift.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-04T15:52:02.456056"}}
{"question": "How does Amazon AppFlow ensure data security during transfers?", "answer": "Amazon AppFlow ensures data security during transfers by automatically encrypting data in motion and allowing users to restrict data from flowing over the public Internet for SaaS applications that are integrated with AWS PrivateLink, thus reducing exposure to security threats.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-04T15:52:02.456383"}}
{"question": "What are the differences between running data flows on a schedule versus on demand in Amazon AppFlow?", "answer": "Running data flows on a schedule in Amazon AppFlow allows users to execute data transfers at predetermined times, while running them on demand enables users to initiate data transfers whenever they choose, in response to specific business events or needs.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-04T15:52:02.456958"}}
{"question": "What features does Amazon AppFlow include by default to facilitate integration?", "answer": "Amazon AppFlow includes features like data pagination, error logging, and network connection retries by default, which eliminates the need for coding or management.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-04T15:52:12.796172"}}
{"question": "How does Amazon AppFlow contribute to the speed and agility of application integration?", "answer": "Amazon AppFlow contributes to speed and agility by enabling users to integrate applications in a few minutes, removing the long wait times associated with coding custom connectors. This allows SaaS application administrators and business analysts to implement most integrations quickly without waiting months for IT to complete integration projects.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-04T15:52:12.797418"}}
{"question": "In what ways does AppFlow enhance data privacy and security compared to traditional integration methods?", "answer": "AppFlow enhances data privacy and security by encrypting data both at rest and in motion, allowing users to use AWS managed keys or bring their own custom keys. Additionally, it enables the restriction of data from flowing over the public Internet using Amazon VPC endpoints enabled by AWS PrivateLink, which minimizes threats from Internet-based attacks and reduces the risk of sensitive data leakage.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-04T15:52:12.797709"}}
{"question": "What are the steps an authorized IAM user needs to follow to create and configure a Flow in AppFlow?", "answer": "An authorized IAM user needs to follow these steps to create and configure a Flow in AppFlow: 1. Connect your data source and destination by naming your flow and choosing from the list of integrated application sources and destinations. 2. Choose your data flow trigger, which can be on demand, scheduled, or event-based. 3. Map source fields to destination, either by configuring field mapping or uploading a CSV file for bulk mappings, and optionally add data field transformations. 4. Add data filters and validations to include or exclude specific data fields and ensure data integrity. 5. Click Create Flow to finalize, and your data will begin to flow based on the triggers set.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-2", "source_tokens": 493, "generated_at": "2026-02-04T15:52:19.404498"}}
{"question": "What types of data flow triggers does AppFlow support?", "answer": "AppFlow supports three types of data flow triggers: on demand flows, which run once immediately; scheduled flows, which run at a specified interval; and event-based flows, which run in response to specific business events such as the creation of a sales opportunity or a status change in a support ticket.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-2", "source_tokens": 493, "generated_at": "2026-02-04T15:52:19.404830"}}
{"question": "How do the data flow triggers in AppFlow differ from each other?", "answer": "The data flow triggers in AppFlow differ in their execution timing and conditions: on demand flows are triggered immediately when initiated, scheduled flows are triggered at defined intervals, and event-based flows are triggered in response to specific business events.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-2", "source_tokens": 493, "generated_at": "2026-02-04T15:52:19.405019"}}
{"question": "What are the three different ways to run data flows using AppFlow?", "answer": "Data flows using AppFlow can be run in three different ways: on demand, event-based, and scheduled. On demand allows users to run flows immediately by clicking 'Run Flow'. Event-based runs flows in response to specific business events, such as creating a sales opportunity or changing the status of a support ticket. Scheduled runs flows at a routine schedule based on a chosen time interval.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T15:52:25.086007"}}
{"question": "How does AppFlow benefit users who prefer not to write code?", "answer": "AppFlow benefits users who prefer not to write code by allowing them to implement a range of common integration tasks without needing to learn the API documentation of various SaaS applications. It is a fully managed API integration service that simplifies the process of data integration by managing resources, API authorization, and the life-cycle of access tokens and API keys.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T15:52:25.086270"}}
{"question": "How do the sources and destinations supported by AppFlow compare?", "answer": "AppFlow supports a variety of sources such as Amazon S3, Salesforce, SAP, Marketo, Zendesk, and Slack. In contrast, it supports destinations for flows that include Amazon S3, Amazon RedShift, Salesforce, and Snowflake. This indicates that while some sources are SaaS applications, the destinations include both SaaS and AWS services.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T15:52:25.086424"}}
{"question": "What encryption method does AppFlow use for data at rest and in transit?", "answer": "AppFlow uses encryption at rest and in transit by default with your AWS managed customer master key (CMK). Additionally, users can choose to use their own managed keys, specifically customer managed CMKs, for encryption.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T15:52:32.726617"}}
{"question": "How does AppFlow differ from AWS DataSync in terms of its data handling capabilities?", "answer": "AppFlow is designed for operational data flows and facilitates the exchange of data between SaaS applications and AWS services, typically triggered by a person, an event, or a schedule. In contrast, AWS DataSync is intended for moving large amounts of data between on-premises sources and AWS Cloud, focusing on bulk data migration, processing, and backup or disaster recovery.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T15:52:32.727082"}}
{"question": "What is the primary function of AWS Glue in relation to data analytics?", "answer": "AWS Glue provides a managed ETL service that helps data engineers prepare and load data stored on AWS for analytics. It creates a data catalog from JDBC-compliant data sources, making metadata available for ETL and querying through services like Amazon Athena, Amazon EMR, and Amazon Redshift Spectrum.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T15:52:32.727491"}}
{"question": "How can I receive a history of AppFlow API calls made on my account?", "answer": "You can receive a history of AppFlow API calls made on your account by turning on CloudTrail in the AWS Management Console.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-5", "source_tokens": 31, "generated_at": "2026-02-04T15:52:38.954962"}}
{"question": "What is the purpose of enabling CloudTrail in relation to AppFlow API calls?", "answer": "The purpose of enabling CloudTrail in relation to AppFlow API calls is to receive a history of those API calls made on your account.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-5", "source_tokens": 31, "generated_at": "2026-02-04T15:52:38.955355"}}
{"question": "What is the relationship between CloudTrail and AppFlow API calls?", "answer": "The relationship between CloudTrail and AppFlow API calls is that CloudTrail must be enabled to track and provide a history of the AppFlow API calls made on your account.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-5", "source_tokens": 31, "generated_at": "2026-02-04T15:52:38.955713"}}
{"question": "What is AWS Application Migration Service (AWS MGN) primarily used for?", "answer": "AWS Application Migration Service (AWS MGN) is primarily used for migrating applications to AWS by automatically converting source servers from physical, virtual, or cloud infrastructure to run natively on AWS.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-04T15:52:45.465000"}}
{"question": "How does AWS Application Migration Service simplify the migration process?", "answer": "AWS Application Migration Service simplifies the migration process by allowing the use of the same automated process for a wide range of applications without requiring changes to the applications, their architecture, or the migrated servers. It also enables non-disruptive testing prior to cutover and allows for quick migrations during a short cutover window.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-04T15:52:45.465349"}}
{"question": "How does migrating applications using AWS Application Migration Service compare to migrating Amazon EC2 instances?", "answer": "Migrating applications using AWS Application Migration Service involves converting various types of source servers such as physical or virtual servers, while migrating Amazon EC2 instances can specifically include moving instances between AWS Regions or accounts, and migrating from EC2-Classic to a VPC. Both processes utilize the AWS Application Migration Service, but they target different sources and purposes.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-04T15:52:45.465842"}}
{"question": "What types of servers can be migrated using AWS Application Migration Service?", "answer": "AWS Application Migration Service allows you to migrate physical, virtual, and cloud source servers to AWS for a variety of supported operating systems.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T15:52:51.299716"}}
{"question": "Why is the agent-based replication option recommended over the agentless replication option in AWS Application Migration Service?", "answer": "The agent-based replication option is recommended because it provides continuous data replication and shortens cutover windows, which can enhance the migration process compared to agentless replication.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T15:52:51.300041"}}
{"question": "How does AWS Application Migration Service integrate with AWS Migration Hub?", "answer": "AWS Migration Hub is integrated with AWS Application Migration Service, allowing users to monitor the servers they are migrating using the AWS Migration Hub console.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T15:52:51.300572"}}
{"question": "What is the duration of the free period for using AWS Application Migration Service for each source server?", "answer": "The free period for using AWS Application Migration Service for each source server is 2,160 hours, which is equivalent to 90 days when used continuously.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T15:52:56.958687"}}
{"question": "What are the key features of AWS Application Migration Service compared to CloudEndure Migration?", "answer": "AWS Application Migration Service is described as the next generation of CloudEndure Migration and offers key features and operational benefits that are not available with CloudEndure Migration.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T15:52:56.958965"}}
{"question": "How does data encryption differ between replication in transit and at rest in AWS Application Migration Service?", "answer": "Data replication in transit using AWS Application Migration Service is encrypted using TLS 1.2, while data at rest on AWS is encrypted using Amazon EBS encryption.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T15:52:56.959557"}}
{"question": "Where can I find the most up-to-date information on AWS regional services?", "answer": "You can find the most up-to-date information on AWS regional services in the AWS Regional Services List.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-04T15:53:01.030625"}}
{"question": "Why is it important to refer to the AWS Regional Services List?", "answer": "It is important to refer to the AWS Regional Services List to ensure you have the latest information regarding the availability of AWS services in different regions.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-04T15:53:01.030885"}}
{"question": "How does the AWS Regional Services List differ from other AWS documentation?", "answer": "The AWS Regional Services List specifically focuses on the availability and up-to-date status of AWS services across different regions, while other AWS documentation may cover a broader range of topics, including service features, pricing, and usage guidelines.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-04T15:53:01.031394"}}
{"question": "What does AWS AppSync provide for setting up an API, schema, and data sources?", "answer": "AWS AppSync can automatically set up your entire API, schema, and connect data sources using a simple UI builder that allows you to type in your data model in seconds. The console also offers many sample schemas and data sources for fully functioning applications.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-04T15:53:08.095202"}}
{"question": "How does AWS AppSync handle GraphQL requests and what is the role of resolvers?", "answer": "GraphQL requests in AWS AppSync execute as 'resolvers' which need to be converted into the appropriate message format for various AWS Services that integrate with AppSync. For instance, a GraphQL query on a field will be converted into unique formats for services like Amazon DynamoDB, AWS Lambda, and Amazon OpenSearch Service. AppSync allows you to write custom logic for your resolvers using JavaScript and execute it on a custom AppSync JavaScript runtime.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-04T15:53:08.095534"}}
{"question": "What are the differences between using mock data for testing resolvers and interacting with real data sources in AWS AppSync?", "answer": "Using mock data for testing resolvers in AWS AppSync allows you to verify the behavior of your code directly from the console without interacting with actual data sources. This enables you to test the evaluation of your resolvers safely. In contrast, interacting with real data sources involves actual API calls and responses, which can affect the data and performance during the testing process.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-04T15:53:08.096042"}}
{"question": "What data sources can you interact with using JavaScript resolvers in AWS AppSync?", "answer": "You can interact with data sources like Amazon DynamoDB, Amazon Aurora Serverless, Amazon OpenSearch Service, HTTP APIs, and other AWS services using JavaScript resolvers in AWS AppSync.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-04T15:53:15.787989"}}
{"question": "How does the Merged APIs feature in AWS AppSync benefit organizations?", "answer": "The Merged APIs feature in AWS AppSync benefits organizations by allowing them to provide a single API schema to data consumers while enabling independent evolution of sub-schemas by the teams that are most familiar with their related data domains. This facilitates collaboration among teams that share development of a single AppSync API while allowing them to operate independently.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-04T15:53:15.788261"}}
{"question": "What is the difference between using JavaScript resolvers and Lambda data sources in AWS AppSync?", "answer": "The difference between using JavaScript resolvers and Lambda data sources in AWS AppSync is that JavaScript resolvers allow you to implement custom business logic to access data sources directly without additional infrastructure, while Lambda data sources are used when complex business logic is required that is not supported by JavaScript resolvers. Lambda data sources act as a proxy to interact with the target data source and utilize the full capabilities of AWS Lambda.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-04T15:53:15.788838"}}
{"question": "What types of data sources are supported by AWS AppSync?", "answer": "AWS AppSync supports data sources such as Amazon DynamoDB, Amazon OpenSearch Service, and AWS Lambda.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T15:53:22.040945"}}
{"question": "How does AWS AppSync facilitate the use of GraphQL for existing DynamoDB tables?", "answer": "AWS AppSync can automatically generate a GraphQL schema from an existing DynamoDB table, inferring the tables key schema and indexes. This allows for the use of GraphQL queries, mutations, and subscriptions with zero coding once the import is complete.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T15:53:22.041225"}}
{"question": "What are the recommended Amplify client categories for connecting to AWS AppSync based on data source type and offline requirements?", "answer": "For DynamoDB data sources, the recommended category is the DataStore category in the Amplify client, as it provides the best developer experience and built-in conflict detection and resolution. For non-DynamoDB data sources without offline requirements, the API (GraphQL) category should be used. For non-DynamoDB data sources with offline requirements, the AppSync SDK is recommended.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T15:53:22.041400"}}
{"question": "What is required to create a custom domain name for an AWS AppSync API?", "answer": "To create a custom domain name for an AWS AppSync API, you need to provide a domain name that you own and indicate a valid AWS Certificate Manager (ACM) certificate that covers your domain.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T15:53:28.823258"}}
{"question": "How does AWS AppSync handle requests on a custom domain endpoint?", "answer": "When AWS AppSync receives a request on the custom domain endpoint, it routes the request to the associated API for handling.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T15:53:28.823589"}}
{"question": "What is the difference between a channel and a namespace in AWS AppSync Events?", "answer": "A channel is a routing concept that serves as the logical destination of an event, allowing publishers to specify where their events should be routed and subscribers to monitor for arriving events. In contrast, a namespace is a logical construct used to define capabilities shared by channels within it, such as defining multiple authorization modes for an Event API and attaching specific modes to namespaces.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T15:53:28.824051"}}
{"question": "What is the purpose of Event Handlers in an API?", "answer": "Event Handlers allow you to define the runtime behavior of your API and provide logic that is executed in response to system events.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-04T15:53:34.161490"}}
{"question": "How can Event Handlers enhance the functionality of an API?", "answer": "Event Handlers enhance the functionality of an API by allowing you to attach logic that responds to specific events, such as client subscriptions and message publications, enabling authorization, filtering, and event transformation.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-04T15:53:34.161826"}}
{"question": "What are the differences between the onSubscribe and onPublish handlers?", "answer": "The onSubscribe handler is called when a client subscribes to a channel in the namespace, allowing for subscription authorization and filtering. In contrast, the onPublish handler is called for events published to your channels and allows you to transform the event before it is sent to subscribed clients, with the option to drop messages by returning null.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-04T15:53:34.162281"}}
{"question": "What is AWS Artifact?", "answer": "AWS Artifact is a self-service audit artifact retrieval portal available in the console that provides customers with on-demand access to AWS' compliance documentation and AWS agreements.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-04T15:53:40.954915"}}
{"question": "How can IAM users with non-admin permissions access AWS Artifact?", "answer": "IAM users with non-admin permissions can access AWS Artifact by being granted access using IAM permissions. This allows you to grant a user access to AWS Artifact while restricting access to other services and resources within your AWS Account.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-04T15:53:40.955209"}}
{"question": "What is the difference between an Active Agreement and an Inactive Agreement in AWS Artifact?", "answer": "An Agreement is in an Active state if it has been accepted by the user, while it is in an Inactive state if it has not been accepted or if a previously accepted Agreement has been terminated by the user.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-04T15:53:40.955377"}}
{"question": "What is an audit artifact in the context of AWS Artifact?", "answer": "An audit artifact is a piece of evidence that demonstrates that an organization is following a documented process or meeting a specific requirement. Audit artifacts are gathered and archived throughout the system development life cycle and are to be used as evidence in internal and/or external audits and assessments.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-04T15:53:46.711950"}}
{"question": "How can IAM policies be utilized in AWS Artifact?", "answer": "IAM policies can be utilized in AWS Artifact to delegate permissions differently for various users based on the level of access they need. This allows for specific configurations of user permissions to control access to documents and agreements.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-04T15:53:46.712238"}}
{"question": "What are the differences between providing AWS audit artifacts to auditors and using them for designing cloud architecture?", "answer": "Providing AWS audit artifacts to auditors involves supplying them as evidence of AWS security controls, while using the artifacts for designing cloud architecture involves leveraging the responsibility guidance provided to determine additional security controls needed for specific use cases of a system.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-04T15:53:46.712682"}}
{"question": "What is the purpose of AWS Artifact Reports?", "answer": "AWS Artifact Reports can be used by all AWS customers to assess and validate the security and compliance of the AWS infrastructure and services that they use.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T15:53:53.395320"}}
{"question": "When should a user consider using AWS Artifact Reports?", "answer": "You should use AWS Artifact Reports if you are obligated to demonstrate the compliance of your cloud architectures during system design, development, and audit life cycles, are required to or are interested in using audit artifacts to validate that your AWS implemented controls are operating effectively, are interested in continuously monitoring or auditing your suppliers, or are a member of a development team building secure cloud architectures and need guidance on complying with ISO, PCI, SOC, and other regulatory standards.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T15:53:53.395651"}}
{"question": "How does sharing AWS compliance reports with customers differ from accessing them directly?", "answer": "You can share the AWS compliance reports with your customers directly if permitted by the terms and conditions applicable to the specific AWS compliance report. Alternatively, customers can access AWS compliance reports using their own AWS Account, and if they do not have an account, they can create one at no charge. This means that sharing is subject to specific permissions, while customers have the option to access reports independently through their accounts.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T15:53:53.396178"}}
{"question": "Who can access third-party compliance reports from AWS Marketplace Vendor Insights?", "answer": "Only those AWS customers who have been granted access to AWS Marketplace Vendor Insights for a specific Independent Software Vendor (ISV) can access third-party compliance reports.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:53:59.705845"}}
{"question": "What is the purpose of AWS Artifact Agreements?", "answer": "AWS Artifact Agreements enables customers to review, accept, and manage agreements with AWS for their individual account and for all accounts that are part of their organization in AWS Organizations. It also allows customers to terminate agreements they have previously accepted if they are no longer required.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:53:59.706170"}}
{"question": "How does the sharing of third-party compliance reports differ from AWS Artifact Agreements?", "answer": "The sharing of third-party compliance reports is governed by the applicable Terms and Conditions (T&Cs) documented on the cover page of the downloaded report, which may vary for each report. In contrast, AWS Artifact Agreements requires customers to download and agree to the AWS Artifact nondisclosure agreement (NDA) before accessing and downloading confidential documents, and each agreement is confidential and cannot be shared with others outside of the company.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:53:59.706665"}}
{"question": "What permissions does an administrator of an AWS account have regarding agreements?", "answer": "An administrator of an AWS account automatically has permissions to download, accept, and terminate agreements for that account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-04T15:54:04.874708"}}
{"question": "Why is it important to review agreement terms with legal, privacy, and compliance teams before accepting them?", "answer": "It is important to review agreement terms with legal, privacy, and compliance teams to ensure that the terms are in line with the organization's policies and compliance requirements before acceptance.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-04T15:54:04.875031"}}
{"question": "How do AWS Artifact Account Agreements differ from AWS Artifact Organization Agreements in terms of application?", "answer": "AWS Artifact Account Agreements apply only to the individual account used to sign into AWS, while AWS Artifact Organization Agreements apply to all accounts in an organization created through AWS Organizations, including both the management account and all member accounts.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-04T15:54:04.875521"}}
{"question": "What must be enabled for an organization to accept agreements on behalf of all member accounts?", "answer": "The organization must be enabled for all features in order to accept agreements on behalf of all current and future member accounts.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-04T15:54:09.407920"}}
{"question": "Why does AWS need permission to create a service-linked role in your account?", "answer": "AWS needs permission to create a service-linked role in your account so that the AWS Artifact service can ListAccounts to identify the complete list of member accounts in your organization when an agreement is accepted.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-04T15:54:09.408128"}}
{"question": "How do the roles of a management account and member accounts differ in an AWS Organization regarding agreement acceptance?", "answer": "Only management accounts can use AWS Artifact Organization Agreements to accept or terminate agreements on behalf of all accounts in an organization, while member accounts do not have this capability.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-04T15:54:09.408302"}}
{"question": "What is a member account in AWS Organizations?", "answer": "A member account is an AWS account, other than the management account, that is part of an organization in AWS Organizations.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-04T15:54:15.921934"}}
{"question": "How do member accounts interact with AWS Artifact Account Agreements and AWS Artifact Organization Agreements?", "answer": "Member accounts can use AWS Artifact Account Agreements to accept or terminate agreements on behalf of that individual member account only. Additionally, member accounts can use AWS Artifact Organization Agreements to view the agreements accepted on the member accounts behalf by the organizations management account.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-04T15:54:15.922209"}}
{"question": "What is the difference between AWS Artifact Account Agreements and AWS Artifact Organization Agreements in terms of accepting agreements?", "answer": "AWS Artifact Account Agreements allows member accounts to accept agreements individually for that specific account, while AWS Artifact Organization Agreements allows the management account to accept agreements on behalf of all accounts within the organization. If agreements need to be accepted for only some member accounts, each account must be signed in to individually to accept the relevant agreements via AWS Artifact Account Agreements.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-04T15:54:15.922683"}}
{"question": "Can both management accounts and member accounts have AWS Artifact Account Agreements and Organization Agreements at the same time?", "answer": "Yes, management accounts and member accounts can have AWS Artifact Account Agreements and AWS Artifact Organization Agreements of the same type in place at the same time.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T15:54:21.478718"}}
{"question": "What happens to an account agreement if an organization agreement is terminated?", "answer": "If an organization agreement is terminated, the account agreement in place for that individual account will remain active and will continue to apply. The account agreement will apply to that account if the organization agreement is no longer in effect.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T15:54:21.478993"}}
{"question": "How do the organization agreements and account agreements differ in terms of their applicability when both are active?", "answer": "When both an organization agreement and an account agreement of the same type are active, the organization agreement will apply instead of the account agreement. If the organization agreement is terminated, then the account agreement will apply to that account.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T15:54:21.479420"}}
{"question": "What is the purpose of AWS Artifact Agreements?", "answer": "AWS Artifact Agreements enables you to review and accept the AWS BAA from the AWS Management Console for your account or your organization in AWS Organizations. It allows you to designate your AWS account(s) for use in connection with protected health information (PHI) upon acceptance.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T15:54:27.315783"}}
{"question": "How does accepting the AWS BAA under the Organization agreements tab differ from accepting it under the Account agreements tab?", "answer": "When you accept the AWS BAA under the Organization agreements tab, it applies to all accounts linked to your management account through AWS Organizations, automatically designating them as HIPAA Accounts. In contrast, accepting the BAA under the Account agreements tab only applies to the individual account you used to accept the account BAA, and does not affect any other accounts.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T15:54:27.316112"}}
{"question": "What happens to member accounts added to an organization after the management account accepts the organization BAA?", "answer": "Member accounts that are later added to the organization will be automatically designated as HIPAA Accounts once the management account accepts the organization BAA in AWS Artifact Agreements.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T15:54:27.316553"}}
{"question": "What is the purpose of the Organization agreements tab in AWS Artifact Agreements?", "answer": "The Organization agreements tab in AWS Artifact Agreements allows the management account of your organization to accept an organization BAA on behalf of all existing and future member accounts in the organization. When both the account and organization BAA are accepted, the organization BAA will apply instead of the account BAA.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-04T15:54:33.392120"}}
{"question": "What should you do before terminating a BAA if you are no longer using AWS accounts in connection with PHI?", "answer": "Before terminating a BAA, you should ensure that you have removed all protected health information (PHI) from the account and will no longer use the account in connection with PHI. This applies to both individual accounts and organization accounts.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-04T15:54:33.392390"}}
{"question": "How does the acceptance of an organization BAA affect existing account BAAs?", "answer": "If you have both an account BAA and an organization BAA in place at the same time, the terms of the organization BAA will apply instead of the terms of the account BAA. However, terminating the organization BAA does not terminate the account BAA, so if you terminate the organization BAA, the account BAA will continue to apply to that account.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-04T15:54:33.392574"}}
{"question": "What happens to accepted organization agreements when a member account leaves an organization?", "answer": "When a member account leaves an organization, any accepted organization agreement(s) no longer apply to that account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-04T15:54:37.937115"}}
{"question": "Why is it recommended to use AWS Artifact Agreements instead of entering into an offline BAA?", "answer": "It is recommended to use AWS Artifact Agreements because they provide speed, efficiency, and visibility compared to entering into an offline BAA.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-04T15:54:37.937440"}}
{"question": "How do the terms of an offline BAA apply to accounts designated as HIPAA Accounts?", "answer": "If you previously signed an offline BAA, the terms of that BAA will continue to apply to the accounts you designated as HIPAA Accounts under that offline BAA. For any accounts not designated as HIPAA Accounts under your offline BAA, you can use AWS Artifact Agreements to accept an online BAA for those accounts.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-04T15:54:37.937883"}}
{"question": "What is the process to designate additional HIPAA Accounts under an offline BAA?", "answer": "To designate additional HIPAA Accounts under your offline BAA, you need to follow the process described in your offline BAA, which may include sending an email to aws-hipaa@amazon.com. Once confirmed by AWS, the Artifact Agreements interface will change for the newly designated account to reflect its status as a HIPAA Account under your offline BAA.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-04T15:54:44.452680"}}
{"question": "What are the requirements for an AWS account to be considered a HIPAA Account?", "answer": "An AWS account is considered a HIPAA Account if it stores or transmits protected health information (PHI), uses only HIPAA Eligible Services to store or transmit that PHI, and has applied the required security configurations specified in the AWS BAA, such as encryption of PHI at rest and in transit.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-04T15:54:44.453013"}}
{"question": "How does removing an account as a HIPAA Account under the offline BAA differ from terminating the offline BAA itself?", "answer": "Removing an account as a HIPAA Account under your offline BAA can be done through AWS Artifact Agreements, but it does not terminate the offline BAA itself. To terminate an offline BAA, you must provide written notice to AWS according to the terms of the offline BAA.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-04T15:54:44.453401"}}
{"question": "What is the purpose of AWS Artifact Agreements?", "answer": "AWS Artifact Agreements enables you to review and accept an ANDB Addendum from the AWS Management Console for either your AWS account or your AWS organization if you are a management account. It allows you to see which agreements are in place and review their terms.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-04T15:54:50.640370"}}
{"question": "How does accepting the ANDB Addendum in the Organization agreements tab differ from the Account agreements tab?", "answer": "Accepting the ANDB Addendum in the Organization agreements tab applies to all existing and future AWS accounts linked to your management account through AWS Organizations. In contrast, accepting the ANDB Addendum in the Account agreements tab only applies to the individual AWS account you used to accept it.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-04T15:54:50.640702"}}
{"question": "If a user accepts both the account ANDB Addendum and the organizations ANDB Addendum, which one takes precedence?", "answer": "If both the account ANDB Addendum and the organizations ANDB Addendum are accepted, the organizations ANDB Addendum will apply instead of the account ANDB Addendum.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-04T15:54:50.641268"}}
{"question": "What happens to an AWS account when you terminate an account ANDB Addendum?", "answer": "When you terminate an account ANDB Addendum, the AWS account you used to sign into AWS Artifact will not be covered by an ANDB Addendum with AWS unless it is also covered by an organization's ANDB Addendum.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T15:54:55.396567"}}
{"question": "What should you ensure before terminating an organizations ANDB Addendum?", "answer": "Before terminating an organizations ANDB Addendum, you should ensure that all personal information has been removed from the AWS accounts in that AWS organization and that those AWS accounts will no longer be used in connection with personal information, or that you have agreed account ANDB Addendums for those AWS accounts that are used in connection with personal information.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T15:54:55.396843"}}
{"question": "How do the terms of an organizations ANDB Addendum relate to an account ANDB Addendum when both are in place?", "answer": "If you have both an account ANDB Addendum and an organizations ANDB Addendum in place at the same time, the terms of the organizations ANDB Addendum will apply instead of the terms of the account ANDB Addendum.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T15:54:55.397327"}}
{"question": "What defines an ANDB Account according to the organizations ANDB Addendum?", "answer": "An ANDB Account is defined as an AWS account where the entity responsible for that account is subject to the Australian Privacy Act, and that AWS account includes 'personal information' as defined in the Australian Privacy Act in AWS' possession or control.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T15:55:01.118254"}}
{"question": "What is the primary purpose of the AWS Artifact Agreements?", "answer": "The primary purpose of the AWS Artifact Agreements is to enable users to review and accept the NZNDB Addendum either for their individual AWS account or, if they are a management account in an AWS organization, for their entire AWS organization.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T15:55:01.118528"}}
{"question": "What is the difference between accepting the NZNDB Addendum in the Account agreements tab and the Organization agreements tab?", "answer": "The NZNDB Addendum accepted in the Organization agreements tab applies to all existing and future AWS accounts linked to the management account through AWS Organizations, whereas the NZNDB Addendum accepted in the Account agreements tab only applies to the individual AWS account used to accept it. If both are accepted, the organizations NZNDB Addendum takes precedence over the account NZNDB Addendum.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T15:55:01.118872"}}
{"question": "How can I terminate an account NZNDB Addendum in AWS Artifact?", "answer": "To terminate an account NZNDB Addendum, you can use the Account agreements tab in AWS Artifact and click on the 'Terminate the AWS New Zealand Notifiable Data Breach Addendum for this Account' button.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-04T15:55:07.831302"}}
{"question": "What should you ensure before terminating an account NZNDB Addendum?", "answer": "Before terminating an account NZNDB Addendum, you should ensure that you have removed all personal information from the AWS account and that you will no longer use the AWS account in connection with personal information, or that you join that AWS account as a member account in an AWS organization that has an organizations NZNDB Addendum.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-04T15:55:07.831578"}}
{"question": "What is the difference between terminating an account NZNDB Addendum and an organizations NZNDB Addendum?", "answer": "Terminating an account NZNDB Addendum affects only the specific AWS account you used to sign into AWS Artifact, meaning it will not be covered by an NZNDB Addendum unless it is also covered by an organizations NZNDB Addendum. In contrast, terminating an organizations NZNDB Addendum impacts all AWS accounts in that organization, which will not be covered by an NZNDB Addendum unless they have account NZNDB Addendums.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-04T15:55:07.831996"}}
{"question": "What happens to the account NZNDB Addendum when the organizations NZNDB Addendum is in place?", "answer": "When both an account NZNDB Addendum and an organizations NZNDB Addendum are in place, the terms of the organizations NZNDB Addendum will apply instead of the terms of the account NZNDB Addendum.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-04T15:55:14.668531"}}
{"question": "Why would a member account need to accept account agreements before leaving an AWS organization?", "answer": "A member account needs to accept account agreements before leaving an AWS organization because once it leaves the organization, any accepted organization agreement(s), like the organizations NZNDB Addendum, no longer apply. To ensure that relevant agreements continue to apply after leaving, the member account should accept them under the Account agreements tab in AWS Artifact prior to leaving.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-04T15:55:14.668865"}}
{"question": "How does the application of the organizations NZNDB Addendum differ for NZNDB Accounts versus non-NZNDB Accounts?", "answer": "The organizations NZNDB Addendum only applies to NZNDB Accounts, which are defined as AWS accounts where the responsible entity is subject to the New Zealand Privacy Act and holds personal information as defined by that act. In contrast, accounts that do not meet this definition of an NZNDB Account are not subject to the organizations NZNDB Addendum.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-04T15:55:14.669390"}}
{"question": "What permission do I need to accept agreements in AWS Artifact?", "answer": "To accept agreements in AWS Artifact, you need the permission artifact:AcceptAgreement. You should contact your account administrator to attach this permission to your IAM user.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-04T15:55:20.095121"}}
{"question": "Why might I receive an error message stating I don't have permissions to download the agreement in AWS Artifact?", "answer": "You might receive this error message because your IAM user does not have the required permission artifact:DownloadAgreement to download agreements in AWS Artifact. This indicates insufficient permissions to perform the desired action.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-04T15:55:20.095390"}}
{"question": "How do the permissions required for managing agreements differ from those required for accepting agreements in AWS Artifact?", "answer": "To manage agreements for your organization in AWS Artifact, you need permissions such as iam:ListRoles, iam:CreateRole, and iam:AttachRolePolicy. In contrast, to accept agreements, you only need the permission artifact:AcceptAgreement. This highlights that managing agreements requires broader IAM permissions compared to simply accepting them.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-04T15:55:20.095545"}}
{"question": "What permission do I need to enable AWS service access for my IAM user?", "answer": "You need to contact your account administrator to attach the permission 'organizations:EnableAWSServiceAccess' to your IAM user.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-04T15:55:26.765867"}}
{"question": "Why might my delivery channel status be 'Pending'?", "answer": "Your delivery channel status may be 'Pending' because the given email has not been verified yet. You should check your inbox and spam folders for a verification email from AWS User Notifications.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-04T15:55:26.766144"}}
{"question": "What are the differences between the permissions required to list configurations and those required to create a configuration?", "answer": "To list configurations, you need permissions such as 'artifact:GetAccountSettings', 'notifications:ListChannels', 'notifications:ListEventRules', 'notifications:ListNotificationConfigurations', 'notifications:ListNotificationHubs', and 'notifications-contacts:GetEmailContact'. In contrast, to create a configuration, you need permissions including 'artifact:GetAccountSettings', 'artifact:PutAccountSettings', 'notifications:AssociateChannel', 'notifications:CreateEventRule', 'notifications:TagResource', 'notifications:CreateNotificationConfiguration', 'notifications-contacts:CreateEmailContact', 'notifications-contacts:SendActivationCode', and 'notifications:ListNotificationHubs'.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-04T15:55:26.766733"}}
{"question": "What permission is required to list email contacts in AWS notifications?", "answer": "The permission required to list email contacts in AWS notifications is 'notifications-contacts:ListEmailContacts'.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-04T15:55:32.068584"}}
{"question": "Why might a user need to contact their account administrator regarding IAM permissions?", "answer": "A user might need to contact their account administrator to attach specific permissions to their IAM user, as they may not have the necessary permissions to perform certain actions such as editing configurations, deleting configurations, viewing details, or registering notification hubs.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-04T15:55:32.068901"}}
{"question": "What is the difference between the permissions required for editing configurations and deleting configurations?", "answer": "To edit configurations, a user needs permissions such as 'artifact:GetAccountSettings', 'notifications:UpdateNotificationConfiguration', and 'notifications:UpdateEventRule'. In contrast, to delete configurations, the necessary permission is 'notifications:DeleteNotificationConfiguration'. This indicates that the permissions for editing include a broader set of actions compared to the single permission required for deletion.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-04T15:55:32.069098"}}
{"question": "What is the purpose of AWS Artifact notifications?", "answer": "The purpose of AWS Artifact notifications is to provide users with a user interface to subscribe and unsubscribe to notifications about the availability of new documents, such as reports or agreements, or updates to existing documents. This allows users to proactively learn about new content without manually checking the AWS Artifact console.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-04T15:55:39.101960"}}
{"question": "How can users filter notifications for reports in AWS Artifact?", "answer": "Users can filter notifications for reports in AWS Artifact by choosing specific categories and series of reports on which they need notifications. This allows them to receive updates only for the reports that are relevant to them.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-04T15:55:39.102295"}}
{"question": "What is the difference between subscribing to notifications and creating notification configurations in AWS Artifact?", "answer": "Subscribing to notifications in AWS Artifact is a one-time action that allows users to opt-in to receive notifications, while creating notification configurations is the subsequent step where users specify whether they need notifications for all reports and agreements or a subset of reports, and provide the email addresses of individuals who would like to receive notifications.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-04T15:55:39.102818"}}
{"question": "How many email addresses can be provided per notification configuration in AWS Artifact notifications?", "answer": "You can provide up to 20 email addresses per notification configuration in AWS Artifact notifications.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-04T15:55:43.643769"}}
{"question": "What is the purpose of the AWS User Notifications service in relation to AWS Artifact notifications?", "answer": "The AWS User Notifications service is leveraged by AWS Artifact notifications to configure notifications and to send emails to the verified email addresses provided by the user.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-04T15:55:43.644082"}}
{"question": "How do notifications differ in their delivery method between email and the AWS User Notifications center console?", "answer": "Notifications will be delivered to the verified email addresses provided by the user and also delivered within the AWS User Notifications center console. However, notifications are only sent to verified email addresses, while they are accessible in the console regardless of email verification.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-04T15:55:43.644613"}}
{"question": "What is Amazon Athena and what does it allow users to do?", "answer": "Amazon Athena is an interactive analytics service that makes it simple to analyze data in Amazon Simple Storage Service (S3) using SQL. It allows users to analyze data immediately without setting up or managing infrastructure, as it is serverless. Users do not need to load their data into Athena; it works directly with data stored in Amazon S3.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-04T15:55:50.788460"}}
{"question": "What are the benefits of using Amazon Athena for data analysis?", "answer": "The benefits of using Amazon Athena for data analysis include its serverless architecture, which means there is no infrastructure to set up or manage, allowing users to start analyzing data immediately. Additionally, Athena works directly with data stored in Amazon S3, eliminating the need for data loading. It supports full standard SQL with various data formats such as CSV, JSON, Apache ORC, Apache Parquet, and Apache Avro.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-04T15:55:50.788791"}}
{"question": "How does Amazon Athena for SQL differ from Amazon Athena for Apache Spark?", "answer": "Amazon Athena for SQL uses Trino and Presto with full standard SQL support and works with various standard data formats, while Amazon Athena for Apache Spark supports SQL but allows users to utilize Apache Spark, which is an open-source, distributed processing system used for big data workloads. This indicates that Athena for SQL focuses on SQL-based queries directly, while Athena for Apache Spark is designed for more complex processing tasks typical in big data applications.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-04T15:55:50.789276"}}
{"question": "What types of data formats can Athena process?", "answer": "Athena can process unstructured, semi-structured, and structured datasets. Examples of data formats include CSV, JSON, Avro, and columnar data formats such as Parquet and ORC.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-04T15:55:56.136191"}}
{"question": "How does Athena facilitate data analysis without loading data?", "answer": "Athena allows users to run interactive analytics using ANSI SQL or Python directly on data stored in S3, without the need to aggregate or load the data into Athena. This means queries can be executed directly on the data in S3.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-04T15:55:56.136448"}}
{"question": "What are the differences between accessing Athena through the AWS Management Console versus using the ODBC or JDBC driver?", "answer": "Accessing Athena through the AWS Management Console allows users to create schemas and run queries using a built-in query editor. In contrast, using the ODBC or JDBC driver enables programmatic access, allowing users to run queries, add tables, or partitions programmatically.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-04T15:55:56.136786"}}
{"question": "What data formats does Athena for SQL support?", "answer": "Athena for SQL supports various standard data formats, including CSV, JSON, ORC, Avro, and Parquet.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-04T15:56:01.751827"}}
{"question": "How does the continuous integration approach in Athena version 3 benefit users?", "answer": "The continuous integration approach in Athena version 3 keeps customers up to date with the Trino and PrestoDB projects by aiming to stay within 60-90 days of open-source Trino launches. This ensures that users benefit from the latest features and improvements in open-source software management.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-04T15:56:01.752162"}}
{"question": "What is the difference in catalog usage between regions where AWS Glue is available and those where it is not for Athena?", "answer": "In regions where AWS Glue is available, Athena uses a managed AWS Glue Data Catalog to store information and schemas about the databases and tables. In regions where AWS Glue is not available, Athena uses an internal catalog instead.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-04T15:56:01.752662"}}
{"question": "What are the three main components of AWS Glue?", "answer": "The three main components of AWS Glue are: 1) a crawler that automatically scans your data sources, identifies data formats, and infers schemas; 2) a fully managed ETL service that allows you to transform and move data to various destinations; and 3) a Data Catalog that stores metadata information about databases and tables either stored in S3 or an ODBC- or JDBC-compliant data store.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-04T15:56:08.655446"}}
{"question": "Why is it beneficial to upgrade from Athenas internal Data Catalog to the Glue Data Catalog?", "answer": "Upgrading to the Glue Data Catalog provides benefits such as a unified metadata repository that is integrated across various AWS services, automatic schema and partition recognition, and support for data stored in multiple sources including Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for PostgreSQL, Amazon Redshift, and S3.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-04T15:56:08.655777"}}
{"question": "How does AWS Glue's automatic schema recognition compare with the manual management of schemas in Athena's internal Data Catalog?", "answer": "AWS Glue's automatic schema recognition allows for the automatic crawling of data sources, identification of data formats, and suggestion of schemas and transformations, which can help automate table creation and loading of partitions. In contrast, Athena's internal Data Catalog requires more manual management of schemas without these automated capabilities.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-04T15:56:08.656200"}}
{"question": "What types of data formats does Athena support?", "answer": "Athena supports various data formats including CSV, TSV, JSON, and Textfiles. It also supports open-source columnar formats such as ORC and Parquet, as well as compressed data formats like Snappy, Zlib, LZO, and GZIP.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-04T15:56:14.821080"}}
{"question": "How does Athena's schema-on-read approach benefit users?", "answer": "Athena's schema-on-read approach allows users to project their schema onto the data when executing a query, which decreases the need for any data loading or transformation. This means that users can run queries directly against their data in S3 without modifying the data itself.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-04T15:56:14.821411"}}
{"question": "What is the difference between Athena's use of Hive and Trino/Presto?", "answer": "Athena uses Hive specifically for Data Definition Language (DDL) tasks, which include the creation, modification, and deletion of tables or partitions. In contrast, when executing SQL queries against data on S3, Athena utilizes Trino and Presto, allowing users to run ANSI-compliant SQL SELECT statements.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-04T15:56:14.821882"}}
{"question": "What does SerDe stand for and what is its purpose in Hive and Athena?", "answer": "SerDe stands for Serializer/Deserializer, which are libraries that tell Hive how to interpret data formats. In Hive and Athena, SerDes are required in DDL statements to specify how the system interprets the data being pointed to.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-04T15:56:21.581548"}}
{"question": "How does Athena utilize SerDes and what is their relationship with Hive?", "answer": "Athena uses SerDes to interpret data read from S3, and the concept of SerDes in Athena is the same as that used in Hive. This means that the way data formats are handled in Athena is consistent with how they are managed in Hive.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-04T15:56:21.581802"}}
{"question": "What are the supported SerDes in Athena, and how do Parquet and ORC files created with Spark compare in terms of read capability?", "answer": "Athena supports various SerDes including Apache Web Logs, CSV, TSV, Custom Delimiters, Parquet, Orc, and JSON. Both Parquet and ORC files created with Spark can be read in Athena, indicating that they are compatible formats for querying within the Athena environment.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-04T15:56:21.582163"}}
{"question": "What clause is used to specify the partitioning scheme when creating a table in Athena?", "answer": "You can specify your partitioning scheme using the PARTITIONED BY clause in the CREATE TABLE statement.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T15:56:26.984122"}}
{"question": "How do partitions in Athena contribute to performance improvements during queries?", "answer": "Partitions allow you to limit the amount of data that each query scans, leading to cost savings and faster performance.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T15:56:26.984392"}}
{"question": "What is the difference between querying a partitioned table and a non-partitioned table in Athena regarding adding new data?", "answer": "If your data is partitioned, you will need to run a metadata query (ALTER TABLE ADD PARTITION) to add the partition to Athena after new data becomes available on S3. In contrast, if your data is not partitioned, adding the new data (or files) to the existing prefix automatically adds the data to Athena.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T15:56:26.984910"}}
{"question": "What are some methods to improve query performance in Athena?", "answer": "You can improve the performance of your query in Athena by compressing, partitioning, or converting your data into columnar formats. Athena supports open-source columnar data formats, such as Parquet and ORC, which lower costs and improve query performance by enabling Athena to scan less data from S3.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-04T15:56:32.880001"}}
{"question": "How do UDFs enhance the functionality of Athena queries?", "answer": "UDFs, or User Defined Functions, enhance the functionality of Athena queries by allowing users to write custom scalar functions that can perform specific processing tasks. This includes operations like compressing and decompressing data, redacting sensitive information, or applying customized decryption. UDFs can be used in both SELECT and FILTER clauses of a SQL query, providing greater flexibility in data manipulation.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-04T15:56:32.880273"}}
{"question": "How does the use of UDFs in Athena compare to built-in functions?", "answer": "The use of UDFs in Athena provides the capability to perform custom processing, which is not possible with built-in functions. While Athena offers various built-in functions for common operations, UDFs allow for tailored functionality that can address specific requirements, such as handling sensitive data or performing unique transformations. This makes UDFs more versatile in scenarios where built-in functions do not suffice.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-04T15:56:32.880472"}}
{"question": "What types of databases can organizations store data in according to the context?", "answer": "Organizations can store data in various types of databases including relational, key-value, document, in-memory, search, graph, time-series, and ledger databases. Additionally, they can store data in an S3 data lake.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-04T15:56:39.412677"}}
{"question": "How does Athena simplify the process of performing analytics on diverse data sources?", "answer": "Athena simplifies the process of performing analytics on diverse data sources by allowing users to run SQL queries directly on the data where it is stored. This eliminates the need to learn new programming languages or database constructs and reduces the complexity of building complex pipelines to extract, transform, and duplicate data before analysis.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-04T15:56:39.412964"}}
{"question": "What is the relationship between Athena's connectors and the types of data storage it supports?", "answer": "Athena provides built-in connectors to 30 popular AWS, on-premises, and other cloud data stores, which enables SQL analytics use cases across various types of data storage, including structured, semi-structured, object, graph, and time series data. This relationship allows users to perform SQL queries on a wide range of data sources efficiently.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-04T15:56:39.413456"}}
{"question": "What is one of the main advantages of using Amazon Athena for data analysis?", "answer": "One of the main advantages of using Amazon Athena for data analysis is that it allows you to use your existing SQL knowledge to extract insights from various data sources without the need to learn a new language, develop scripts to extract and duplicate data, or manage infrastructure.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T15:56:50.224267"}}
{"question": "How does Amazon Athena support machine learning workflows?", "answer": "Amazon Athena supports machine learning workflows by allowing users to invoke SageMaker AI models directly in an Athena SQL query to run inference. This integration simplifies complex tasks such as anomaly detection, customer cohort analysis, and sales predictions, enabling users with SQL experience to easily run ML models deployed on SageMaker AI.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T15:56:50.224505"}}
{"question": "What is the relationship between data source connectors and Athena's ability to run SQL queries on federated data stores?", "answer": "Data source connectors are pieces of code that run on Lambda and translate between your target data source and Athena. When a data source connector is used to register a data store with Athena, it enables the execution of SQL queries on federated data stores. When a query is executed on a federated source, Athena calls the Lambda function associated with the data source connector to handle the parts of the query specific to that federated source.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T15:56:50.224650"}}
{"question": "What types of analyses can financial risk data analysts perform using Athena?", "answer": "Financial risk data analysts can run what-if analysis and Monte Carlo simulations using Athena.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T15:56:56.143824"}}
{"question": "How does Athena support machine learning model usage with SageMaker?", "answer": "Athena can invoke any ML model that is deployed on SageMaker. Users have the flexibility to train their own models using proprietary data or utilize pretrained models that are already deployed on SageMaker. However, users cannot train and deploy their ML models directly on SageMaker AI using Athena; they can only train their ML models or use existing pretrained models.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T15:56:56.144149"}}
{"question": "How do the training data requirements differ for cluster analysis and predicting sports events when using Athena with SageMaker?", "answer": "For cluster analysis, which seeks to categorize new records into existing categories, the model would likely be trained on the user's own data. In contrast, for predicting real-world sports events, a publicly available model could be used because the training data for such models is already in the public domain.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T15:56:56.144692"}}
{"question": "What capabilities does Athena offer in relation to machine learning?", "answer": "Athena offers ML inference (prediction) capabilities wrapped by a SQL interface. It allows users to call an Athena UDF to invoke pre- or post-processing logic on their result set, with inputs that can include any column, record, or table. Additionally, multiple calls can be batched together for higher scalability, and inference can be run in the Select phase or in the Filter phase.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-04T15:57:04.806387"}}
{"question": "How does the approach to training models in SageMaker AI differ for domain-specific predictions versus undifferentiated ML needs?", "answer": "For domain- or industry-specific predictions in SageMaker AI, models are typically trained on the user's own data to ensure the predictions relate closely to specific categories or contexts. In contrast, undifferentiated ML needs, such as machine translation, are more likely to utilize external, publicly available models because they do not require customization to specific datasets.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-04T15:57:04.806667"}}
{"question": "How does the machine learning inference process in Athena compare to the model training in SageMaker AI?", "answer": "The machine learning inference process in Athena provides a SQL interface for predictions, allowing users to apply logic directly on their result sets with the ability to run inference during either the Select or Filter phase. In contrast, SageMaker AI focuses on model training and deployment, where users can create proprietary ML models or use publicly available models depending on their needs. While Athena is primarily for inference, SageMaker AI encompasses the entire model lifecycle from training to deployment.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-04T15:57:04.807084"}}
{"question": "What types of table formats does Amazon Athena support for fine-grained access control?", "answer": "Amazon Athena supports fine-grained access control using table formats such as Apache Iceberg, Apache Hudi, Apache Hive, and federated data sources that are registered with the lakehouse in Amazon SageMaker.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-04T15:57:12.643069"}}
{"question": "How does Amazon Athena facilitate centralized data governance?", "answer": "Amazon Athena facilitates centralized data governance by allowing users to manage permissions and access control for data catalog resources through the Amazon SageMaker data lakehouse. It enables the enforcement of fine-grained access control policies in queries for data stored in any supported file format, providing flexibility in choosing table and file formats while ensuring secure data access.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-04T15:57:12.643368"}}
{"question": "How do IAM policies and ACLs differ in controlling access to data in Amazon Athena?", "answer": "IAM policies allow for fine-grained control to S3 buckets by granting specific permissions to IAM users, while access control lists (ACLs) provide another method of controlling access to the data. Both can be used in conjunction with S3 bucket policies to manage access, but IAM policies are specifically focused on user permissions, whereas ACLs offer a different mechanism for access control.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-04T15:57:12.643575"}}
{"question": "What types of access control does Amazon Athena support with AWS Lake Formation?", "answer": "Amazon Athena supports fine-grained access control with AWS Lake Formation, which allows for centrally managing permissions and access control for data catalog resources in your S3 data lake.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-04T15:57:17.954030"}}
{"question": "How does AWS Lake Formation enhance data governance when using Amazon Athena?", "answer": "AWS Lake Formation enhances data governance by allowing for centralized management of permissions and access control for data catalog resources in your S3 data lake, enabling users to enforce fine-grained access control policies in Athena queries for data stored in various supported file formats.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-04T15:57:17.954284"}}
{"question": "How does the use of Iceberg table format with AWS Lake Formation affect data access for analysts in different countries?", "answer": "Using Iceberg table format with AWS Lake Formation allows for reliable write transactions at scale and enables the implementation of row-level security filters, ensuring that data analysts in different countries can only access data for customers located in their own country to meet regulatory requirements.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-04T15:57:17.954668"}}
{"question": "How does Athena charge for queries when using per query billing?", "answer": "Athena charges based on the amount of data scanned per query, measured in terabytes (TB).", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-04T15:57:23.410626"}}
{"question": "What are the benefits of compressing, partitioning, and converting data to columnar formats when using Athena?", "answer": "The benefits include cost savings and improved performance, as these operations reduce the amount of data scanned and the time required for execution. They allow Athena to scan less data, leading to charges that are 30% to 90% less per query.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-04T15:57:23.410831"}}
{"question": "What is the difference in billing between per query pricing and Provisioned Capacity in Athena?", "answer": "With per query pricing, you are charged based on the amount of data scanned per query, while with Provisioned Capacity, you pay an hourly price for query processing capacity regardless of the data scanned.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-04T15:57:23.410931"}}
{"question": "Is there a separate charge for using the Data Catalog in AWS?", "answer": "Yes, you are charged separately for using the Data Catalog. To learn more about Data Catalog pricing, you can review the AWS Glue pricing page.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-04T15:57:28.719224"}}
{"question": "What advantages does using Athena for Apache Spark provide to data analysts and engineers?", "answer": "Using Athena for Apache Spark provides data analysts and engineers with an interactive, fully managed analytics experience. It offers a simplified notebook experience or access through Athena APIs, allows for querying data from various sources, chaining calculations, and visualizing results. It minimizes the work required for version upgrades, performance tuning, and integration with other AWS services, enabling users to run applications under a second.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-04T15:57:28.719797"}}
{"question": "How does the integration of Athena with Data Catalog enhance the use of Spark applications?", "answer": "The integration of Athena with Data Catalog enhances the use of Spark applications by allowing users to create Spark applications on data in S3 data lakes by referencing tables from their Data Catalog. This tight integration facilitates easier access to data and improves the overall analytics workflow.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-04T15:57:28.719986"}}
{"question": "How can I start a session with Athena for Apache Spark?", "answer": "You can start a session with Athena for Apache Spark by either starting a notebook in the Athena console or using the AWS Command Line Interface (CLI) or Athena API.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T15:57:34.424735"}}
{"question": "What are the benefits of using notebooks in Athena for Apache Spark?", "answer": "Using notebooks in Athena for Apache Spark allows you to query data from various sources, chain together multiple calculations, and visualize the results of your analyses. Additionally, you can start entering and shutting down Spark applications using Python, and you can check the execution status and review logs and execution history in the Athena console.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T15:57:34.425065"}}
{"question": "What are the differences between the notebook node and the Spark driver node in Athena for Apache Spark?", "answer": "In Athena for Apache Spark, the notebook node acts as the server for the notebook user interface, while the Spark driver node coordinates the Spark application and communicates with all the Spark worker nodes. Both nodes are provisioned when you start a Spark session, and you are charged for driver and worker nodes during the session, but the notebook nodes are provided at no additional cost.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T15:57:34.426342"}}
{"question": "What is the primary use case for Amazon Redshift?", "answer": "Amazon Redshift provides the fastest query performance for enterprise reporting and business intelligence workloads, particularly those involving complex SQL with multiple joins and subqueries.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-04T15:57:39.919162"}}
{"question": "How does Amazon EMR enhance the process of running distributed processing frameworks compared to on-premises deployments?", "answer": "Amazon EMR simplifies the process and makes it cost-effective to run highly distributed processing frameworks, such as Apache Hadoop, Spark, and Presto when compared to on-premises deployments.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-04T15:57:39.919468"}}
{"question": "How does Athena differ from Amazon EMR in terms of server management?", "answer": "Athena provides a simplified way to run interactive queries for data in S3 without the need to set up or manage any servers, whereas Amazon EMR requires users to define specific compute, memory, storage, and application parameters for their processing needs.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-04T15:57:39.919731"}}
{"question": "What are the primary use cases for Amazon Redshift?", "answer": "Amazon Redshift is best suited for driving scaled analytics and handling massive, structured, and semi-structured datasets. It performs well for enterprise reporting and business intelligence workloads, particularly those involving extremely complex SQL with multiple joins and subqueries.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-04T15:57:45.745610"}}
{"question": "How does Amazon Athena differ from Amazon Redshift in terms of service management?", "answer": "Amazon Athena is completely serverless, meaning theres no infrastructure to manage or set up, while Amazon Redshift offers both provisioned and serverless options, which allows customers to get started with analytics easily without managing infrastructure.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-04T15:57:45.745908"}}
{"question": "In what ways do Amazon Redshift and Amazon Athena serve different analytics needs?", "answer": "Amazon Redshift is designed for complex BI and analytics workloads, offering high performance for enterprise reporting and deep integration with AWS services. It is suitable for structured and semi-structured datasets and involves complex SQL operations. On the other hand, Amazon Athena is geared towards interactive analytics and data exploration, allowing users to work with data in Amazon S3 and use open-source frameworks, making it better for flexible querying and data portability.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-04T15:57:45.746305"}}
{"question": "What types of tasks can you run using Amazon EMR?", "answer": "With Amazon EMR, you can run various scale-out data processing tasks for applications, such as machine learning (ML), graph analytics, data transformation, streaming data, and virtually anything that you can code.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-04T15:57:49.555824"}}
{"question": "How does Amazon EMR differ from Athena in terms of infrastructure management?", "answer": "Amazon EMR requires you to manage the configuration of your clusters and the software installed on them, while Athena allows you to run interactive SQL queries against data on S3 without having to manage any infrastructure or clusters.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-04T15:57:49.556107"}}
{"question": "What big data processing frameworks are compatible with Amazon EMR?", "answer": "Amazon EMR is compatible with the latest big data processing frameworks, such as Apache HBase, Spark, Hadoop, or Presto.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-04T15:57:49.556694"}}
{"question": "What is EMR Serverless and what advantages does it offer?", "answer": "EMR Serverless is the easiest way to run Spark and Hive applications in the cloud and is the only serverless Hive solution in the industry. It eliminates the operational overhead of tuning, rightsizing, securing, patching, and managing clusters, allowing customers to only pay for the resources that their applications actually use. Additionally, it provides 2x+ faster performance than standard open source due to EMR's performance-optimized runtime, which is 100% API compatible with standard open source, meaning applications do not need to be rewritten to run on EMR.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-04T15:57:58.191441"}}
{"question": "How does EMR Serverless differ from EMR clusters and EMR on EKS in terms of customer control and management?", "answer": "EMR Serverless is designed for customers who want to avoid managing and operating clusters and simply want to run applications using open-source frameworks. In contrast, EMR clusters provide maximum control and flexibility, allowing customers to choose the EC2 instance type, customize the Amazon Linux Image AMI, and install additional custom software. EMR on EKS is for customers who want to standardize on EKS to manage clusters across applications or use different versions of an open-source framework on the same cluster.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-04T15:57:58.191779"}}
{"question": "How does Amazon Athena for Apache Spark compare to EMR Serverless in terms of user experience and application focus?", "answer": "Amazon Athena for Apache Spark offers an instant on, interactive experience similar to the SQL-based query experience, specifically optimized for applications with short runtimes and requiring sub-second startup time. It handles performance tuning, configurations, software patching, and updates automatically without customer involvement. In contrast, EMR Serverless is aimed at customers who want to run applications using open-source frameworks without managing clusters, but it does not specifically focus on providing a similar interactive experience as Athena.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-04T15:57:58.192281"}}
{"question": "What data formats does Athena support?", "answer": "Athena supports many of the same data formats as Amazon EMR.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-04T15:58:02.494065"}}
{"question": "How does the Athena Data Catalog relate to the Hive metastore?", "answer": "The Athena Data Catalog is compatible with the Hive metastore, allowing users with an existing Hive metastore on Amazon EMR to run DDL statements on Athena and query their data without impacting their Amazon EMR jobs.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-04T15:58:02.494336"}}
{"question": "What is the difference between querying data in Athena and Amazon EMR?", "answer": "While both Athena and Amazon EMR can query data, Athena allows users to run SQL queries directly on data stored in S3 without managing infrastructure, whereas Amazon EMR requires users to manage clusters and can impact ongoing jobs when DDL statements are executed. Additionally, Athena supports federated queries across various data sources.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-04T15:58:02.494690"}}
{"question": "What is the primary function of AWS Audit Manager?", "answer": "The primary function of AWS Audit Manager is to help you continuously audit your AWS usage to simplify how you assess risk and compliance with regulations and industry standards. It automates evidence collection to assess if your policies, procedures, and activities, also known as controls, are operating effectively.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T15:58:07.006236"}}
{"question": "How does AWS Audit Manager assist with evidence collection during audits?", "answer": "AWS Audit Manager assists with evidence collection during audits by automatically collecting and organizing evidence as defined by each control requirement. This automation saves time and reduces the manual effort required to prepare for audits.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T15:58:07.006524"}}
{"question": "How do the prebuilt frameworks in AWS Audit Manager compare to customizable frameworks?", "answer": "The prebuilt frameworks in AWS Audit Manager include mappings of AWS resources to control requirements for established industry standards and regulations, such as HIPAA, GDPR, and PCI DSS. In contrast, customizable frameworks allow you to make an editable copy of a prebuilt framework and its controls to better meet your unique business requirements.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T15:58:07.007050"}}
{"question": "What functionalities does AWS Audit Manager provide for evidence management?", "answer": "AWS Audit Manager enables you to automate evidence collection, track the chain of custody of evidence, facilitate teamwork collaboration, and manage evidence security and integrity. It supports continuous auditing and compliance as well as internal risk assessments.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-04T15:58:12.443891"}}
{"question": "How does AWS Audit Manager complement AWS Security Hub in terms of compliance and security?", "answer": "AWS Audit Manager is used by audit and compliance professionals to continuously assess compliance with regulations and industry standards, while AWS Security Hub is used by security and compliance professionals and DevOps engineers to continuously monitor and improve the security posture of AWS accounts and resources. Security Hub conducts automated security checks aligned with various frameworks, and Audit Manager collects the findings generated by these checks as evidence, combining them with other evidence like AWS CloudTrail logs to generate assessment reports.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-04T15:58:12.444215"}}
{"question": "What is the difference in focus between AWS Audit Manager and AWS Security Hub regarding evidence collection?", "answer": "AWS Audit Manager covers a full set of controls in each supported framework, including both automated evidence and controls that require manual evidence uploads, such as incident response plans. In contrast, AWS Security Hub focuses on generating automated evidence through its security checks for a subset of controls in each supported framework and does not cover controls that require evidence from other AWS services or manual uploads.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-04T15:58:12.444640"}}
{"question": "What is the maximum number of active assessments allowed per account in AWS Audit Manager?", "answer": "The maximum number of active assessments allowed per account in AWS Audit Manager is 100.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T15:58:17.254528"}}
{"question": "How does AWS Audit Manager ensure that evidence collected is regionally based?", "answer": "AWS Audit Manager is a regional service, which means that all evidence collected is regionally based and does not cross AWS regional boundaries. Users must enable Audit Manager in each Region to view evidence specific to that Region.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T15:58:17.254862"}}
{"question": "How does the number of custom controls compare to the number of custom frameworks allowed per account in AWS Audit Manager?", "answer": "In AWS Audit Manager, the number of custom controls allowed per account is 500, while the number of custom frameworks allowed is 100. This indicates that each account can create more custom controls than custom frameworks, allowing for greater flexibility in compliance management.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T15:58:17.255373"}}
{"question": "What is the purpose of a control in the context of AWS Audit Manager?", "answer": "A control is a prescriptive description that explains how to implement a procedure to conform to a given rule, such as a compliance requirement. It provides reasonable assurance that the resources used by your organization operate as intended, that data is reliable, and that your organization is in compliance with applicable laws and regulations.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-04T15:58:21.955540"}}
{"question": "How does AWS Audit Manager help organizations meet unique compliance requirements?", "answer": "AWS Audit Manager enables organizations to define their own controls to collect evidence from specific data sources, which helps them meet unique compliance requirements. It allows for the customization of controls and the collection of evidence that supports various compliance obligations.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-04T15:58:21.955860"}}
{"question": "What is the relationship between an AWS Audit Manager assessment and a resource assessment?", "answer": "An AWS Audit Manager assessment is an implementation of an AWS Audit Manager framework that defines the scope of the audit, including specific AWS accounts. In contrast, a resource assessment is a process that collects, stores, and manages evidence for each individual resource within the scope of the assessment, such as Amazon EC2 instances or Amazon S3 buckets.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-04T15:58:21.956365"}}
{"question": "How can you get started with AWS Audit Manager?", "answer": "You can get started by setting up AWS Audit Manager in the AWS Management Console, AWS CLI, or via API. Additionally, the AWS Audit Manager documentation contains a getting started tutorial that provides a hands-on introduction to AWS Audit Manager, allowing you to create an assessment using a standard framework and begin the automated collection of evidence.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-04T15:58:27.106755"}}
{"question": "What is the benefit of using AWS Audit Manager for audits?", "answer": "AWS Audit Manager saves you time by automatically collecting and organizing evidence as defined by each control requirement. It allows you to focus on reviewing the relevant evidence to ensure your controls are working as intended. When it's time for an audit, it helps you manage stakeholder reviews of your controls and enables you to build audit-ready reports with much less manual effort.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-04T15:58:27.107051"}}
{"question": "What features does AWS Audit Manager offer for delegating control reviews?", "answer": "AWS Audit Manager allows you to delegate a control set, which contains a collection of controls, to another user for review. The delegate can review evidence, add comments, upload manual evidence, and update the control status for each of the controls in the control set. After the delegate submits the review back to you, you can check the control set and related comments and complete the review of that control set.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-04T15:58:27.107305"}}
{"question": "What standard frameworks are pre-built by AWS Audit Manager?", "answer": "The standard frameworks pre-built by AWS Audit Manager include PCI DSS, CIS Foundation Benchmark, and HIPAA.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-04T15:58:31.376245"}}
{"question": "What are the two methods to create a custom framework in AWS Audit Manager?", "answer": "The two methods to create a custom framework in AWS Audit Manager are to make an editable copy of an existing framework or to create a new framework from scratch.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-04T15:58:31.376648"}}
{"question": "How do the methods of creating custom frameworks and custom controls in AWS Audit Manager compare?", "answer": "Both custom frameworks and custom controls can be created by making an editable copy of an existing framework or control, or by creating a new one from scratch. However, while custom frameworks allow you to add controls and organize them into control sets, custom controls enable you to specify details such as control name, description, testing information, and evidence sources.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-04T15:58:31.377061"}}
{"question": "What types of data sources can AWS Audit Manager automatically collect evidence from?", "answer": "AWS Audit Manager can automatically collect evidence from four data source types: AWS CloudTrail, AWS Security Hub, AWS Config, and AWS API calls.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T15:58:36.053978"}}
{"question": "What is the benefit of using AWS managed sources when configuring a custom control in Audit Manager?", "answer": "The benefit of using AWS managed sources when configuring a custom control in Audit Manager is that these are predefined groupings of data sources that represent a common control or a core control. Whenever an AWS managed source is updated, the same updates are automatically applied to all custom controls that use these sources.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T15:58:36.054296"}}
{"question": "How does the frequency of evidence collection differ between configuration data evidence and compliance check evidence in AWS Audit Manager?", "answer": "The frequency of evidence collection for configuration data evidence, which includes snapshots of resource configurations, can be configured to be daily, weekly, or monthly. In contrast, compliance check evidence, which includes results from AWS Security Hub and/or AWS Config, is captured based on a frequency defined in those services. This can be either on a periodic basis or triggered by changes to resource configurations.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T15:58:36.054840"}}
{"question": "What does AWS Security Hub do?", "answer": "AWS Security Hub monitors your environment using automated security checks based on AWS best practices and industry standards, allowing you to take corrective action on findings.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-04T15:58:39.498425"}}
{"question": "How does AWS Audit Manager enhance the findings from AWS Security Hub?", "answer": "AWS Audit Manager imports Security Hub findings for supported compliance standards, such as the CIS Foundations Benchmark and PCI. It automatically performs additional analysis and adds annotations to the collected findings to generate evidence for the AWS services that are monitored by AWS Security Hub.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-04T15:58:39.498762"}}
{"question": "What is the relationship between AWS CloudTrail and AWS Audit Manager?", "answer": "AWS CloudTrail allows you to log, continuously monitor, and retain account activity related to actions across your AWS infrastructure. AWS Audit Manager collects log data from CloudTrail directly, performs additional analysis, and annotates the data to generate evidence automatically for over 175 AWS services that feed logs into AWS CloudTrail.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-04T15:58:39.499152"}}
{"question": "What service does AWS Audit Manager provide for Amazon Bedrock customers?", "answer": "AWS Audit Manager provides a generative AI best practices framework for Amazon Bedrock customers.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-04T15:58:43.316346"}}
{"question": "How does AWS Audit Manager help organizations using generative AI models?", "answer": "AWS Audit Manager helps organizations by allowing them to deploy a generative AI best practices framework in the accounts where they are running their generative AI models and applications. This framework aids in collecting evidence to monitor compliance with intended policies.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-04T15:58:43.316616"}}
{"question": "What is the relationship between Amazon Bedrock and AWS Audit Manager?", "answer": "Amazon Bedrock is a service that makes foundation models available through an API, while AWS Audit Manager provides a best practices framework specifically for customers using Amazon Bedrock, enabling them to monitor compliance and manage generative AI models effectively.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-04T15:58:43.317147"}}
{"question": "What solution provider has AWS Audit Manager integrated with?", "answer": "AWS Audit Manager has integrated with MetricStream, which is a Governance, Risk and Compliance (GRC) solution provider.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-04T15:58:46.523260"}}
{"question": "How does the integration between AWS Audit Manager and MetricStream benefit users?", "answer": "The integration allows users to import evidence of their AWS usage and configurations directly from Audit Manager into MetricStream CyberGRC.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-04T15:58:46.523525"}}
{"question": "What is the relationship between AWS Audit Manager and MetricStream CyberGRC?", "answer": "AWS Audit Manager provides the capability to import evidence of AWS usage and configurations into MetricStream CyberGRC, indicating that AWS Audit Manager supports compliance and governance processes within the MetricStream platform.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-04T15:58:46.523905"}}
{"question": "What is Amazon Augmented AI (Amazon A2I) used for?", "answer": "Amazon Augmented AI (Amazon A2I) is used to build workflows required for human review of machine learning predictions, making it easier for developers to incorporate human review into their applications.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-04T15:58:50.663222"}}
{"question": "How does Amazon A2I benefit machine learning applications that require human review?", "answer": "Amazon A2I benefits machine learning applications by removing the heavy lifting associated with building human review systems, simplifying the process of managing human reviewers, and providing built-in workflows for common use cases, thus saving time and reducing costs.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-04T15:58:50.663565"}}
{"question": "How does Amazon A2I compare to building custom human review systems?", "answer": "Amazon A2I simplifies the process of managing human reviews compared to building custom systems, which can be time-consuming and expensive due to the complex workflows and custom software needed. A2I provides built-in workflows and allows easy integration with existing machine learning models, while custom systems require more effort to implement.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-04T15:58:50.663982"}}
{"question": "How do you get started with Amazon A2I?", "answer": "To get started with Amazon A2I, sign in to your AWS Console, navigate to the Amazon SageMaker console, and select Human review workflows under Augmented AI.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T15:58:55.749971"}}
{"question": "What are the key components involved in setting up a human review workflow with Amazon A2I?", "answer": "The key components involved in setting up a human review workflow with Amazon A2I include providing a pointer to the S3 bucket for storing review results, selecting the appropriate task type, defining conditions for when a human review should be triggered, and optionally using pre-built workflows or creating custom workflows with specific review templates.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T15:58:55.750293"}}
{"question": "What are the different workforce options available in Amazon A2I, and how do they compare?", "answer": "Amazon A2I provides three workforce options: (1) Amazon Mechanical Turk, which allows for crowdsourced labor; (2) third-party data labeling service providers available through the AWS Marketplace, which can offer specialized labeling services; and (3) your own employees, allowing for internal resources to conduct reviews. Each option caters to different needs for human review based on the nature of the tasks and the required expertise.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T15:58:55.750774"}}
{"question": "What is required of human review service providers in terms of compliance?", "answer": "Human review service providers are required to go through SOC 2 compliance and certification on an annual basis. The SOC 2 report assesses the service providers control environment based on the AICPA Trust Services Criteria, which includes Security, Availability, Processing Integrity, Confidentiality, and Privacy.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-04T15:59:01.785949"}}
{"question": "Why is it important to review the Standard Service Agreement before sharing confidential information with Amazon Augmented AI service providers?", "answer": "It is important to review the Standard Service Agreement because it contains clauses that protect your confidential information. Understanding these terms helps ensure that your data is handled appropriately and securely by the service provider.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-04T15:59:01.786232"}}
{"question": "How do the security controls for service providers differ between normal operations and those with a remote work policy due to COVID-19?", "answer": "Under normal operations, service providers are required to adhere to SOC 2 compliance and additional security controls. However, during the remote work policy due to COVID-19, some of these security standards, including SOC 2 compliance, may not be applicable, and impacted service providers have updated their AWS Marketplace listings accordingly. They will not process customer data from remote work environments without explicit customer consent.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-04T15:59:01.786657"}}
{"question": "What certification reports must service providers provide to AWS before being listed in the marketplace?", "answer": "Service providers must furnish their SOC 2 certification reports prior to being listed in the marketplace.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-04T15:59:05.498606"}}
{"question": "Why does AWS require service providers to have their security standards reviewed annually?", "answer": "AWS requires service providers to have their security standards reviewed annually to ensure they meet the mandatory requirements.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-04T15:59:05.498943"}}
{"question": "What happens if a service provider fails to meet the security standards compared to if they meet the standards?", "answer": "If a service provider fails to meet the security standards, their listing will be removed from the AWS Marketplace within 24 hours, and all affected customers will be notified by email. In contrast, if they meet the security standards, they will remain listed in the marketplace.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-04T15:59:05.499377"}}
{"question": "What is the primary purpose of AWS Auto Scaling?", "answer": "The primary purpose of AWS Auto Scaling is to help optimize the performance of applications while lowering infrastructure costs by easily and safely scaling multiple AWS resources.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-04T15:59:10.389489"}}
{"question": "How does AWS Auto Scaling simplify the scaling experience for users?", "answer": "AWS Auto Scaling simplifies the scaling experience by allowing users to scale collections of related resources that support their application with just a few clicks and provides a unified scaling experience for all scalable resources powering the application.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-04T15:59:10.389767"}}
{"question": "How does AWS Auto Scaling manage resources when demand spikes compared to when demand drops?", "answer": "When demand spikes, AWS Auto Scaling automatically increases the capacity of constrained resources to maintain a high quality of service. In contrast, when demand drops, AWS Auto Scaling automatically removes any excess resource capacity to avoid overspending.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-04T15:59:10.390231"}}
{"question": "What is a good example of an application that would benefit from using AWS Auto Scaling?", "answer": "A good example of an application that would benefit from using AWS Auto Scaling is an e-commerce web application that receives variable traffic throughout the day.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T15:59:14.458735"}}
{"question": "How does AWS Auto Scaling determine how to scale resources for an application?", "answer": "AWS Auto Scaling determines how to scale resources for an application by creating a scaling plan that defines how each of the resources should be scaled based on selected resource tags or AWS CloudFormation stacks. It then creates a target tracking scaling policy for each resource that keeps it at a target value based on the selected scaling strategy.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T15:59:14.458920"}}
{"question": "How do the predefined scaling recommendations in AWS Auto Scaling differ?", "answer": "The predefined scaling recommendations in AWS Auto Scaling differ in their focus: one optimizes availability, another optimizes costs, and the third balances the two. Users can also define their own target values if they prefer.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T15:59:14.459029"}}
{"question": "What does Amazon EC2 Auto Scaling do?", "answer": "Amazon EC2 Auto Scaling helps ensure that you have the correct number of Amazon EC2 instances available to handle the load for your application. It can also detect when an instance is unhealthy, terminate it, and launch an instance to replace it.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-04T15:59:18.866602"}}
{"question": "How does Application Auto Scaling differ from Amazon EC2 Auto Scaling?", "answer": "Application Auto Scaling is used to scale resources other than EC2 instances, allowing you to define scaling policies for various AWS resources, such as Amazon ECS services, Amazon EMR clusters, and Amazon DynamoDB tables. In contrast, Amazon EC2 Auto Scaling specifically focuses on managing Amazon EC2 instances.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-04T15:59:18.866936"}}
{"question": "What benefits do applications gain by using EC2 Auto Scaling?", "answer": "By using EC2 Auto Scaling, applications gain better fault tolerance, availability, and cost management.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-04T15:59:18.867363"}}
{"question": "What is the primary purpose of AWS Auto Scaling?", "answer": "The primary purpose of AWS Auto Scaling is to manage scaling for multiple resources across multiple services by defining dynamic scaling policies for EC2 Auto Scaling groups or other resources using predefined scaling strategies.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:59:23.909306"}}
{"question": "Why is using AWS Auto Scaling considered faster and easier than managing scaling policies for individual resources?", "answer": "Using AWS Auto Scaling is considered faster and easier because it allows you to configure scaling policies for all scalable resources in your application in one place, rather than managing each resource via its individual service console. Additionally, AWS Auto Scaling includes predefined scaling strategies that simplify the setup of scaling policies.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:59:23.909596"}}
{"question": "How does AWS Auto Scaling differ from EC2 Auto Scaling in terms of scalability features?", "answer": "AWS Auto Scaling is designed to manage scaling for multiple resources across multiple services and supports predefined scaling strategies, including predictive scaling. In contrast, EC2 Auto Scaling is specifically focused on scaling Amazon EC2 Auto Scaling groups and maintaining the health of the EC2 fleet, and it only supports target tracking scaling policies, not predictive scaling or scheduled scaling.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T15:59:23.909796"}}
{"question": "What is the primary function of Predictive Scaling in AWS?", "answer": "The primary function of Predictive Scaling in AWS is to generate schedules for EC2 instances based on forecasted traffic, setting up the minimum capacity for applications according to predicted incoming application traffic.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-04T15:59:27.798139"}}
{"question": "How do Predictive Scaling and target tracking work together in managing EC2 capacity?", "answer": "Predictive Scaling works in conjunction with target tracking to make EC2 capacity changes more responsive to incoming application traffic. While Predictive Scaling sets the minimum capacity based on forecasted traffic, target tracking adjusts the actual capacity according to real-time traffic conditions, tracking desired capacity utilization levels and addressing unexpected traffic spikes.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-04T15:59:27.798476"}}
{"question": "What is the difference between Predictive Scaling and Dynamic Scaling in terms of configuration options?", "answer": "You can configure a scaling plan with only Dynamic Scaling and opt-out of Predictive Scaling. Conversely, it is also possible to enable just Predictive Scaling without configuring Dynamic Scaling. This flexibility allows users to choose the scaling method that best suits their application needs.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-04T15:59:27.798980"}}
{"question": "Is Predictive Scaling free to use in AWS?", "answer": "Yes, Predictive Scaling is free to use. However, you will pay for the resources being utilized for running your applications.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T15:59:33.441244"}}
{"question": "What are the advantages of using AWS Auto Scaling compared to Amazon EC2 Auto Scaling?", "answer": "AWS Auto Scaling offers application-wide scaling using a unified interface, automatic discovery of all scalable resources in your application, the ability to scale multiple resources across multiple services with a unified interface, and guidance and recommendations for setting up scaling policies. In contrast, Amazon EC2 Auto Scaling scales one Auto Scaling group at a time and does not provide these additional features.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T15:59:33.441516"}}
{"question": "How does the ability to create and set up Auto Scaling groups differ between AWS Auto Scaling and Amazon EC2 Auto Scaling?", "answer": "AWS Auto Scaling does not allow you to create and set up Auto Scaling groups, while Amazon EC2 Auto Scaling does allow this functionality. This indicates that AWS Auto Scaling is focused on application-wide scaling, whereas Amazon EC2 Auto Scaling is more resource-specific.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T15:59:33.441908"}}
{"question": "What are the metrics and thresholds used for AWS Auto Scaling recommendations?", "answer": "AWS Auto Scaling bases its scaling recommendations on the most popular scaling metrics and thresholds used for Auto Scaling.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-04T15:59:37.201505"}}
{"question": "How does AWS Auto Scaling help users get started with their scaling strategy?", "answer": "AWS Auto Scaling provides recommendations for the minimum and maximum sizes of the resources, allowing users to get started quickly and fine-tune their scaling strategy over time.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-04T15:59:37.201839"}}
{"question": "What is the difference between resource discovery for AWS CloudFormation stacks and resources based on tags in AWS Auto Scaling?", "answer": "AWS Auto Scaling can either scan an AWS CloudFormation stack or resources based on common resource tags to identify supported AWS resource types that can be scaled. However, ECS services cannot be discovered using tags.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-04T15:59:37.202378"}}
{"question": "What protocols does the AWS Transfer Family support for file transfer?", "answer": "The AWS Transfer Family supports the transfer of files over SFTP, AS2, FTPS, FTP, and web browsers directly into and out of Amazon S3 or Amazon EFS.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T15:59:41.765115"}}
{"question": "How does SFTP ensure secure data transfer compared to FTP?", "answer": "SFTP, or Secure Shell File Transfer Protocol, ensures secure data transfer by using the security and authentication functionalities of SSH, while FTP does not support encryption and transfers data in cleartext.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T15:59:41.765475"}}
{"question": "What is the main difference in security between FTP and FTPS?", "answer": "The main difference in security between FTP and FTPS is that FTP uses cleartext for data transfer and does not support encryption, whereas FTPS encrypts traffic using Transport Layer Security (TLS) and allows for encryption of both the control and data channel connections.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T15:59:41.765681"}}
{"question": "What does AS2 stand for and what is its primary use?", "answer": "AS2 stands for Applicability Statement 2, and it is a network protocol used for the secure and reliable transfer of business-to-business data over the public internet using HTTP/HTTPS or any TCP/IP network.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T15:59:46.917709"}}
{"question": "How does AWS Transfer Family simplify the file transfer process for businesses?", "answer": "AWS Transfer Family simplifies the file transfer process by providing fully managed and secure connectivity options over multiple protocols including SFTP, AS2, FTPS, FTP, and web browsers. This eliminates the need for businesses to host and manage their own file transfer service, which would require investments in infrastructure, monitoring for uptime, and user management. Instead, businesses can focus on their workflows while AWS manages the underlying infrastructure.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T15:59:46.918475"}}
{"question": "How does AWS Transfer Family's event notification system compare to traditional file transfer management?", "answer": "AWS Transfer Family's event notification system publishes event notifications in Amazon EventBridge for each file transfer operation, allowing users to subscribe to these events and orchestrate event-driven workflows. This is in contrast to traditional file transfer management, which typically does not provide integrated event notifications, requiring businesses to implement their own mechanisms for monitoring and managing file transfer activities.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T15:59:46.918696"}}
{"question": "What protocols does AWS Transfer Family support for file transfer endpoints?", "answer": "AWS Transfer Family supports SFTP, FTPS, and FTP protocols for file transfer endpoints.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T15:59:53.534400"}}
{"question": "How does AWS Transfer Family ensure that end users' workflows remain unchanged during file transfers?", "answer": "AWS Transfer Family ensures that end users' workflows remain unchanged by allowing users to continue using their existing SFTP, FTPS, or FTP clients and configurations while managing the underlying file transfer infrastructure.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T15:59:53.534725"}}
{"question": "What are the steps to set up an SFTP connector for copying files to Amazon S3, and how do they compare to the steps for setting up AWS Transfer Family?", "answer": "To set up an SFTP connector for copying files to Amazon S3, the steps are: first, create a secret to store the credentials for authentication; second, create the SFTP connector by supplying the secret and remote servers URL; and third, start using the connector to copy files by invoking the StartFileTransfer API. In comparison, setting up AWS Transfer Family involves selecting the desired protocols, configuring user access via authentication options, and selecting the server to access S3 or EFS file systems. Both processes involve three main steps, but they differ in their specific actions and the focus on user access or connection configuration.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T15:59:53.535308"}}
{"question": "What types of protocols can be used for secure transfers according to the context?", "answer": "The types of protocols that can be used for secure transfers according to the context are FTPS, SFTP, and AS2.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-04T15:59:58.381278"}}
{"question": "How does AS2 ensure message delivery and integrity compared to SFTP?", "answer": "AS2 ensures message delivery and integrity by providing a built-in mechanism for Message Disposition Notification (MDN) that alerts the sender when the message has been successfully received and decrypted by the recipient. This offers proof of delivery and integrity, which is not explicitly mentioned for SFTP in the context.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-04T15:59:58.381615"}}
{"question": "What is the difference in channel usage between SFTP and FTPS?", "answer": "SFTP uses a single channel for commands and data, which requires fewer port openings than FTPS, which uses different channels for commands and data.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-04T15:59:58.382049"}}
{"question": "Can Transfer Family support SCP commands through the SFTP protocol?", "answer": "Yes, Transfer Family can support SCP commands through the SFTP protocol to meet most SCP use cases for file transfers using S3 and EFS storage. However, it is important to note that SCP protocol has been deprecated and is not supported by the service.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T16:00:04.287034"}}
{"question": "What customization options are available for banners and messages in Transfer Family?", "answer": "You can configure your Transfer Family server to display customized banners such as organization policies or terms and conditions to users. Additionally, you can display a customized Message of The Day (MOTD) to users who have successfully authenticated.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T16:00:04.288230"}}
{"question": "How does the accessibility of a Transfer Family server differ when using FTP versus other protocols?", "answer": "When you enable FTP, you will only be able to use the VPC hosted endpoints internal access option because FTP transmits data in clear text. In contrast, secure protocols such as SFTP or FTPS can be used if traffic needs to traverse the public network, allowing for broader accessibility options.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T16:00:04.288480"}}
{"question": "Is a VPC required to host FTP server endpoints?", "answer": "No, a VPC is required to host FTP server endpoints.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-04T16:00:09.994864"}}
{"question": "What options do I have to restrict incoming traffic to my server endpoint based on users source IP address?", "answer": "You have three options to restrict incoming traffic based on users source IP address. If hosting your server endpoint within a VPC, you can use Security Groups to allow list source IP addresses or utilize the AWS Network Firewall service. For a public EndpointType Transfer server and API Gateway integration with your identity management system, you can also use AWS WAF to allow, block, or rate limit access based on source IP address.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-04T16:00:09.995186"}}
{"question": "What are the differences between using AWS Global Accelerator and deploying a server endpoint with shared VPC environments?", "answer": "The AWS Global Accelerator is used to improve file transfer throughput and round-trip time for your Transfer server endpoint. In contrast, deploying a server endpoint with shared VPC environments is typically aimed at segmenting your AWS environment for reasons such as security, cost monitoring, and scalability. Both serve different purposes in enhancing the performance and management of your server endpoints.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-04T16:00:09.995684"}}
{"question": "Are fixed IP addresses supported on the PUBLIC Endpoint type for firewall whitelisting?", "answer": "No, fixed IP addresses that are usually used for firewall whitelisting purposes are currently not supported on the PUBLIC Endpoint type. Instead, you should use VPC hosted endpoints to assign static IP addresses for your endpoint.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-04T16:00:16.132151"}}
{"question": "What are the advantages of using passive mode for FTPS access?", "answer": "Passive mode allows your end users clients to initiate connections with your server and requires fewer port openings on the client side, making your server endpoint more compatible with end users behind protected firewalls.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-04T16:00:16.132419"}}
{"question": "How does the management of host keys differ between SFTP and FTPS servers?", "answer": "For SFTP servers, you can import host keys when creating or updating the server, and the oldest host key of each key type can be used to verify the server's authenticity. In contrast, FTPS servers require a certificate from Amazon Certificate Manager (ACM) to verify the identity of the server, and only explicit FTPS mode is supported.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-04T16:00:16.132763"}}
{"question": "What mode is used by default for file transfers traversing a firewall or router?", "answer": "File transfers traversing a firewall or a router are supported by default using extended passive connection mode (EPSV).", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-04T16:00:23.075657"}}
{"question": "What are AWS Transfer Family web apps designed to provide to end users?", "answer": "AWS Transfer Family web apps are designed to provide end users with a simple interface for transferring data to and from Amazon S3 over a web browser.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-04T16:00:23.075914"}}
{"question": "How do AWS Transfer Family web apps and servers relate to each other?", "answer": "AWS Transfer Family web apps and servers are separate, standalone resources that are not connected. You create a web app independent of a server.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-04T16:00:23.076451"}}
{"question": "What identity providers can automatically synchronize user and group information with IAM Identity Center using SCIM?", "answer": "You can automatically synchronize user and group information from Okta Universal Directory, Microsoft Entra ID (formerly Azure AD), OneLogin, and PingFederate using the SCIM standard.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T16:00:29.422901"}}
{"question": "How do S3 Access Grants control access for users in Transfer Family web apps?", "answer": "S3 Access Grants control access by offering three access levels: READ, WRITE, and READWRITE. These levels define the authorized actions users can perform, such as listing, uploading, downloading, and copying files. READ allows users to view and retrieve objects, WRITE allows users to write to and delete objects, and READWRITE allows users to perform both READ and WRITE actions.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T16:00:29.423125"}}
{"question": "How does the customization of web apps differ from the customization of the sign-in URL in AWS Transfer Family?", "answer": "Customization of web apps in AWS Transfer Family involves updating elements like the company logo, favicon, and page title through the AWS Transfer Family console or using the AWS CLI or API. In contrast, customizing the sign-in URL involves associating a custom domain name with your web app using Amazon CloudFront and customizing the sign-in URL to your Identity Center applications portal through AWS IAM Identity Center.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T16:00:29.423285"}}
{"question": "What is the primary function of the Storage Browser for S3?", "answer": "The Storage Browser for S3 is an open-source component that you can add to your web applications to provide your end users with a simple interface for data stored in S3.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-04T16:00:34.770125"}}
{"question": "How does the connector validate the identity of a remote server?", "answer": "The connector uses the public portion of the host key to validate the identity of the remote server. If the host fingerprint provided by the remote server does not match that uploaded to the connectors configuration, the connection will fail, and error details will be logged in CloudWatch.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-04T16:00:34.773229"}}
{"question": "What is the difference between using SSH key-pairs and passwords for authentication when connecting to remote servers?", "answer": "You can authenticate connections to remote servers using either SSH key-pairs or passwords, or both, depending on the remote server requirements. The context does not specify which method is preferred or more secure, indicating that the choice depends on the specific requirements of the remote server.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-04T16:00:34.773522"}}
{"question": "What are the actions you can perform with SFTP connectors?", "answer": "With SFTP connectors, you can list files stored in a directory on a remote SFTP server, retrieve files from a remote SFTP server to Amazon S3, send files from Amazon S3 to a remote SFTP server, and delete, rename, or move files stored in the remote SFTP server.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-04T16:00:41.732806"}}
{"question": "How do SFTP connectors ensure the security of the cryptographic algorithms used during connections?", "answer": "SFTP connectors allow you to select one of the available service managed security policies based on your security and compatibility requirements. The policy controls the cryptographic algorithms that will be advertised by your SFTP connector, and only the algorithms specified in the attached policy will be used to negotiate the connection when attempting to connect to a remote server.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-04T16:00:41.733084"}}
{"question": "What is the difference between using the StartDirectoryListing API command and the StartFileTransfer API command with SFTP connectors?", "answer": "The StartDirectoryListing API command is used to list the files stored in a directory on remote SFTP servers, while the StartFileTransfer API command is used to retrieve files from the remote server. When using StartFileTransfer, you can pass file names directly from the directory listing or filter the file list based on specific wildcard criteria for filename patterns.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-04T16:00:41.733432"}}
{"question": "What AWS service can be used to schedule file transfers?", "answer": "You can schedule file transfers using Amazon EventBridge Scheduler.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-04T16:00:46.626346"}}
{"question": "How can AWS Step Functions enhance the file transfer process with AWS Transfer Family?", "answer": "AWS Step Functions integrates with various AWS services, including AWS Transfer Family, enabling you to invoke the SFTP connectors StartFileTransfer action directly from your state machine. Once you have created your SFTP connector with AWS Transfer Family, you can leverage Step Functions AWS SDK integrations to call the StartFileTransfer API.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-04T16:00:46.626610"}}
{"question": "What is the relationship between SFTP connectors and static IP addresses in AWS Transfer Family?", "answer": "All SFTP connectors in an AWS account region will share a set of static IP addresses. This sharing of IP addresses reduces the amount of allow-list documentation as well as the onboarding communications needed with your external partners.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-04T16:00:46.627041"}}
{"question": "What is one way to retrieve the host fingerprint for a connector configuration?", "answer": "One way to retrieve the host fingerprint for a connector configuration is to create a connector without the host fingerprint information and then use the TestConnection API command or console action to scan the remote server for the host key information using your connector.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T16:00:53.263244"}}
{"question": "Why might someone want to create concurrent connections to a remote SFTP server?", "answer": "Someone might want to create concurrent connections to a remote SFTP server to improve transfer performance by processing multiple files in parallel, provided the server supports concurrent sessions from the same user.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T16:00:53.263583"}}
{"question": "How does the process of retrieving the host key information differ between using the TestConnection command and the ssh-keyscan utility?", "answer": "Using the TestConnection command allows you to create a connector without the host key information and then scan the remote server to retrieve the public host key. In contrast, using the ssh-keyscan utility involves scanning the remote server before creating the connector to obtain the host key information.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T16:00:53.264088"}}
{"question": "What are the three identity provider options supported by the service?", "answer": "The three identity provider options supported by the service are Service Managed, Microsoft Active Directory, and Custom Identity Providers, which enable integration with an identity provider of your choice.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-04T16:01:00.375536"}}
{"question": "Why is it recommended to maintain separate credentials for FTP?", "answer": "It is recommended to maintain separate credentials for FTP because FTP transmits credentials in cleartext. If FTP credentials are inadvertently shared or exposed, it could compromise the security of workloads using SFTP or FTPS, which are more secure.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-04T16:01:00.375795"}}
{"question": "How does Service Managed authentication differ from using Custom Identity Providers?", "answer": "Service Managed authentication allows you to store user identities within the service and is only supported for server endpoints that are enabled for SFTP. In contrast, Custom Identity Providers enable you to integrate an identity provider of your choice, offering more flexibility in identity management.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-04T16:01:00.376164"}}
{"question": "What must you specify when associating an AD group with access control information?", "answer": "When associating an AD group with access control information, you must specify an IAM Role, a scope down policy (for S3 only), a POSIX Profile (for EFS only), a home directory location, and logical directory mappings.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-04T16:01:07.299261"}}
{"question": "How does the scope down policy enhance user access to S3 buckets or EFS file systems?", "answer": "The scope down policy enhances user access by being evaluated at runtime based on users information, such as their username. This allows for providing access to unique prefixes in the bucket based on their username and enables the evaluation of logical directory mappings, which standardizes how S3 bucket or EFS file system contents are visible to the user.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-04T16:01:07.299576"}}
{"question": "What is the difference between using AWS Managed Microsoft AD and a custom identity provider for user authentication?", "answer": "Using AWS Managed Microsoft AD allows you to authenticate users directly for access over SFTP, FTPS, and FTP, while using a custom identity provider, such as Okta or Microsoft AzureAD, enables you to leverage an existing identity provider to manage your end users for all protocol types, facilitating easy and seamless migration of users and allowing credentials to be stored in a corporate directory or an in-house identity datastore.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-04T16:01:07.299916"}}
{"question": "What options do I have for integrating my identity provider with an AWS Transfer Family server?", "answer": "You can use an AWS Lambda function or an Amazon API Gateway endpoint to integrate your identity provider with an AWS Transfer Family server. Use Amazon API Gateway if you need a RESTful API or want to leverage AWS WAF for geo-blocking and rate limiting capabilities.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T16:01:14.341606"}}
{"question": "Why would I want to pass the client source IP to my identity provider when connecting through AWS Lambda or API Gateway?", "answer": "Passing the client source IP to your identity provider allows you to allow, deny, or limit access based on the IP addresses of clients. This ensures that your data is accessed only from IP addresses that you have specified as trusted.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T16:01:14.341931"}}
{"question": "How does the support for password-based authentication differ between AWS Transfer Family and Active Directory?", "answer": "AWS Transfer Family only supports password-based authentication when using Microsoft AD through AWS Directory Service. In contrast, if you want to use other authentication modes, you must use a custom authorizer option instead of relying solely on AD Groups.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T16:01:14.342456"}}
{"question": "What certification has AWS Transfer Family for AS2 received?", "answer": "AWS Transfer Family for AS2 has received the official Drummond Group AS2 Cloud Certification Seal.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-04T16:01:19.728763"}}
{"question": "What is the purpose of non-repudiation in AS2, and how is it achieved?", "answer": "Non-repudiation in AS2 validates that messages are successfully exchanged between two parties. It is achieved using Message Disposition Notifications (MDN), which ensure that the sender sent the message, the receiver successfully received it, and that the message sent by the sender was the same message received by the receiver.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-04T16:01:19.729087"}}
{"question": "How does the process of message transmission differ from the sender's perspective compared to the receiver's perspective in AS2?", "answer": "From the sender's perspective in AS2, the message is signed using the senders private key, encrypted using the receivers certificate, and its integrity is calculated using a hash before being transmitted. In contrast, from the receiver's perspective, the message is decrypted using the receivers private key, validated using the senders public key, and upon successful receipt, a signed Message Disposition Notification (MDN) is sent back to acknowledge delivery.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-04T16:01:19.729593"}}
{"question": "What options does the sender have when requesting an MDN?", "answer": "The sender can choose to request an MDN, select a signed or unsigned MDN, and choose the signing algorithms that should be used to sign the MDN.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-04T16:01:26.250073"}}
{"question": "What are the differences between synchronous and asynchronous MDN responses?", "answer": "Synchronous MDNs are sent over the same connection channel as the message, making them simpler and the recommended option. Asynchronous MDNs are preferred when more time is needed to process the message before sending the MDN.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-04T16:01:26.250410"}}
{"question": "How does AWS Transfer Family handle the storage and querying of AS2 information?", "answer": "AWS Transfer Family extracts key AS2 information from payloads and MDNs exchanged and stores them as JSON files in your Amazon S3 bucket. These JSON files can be queried using S3 Select or Amazon Athena, or indexed using Amazon OpenSearch or Amazon DocumentDB for analytics.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-04T16:01:26.250825"}}
{"question": "What authentication method is supported for connecting to a trading partners AS2 server?", "answer": "Basic authentication is supported for connecting to your trading partners AS2 server.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-18", "source_tokens": 422, "generated_at": "2026-02-04T16:01:33.445284"}}
{"question": "How can I use Amazon EventBridge with AS2 messages?", "answer": "Every AS2 message received publishes an event to your default event-bus in Amazon EventBridge. You can subscribe to these events to orchestrate event-driven processing of the received messages, such as copying incoming messages to S3, performing malware scans using a custom Lambda, or tagging messages for indexing and searching with services like Amazon CloudSearch.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-18", "source_tokens": 422, "generated_at": "2026-02-04T16:01:33.445890"}}
{"question": "What are the uses of static IP addresses in AS2 connectors compared to AS2 server endpoints?", "answer": "Static IP addresses in AS2 connectors are used when sending messages to remote AS2 servers and for returning asynchronous message disposition notification (MDN) responses. Similarly, AS2 server endpoints also support static IP addresses for configuring IP allow-list controls using security groups. Both connectors and server endpoints utilize static IP addresses for communication, but they serve slightly different purposes in the context of message transmission and security configurations.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-18", "source_tokens": 422, "generated_at": "2026-02-04T16:01:33.446116"}}
{"question": "What data formats can AWS B2B Data Interchange transform X12 EDI contents into?", "answer": "AWS B2B Data Interchange can transform X12 EDI contents into common data representations such as JSON and XML.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-04T16:01:40.061470"}}
{"question": "How can you automate the sending of AS2 messages using Amazon EventBridge?", "answer": "You can automate the sending of AS2 messages by scheduling them with the Amazon EventBridge Scheduler or by triggering them using Amazon EventBridge rules. For time-based workflows, create a schedule using the EventBridge Scheduler and specify AWS Transfer Familys StartFileTransfer API as the target. For event-driven workflows, create an Amazon EventBridge rule that matches events and specify the same API as the target.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-04T16:01:40.061794"}}
{"question": "What is the relationship between AWS Transfer Family and Amazon EventBridge in the context of AS2 messages?", "answer": "AWS Transfer Family publishes events to Amazon EventBridge for every successful or failed AS2 message or MDN sent and received. These events are then published to the default event-bus in Amazon EventBridge, allowing users to trigger notifications through services like Amazon SNS based on the events.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-04T16:01:40.062261"}}
{"question": "What types of file transfer events does AWS Transfer Family publish to Amazon EventBridge?", "answer": "AWS Transfer Family publishes file transfer event notifications in Amazon EventBridge for files transferred over SFTP, AS2, FTPS, and FTP.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-04T16:01:45.616980"}}
{"question": "What is the purpose of AWS Transfer Family managed workflows?", "answer": "The purpose of AWS Transfer Family managed workflows is to provide a pre-built framework that makes it easier to automatically execute post-upload processing of files uploaded over SFTP, FTPS, and FTP server endpoints using pre-built file processing steps.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-04T16:01:45.617520"}}
{"question": "How do the functionalities of event notifications in Amazon EventBridge and managed workflows differ in AWS Transfer Family?", "answer": "Event notifications in Amazon EventBridge are used to trigger processing of files based on file transfer events, whether successful or failed, while managed workflows provide a pre-built framework for automatically executing a linear sequence of processing steps for files uploaded over SFTP, FTPS, and FTP. Essentially, event notifications allow for event-driven processing, whereas managed workflows enable a structured processing approach.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-04T16:01:45.617762"}}
{"question": "What are some of the tasks that managed workflows can execute for file processing?", "answer": "Managed workflows can execute a linear sequence of file-processing tasks for all files uploaded to your server endpoints. These tasks include moving uploaded files to user-specific folders, decrypting files using PGP keys, performing malware scanning, and tagging the files.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T16:01:51.982354"}}
{"question": "Why is it beneficial to use managed workflows for file processing in an organization?", "answer": "Using managed workflows for file processing is beneficial because they remove the complexities of managing multiple tasks, provide a standardized file-processing solution that can be replicated across the organization, and include built-in exception handling and file traceability for each step. This helps meet business and legal requirements, allows for quicker deployment of workflows through Infrastructure as Code (IaC), and enables businesses to focus on their core differentiating work instead of managing infrastructure.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T16:01:51.982647"}}
{"question": "How do managed workflows differ in handling fully uploaded files compared to partially uploaded files?", "answer": "Managed workflows differ in handling fully uploaded files by allowing a specific workflow to be triggered only when files are fully uploaded, ensuring that all processing tasks are executed correctly. In contrast, a separate managed workflow can be associated to process partially uploaded files, enabling the organization to handle incomplete uploads appropriately.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T16:01:51.983046"}}
{"question": "What operational information is published by AWS Transfer Family when a file transfer operation completes?", "answer": "When a file transfer operation completes, AWS Transfer Family publishes operational information such as the file location, username of the sender, server-id or connector-id, and the transfer status in Amazon EventBridge.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-04T16:01:57.608294"}}
{"question": "How do AWS Transfer Family managed workflows differ from event notifications in terms of processing file uploads?", "answer": "AWS Transfer Family managed workflows provide a pre-built framework to define a linear sequence of common file processing steps that apply to all uploaded files, while event notifications allow for granular control in defining file processing, such as using conditional logic based on the source of the file.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-04T16:01:57.608572"}}
{"question": "Can the same managed workflow be associated with multiple servers in AWS Transfer Family, and what is the benefit of this?", "answer": "Yes, the same managed workflow can be associated with multiple servers in AWS Transfer Family. This allows for easier maintenance and standardization of configurations across different servers.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-04T16:01:57.609102"}}
{"question": "What actions can be performed once a transfer server has received a file from the client?", "answer": "Once a transfer server has received a file from the client, the following actions can be performed: decrypting the file using PGP keys, moving or copying data to the required location, deleting the original file post archiving or copying, tagging the file based on its contents for indexing and searching by downstream services (applicable for S3), and executing custom file processing logic by supplying a Lambda function to the workflow.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-04T16:02:04.232427"}}
{"question": "How does using a username as a variable in workflow copy steps benefit file automation in Amazon S3?", "answer": "Utilizing a username as a variable in workflow copy steps allows for dynamic routing of files to user-specific folders in Amazon S3. This feature eliminates the need to hardcode destination folder locations, enabling the automation of the creation of user-specific folders and facilitating the scaling of file automation workflows.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-04T16:02:04.232762"}}
{"question": "What is the relationship between the original file and copies created using managed workflows?", "answer": "Using managed workflows, you can create multiple copies of the original file while still preserving the original file for records retention. This relationship ensures that both the original and the copies can coexist, allowing for retention and easier access to file versions.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-04T16:02:04.233263"}}
{"question": "What are the types of uploads for which separate workflows can be defined in AWS Step Functions?", "answer": "You can define separate workflows to be triggered on complete file uploads and on partial file uploads.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:02:11.951440"}}
{"question": "How do managed workflows in AWS Step Functions differ from existing solutions for file processing?", "answer": "Managed workflows differ from existing solutions in several ways: 1) You can granularly define workflows to be executed only on full file uploads, as well as workflows to be executed only on partial file uploads; 2) workflows can be triggered automatically for S3 as well as EFS (which doesnt offer post upload events); 3) workflows provide no code and pre-built options for common file processing like PGP decryption; and 4) customers can get end to end visibility into their file transfers and processing in CloudWatch logs.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:02:11.952177"}}
{"question": "What limitations exist regarding the invocation of managed workflows in AWS Step Functions?", "answer": "Managed workflows can only be triggered for files uploaded over SFTP, FTPS, and FTP server endpoints and process one file per execution. They are not supported for messages exchanged over AS2, for file downloads over server endpoints, for files transferred using SFTP connectors, and they cannot be invoked on a granular, per-user basis. Additionally, managed workflows are not supported for web apps.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:02:11.952435"}}
{"question": "What is the requirement for using AWS PrivateLink with AWS Transfer Family servers and Amazon S3?", "answer": "You do not need to use AWS PrivateLink for data transferred from the AWS Transfer Family server to Amazon S3, as the data transfer happens over internal AWS networks and doesnt traverse the public internet. The Transfer Family service doesnt require AWS PrivateLink endpoints to communicate with Amazon S3, assuming that the AWS storage service and the Transfer Family server are in the same region.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T16:02:18.491069"}}
{"question": "How does AWS IAM facilitate user access within the AWS Transfer Family service?", "answer": "AWS IAM is used to determine the level of access for users in the AWS Transfer Family service. It includes defining the operations enabled on their client and specifying which Amazon S3 buckets they can access, whether that access is for the entire bucket or specific portions of it.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T16:02:18.491353"}}
{"question": "How do the roles of files and directories differ in the context of AWS Transfer Family and Amazon S3?", "answer": "In the context of AWS Transfer Family and Amazon S3, files are stored as individual objects in the Amazon S3 bucket, while directories are managed as folder objects in S3 using the same syntax as the S3 console. This creates a one-to-one mapping between files and objects, allowing native access to objects using AWS services for processing or analytics.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T16:02:18.491508"}}
{"question": "How can file operations be enabled or disabled for users in AWS Transfer Family?", "answer": "File operations can be enabled or disabled using the AWS IAM role that is mapped to the user's username. You should refer to the documentation on Creating IAM Policies and Roles to control your end users' access.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-04T16:02:24.463820"}}
{"question": "What benefit do S3 Access Point aliases provide when used with AWS Transfer Family?", "answer": "S3 Access Point aliases combined with AWS Transfer Family logical directories enable you to create fine-grained access control for different applications, teams, and departments, while reducing the overhead of managing bucket policies.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-04T16:02:24.464055"}}
{"question": "What is the difference in bucket access when using the AWS Transfer Family Console versus the CLI and API?", "answer": "When using the AWS Transfer Family Console, the drop-down will only list buckets in Account A. In contrast, when using the CLI and API, you can set up cross-account access between your server and the buckets you want to use for storing files transferred over supported protocols.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-04T16:02:24.464415"}}
{"question": "What type of event notifications does Amazon S3 publish?", "answer": "Amazon S3 can publish event notifications for any new object created in your bucket.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-04T16:02:29.859076"}}
{"question": "How does AWS Transfer Family event notifications differ from Amazon S3 event notifications?", "answer": "AWS Transfer Family event notifications differ from Amazon S3 event notifications in several ways: You can have granular control in defining post-upload processing for full file uploads versus partial file uploads, Transfer Family events are published for file uploads in both S3 as well as EFS, and the events generated by Transfer Family contain operational information such as the username of the sender, server-id, transfer status, etc., allowing for granular file processing based on conditional logic over these attributes.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-04T16:02:29.859432"}}
{"question": "What are the default settings for optimized S3 directory listing when creating a new server using the console after 11/17/2023?", "answer": "When creating a new server through the console after 11/17/2023, optimized S3 directory listing is enabled by default if you are using Amazon S3 as your storage.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-04T16:02:29.859624"}}
{"question": "What is the purpose of logical directory mappings in AWS Transfer Family?", "answer": "Logical directory mappings only allow users to access their designated logical paths and subdirectories, and forbid relative paths that traverse the logical roots. They help ensure that users can only access the files you intend them to.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-04T16:02:35.737555"}}
{"question": "Why might you not need both session policies and logical directories in AWS Transfer Family?", "answer": "You generally do not need both session policies and logical directories because logical directory mappings already restrict user access to designated paths and subdirectories. They actively block relative paths that could lead users beyond their intended access, thus providing the necessary security.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-04T16:02:35.738409"}}
{"question": "How does data transfer between AWS Transfer Family servers and Amazon EFS differ from using AWS PrivateLink?", "answer": "Data transfer between AWS Transfer Family servers and Amazon EFS occurs over internal AWS networks and does not traverse the public internet, which means that AWS PrivateLink is not needed for this transfer. In contrast, AWS PrivateLink is typically used to keep traffic from going over the internet, but in this case, the Transfer Family service does not require it to communicate with Amazon EFS.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-04T16:02:35.738744"}}
{"question": "What are the components of POSIX IDs used by Amazon EFS?", "answer": "POSIX IDs used by Amazon EFS consist of an operating system user id, group id, and secondary group id to control access to a file system.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-04T16:02:40.800830"}}
{"question": "Why is it important for an EFS administrator to ensure that files and directories are owned by the corresponding POSIX ids?", "answer": "It is important for an EFS administrator to ensure that files and directories are owned by the corresponding POSIX ids so that AWS Transfer Family users can access the files and directories they are permitted to use through their file transfer clients.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-04T16:02:40.801095"}}
{"question": "How does AWS Transfer Family handle user authentication in relation to EFS file systems?", "answer": "When an AWS Transfer Family user authenticates successfully using their file transfer client, they are placed directly within the specified home directory or root of the specified EFS file system, and their operating system POSIX id is applied to all requests made through their file transfer clients.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-04T16:02:40.801290"}}
{"question": "Which commands are supported for both Amazon S3 and Amazon EFS?", "answer": "The commands supported for both Amazon S3 and Amazon EFS include cd, ls/dir, pwd, put, get, rename, mkdir, rm/delete, and rmdir. However, the rename command has specific limitations regarding directory renames and overwriting existing files.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-04T16:02:46.277624"}}
{"question": "How does the IAM policy affect AWS Transfer Family users' access to file systems?", "answer": "The IAM policy you supply for your AWS Transfer Family user determines whether they have read-only, read-write, or root access to your file system. This means that the permissions outlined in the IAM policy will define the level of access each user has.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-04T16:02:46.277921"}}
{"question": "What is the difference in command support for changing ownership (chown) between Amazon S3 and Amazon EFS?", "answer": "The command to change ownership (chown) is not supported in Amazon S3, while it is supported in Amazon EFS, but only for root users (uid=0) or the file's owner, who can only change a file's group to one of their secondary groups.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-04T16:02:46.278419"}}
{"question": "What happens to symbolic links in directories accessible to the user when accessed?", "answer": "If symbolic links are present in directories accessible to your user and your user tries to access them, the links will be resolved to its target.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-04T16:02:50.975157"}}
{"question": "What are the two options for processing uploaded files in AWS Transfer Family?", "answer": "You have two options for processing uploaded files: 1) AWS Transfer Family publishes event notifications in Amazon EventBridge upon completion of a file transfer operation, which can be used to automate post upload processing of your files, and 2) you can use AWS Transfer Family managed workflows to define a linear sequence of common file processing steps that are applied for each file uploaded over your SFTP, FTPS, or FTP server endpoints.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-04T16:02:50.975471"}}
{"question": "How does cross account access differ between the AWS Transfer Family console and the CLI/API?", "answer": "The AWS Transfer Family console will only list file systems in the same account, while you can use the CLI and API to set up cross account access between your AWS Transfer Family resources and EFS file systems.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-04T16:02:50.975871"}}
{"question": "What happens if an AWS Transfer Family server is set up to access a cross account EFS file system that is not enabled for cross account access?", "answer": "If you set up an AWS Transfer Family server to access a cross account EFS file system that is not enabled for cross account access, your SFTP/FTP/FTPS users will be denied access to the file system.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T16:02:55.504959"}}
{"question": "What are the benefits of using AWS Transfer Family with Amazon EFS?", "answer": "You can use AWS Transfer Family to write files into EFS and configure EFS Lifecycle Management to migrate files that have not been accessed for a set period of time to the Infrequent Access (IA) storage class. Amazon EFS also provides a file system interface, file system access semantics such as strong consistency and file locking, and concurrently-accessible storage for up to thousands of NFS/SFTP/FTPS/FTP clients.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T16:02:55.505271"}}
{"question": "How does the access of EFS file systems via AWS Transfer Family servers affect EFS burst credits compared to other access methods?", "answer": "Accessing your EFS file systems using your AWS Transfer Family servers will consume your EFS burst credits regardless of the throughput mode.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T16:02:55.505667"}}
{"question": "What compliance standards do AWS East/West and GovCloud (US) Regions adhere to?", "answer": "AWS East/West and GovCloud (US) Regions are FISMA compliant. Additionally, AWS Transfer Family will also be FISMA compliant when authorized for FedRAMP within these regions.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-04T16:03:01.220845"}}
{"question": "How does AWS demonstrate compliance with FISMA and FedRAMP in the East/West and GovCloud Regions?", "answer": "AWS demonstrates compliance through annual assessments and by documenting compliance with in-scope NIST SP 800-53 controls within their System Security Plans. This compliance is further validated by the FedRAMP Authorization of these regions to FedRAMP Moderate and FedRAMP High.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-04T16:03:01.221195"}}
{"question": "Can you compare the log monitoring capabilities of AWS Transfer Family with CloudWatch versus using AWS Transfer Family managed workflows?", "answer": "AWS Transfer Family allows you to monitor end users file transfer activities using JSON formatted logs delivered to Amazon CloudWatch, where you can parse and query logs with CloudWatch Log Insights and track usage with CloudWatch Contributor Insights. In contrast, AWS Transfer Family managed workflows provide automated file decryption using PGP keys when files are uploaded to the servers, which is a different function focused on file processing rather than monitoring.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-04T16:03:01.221573"}}
{"question": "What metrics can be monitored using AWS CloudWatch for workflow executions?", "answer": "AWS CloudWatch metrics that can be monitored for workflow executions include the total number of workflow executions, successful executions, and failed executions.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-04T16:03:05.281299"}}
{"question": "How can you receive notifications for files uploaded using AWS Transfer Family?", "answer": "You can receive notifications for files uploaded over your SFTP, FTPS, and FTP server endpoints by using Transfer Familys managed workflows or by subscribing to AWS Transfer Family events in Amazon EventBridge to receive notifications using Amazon Simple Notification Service (SNS).", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-04T16:03:05.281558"}}
{"question": "How does billing work for AWS Transfer Family protocols when multiple protocols are enabled?", "answer": "You are billed on an hourly basis for each of the protocols you have enabled and for the amount of data transferred through each of the protocols. This billing occurs regardless of whether the same endpoint is enabled for multiple protocols or if you are using different endpoints for each protocol.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-04T16:03:05.281736"}}
{"question": "Does stopping the server using the console or CLI command affect billing?", "answer": "No, stopping the server, whether by using the console, the 'stop-server' CLI command, or the 'StopServer' API command, does not impact billing. You are billed on an hourly basis from the time you create your server endpoint and configure access to it until you delete it.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-04T16:03:10.115012"}}
{"question": "What factors contribute to the billing for a Decrypt workflow step?", "answer": "You are billed for the Decrypt workflow step based on the amount of data you decrypt using PGP keys. There are no additional charges for using managed workflows. Additionally, depending on your workflow configuration, you may also incur charges for the use of Amazon S3, Amazon EFS, AWS Secrets Manager, and AWS Lambda.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-04T16:03:10.115289"}}
{"question": "How does the billing for SFTP connectors compare to server billing?", "answer": "There is no hourly billing for SFTP connectors, while servers are billed on an hourly basis from the time of creation until deletion. This indicates that SFTP connectors do not incur charges based on time, unlike server endpoints that do.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-04T16:03:10.115711"}}
{"question": "What is AWS Backup and what services does it protect?", "answer": "AWS Backup is a fully managed service that centralizes and automates data protection across various AWS services, including Amazon Simple Storage Service (S3), Amazon FSx, Amazon Elastic Compute Cloud (EC2), and Amazon Relational Database Service (RDS), as well as hybrid workloads like VMware on premises, VMware Cloud on AWS, and VMware Cloud on AWS Outposts.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:03:17.308024"}}
{"question": "How does AWS Backup simplify data protection at scale?", "answer": "AWS Backup simplifies data protection at scale by offering a cost-effective, fully managed, policy-based service. Users can define a central data protection policy called a backup plan that works across AWS services, which includes parameters such as backup frequency and retention period. This automation allows for the creation and management of backups across multiple resources and accounts.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:03:17.308378"}}
{"question": "What are the benefits of using AWS Backup in conjunction with AWS Organizations?", "answer": "Using AWS Backup in conjunction with AWS Organizations allows users to centrally deploy data protection policies across their AWS accounts and resources. This integration helps configure, manage, and govern backup activities more effectively, ensuring consistent application of backup policies and automating backup access management across all accounts.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:03:17.308593"}}
{"question": "What features does AWS Backup provide for managing data protection?", "answer": "AWS Backup provides a centralized console, automated backup scheduling, backup retention management, and backup monitoring and alerting. Additionally, it offers advanced features such as lifecycle policies for transitioning backups to a low-cost storage tier, backup storage and encryption independent from its source data, audit and compliance reporting capabilities with AWS Backup Audit Manager, delete protection with AWS Backup Vault Lock, and immutable backup copies with AWS Backup logically air-gapped vault.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-04T16:03:23.631863"}}
{"question": "Why is AWS Backup considered beneficial for data protection compared to building custom backup workflows?", "answer": "AWS Backup is considered beneficial for data protection because it removes the need for costly, custom solutions or manual processes. It provides a fully managed, policy-based data protection solution that simplifies the complexity and costs associated with building and managing backup workflows across various applications in a compliant and consistent manner.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-04T16:03:23.636734"}}
{"question": "How does AWS Backup support both on-premises and AWS environments?", "answer": "AWS Backup supports both on-premises and AWS environments by allowing backups of on-premises Storage Gateway volumes and VMware virtual machines, providing a common way to manage the backups of application data regardless of the location.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-04T16:03:23.636871"}}
{"question": "What types of backups can AWS Backup access?", "answer": "AWS Backup can access backups created using services with existing backup capabilities, such as EBS Snapshots. Additionally, backups created by AWS Backup can also be accessed using the source service.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-04T16:03:29.054147"}}
{"question": "How does AWS Backup enhance backup management for AWS services?", "answer": "AWS Backup enhances backup management by providing a centralized service that offers backup scheduling, retention management, and backup monitoring across AWS services. It supports existing backup functionality from services like S3, EBS, RDS, Amazon FSx, DynamoDB, and Storage Gateway, and allows for management of backups both on AWS and on premises.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-04T16:03:29.054487"}}
{"question": "What is the relationship between Amazon Data Lifecycle Manager and AWS Backup regarding EBS snapshots?", "answer": "Amazon Data Lifecycle Manager and AWS Backup provide two independent ways to manage EBS snapshots. Amazon Data Lifecycle Manager offers a streamlined approach to automate the creation, retention, and deletion of EBS snapshots, while AWS Backup is used to manage and monitor backups across various AWS services, including EBS volumes, from a single interface.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-04T16:03:29.054884"}}
{"question": "What features does AWS Backup's native dashboard provide for monitoring backup activities?", "answer": "AWS Backup's native dashboard provides a scalable mechanism to monitor backup health across multiple environments through cross account and cross region support. It allows users to track backup, copy, and restore jobs and to surface and pinpoint specific failure jobs across organizations using built-in metrics.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-04T16:03:34.816471"}}
{"question": "How does AWS Backup integrate with AWS CloudTrail, and what benefit does this provide?", "answer": "AWS Backup integrates with AWS CloudTrail to provide a consolidated view of backup activity logs. This integration simplifies the audit process for protected resources, making it easier to track and review backup activities.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-04T16:03:34.816793"}}
{"question": "In regions where AWS Backup's native dashboard is not supported, how can users monitor their backup activities?", "answer": "In regions where AWS Backup's native dashboard is not supported, users can monitor their backup activities through Amazon CloudWatch dashboards included in the AWS Backup console. This allows customers to see metrics on completed or failed backup, copy, and restore jobs, and to view job status by customizable time periods.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-04T16:03:34.817207"}}
{"question": "What are the components of a backup rule in an AWS Backup plan?", "answer": "A backup rule in an AWS Backup plan is composed of four components: 1) a backup schedule, which includes the backup frequency (Recovery Point Objective [RPO]) and backup window; 2) a lifecycle rule that specifies when to transition a backup from one storage tier to another and when to expire the recovery point; 3) the backup vault in which to place the created recovery points; and 4) the tags to be added to backups upon creation.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-04T16:03:40.340857"}}
{"question": "How does the AWS Backup lifecycle feature benefit users?", "answer": "The AWS Backup lifecycle feature benefits users by automatically transitioning recovery points from a warm storage tier to a lower-cost cold storage tier, helping to optimize storage costs for backups that are not frequently accessed.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-04T16:03:40.341205"}}
{"question": "What is the difference between a backup vault and backup plans in AWS Backup?", "answer": "A backup vault is an encrypted storage location that stores and organizes backups (recovery points), while backup plans are policy expressions that define when and how to back up AWS resources. Backup plans consist of one or more backup rules that dictate the backup schedule, lifecycle, storage, and tagging, whereas backup vaults are where the created recovery points are stored.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-04T16:03:40.341595"}}
{"question": "What types of services have backups that are encrypted in transit and at rest independently from source services?", "answer": "Backups for EFS, DynamoDB, S3, Timestream, and VMware virtual machines are encrypted in transit and at rest independently from source services.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T16:03:45.415211"}}
{"question": "How does AWS Backup enhance data protection across different AWS services?", "answer": "AWS Backup enhances data protection by centralizing and automating data protection policies based on organizational best practices and regulatory standards. It also allows for the setting of resource-based policies on backup vaults, enabling control over access to the vault and the backups within. Additionally, it supports advanced features such as lifecycle tiering, independent backup storage and encryption, and backup access policies.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T16:03:45.415429"}}
{"question": "How does the backup encryption methodology differ between EBS snapshots and backups for services like EFS and S3?", "answer": "EBS snapshots are encrypted using the encryption key of the volume the snapshot was created from, which is the source service's backup encryption methodology. In contrast, backups for services like EFS and S3 are encrypted in transit and at rest independently from their source services, with encryption configured at the backup vault level.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-04T16:03:45.415557"}}
{"question": "What is the purpose of AWS Backup Audit Manager?", "answer": "The purpose of AWS Backup Audit Manager is to verify that the workloads you create in or migrate to AWS meet your data protection requirements. It simplifies the implementation, tracking, and demonstration of adherence to backup governance and compliance policies.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-04T16:03:50.236453"}}
{"question": "How does AWS Backup Audit Manager help in managing backup compliance?", "answer": "AWS Backup Audit Manager helps in managing backup compliance by providing built-in compliance controls that can be customized to define data protection policies. It automatically detects violations of these policies and prompts users to take corrective actions. Additionally, it allows continuous evaluation of backup activity and generates audit reports to demonstrate compliance with regulatory requirements.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-04T16:03:50.236733"}}
{"question": "What is the relationship between an AWS Backup Audit Manager control and a framework?", "answer": "An AWS Backup Audit Manager control is a procedure designed to audit the compliance of a specific backup requirement, while a framework is a collection of these controls that can be deployed and managed as a single entity. The compliance status of a control is determined by evaluating the configuration of backup resources against defined settings, and the compliance status of a framework is COMPLIANT only if all of its controls are compliant.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-04T16:03:50.237135"}}
{"question": "What does AWS Config do?", "answer": "AWS Config continuously monitors and records your AWS resource configurations, allowing you to automate the evaluation of recorded configurations against desired configurations.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-04T16:03:54.533091"}}
{"question": "How does AWS Backup Audit Manager enhance backup compliance?", "answer": "AWS Backup Audit Manager integrates with AWS Config to track your backup activity and transcribe your data protection policies into backup controls. It evaluates your backup activity against these controls, records backup compliance status, and allows you to generate reports for auditing and monitoring purposes.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-04T16:03:54.533422"}}
{"question": "What compliance standards does AWS Backup meet, and how does it relate to PCI DSS and HIPAA?", "answer": "AWS Backup has been assessed to meet global and industry security standards, including PCI DSS, ISO 9001, 27001, 27017, and 27018, and is HIPAA eligible. This means AWS Backup can be used to transfer payment information under PCI DSS compliance and protected health information (PHI) if a HIPAA BAA is in place with AWS.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-04T16:03:54.533790"}}
{"question": "What is the primary purpose of AWS Backup Vault Lock?", "answer": "The primary purpose of AWS Backup Vault Lock is to help prevent changes to backup lifecycle and to prevent manual deletion of backups, ensuring compliance with requirements.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-04T16:03:58.861215"}}
{"question": "How does AWS Backup Vault Lock help organizations meet compliance requirements?", "answer": "AWS Backup Vault Lock helps organizations meet compliance requirements by verifying that backups are stored using a Write-Once-Read-Many (WORM) model, preventing any user, including administrators, from deleting backups or changing their lifecycle settings such as retention periods and transitions to cold storage.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-04T16:03:58.861452"}}
{"question": "What is the difference between AWS Backup Vault Lock and S3 Glacier Vault Lock?", "answer": "AWS Backup Vault Lock applies to data residing in AWS Backup backup vaults and prevents manual deletion and changes to lifecycle settings for backups, while S3 Glacier Vault Lock applies to individual S3 Glacier vaults and enables compliance controls specifically for long-term record retention of those vaults.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-04T16:03:58.861796"}}
{"question": "What are the three properties that comprise the AWS Backup Vault Lock configuration?", "answer": "The three properties that comprise the AWS Backup Vault Lock configuration are minimum acceptable retention days, maximum acceptable retention days, and grace time.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T16:04:03.670027"}}
{"question": "How does AWS Backup Vault Lock protect newly created recovery points?", "answer": "When you activate the AWS Backup Vault Lock configuration, AWS Backup will protect all newly created recovery points in the vault against deletion and changes to their lifecycle. It will also fail all backup jobs with retention periods that do not meet the acceptable retention periods defined by the AWS Backup Vault Lock.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T16:04:03.670302"}}
{"question": "What is the difference between the AWS Backup Vault Lock configuration and legal holds?", "answer": "The AWS Backup Vault Lock configuration prevents deletion and changes to the lifecycle of backups based on defined retention periods, and it can be modified during the grace time before it locks. In contrast, legal holds, or litigation holds, prevent backups from being deleted even after their retention period has expired and remain in place until explicitly released, regardless of the retention settings.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T16:04:03.670709"}}
{"question": "What capabilities do AWS Backup and Amazon S3 provide for business continuity management?", "answer": "Both AWS Backup and Amazon S3 offer capabilities that help manage the business continuity of applications. AWS Backup allows for centralized management of backup and restore across multiple AWS services, while Amazon S3 enables management of data in S3 buckets and objects.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:04:10.038298"}}
{"question": "How can you use AWS Backup to integrate Amazon S3 resources into your existing backup plan?", "answer": "You can integrate Amazon S3 resources into your existing backup plan by adding them using tags or S3 bucket ARNs. AWS Backup will match the tags in S3 buckets with those assigned to your backup plan and back up those resources along with other AWS services used by your application.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:04:10.038540"}}
{"question": "What are the differences between continuous and periodic backups for Amazon S3 resources in AWS Backup?", "answer": "Continuous backups for Amazon S3 resources allow restoration to any point in time within the last 35 days, which is useful for undoing accidental deletions. In contrast, periodic backups retain data for an infinite period and can be scheduled at frequencies such as 1 hour, 12 hours, 1 day, 1 week, or 1 month, or created on demand, which helps meet long-term data retention needs.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:04:10.038935"}}
{"question": "What versions of VMware ESXi does AWS Backup support?", "answer": "AWS Backup supports VMware ESXi 6.7.X and 7.0.X VMs.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T16:04:15.342811"}}
{"question": "How does AWS Backup integrate with VMware environments for data protection?", "answer": "AWS Backup integrates with VMware environments by connecting to VMware workloads using the AWS Backup gateway, which is deployed in the VMware environment. It discovers VMs through VMware vCenter Server, takes VM snapshots, and manages backup and restore data between AWS Backup and the VMware environment. This allows AWS Backup to provide a unified view of backups and centrally manage the protection of VMware workloads along with supported AWS services.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T16:04:15.343139"}}
{"question": "What are the differences between SCSI Hot-Add and Network Block Device (NBD) transport modes in AWS Backup?", "answer": "The context does not provide specific differences between SCSI Hot-Add and Network Block Device (NBD) transport modes in AWS Backup. It only states that AWS Backup supports both transport modes for copying data from source virtual machines to AWS.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T16:04:15.343558"}}
{"question": "What encryption method does AWS Backup use for VMware backups?", "answer": "AWS Backup encrypts VMware backups in transit and at rest using the AES-256 encryption algorithm. Additionally, you can use customer-managed keys to encrypt backups stored in the cloud.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-04T16:04:20.460808"}}
{"question": "How does AWS Backup help in meeting low latency and local data processing needs for VMware Cloud on AWS Outposts?", "answer": "AWS Backup allows you to protect your VMware Cloud on AWS Outposts VMs, ensuring that your application data can be processed locally while meeting low latency requirements. It stores your VM backups in the AWS Region that your VMware Cloud on AWS Outposts is connected to, which aligns with data residency requirements.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-04T16:04:20.461123"}}
{"question": "What is the difference between app-consistent and crash-consistent backups in AWS Backup?", "answer": "App-consistent backups in AWS Backup are created using the VMware Tools quiescence setting on the VM, ensuring that the backups include all application data in a consistent state. In contrast, crash-consistent backups are captured when the quiescence capability is not available, which may not reflect the application's state at the time of backup.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-04T16:04:20.461562"}}
{"question": "Can you copy VMware backups to another AWS account?", "answer": "Yes, you can copy VMware backups to another AWS account, which helps you use backups between your production and dev/test environments or between different department and project accounts. This capability is enabled by AWS Backups integration with AWS Organizations.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-04T16:04:26.304336"}}
{"question": "What is a logically air-gapped vault in AWS Backup?", "answer": "A logically air-gapped vault is a type of AWS Backup vault that stores an immutable copy of a backup with encryption using AWS owned keys. It allows for secure sharing of access to other accounts, facilitating faster and more flexible recovery time objectives (RTOs) in case of an incident that requires rapid restoration of resources. This vault type is automatically set with a vault lock in compliance mode and is intended to enhance your organization's retention and recovery capabilities.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-04T16:04:26.304776"}}
{"question": "How does the network bandwidth requirement for backing up VMware VMs compare to the recommended bandwidth for AWS Backup?", "answer": "The required network bandwidth for backing up VMware VMs depends on several factors, including the size of each VM, the incremental data generated per VM, and your backup window and restore requirements. However, it is recommended to have at least 100-Mbps bandwidth to AWS for backing up on-premises VMware VMs using AWS Backup.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-04T16:04:26.305276"}}
{"question": "What is a logically air-gapped vault in AWS Backup?", "answer": "A logically air-gapped vault provides a secure backup environment where immutable backup copies are locked by default and protected through encryption using AWS-owned keys. This encryption is managed through AWS Key Management Service (AWS KMS), which eliminates the operational overhead and costs associated with managing your own encryption keys.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-04T16:04:32.566962"}}
{"question": "How does Multi-party approval enhance security for access to backups in logically air-gapped vaults?", "answer": "Multi-party approval enhances security by requiring multiple authorized individuals to approve access to backups stored in logically air-gapped vaults. This additional layer of security ensures that access to backups is authorized even when the vault account becomes inaccessible due to inadvertent or intentional events, such as malware.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-04T16:04:32.567313"}}
{"question": "What are the differences in backup sharing between accounts within the same AWS Organization and accounts in different Organizations?", "answer": "Backups can be shared across accounts within the same AWS Organization and with accounts in different Organizations through AWS Resource Access Manager (AWS RAM). However, when a vault is shared, backups can be restored directly in the destination account without needing to create additional copies, which helps reduce recovery time and costs for both scenarios.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-04T16:04:32.567729"}}
{"question": "What is AWS Batch used for?", "answer": "AWS Batch is used for running hundreds of thousands of batch computing jobs on AWS efficiently. It dynamically provisions the optimal quantity and type of compute resources based on the specific resource requirements of the batch jobs submitted.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T16:04:37.131056"}}
{"question": "How does AWS Batch improve the efficiency of compute resource utilization?", "answer": "AWS Batch improves the efficiency of compute resource utilization by avoiding idling compute resources with frequent manual intervention and supervision, and it increases efficiency by driving higher utilization of compute resources.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T16:04:37.131494"}}
{"question": "What are the differences between AWS Batch and traditional batch computing methods?", "answer": "AWS Batch automates the provisioning and management of batch computing resources, which eliminates the need to install and manage batch computing software or server clusters. Traditional batch computing methods typically require manual intervention and do not dynamically allocate resources based on job requirements.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T16:04:37.131696"}}
{"question": "When should I use AWS Batch with Fargate?", "answer": "You should run your jobs on Fargate when you want AWS Batch to handle provisioning of compute completely abstracted from ECS infrastructure.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-04T16:04:41.645373"}}
{"question": "What are the benefits of using EC2 with AWS Batch?", "answer": "You should run your jobs on EC2 if you need access to particular instance configurations, such as specific processors, GPUs, or architecture, or if you are dealing with very-large scale workloads.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-04T16:04:41.645721"}}
{"question": "How do the job start times compare between Fargate and EC2 for different workloads?", "answer": "Fargate jobs will start faster in the case of initial scale-out of work, as there is no need to wait for an EC2 instance to launch. However, for larger workloads, EC2 instances may be faster because Batch reuses instances and container images to run subsequent jobs.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-04T16:04:41.645941"}}
{"question": "What happens when the vCPU count hits max vCPU in a Fargate Compute Environment (CE)?", "answer": "When your vCPU count hits max vCPU in a Fargate Compute Environment, AWS Batch will begin scheduling jobs on the next Fargate CE in order that is attached to the queue, if there is one.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-04T16:04:47.209337"}}
{"question": "What is the purpose of setting a max vCPU for a Fargate CE in AWS Batch?", "answer": "Setting a max vCPU for a Fargate CE allows you to control the total amount of vCPU used by all jobs currently running in that CE, which helps manage resource allocation and ensures that certain business requirements are met before spilling over into other compute environments.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-04T16:04:47.209659"}}
{"question": "How does AWS Batch manage job scheduling between Fargate Spot CE and Fargate CE?", "answer": "AWS Batch will spill over into Fargate CE from a Fargate Spot CE only when the vCPU used by jobs exceeds the max vCPU for the Fargate Spot CE. If Fargate Spot is reclaimed and the max vCPU is not met, Batch will not request Fargate resources in the subsequent CE to run jobs.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-04T16:04:47.210273"}}
{"question": "What feature should you use in AWS Batch to model your workload as a set of logically distinct elements?", "answer": "You should use the multi-container jobs feature to model your AWS Batch workload as a set of logically distinct elements.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-04T16:04:51.243966"}}
{"question": "How does using multi-container jobs in AWS Batch simplify DevOps?", "answer": "Using multi-container jobs simplifies DevOps by allowing you to avoid combining all workload elements into a monolithic container, which would require rebuilding after every code change. Instead, you can keep containers small and fast to download, and facilitate the parallelization of work.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-04T16:04:51.244244"}}
{"question": "In what ways do AWS Batch compute environments support running multi-container jobs?", "answer": "AWS Batch supports running multi-container jobs in all compute environments, including Amazon ECS, Amazon EC2, AWS Fargate, and Amazon EKS. This allows jobs to be executed across various environments while managing compute resources effectively.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-04T16:04:51.244731"}}
{"question": "What are the two types of Compute Environments supported by AWS Batch?", "answer": "AWS Batch supports two types of Compute Environments: Managed Compute Environments, which are provisioned and managed by AWS, and Unmanaged Compute Environments, which are managed by customers.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-04T16:04:55.998784"}}
{"question": "How does AWS Batch optimize the execution of a job?", "answer": "AWS Batch optimizes the execution of a job through Job Definitions, which describe the job to be executed, including parameters, environmental variables, compute requirements, and other information.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-04T16:04:55.999065"}}
{"question": "How do Managed Compute Environments and Unmanaged Compute Environments differ in terms of resource management?", "answer": "Managed Compute Environments are provisioned and managed by AWS, while Unmanaged Compute Environments are managed by customers, allowing for the use of specialized resources such as Dedicated Hosts and larger storage configurations.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-04T16:04:55.999468"}}
{"question": "What types of accelerators can currently be used with AWS Batch?", "answer": "Currently, you can use GPUs on P and G accelerated instances with AWS Batch.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-04T16:05:02.259543"}}
{"question": "How does AWS Batch manage the scheduling and provisioning of jobs that require accelerators?", "answer": "AWS Batch dynamically schedules and provisions jobs according to their accelerator needs. It ensures that the appropriate number of accelerators are reserved against the jobs, scales up EC2 Accelerated Instances when needed, and scales them down when the jobs are completed. This allows users to focus on their applications.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-04T16:05:02.259986"}}
{"question": "How does Batch handle job scheduling for jobs that do not require acceleration on accelerated instances?", "answer": "Batch will avoid scheduling jobs that do not require acceleration on accelerated instances when possible. This is done to prevent long-running jobs from occupying the accelerated instance without utilizing the accelerator, which would increase costs. However, in rare cases with Spot pricing, Batch might determine that using an accelerated instance is the least expensive way to run jobs, regardless of whether they need acceleration.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-04T16:05:02.260306"}}
{"question": "What type of AMI will p-type instances launch with by default?", "answer": "P-type instances will launch by default with the ECS GPU-optimized AMI, which contains libraries and runtimes needed to run GPU-based applications.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-04T16:05:07.575461"}}
{"question": "What is the purpose of the ECS GPU-optimized AMI?", "answer": "The ECS GPU-optimized AMI is designed to provide the necessary libraries and runtimes needed to run GPU-based applications.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-04T16:05:07.575793"}}
{"question": "How does the AWS Batch web console assist users in managing compute resources?", "answer": "The AWS Batch web console guides users through the process of creating their first Compute Environment and Job Queue, allowing them to submit their first job without needing to manually launch their own compute resources. Additionally, resources within the compute environment will scale up as more jobs are ready to run and scale down as the number of runnable jobs decreases.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-04T16:05:07.576232"}}
{"question": "What is Amazon Bedrock?", "answer": "Amazon Bedrock is a fully managed service that offers a choice of industry-leading foundation models (FMs) along with a broad set of capabilities needed to build generative AI applications. It simplifies development with a focus on security, privacy, and responsible AI.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:05:13.529373"}}
{"question": "How does Amazon Bedrock enable the customization of foundation models?", "answer": "Amazon Bedrock allows users to customize foundation models privately with their data using techniques such as fine-tuning and retrieval-augmented generation (RAG). This enables users to tailor the models to better fit their specific needs.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:05:13.529706"}}
{"question": "What are the advantages of using Amazon Bedrock compared to managing your own infrastructure for generative AI applications?", "answer": "The advantages of using Amazon Bedrock include that it is a serverless service, meaning users do not have to manage any infrastructure. Additionally, it allows for secure integration and deployment of generative AI capabilities into applications using familiar AWS services.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:05:13.530343"}}
{"question": "What is one benefit of using Amazon Bedrock for building generative AI applications?", "answer": "One benefit of using Amazon Bedrock for building generative AI applications is the choice of leading foundational models (FMs). It offers an easy-to-use developer experience to work with a broad range of high-performing FMs from leading AI companies, allowing users to quickly experiment with various models and use a single API for inference regardless of the models chosen.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-04T16:05:20.061570"}}
{"question": "How does Amazon Bedrock allow users to customize foundational models with their own data?", "answer": "Amazon Bedrock allows users to privately customize foundational models with their own data through a visual interface without the need to write any code. Users can simply select the training and validation datasets stored in Amazon Simple Storage Service (Amazon S3) and, if necessary, adjust hyperparameters to achieve optimal model performance.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-04T16:05:20.061833"}}
{"question": "How do the fully managed agents in Amazon Bedrock compare to traditional methods of executing business tasks?", "answer": "The fully managed agents in Amazon Bedrock differ from traditional methods as they can dynamically invoke APIs to execute complex business tasks, such as booking travel or processing insurance claims. This capability allows the agents to extend the reasoning capabilities of FMs to break down tasks, create orchestration plans, and execute them, which may not be as easily achievable with traditional methods.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-04T16:05:20.061989"}}
{"question": "What compliance certifications does Amazon Bedrock support?", "answer": "Amazon Bedrock supports several compliance certifications including Service and Organization Control (SOC), International Organization for Standardization (ISO), is Health Insurance Portability and Accountability Act (HIPAA) eligible, and can be used in compliance with the General Data Protection Regulation (GDPR). Additionally, Amazon Bedrock is CSA Security Trust Assurance and Risk (STAR) Level 2 certified.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-04T16:05:26.354538"}}
{"question": "How does Amazon Bedrock ensure the security of customer data?", "answer": "Amazon Bedrock ensures the security of customer data by always encrypting data in transit and at rest. Additionally, customers have the option to encrypt their data using their own keys. Furthermore, Amazon Bedrock does not use customer content to improve its base models nor share it with model providers, ensuring privacy.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-04T16:05:26.354765"}}
{"question": "How does the use of AWS PrivateLink with Amazon Bedrock compare to traditional internet connectivity?", "answer": "Using AWS PrivateLink with Amazon Bedrock allows for private connectivity between your foundation models (FMs) and your Amazon Virtual Private Cloud (Amazon VPC) without exposing your traffic to the Internet. This contrasts with traditional internet connectivity, which involves exposing traffic to potential security risks over the public internet.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-04T16:05:26.355220"}}
{"question": "What types of content can you create using Amazon Bedrock?", "answer": "Using Amazon Bedrock, you can create new pieces of original content such as short stories, essays, social media posts, and web page copy. Additionally, you can create realistic and artistic images of various subjects, environments, and scenes from language prompts.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-04T16:05:32.215083"}}
{"question": "How does Amazon Bedrock facilitate the integration of FMs into applications?", "answer": "Amazon Bedrock facilitates the integration of FMs into applications by allowing users to easily integrate them using AWS tools without having to manage any infrastructure. Once users have identified their use case, they can quickly start utilizing the FMs in their applications.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-04T16:05:32.215446"}}
{"question": "In what ways can fine-tuning FMs on Amazon Bedrock be achieved compared to using pretrained models?", "answer": "Fine-tuning FMs on Amazon Bedrock can be achieved using tagged data or by utilizing the continued pre-train feature, which allows customization of the model using non-tagged data. In contrast, pretrained models can be used directly to generate text or images without any additional customization.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-04T16:05:32.215911"}}
{"question": "Which models are currently supported for import into Amazon Bedrock using the Custom Model Import feature?", "answer": "The Custom Model Import feature in Amazon Bedrock currently supports Llama 2/3, Mistral, and Flan architectures.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-04T16:05:35.643890"}}
{"question": "What benefits does latency-optimized inference in Amazon Bedrock provide for model interactions?", "answer": "Latency-optimized inference in Amazon Bedrock reduces response times for foundation model interactions, maintains accuracy while improving speed, and requires no additional setup or model fine-tuning.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-04T16:05:35.644236"}}
{"question": "How does the performance of Claude 3.5 Haiku in Amazon Bedrock compare to its performance in other environments?", "answer": "Claude 3.5 Haiku runs faster on AWS with latency-optimized inference than anywhere else, according to verification by Anthropic.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-04T16:05:35.644766"}}
{"question": "What is Amazon Bedrock Agents designed to do?", "answer": "Amazon Bedrock Agents is designed to make it easier for developers to create generative-AI based applications that can complete complex tasks for a wide range of use cases and deliver up-to-date answers based on proprietary knowledge sources.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-04T16:05:41.182797"}}
{"question": "How does Amazon Bedrock Agents enhance the process of task management for developers?", "answer": "Amazon Bedrock Agents enhances the process of task management for developers by automatically breaking down tasks and creating an orchestration plan without any manual coding. It also securely connects to company data through an API, converting data into a machine-readable format and augmenting requests with relevant information to generate the most accurate responses.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-04T16:05:41.183137"}}
{"question": "What are the differences between Amazon Bedrock Agents and AgentCore in terms of their intended use?", "answer": "Amazon Bedrock Agents is focused on helping developers create generative-AI based applications and manage complex tasks, while AgentCore is designed for organizations looking to move AI agents from proofs of concept to production. AgentCore provides tools and infrastructure to support dynamic execution paths, monitoring behavior, and enhancing agents, emphasizing robust infrastructure and enterprise-grade security.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-04T16:05:41.183611"}}
{"question": "What is the purpose of the Memory service in AgentCore?", "answer": "The Memory service in AgentCore makes it easy for developers to build context-aware agents by eliminating complex memory infrastructure management while providing full control over what the AI agent remembers.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T16:05:45.971206"}}
{"question": "How does the Gateway service enhance the capabilities of AI agents in AgentCore?", "answer": "The Gateway service enhances the capabilities of AI agents by providing a secure way for agents to discover and use tools, along with making it easy to transform APIs, Lambda functions, and existing services into agent-compatible tools.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T16:05:45.971490"}}
{"question": "In what ways do the Code Interpreter and Browser tool services in AgentCore differ in their functionalities?", "answer": "The Code Interpreter service enables AI agents to write and execute code securely in sandbox environments, enhancing their accuracy and expanding their ability to solve complex end-to-end tasks. In contrast, the Browser tool provides a fast, secure, cloud-based browser runtime that enables AI agents to interact with websites at scale. Thus, the Code Interpreter focuses on code execution, while the Browser tool focuses on web interaction.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T16:05:45.971942"}}
{"question": "What functionalities does AgentCore provide compared to Amazon Bedrock Agents?", "answer": "AgentCore provides additional functionalities such as the ability to use any agent authoring framework (including Strands Agents, Crew AI, LangGraph, LangChain, or LlamaIndex), fine-grained control on identity, memory, and observability. It also offers upgraded tools and infrastructure for running agents at scale, including customizable long-term memory, an enhanced code interpreter tool, a built-in browser tool, observability, native support for Model Context Protocol for connection to thousands of tools, and a runtime with industry-leading execution time, payload size, and complete session isolation.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-04T16:05:51.816480"}}
{"question": "Why might a customer choose to switch from Amazon Bedrock Agents to AgentCore?", "answer": "A customer might choose to switch from Amazon Bedrock Agents to AgentCore to take advantage of the additional functionalities that AgentCore offers, such as the ability to use any agent authoring framework, enhanced control over identity and memory, improved observability, and upgraded tools for running agents at scale. This switch can facilitate production-grade deployment and provide better performance and customization options.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-04T16:05:51.816884"}}
{"question": "How does the data handling of Amazon Bedrock compare to the handling of users' inputs and model outputs?", "answer": "Amazon Bedrock encrypts and stores any customer content processed in the AWS Region where it is used, ensuring data security. In contrast, users' inputs and model outputs are not shared with any model providers, indicating a focus on user privacy and data protection.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-04T16:05:51.817171"}}
{"question": "What compliance standards is Amazon Bedrock in scope for?", "answer": "Amazon Bedrock is in scope for compliance standards such as Fedramp Moderate, Service and Organization Control (SOC), International Organization for Standardization (ISO), Health Insurance Portability and Accountability Act (HIPAA) eligibility, and General Data Protection Regulation (GDPR).", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-04T16:05:58.805861"}}
{"question": "How does Amazon Bedrock ensure the privacy of user data?", "answer": "Amazon Bedrock ensures the privacy of user data by stating that the content is not used to improve the base models and is not shared with any model providers. Additionally, customers can use AWS PrivateLink to establish private connectivity from Amazon VPC to Amazon Bedrock, which avoids exposing data to internet traffic.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-04T16:05:58.806144"}}
{"question": "How does the certification of Amazon Bedrock under ISO standards compare to its compliance with SOC reports?", "answer": "Amazon Bedrock is included in the scope of the SOC 1, 2, 3 reports, allowing customers to gain insights into security controls through extensive third-party audits of AWS controls. In contrast, it is also certified under multiple ISO standards including ISO 9001, ISO 27001, ISO 27017, ISO 27018, ISO 27701, ISO 22301, and ISO 20000, which demonstrates compliance with a broader range of quality and security management standards.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-04T16:05:58.806628"}}
{"question": "What types of models will customers see billed on their AWS Marketplace bill?", "answer": "Customers will see an AWS Marketplace bill for certain Bedrock serverless models and Bedrock Marketplace models, as these models are sold by third party providers as 'Third-Party Content'.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-04T16:06:04.212841"}}
{"question": "How does Amazon Bedrock ensure the security of data when fine-tuning a model?", "answer": "When fine-tuning a model, Amazon Bedrock ensures the security of data by never exposing it to the public internet, keeping it within the AWS network, securely transferring it through the VPC, and encrypting it in transit and at rest. Additionally, Amazon Bedrock enforces the same AWS access controls that apply to other AWS services.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-04T16:06:04.213331"}}
{"question": "What is the difference between continued pretraining and direct fine-tuning of Amazon Titan base models?", "answer": "Continued pretraining adapts the Amazon Titan base model to a more specific domain using large amounts of unlabeled data, preserving most of its capabilities and requiring fewer labeled training records for subsequent fine-tuning. In contrast, direct fine-tuning of the base model requires large amounts of labeled training records and a longer training duration to achieve accurate results.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-04T16:06:04.213620"}}
{"question": "What steps should I follow to create a continued pretraining job in Amazon Bedrock?", "answer": "To create a continued pretraining job in Amazon Bedrock, navigate to the Amazon Bedrock console and click on 'Custom Models.' You will then go to the custom model page which has two tabs: Models and Training jobs. Both tabs feature a 'Customize Model' drop-down menu on the right. Select 'Continued Pretraining' from the drop-down menu to navigate to 'Create Continued Pretraining Job.' You will need to provide the source model, name, model encryption, input data, hyper-parameters, and output data. Additionally, you can provide tags and details about AWS Identity and Access Management (IAM) roles and resource policies for the job.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T16:06:11.530609"}}
{"question": "What are the benefits of unifying the APIs for continued pretraining and fine-tuning in Amazon Bedrock?", "answer": "The unification of the APIs for continued pretraining and fine-tuning in Amazon Bedrock reduces the learning curve for customers. It allows them to use standard features such as Amazon EventBridge to track long-running jobs, Amazon S3 integration for fetching training data, resource tags, and model encryption, making the overall user experience more efficient and streamlined.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T16:06:11.530945"}}
{"question": "How do the Amazon Titan models differ from standard models in terms of their development and capabilities?", "answer": "Amazon Titan models are exclusive to Amazon Bedrock and incorporate 25 years of Amazon's experience in AI and machine learning innovation. They provide customers with a breadth of high-performing image, multimodal, and text model choices through a fully managed API. Unlike standard models, Amazon Titan models are pretrained on large datasets, making them powerful, general-purpose models that can support a variety of use cases, while also allowing for private customization with the user's own data.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T16:06:11.531342"}}
{"question": "What feature does Amazon Bedrock Knowledge Bases provide to manage context during interactions?", "answer": "Amazon Bedrock Knowledge Bases includes built-in session context management, which allows applications to maintain context across multiple interactions, making it essential for supporting multi-turn conversations.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-04T16:06:15.784930"}}
{"question": "How does Amazon Bedrock Knowledge Bases enhance transparency in the information it retrieves?", "answer": "Amazon Bedrock Knowledge Bases enhances transparency by including citations for all information retrieved, which minimizes the risk of hallucinations in the generated responses.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-04T16:06:15.785286"}}
{"question": "What are the differences between the built-in default Bedrock parser and Amazon Bedrock Data Automation (BDA) for processing data?", "answer": "The built-in default Bedrock parser is available at no additional cost and is ideal for text-only processing where multimodal data is not required. In contrast, Amazon Bedrock Data Automation (BDA) or foundation models can be used to parse multimodal data, which includes text as well as visual elements like images and charts.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-04T16:06:15.785877"}}
{"question": "What are the predefined metrics available for automatic evaluation in Amazon Bedrock?", "answer": "The predefined metrics available for automatic evaluation in Amazon Bedrock include accuracy, robustness, and toxicity.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-04T16:06:19.519196"}}
{"question": "How does human evaluation differ from automatic evaluation in the context of Amazon Bedrock?", "answer": "Human evaluation differs from automatic evaluation in that it focuses on subjective or custom metrics, such as friendliness and brand voice, which require human judgment. In contrast, automatic evaluation uses predefined metrics like accuracy, robustness, and toxicity to quickly assess models.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-04T16:06:19.519480"}}
{"question": "What are the advantages of using automatic evaluations compared to human evaluations in Amazon Bedrock?", "answer": "The advantages of using automatic evaluations in Amazon Bedrock include the ability to quickly narrow down the list of available FMs against standard criteria such as accuracy, toxicity, and robustness. In comparison, human evaluations are better suited for assessing more nuanced or subjective criteria that cannot be easily measured by automatic evaluations.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-04T16:06:19.519941"}}
{"question": "What features does Amazon Bedrock provide for human review workflows?", "answer": "Amazon Bedrock allows you to set up human review workflows, where in-house employees or an expert team managed by AWS can evaluate models. Users can review and give feedback on model responses by clicking thumbs up or down, rating on a scale of 1-5, choosing the best of multiple responses, or ranking prompts. Additionally, you can customize the evaluation interface by specifying evaluation criteria, customizing instructions, and providing detailed guidance with examples.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T16:06:25.221025"}}
{"question": "How can Amazon Bedrock's evaluation workflows benefit the model evaluation process?", "answer": "The evaluation workflows in Amazon Bedrock are beneficial because they allow for the assessment of subjective criteria that require human judgment or nuanced subject matter expertise. This is particularly useful for evaluations that cannot be easily judged by automatic evaluations, enabling more accurate and relevant feedback on model outputs.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T16:06:25.221572"}}
{"question": "What is the difference between Amazon Bedrock's human review workflows and Amazon Bedrock Guardrails?", "answer": "Amazon Bedrock's human review workflows focus on facilitating human evaluation of model responses through various feedback mechanisms, allowing for subjective assessments based on custom criteria. In contrast, Amazon Bedrock Guardrails implement safeguards for generative AI applications, helping to standardize safety and privacy controls across multiple foundation models for different use cases. While the former is about model evaluation, the latter is about ensuring responsible AI practices.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T16:06:25.221839"}}
{"question": "What are the six types of policies that can be configured in Amazon Bedrock Guardrails?", "answer": "The six types of policies that can be configured in Amazon Bedrock Guardrails are: Multi modal content filters, Denied topics, Word filters, Sensitive information filters, Contextual grounding checks, and Automated Reasoning checks.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-04T16:06:30.374613"}}
{"question": "How do sensitive information filters in Amazon Bedrock Guardrails work?", "answer": "Sensitive information filters in Amazon Bedrock Guardrails help block or mask sensitive information, such as personally identifiable information (PII), by probabilistically detecting sensitive information in standard formats like SSN numbers, Date of Birth, and addresses. They also allow for regular expression-based detection of patterns for identifiers.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-04T16:06:30.375004"}}
{"question": "How do the Multi modal content filters and Word filters differ in Amazon Bedrock Guardrails?", "answer": "The Multi modal content filters focus on detecting and filtering harmful text and/or image content across various categories such as hate, insults, and violence, while the Word filters specifically block undesirable words, phrases, and profanity based on exact matches, which can include offensive terms and competitor names.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-04T16:06:30.375418"}}
{"question": "What languages are supported by the Standard Tier of Bedrock Guardrails?", "answer": "The Standard Tier of Bedrock Guardrails supports up to 60 languages, with varying support depending on the policy.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-04T16:06:34.807937"}}
{"question": "What is the primary advantage of using the Standard Tier over the Classic Tier in Bedrock Guardrails?", "answer": "The primary advantage of using the Standard Tier over the Classic Tier in Bedrock Guardrails is the robust performance and comprehensive language support for up to 60 languages, whereas the Classic Tier only supports English, French, and Spanish.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-04T16:06:34.808318"}}
{"question": "What are the six guardrail policies provided by Bedrock Guardrails?", "answer": "The six guardrail policies provided by Bedrock Guardrails are Content filters, Denied topic, Sensitive information filter, Word filters, Contextual grounding checks, and Automated Reasoning checks.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-04T16:06:34.808685"}}
{"question": "What type of protection does AWS provide for customers using its generative AI services regarding copyright claims?", "answer": "AWS offers an uncapped intellectual property (IP) indemnity for copyright claims arising from the generative output of its generally available Amazon generative AI services, which means customers are protected from third-party claims alleging copyright infringement by the output generated by these services.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:06:40.245725"}}
{"question": "How do Automated Reasoning checks differ from Contextual Grounding checks in terms of upfront requirements?", "answer": "Automated Reasoning checks require upfront involvement from a domain expert to create a Policy and only support content that defines rules. In contrast, Contextual Grounding checks use machine learning techniques and do not require any additional upfront work to ensure the generated content closely follows the documents provided as input.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:06:40.246053"}}
{"question": "What are the main functionalities of Amazon Bedrock Guardrails compared to the Automated Reasoning checks?", "answer": "Amazon Bedrock Guardrails provide Sensitive Information filters, help monitor production traffic with detailed logs of input and output violations, and allow for the creation of custom dashboards. In contrast, Automated Reasoning checks focus on identifying accurate claims and factual inaccuracies in content, providing logical explanations for both types of output. While Guardrails emphasize monitoring and filtering, Automated Reasoning focuses on validating content accuracy.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:06:40.246564"}}
{"question": "What image formats are supported with Bedrock Guardrails?", "answer": "PNG and JPEG image formats are supported with Bedrock Guardrails.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:06:44.029227"}}
{"question": "How does Automated Reasoning enhance the validation of statements in Amazon Bedrock?", "answer": "Automated Reasoning uses formal verification techniques alongside LLMs to identify up to 99% of the valid statements. It provides feedback on content that points out ambiguity and suggests corrections for wrong or incomplete answers, making it easier to rewrite answers until they are judged valid.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:06:44.029477"}}
{"question": "What is the relationship between Amazon Bedrock Marketplace and the deployment of models?", "answer": "Amazon Bedrock Marketplace offers customers access to over 100 popular, emerging, or specialized models, which can be deployed onto fully managed endpoints. Customers can choose the desired number of instances and instance types for their models, and once deployed, these models can be accessed through Amazon Bedrocks Invoke API.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:06:44.029726"}}
{"question": "How can I subscribe to an Amazon Bedrock Marketplace model?", "answer": "You can subscribe to an Amazon Bedrock Marketplace model by navigating to the Model Detail page, selecting the model you want to use, and accepting the EULA and price(s) set by the provider.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-04T16:06:49.109480"}}
{"question": "What is the process to deploy a model in Amazon Bedrock after subscription?", "answer": "After subscribing to a model, you can deploy it to a fully managed SageMaker endpoint by clicking on 'Deploy' in the Model Detail page or by using APIs. During deployment, you can select your desired number of instances and instance types to meet your workload. The endpoint setup typically takes 10  15 minutes, after which you can start making inference calls to the endpoint.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-04T16:06:49.109813"}}
{"question": "What is the difference between models supported by Custom Model Import and those that are not?", "answer": "Models with architectures supported by Custom Model Import, such as Mistral, Mixtral, Flan, and Llama2/3/3.1/3.2, can be fine-tuned in SageMaker and made available in Amazon Bedrock via Custom Model Import. In contrast, models that are not supported by Custom Model Import can still be fine-tuned in SageMaker, but the fine-tuned versions cannot be used in Amazon Bedrock.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-04T16:06:49.110699"}}
{"question": "What are the main capabilities of Amazon Bedrock Data Automation?", "answer": "Amazon Bedrock Data Automation is a GenAI-powered capability that streamlines the development of generative AI applications and automates workflows involving documents, images, audio, and videos. It reduces development time and effort, provides industry-leading accuracy at lower costs, and includes features like visual grounding with confidence scores for explainability and built-in hallucination mitigation.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-04T16:06:53.993683"}}
{"question": "How does Bedrock Data Automation improve the development process for generative AI applications?", "answer": "Bedrock Data Automation improves the development process by allowing developers to easily customize output to generate specific insights in consistent formats, thus eliminating the need to manage multiple models, engineering prompts, or implementing safety guardrails. This results in the efficient transformation of unstructured enterprise data into application-specific formats for GenAI applications and ETL workflows.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-04T16:06:53.994018"}}
{"question": "In what ways does Bedrock Data Automation differ from traditional methods of managing unstructured data?", "answer": "Bedrock Data Automation differs from traditional methods by providing a fully managed API that eliminates the need for customers to scale compute resources, select and orchestrate models, or manage prompts for foundation models (FMs). This contrasts with traditional methods that often require manual processes and management of multiple components, leading to increased time and effort.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-04T16:06:53.994604"}}
{"question": "What is a blueprint in the context of AWS?", "answer": "A blueprint is a feature that customers use to specify their output requirements using natural language or a schema editor. It includes a list of fields that they desire to extract, a data format for each field, and natural language instructions for each field.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-04T16:06:57.872438"}}
{"question": "How do developers utilize blueprints when working with the inference API?", "answer": "Developers reference blueprints as part of the inference API calls so that the system returns information in the format described in the blueprint.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-04T16:06:57.872784"}}
{"question": "What elements are included in a blueprint, and how do they contribute to the output requirements?", "answer": "A blueprint includes a list of fields that customers want to extract, a data format for each field, and natural language instructions for each field. These elements collectively help specify the output requirements and ensure that the output aligns with the customer's needs.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-04T16:06:57.873157"}}
{"question": "What types of output does Bedrock Data Automation support for documents?", "answer": "Bedrock Data Automation supports both standard output and custom output for documents. Standard output includes extraction of text, generative output like document summaries and captions for tables/figures/diagrams, and can be grouped by layout elements. Custom output uses blueprints to specify output requirements.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-04T16:07:03.115038"}}
{"question": "How does custom output differ from standard output in Bedrock Data Automation?", "answer": "Custom output in Bedrock Data Automation leverages blueprints, which allow users to specify output requirements using natural language or a schema editor. This includes defining a list of fields to extract and the data format for each field. In contrast, standard output provides predefined types of information without the need for custom specifications.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-04T16:07:03.115359"}}
{"question": "How does the maximum file size and concurrency for images compare to those for documents in Bedrock Data Automation?", "answer": "For documents, Bedrock Data Automation supports a maximum file size of 500MB and allows 50 concurrent jobs with 10 transactions per second per customer. In comparison, for images, the maximum file size is 5MB, and it supports a maximum concurrency of 20 images with the same rate of 10 transactions per second per customer.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-04T16:07:03.115572"}}
{"question": "What are the maximum video duration and file size supported by Bedrock Data Automation?", "answer": "Bedrock Data Automation supports a maximum video duration of 4 hours and a maximum file size of 2 GB per API request.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-04T16:07:09.026039"}}
{"question": "What features does the standard output for audio provide in Bedrock Data Automation?", "answer": "The standard output for audio in Bedrock Data Automation provides summarization including chapter summarization, full transcription, and detection of explicit content moderation for audio files.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-04T16:07:09.026385"}}
{"question": "How does the maximum concurrency for video processing in Bedrock Data Automation compare to its audio processing capabilities?", "answer": "The maximum concurrency for video processing in Bedrock Data Automation is 20 videos at 10 transactions per second (TPS) per customer. The context does not provide specific information about the maximum concurrency for audio processing, so a direct comparison cannot be made.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-04T16:07:09.026577"}}
{"question": "In which AWS Regions is Amazon Bedrock Data Automation generally available?", "answer": "Amazon Bedrock Data Automation is generally available in the US West (Oregon) and US East (N. Virginia) AWS Regions.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-04T16:07:14.008936"}}
{"question": "What are the primary ways users can access Amazon Bedrock's capabilities?", "answer": "Users can access Amazon Bedrock through the AWS Management Console, APIs, or Amazon SageMaker Unified Studio.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-04T16:07:14.010031"}}
{"question": "How does the access method for Amazon Bedrock differ when using Amazon SageMaker Unified Studio compared to using the AWS Management Console?", "answer": "When using Amazon SageMaker Unified Studio, users can experiment with models, collaborate on projects, and access various Bedrock tools and resources through an intuitive interface. In contrast, accessing Amazon Bedrock through the AWS Management Console does not provide this collaborative and iterative environment.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-04T16:07:14.010244"}}
{"question": "What are the new features introduced in Amazon Bedrock when accessed through Amazon SageMaker Unified Studio?", "answer": "The new features introduced in Amazon Bedrock when accessed through Amazon SageMaker Unified Studio include a model hub for side-by-side AI model comparison, an expanded playground supporting chat, image, and video interactions, improved Knowledge Base creation with web crawling, Agent creation for more complex chat applications, simplified sharing of AI apps and prompts within organizations, access to underlying application code, and the ability to export chat apps as CloudFormation templates.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-04T16:07:20.448100"}}
{"question": "How does Amazon SageMaker Unified Studio enhance the capabilities of Amazon Bedrock compared to the original Amazon Bedrock Studio?", "answer": "Amazon SageMaker Unified Studio enhances the capabilities of Amazon Bedrock compared to the original Amazon Bedrock Studio by providing access to advanced AI models from leading companies, tools for creating and testing AI prompts, and seamless integration with various Amazon Bedrock features such as Knowledge Bases, Guardrails, Flows, and Agents. It also supports collaboration in a governed environment, allowing teams to create projects, invite colleagues, and receive quick feedback, which fosters more efficient development of custom AI applications.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-04T16:07:20.448632"}}
{"question": "What access controls and governance features are available in Amazon SageMaker Unified Studio for sharing generative AI applications?", "answer": "In Amazon SageMaker Unified Studio, robust access controls and governance features are available for sharing generative AI applications. These features allow only authorized members to access project resources such as data or the generative AI applications, thereby supporting data privacy and compliance. Applications can be shared from a builder to specific users in the SageMaker Unified Studio domain or with specific individuals, ensuring proper access rights, controls, and governance of such assets.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-04T16:07:20.448903"}}
{"question": "What are the different ways to access Amazon Bedrock?", "answer": "Amazon Bedrock can be accessed through the AWS Management Console, APIs, or Amazon SageMaker Unified Studio.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-04T16:07:26.150816"}}
{"question": "How does Amazon SageMaker Unified Studio enhance the generative AI development process?", "answer": "Amazon SageMaker Unified Studio enhances the generative AI development process by providing a unified development experience where teams can access familiar JupyterLab environments and analytics tools, seamlessly incorporating Amazon Bedrock's generative AI capabilities within the same workspace. This setup allows for seamless collaboration among developers of various skill levels and integrates tools for knowledge base creation, guardrail configuration, and generative AI application development within a secure framework.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-04T16:07:26.151128"}}
{"question": "What is the difference between the Generative AI Playground and the Generative AI App Development in Amazon SageMaker Unified Studio?", "answer": "The Generative AI Playground, found in the Discover section, enables teams to experiment with foundation models, test different models and configurations, compare model outputs, and collaborate on prompts and applications. In contrast, the Generative AI App Development in the Build section provides teams with tools to create production-ready generative AI applications, manage Knowledge Bases, implement Guardrails for responsible AI, and develop Agents and Flows while ensuring secure collaboration and compliance controls.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-04T16:07:26.151295"}}
{"question": "What capabilities does Amazon Bedrock offer within Amazon SageMaker Unified Studio?", "answer": "Amazon Bedrock's capabilities within Amazon SageMaker Unified Studio include a governed collaborative environment that empowers developers to rapidly create and customize generative AI applications. It provides seamless access to high-performance foundation models (FMs) and advanced customization tools for the collaborative development of tailored generative AI applications.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-04T16:07:31.549958"}}
{"question": "How does Amazon Bedrock integrate with other features of Amazon SageMaker Unified Studio?", "answer": "Amazon Bedrock seamlessly integrates with Amazon SageMaker's analytics, machine learning (ML), and generative AI capabilities within SageMaker Unified Studio. This integration allows organizations to prototype and experiment with foundation models in Amazon Bedrock and then transition easily to JupyterLab notebooks or code editors to incorporate these resources into broader applications and workflows.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-04T16:07:31.550327"}}
{"question": "What is the difference in cost between accessing Amazon Bedrock through SageMaker Unified Studio and the underlying resources used in generative AI applications?", "answer": "Access to Amazon Bedrock through SageMaker Unified Studio comes at no extra cost, meaning that users do not incur additional charges just for access. However, they will pay for the usage of the underlying resources required by their generative AI applications, such as the associated model, Guardrail, and Knowledge Base that they have utilized.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-04T16:07:31.550547"}}
{"question": "What approach does AWS use for pricing their cloud services?", "answer": "AWS offers a pay-as-you-go approach for pricing for the vast majority of their cloud services. This means you pay only for the individual services you need, for as long as you use them, without requiring long-term contracts or complex licensing.", "question_type": "factual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T16:07:37.151938"}}
{"question": "How does AWS Billing and Cost Management help users understand their charges?", "answer": "AWS Billing and Cost Management measures usage of AWS services and calculates charges. It provides an invoice at the end of each month or after a one-time purchase, and the AWS Bills page offers detailed insights on how charges were calculated, organized by service, AWS Region, or member account. Users can view pricing and usage details, and download invoices for various purposes.", "question_type": "conceptual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T16:07:37.152197"}}
{"question": "What is the difference between the 'cash' view provided by the Bills page and the view from Cost Explorer?", "answer": "The 'cash' view provided by the Bills page reflects the actual amount that you pay to AWS each month, inclusive of discounts, credits, refunds, and taxes. In contrast, Cost Explorer provides an amortized view of costs, where upfront charges like Savings Plans are spread over the term of the commitment, either one year or three years.", "question_type": "comparison", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T16:07:37.152453"}}
{"question": "How can I enable CSV download of my monthly charges?", "answer": "To enable CSV download of your monthly charges, navigate to the Billing Preferences page in the Billing console. In the Detailed Billing Reports section, check the box to turn on the detailed billing reports. Then, click Configure to choose an existing S3 bucket to have these reports delivered to, or create a new S3 bucket. Finally, click Save Preferences.", "question_type": "factual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-04T16:07:41.792129"}}
{"question": "What steps should I follow to receive detailed billing reports via S3?", "answer": "To receive detailed billing reports via S3, you need to navigate to the Billing Preferences page in the Billing console, check the box to enable detailed billing reports in the Detailed Billing Reports section, click Configure to select or create an S3 bucket for report delivery, and then click Save Preferences.", "question_type": "conceptual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-04T16:07:41.792503"}}
{"question": "What is the difference between enabling detailed billing reports and receiving a PDF version of the invoice?", "answer": "Enabling detailed billing reports allows you to download CSV files of your monthly charges, which can be configured to be delivered to an S3 bucket. In contrast, receiving a PDF version of your invoice requires enabling a separate option on the Billing Preferences page. These are two distinct functionalities serving different purposes.", "question_type": "comparison", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-04T16:07:41.792925"}}
{"question": "What is the primary function of AWS Certificate Manager (ACM)?", "answer": "The primary function of AWS Certificate Manager (ACM) is to let you easily provision, manage, and deploy public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates. These certificates are used to secure network communications and establish the identity of websites over the Internet as well as resources on private networks.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T16:07:47.419367"}}
{"question": "How does AWS Certificate Manager simplify the management of SSL/TLS certificates?", "answer": "AWS Certificate Manager simplifies the management of SSL/TLS certificates by removing the time-consuming manual process of purchasing, uploading, and renewing these certificates. It allows users to quickly request a certificate, deploy it on AWS resources, and lets ACM handle certificate renewals automatically.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T16:07:47.419650"}}
{"question": "What are the differences in cost for using public and private SSL/TLS certificates with AWS Certificate Manager?", "answer": "Public and private SSL/TLS certificates provisioned through AWS Certificate Manager and used exclusively with ACM-integrated services, such as Elastic Load Balancing, Amazon CloudFront, and Amazon API Gateway, are free. However, if you choose to issue exportable public certificates, you will incur costs for certificate issuance, certificate renewal, and related API usage. Additionally, there is a monthly fee for the operation of each private Certificate Authority (CA) until it is deleted, and for private certificates that are issued and not used exclusively with ACM-integrated services.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T16:07:47.420031"}}
{"question": "What is the role of SSL/TLS certificates in web browsers?", "answer": "SSL/TLS certificates allow web browsers to identify and establish encrypted network connections to web sites using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:07:52.390159"}}
{"question": "How do private certificates differ from public certificates in terms of trust configuration?", "answer": "Public certificates are trusted automatically by applications and browsers by default, while private certificates require an administrator to explicitly configure applications to trust them.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:07:52.390426"}}
{"question": "What are the main differences between public and private certificate authorities (CAs)?", "answer": "Public CAs, which issue public certificates, must follow strict rules, provide operational visibility, and meet security standards imposed by browser and operating system vendors. In contrast, private CAs are managed by private organizations, allowing their administrators to establish their own rules for issuing private certificates, including practices for issuing certificates and the information contained within a certificate.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:07:52.390585"}}
{"question": "What does ACM do to simplify the management of SSL/TLS certificates?", "answer": "ACM simplifies the management of SSL/TLS certificates by eliminating many of the manual processes previously associated with using and managing these certificates. It also helps avoid downtime caused by misconfigured, revoked, or expired certificates by managing renewals.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-04T16:08:00.428475"}}
{"question": "Why is enabling SSL/TLS for Internet-facing sites important?", "answer": "Enabling SSL/TLS for Internet-facing sites is important because it can help improve the search rankings for your site and assist in meeting regulatory compliance requirements for encrypting data in transit.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-04T16:08:00.428809"}}
{"question": "How does ACM ensure the security of certificate private keys compared to traditional management methods?", "answer": "ACM ensures the security of certificate private keys by securely protecting and storing them using strong encryption and key management best practices, which may not be as consistently applied in traditional management methods.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-04T16:08:00.429307"}}
{"question": "What services can ACM manage public certificates for?", "answer": "ACM can manage public certificates for ACM-integrated services including Amazon CloudFront, Elastic Load Balancing, and Amazon API Gateway.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-04T16:08:04.302797"}}
{"question": "How does ACM handle the renewal of private certificates?", "answer": "When private certificate management is delegated to ACM, it can automatically renew and deploy private certificates used with ACM-integrated services. Additionally, AWS Private CA automatically renews these certificates and sends an Amazon CloudWatch notification when the renewal is completed.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-04T16:08:04.303145"}}
{"question": "What is the difference in renewal capabilities between imported certificates and public certificates managed by ACM?", "answer": "ACM can manage the renewal of public certificates automatically, while it cannot renew imported certificates. For imported certificates, users are responsible for monitoring their expiration dates and renewing them before they expire.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-04T16:08:04.303662"}}
{"question": "How can I request an SSL/TLS certificate using ACM?", "answer": "To request an SSL/TLS certificate using ACM, navigate to Certificate Manager in the AWS Management Console and use the wizard to request a certificate. You can also request a certificate using the AWS CLI or API.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-04T16:08:08.890492"}}
{"question": "What are the options available when requesting a certificate if I have already created a Private CA?", "answer": "If you have already created a Private CA, you can choose whether you want a public or private certificate, and then enter the name of your site when requesting a certificate.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-04T16:08:08.890799"}}
{"question": "What is the relationship between ACM certificates and Amazon CloudFront?", "answer": "To use an ACM certificate with Amazon CloudFront, you must request or import the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are then distributed to all the geographic locations configured for that distribution.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-04T16:08:08.891196"}}
{"question": "What is the maximum validity period for a TLS certificate issued by AWS Certificate Manager (ACM) as of March 15, 2026?", "answer": "As of March 15, 2026, the maximum lifetime for a TLS certificate issued by AWS Certificate Manager (ACM) will be 200 days.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:08:14.038136"}}
{"question": "Why does AWS Certificate Manager (ACM) enforce shorter validity lifetimes for public certificates?", "answer": "AWS Certificate Manager (ACM) enforces shorter validity lifetimes for public certificates to align with the Certificate Authority/Browser Forum (CA/Browser Forum) requirements for TLS certificates.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:08:14.038493"}}
{"question": "How does a wildcard domain name differ from a regular domain name in terms of subdomain matching?", "answer": "A wildcard domain name matches any first-level subdomain or hostname in a domain, while a regular domain name does not have this capability. For example, a wildcard name like *.example.com can protect multiple first-level subdomains such as www.example.com and images.example.com, whereas a regular domain name would only represent itself specifically.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:08:14.039046"}}
{"question": "What is the default key size and algorithm used for certificates issued in AWS ACM?", "answer": "By default, certificates issued in ACM use RSA keys with a 2048-bit modulus and SHA-256.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:08:19.740351"}}
{"question": "How does AWS ACM plan to address potential cost increases for certificates as industry standards change?", "answer": "AWS is committed to maintaining fair pricing for certificates issued through ACM. As industry standards evolve, they plan to adjust their pricing structure accordingly, aiming to keep the annual cost for certificates in line with current rates and will provide further details before any changes go into effect.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:08:19.740714"}}
{"question": "In which region must ACM certificates be used, and what is the exception for Amazon CloudFront?", "answer": "ACM certificates must be in the same Region as the resource where they are being used, with the exception of Amazon CloudFront, which requires certificates in the US East (N. Virginia) region. Certificates in this region associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:08:19.741221"}}
{"question": "How can I use a third-party certificate with Amazon CloudFront?", "answer": "You can import a third-party certificate into ACM using the AWS Management Console, AWS CLI, or ACM APIs. However, ACM does not manage the renewal process for imported certificates, so you will need to monitor the expiration dates and import a new certificate to replace an expiring one.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-04T16:08:25.406563"}}
{"question": "What is the significance of Domain Validated (DV) public certificates provided by ACM?", "answer": "ACM provides Domain Validated (DV) public certificates for use with websites and applications that terminate SSL/TLS. These certificates help secure communication and identify resources on networks, thereby facilitating secure connections which are essential for compliance with various regulatory requirements.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-04T16:08:25.406861"}}
{"question": "What types of certificates does ACM provide, and how do they differ in terms of trust by browsers?", "answer": "ACM provides both public and private certificates. Public certificates are trusted by most modern browsers, operating systems, and mobile devices, achieving 99% browser and operating system ubiquity. They are verified by Amazons certificate authority and are recognized by any browser, application, or OS that includes the Amazon Root CA. In contrast, the context does not provide specific details about the trust characteristics of private certificates, only mentioning the public certificates' trust levels.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-04T16:08:25.407229"}}
{"question": "Does ACM have a Service Level Agreement (SLA)?", "answer": "No, ACM does not have an SLA.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-04T16:08:29.811956"}}
{"question": "What are the two methods of validation that ACM offers when requesting a certificate?", "answer": "ACM offers DNS validation and email validation when requesting a certificate. With DNS validation, you write a record to the public DNS configuration for your domain, while with email validation, emails are sent to the domain owner requesting approval to issue the certificate.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-04T16:08:29.812245"}}
{"question": "What is the difference between DNS validation and email validation in the context of ACM certificate issuance?", "answer": "The difference between DNS validation and email validation in the context of ACM certificate issuance is that DNS validation requires you to write a record to your public DNS configuration to establish domain control, and once validated, you do not need to validate again for future certificates as long as the record remains in place. In contrast, email validation sends approval requests via email to the domain owner for each certificate request, requiring action each time.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-04T16:08:29.812696"}}
{"question": "What are the two methods of validation you can choose when requesting a certificate from ACM?", "answer": "You can choose DNS validation or email validation when requesting a certificate from ACM.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-04T16:08:35.618393"}}
{"question": "Why is DNS validation generally recommended over email validation when issuing certificates from ACM?", "answer": "DNS validation is recommended if you have the ability to change the DNS configuration for your domain, as it allows for quicker validation. Additionally, customers who cannot receive validation emails or those using a domain registrar that does not publish domain owner email contact information in WHOIS should also use DNS validation.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-04T16:08:35.618695"}}
{"question": "How does the validation process differ for certificates requested for Amazon CloudFront SaaS Manager compared to regular certificates issued from ACM?", "answer": "For certificates requested for Amazon CloudFront SaaS Manager, ACM automatically issues HTTP validated certificates as part of the CloudFront provisioning process. In contrast, regular certificates require either DNS or email validation depending on the customer's ability to manage DNS records or receive validation emails.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-04T16:08:35.619112"}}
{"question": "What happens to the status of the certificate request after all domain names in the request are validated?", "answer": "After all of the domain names in the certificate request are validated, the status of the certificate request changes to Issued, and you can start using it with other AWS services that are integrated with ACM.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-04T16:08:42.016904"}}
{"question": "How does DNS validation work when requesting a certificate from ACM?", "answer": "With DNS validation, you can validate your ownership of a domain by adding a CNAME record to your DNS configuration. This process makes it easy for you to establish that you own a domain when requesting public SSL/TLS certificates from ACM.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-04T16:08:42.017254"}}
{"question": "What are the differences in requirements for issuing a certificate if a domain has a CAA record compared to if it does not?", "answer": "If a domain has a CAA record, that record must specify one of the following Certificate Authorities: amazon.com, amazontrust.com, awstrust.com, or amazonaws.com, before Amazon can issue a certificate for the domain. In contrast, if a CAA record is not present, Amazon can issue a certificate for the domain without any specific requirements.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-04T16:08:42.017742"}}
{"question": "What must you add to your DNS configuration to validate a domain for an SSL/TLS certificate using DNS validation?", "answer": "You must add a CNAME record for the domain you want to validate. For example, to validate the name www.example.com, you add a CNAME record to the zone for example.com. The record contains a unique token that ACM generates specifically for your domain and your AWS account.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:08:48.180345"}}
{"question": "How does the ACM management console simplify the DNS validation process for customers using Amazon Route 53?", "answer": "The ACM management console can configure DNS records for you if you manage your DNS records with Amazon Route 53, making it easy to establish control of your domain name with just a few mouse clicks.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:08:48.180607"}}
{"question": "What are the main differences between using DNS validation and email validation for obtaining SSL/TLS certificates through ACM?", "answer": "DNS validation requires you to add a CNAME record to your DNS configuration, while email validation is available for customers who cannot change their DNS configuration. DNS validation is considered easier if you can manage DNS records, whereas email validation is an alternative for those who cannot.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:08:48.181017"}}
{"question": "Can I use one CNAME record for multiple certificate requests for the same domain in AWS?", "answer": "Yes, you can obtain multiple certificates for the same domain name in the same AWS account using one CNAME record. For example, if you make 2 certificate requests from the same AWS account for the same domain name, you need only 1 DNS CNAME record.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-04T16:08:55.060609"}}
{"question": "What are the components of a DNS CNAME record as described in the context?", "answer": "DNS CNAME records have two components: a name and a label. The name component is constructed from an underscore character (_) followed by a token, which is a unique string tied to your AWS account and domain name. The label is constructed from an underscore character pre-pended to a different token, also tied to your AWS account and domain name, and is used for validations with the DNS domain name acm-validations.aws.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-04T16:08:55.061115"}}
{"question": "How does ACM generate CNAME records for wildcard names compared to regular domain names?", "answer": "ACM removes the wildcard label (*) when generating CNAME records for wildcard names. As a result, the CNAME record generated by ACM for a wildcard name (such as *.example.com) is the same record returned for the domain name without the wildcard label (example.com). This means that both will have identical CNAME records.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-04T16:08:55.061408"}}
{"question": "How long can ACM renew certificates using a CNAME record?", "answer": "ACM can renew certificates for as long as the CNAME record exists. The CNAME record directs to a TXT record in an AWS domain (acm-validations.aws) that ACM can update as needed to validate or re-validate a domain name, without any action from you.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-04T16:09:00.379567"}}
{"question": "What happens if you remove the CNAME record used for DNS validation?", "answer": "If you remove the CNAME record, ACM does not issue or renew certificates for your domain using DNS validation after the record is removed and the change is distributed through DNS. The propagation time to remove the record depends on your DNS provider.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-04T16:09:00.379918"}}
{"question": "What is the difference between DNS validation and email validation in ACM?", "answer": "With DNS validation, a CNAME record is created that allows ACM to renew certificates automatically. In contrast, with email validation, an approval request email is sent to the registered domain owner for each domain name in the certificate request, who must then approve the certificate request by following the instructions in the email.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-04T16:09:00.380128"}}
{"question": "What five email addresses does ACM send validation messages to for each domain?", "answer": "ACM sends validation email messages to the following five common system emails for each domain: admin@, administrator@, hostmaster@, webmaster@, and postmaster@, which are formed by pre-pending these prefixes to the domain name youre requesting.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-04T16:09:06.019956"}}
{"question": "How does ACM handle validation email addresses for domain names that start with 'www' or wildcard names?", "answer": "For domain names that begin with 'www' or wildcard names starting with an asterisk (*), ACM removes the leading 'www' or asterisk and sends email to the administrative addresses formed by pre-pending admin@, administrator@, hostmaster@, postmaster@, and webmaster@ to the remaining portion of the domain name.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-04T16:09:06.020388"}}
{"question": "Can you configure a different base domain name for validation emails when requesting a certificate, and how does it relate to the domain in the request?", "answer": "Yes, you can configure the base domain name to which you want the validation email to be sent. The base domain name must be a superdomain of the domain name in the certificate request. For example, if you request a certificate for server.domain.example.com, you can direct the approval email to admin@domain.example.com using the AWS CLI or API.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-04T16:09:06.020557"}}
{"question": "Where is the private key of each ACM certificate stored?", "answer": "The private key of each ACM certificate is stored in the Region where you request the certificate. For example, if you obtain a new certificate in the US East (N. Virginia) Region, ACM stores the private key in the N. Virginia Region.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-04T16:09:11.287320"}}
{"question": "How does ACM managed renewal and deployment improve the management of SSL/TLS certificates?", "answer": "ACM managed renewal and deployment improves the management of SSL/TLS certificates by automating the process of renewing certificates and deploying them after renewal. This automation makes configuring and maintaining SSL/TLS for secure web services or applications more operationally sound than manual processes, which can be error-prone. It also helps avoid downtime due to expired certificates.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-04T16:09:11.287701"}}
{"question": "How does ACM handle the distribution of certificates for CloudFront compared to other services?", "answer": "ACM certificates are typically stored in the Region where they are requested, but they are only copied across Regions if the certificate is associated with a CloudFront distribution. In that scenario, CloudFront distributes the ACM certificate to the geographic locations configured for your distribution. This distinguishes the handling of certificates for CloudFront from other services, where the certificates remain in their original Region unless explicitly configured otherwise.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-04T16:09:11.288160"}}
{"question": "What is the validity period for ACM certificates?", "answer": "The validity period for ACM certificates is currently 13 months, which is equivalent to 395 days.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-04T16:09:16.709695"}}
{"question": "How does ACM manage the renewal process for public certificates that require additional validation?", "answer": "For public certificates that cannot be renewed without additional validation, ACM manages the renewal process by validating domain ownership or control for each domain name in the certificate. After validating each domain name, ACM renews the certificate and automatically deploys it with your AWS resources. If ACM cannot validate domain ownership, it will notify the AWS account owner.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-04T16:09:16.710046"}}
{"question": "How does the renewal process for private certificates differ based on their management options?", "answer": "The renewal process for private certificates varies based on how they are managed. For private certificates issued with AWS Private CAs and used with ACM-integrated services, ACM can fully automate renewal and deployment as long as the private CA remains in the Active state. In contrast, for private certificates exported from ACM for use with on-premises resources, EC2 instances, and IoT devices, ACM automatically renews the certificate, but the user is responsible for retrieving the new certificate and private key and deploying them with their application.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-04T16:09:16.710654"}}
{"question": "What happens to a certificate in AWS Certificate Manager (ACM) if DNS validation is chosen for a public certificate request?", "answer": "If you chose DNS validation in your certificate request for a public certificate, then ACM can renew your certificate without any further action from you, as long as the certificate is in use (associated with other AWS resources) and your CNAME record remains in place.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-04T16:09:21.321492"}}
{"question": "How does AWS Certificate Manager (ACM) manage renewals for public certificates that are not reachable from the Internet?", "answer": "ACM can renew public certificates that are not reachable from the Internet using AWS Private CA to issue private certificates without requiring validation.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-04T16:09:21.321868"}}
{"question": "What is the difference in cost between public certificates provisioned through AWS Certificate Manager and private certificates issued by AWS Private CA?", "answer": "Public certificates provisioned through AWS Certificate Manager for use with ACM-integrated services, such as Elastic Load Balancing, Amazon CloudFront, and Amazon API Gateway services are free. In contrast, AWS Private CA has pay as you go pricing, meaning that there are costs associated with issuing private certificates.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-04T16:09:21.322281"}}
{"question": "What chat clients are supported by AWS Chatbot for setting up ChatOps?", "answer": "AWS Chatbot supports Amazon Chime, Microsoft Teams, and Slack for setting up ChatOps.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T16:09:25.060701"}}
{"question": "How does AWS Chatbot enhance team collaboration regarding operational events and alerts?", "answer": "AWS Chatbot enhances team collaboration by allowing teams to receive notifications about operational events, security findings, or budget alerts directly in their chatroom, where they can see and discuss them together.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T16:09:25.061022"}}
{"question": "What types of CLI commands can be executed using AWS Chatbot, and what types are not supported?", "answer": "AWS Chatbot supports both read-only and mutative CLI commands for most AWS services. However, it does not support commands for services and operations related to credentials, authorization, and AWS Identity and Access Management (IAM) permissions, such as IAM, STS, KMS, and EC2.GetPasswordData.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-04T16:09:25.061654"}}
{"question": "What is AWS Chatbot designed for?", "answer": "AWS Chatbot is designed to help teams stay updated on, respond to, and resolve operational events, security findings, and budget alerts for applications running in the AWS environment.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:09:29.001958"}}
{"question": "How does AWS Chatbot facilitate team collaboration during operational events?", "answer": "AWS Chatbot facilitates team collaboration by allowing users to configure it to publish notifications and run commands in a team channel or chatroom. This enables the entire team to see alerts, retrieve diagnostic information, discuss mitigation plans, and resolve alarms directly from the chat channel.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:09:29.002307"}}
{"question": "How does AWS Chatbot compare to Amazon Lex in terms of functionality?", "answer": "AWS Chatbot is focused on monitoring, operating, and troubleshooting AWS resources through alert notifications and command execution, while Amazon Lex provides advanced deep learning capabilities for automatic speech recognition and natural language understanding to build conversational bots. Therefore, AWS Chatbot is more oriented towards team operations and incident resolution, whereas Amazon Lex is centered on creating sophisticated conversational interactions.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:09:29.002795"}}
{"question": "What services can you use to provision Microsoft Teams and Slack channel configurations?", "answer": "You can provision Microsoft Teams and Slack channel configurations using AWS CLI, AWS CloudFormation, AWS Cloud Control APIs, and SDKs.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:09:34.821121"}}
{"question": "How does AWS Chatbot ensure the security and privacy of customer data?", "answer": "AWS Chatbot implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, customer data. They prioritize customer trust, privacy, and data security while ensuring compliance with their commitments.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:09:34.821636"}}
{"question": "In what ways can AWS Chatbot be customized for ChatOps use cases?", "answer": "AWS Chatbot can be customized to suit ChatOps use cases by designating different channels to monitor and operate different aspects of cloud applications, operating resources across multiple accounts and regions from a channel, and using IAM-based permissions, guardrails, and Service Control Policies (SCPs) to determine actions channel members can take. Additionally, users can send custom notifications, customize action buttons on notifications, and configure command aliases for quick command execution.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:09:34.822048"}}
{"question": "What platforms does AWS Chatbot support for integration?", "answer": "AWS Chatbot supports integration with Microsoft Teams, Slack, and Amazon Chime.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T16:09:38.784648"}}
{"question": "How does AWS Chatbot handle command execution in different platforms?", "answer": "AWS Chatbot currently supports running commands only in Microsoft Teams and Slack, while it integrates with Amazon Chime via webhooks but does not support command execution.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T16:09:38.784852"}}
{"question": "What is the difference between installing AWS Chatbot for Microsoft Teams and Slack?", "answer": "The installation of AWS Chatbot for Microsoft Teams is done using a click-through flow in a browser or AWS CloudFormation templates, while the installation for Slack is performed through a click-through OAuth 2.0 flow in a browser. Both installations are designed to be quick, but the methods of installation differ.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T16:09:38.784972"}}
{"question": "What types of events does AWS Chatbot support for notifications?", "answer": "AWS Chatbot supports notifications for Amazon EventBridge events and custom application events to chat channels.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-04T16:09:43.400701"}}
{"question": "How can you customize notifications for application events in AWS Chatbot?", "answer": "You can customize notifications for application events in AWS Chatbot by sending the event in a Chatbot custom notification schema format to an SNS topic. This allows you to define and add additional information in the notifications to monitor the health and performance of your AWS applications.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-04T16:09:43.401259"}}
{"question": "Can you use SNS topics from multiple AWS accounts in a single AWS Chatbot configuration?", "answer": "No, you can only use SNS topics from the AWS account that hosts the AWS Chatbot configuration. However, you can create Chatbot configurations in other AWS accounts and map those configurations to a single chatroom, but each configuration will be independent.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-04T16:09:43.401432"}}
{"question": "What types of notifications does AWS Chatbot support?", "answer": "AWS Chatbot supports notifications for most AWS service events that are handled by Amazon EventBridge.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-04T16:09:47.946213"}}
{"question": "How can you unsubscribe from certain notifications in AWS Chatbot?", "answer": "To unsubscribe from certain notifications in AWS Chatbot, you can remove specific Amazon SNS topics from the AWS Chatbot configuration for the channel or chatroom.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-04T16:09:47.946669"}}
{"question": "What is the difference in command execution between AWS Chatbot and the AWS CLI in terms of limitations?", "answer": "While AWS Chatbot supports commands for most AWS services and allows both read-only and mutative CLI commands, it has limitations compared to the AWS CLI, particularly regarding certain services and commands, such as IAM and AWS Key Management Service (KMS), which are disabled to prevent exposing credentials in chat channels.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-04T16:09:47.946978"}}
{"question": "What are message actions in AWS Chatbot?", "answer": "Message actions are shortcuts that allow users to take quick actions by clicking a button on notifications and messages sent by AWS Chatbot. For example, CloudWatch Alarm notifications for Lambda functions and API Gateway stages feature buttons like 'Show Logs' and 'Show Error Logs' that display the logs for the affected resource in the chat channel.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:09:53.189640"}}
{"question": "How do AWS Organizations help manage permissions for AWS Chatbot?", "answer": "AWS Organizations allows customers to use chatbot policies and multi-account management services to determine which permissions models, chat applications, and chat workspaces can access their accounts. For instance, customers can restrict access to production accounts from chat channels in designated workspaces/teams, and they can use Service Control Policies (SCPs) to specify guardrails on CLI command tasks executed from chat channels.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:09:53.189962"}}
{"question": "What is the difference between a shared channel IAM role and an individual user IAM role in AWS Chatbot?", "answer": "In AWS Chatbot, a shared channel IAM role allows all channel members to use the same IAM role to run commands, while an individual user IAM role requires channel members to choose a specific IAM role to run commands. This distinction affects how permissions are managed and utilized within the chat channel.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:09:53.190465"}}
{"question": "What is the AWS Cloud Development Kit (AWS CDK)?", "answer": "The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure as code with modern programming languages and deploying it through AWS CloudFormation.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:09:57.659492"}}
{"question": "How does the AWS CDK Command Line Interface (CLI) assist users?", "answer": "The AWS CDK Command Line Interface (CLI) allows users to interact with their CDK applications by listing the stacks defined in their CDK app, synthesizing the stacks into CloudFormation templates, determining the differences between running stack instances and the stacks defined in the CDK code, and deploying stacks to any public AWS Region.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:09:57.660771"}}
{"question": "What programming language is the business logic of AWS Construct Library packages built in, and how does this affect the behavior of constructs across different languages?", "answer": "The business logic of AWS Construct Library packages is built in TypeScript, and this ensures that AWS CDK constructs behavior is consistent across all supported programming languages, allowing for a comprehensive set of construct packages available in all languages.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-04T16:09:57.661214"}}
{"question": "Where can I find the AWS CDK code repository?", "answer": "The AWS CDK code is open-source and available through GitHub at https://github.com/awslabs/aws-cdk.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-04T16:10:01.501898"}}
{"question": "What is the purpose of AWS Solutions Constructs in relation to AWS CDK?", "answer": "AWS Solutions Constructs is an open-source library extension of AWS CDK that provides a collection of vetted, multi-service architecture patterns built using the best practices established by the AWS Well-Architected Framework.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-04T16:10:01.502251"}}
{"question": "How does the availability of AWS CDK in public regions relate to CloudFormation?", "answer": "AWS CDK is available to define and deploy AWS resources in all public regions, and since it leverages the CloudFormation service, it is subject to the same limits imposed by CloudFormation.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-04T16:10:01.502658"}}
{"question": "What does the AWS Construct Library provide in relation to AWS services and features?", "answer": "The AWS Construct Library provides coverage for many common AWS services and features with rich, high-level constructs, as well as complete coverage of the lower-level CloudFormation resources. The library is kept up to date by autogenerating resource-level APIs every time the CloudFormation specification changes.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-04T16:10:06.964527"}}
{"question": "How does the AWS CDK enhance the experience of defining AWS infrastructure compared to using CloudFormation directly?", "answer": "The AWS CDK enhances the experience of defining AWS infrastructure by providing a developer-centric toolkit that leverages modern programming languages. It allows developers to define infrastructure as code and compiles applications down to fully formed CloudFormation JSON/YAML templates, which are then submitted to the CloudFormation service for provisioning. This process incorporates the benefits of CloudFormation, such as safe deployment, automatic rollback, and drift detection.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-04T16:10:06.964911"}}
{"question": "How do AWS CDK construct libraries compare to traditional libraries in terms of versioning and updates?", "answer": "AWS CDK construct libraries are similar to traditional libraries in that they are consumed through the package manager of the programming language used, and keeping them up to date is part of the normal workflow. All packages support semantic versioning, which allows developers to make conscious choices about when to migrate to new infrastructure models, just like with traditional libraries.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-04T16:10:06.965135"}}
{"question": "What is the primary focus of AWS Serverless Application Model (SAM)?", "answer": "The primary focus of AWS Serverless Application Model (SAM) is on serverless use cases and architectures, allowing users to define their infrastructure in compact, declarative JSON/YAML templates.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-04T16:10:11.028977"}}
{"question": "How does AWS CDK differ from AWS SAM in terms of programming language support?", "answer": "AWS CDK allows you to define cloud infrastructure in modern programming languages like TypeScript, Python, C#, and Java, while AWS SAM specifically uses compact, declarative JSON/YAML templates and is focused on serverless applications.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-04T16:10:11.029358"}}
{"question": "What are the similarities between AWS SAM and AWS CDK regarding infrastructure deployment?", "answer": "Both AWS SAM and AWS CDK leverage CloudFormation as the provisioning engine for your infrastructure stacks, ensuring repeatable and safe infrastructure deployment.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-04T16:10:11.046557"}}
{"question": "What is AWS CloudFormation?", "answer": "AWS CloudFormation is a service that allows developers and businesses to create a collection of related AWS and third-party resources, and provision and manage them in an orderly and predictable fashion.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-04T16:10:15.506240"}}
{"question": "How does AWS CloudFormation simplify the deployment and management of resources?", "answer": "AWS CloudFormation simplifies the deployment and management of resources by allowing developers to deploy and update compute, database, and many other resources in a simple, declarative style that abstracts away the complexity of specific resource APIs. It is designed to manage resource lifecycles in a repeatable, predictable, and safe manner.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-04T16:10:15.507375"}}
{"question": "What are some recent enhancements introduced in AWS CloudFormation?", "answer": "Recent enhancements in AWS CloudFormation include multiple ways to create resources, such as using AWS CDK for coding in higher-level languages, importing existing resources, detecting configuration drift, and a new Registry that simplifies the creation of custom types that inherit many core CloudFormation benefits.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-04T16:10:15.507622"}}
{"question": "What is the primary function of AWS Elastic Beanstalk?", "answer": "The primary function of AWS Elastic Beanstalk is to provide an environment where users can easily deploy and run applications in the cloud. It is integrated with developer tools and offers a one-stop experience for managing the application lifecycle.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-04T16:10:27.009228"}}
{"question": "How does AWS CloudFormation relate to AWS Elastic Beanstalk?", "answer": "AWS CloudFormation relates to AWS Elastic Beanstalk by serving as a provisioning mechanism that supports Elastic Beanstalk application environments as one of the AWS resource types. This allows users to create and manage an Elastic Beanstalk-hosted application along with other AWS resources, such as an RDS database, all managed together.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-04T16:10:27.010262"}}
{"question": "In what ways do AWS Elastic Beanstalk and AWS CloudFormation differ in terms of control over application workloads?", "answer": "AWS Elastic Beanstalk provides a more turn-key experience for managing application workloads, ideal for users who want ease of use and integration with developer tools. In contrast, AWS CloudFormation offers additional functionality for users who require more custom control over their workloads, allowing for detailed management of resources through templates and stacks.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-04T16:10:27.010452"}}
{"question": "What types of elements can be found in CloudFormation templates?", "answer": "CloudFormation templates are comprised of five types of elements: an optional list of template parameters, an optional list of output values, an optional list of data tables for static configuration values, the list of AWS resources and their configuration values, and a template file format version number.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-04T16:10:33.250019"}}
{"question": "Why is it recommended to allow CloudFormation to manage changes to your resources?", "answer": "It is recommended to allow CloudFormation to manage changes to your resources because it can enforce additional rules, best practices, and compliance controls. This predictable and controlled approach helps in managing hundreds or thousands of resources across your application portfolio.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-04T16:10:33.250266"}}
{"question": "How do template parameters and output values differ in CloudFormation templates?", "answer": "Template parameters are used to customize aspects of your template at run time, such as specifying Amazon RDS database size or EC2 instance types when a stack is created. In contrast, output values are used to present key resources of a stack, like the address of an Elastic Load Balancer or Amazon RDS database, to the user after the stack is created.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-04T16:10:33.250419"}}
{"question": "What feature does AWS CloudFormation provide to avoid name collisions between AWS resources?", "answer": "AWS CloudFormation allows you to assign logical names to AWS resources in a template. When a stack is created, CloudFormation binds the logical name to the name of the corresponding actual AWS resource. This ensures that actual resource names are a combination of the stack and logical resource name, allowing multiple stacks to be created from a template without fear of name collisions.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-04T16:10:39.881282"}}
{"question": "Why does AWS CloudFormation restrict naming resources in a template?", "answer": "CloudFormation restricts naming resources because naming them can limit the reusability of templates and may lead to naming conflicts when an update causes a resource to be replaced. To minimize these issues, CloudFormation supports resource naming on a case-by-case basis.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-04T16:10:39.881724"}}
{"question": "How does AWS CloudFormation compare to other tools like Chef and Puppet in terms of bootstrapping applications on EC2 instances?", "answer": "AWS CloudFormation can be used to bootstrap both the Chef Server and Chef Client software as well as the Puppet Master and Puppet Client software on EC2 instances. It supports the integration with both Chef and Puppet for application bootstrapping, similarly to how it can bootstrap other application environments like Terraform. This shows that CloudFormation provides versatile support for various configuration management tools for software installation on EC2 instances.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-04T16:10:39.882047"}}
{"question": "What feature does CloudFormation provide to ensure that all resources in a stack are created or updated only if all individual operations succeed?", "answer": "The feature is called 'automatic rollback on error', which is enabled by default. This feature ensures that if any operation fails, CloudFormation reverts the stack to the last known stable configuration, allowing for reliable stack creation and updates.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-04T16:10:47.915002"}}
{"question": "How does the WaitCondition resource in CloudFormation function?", "answer": "The WaitCondition resource acts as a barrier that blocks the creation of other resources until a completion signal is received from an external source, such as an application or management system. This allows for synchronization of resource creation with external processes.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-04T16:10:47.915366"}}
{"question": "What are some resources that CloudFormation can create within a VPC, and how do they relate to each other?", "answer": "CloudFormation can create VPCs, subnets, gateways, route tables, and network ACLs as well as resources such as elastic IPs, Amazon EC2 Instances, EC2 security groups, auto scaling groups, elastic load balancers, Amazon RDS database instances, and Amazon RDS security groups. These resources work together to establish a network infrastructure that supports scalable and secure applications within the AWS environment.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-04T16:10:47.915859"}}
{"question": "What information is required to register for CloudFormation?", "answer": "To register for CloudFormation, you need to have a valid phone number and email address on file with AWS. This is necessary in case AWS needs to contact you during the registration process.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T16:10:52.457100"}}
{"question": "What is the purpose of the Getting Started Guide for CloudFormation?", "answer": "The Getting Started Guide for CloudFormation is designed to help new users quickly learn how to deploy and use CloudFormation. It includes sample templates that illustrate how to create the infrastructure needed to run applications, enabling users to get started within a few minutes.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T16:10:52.457548"}}
{"question": "How do sample templates in CloudFormation help users?", "answer": "Sample templates in CloudFormation help users by illustrating how to interconnect and use multiple AWS resources following best practices. They provide examples of how to achieve redundancy, scale out, and implement alarming, making it easier for users to understand and utilize AWS resources effectively.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T16:10:52.459466"}}
{"question": "What is a resource provider in the context of AWS CloudFormation?", "answer": "A resource provider is a set of resource types with specifications and handlers that control the lifecycle of underlying resources via create, read, update, delete, and list operations. You can use resource providers to model and provision resources using CloudFormation.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:10:58.843260"}}
{"question": "How do AWS resource providers differ from third-party resource providers?", "answer": "The primary difference between AWS and third-party resource providers is their origin. AWS resource providers are built and maintained by Amazon and AWS to manage AWS resources and services, while third-party resource providers are built by another company, organization, or the developer community to help manage both AWS and non-AWS resources.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:10:58.843627"}}
{"question": "Can you provide examples of resource types from AWS resource providers and third-party resource providers?", "answer": "Examples of resource types from AWS resource providers include AWS::DynamoDB::Table, AWS::Lambda::Function, and AWS::EC2::Instance, which help manage Amazon DynamoDB, AWS Lambda, and Amazon EC2 resources respectively. In contrast, third-party resource providers can manage resources such as SaaS software services for monitoring, team productivity, incident management, or version control management tools, but specific examples of these third-party resources are not provided in the context.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:10:58.844092"}}
{"question": "What are the two methods mentioned for using the AWS CloudFormation CLI?", "answer": "The two methods mentioned for using the AWS CloudFormation CLI are using the open source AWS CloudFormation CLI or directly calling the RegisterType and related Registry APIs available via the AWS SDKs and AWS CLI.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-04T16:11:03.748126"}}
{"question": "What is the purpose of the CloudFormation Public Registry?", "answer": "The purpose of the CloudFormation Public Registry is to provide a searchable and managed catalog of extensions that contains resource types and modules published by AWS Partner Network (APN) Partners and the developer community. It allows anyone to publish resource types and modules, enabling customers to easily discover and use these published resources without the need to build and maintain them themselves.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-04T16:11:03.748423"}}
{"question": "How does the CloudFormation Public Registry differ from the initial CloudFormation Registry launched in November 2019?", "answer": "The initial CloudFormation Registry launched in November 2019 consisted of a private listing for customers to extend CloudFormation for their own private use, while the CloudFormation Public Registry extends this by adding a public, searchable, central location for sharing, finding, consuming, and managing resource types and modules, making it easier to configure and manage infrastructure and applications for both AWS and third-party products.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-04T16:11:03.749048"}}
{"question": "What is a Resource Type in AWS CloudFormation?", "answer": "A Resource Type is a code package containing provisioning logic that allows you to manage the lifecycle of a resource, such as an Amazon EC2 Instance or an Amazon DynamoDB Table, from creation to deletion, abstracting away complex API interactions. Resource Types contain a schema that defines the shape and properties of a resource, as well as the necessary logic to provision, update, delete, and describe a resource.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T16:11:09.384769"}}
{"question": "How do Modules differ from Resource Types in AWS CloudFormation?", "answer": "Modules are building blocks that can be reused across multiple CloudFormation templates and are used like a native CloudFormation resource, whereas Resource Types are specific code packages that manage the lifecycle of individual resources. Modules can pertain to a single resource, such as best practices for defining an Amazon EC2 instance, or they can encompass multiple resources to define common patterns of application architecture.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T16:11:09.385126"}}
{"question": "What are the cost implications of using AWS CloudFormation with resource providers in namespaces other than AWS::*, Alexa::*, and Custom::*?", "answer": "When using resource providers with AWS CloudFormation outside the specified namespaces, you incur charges per handler operation, which includes create, update, delete, read, or list actions on a resource. This means that you will be billed for these operations, unlike when using the mentioned namespaces where there are no additional charges for using AWS CloudFormation.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T16:11:09.385612"}}
{"question": "What can you find in the AWS CloudFormation quotas regarding templates?", "answer": "In the AWS CloudFormation quotas, you can find information about the number of parameters and outputs you can specify in a template, as well as the number of resources you can declare in a template.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-04T16:11:14.884423"}}
{"question": "Why is it considered a best practice to create smaller templates and stacks in AWS CloudFormation?", "answer": "Creating smaller templates and stacks is considered a best practice to minimize the blast radius for your resource changes and to troubleshoot issues with multiple resource dependencies faster, as smaller groups of resources will have less complex dependencies than larger groups.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-04T16:11:14.884927"}}
{"question": "How does the information on the number of parameters and outputs compare to the information on the number of resources in AWS CloudFormation?", "answer": "Both the number of parameters and outputs you can specify in a template, as well as the number of resources you can declare in a template, are addressed in the AWS CloudFormation quotas. However, they focus on different aspects of template design: parameters and outputs are related to the inputs and outputs of a template, while resources pertain to the actual AWS services and components that the template will manage.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-04T16:11:14.885244"}}
{"question": "What is Amazon CloudFront and what benefits does it offer?", "answer": "Amazon CloudFront is a web service that provides businesses and web application developers an easy and cost-effective way to distribute content. It offers low latency and high data transfer speeds by delivering files to end-users through a global network of edge locations. Additionally, CloudFront is a self-service, pay-per-use offering, requiring no long-term commitments or minimum fees.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-04T16:11:19.993361"}}
{"question": "How does Amazon CloudFront enable efficient content delivery?", "answer": "Amazon CloudFront enables efficient content delivery by utilizing a global network of edge locations to serve requests. This setup allows for low latency and high data transfer rates when distributing content to end-users.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-04T16:11:19.993651"}}
{"question": "How does the pricing model of Amazon CloudFront compare to other AWS services?", "answer": "Amazon CloudFront operates on a self-service, pay-per-use model, similar to other AWS services. However, it specifically requires no long-term commitments or minimum fees, which may differ from the pricing structures of other AWS services that could involve contracts or minimum usage requirements.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-04T16:11:19.993824"}}
{"question": "What types of origin servers can be used with Amazon CloudFront for static and dynamic content?", "answer": "For static files, you can use one or more origin servers like Amazon S3 buckets to store the definitive versions of your files. For dynamically generated content that is personalized or customized, you can use Amazon EC2 or any other web server as the origin server.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-04T16:11:24.860374"}}
{"question": "How does Amazon CloudFront improve performance for end-users when delivering content?", "answer": "Amazon CloudFront improves performance for end-users by employing a global network of edge locations and regional edge caches that cache copies of content close to viewers. It ensures that viewer requests are served by the closest edge location, which reduces the distance requests travel. Additionally, for files not cached at the edge locations, CloudFront maintains persistent connections with origin servers to fetch those files quickly.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-04T16:11:24.860844"}}
{"question": "What is the difference between using Amazon S3 and Amazon EC2 as origin servers in Amazon CloudFront?", "answer": "The main difference is that Amazon S3 is used for storing static files, while Amazon EC2 is used for dynamically generated content that is personalized or customized. This means S3 is suitable for definitive versions of files, whereas EC2 can handle more complex content generation needs.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-04T16:11:24.861109"}}
{"question": "What are the cost advantages of using Amazon CloudFront compared to self-hosting?", "answer": "Amazon CloudFront has no minimum commitments and charges you only for what you use, which spares you from the expense and complexity of operating a network of cache servers in multiple sites across the internet. It eliminates the need to over-provision capacity to serve potential spikes in traffic, and it reduces the load on your origin servers, further bringing cost savings.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-04T16:11:29.806313"}}
{"question": "How does Amazon CloudFront improve performance and reliability when using AWS origins?", "answer": "When using AWS origins, Amazon CloudFront improves performance and reliability by tracking and adjusting origin routes, monitoring system health, and responding quickly to any issues. Additionally, it integrates well with other AWS services, which enhances ease of use.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-04T16:11:29.806613"}}
{"question": "How does Amazon CloudFront manage simultaneous viewer requests compared to traditional origin server handling?", "answer": "Amazon CloudFront collapses simultaneous viewer requests at an edge location for the same file into a single request to your origin server, which reduces the load on your origin servers. In contrast, traditional origin server handling would not have such optimizations, potentially leading to higher loads and the need for more infrastructure scaling.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-04T16:11:29.806792"}}
{"question": "What types of content can Amazon CloudFront support for delivery?", "answer": "Amazon CloudFront supports content that can be sent using the HTTP or WebSocket protocols. This includes dynamic web pages and applications such as HTML or PHP pages, WebSocket-based applications, and popular static files like website images, audio, video, media files, or software downloads. Additionally, it supports the delivery of live or on-demand media streaming over HTTP.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-04T16:11:37.451720"}}
{"question": "How does Amazon CloudFront provide high performance content delivery to developers?", "answer": "Amazon CloudFront provides high performance content delivery through a pay-as-you-go pricing model without the need for negotiated contracts. It also offers a self-service model, allowing developers to access its features easily. Furthermore, it has tight integration with other Amazon Web Services, and it works seamlessly with Amazon S3, Amazon EC2, and Elastic Load Balancing as origin servers, enhancing its performance and usability.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-04T16:11:37.452245"}}
{"question": "What is the relationship between primary and backup origins in Amazon CloudFront?", "answer": "In Amazon CloudFront, for every origin that you add to a distribution, you can assign a backup origin. This backup origin will automatically serve your traffic if the primary origin becomes unavailable. You can also choose specific HTTP 4xx/5xx status codes that will trigger the failover to the backup origin when returned from the primary origin. The two origins can be any combination of AWS and non-AWS origins.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-04T16:11:37.452572"}}
{"question": "How can you point your zone apex to your Amazon CloudFront distribution using Amazon Route 53?", "answer": "You can configure an ALIAS record in Amazon Route 53 that maps the apex or root of your DNS name (example.com) to your Amazon CloudFront distribution. Amazon Route 53 will then respond to requests for this ALIAS record with the appropriate IP address(es) for your CloudFront distribution, and there is no charge for queries to ALIAS records mapped to a CloudFront distribution.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T16:11:44.131507"}}
{"question": "What is the purpose of Regional Edge Caches in Amazon CloudFront?", "answer": "Regional Edge Caches (RECs) in Amazon CloudFront provide an additional caching layer between your origin web server and the global edge locations. They help improve performance for viewers by keeping more content cached closer to them, which reduces the need for CloudFront to retrieve objects from the origin web server. RECs have a larger cache width than individual edge locations, allowing objects to remain cached longer and enhancing overall content delivery performance.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T16:11:44.131860"}}
{"question": "What are the differences between using Amazon Route 53 and CloudFront's Anycast Static IPs for pointing the apex domain to the CloudFront distribution?", "answer": "Using Amazon Route 53, you can create an ALIAS record to map the apex domain to your CloudFront distribution without any charges for queries. In contrast, using CloudFront's Anycast Static IPs allows you to point your apex domain through any DNS provider by creating standard A records with the 3 static IP addresses provided by CloudFront. This method extends apex domain support beyond Route 53 while ensuring traffic is routed to the closest edge locations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-04T16:11:44.132312"}}
{"question": "Is there any charge for using the Geo Restriction feature in Amazon CloudFront?", "answer": "No, there are no additional charges to use the Geo Restriction feature in Amazon CloudFront.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-04T16:11:48.410606"}}
{"question": "How does Amazon CloudFront determine how frequently to check for updates to files stored at the origin?", "answer": "Amazon CloudFront uses cache control headers to determine how frequently it needs to check the origin for an updated version of a file. If no cache control header is set, each edge location checks for an updated version of the file whenever it receives a request more than 24 hours after the previous time it checked the origin for changes.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-04T16:11:48.411121"}}
{"question": "What happens when a viewer requests content from a restricted country using CloudFront's Geo Restriction feature compared to a viewer from an unrestricted country?", "answer": "When a viewer requests content from a restricted country, CloudFront responds with an HTTP status code 403 (Forbidden). In contrast, a viewer from an unrestricted country would be able to access the content as intended.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-04T16:11:48.411385"}}
{"question": "What are the two main methods for removing a file from Amazon CloudFront edge locations?", "answer": "The two main methods for removing a file from Amazon CloudFront edge locations are: 1) deleting the file from your origin, which allows the content in the edge locations to be removed once it reaches the expiration period defined in each objects HTTP header, and 2) using the Invalidation API to remove the object from all Amazon CloudFront edge locations before the specified expiration time.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-04T16:11:55.814132"}}
{"question": "Why is it recommended to implement a versioning system or set a short expiration period for files that need to be removed frequently from cache?", "answer": "It is recommended to implement a versioning system for your files and/or set a short expiration period if you know beforehand that your files will need to be removed from cache frequently, because using invalidation is suggested only in unexpected circumstances. This approach can help avoid the limitations and potential errors associated with invalidation requests.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-04T16:11:55.814501"}}
{"question": "How do the limits on invalidating objects individually compare to the limits on using wildcard invalidation requests?", "answer": "The limits on invalidating objects individually allow for up to 3,000 objects per distribution in progress at one time, while the limits on using wildcard invalidation requests allow for requests for up to 15 invalidation paths in progress at one time. Importantly, the limit on wildcard invalidation requests is independent of the limit on invalidating objects individually.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-04T16:11:55.814734"}}
{"question": "What is the primary difference between CloudFront embedded POPs and CloudFront POPs?", "answer": "The primary difference between CloudFront embedded POPs and CloudFront POPs is their deployment location and the type of content they deliver. CloudFront embedded POPs are deployed directly in ISP and MNO networks and are purpose built for delivering large scale cacheable traffic such as video streams and game downloads. In contrast, CloudFront POPs are deployed within the AWS network and are designed to deliver a variety of workloads, including both cacheable and dynamic content.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-04T16:12:01.324407"}}
{"question": "Why would a user choose to enable CloudFront embedded POPs for their workload?", "answer": "A user would choose to enable CloudFront embedded POPs for their workload primarily for the delivery of large scale cacheable traffic that is accessed by many end viewers simultaneously. This includes use cases such as large scale live video streaming, video on demand, and game downloads, which require optimized performance for high traffic scenarios.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-04T16:12:01.324890"}}
{"question": "How do CloudFront embedded POPs and CloudFront POPs work together for content delivery?", "answer": "CloudFront embedded POPs and CloudFront POPs work together seamlessly for content delivery. Once a CloudFront distribution is enabled for embedded POPs, CloudFront's routing system dynamically utilizes both types of POPs to deliver content. This approach ensures optimal performance for end users by leveraging the strengths of both embedded and standard CloudFront POPs.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-04T16:12:01.325180"}}
{"question": "What compliance standards does Amazon CloudFront meet?", "answer": "Amazon CloudFront is compliant with the Payment Card Industry Data Security Standard (PCI DSS) Merchant Level 1, HIPAA, and SOC (System & Organization Control) measures.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:12:05.381323"}}
{"question": "How can Amazon CloudFront be used in relation to protected health information (PHI)?", "answer": "Amazon CloudFront can be used to accelerate the delivery of protected health information (PHI) if you have an executed Business Associate Agreement (BAA) with AWS, as it is now a HIPAA eligible service.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:12:05.381675"}}
{"question": "How does Amazon CloudFront handle caching for different HTTP request methods?", "answer": "Amazon CloudFront does not cache the responses to POST, PUT, DELETE, and PATCH requests; these requests are proxied back to the origin server. However, it may enable caching for the responses to OPTIONS requests.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:12:05.382093"}}
{"question": "How can I enable HTTP/2 for an existing Amazon CloudFront distribution?", "answer": "You can turn on HTTP/2 for an existing Amazon CloudFront distribution using the API or the Management Console. In the Console, go to the 'Distribution Configuration' page and navigate to the section 'Supported HTTP Versions.' There, you can select 'HTTP/2, HTTP/1.1, or HTTP/1.0.'", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-04T16:12:12.776907"}}
{"question": "What are the benefits of using HTTP/3 over previous HTTP versions?", "answer": "HTTP/3 offers several benefits over previous HTTP versions, including faster response times and enhanced security. It uses QUIC, a user datagram protocol (UDP) based, stream-multiplexed, and secure transport protocol that improves upon the capabilities of existing transmission control protocol (TCP), TLS, and HTTP/2.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-04T16:12:12.777181"}}
{"question": "How does Amazon CloudFront's use of HTTP/2 differ from its use of HTTP/1.1?", "answer": "Amazon CloudFront supports HTTP/2 for delivering content to viewers' clients and browsers, while it continues to use HTTP/1.1 for communication between the edge location and your origin servers. This means that HTTP/2 is utilized for client-side delivery, but the backend communication remains on HTTP/1.1.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-04T16:12:12.777626"}}
{"question": "What are the performance improvements offered by HTTP/3 over previous HTTP versions?", "answer": "HTTP/3 offers several performance improvements over previous HTTP versions, including faster and reliable connections through 1-RTT for TLS handshake, better web performance with client-side connection migrations, and improved handling of poor connections. Additionally, QUIC, which underlies HTTP/3, is better suited for congested networks with high packet loss and allows faster reconnections during Wifi or cellular handoffs.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-04T16:12:17.052395"}}
{"question": "How does HTTP/3 enhance security compared to previous versions of HTTP?", "answer": "HTTP/3 enhances security compared to previous versions by encrypting packets exchanged during TLS handshakes, which makes inspection by middleboxes harder, providing additional privacy and reducing the risk of man-in-the-middle attacks.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-04T16:12:17.052662"}}
{"question": "In what ways does CloudFront's HTTP/3 support differ from its support for TCP connections?", "answer": "CloudFront's HTTP/3 support differs from its support for TCP connections in that HTTP/3, based on QUIC, is not lossless, making it more effective in congested networks with high packet loss. Additionally, HTTP/3 supports client-side connection migrations to recover from poor connections with minimal interruptions, whereas TCP does not have this capability.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-04T16:12:17.053092"}}
{"question": "What header does CloudFront automatically add when HTTP/3 is enabled on a distribution?", "answer": "When HTTP/3 is enabled on a CloudFront distribution, CloudFront automatically adds the Alt-Svc header to advertise that HTTP/3 support is available.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-04T16:12:22.777543"}}
{"question": "Why is fallback support to HTTP/1.1 or HTTP/2 required when using HTTP/3?", "answer": "Fallback support to HTTP/1.1 or HTTP/2 is required as part of the HTTP/3 specification to ensure that clients that do not support HTTP/3 can still communicate with CloudFront distributions that have HTTP/3 enabled.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-04T16:12:22.777856"}}
{"question": "How does CloudFront handle communication between edge locations and origin servers when HTTP/3 is enabled?", "answer": "CloudFront continues to use HTTP/1.1 for communication between the edge location and your origin servers, even when HTTP/3 is enabled for communication between viewers' clients/browsers and CloudFront edge locations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-04T16:12:22.778545"}}
{"question": "What is the purpose of CloudFront SaaS Manager?", "answer": "CloudFront SaaS Manager is designed for organizations that face the challenge of managing multiple websites efficiently. It is particularly valuable for Software-as-a-Service (SaaS) and web development platform providers, as it allows them to maintain consistent settings across their tenants' websites.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-04T16:12:28.032060"}}
{"question": "How does a multi-tenant distribution differ from a standard distribution in CloudFront?", "answer": "A multi-tenant distribution defines a base configuration that is shared across domains and cannot serve traffic directly. It contains shared configuration settings such as origin configurations, cache behaviors, and security settings, and offers customizable, parametrized fields to meet each domain's unique needs. In contrast, a standard distribution serves traffic directly and does not have the multi-tenant capabilities.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-04T16:12:28.032423"}}
{"question": "What are the customization options available for a Distribution Tenant in a multi-tenant distribution?", "answer": "A Distribution Tenant can include the following customizations: unique origin paths and/or origin domain names (defined through parameter values in the multi-tenant distribution), custom TLS certificates, Web ACL overrides, and Geo Restriction overrides.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-04T16:12:28.032842"}}
{"question": "What does the integration of CloudFront with AWS Certificate Manager (ACM) provide?", "answer": "The integration of CloudFront with AWS Certificate Manager (ACM) provides a seamless domain control validation experience, removes the burden of certificate issuance and management, and offers automated lifecycle management for Amazon-issued SSL/TLS certificates.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-04T16:12:32.706172"}}
{"question": "How does CloudFront support apex or root domains?", "answer": "CloudFront supports apex or root domains by allowing customers to use Route 53 to manage DNS and add an ALIAS record for their apex domain to point to a CloudFront provided domain. For customers who cannot use Route 53, Anycast Static IPs can provide a dedicated set of IP addresses that can be used in place of CNAME/ALIAS records.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-04T16:12:32.706478"}}
{"question": "What is the difference between CloudFront Distribution Tenants and standard CloudFront distributions?", "answer": "CloudFront Distribution Tenants are new resources that inherit configuration settings from a CloudFront Multi-Tenant Distribution, and they are charged based on the number of Distribution Tenant resources created. In contrast, standard CloudFront distributions do not inherit settings from a Multi-Tenant Distribution and have their own pricing structure.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-04T16:12:32.706876"}}
{"question": "What header must a client include for Amazon CloudFront to establish WebSocket connections?", "answer": "The client must include the 'Upgrade: websocket' header for Amazon CloudFront to establish WebSocket connections.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-04T16:12:37.669668"}}
{"question": "Why is gRPC considered suitable for real-time communication applications?", "answer": "gRPC is considered suitable for real-time communication applications because it allows bidirectional communication between a client and a server over a long-held HTTP/2 connection, enabling the client and server to send real-time data to each other without the need for the client to frequently reinitiate connections to check for new data. This is crucial for low latency and high transfer speeds.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-04T16:12:37.669926"}}
{"question": "How does enabling gRPC on a CloudFront distribution affect the support for HTTP/2 and POST requests?", "answer": "Enabling gRPC on a CloudFront distribution ensures that both HTTP/2 and support for POST requests are also enabled on the distribution, as gRPC only supports the POST method over HTTP/2.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-04T16:12:37.670332"}}
{"question": "What encryption method does gRPC use to secure traffic from the client to origin servers?", "answer": "gRPC uses HTTP/2, which ensures that traffic is end-to-end encrypted from the client to your origin servers.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-04T16:12:42.949245"}}
{"question": "How does gRPC's use of Protocol Buffers contribute to better performance compared to traditional payloads like JSON?", "answer": "gRPC leverages a binary message format called Protocol Buffers, which are smaller than traditional payloads like JSON. Parsing Protocol Buffers is less CPU-intensive because the data is in a binary format, resulting in faster message exchanges and better overall performance.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-04T16:12:42.949567"}}
{"question": "What are the different streaming combinations supported by gRPC on CloudFront, and how do they compare to traditional RESTful APIs?", "answer": "gRPC on CloudFront supports the following streaming combinations: Unary (no streaming), Client-to-server streaming, Server-to-client streaming, and Bi-directional streaming. This built-in streaming support simplifies the creation of streaming services or clients, whereas traditional RESTful APIs typically do not have such native support for streaming.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-04T16:12:42.950053"}}
{"question": "What encryption method do web applications use to protect sensitive data between the end user and CloudFront?", "answer": "Web applications use SSL/TLS encryption to protect sensitive data between the end user and CloudFront.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-04T16:12:47.731699"}}
{"question": "Why is it important for web applications to limit access to sensitive information among micro-services?", "answer": "It is important to limit access to sensitive information among micro-services because most components do not need direct access to this data. A simple programming mistake, such as logging the wrong variable, could accidentally expose sensitive information like a customer's credit card number.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-04T16:12:47.732099"}}
{"question": "How does field-level encryption enhance security compared to allowing all micro-services direct access to sensitive data?", "answer": "Field-level encryption enhances security by allowing only applications that have the private keys to decrypt sensitive fields, such as credit card data. This means that while the order fulfillment service can only view encrypted credit card numbers, the payment services can decrypt them. Therefore, even if an application service leaks cipher text, the data remains cryptographically protected, reducing the risk of exposing sensitive information.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-04T16:12:47.732282"}}
{"question": "What is the monthly cost for using Dedicated IP Custom SSL?", "answer": "The monthly cost for using Dedicated IP Custom SSL is $600, which is prorated by the hour.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-04T16:12:52.335792"}}
{"question": "How does SNI Custom SSL differ from Dedicated IP Custom SSL in terms of browser support?", "answer": "SNI Custom SSL works with most modern browsers that support the SNI extension, while Dedicated IP Custom SSL is designed for browsers and clients that do not support SNI. This means that SNI Custom SSL can serve multiple domains over the same IP address, but older browsers that do not support SNI cannot establish a connection to CloudFront for HTTPS content.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-04T16:12:52.336147"}}
{"question": "What is the main advantage of using Dedicated IP Custom SSL over SNI Custom SSL?", "answer": "The main advantage of using Dedicated IP Custom SSL is that it serves SSL content to clients that do not support SNI, ensuring compatibility with a wider range of legacy browsers. In contrast, SNI Custom SSL relies on SNI support, which is not available in older browsers.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-04T16:12:52.336593"}}
{"question": "How can I provision and manage SSL/TLS certificates for my CloudFront distribution?", "answer": "You can provision SSL/TLS certificates by using the new AWS Certificate Manager (ACM). Once you provision a certificate, you can deploy it to your CloudFront distribution with just a couple of clicks. ACM also manages the certificate renewals for you, and there are no additional charges for using this service.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T16:12:58.336312"}}
{"question": "What is the difference between AWS Shield Standard and AWS Shield Advanced?", "answer": "AWS Shield Standard is a managed service that provides protection against common DDoS attacks at no additional cost for all AWS customers. It protects against frequently occurring Infrastructure (layer 3 and 4) attacks like SYN/UDP Floods and Reflection attacks. In contrast, AWS Shield Advanced is an optional paid service available to AWS Business Support and AWS Enterprise Support customers, offering additional protections against larger and more sophisticated attacks for applications running on Elastic Load Balancing (ELB), Amazon CloudFront, and Route 53.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T16:12:58.337424"}}
{"question": "What feature does Amazon CloudFront offer to control access to files?", "answer": "Amazon CloudFront has an optional private content feature that allows you to control access to files. When this feature is enabled, CloudFront will only deliver files when you securely sign your requests, ensuring that you have control over file access.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T16:12:58.337593"}}
{"question": "What is the purpose of CloudFront Origin Access Control (OAC)?", "answer": "The purpose of CloudFront Origin Access Control (OAC) is to restrict access to your Amazon Simple Storage Service (S3) Origins, AWS Elemental Origins, and Lambda Function URLs, ensuring that only CloudFront can access the content.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-04T16:13:06.314575"}}
{"question": "How does IP Allowlisting enhance security for CloudFront origins?", "answer": "IP Allowlisting enhances security for CloudFront origins by allowing you to configure your origin's security group or firewall to exclusively permit incoming traffic from CloudFront's IP ranges. This significantly limits access to only those requests that come through CloudFront, reducing the risk of unauthorized direct access to your origin.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-04T16:13:06.314946"}}
{"question": "What are the differences between CloudFront Origin Access Control (OAC) and VPC origins?", "answer": "CloudFront Origin Access Control (OAC) is a security feature that restricts access to specific origins like Amazon S3, ensuring that only CloudFront can access the content. In contrast, VPC origins allow you to deliver content from applications hosted in a VPC private subnet using resources like Application Load Balancers, Network Load Balancers, and EC2 Instances. Therefore, OAC focuses on restricting access to origins, while VPC origins focus on delivering content from private subnets.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-04T16:13:06.315462"}}
{"question": "What is the purpose of CloudFront Virtual Private Cloud (VPC) origins?", "answer": "The purpose of CloudFront Virtual Private Cloud (VPC) origins is to allow users to deliver content from applications hosted in a VPC private subnet through CloudFront distributions. This feature enhances security and enables private access without needing an externally resolvable Domain Name Service (DNS) name.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-04T16:13:11.532778"}}
{"question": "How do VPC origins enhance security compared to traditional origin configurations?", "answer": "VPC origins enhance security by allowing access to the origins in a VPC only through CloudFront distributions, eliminating the need for complex configurations such as secret headers or Access Control Lists. This streamlined approach reduces the intricacies of managing security measures.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-04T16:13:11.533964"}}
{"question": "How do VPC origins and traditional external origins differ in terms of DNS requirements?", "answer": "VPC origins do not require the origin to have an externally resolvable Domain Name Service (DNS) name, while traditional external origins typically do require this to be accessible. This difference allows VPC origins to operate solely within the private subnet of a VPC.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-04T16:13:11.534160"}}
{"question": "What are the components that VPC origins support for delivering content using CloudFront?", "answer": "VPC origins support Application Load Balancers, Network Load Balancers, and EC2 Instances for delivering content using CloudFront.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-04T16:13:16.968737"}}
{"question": "How does using VPC origins enhance the security posture of applications?", "answer": "Using VPC origins enhances the security posture of applications by placing load balancers and EC2 instances in private subnets, making CloudFront the sole ingress point. User requests are routed from CloudFront to the VPC origins over a private, secure connection, which provides additional security for the applications.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-04T16:13:16.969041"}}
{"question": "What is the difference in traffic management between VPC subnets with VPC Block Public Access (BPA) enabled and those without?", "answer": "When VPC Block Public Access (BPA) is enabled on a subnet with a VPC origin, active connections from CloudFront are terminated towards that subnet, and no new connections are sent to that subnet. Instead, connections are either routed to other subnets where the VPC origin resides and BPA is not enabled, or they are dropped if all subnets with the VPC origin have BPA enabled. In contrast, subnets without BPA do not block incoming or outgoing traffic through AWS provided internet paths.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-04T16:13:16.969396"}}
{"question": "What is the purpose of configuring custom headers in Amazon CloudFront?", "answer": "Configuring custom headers in Amazon CloudFront allows you to add custom headers or override existing header values in requests forwarded to your origin. This helps validate that requests made to your origin were sent from CloudFront and can be used to distinguish origin requests from different CloudFront distributions. Additionally, custom headers can aid in determining appropriate CORS headers for the requests.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-04T16:13:22.535392"}}
{"question": "How do custom headers enhance the functionality of Amazon CloudFront?", "answer": "Custom headers enhance the functionality of Amazon CloudFront by allowing you to control and validate requests sent to your origin. They enable you to specify which requests are accepted based on custom header values, distinguish between requests from multiple distributions using the same origin, and determine the correct CORS headers to return for requests. This customization can improve security and performance by ensuring that only valid requests are processed.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-04T16:13:22.536292"}}
{"question": "How does the query string whitelisting feature in Amazon CloudFront compare to simply forwarding all query parameters to the origin?", "answer": "The query string whitelisting feature in Amazon CloudFront allows you to configure the service to only use certain parameters in the cache key, while still forwarding all parameters to the origin. This is different from simply forwarding all query parameters, as it helps optimize caching by identifying unique objects in the cache based solely on the whitelisted parameters, which can improve cache efficiency and performance for dynamic content.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-04T16:13:22.536542"}}
{"question": "What must a client add to the request header for CloudFront to compress objects automatically?", "answer": "The client must add Accept-Encoding: gzip in the request header for CloudFront to compress objects automatically.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-04T16:13:26.133010"}}
{"question": "What are some benefits of streaming content compared to traditional download delivery?", "answer": "Some benefits of streaming content include giving viewers more control over their viewing experience, allowing for easier seeking in videos, giving content providers more control since no file remains on the viewer's device after watching, and reducing costs by only delivering the portions of a media file that viewers actually watch.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-04T16:13:26.133361"}}
{"question": "How does streaming content differ from traditional download delivery in terms of media access?", "answer": "Streaming content differs from traditional download delivery because streaming allows viewers to watch the media in real time as it is delivered, while traditional downloads require the entire media file to be downloaded before playback can occur.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-04T16:13:26.133857"}}
{"question": "What formats can media files be converted to for use with Amazon CloudFront?", "answer": "Media files can be converted to HLS, MPEG-DASH, or Microsoft Smooth Streaming formats for use with Amazon CloudFront.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-04T16:13:30.793701"}}
{"question": "How does Amazon CloudFront support live streaming?", "answer": "Amazon CloudFront supports live streaming with any live video origination service that outputs HTTP-based streams, such as AWS Elemental MediaPackage or AWS Elemental MediaStore.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-04T16:13:30.794056"}}
{"question": "What is the difference between using AWS Elemental MediaConvert and running a third-party streaming server on Amazon EC2?", "answer": "AWS Elemental MediaConvert is used to convert media files to streaming formats such as HLS and MPEG-DASH before storing them in Amazon S3, allowing direct streaming via Amazon CloudFront without media servers. In contrast, running a third-party streaming server, like Wowza Media Server on Amazon EC2, requires the server to convert the media file to the required HTTP streaming format and then designate it as the origin for an Amazon CloudFront web distribution.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-04T16:13:30.794694"}}
{"question": "What is Media-Quality Aware Resiliency (MQAR)?", "answer": "Media-Quality Aware Resiliency (MQAR) is an integrated capability between Amazon CloudFront and AWS Media Services that provides automatic cross-region origin selection and failover based on a dynamically generated video quality score. It allows for the deployment of a redundant AWS media services workflow in two different AWS Regions for resilient live event delivery.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-04T16:13:36.393283"}}
{"question": "How does Origin Shield help reduce the load on your origin?", "answer": "Origin Shield helps increase your cache hit ratio to reduce the load on your origin by serving as a centralized caching layer. It collapses requests across regions so that as few as one request goes to your origin per object, making sure that CloudFront routes all origin fetches through Origin Shield and only makes a request to your origin if the content is not already stored in Origin Shield's cache.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-04T16:13:36.393544"}}
{"question": "How does the functionality of MQAR compare to that of Origin Shield in terms of live event delivery?", "answer": "MQAR focuses on delivering high-quality media streaming by automatically selecting the origin with the highest quality score for live event delivery, thus ensuring a better viewer experience. In contrast, Origin Shield is designed to improve cache efficiency and reduce redundancy by routing requests through a centralized cache, which decreases the load on the origin and operating costs. While MQAR enhances the quality of media delivery, Origin Shield optimizes the efficiency of content delivery.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-04T16:13:36.393950"}}
{"question": "What should you consider when choosing the AWS Region for Origin Shield?", "answer": "When choosing the AWS Region for Origin Shield, you should select the region that has the lowest latency to your origin.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-04T16:13:40.090598"}}
{"question": "How does Origin Shield ensure high availability?", "answer": "Origin Shield ensures high availability by being built using a highly-available architecture that spans several Availability Zones and employs fleets of auto-scaling Amazon EC2 instances. Additionally, it uses active error tracking for each request to automatically route requests to a secondary Origin Shield location if the primary location is unavailable.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-04T16:13:40.090890"}}
{"question": "What are the differences between Origin Shield and Anycast Static IPs in terms of function?", "answer": "Origin Shield is designed to improve performance and reduce latency by caching content closer to the origin, while Anycast Static IPs provide a consistent set of static IP addresses that can be used globally across CloudFront edge locations, simplifying allow-listing and enhancing security. Origin Shield focuses on optimizing content delivery, whereas Anycast Static IPs address operational challenges related to IP management.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-04T16:13:40.091355"}}
{"question": "What is the maximum size of a single file that can be delivered through Amazon CloudFront?", "answer": "The maximum size of a single file that can be delivered through Amazon CloudFront is 30 GB. This limit applies to all Amazon CloudFront distributions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-04T16:13:44.995681"}}
{"question": "What are the notable exceptions when using Anycast Static IPs with CloudFront?", "answer": "There are three notable exceptions when using Anycast Static IPs with CloudFront: 1) Anycast Static IPs will not support legacy clients that cannot support SNI, 2) you are required to use Price Class All when using Anycast Static IPs, and 3) you must disable IPv6 when using Anycast Static IPs.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-04T16:13:44.995916"}}
{"question": "How do Anycast Static IPs differ from dynamic IP addresses in CloudFront distributions?", "answer": "Anycast Static IPs are explicitly associated with distributions in an AWS account, while dynamic IP addresses are used by default until a distribution is linked to an existing Anycast Static IP list. Anycast Static IPs also support Server Name Indication (SNI), allowing correct certificates to be returned, which is not mentioned for dynamic IP addresses.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-04T16:13:44.996302"}}
{"question": "What kind of information do CloudFront standard logs provide?", "answer": "CloudFront standard logs provide detailed records about every request made to a distribution, which are useful for scenarios including security and access audits.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-04T16:13:50.745228"}}
{"question": "How do CloudFront real-time logs differ from standard logs?", "answer": "CloudFront real-time logs provide information about requests made to a distribution in real time, with log records delivered within seconds of receiving the requests. In contrast, standard logs contain detailed records of all requests but are not delivered in real time.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-04T16:13:50.745568"}}
{"question": "What are the delivery destinations for CloudFront standard logs compared to real-time logs?", "answer": "CloudFront standard logs are delivered to the Amazon S3 bucket of your choice, Amazon CloudWatch logs, and Amazon Data Firehose. In contrast, CloudFront real-time logs are delivered to the data stream of your choice in Amazon Kinesis Data Streams.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-04T16:13:50.745833"}}
{"question": "What log formats can CloudFront standard access logs be delivered in?", "answer": "CloudFront standard access logs can be delivered in several output log formats, including plain, w3c, JSON, csv, and parquet.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-04T16:13:54.402623"}}
{"question": "How does cost allocation tagging help with managing AWS resources in CloudFront?", "answer": "Cost allocation tagging helps by allowing you to categorize and group AWS resources, making it easier to allocate costs and optimize spending. For example, tags can be used to group resources by administrator, application name, cost center, or a specific project.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-04T16:13:54.402936"}}
{"question": "How does the logging delivery to S3 differ from other log delivery options in terms of partitioning?", "answer": "For logs delivered to S3, you have the option to enable partitioning, allowing logs to be automatically partitioned on an hourly or daily basis. This specific partitioning feature is not mentioned for other log delivery options like Amazon CloudWatch or Amazon Data Firehose.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-04T16:13:54.403337"}}
{"question": "What metrics does CloudFront publish to Amazon CloudWatch?", "answer": "CloudFront automatically publishes six operational metrics into Amazon CloudWatch, each at 1-minute granularity.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-04T16:13:57.755233"}}
{"question": "When would you choose to use real-time logs over standard logs for CloudFront?", "answer": "You would choose to use real-time logs if you have time-sensitive use cases and require access log data quickly within a few seconds.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-04T16:13:57.755599"}}
{"question": "How do real-time logs differ from standard logs in terms of availability and cost?", "answer": "Real-time logs are built for quick data delivery and may have dropped log records if there are data delays, while standard logs are a low-cost processing solution built for completeness and are typically available in a few minutes.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-04T16:13:57.756113"}}
{"question": "Where are CloudFront standard logs delivered?", "answer": "CloudFront standard logs are delivered to your S3 bucket.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-04T16:14:01.615195"}}
{"question": "What is the purpose of using Kinesis Data Streams with CloudFront logs?", "answer": "Kinesis Data Streams is used to deliver real-time logs from CloudFront, allowing for further processing and integration with services such as Amazon Kinesis Data Firehose for data delivery to various destinations.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-04T16:14:01.615547"}}
{"question": "How does the delivery of logs differ between CloudFront standard logs and real-time logs?", "answer": "CloudFront standard logs are delivered to an S3 bucket, while real-time logs are delivered to Kinesis Data Streams, which can then publish the logs to Amazon Kinesis Data Firehose for further delivery to multiple destinations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-04T16:14:01.616197"}}
{"question": "How can I calculate the number of requests per second for my CloudFront distribution?", "answer": "You can calculate the number of requests per second that your CloudFront distribution receives by using the CloudFront usage reports or the CloudFront metrics.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-04T16:14:07.793344"}}
{"question": "What factors should I consider when estimating the number of shards needed for Kinesis Data Streams?", "answer": "When estimating the number of shards needed for Kinesis Data Streams, you should consider the number of requests per second that your CloudFront distribution receives, the typical size of a single real-time log record, and the maximum capacity of a single shard, which can handle no more than 1 MB per second and 1,000 requests per second. Additionally, it is recommended to add up to 25% as a buffer.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-04T16:14:07.793709"}}
{"question": "How does CloudFront Functions compare to AWS Lambda@Edge in terms of cost and use case?", "answer": "CloudFront Functions is a serverless edge compute feature that allows running JavaScript code at CloudFront edge locations for lightweight HTTP(s) transformations and manipulations, and it is offered at a fraction of the price of AWS Lambda@Edge. CloudFront Functions is purpose-built for flexibility and performance, specifically for lightweight tasks, whereas AWS Lambda@Edge is more suited for a broader range of serverless functions.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-04T16:14:07.794149"}}
{"question": "What are the capabilities of CloudFront Functions?", "answer": "CloudFront Functions allows customers to build, test, and deploy lightweight, short-running functions such as cache key normalization, header manipulation, URL redirects or rewrites, and request authorization. It also integrates with CloudFront KeyValueStore to store and retrieve lookup data to enhance function logic.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-04T16:14:14.128750"}}
{"question": "How does the CloudFront KeyValueStore enhance the functionality of CloudFront Functions?", "answer": "The CloudFront KeyValueStore enhances the functionality of CloudFront Functions by providing a global, low-latency, fully managed key-value data store that allows functions to retrieve key-value data. This makes functions more customizable by enabling independent data updates and ensures the key-value data is accessible across all CloudFront edge locations, facilitating fast reads.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-04T16:14:14.129105"}}
{"question": "What is the difference between the types of functions that can be created with CloudFront Functions and the capabilities of CloudFront KeyValueStore?", "answer": "CloudFront Functions are designed for lightweight, short-running tasks such as cache key normalization, header manipulation, URL redirects or rewrites, and request authorization. In contrast, CloudFront KeyValueStore serves as a global key-value data store that enhances these functions by allowing them to access and modify data independently, ensuring quick retrieval across all edge locations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-04T16:14:14.129738"}}
{"question": "What is the main purpose of using CloudFront KeyValueStore?", "answer": "The main purpose of using CloudFront KeyValueStore is for frequent reads at the edge locations and infrequent updates. It simplifies the management of URL rewrites and redirects, facilitates A/B testing and feature flags, and helps implement access authorization by creating and validating user-generated tokens.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-04T16:14:20.152252"}}
{"question": "How does CloudFront Functions work in conjunction with Lambda@Edge?", "answer": "CloudFront Functions is meant to complement Lambda@Edge, not replace it. The combination of both allows you to select the right tool for different event triggers within the same cache behavior in your CloudFront distributions. For example, Lambda@Edge can manipulate streaming manifest files to inject custom tokens, while CloudFront Functions can validate those tokens when a user makes a request for a segment from the manifest.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-04T16:14:20.152764"}}
{"question": "What are the differences in use cases between CloudFront Functions and Lambda@Edge?", "answer": "CloudFront Functions is used for lightweight operations such as validating user-generated tokens, while Lambda@Edge is more suited for complex manipulations, such as modifying streaming manifest files. Both can be used together in the same cache behavior but serve different functions based on the requirements of the task.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-04T16:14:20.153009"}}
{"question": "What are the two options for running code in response to CloudFront events?", "answer": "The two options for running code in response to CloudFront events are CloudFront Functions and Lambda@Edge.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-04T16:14:24.565761"}}
{"question": "When should you use Lambda@Edge instead of CloudFront Functions?", "answer": "You should use Lambda@Edge for computationally intensive operations, which includes tasks that take longer to complete, have dependencies on external 3rd party libraries, require integrations with other AWS services like S3 or DynamoDB, or need network calls for data processing.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-04T16:14:24.566119"}}
{"question": "How does CloudFront Functions differ from Lambda@Edge in terms of use cases?", "answer": "CloudFront Functions is purpose-built for lightweight, high scale, and latency sensitive request/response transformations and manipulations, while Lambda@Edge is used for more computationally intensive operations, such as HLS streaming manifest manipulation and server-side rendering of single-page apps.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-04T16:14:24.566551"}}
{"question": "What security model does CloudFront Functions use to maintain isolation between functions?", "answer": "CloudFront Functions employs a process-based isolation model that provides strict isolation boundaries between the Functions code. This model ensures that functions cannot access or modify data belonging to other customers by running functions in a dedicated process on a dedicated CPU.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-04T16:14:29.679824"}}
{"question": "How does the compute utilization metric help in testing a CloudFront Function?", "answer": "The compute utilization metric indicates how close your function is to the execution time limit, expressed as a percentage. For instance, a compute utilization of 30 means the function is using 30% of the total allowable execution time. This metric helps you understand if your function will perform properly when associated with a CloudFront distribution, especially if it is not near 100% utilization.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-04T16:14:29.680181"}}
{"question": "How does the security model of CloudFront Functions compare to that of V8 isolates used by some other vendors?", "answer": "CloudFront Functions' security model is considered more secure than the V8 isolates-based model offered by some other vendors. While both models aim to provide security, CloudFront Functions achieves this through a process-based isolation method, whereas V8 isolates may not offer the same level of isolation between customer functions.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-04T16:14:29.680416"}}
{"question": "What metrics are generated for each invocation of a CloudFront Function?", "answer": "Metrics generated for each invocation of a CloudFront Function include the number of invocations, compute utilization, validation errors, and execution errors.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-04T16:14:33.913477"}}
{"question": "How does Lambda@Edge enhance the performance and flexibility of serverless computing?", "answer": "Lambda@Edge enhances the performance and flexibility of serverless computing by allowing code to run at global edge locations without the need for provisioning or managing servers. This enables complex functions and full application logic to be executed closer to viewers, improving response times and reducing latency.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-04T16:14:33.913830"}}
{"question": "How do CloudFront Functions and Lambda@Edge differ in terms of execution environment?", "answer": "CloudFront Functions do not specify a particular execution environment in the provided context, while Lambda@Edge functions run specifically in a Node.js or Python environment.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-04T16:14:33.914364"}}
{"question": "What events trigger Lambda@Edge functions in Amazon CloudFront?", "answer": "Lambda@Edge functions are automatically triggered in response to four Amazon CloudFront events: Viewer Request, Viewer Response, Origin Request, and Origin Response. The Viewer Request event occurs when an end user or device makes an HTTP(S) request to CloudFront at the nearest edge location. The Viewer Response event occurs when the CloudFront server at the edge is ready to respond to the end user. The Origin Request event happens when the CloudFront edge server does not have the requested object in its cache and is ready to send the viewer request to the backend origin webserver. Finally, the Origin Response event occurs when the CloudFront server at the edge receives a response from the backend origin webserver.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-04T16:14:41.324760"}}
{"question": "How does continuous deployment on CloudFront enhance deployment safety?", "answer": "Continuous deployment on CloudFront enhances deployment safety by allowing you to deploy two separate but identical environmentsblue and green. This setup enables you to test and validate configuration changes with a portion of live traffic before deploying changes to all viewers. It also allows for gradual rollouts without DNS changes and ensures session stickiness, thereby providing a consistent experience for viewers. Additionally, you can monitor performance and quickly revert to the previous configuration if needed.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-04T16:14:41.325142"}}
{"question": "What is the difference between the Viewer Request and Origin Request events in CloudFront?", "answer": "The Viewer Request event occurs when an end user or device makes an HTTP(S) request to CloudFront, and this request is received at the edge location closest to that user. In contrast, the Origin Request event occurs when the CloudFront edge server does not already have the requested object in its cache and is preparing to send the viewer request to the backend origin webserver. Essentially, the Viewer Request is the initial request from the end user, while the Origin Request is the subsequent action taken by CloudFront when it needs to fetch content from the backend.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-04T16:14:41.325650"}}
{"question": "What are the existing methods of monitoring that can be used for real user monitoring in continuous deployment?", "answer": "The existing methods of monitoring that can be used for real user monitoring in continuous deployment include the CloudFront console, CloudFront API, CLI, and CloudWatch. These methods allow for the measurement of operational metrics of both primary and staging distributions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-04T16:14:47.432125"}}
{"question": "How does session stickiness work when routing traffic to a staging distribution in continuous deployment?", "answer": "When you use a weight-based configuration to route traffic to a staging distribution, enabling session stickiness ensures that CloudFront treats requests from the same viewer as a single session. When session stickiness is enabled, CloudFront sets a cookie, so all requests from the same viewer in a single session are served by either the primary or the staging distribution.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-04T16:14:47.433048"}}
{"question": "How do IPv4 and IPv6 differ in terms of address length and the number of unique addresses they can provide?", "answer": "IPv4 addresses are 32 bits long, which allows for approximately 4.3 billion unique addresses. In comparison, IPv6 addresses are 128 bits long, allowing for approximately three hundred and forty trillion, trillion unique IP addresses. This significant increase in address space allows IPv6 to accommodate the growing number of devices connected to the Internet.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-04T16:14:47.433516"}}
{"question": "What is one benefit of using IPv6 support for Amazon CloudFront?", "answer": "One benefit of using IPv6 support for Amazon CloudFront is that it allows your applications to connect to Amazon CloudFront edge locations without needing any IPv6 to IPv4 translation software or systems. This can help meet the requirements for IPv6 adoption set by governments, including the U.S. Federal government, and provides extensibility, simplicity in network management, and additional built-in support for security.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-04T16:14:53.104082"}}
{"question": "Why is it necessary to verify log processing systems when enabling IPv6 for Amazon CloudFront?", "answer": "It is necessary to verify log processing systems when enabling IPv6 for Amazon CloudFront because if you have turned on the Amazon CloudFront Access Logs feature, you will start seeing your viewers IPv6 address in the 'c-ip' field. You need to ensure that your log processing systems continue to work properly with IPv6 addresses.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-04T16:14:53.104425"}}
{"question": "How should you configure distributions when using Trusted Signer URLs with IP whitelists and enabling IPv6?", "answer": "When using Trusted Signer URLs with IP whitelists and enabling IPv6, you should use two separate distributions. One distribution should be dedicated exclusively to your Trusted Signer URLs with IP whitelist and have IPv6 disabled, while the other distribution should be used for all other content, which will work with both IPv4 and IPv6. This setup avoids issues that could arise from signing requests arriving over different IP versions.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-04T16:14:53.104903"}}
{"question": "What field in the access logs will show the viewer's IPv6 addresses when using Amazon CloudFront?", "answer": "The viewers IPv6 addresses will be shown in the 'c-ip' field of the access logs if you have the Amazon CloudFront Access Logs feature enabled.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:14:58.123433"}}
{"question": "Why is it important to verify log processing systems before enabling IPv6 for Amazon CloudFront distributions?", "answer": "It is important to verify log processing systems before enabling IPv6 because they need to continue functioning correctly with IPv6 addresses in the access logs. This ensures that the tool or software can handle IPv6 traffic without issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:14:58.123750"}}
{"question": "How does enabling IPv6 for an Amazon CloudFront distribution affect the origin systems in terms of IP address processing?", "answer": "When IPv6 is enabled for an Amazon CloudFront distribution, the detailed access logs will include IPv6 addresses, and the 'X-Forwarded-For' header sent to origins will also contain IPv6 addresses. If the origin systems can only process IPv4 addresses, it is necessary to verify that they will still work correctly with IPv6 addresses before enabling IPv6 for distributions.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:14:58.124228"}}
{"question": "What are the free tier limits for AWS customers starting December 1, 2021?", "answer": "Starting December 1, 2021, all AWS customers will receive 1 TB of data transfer out, 10,000,000 HTTP/HTTPS requests, and 2,000,000 CloudFront Functions invocations each month for free.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-04T16:15:03.453386"}}
{"question": "How does the free tier for AWS customers using Consolidated Billing differ from individual accounts?", "answer": "Customers that use Consolidated Billing to consolidate payment across multiple accounts will only have access to one Free Tier per Organization, unlike individual accounts that may each have their own free tier benefits.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-04T16:15:03.453772"}}
{"question": "What additional benefits do customers subscribed to the CloudFront Security Savings bundle receive in relation to the free tier?", "answer": "Customers subscribed to the CloudFront Security Savings bundle will also benefit from the free tier, allowing them access to the same monthly free tier limits as other AWS customers.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-04T16:15:03.454268"}}
{"question": "What are the five areas on which Amazon CloudFront charges are based?", "answer": "Amazon CloudFront charges are based on actual usage of the service in five areas: Data Transfer Out, HTTP/HTTPS Requests, Invalidation Requests, Real-time Log Requests, and Dedicated IP Custom SSL certificates associated with a CloudFront distribution.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-04T16:15:09.533758"}}
{"question": "How does the AWS Free Usage Tier benefit new users of Amazon CloudFront?", "answer": "The AWS Free Usage Tier allows new users to get started with Amazon CloudFront for free and helps keep rates low as their usage grows. All CloudFront customers receive 1 TB of data transfer out and 10,000,000 HTTP and HTTPS requests free of charge, even if these limits are exceeded.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-04T16:15:09.534153"}}
{"question": "How is the data transfer charge for Amazon CloudFront to the internet calculated compared to data transfer from CloudFront to an AWS origin?", "answer": "For data transfer out to the internet, you are charged based on the volume of data transferred from Amazon CloudFront edge locations, measured in GB, with costs calculated based on pricing tiers for specific geographic regions. In contrast, if you use an AWS origin, there is no charge for data transfer out from AWS to Amazon CloudFront, effective December 1, 2014.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-04T16:15:09.534588"}}
{"question": "How many paths can you request from Amazon CloudFront for invalidation each month at no additional charge?", "answer": "You can request up to 1,000 paths each month from Amazon CloudFront at no additional charge.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-04T16:15:15.427590"}}
{"question": "What factors determine the charges for real-time logs in CloudFront?", "answer": "The charges for real-time logs in CloudFront are determined by the number of log lines that are generated, with a cost of $0.01 for every 1,000,000 log lines that CloudFront publishes to your log destination.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-04T16:15:15.427949"}}
{"question": "How does the cost of using Dedicated IP Custom SSL certificates compare to the cost of real-time log requests?", "answer": "The cost of using Dedicated IP Custom SSL certificates is $600 per month for each certificate, while real-time log requests are charged at $0.01 for every 1,000,000 log lines published. This means that the SSL certificate has a fixed monthly fee, whereas the cost of real-time logs varies based on the number of log lines generated.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-04T16:15:15.428441"}}
{"question": "What is the monthly cost of Kinesis Data Stream in US East (Ohio) with 2 shards?", "answer": "The monthly cost of Kinesis Data Stream in US East (Ohio) with 2 shards is $47.74/month as calculated using the Kinesis calculator.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-04T16:15:22.269800"}}
{"question": "How is the monthly cost of CloudFront real-time logs calculated?", "answer": "The monthly cost of CloudFront real-time logs is calculated by multiplying the number of requests per month by the cost of real-time logs. For example, if there are 1,000 requests per second, the calculation is 1,000 * (60 sec * 60 min * 24 hrs * 30 days) X ($0.01 / 1,000,000), which equals $25.92/month.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-04T16:15:22.270185"}}
{"question": "How does a 304 response affect CloudFront charges compared to a standard response with a message-body?", "answer": "A 304 response results in a charge for the HTTP/HTTPS request and the Data Transfer Out to Internet, similar to a standard response. However, a 304 response does not contain a message-body, which means it does not incur charges for the message-body size. Instead, the HTTP headers associated with the object will consume some bandwidth, leading to standard CloudFront data transfer fees based on the headers.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-04T16:15:22.270664"}}
{"question": "What is the purpose of Price Classes in Amazon CloudFront?", "answer": "The purpose of Price Classes in Amazon CloudFront is to provide an option to lower the prices you pay to deliver content by excluding more expensive edge locations from your distribution. This allows you to reduce your delivery prices while still delivering content from selected edge locations.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-04T16:15:29.063568"}}
{"question": "How does selecting a different Price Class affect content delivery and latency for users?", "answer": "Selecting a different Price Class can affect content delivery and latency by excluding certain edge locations. If you choose a Price Class that does not include all locations, users in geographic areas not covered by your selected class may experience higher latency compared to when content is served from all Amazon CloudFront locations.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-04T16:15:29.064258"}}
{"question": "How does Amazon CloudFront charge for content delivery when using Price Classes versus the default setting?", "answer": "When using Price Classes, Amazon CloudFront charges based on the data transfer and request pricing from the actual location where the content is delivered, which may be less expensive if more costly edge locations are excluded. In contrast, the default setting charges more because it utilizes the entire global network of edge locations, which includes higher-cost areas, resulting in potentially higher delivery prices.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-04T16:15:29.064516"}}
{"question": "What is the maximum percentage of savings available through the CloudFront Security Savings Bundle?", "answer": "The maximum percentage of savings available through the CloudFront Security Savings Bundle is up to 30%.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-04T16:15:34.736767"}}
{"question": "How does commitment to a monthly usage amount affect the savings received with the CloudFront Security Savings Bundle?", "answer": "By committing to a consistent monthly usage amount, such as $100/month for a 1-year term, you receive savings of up to 30% on your CloudFront bill. This commitment allows you to cover more than what you are paying for, as a $100 commitment would cover $142.86 worth of CloudFront usage.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-04T16:15:34.737088"}}
{"question": "How does the inclusion of AWS WAF usage benefit users of the CloudFront Security Savings Bundle compared to standard pricing?", "answer": "Users of the CloudFront Security Savings Bundle benefit from up to $10 of AWS WAF usage included at no additional charge, which covers up to 10% of their committed CloudFront plan amount. In contrast, under standard pricing, users would have to pay separately for any AWS WAF usage without this included benefit.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-04T16:15:34.737596"}}
{"question": "How can I get started with the CloudFront Security Savings Bundle?", "answer": "You can get started with the CloudFront Security Savings Bundle by visiting the CloudFront console to get recommendations on commitment amounts based on your historical CloudFront and AWS WAF usage or by entering your own estimated monthly usage.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:15:39.276076"}}
{"question": "What happens when the term of my CloudFront Security Savings Bundle expires?", "answer": "Once your CloudFront Security Savings Bundle term expires, standard service charges will apply for your CloudFront and AWS WAF usage. The monthly Savings Bundle commitment will no longer be billed and the savings bundle benefits will no longer apply.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:15:39.277224"}}
{"question": "How do the savings benefits of CloudFront Security Savings Bundles apply across AWS accounts?", "answer": "The benefits provided by the CloudFront Security Savings Bundle are applied as credits on your bill and are applicable to usage across all accounts within an AWS Organization/consolidated billing family by default, with credit sharing turned on. This is dependent on when the subscribing account joins or leaves an organization.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:15:39.277567"}}
{"question": "What does AWS Budgets allow you to do regarding cost and usage thresholds?", "answer": "AWS Budgets allows you to set cost and usage thresholds and get notifications by email or Amazon SNS topic when your actual or forecasted charges exceed the threshold.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-04T16:15:43.708537"}}
{"question": "How does the CloudFront Security Savings Bundle benefit AWS WAF usage?", "answer": "The CloudFront Security Savings Bundle includes AWS WAF usage, up to 10% of your committed plan amount, to protect CloudFront resources at no additional charge.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-04T16:15:43.708840"}}
{"question": "What is the difference in coverage between the CloudFront Security Savings Bundle and managed WAF rules subscribed through the AWS Marketplace?", "answer": "The CloudFront Security Savings Bundle covers AWS WAF usage up to 10% of your committed plan amount at no additional charge, while standard CloudFront and AWS WAF charges apply for any usage beyond that. In contrast, managed WAF rules subscribed through the AWS Marketplace are not covered by the CloudFront Security Savings Bundle.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-04T16:15:43.709017"}}
{"question": "What is the primary purpose of the AWS CloudHSM service?", "answer": "The primary purpose of the AWS CloudHSM service is to help meet corporate, contractual, and regulatory compliance requirements for data security by using dedicated Hardware Security Module (HSM) instances within the AWS cloud.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-04T16:15:48.731315"}}
{"question": "How does AWS CloudHSM complement existing data protection solutions?", "answer": "AWS CloudHSM complements existing data protection solutions by providing additional protection for applications and data that are subject to contractual or regulatory mandates for managing cryptographic keys. It allows you to protect your encryption keys within HSMs that are designed and validated to government standards for secure key management.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-04T16:15:48.731676"}}
{"question": "What distinguishes a hardware security module (HSM) from other data protection solutions?", "answer": "A hardware security module (HSM) is distinct from other data protection solutions because it provides secure key storage and cryptographic operations within a tamper-resistant hardware device, ensuring that cryptographic key material is securely stored and used without exposing it outside the cryptographic boundary of the hardware.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-04T16:15:48.732168"}}
{"question": "What is required to use the AWS CloudHSM service?", "answer": "To use the AWS CloudHSM service, you first need to create a CloudHSM Cluster. This cluster can contain multiple HSMs that are spread across multiple Availability Zones in a region.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:15:54.913823"}}
{"question": "How does AWS CloudHSM ensure the security of customer data?", "answer": "AWS CloudHSM ensures the security of customer data by providing dedicated, single-tenant access to each HSM in your cluster, meaning that no AWS personnel have access to your keys or data. Additionally, the HSMs are monitored for health, and the secure channel for cryptographic requests further protects the data.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:15:54.914338"}}
{"question": "How does the network connectivity requirement differ between AWS CloudHSM and on-premises HSMs?", "answer": "AWS CloudHSM requires that the server or instance running the application and the HSM client must have network reachability to all HSMs in the cluster, which can be achieved in various ways like operating in the same VPC or using VPC peering. In contrast, AWS CloudHSM does not interoperate directly with on-premises HSMs, although it allows secure transfer of exportable keys between AWS CloudHSM and most commercial HSMs using supported RSA key wrap methods.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:15:54.914485"}}
{"question": "What third-party software solutions have been tested with AWS CloudHSM?", "answer": "AWS CloudHSM has been integrated and tested with third-party software solutions such as Oracle Database 19c and web servers including Apache and Nginx.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T16:16:01.346452"}}
{"question": "How can custom applications utilize AWS CloudHSM?", "answer": "Custom applications can utilize AWS CloudHSM by using the standard APIs supported by it, which include PKCS#11, Java JCE (Java Cryptography Extensions), OpenSSL Dynamic Engine, or Microsoft KSP/CNG.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T16:16:01.346837"}}
{"question": "What is the difference between AWS CloudHSM and AWS Payment Cryptography?", "answer": "AWS CloudHSM provides general-purpose HSMs for various cryptographic operations, while AWS Payment Cryptography specifically offers cryptography operations for cloud-hosted payment applications.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T16:16:01.347267"}}
{"question": "What is the billing model for AWS CloudHSM?", "answer": "You will be charged an hourly fee for each hour (or partial hour) that an HSM is provisioned to an AWS CloudHSM cluster. A cluster with no HSMs in it is not billed, and you are not billed for automatic storage of encrypted backups.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-04T16:16:07.045055"}}
{"question": "What is the recommended number of HSMs to use for production workloads in AWS CloudHSM?", "answer": "AWS strongly recommends that you use at least two HSMs in two different Availability Zones for any production workload. For mission-critical workloads, it is recommended to use at least three HSMs in at least two separate Availability Zones.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-04T16:16:07.046512"}}
{"question": "How does the hourly fee for AWS CloudHSM differ from reserved instance pricing?", "answer": "The hourly fee for AWS CloudHSM varies by region and does not depend on how much you use your HSM. In contrast, AWS CloudHSM does not offer reserved instance pricing.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-04T16:16:07.046824"}}
{"question": "How often does AWS take automatic encrypted backups of your CloudHSM Cluster?", "answer": "AWS takes automatic encrypted backups of your CloudHSM Cluster on a daily basis.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-4", "source_tokens": 386, "generated_at": "2026-02-04T16:16:11.474199"}}
{"question": "What is recommended to ensure the durability of key material created or imported to your CloudHSM Cluster?", "answer": "It is strongly recommended to ensure that any keys created are synchronized to at least two HSMs in two different Availability Zones to ensure the durability of your keys.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-4", "source_tokens": 386, "generated_at": "2026-02-04T16:16:11.474556"}}
{"question": "What happens if an HSM in your CloudHSM Cluster fails?", "answer": "If an HSM in your CloudHSM Cluster fails, it will be replaced automatically, and all clients will be updated to reflect the new configuration without interrupting any processing.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-4", "source_tokens": 386, "generated_at": "2026-02-04T16:16:11.474993"}}
{"question": "What does AWS CloudHSM use to ensure separation of duties and role-based access control?", "answer": "AWS CloudHSM inherently incorporates separation of duties and role-based access control in its design. AWS maintains a limited credential to the HSM which allows monitoring and maintenance of the HSM's health and availability, taking encrypted backups, and extracting and publishing audit logs to CloudWatch Logs. However, AWS has no access to any keys or data inside your CloudHSM Cluster and cannot perform any operations beyond those allowed for an HSM appliance user.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T16:16:18.913780"}}
{"question": "How does AWS CloudHSM handle tampering and brute-force login attempts?", "answer": "AWS CloudHSM has both physical and logical tamper detection and response mechanisms that trigger key deletion (zeroization) if tampering is detected. The hardware is designed to notice breaches of its physical barrier. Additionally, HSMs are protected against brute-force login attacks: after a fixed number of unsuccessful attempts to access an HSM with admin or crypto officer (CO) credentials, the HSM will lock the admin/CO out. Similarly, after a set number of unsuccessful attempts with crypto user (CU) credentials, the user will be locked out and must be unlocked by a CO or admin.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T16:16:18.914063"}}
{"question": "What is the difference between how AWS monitors the health of the HSM and how users can check the health of an individual HSM?", "answer": "AWS monitors and maintains the HSM and the network for availability and error conditions, ensuring that if an HSM fails or loses network connectivity, it will be automatically replaced. In contrast, users can check the health of an individual HSM using AWS CloudHSM's APIs, SDKs, or CLI Tools. Users also have the option to check the overall health of the service at any time using the AWS Service Health Dashboard.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T16:16:18.914717"}}
{"question": "What happens to keys created in a single HSM setup if the HSM fails?", "answer": "If your AWS CloudHSM Cluster only has a single HSM, it is possible to lose keys that were created since the most recent daily backup if the HSM fails.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-04T16:16:24.548613"}}
{"question": "How does AWS CloudHSM ensure compliance with FIPS standards?", "answer": "AWS CloudHSM is built on hardware that is validated at Federal Information Processing Standard (FIPS) 140-2 Level 3. Additionally, it offers hsm2m.medium instances that are standards-compliant, single-tenant, and FIPS 140-3 Level 3 certified. Customers can also choose to run in non-FIPS mode if their use cases fall outside the restrictions of FIPS 140-3.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-04T16:16:24.548972"}}
{"question": "How does AWS CloudTrail differ from AWS CloudWatch Logs in terms of logging HSM activity?", "answer": "AWS CloudTrail records AWS API calls for your account and is used for security analysis, resource change tracking, and compliance auditing. In contrast, AWS CloudWatch Logs provides access logs for HSM devices, which are not included in the AWS CloudTrail logs.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-04T16:16:24.549462"}}
{"question": "What is the primary compliance validation for AWS CloudHSM?", "answer": "The primary compliance validation for AWS CloudHSM is the FIPS 140-2 Level 3 validation of the hardware itself.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-04T16:16:29.506696"}}
{"question": "Why is FIPS 140-2 Level 3 validation important for certain use cases in AWS CloudHSM?", "answer": "FIPS 140-2 Level 3 validation is important for certain use cases, such as document signing, payments, or operating as a public Certificate Authority for SSL certificates, as it ensures that the hardware meets specific security requirements necessary for those applications.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-04T16:16:29.507049"}}
{"question": "How does AWS CloudHSM communication security compare to that of other AWS services?", "answer": "Unlike other AWS services, all communication between the client and your HSM in AWS CloudHSM is encrypted end to end, meaning that AWS cannot see or intercept this communication, and has no visibility into your cluster access credentials.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-04T16:16:29.507481"}}
{"question": "What is the communication method between CloudHSM Tools and the CloudHSM Cluster?", "answer": "The CloudHSM Tools communicate directly with your CloudHSM Cluster via the CloudHSM Client Library over a secured, mutually authenticated channel.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-04T16:16:35.814902"}}
{"question": "Why is it important to have network reachability to all HSMs in your CloudHSM Cluster when using the CloudHSM Client Library?", "answer": "It is important to have network reachability to all HSMs in your CloudHSM Cluster because the host running the CloudHSM Client Library and/or CLI tools must be able to communicate directly with all HSMs for effective operation.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-04T16:16:35.815258"}}
{"question": "How does the AWS CloudHSM API's capabilities compare to the actions that AWS can perform with its restricted access?", "answer": "The AWS CloudHSM API can perform operations such as creating, modifying, deleting, and getting the status of CloudHSM Clusters and HSMs, but it is limited to actions that AWS can perform with its restricted access and cannot access the contents of the HSM or modify any users, policies, or other settings.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-04T16:16:35.815773"}}
{"question": "What is the process for rotating private keys for signing in AWS CloudHSM?", "answer": "To rotate private keys for signing in AWS CloudHSM, you first create a new private key and generate the corresponding CSR using OpenSSL on AWS CloudHSM. Then, you sign the CSR with the same offline enterprise root. You may need to register this new certificate with any partners who do not automatically verify the entire certificate chain. Moving forward, you will sign all new requests with the new private key corresponding to the new certificate, while you can still verify signatures from the original private key using the corresponding public key. No revocation is necessary.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T16:16:42.199542"}}
{"question": "What is envelope encryption and how does it relate to key rotation in AWS CloudHSM?", "answer": "Envelope encryption is a key architecture where one key on the HSM encrypts and decrypts many data keys on the application host. In the context of AWS CloudHSM, if you already have a key rotation process in place, you would go through and decrypt the data keys with the old wrapping key and re-encrypt them with a new wrapping key. During migration, the new wrapping key will be created and used on AWS CloudHSM instead of your original HSM.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T16:16:42.200470"}}
{"question": "How does the key rotation process differ for private keys used for signing compared to symmetric keys used for envelope encryption?", "answer": "The key rotation process for private keys used for signing involves creating a new private key, generating a CSR, signing it with an offline enterprise root, and registering the new certificate if necessary. In contrast, the key rotation process for symmetric keys used for envelope encryption involves decrypting data keys with the old wrapping key and re-encrypting them with a new wrapping key. The key for envelope encryption is created and used on AWS CloudHSM, while for signing, the new private key corresponds to a newly issued certificate.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T16:16:42.200622"}}
{"question": "Will AWS notify users in advance about maintenance events?", "answer": "Yes, AWS will make every effort to notify users in advance about maintenance events using the Personal Health Dashboard if any impact is expected.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-04T16:16:45.810439"}}
{"question": "Why is it important to architect your cluster for high availability?", "answer": "It is important to architect your cluster for high availability because AWS may need to conduct maintenance due to necessary upgrades or faulty hardware, which can impact service availability.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-04T16:16:45.811068"}}
{"question": "What does AWS recommend regarding the use of CloudHSM Clusters?", "answer": "AWS recommends using CloudHSM Clusters with two or more HSMs in separate Availability Zones to ensure high availability.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-04T16:16:45.811477"}}
{"question": "What is AWS CloudShell and what does it allow users to do?", "answer": "AWS CloudShell is a browser-based shell that helps users securely manage, explore, and interact with their AWS resources. It allows users to quickly run scripts with the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, and use a variety of other tools to enhance productivity.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-04T16:16:52.195165"}}
{"question": "How does AWS CloudShell facilitate the automation of tasks and management of AWS services?", "answer": "AWS CloudShell facilitates automation and management by providing pre-installed tools such as the AWS CLI, Amazon ECS CLI, and AWS SAM CLI, which allow users to automate tasks, manage infrastructure, and interact with AWS services more efficiently. Additionally, users can clone, edit, and store commonly used scripts, further streamlining their workflows.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-04T16:16:52.195408"}}
{"question": "How does the storage capacity and cost structure of AWS CloudShell compare to other AWS services?", "answer": "AWS CloudShell provides users with 1 GB of persistent storage available in their home directory at no additional charge. Users only pay for other AWS resources they utilize while using CloudShell, without any minimum fees or upfront commitments. This cost structure allows for a pay-as-you-go model, which may differ from other AWS services that might have different pricing models or storage costs.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-04T16:16:52.195791"}}
{"question": "How can I upload files to my CloudShell instance?", "answer": "You can upload files to the home directory of your CloudShell instance through your browser from your local machine.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-04T16:16:59.477754"}}
{"question": "What are the main differences between CloudShell and Amazon EC2 Instance Connect?", "answer": "Amazon EC2 Instance Connect is most useful for connecting to existing EC2 instances via SSH, while CloudShell is primarily useful for running AWS CLI commands and general purpose scripting. Additionally, CloudShell does not require any resources in your account, whereas Cloud9, which is another tool, requires an EC2 instance in your account and incurs costs for that instance.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-04T16:16:59.478004"}}
{"question": "How does the cost structure of AWS Cloud9 differ from CloudShell?", "answer": "In AWS Cloud9, you are billed for the EC2 instance that runs your Cloud9 environment, while CloudShell can be used at no additional cost; you only pay for the AWS resources needed to run scripts and commands. Both services charge for data transfer at standard rates.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-04T16:16:59.478420"}}
{"question": "What is the default requirement for users to start a CloudShell session?", "answer": "By default, only users that have the Administrator or PowerUser role can start a CloudShell session.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:17:03.499186"}}
{"question": "How can users customize their CloudShell environment?", "answer": "Users can customize their CloudShell environment by checking out configuration files from a Git repository or by uploading them to their CloudShell environment. Additionally, they can customize the look of CloudShell by clicking the settings icon and selecting their desired theme and font size, with changes updating immediately.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:17:03.499996"}}
{"question": "What is the difference between software installed in the home directory and software installed outside of it in CloudShell?", "answer": "Software installed completely within the home directory in CloudShell will persist across sessions, meaning it does not need to be re-installed each time CloudShell is used. In contrast, software installed outside of the home directory does not persist across sessions.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T16:17:03.500315"}}
{"question": "Who can start a CloudShell session by default?", "answer": "Only users that have the Administrator or PowerUser role can start a CloudShell session by default. All other users must be granted permission from an administrator in order to start a CloudShell session.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-04T16:17:09.290627"}}
{"question": "What happens to files stored in your home directory in CloudShell after 120 days?", "answer": "Files stored in your home directory ($HOME) in CloudShell will be preserved for up to 120 days from the last time you initiated a CloudShell session. This limit applies on a regional basis, and if you use CloudShell in multiple Regions, each Region has a separate timer that begins when your last CloudShell session was closed per Region.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-04T16:17:09.290991"}}
{"question": "How does the access to CloudShell differ for users with IAM administrator permissions compared to regular users?", "answer": "Users with IAM administrator permissions can grant access to CloudShell to other users, whereas only users with the Administrator or PowerUser role can start a CloudShell session by default. Regular users must receive explicit permission from an administrator to start a CloudShell session.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-04T16:17:09.291325"}}
{"question": "Does the CloudShell retention policy apply globally or regionally?", "answer": "The CloudShell retention policy applies on a regional basis. Each Region has its own timer associated with your storage.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-04T16:17:13.076321"}}
{"question": "How will users be informed about the deletion of their CloudShell data?", "answer": "Users will be notified via the personal health dashboard before their CloudShell data is deleted.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-04T16:17:13.076679"}}
{"question": "Are the CloudShell retention policies the same across all AWS Regions?", "answer": "No, the CloudShell retention policies are not the same across all AWS Regions, as each Region has its own timer associated with your storage.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-04T16:17:13.077082"}}
{"question": "What is the primary purpose of AWS CloudTrail?", "answer": "The primary purpose of AWS CloudTrail is to enable auditing, security monitoring, and operational troubleshooting by tracking user activity and API usage. It logs, continuously monitors, and retains account activity related to actions across your AWS infrastructure.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:17:19.271013"}}
{"question": "How does CloudTrail help improve security posture and compliance?", "answer": "CloudTrail helps improve security posture and compliance by providing visibility into user activity, recording actions taken on your account, and tracking changes made to your AWS resources. This information assists in proving compliance, consolidating activity records across Regions and accounts, and ensuring adherence to internal policies and regulatory standards.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:17:19.272250"}}
{"question": "In what ways does CloudTrail contribute to operational troubleshooting compared to security monitoring?", "answer": "CloudTrail contributes to operational troubleshooting by tracking user activity and API usage, which helps identify and resolve operational issues. In contrast, for security monitoring, CloudTrail provides insights into user actions and helps detect potential security breaches. Both functions are crucial, but troubleshooting focuses more on resolving issues while security monitoring emphasizes preventing unauthorized access.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:17:19.272607"}}
{"question": "What is required to begin viewing account activity in AWS CloudTrail?", "answer": "Nothing is required to begin viewing your account activity. You can visit the AWS CloudTrail console or AWS CLI and begin viewing up to the past 90 days of account activity.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:17:25.450513"}}
{"question": "What types of events does AWS CloudTrail show in its Event history?", "answer": "AWS CloudTrail shows management events that create, modify, and delete API calls and account activity in its Event history for the current Region you are viewing for the last 90 days.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:17:25.450901"}}
{"question": "How does viewing account activity differ when using CloudTrail Event History versus a configured CloudTrail trail?", "answer": "CloudTrail Event History allows you to view account activity for the last 90 days but is limited to management events. In contrast, a configured CloudTrail trail provides a complete record of account activity, including management events, data events, and read-only activity, and can deliver these events to Amazon S3, CloudWatch Logs, and CloudWatch Events for archiving and analysis.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T16:17:25.451130"}}
{"question": "What types of clients can make API calls that are recorded by CloudTrail?", "answer": "CloudTrail records API calls made from any client, including the AWS Management Console, AWS SDKs, command line tools, and higher-level AWS services.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T16:17:31.685374"}}
{"question": "What does it mean to apply a trail to all AWS Regions?", "answer": "Applying a trail to all AWS Regions means creating a trail that records AWS account activity across all Regions where your data is stored. This setting also applies to any new Regions that may be added in the future.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T16:17:31.685735"}}
{"question": "How does CloudTrail handle log files for services with Regional endpoints compared to services with single endpoints?", "answer": "For services with Regional endpoints, such as Amazon EC2 and Amazon RDS, activity information is captured and processed in the same Region as the action is made, then delivered to the Region associated with your S3 bucket. In contrast, for services with single endpoints, like IAM and AWS STS, the activity information is captured in the Region where the endpoint is located, processed in the Region where the CloudTrail trail is configured, and then delivered to the Region associated with your S3 bucket.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T16:17:31.685968"}}
{"question": "How long does it typically take to replicate the trail configuration to all Regions?", "answer": "It typically takes less than 30 seconds to replicate the trail configuration to all Regions.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T16:17:36.472816"}}
{"question": "What are the benefits of having multiple trails in AWS CloudTrail?", "answer": "Having multiple trails allows different stakeholders, such as security administrators, software developers, and IT auditors, to create and manage their own trails. For example, a security administrator can create a trail that applies to all Regions and configure encryption using one Amazon Key Management Service (Amazon KMS) key, while a developer can create a trail that applies to one Region for troubleshooting operational issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T16:17:36.473562"}}
{"question": "How does a trail that applies to all Regions differ from a trail that applies to a single Region in terms of counting towards the limit of trails?", "answer": "A trail that applies to all Regions exists in each Region and is counted as one trail in each Region, while you can create up to five trails in a Region. Therefore, a single trail that applies to all Regions counts as multiple trails towards the limit, as it is present in each Region.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T16:17:36.473809"}}
{"question": "What information does an event contain in CloudTrail?", "answer": "An event in CloudTrail contains information about the associated activity, including who made the request, the services used, the actions performed, the parameters for the action, and the response elements returned by the AWS service.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:17:42.787415"}}
{"question": "How do data events differ from management events in CloudTrail?", "answer": "Data events provide insights into the resource operations performed on or within the resource itself and often involve high-volume activities, such as S3 object level API operations and AWS Lambda function invokes. In contrast, management events typically involve management operations. Additionally, data events are deactivated by default and incur additional costs when enabled, whereas management events do not have these same cost implications.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:17:42.787772"}}
{"question": "What happens if the S3 bucket policies are misconfigured in relation to CloudTrail log file delivery?", "answer": "If the S3 bucket policies are misconfigured, CloudTrail will not be able to deliver log files to the bucket, as log files are delivered in accordance with the bucket policies in place.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:17:42.788247"}}
{"question": "What do S3 data events represent in AWS?", "answer": "S3 data events represent API activity on S3 Objects. They record any API actions performed on the Objects within a specified S3 bucket when CloudTrail is configured appropriately.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-04T16:17:46.354396"}}
{"question": "How can you enable logging for Lambda data events in AWS?", "answer": "You can enable logging for Lambda data events using the CLI or CloudTrail console. This involves selecting which Lambda functions to log by creating a new trail or editing an existing trail.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-04T16:17:46.355659"}}
{"question": "How do network activity events differ from S3 and Lambda data events in terms of delivery?", "answer": "Network activity events are only delivered to the owner of the VPC endpoint, while S3 and Lambda data events are delivered to both the API caller and the owner of the resource. This distinction affects who can access the logs of the recorded events.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-04T16:17:46.356120"}}
{"question": "What locations can VPC Flow Logs data be published to?", "answer": "VPC Flow Logs data can be published to Amazon CloudWatch Logs, Amazon S3, or Amazon Data Firehose.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-04T16:17:50.768362"}}
{"question": "How do CloudTrail Insights events help in monitoring AWS accounts?", "answer": "CloudTrail Insights events help identify unusual activity in AWS accounts, such as spikes in resource provisioning, bursts of IAM actions, or gaps in periodic maintenance activity. It uses machine learning models to monitor CloudTrail write management events for abnormal activity.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-04T16:17:50.768710"}}
{"question": "What is the difference between the management account and delegated administrator accounts in terms of organization trails in CloudTrail?", "answer": "The management account remains the owner of any organization trails or event datastores created at the organization level, regardless of whether they were created by a delegated admin account or by the management account itself.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-04T16:17:50.769140"}}
{"question": "What does CloudTrail Insights do?", "answer": "CloudTrail Insights detects unusual activity by analyzing CloudTrail write management events within an AWS account and a Region. It identifies unusual or abnormal events as those where the volume of AWS API calls deviates from previously established operating patterns or baselines.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T16:17:55.169513"}}
{"question": "How does CloudTrail Insights adapt to changes in normal operating patterns?", "answer": "CloudTrail Insights adapts to changes in normal operating patterns by considering time-based trends in API calls and applying adaptive baselines as workloads change. This allows it to effectively monitor for unusual activity even as operational patterns evolve.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T16:17:55.169901"}}
{"question": "How does the function of CloudTrail Insights compare to Amazon GuardDuty and Amazon Macie?", "answer": "CloudTrail Insights focuses on detecting unusual operational activity and helps address operational issues, while Amazon GuardDuty is aimed at improving security by providing threat detection through monitoring account activity. Amazon Macie, on the other hand, is designed for data protection by discovering, classifying, and protecting sensitive data. Together, these services offer complementary protections against different types of problems in an AWS account.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T16:17:55.170129"}}
{"question": "What is the primary function of CloudTrail Lake?", "answer": "The primary function of CloudTrail Lake is to help examine incidents by querying all actions logged by CloudTrail, configuration items recorded by AWS Config, evidence from Audit Manager, or events from non-AWS sources. It simplifies incident logging and aids in incident investigation by providing tools to reduce reliance on complex data process pipelines.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-04T16:17:59.939671"}}
{"question": "How does CloudTrail Lake enhance the process of querying logs for users who are less experienced with SQL?", "answer": "CloudTrail Lake enhances the querying process for users less experienced with SQL by providing natural language query generation. This feature helps users create SQL queries more easily, simplifying data analysis.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-04T16:17:59.939951"}}
{"question": "How does the logging and querying process differ between CloudTrail and CloudTrail Lake?", "answer": "CloudTrail is the canonical source of logs for user activity and API usage across AWS services, while CloudTrail Lake allows for the examination and querying of those logs once they are available in CloudTrail. CloudTrail Lake simplifies incident logging and analysis by not requiring the movement and ingestion of logs elsewhere, thus maintaining data fidelity and providing real-time processing capabilities.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-04T16:17:59.940339"}}
{"question": "What is AWS Config advanced query used for?", "answer": "AWS Config advanced query is used to aggregate and query on the current state of AWS Config configuration items (CI). It assists customers with inventory management, security and operational intelligence, cost optimization, and compliance data.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-04T16:18:04.696124"}}
{"question": "How does CloudTrail Lake support AWS Config configuration items?", "answer": "CloudTrail Lake supports AWS Config configuration items by providing query coverage for them, including resource configuration and compliance history. Analyzing this data alongside related CloudTrail events helps infer who made changes, when changes occurred, and what specifically changed on those resources, which aids in root-cause analysis for incidents related to security exposure or non-compliance.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-04T16:18:04.696437"}}
{"question": "What happens if multiple configuration changes are attempted on a single resource by different users in quick succession, and how does this affect querying?", "answer": "If multiple configuration changes are attempted on a single resource by different users in quick succession, only one configuration item may be created that maps to the end state configuration of the resource. This scenario may hinder the ability to provide 100% correlation on which user made what configuration changes when querying CloudTrail and configuration items for a specific time range and resource ID.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-04T16:18:04.696965"}}
{"question": "What are some common use cases for AWS CloudTrail?", "answer": "Common use cases for AWS CloudTrail include investigating security incidents, such as unauthorized access or compromised user credentials, and enhancing your security posture by performing audits to regularly baseline user permissions. Additionally, you can track actions taken on your resources and assess modifications or deletions, as well as get deeper insights on your AWS services bills including the IAM users subscribing to services.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-04T16:18:11.086560"}}
{"question": "How does the CloudTrail Lake capability enhance the querying of event data?", "answer": "The CloudTrail Lake capability enhances the querying of event data by allowing users to run queries on event data stores through the API or the CloudTrail console. Users can create event data stores, choose pricing options, select event categories to log, and utilize enhanced event filtering capabilities. For those less familiar with SQL, natural language query generation is available to help create SQL queries, and query results can be summarized using generative AI, further improving insight derivation from CloudTrail data.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-04T16:18:11.086957"}}
{"question": "What options do users have for visualizing their CloudTrail Lake data?", "answer": "Users have the option to visualize their CloudTrail Lake data using pre-curated dashboards available directly within the CloudTrail console, which provide out-of-the-box visibility and key insights from audit and security data. Additionally, users can create custom dashboards tailored to their specific needs for more targeted monitoring and analysis.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-04T16:18:11.087375"}}
{"question": "Can I update the pricing option for my event data store from seven-year retention to one-year extendable retention pricing?", "answer": "Yes, you can update the pricing option from seven-year retention pricing to one-year extendable retention pricing as part of the event data store configuration. Your existing data will remain available in the event data store for the configured retention period without incurring any extended retention charges.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T16:18:17.395468"}}
{"question": "What is the purpose of CloudTrail Lake?", "answer": "CloudTrail Lake is an audit lake that helps customers meet their use case needs around compliance and auditing. It allows customers to retain audit logs for a specified duration based on their compliance program mandates, regardless of when the logs were ingested into CloudTrail Lake.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T16:18:17.395791"}}
{"question": "How does the retention period of events in CloudTrail Lake compare for historical events versus newly ingested events?", "answer": "Historical events in CloudTrail Lake are retained for a period of 1 year starting from the event-time, which means they may be stored for less than 1 year if the event-time is in the past. In contrast, newly ingested data will follow the configured retention period of the event data store, which can vary based on the selected pricing option.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T16:18:17.396231"}}
{"question": "What kind of dashboards does CloudTrail Lake offer for security monitoring?", "answer": "CloudTrail Lake offers the 'Security Monitoring Dashboard' for security monitoring, which helps track critical security events such as access denied events, failed login attempts, and destructive actions.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-04T16:18:22.109465"}}
{"question": "How does the 'IAM Activity Dashboard' support compliance efforts?", "answer": "The 'IAM Activity Dashboard' supports compliance efforts by providing visibility into changes to IAM entities, helping organizations identify unintended IAM actions and potential compliance issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-04T16:18:22.109818"}}
{"question": "What are the differences between the 'Error Analysis Dashboard' and the 'Resource Changes Dashboard'?", "answer": "The 'Error Analysis Dashboard' is focused on identifying and troubleshooting service throttling errors and other operational issues across services, while the 'Resource Changes Dashboard' provides visibility into trends in provisioning, deletion, and modifications of AWS resources, including changes made through CloudFormation and manually.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-04T16:18:22.110209"}}
{"question": "What feature allows you to enrich CloudTrail events with resource tags on AWS Resources?", "answer": "You can enrich CloudTrail events with resource tags on AWS Resources by incorporating your organization's resource tagging strategy into your CloudTrail events, which helps categorize and analyze AWS activities in the context of your business operations, projects, or departments.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-04T16:18:27.894644"}}
{"question": "How do IAM Global Condition Keys enhance the information included in CloudTrail events?", "answer": "IAM Global Condition Keys enhance CloudTrail events by including information about AWS condition keys that were evaluated during the authorization process. This includes details about the principal making the request and specifics about the request itself, such as the aws:SourceAccount for API calls made directly by an AWS service principal.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-04T16:18:27.895018"}}
{"question": "How does enriching CloudTrail events with resource tags compare to using IAM Global Condition Keys?", "answer": "Enriching CloudTrail events with resource tags allows for categorization and analysis based on your organization's tagging strategy, making it easier to view events related to specific resources like production S3 buckets. In contrast, using IAM Global Condition Keys provides additional context about the authorization process and the principal making the request, which includes specific keys evaluated during authorization. Both methods enhance the information available in CloudTrail events but focus on different aspects: resource management versus authorization context.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-04T16:18:27.895482"}}
{"question": "How does CloudTrail update AWS resource tags information?", "answer": "CloudTrail updates AWS resource tags information on a best-effort basis using the Resource Groups Tagging API (RGTA). However, if tag information is not available to CloudTrail at the time an AWS API call is made, it will not be included in the corresponding CloudTrail event.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T16:18:32.745921"}}
{"question": "What does it mean when CloudTrail events are delayed due to a service issue?", "answer": "When CloudTrail events are delayed due to a service issue, it means that CloudTrail could not retrieve the resource tag information in time. Such delayed events will include an 'addendum' field that provides information about the reason for the delay.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T16:18:32.746278"}}
{"question": "What is the relationship between IAM global condition keys and CloudTrail events?", "answer": "IAM global condition keys, including Principal Tags, are updated in CloudTrail events as API actions are authorized. However, a global condition key will only be included in an event if it was evaluated as part of the IAM policy during the authorization process. Therefore, just configuring CloudTrail to include a condition key does not guarantee its presence in every event.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-04T16:18:32.746722"}}
{"question": "Can multiple accounts configure one S3 bucket as a destination for their logs?", "answer": "Yes, you can configure one S3 bucket as the destination for multiple accounts.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-04T16:18:37.542248"}}
{"question": "What are the benefits of integrating CloudTrail with CloudWatch Logs?", "answer": "The integration of CloudTrail with CloudWatch Logs allows you to receive SNS notifications of account activity captured by CloudTrail. It also enables you to create CloudWatch alarms to monitor API calls that create, modify, and delete Security Groups and Network access control lists (ACLs).", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-04T16:18:37.542533"}}
{"question": "How does the delivery of account activity to CloudWatch Logs compare to the delivery of logs to an S3 bucket?", "answer": "After you turn on the CloudTrail integration with CloudWatch Logs, CloudTrail continually delivers account activity to a CloudWatch Logs log stream in the specified log group, while it continues to deliver logs to your S3 bucket as before. Both methods ensure that you receive account activity logs, but they serve different purposes and can be used in conjunction.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-04T16:18:37.542714"}}
{"question": "What permissions must your application have when using SSE-KMS for S3 log file decryption?", "answer": "Your application must have appropriate permissions such as S3 GetObject and AWS KMS Decrypt permissions when using SSE-KMS for S3 log file decryption.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-04T16:18:42.041665"}}
{"question": "How does the CloudTrail log file integrity validation feature assist in IT security and auditing processes?", "answer": "The CloudTrail log file integrity validation feature helps you determine whether a CloudTrail log file was unchanged, deleted, or modified since CloudTrail delivered it to the specified S3 bucket, thus aiding in IT security and auditing processes.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-04T16:18:42.042858"}}
{"question": "How are the digest files related to the log files in terms of delivery and storage?", "answer": "The digest files are delivered to the same S3 bucket where your log files are delivered, but they are stored in a different folder. This separation allows you to enforce granular access control policies on the digest files.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-04T16:18:42.043103"}}
{"question": "What is the purpose of the CloudTrail Processing Library?", "answer": "The CloudTrail Processing Library is a Java library that makes it easier to build an application that reads and processes CloudTrail log files.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-04T16:18:46.753833"}}
{"question": "How do charges apply when using CloudTrail to deliver management events to S3?", "answer": "The first copy of management events is delivered free of charge in each Region. However, you will incur S3 charges based on your usage once a CloudTrail trail is set up. Additionally, you will be charged for data events, network activity events, and extra copies of management events beyond the first copy.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-04T16:18:46.754123"}}
{"question": "How does the pricing for CloudTrail Lake differ from the pricing for standard CloudTrail usage?", "answer": "In CloudTrail Lake, you pay for ingestion and storage together, with billing based on the amount of uncompressed data ingested and the amount of compressed data stored. In contrast, for standard CloudTrail usage, the first copy of management events is free, while you are charged for data events, network activity events, and additional copies of management events.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-04T16:18:46.754640"}}
{"question": "What features do the integrated solutions for analyzing CloudTrail log files include?", "answer": "The integrated solutions for analyzing CloudTrail log files include features like change tracking, troubleshooting, and security analysis.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-04T16:18:51.668996"}}
{"question": "How can I get assistance for integrating with CloudTrail?", "answer": "To get assistance for integrating with CloudTrail, you can review the Partner Onboarding Guide, engage with your partner development team, or partner solutions architect to connect with the CloudTrail Lake team for a deeper dive or further questions.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-04T16:18:51.669222"}}
{"question": "Does turning on CloudTrail affect the performance of AWS resources or API call latency?", "answer": "No, turning on CloudTrail has no impact on performance for your AWS resources or API call latency.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-04T16:18:51.669449"}}
{"question": "What is Amazon CloudWatch used for?", "answer": "Amazon CloudWatch is an AWS monitoring service that is used to collect and track metrics, monitor log files, and set alarms for cloud resources and the applications running on AWS. It can monitor AWS resources like Amazon EC2 instances, Amazon DynamoDB tables, and Amazon RDS DB instances, as well as custom metrics generated by applications and services, and log files from on-premises, hybrid, or other cloud environments.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T16:18:56.457313"}}
{"question": "How does Amazon CloudWatch help in application performance management?", "answer": "Amazon CloudWatch helps in application performance management by providing system-wide visibility into resource utilization, application performance, and operational health. This allows users to gain insights that can be used to react promptly and maintain the smooth running of their applications.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T16:18:56.457721"}}
{"question": "In what ways can Amazon CloudWatch be accessed by users?", "answer": "Amazon CloudWatch can be accessed via API, command-line interface, AWS SDKs, and the AWS Management Console.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T16:18:56.457899"}}
{"question": "What is the purpose of integrating Amazon CloudWatch with AWS Identity and Access Management (IAM)?", "answer": "The integration of Amazon CloudWatch with AWS Identity and Access Management (IAM) allows you to specify which CloudWatch actions a user in your AWS Account can perform. For example, you can create an IAM policy that gives certain users permission to use actions like GetMetricStatistics to retrieve data about cloud resources.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-04T16:19:02.516942"}}
{"question": "How does Amazon CloudWatch Logs assist in monitoring systems and applications?", "answer": "Amazon CloudWatch Logs assists in monitoring systems and applications by allowing you to monitor your existing system, application, and custom log files in near real time for specific phrases, values, or patterns. You can set alarms based on log data, view graphs of metrics like latency, and access the original log data to troubleshoot issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-04T16:19:02.517263"}}
{"question": "What limitations exist regarding IAM's control over CloudWatch data access?", "answer": "The limitations regarding IAM's control over CloudWatch data access include that you cannot specify IAM permissions for access to CloudWatch data for specific resources. This means you cannot grant a user access to CloudWatch data for only certain instances or a specific LoadBalancer; permissions granted using IAM cover all cloud resources used with CloudWatch.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-04T16:19:02.517685"}}
{"question": "What is the primary purpose of CloudWatch Logs?", "answer": "The primary purpose of CloudWatch Logs is to monitor and store logs to help users better understand and operate their systems and applications.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T16:19:07.038273"}}
{"question": "How does CloudWatch Logs assist in real-time application monitoring?", "answer": "CloudWatch Logs assists in real-time application monitoring by tracking the number of errors that occur in application logs and sending notifications whenever the rate of errors exceeds a specified threshold. This monitoring is done using log data without requiring any code changes.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T16:19:07.038621"}}
{"question": "How does the CloudWatch Logs Agent compare to CloudWatch Logs Insights in terms of functionality?", "answer": "The CloudWatch Logs Agent is primarily designed for monitoring individual log files on the host and moving log data to the log service, while CloudWatch Logs Insights is an interactive log analytics capability that enables users to search, visualize, and analyze their logs for insights. Logs Insights focuses on log analytics and visualization, whereas the Logs Agent focuses on log data collection and management.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T16:19:07.039043"}}
{"question": "What is required to start using Logs Insights with CloudWatch Logs?", "answer": "You can immediately start using Logs Insights to run queries on all your logs being sent to CloudWatch Logs with no setup required and no infrastructure to manage.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-04T16:19:12.037841"}}
{"question": "How does Amazon CloudWatch Anomaly Detection help in monitoring metrics?", "answer": "Amazon CloudWatch Anomaly Detection applies machine-learning algorithms to continuously analyze single time series of systems and applications, determine a normal baseline, and surface anomalies with minimal user intervention. It allows you to create alarms that auto-adjust thresholds based on natural metric patterns and visualize metrics with anomaly detection bands on dashboards.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-04T16:19:12.038510"}}
{"question": "How does Contributor Insights differ from Anomaly Detection in CloudWatch?", "answer": "Contributor Insights analyzes time-series data to provide a view of the top contributors influencing system performance, while Anomaly Detection focuses on identifying anomalies in metrics based on machine-learning algorithms that analyze time series. Contributor Insights runs continuously without additional user intervention, whereas Anomaly Detection automatically adjusts thresholds and visualizes expected values.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-04T16:19:12.038761"}}
{"question": "How often does Amazon CloudWatch Synthetics run tests on application endpoints?", "answer": "Amazon CloudWatch Synthetics runs tests on your application endpoints every minute, 24x7.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-4", "source_tokens": 315, "generated_at": "2026-02-04T16:19:17.124204"}}
{"question": "What types of checks can be customized in Amazon CloudWatch Synthetics?", "answer": "In Amazon CloudWatch Synthetics, you can customize checks for availability, latency, transactions, broken or dead links, step by step task completions, page load errors, load latencies for UI assets, complex wizard flows, or checkout flows in your applications.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-4", "source_tokens": 315, "generated_at": "2026-02-04T16:19:17.124690"}}
{"question": "What is the difference between standard Amazon EC2 monitoring and EC2 Detailed Monitoring in relation to CloudWatch?", "answer": "All Amazon EC2 instance types automatically send key health and performance metrics to CloudWatch at no cost. However, if you enable EC2 Detailed Monitoring, you will be charged for custom metrics based on the number of metrics sent to CloudWatch for the instance. The number of metrics sent depends on the instance type.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-4", "source_tokens": 315, "generated_at": "2026-02-04T16:19:17.125007"}}
{"question": "What changes were made to the billing structure of CloudWatch charges prior to July 2017?", "answer": "Prior to July 2017, charges for CloudWatch Alarms, CloudWatch Metrics, and CloudWatch API usage were reported under the 'Elastic Compute Cloud' (EC2) detail section of the AWS bill, while charges for CloudWatch Logs and CloudWatch Dashboards were reported under the 'CloudWatch' detail section. After the changes, all CloudWatch monitoring charges, including Metrics, Alarms, and API usage, were moved to the 'CloudWatch' section of the bill, consolidating them under a single section.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-04T16:19:23.634319"}}
{"question": "How does the Billing Metric 'Estimated Charges' change after the consolidation of CloudWatch charges?", "answer": "The 'Total Estimated Charge' metric will not change; however, the 'EstimatedCharges' metric broken down by Service will change for the dimension ServiceName equal to 'AmazonEC2' and dimension ServiceName equal to 'AmazonCloudWatch'. As a result of the billing consolidation, you may see a decrease in your AmazonEC2 billing metric and an increase in your AmazonCloudWatch billing metric as usage and billing charges are moved from EC2 to CloudWatch.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-04T16:19:23.634706"}}
{"question": "What is the difference in charges for queries in CloudWatch Logs Insights based on their status?", "answer": "You are charged for the amount of ingested log data scanned by a query in CloudWatch Logs Insights if you cancel the query manually up to the point at which it was cancelled. However, you are not charged for failed queries.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-04T16:19:23.635128"}}
{"question": "What is the primary function of cross-account observability in CloudWatch?", "answer": "The primary function of cross-account observability in CloudWatch is to monitor and troubleshoot applications that span across multiple accounts within a Region. It allows users to search, visualize, and analyze their metrics, logs, and traces without worrying about account boundaries.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-04T16:19:30.254125"}}
{"question": "How does cross-account observability improve the troubleshooting process in CloudWatch?", "answer": "Cross-account observability improves the troubleshooting process by providing seamless cross-account data access and navigation, which reduces the manual effort required to troubleshoot issues and saves valuable time in resolution. It allows users to start with an aggregated view of their application to identify resources exhibiting errors and dive deep into related traces, metrics, and logs for root cause analysis.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-04T16:19:30.255599"}}
{"question": "What are the differences between a monitoring account and a source account in the context of cross-account observability?", "answer": "A monitoring account is a central AWS account that can view and interact with observability data generated across other accounts, while a source account is an individual AWS account that generates observability data for the resources that reside in it. The monitoring account aggregates data from multiple source accounts to provide a comprehensive view of application health and performance.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-04T16:19:30.255908"}}
{"question": "What capabilities does cross-account observability provide in Amazon CloudWatch?", "answer": "Cross-account observability in Amazon CloudWatch allows users to search for log groups across multiple accounts from a central view, run cross-account Logs Insights queries, perform Live Tail analytics, and create Contributor Insights rules to identify top-N contributors generating log entries. It also enables metrics search for visualizing metrics from various accounts, creating alarms for metrics evaluation, and setting up a cross-account metric stream. Additionally, users can view an interactive map of cross-account applications using ServiceLens with one-step drill downs to relevant metrics, logs, and traces.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-04T16:19:36.845109"}}
{"question": "How does cross-account observability enhance monitoring in AWS environments?", "answer": "Cross-account observability enhances monitoring in AWS environments by providing a centralized view of logs and metrics across multiple accounts, allowing for comprehensive analysis and visualization. It enables users to identify trends and anomalies through alarms and dashboards, facilitates quick access to relevant metrics and logs for troubleshooting, and leverages the Observability Access Manager API to manage access policies efficiently. This approach leads to a more integrated and effective monitoring experience across various AWS accounts.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-04T16:19:36.845465"}}
{"question": "What is the difference between cross-account observability and the cross-account, cross-Region feature in CloudWatch?", "answer": "The difference between cross-account observability and the cross-account, cross-Region feature in CloudWatch is that cross-account observability allows users to view logs and metrics across multiple accounts in a single AWS Region at a time, while the cross-account, cross-Region feature provides organization-wide telemetry access through IAM roles across different regions. Additionally, when cross-account observability is set up, the cross-account, cross-Region drop-down menus are removed from the console.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-04T16:19:36.845935"}}
{"question": "How can you enable Application Signals in AWS?", "answer": "You can turn on Application Signals in the AWS Management Console for CloudWatch or when enabling CloudWatch on AWS resources, such as Amazon EKS clusters.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-04T16:19:40.910974"}}
{"question": "What is the purpose of defining service level objectives (SLOs) in Amazon CloudWatch Application Signals?", "answer": "Defining service level objectives (SLOs) allows customers to reflect the business impact and importance of application services, their APIs and dependencies on standard application metrics, real-user or synthetic monitors.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-04T16:19:40.911324"}}
{"question": "How does Amazon CloudWatch Application Signals support monitoring of application services compared to traditional monitoring methods?", "answer": "Amazon CloudWatch Application Signals discovers application services and generates a standard set of application metrics for volume, latency, errors, and faults. It provides new application-centric observability views that summarize application health against SLOs, allowing for a more comprehensive understanding compared to traditional monitoring methods.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-04T16:19:40.911812"}}
{"question": "What is the purpose of Application Signals in AWS?", "answer": "The purpose of Application Signals in AWS is to provide an integrated application performance monitoring experience. It allows users to automatically collect and correlate application telemetry, prioritize business critical applications, and leverage alarms, traces, and events data to take automated actions, ultimately reducing the mean time to recover (MTTR) from issues.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-04T16:19:45.455547"}}
{"question": "How do Application Signals enhance the management of critical applications?", "answer": "Application Signals enhance the management of critical applications by allowing users to create, measure, and track Service Level Objectives (SLOs) that align with business and operational Key Performance Indicators (KPIs). This helps improve availability, decrease downtime, and enable a consistent customer experience.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-04T16:19:45.455898"}}
{"question": "How does Application Signals differ in monitoring applications on Amazon EKS compared to other environments?", "answer": "Application Signals differs in monitoring applications on Amazon EKS by allowing users to enable the service directly in the CloudWatch console without manual configurations. In contrast, for other application environments, users must quickly deploy the CloudWatch Agent to start monitoring their applications.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-04T16:19:45.456356"}}
{"question": "What does CloudWatch Application Insights help monitor?", "answer": "CloudWatch Application Insights helps you monitor your applications that use Amazon EC2 instances along with other application resources.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:19:50.257653"}}
{"question": "How does Amazon CloudWatch Application Signals enhance observability for applications?", "answer": "Amazon CloudWatch Application Signals enhances observability by providing standardized application metrics and application-centric views in the AWS Management Console, allowing users to start without writing custom instrumentation. It summarizes application health to determine business impact and prioritize issues, while also offering a drill down to establish root cause quickly.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:19:50.258034"}}
{"question": "How do the functionalities of CloudWatch Application Insights and X-Ray differ in terms of monitoring applications?", "answer": "CloudWatch Application Insights focuses on monitoring applications by identifying key metrics, logs, and alarms, and generating CloudWatch Events for notifications and actions, along with automated dashboards for troubleshooting. In contrast, X-Ray provides an end-to-end view of requests in distributed applications, creating service maps to show connections and dependency trees, identifying errors, and allowing the building of custom analysis and visualization apps.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-04T16:19:50.258606"}}
{"question": "What is the purpose of the X-Ray Daemon in the AWS X-Ray service?", "answer": "The X-Ray Daemon is a service that collects traces and sends them to X-Ray, simplifying the process compared to direct API usage.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-04T16:19:55.024442"}}
{"question": "How does AWS X-Ray handle data collection for performance and cost-effectiveness?", "answer": "AWS X-Ray collects data for a statistically significant number of requests, rather than capturing data for every single request, in order to maintain performance and cost-effectiveness.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-04T16:19:55.024822"}}
{"question": "What are the differences in setup requirements for using X-Ray with Elastic Beanstalk compared to EC2 or ECS?", "answer": "For Elastic Beanstalk, you need to include the language-specific X-Ray libraries in your application code, whereas for applications running on EC2 or ECS, you will need to install the X-Ray daemon and instrument your application code.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-04T16:19:55.025045"}}
{"question": "What types of events does X-Ray log?", "answer": "X-Ray logs all API calls as management events and calls on traces as data events, including on PutTraceSegments and GetTimeSeriesServiceStatistics among other APIs.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-04T16:19:59.884558"}}
{"question": "How does Container Insights help in monitoring containerized applications and microservices?", "answer": "Container Insights collects, aggregates, and summarizes metrics and logs from containerized applications and microservices, providing container metrics such as CPU, memory, disk, and network metrics. It also delivers deeper diagnostic information like container restart failures, helping users isolate issues quickly. Additionally, it offers automatic dashboards for monitoring application health and performance, and users can set CloudWatch alarms on metrics to be notified of anomalies.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-04T16:19:59.885127"}}
{"question": "What is the difference between standard Container Insights and Container Insights with enhanced observability?", "answer": "Standard Container Insights provides basic metrics and logging, while Container Insights with enhanced observability delivers detailed metrics such as container-level ECS and EKS performance metrics, EKS Kube-state metrics, and EKS control plane metrics. Enhanced observability allows users to visually drill down across various container layers to spot issues, and it provides a list of container layers consuming high levels of resources for proactive risk identification.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-04T16:19:59.885359"}}
{"question": "What is the purpose of using Container Insights with enhanced observability?", "answer": "The purpose of using Container Insights with enhanced observability is to enable you to visually drill up and down across your Amazon EKS and Amazon ECS container layers, allowing you to easily spot issues like memory leaks in individual containers, which reduces the mean time to resolution.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-04T16:20:05.770304"}}
{"question": "How does enhanced observability differ from standard Container Insights?", "answer": "Enhanced observability provides out-of-the-box detailed health and performance metrics, including container-level ECS and EKS performance metrics, EKS Kube-state metrics, and EKS control plane metrics for faster problem isolation and troubleshooting. In contrast, standard Container Insights provides aggregated metrics at the cluster and service levels.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-04T16:20:05.770730"}}
{"question": "Can you enable Container Insights with enhanced observability for both EKS and ECS, and how do the methods differ?", "answer": "Yes, you can enable Container Insights with enhanced observability for both EKS and ECS. For EKS, you enable it by installing the CloudWatch Observability add-on in your clusters after they are created using the add-ons tab in your cluster info view. In contrast, for ECS, you can toggle Enhanced under the Monitoring Tab in the cluster create workflow or update your existing clusters to do the same. Additionally, you can onboard enhanced observability at the account level in ECS, which will enable any new clusters under that account to onboard Container Insights with enhanced observability out-of-the-box.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-04T16:20:05.771151"}}
{"question": "What are the current metric types supported by Container Insights?", "answer": "The current metric types supported by Container Insights are Gauge and Counters. Histogram and Summary metrics are planned for an upcoming release.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-04T16:20:10.793829"}}
{"question": "How does integrating Prometheus with CloudWatch benefit DevOps teams?", "answer": "Integrating Prometheus with CloudWatch allows DevOps teams to automatically discover services for containerized workloads, expose custom metrics, and ingest those metrics in CloudWatch. This helps them monitor, troubleshoot, and alarm on application performance degradation and failures faster while reducing the number of monitoring tools required.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-04T16:20:10.794411"}}
{"question": "How does the retention period for Prometheus metrics compare to that of Kubernetes log groups?", "answer": "The retention period for Prometheus metrics is 15 months per metric data point with automatic roll up, while each Kubernetes cluster has its own log group with a configurable retention period. The specifics of the retention for Kubernetes log groups are not detailed in the provided context.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-04T16:20:10.794625"}}
{"question": "What types of databases are supported by CloudWatch Database Insights?", "answer": "CloudWatch Database Insights is available for Amazon Aurora and RDS databases.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T16:20:14.771767"}}
{"question": "How does CloudWatch Database Insights assist application developers in monitoring their applications?", "answer": "Application developers can correlate the impact of database dependencies with the performance and availability of their business-critical applications by drilling down from the context of their application performance view in CloudWatch Application Signals to the specific dependent database in CloudWatch Database Insights.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T16:20:14.772120"}}
{"question": "How does CloudWatch Database Insights differ from RDS Performance Insights in terms of data visibility?", "answer": "CloudWatch Database Insights provides fleet-level views and the ability to monitor health and performance across multiple databases, while RDS Performance Insights focuses on assessing the load on databases one instance at a time with a pre-built dashboard.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T16:20:14.772343"}}
{"question": "What does Amazon CloudWatch Internet Monitor help you to do?", "answer": "Amazon CloudWatch Internet Monitor helps you to continually monitor internet availability and performance metrics between your AWS-hosted applications and application end users. It allows you to visualize the impact of issues, pinpoint affected locations and providers, and take action to improve end users' network experience.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:20:20.215273"}}
{"question": "How does Internet Monitor assist in improving the network experience for end users?", "answer": "Internet Monitor provides insights and recommendations that can help improve users' experience by using other AWS services. It also offers a global view of traffic patterns and health events, allowing users to drill down into information at different geographical granularities to understand and mitigate issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:20:20.215573"}}
{"question": "What are the components that Internet Monitor uses or references, and how do they relate to monitoring?", "answer": "Internet Monitor uses or references several components, including Monitor, CloudWatch logs, CloudWatch metrics, city-networks, health events, Autonomous System Numbers (ASNs), monitored resources, internet measurements, round-trip time, bytes transferred, and performance and availability scores. These components work together to provide a comprehensive view of application health, performance metrics, and internet measurements specific to the locations and networks communicating with your application.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-04T16:20:20.216147"}}
{"question": "In which AWS Regions is Internet Monitor available for Amazon CloudFront distributions?", "answer": "Internet Monitor is available in all supported Regions for Amazon CloudFront distributions and Amazon WorkSpaces directories.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-04T16:20:24.294207"}}
{"question": "What is the purpose of CloudWatch Lambda Insights?", "answer": "CloudWatch Lambda Insights is a feature for monitoring, troubleshooting, and optimizing the performance and cost of your Lambda functions, simplifying the isolation and analysis of performance issues impacting your Lambda environments.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-04T16:20:24.294577"}}
{"question": "How does Network Monitor compare to CloudWatch Lambda Insights in terms of functionality?", "answer": "Network Monitor provides visibility into the performance of the network connecting AWS-hosted applications to on-premises destinations, focusing on packet loss and latency of hybrid network connections. In contrast, CloudWatch Lambda Insights focuses on monitoring and optimizing the performance of AWS Lambda functions, providing operational visibility of metrics, logs, and traces.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-04T16:20:24.295080"}}
{"question": "What metrics does Network Monitor provide for each probe configured in the monitor?", "answer": "Network Monitor provides round-trip latency and packet loss metrics for each probe configured in the monitor.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-04T16:20:30.015770"}}
{"question": "How does Network Monitor help in understanding network health in AWS?", "answer": "Network Monitor helps in understanding network health in AWS by vending real-time metrics to Amazon CloudWatch, which allows users to view these metrics on CloudWatch dashboards, set up alarms, and assess the AWS network health status to identify when network issues affect performance.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-04T16:20:30.016036"}}
{"question": "What is the relationship between Network Monitor and Amazon CloudWatch?", "answer": "Network Monitor vends real-time metrics to Amazon CloudWatch, where these metrics are aggregated per VPC subnet and per destination endpoint. Users can access CloudWatch dashboards from within the Network Monitor console to view these metrics and set up alarms, thereby utilizing CloudWatch tools to better understand network health in specific AWS regions.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-04T16:20:30.016249"}}
{"question": "What is the primary purpose of Amazon CloudWatch RUM?", "answer": "The primary purpose of Amazon CloudWatch RUM is to provide visibility into an applications client-side performance, helping to reduce mean time to resolution (MTTR) by collecting real-time client-side data on web application performance to identify and debug issues.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-04T16:20:36.744402"}}
{"question": "How does CloudWatch RUM complement CloudWatch Synthetics?", "answer": "CloudWatch RUM complements CloudWatch Synthetics by providing more visibility into the end-users digital experience. While CloudWatch Synthetics focuses on synthetic monitoring, CloudWatch RUM collects real user data, allowing for a more comprehensive understanding of performance issues from the actual users' perspective.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-04T16:20:36.744797"}}
{"question": "What are the key functionalities offered by Amazon CloudWatch Evidently compared to CloudWatch RUM?", "answer": "Amazon CloudWatch Evidently focuses on conducting experiments and validating new features across the full application stack before release, which helps in reducing risks associated with new feature roll-outs. In contrast, CloudWatch RUM is primarily concerned with monitoring client-side performance and debugging issues related to user experience. While Evidently allows for experimentation and monitoring metrics like page load times and conversions, RUM provides insights into real-user performance and helps identify and fix issues in the application.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-04T16:20:36.745186"}}
{"question": "What capabilities does the CloudWatch RUM JavaScript code snippet provide?", "answer": "The CloudWatch RUM JavaScript code snippet allows you to collect client-side user journeys and performance metrics. Additionally, you can add custom metrics, such as conversions, using the Evidently API.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-04T16:20:41.769762"}}
{"question": "How does AppConfig enhance the deployment of new features in an application?", "answer": "AppConfig allows you to create, manage, and deploy feature flags and other application configurations. When developing new features, you can deploy a feature to production while keeping it hidden behind a flag toggle. Once ready to launch, you can update the configuration to release the feature instantly or gradually.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-04T16:20:41.770115"}}
{"question": "What is the relationship between CloudWatch RUM and Evidently in terms of feature management?", "answer": "CloudWatch RUM provides client-side application performance monitoring, and its metrics can be directly used in Evidently for advanced feature management and experimentation. Evidently allows you to run experiments on different feature variations, and the integration with RUM means you can monitor business metrics like visit duration and revenue alongside performance metrics.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-04T16:20:41.770593"}}
{"question": "What is CloudWatch Metrics Insights?", "answer": "CloudWatch Metrics Insights is a high-performance query engine that helps you slice and dice your operational metrics in real time and create aggregations on the fly using standard SQL queries. It aids in understanding the status of application health and performance by allowing analysis of metrics at scale.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-04T16:20:47.266821"}}
{"question": "How does Metrics Insights facilitate the monitoring of application performance?", "answer": "Metrics Insights facilitates the monitoring of application performance by providing the ability to analyze operational metrics in real time using standard SQL queries. It is integrated with CloudWatch Dashboards, allowing users to save queries into their health and performance dashboards for proactive monitoring and quick issue identification.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-04T16:20:47.267198"}}
{"question": "What are the differences between using the visual query builder and the query editor in Metrics Insights?", "answer": "The visual query builder in Metrics Insights allows users to select their metrics of interest, namespaces, and dimensions visually, with the console automatically constructing SQL queries based on selections. In contrast, the query editor enables users to type in their raw SQL queries anytime to dive deeper and pinpoint issues in greater detail.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-04T16:20:47.267649"}}
{"question": "What is the maximum retention period for metric data points with a period of 1 hour in CloudWatch?", "answer": "Data points with a period of 3600 seconds (1 hour) are available for 455 days, which is equivalent to 15 months.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-04T16:20:52.744362"}}
{"question": "How does the aggregation process work for metric data points in CloudWatch after their initial availability period?", "answer": "Data points that are initially published with a shorter period are aggregated together for long-term storage. For example, if data is collected using a period of 1 minute, it remains available for 15 days with 1-minute resolution. After 15 days, the data is still available but is aggregated and retrievable only with a resolution of 5 minutes. After 63 days, the data is further aggregated and can only be accessed with a resolution of 1 hour.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-04T16:20:52.744722"}}
{"question": "How do the availability periods for high-resolution custom metrics compare to standard metrics with a period of 1 minute?", "answer": "High-resolution custom metrics, which have a period of less than 60 seconds, are available for 3 hours. In contrast, standard metrics with a period of 1 minute are available for 15 days before being aggregated.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-04T16:20:52.745214"}}
{"question": "What is the minimum resolution supported by CloudWatch for data points?", "answer": "The minimum resolution supported by CloudWatch is one-second data points, which is considered a high-resolution metric, or you can store metrics at one-minute granularity.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-04T16:20:58.860471"}}
{"question": "How does CloudWatch handle metrics that are received at varying intervals?", "answer": "CloudWatch can receive metrics at varying intervals, such as three-minute or five-minute intervals. If you do not specify that a metric is high resolution by setting the StorageResolution field in the PutMetricData API request, CloudWatch will aggregate and store the metrics at one-minute resolution by default.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-04T16:20:58.860837"}}
{"question": "How does the retention schedule affect the availability of metrics data in CloudWatch?", "answer": "The retention schedule affects the availability of metrics data in CloudWatch by determining the resolutions at which data can be retrieved based on its age. For example, if you request one-minute data for a day from 10 days ago, you will receive 1440 data points. However, if you request one-minute data from five months back, the UI will automatically change the granularity to one-hour, and the GetMetricStatistics API will not return any output.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-04T16:20:58.861046"}}
{"question": "What is the default storage resolution for metrics in Amazon CloudWatch?", "answer": "By default, metrics are stored at one-minute resolution in Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-04T16:21:03.880751"}}
{"question": "Why is it recommended to use a one minute period for troubleshooting in Amazon CloudWatch?", "answer": "It is recommended to use a one minute period for troubleshooting and other activities that require the most precise graphing of time periods because data points are displayed differently based on the time period specified, and a one minute period allows for more accurate representation of data points.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-04T16:21:03.881098"}}
{"question": "How do standard resolution and high resolution metrics differ in Amazon CloudWatch?", "answer": "Standard resolution metrics have a data granularity of one minute, while high resolution metrics have a granularity of one second. High resolution metrics can be published by setting the StorageResolution parameter to one in the PutMetricData API request, whereas standard resolution metrics are stored by default at one-minute resolution.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-04T16:21:03.881570"}}
{"question": "What is the default storage resolution for custom metrics in CloudWatch if the StorageResolution parameter is not specified?", "answer": "If the StorageResolution parameter is not specified, then CloudWatch will store the custom metric at one-minute resolution by default.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-04T16:21:07.991761"}}
{"question": "Why might someone choose to use custom metrics in CloudWatch?", "answer": "Someone might choose to use custom metrics in CloudWatch if their data is not already produced in log format, such as operating system processes or performance measurements. Additionally, they may want to write their own application or script, or use one provided by an AWS partner.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-04T16:21:07.992227"}}
{"question": "How do high-resolution custom metrics differ from standard one-minute custom metrics in terms of pricing?", "answer": "High-resolution custom metrics are priced in the same manner as standard one-minute custom metrics; there is no difference in pricing between the two.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-04T16:21:07.992497"}}
{"question": "What does the application monitoring feature automatically recognize?", "answer": "The application monitoring feature automatically recognizes application metrics and logs, scans your application resources, provides a list of recommended metrics and logs to monitor, and sets them up automatically.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-04T16:21:13.097420"}}
{"question": "How does the intelligent problem detection feature help in monitoring applications?", "answer": "The intelligent problem detection feature helps in monitoring applications by using built-in rules and machine learning algorithms to dynamically monitor and analyze symptoms of a problem across the application stack. It detects application problems, reduces the overhead of dealing with individual metric spikes or log exceptions, and notifies users of real problems along with contextual information related to these issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-04T16:21:13.097774"}}
{"question": "How does the onboarding process differ from enabling monitoring for application components?", "answer": "The onboarding process involves specifying the application to monitor by choosing the associated AWS Resource Group and identifying application components by analyzing application resources. In contrast, enabling monitoring for application components involves specifying the technology tier of the application, which leads to the provision of a recommended set of metrics and logs that can be customized. Once saved, Application Insights sets up CloudWatch to collect these metrics and logs.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-04T16:21:13.097984"}}
{"question": "What is CloudWatch Metric Streams and what does it enable users to do?", "answer": "CloudWatch Metric Streams is a feature that allows you to continuously stream CloudWatch metrics to a destination of your choice with minimal setup and configuration. It is a fully managed solution that does not require you to write any code or maintain any infrastructure, and with just a few clicks, you can configure a metric stream to destinations like Amazon Simple Storage Service (S3) or third-party service providers.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-04T16:21:18.728954"}}
{"question": "How does Metric Streams improve the process of obtaining metrics data from CloudWatch?", "answer": "Metric Streams provides an alternative way to obtain metrics data from CloudWatch without the need to poll APIs. It allows users to create a stream quickly, enabling metrics data to flow continuously to a specified destination, which eliminates the need for manual API calls and improves efficiency in accessing up-to-date metrics.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-04T16:21:18.729435"}}
{"question": "What are the differences between the output formats available for Metric Streams?", "answer": "Metric Streams can output in either OpenTelemetry or JSON format. When creating or managing metric streams, users have the option to select between these two output formats, depending on their requirements for data integration and analysis.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-04T16:21:18.729767"}}
{"question": "What can you find in the monitoring section of the Metric Streams console page?", "answer": "In the monitoring section of the Metric Streams console page, you can see automatic dashboards for the volume of metric updates over time. These metrics are also available under the AWS/CloudWatch namespace and can be used to create alarms for unusual spikes in volume.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-04T16:21:24.443639"}}
{"question": "How does CloudWatch Logs help in monitoring and troubleshooting systems and applications?", "answer": "CloudWatch Logs helps in monitoring and troubleshooting systems and applications by allowing users to monitor logs in near real time for specific phrases, values, or patterns. Users can set alarms on occurrences of errors in system logs or view latency graphs from application logs, and they can access the original log data to identify the source of problems.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-04T16:21:24.443998"}}
{"question": "How do Amazon CloudWatch Vended logs differ from regular log files?", "answer": "Amazon CloudWatch Vended logs are logs that are natively published by AWS services on behalf of the customer, while regular log files are those that users create and manage themselves, such as application or custom logs. VPC Flow logs is the first type of Vended log available, with more AWS service log types expected to be added in the future.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-04T16:21:24.444505"}}
{"question": "What types of logs can CloudWatch Logs ingest and monitor?", "answer": "CloudWatch Logs can ingest, aggregate, and monitor any text-based common log data or JSON-formatted logs.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-04T16:21:30.402247"}}
{"question": "How does CloudWatch Logs enable real-time monitoring without requiring code changes?", "answer": "CloudWatch Logs uses your existing log data for monitoring, which means no code changes are required from you. It can monitor applications and systems in near real time by tracking the number of errors in your application logs and sending notifications when the error rate exceeds a specified threshold.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-04T16:21:30.402569"}}
{"question": "How does the CloudWatch Logs Agent handle non-text log data compared to text-based log data?", "answer": "The CloudWatch Logs Agent will send log data every five seconds by default for both text log data and JSON-formatted logs. However, if it is configured to report non-text log data and encounters an issue, it will record an error in the /var/logs/awslogs.log. This indicates that there is a specific error handling mechanism in place for non-text log data that is different from the normal logging process.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-04T16:21:30.403250"}}
{"question": "What is the purpose of Metric Filters in CloudWatch Logs?", "answer": "Metric Filters are used to monitor log events as they are sent to CloudWatch Logs by turning log data into Amazon CloudWatch Metrics for graphing or alarming. They search for and match terms, phrases, or values in log events and count occurrences in a chosen Amazon CloudWatch Metric.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-04T16:21:35.510248"}}
{"question": "How can Metric Filters be used to extract values from log events?", "answer": "Metric Filters can extract values from space delimited log events or JSON-formatted log events. For extraction, log events must be space delimited and enclosed with double quotes or square braces, and they can track specific data like the latency of web requests or bytes transferred from Apache access logs.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-04T16:21:35.510506"}}
{"question": "What are the differences in the patterns used for searching multiple terms in Metric Filters?", "answer": "To search for multiple terms in Metric Filters, you can list them separated by spaces, such as 'Error Exception' to count occurrences of both terms. If you want to match the exact phrase 'Error Exception', you would enclose it in double quotes as '\"Error Exception\"'. This distinction allows for both broad and precise searches.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-04T16:21:35.510984"}}
{"question": "What tools can you use to test Metric Filter patterns in CloudWatch Logs?", "answer": "You can test Metric Filter patterns using the CloudWatch Logs console or the CLI before you create a Metric Filter. You can test your patterns against your own log data already in CloudWatch Logs or supply your own log events for testing.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-04T16:21:41.121526"}}
{"question": "Why might someone choose to use Amazon Kinesis in relation to CloudWatch Logs?", "answer": "Someone might choose to use Amazon Kinesis in relation to CloudWatch Logs because CloudWatch Metric Filters do not support regular expressions. By using Kinesis, they can connect the stream with a regular expression processing engine to process their log data with regular expressions.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-04T16:21:41.121913"}}
{"question": "How does CloudWatch Logs Standard compare to other log classes offered by CloudWatch?", "answer": "CloudWatch Logs Standard is one of two log classes offered by CloudWatch and delivers comprehensive log management intended for real-time monitoring and advanced analytics capabilities. It enables users to monitor logs in near real-time for specific phrases, values, or patterns, and offers features like Live Tail, metric extraction, alarming, and data protection. The specific comparison with the other log class is not mentioned in the context.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-04T16:21:41.122517"}}
{"question": "What is Amazon CloudWatch Logs Infrequent Access (Logs-IA) designed for?", "answer": "Amazon CloudWatch Logs Infrequent Access (Logs-IA) is designed for consolidating all your logs natively on AWS. It is ideal for ad-hoc querying and after-the-fact forensic analysis, offering managed ingestion, cross-account log analytics, and encryption of CloudWatch Logs Standard at a low per GB ingestion price.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-04T16:21:47.054441"}}
{"question": "How does Logs Insights enhance the usability of CloudWatch Logs?", "answer": "Logs Insights enhances the usability of CloudWatch Logs by allowing users to query all logs being sent to CloudWatch. It automatically discovers log fields from various AWS services and generates three system fields (@message, @logStream, and @timestamp) for all logs. This makes it easier to analyze and understand log data.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-04T16:21:47.054738"}}
{"question": "What are the differences between CloudWatch Logs Standard and CloudWatch Logs-IA in terms of cost and usage?", "answer": "CloudWatch Logs-IA offers a low per GB ingestion price compared to CloudWatch Logs Standard, making it more cost-effective for storing and accessing log data. While both classes provide managed ingestion and cross-account log analytics, Logs-IA is specifically tailored for ad-hoc querying and forensic analysis, making it ideal for cases where logs are accessed infrequently.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-04T16:21:47.054915"}}
{"question": "What are the three query languages supported by CloudWatch Logs Insights?", "answer": "CloudWatch Logs Insights supports three query languages: Logs Insights query language (Logs Insights QL), OpenSearch Service Piped Processing Language (PPL), and OpenSearch Service Structured Query Language (SQL).", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-04T16:21:53.359366"}}
{"question": "How does the OpenSearch Service Piped Processing Language (PPL) simplify the process of querying logs?", "answer": "OpenSearch PPL simplifies the process of querying logs by allowing users to analyze data using a set of commands delimited by pipes (|). This structure makes it easier to understand and compose complex queries while providing commands to filter and aggregate data, along with a rich set of math, string, date, and conditional functions for analysis.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-04T16:21:53.359721"}}
{"question": "In what ways does Logs Insights QL differ from OpenSearch SQL in terms of functionality?", "answer": "Logs Insights QL differs from OpenSearch SQL primarily in its command set and usage. Logs Insights QL has a few but powerful commands focused on retrieving log fields, matching search criteria, aggregating log data, and extracting ephemeral fields. In contrast, OpenSearch SQL allows for a more declarative approach, supporting commands such as SELECT, FROM, WHERE, GROUP BY, HAVING, and it enables executing JOINs across log groups and using subqueries.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-04T16:21:53.360233"}}
{"question": "What types of functions does the query language support?", "answer": "The query language supports string, numeric, and mathematical functions, such as concat, strlen, trim, log, and sqrt. It also allows the use of boolean and logical expressions, as well as aggregate functions like min, max, sum, average, and percentile.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-04T16:22:00.300782"}}
{"question": "How can visualizations be used in Logs Insights?", "answer": "Visualizations in Logs Insights can be used to identify trends and patterns that occur over time within logs. It supports visualizing data using line charts, stacked area charts, bar charts, and pie charts. Visualizations are generated for queries containing one or more aggregate functions, where data is grouped over a time interval or specific fields.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-04T16:22:00.302082"}}
{"question": "What is the difference between the VPC Flow Logs Dashboard and the CloudTrail Dashboard?", "answer": "The VPC Flow Logs Dashboard captures network flow data for Virtual Private Cloud and is designed to analyze network traffic, detect unusual patterns, and monitor resource usage, supporting only VPC v2 fields. In contrast, the CloudTrail Dashboard provides an overview of API activity within an AWS environment using CloudTrail logs, which is useful for monitoring API activity, auditing actions, and identifying potential security or compliance issues.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-04T16:22:00.302397"}}
{"question": "What system fields are generated by Logs Insights and what do they contain?", "answer": "Logs Insights generates three system fields: @message, which contains the raw, unparsed log event as sent to CloudWatch; @logStream, which contains the name of the source that generated the log event; and @timestamp, which contains the time when the log event was added to CloudWatch.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T16:22:06.855663"}}
{"question": "How do regular expressions enhance the functionality of Logs Insights?", "answer": "Regular expressions enhance the functionality of Logs Insights by allowing users to filter log data using complex patterns. This enables more precise queries when searching through logs, helping users find specific information quickly and efficiently.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T16:22:06.855989"}}
{"question": "How does the integration of ISV Partner solutions with CloudWatch Logs Insights compare to using standard AWS services?", "answer": "ISV Partner integrations with CloudWatch Logs Insights provide the ability to analyze log data using preferred tools and frameworks in a high-performance, cost-effective manner without moving large amounts of data. In contrast, standard AWS services may not offer the same level of flexibility and may require more effort to configure and maintain data transfers.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T16:22:06.856423"}}
{"question": "What is the primary purpose of Amazon CloudWatch Logs Anomaly Detection?", "answer": "The primary purpose of Amazon CloudWatch Logs Anomaly Detection is to automatically detect unusual behavior in application logs, helping to cluster related logs for faster investigation, surface key insights over time, and notify users of unusual behavior for quicker remediation.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-04T16:22:13.102678"}}
{"question": "How does Amazon CloudWatch Logs Anomaly Detection differ from Metric Filters?", "answer": "Amazon CloudWatch Logs Anomaly Detection differs from Metric Filters in that it can identify previously unknown conditions, such as newly occurring error codes or sudden spikes in log messages, without requiring the user to monitor specific, known variables. Anomaly Detection automatically adapts to changes in application logs over time, whereas Metric Filters require predefined queries or filters.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-04T16:22:13.102908"}}
{"question": "What types of logs is Amazon CloudWatch Logs Anomaly Detection best suited for?", "answer": "Amazon CloudWatch Logs Anomaly Detection is best suited for application logs generated from application code running in environments such as EC2, EKS, ECS, Lambda, and other resources associated with running application code. It does not require a specific format of logs to function.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-04T16:22:13.103289"}}
{"question": "What is Amazon CloudWatch Logs Live Tail?", "answer": "Amazon CloudWatch Logs Live Tail is an interactive analytics capability that provides a real-time view of incoming logs, allowing developers and IT engineers to quickly troubleshoot issues, monitor the status of deployments, and gain deep visibility into critical application logs.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-04T16:22:19.349657"}}
{"question": "How does Live Tail help in reducing mean time to resolution?", "answer": "Live Tail helps reduce mean time to detection and, in turn, mean time to resolution by providing a real-time interactive view of logs in the context of related events, allowing teams to quickly identify and address issues within their applications and deployments.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-04T16:22:19.350014"}}
{"question": "What are the differences in functionality between Live Tail for custom application logs and Live Tail for AWS Services?", "answer": "Live Tail provides capabilities on custom application logs, allowing deep insights and real-time monitoring. In contrast, Live Tail for AWS Services, such as Amazon VPC, AWS Lambda, and others, also embeds the interactive live tailing experience into consoles, offering the same deep-dive analytics capabilities from within those services.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-04T16:22:19.350491"}}
{"question": "In which regions is Live Tail available?", "answer": "Live Tail is available in the following regions: US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), EU (Paris), and South America (So Paulo).", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-04T16:22:28.352921"}}
{"question": "How does CloudWatch Logs data protection help organizations manage sensitive data?", "answer": "CloudWatch Logs data protection helps organizations manage sensitive data by allowing them to define their own rules and policies to automatically detect and mask sensitive data within logs. It uses machine learning (ML) and pattern matching to identify and mask this information, ensuring that sensitive data is not stored unmasked without elevated Identity and Access Management (IAM) privileges. This feature is particularly beneficial for industries with strict regulations and for customers handling personal and sensitive information.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-04T16:22:28.353215"}}
{"question": "What is the difference between Live Tail and Logs Insights in terms of log data access?", "answer": "The difference between Live Tail and Logs Insights is that Live Tail provides a real-time view of the logs data collected by CloudWatch, whereas Logs Insights is used for accessing historical logs. Live Tail focuses on current log data, while Logs Insights allows users to analyze and query logs that have already been collected.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-04T16:22:28.353585"}}
{"question": "What types of data identifiers can you protect when creating a data protection policy in CloudWatch Logs?", "answer": "When creating a data protection policy in CloudWatch Logs, you can protect various data identifiers such as email addresses, drivers licenses from many countries, credit card numbers, addresses, and more.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-04T16:22:34.171068"}}
{"question": "Why is it important to decide what information is sensitive when creating a data protection policy in CloudWatch Logs?", "answer": "It is important to decide what information is sensitive to your application because this allows you to select the relevant identifiers for your use cases and mask the sensitive data that does not need to be easily accessible.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-04T16:22:34.171377"}}
{"question": "How do composite alarms in CloudWatch help manage alarm noise compared to standard alarms?", "answer": "Composite alarms in CloudWatch help manage alarm noise by allowing you to combine multiple alarms into alarm hierarchies, triggering just once when multiple alarms fire at the same time, which provides an overall state for a grouping of resources.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-04T16:22:34.171692"}}
{"question": "What is the maximum duration for which alarm history is available in Amazon CloudWatch?", "answer": "Alarm history is available for 14 days in Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T16:22:41.878365"}}
{"question": "How does Amazon CloudWatch treat an alarm that remains in the ALARM state for an extended period?", "answer": "An alarm that remains in the ALARM state for a long time is normal behavior if the metric value is still in breach of the threshold. The alarm will continue to evaluate metrics against the threshold until it no longer breaches it. If you want the alarm to treat the new level as OK, you can adjust the alarm threshold accordingly.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T16:22:41.878715"}}
{"question": "What is the difference between Automatic Dashboards and custom Dashboards in Amazon CloudWatch?", "answer": "Automatic Dashboards are pre-built with AWS service recommended best practices, remain resource aware, and dynamically update to reflect the latest state of important performance metrics. In contrast, custom Dashboards allow you to create, customize, interact with, and save graphs of AWS resources and custom metrics, but they do not automatically update to reflect the latest state unless manually adjusted.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T16:22:41.879204"}}
{"question": "What AWS services are currently supported by Amazon CloudWatch Events?", "answer": "Currently, Amazon EC2, Auto Scaling, and AWS CloudTrail are supported by Amazon CloudWatch Events.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:22:47.019949"}}
{"question": "How does Amazon CloudWatch Events differ from AWS Config?", "answer": "Amazon CloudWatch Events is designed for reacting in near real time to resource state changes and does not provide compliance verification or detailed history like AWS Config and Config Rules do. AWS Config, on the other hand, offers a resource inventory, configuration history, and configuration change notifications to enable security and governance.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:22:47.020336"}}
{"question": "What can you do when an event matches a rule in Amazon CloudWatch Events?", "answer": "When an event matches a rule you've created in Amazon CloudWatch Events, you can automatically invoke an AWS Lambda function, relay the event to an Amazon Kinesis stream, notify an Amazon SNS topic, or invoke a built-in workflow.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-04T16:22:47.020812"}}
{"question": "What is AWS CodeArtifact used for?", "answer": "AWS CodeArtifact is used for secure, scalable, and cost-effective package management for software development. It allows users to store and share artifacts across accounts with appropriate access levels for teams and build systems.", "question_type": "factual", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-04T16:22:52.278198"}}
{"question": "How does AWS CodeArtifact reduce overhead for users?", "answer": "AWS CodeArtifact reduces overhead from the setup and maintenance of an artifact server or infrastructure by providing a fully managed service, meaning users do not need to manage the underlying infrastructure themselves.", "question_type": "conceptual", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-04T16:22:52.278557"}}
{"question": "How does AWS CodeArtifact compare to traditional artifact servers in terms of management?", "answer": "AWS CodeArtifact is a fully managed service, which means it alleviates the burden of setup and maintenance associated with traditional artifact servers. In contrast, traditional artifact servers require users to manage the infrastructure and server setup themselves.", "question_type": "comparison", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-04T16:22:52.279105"}}
{"question": "What is AWS CodeBuild?", "answer": "AWS CodeBuild is a fully managed continuous integration service in the cloud that compiles source code, runs tests, and produces packages that are ready to deploy. It eliminates the need to provision, manage, and scale your own build servers, automatically scaling up and down while processing multiple builds concurrently.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:22:58.003010"}}
{"question": "How does AWS CodeBuild manage build server resources?", "answer": "AWS CodeBuild provides a fully managed experience by automatically creating temporary compute containers for each build job. These containers are created fresh for every build and discarded once the build is completed, which means there is no need for users to manage build server hardware or software. Additionally, CodeBuild automatically scales to meet build volume and processes each build immediately, allowing for concurrent build execution.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:22:58.003366"}}
{"question": "How does a build project differ from a build environment in AWS CodeBuild?", "answer": "A build project in AWS CodeBuild defines how a build will run, including information such as the source code location, the build environment to use, the build commands to run, and the storage for build output. In contrast, a build environment refers to the specific combination of the operating system, programming language runtime, and tools that CodeBuild uses to execute the build.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-04T16:22:58.003584"}}
{"question": "What source code repositories can CodeBuild connect to for pulling source code?", "answer": "CodeBuild can connect to AWS CodeCommit, S3, GitHub, GitHub Enterprise, and Bitbucket to pull source code for builds.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T16:23:03.794804"}}
{"question": "How can a user customize their build environment in CodeBuild?", "answer": "A user can customize their build environment in CodeBuild by creating a Docker image and uploading it to the Amazon EC2 Container Registry or the Docker Hub registry. They can then reference this custom image in their build project.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T16:23:03.795187"}}
{"question": "How does the CodeBuild environment for .NET Core 2.0 compare to the environment for .NET Framework?", "answer": "CodeBuild provides a preconfigured build environment for .NET Core 2.0, but it does not currently have a preconfigured build environment for .NET Framework due to Microsoft's unwillingness to address customer requests. Users can still customize their environment to support .NET Framework by creating a Docker image.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T16:23:03.795778"}}
{"question": "What information can you access regarding your past build results?", "answer": "You can access the outcome (success or failure), build duration, output artifact location, and log location of your past build results.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-04T16:23:08.495188"}}
{"question": "How can you debug a build in CodeBuild?", "answer": "You can debug a build by inspecting the detailed logs generated during the build run or by using CodeBuild Local to locally test and debug your builds.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-04T16:23:08.495537"}}
{"question": "How does the memory and processing power requirement for the .NET Core for Windows build environment compare to the build.general1.small compute instance type?", "answer": "The .NET Core for Windows build environment requires more memory and processing power than is available in the build.general1.small compute instance type due to the size of the Windows Docker base container and additional libraries.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-04T16:23:08.495917"}}
{"question": "What types of instances can AWS CodeDeploy automate code deployments to?", "answer": "AWS CodeDeploy can automate code deployments to any instance, including Amazon EC2 instances and instances running on-premises.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-04T16:23:13.242297"}}
{"question": "How does AWS CodeDeploy help in the deployment process?", "answer": "AWS CodeDeploy makes it easier to rapidly release new features, helps avoid downtime during deployment, and handles the complexity of updating applications. It automates deployments, eliminating the need for error-prone manual operations, and it scales with your infrastructure, allowing deployment to one instance or thousands.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-04T16:23:13.242580"}}
{"question": "How does AWS CodeDeploy differ from AWS Elastic Beanstalk and AWS OpsWorks?", "answer": "AWS CodeDeploy is a building block service focused specifically on helping developers deploy and update software on any instance, whereas AWS Elastic Beanstalk and AWS OpsWorks are end-to-end application management solutions.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-04T16:23:13.243142"}}
{"question": "What does AWS CodeDeploy require for an instance to be supported?", "answer": "AWS CodeDeploy supports any instance that can install the CodeDeploy agent and connect to AWS public endpoints.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-04T16:23:19.707764"}}
{"question": "What is a deployment group in AWS CodeDeploy?", "answer": "A deployment group is the AWS CodeDeploy entity for grouping EC2 instances or AWS Lambda functions in a CodeDeploy deployment. For EC2 deployments, it is a set of instances associated with an application that you target for a deployment. You can add instances to a deployment group by specifying a tag, an Auto Scaling group name, or both. For AWS Lambda deployments, a deployment group defines a set of AWS CodeDeploy configurations for future serverless Lambda deployment to the group, such as alarms and rollbacks.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-04T16:23:19.708266"}}
{"question": "How do deployment configurations differ for multi-instance deployment groups compared to the default deployment behavior?", "answer": "A deployment configuration specifies how the behavior for deployment should proceed, including how to handle deployment failure, for a deployment group. It allows for zero-downtime deployments to multi-instance deployment groups, such as requiring at least 50% of the instances to be up and serving traffic. In contrast, if no deployment configuration is associated with the deployment or the deployment group, AWS CodeDeploy will deploy to one instance at a time by default.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-04T16:23:19.708440"}}
{"question": "What are the three parameters you specify for a deployment in AWS CodeDeploy?", "answer": "The three parameters you specify for a deployment in AWS CodeDeploy are Revision, which specifies what to deploy; Deployment group, which specifies where to deploy; and Deployment configuration, which is an optional parameter that specifies how to deploy.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T16:23:27.332278"}}
{"question": "What is the purpose of the AppSpec file in AWS CodeDeploy?", "answer": "The AppSpec file is a configuration file used in AWS CodeDeploy that specifies the files to be copied and the scripts to be executed during the deployment process. It uses the YAML format and is included in the root directory of your revision.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T16:23:27.332586"}}
{"question": "How do the files and hooks sections of the AppSpec file differ in terms of their function?", "answer": "The files section of the AppSpec file specifies the source files in your revision to be copied and the destination folder on each instance, while the hooks section specifies the location of the scripts to run during each phase of the deployment, which are referred to as deployment lifecycle events.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T16:23:27.333075"}}
{"question": "What is the purpose of the ApplicationStop deployment lifecycle event?", "answer": "The ApplicationStop deployment lifecycle event is used to gracefully stop the application or remove currently installed packages in preparation for a deployment. It is the first deployment lifecycle event that occurs before the revision gets downloaded.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-04T16:23:35.156426"}}
{"question": "What tasks can you perform during the BeforeInstall deployment lifecycle event?", "answer": "During the BeforeInstall deployment lifecycle event, you can perform preinstall tasks such as decrypting files and creating a backup of the current version.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-04T16:23:35.156890"}}
{"question": "How does the AfterInstall deployment lifecycle event differ from the Install event?", "answer": "The AfterInstall deployment lifecycle event allows you to perform tasks such as configuring your application or changing file permissions after the revision files have been copied to the final destination. In contrast, the Install deployment lifecycle event is reserved for the agent to copy the revision files from the temporary location to the final destination and does not allow the execution of user scripts.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-04T16:23:35.157176"}}
{"question": "What are the typical one-time setup tasks required during a deployment in AWS CodeDeploy?", "answer": "The typical one-time setup tasks required during a deployment in AWS CodeDeploy are creating an application and a deployment group.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-04T16:23:41.904595"}}
{"question": "What is the purpose of the AppSpec file in AWS CodeDeploy?", "answer": "The purpose of the AppSpec file in AWS CodeDeploy is to specify the files to be copied and the scripts to be executed during the deployment process.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-04T16:23:41.904889"}}
{"question": "How does deploying a revision from GitHub compare to deploying from other source control systems in terms of file format and process?", "answer": "When deploying a revision from GitHub, you can deploy directly in a .zip, .tar, or .tar.gz format from your repository to instances. In contrast, for other source control systems, you must bundle and upload the revision to an Amazon S3 bucket in the same formats (.zip, .tar, or .tar.gz) and specify the Amazon S3 location during the deployment process.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-04T16:23:41.905291"}}
{"question": "How can AWS CodeDeploy be integrated with continuous integration and deployment systems?", "answer": "AWS CodeDeploy can be integrated with continuous integration and deployment systems by calling the public APIs using the AWS CLI or AWS SDKs. Additionally, there are prebuilt integrations and samples available on the product integrations page.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-04T16:23:48.521930"}}
{"question": "What happens to newly launched instances in an Auto Scaling group when associated with a deployment group in AWS CodeDeploy?", "answer": "When an Auto Scaling group is associated with a deployment group in AWS CodeDeploy, every time a new Amazon EC2 instance is launched, it is first put in a Pending state, and a deployment of the last successful revision for that deployment group is triggered on that instance. If the deployment completes successfully, the instance's state changes to InService. If the deployment fails, the instance is terminated, and a new instance is launched in Pending state, with another deployment triggered.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-04T16:23:48.522596"}}
{"question": "What is the difference in deployment behavior between Amazon EC2 instances in an Auto Scaling group and those not in an Auto Scaling group?", "answer": "For Amazon EC2 instances that are launched as part of an Auto Scaling group, AWS CodeDeploy automatically triggers a deployment of the latest application revision upon launch. In contrast, for Amazon EC2 instances that are not part of an Auto Scaling group, AWS CodeDeploy does not automatically deploy the latest revision to newly added instances.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-04T16:23:48.522833"}}
{"question": "How does AWS CodeDeploy handle rolling back to a previous application revision?", "answer": "To roll back an application to a previous revision, you just need to deploy that revision. AWS CodeDeploy keeps track of the files that were copied for the current revision and removes them before starting a new deployment, so there is no difference between redeploying and rolling back. However, you need to ensure that the previous revisions are available for rollback.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:23:56.507773"}}
{"question": "What are the benefits of using AWS CodeDeploy notifications?", "answer": "AWS CodeDeploy notifications provide a way to receive updates regarding events impacting your deployments. These notifications come in the form of Amazon SNS notifications, which include a status message and a link to the resources whose event generated the notification. Notifications have no additional cost, but you may incur charges for other AWS services utilized by notifications, such as Amazon SNS. Additionally, customers using AWS Chatbot can configure notifications to be sent to their Slack Channels or Amazon Chime chat rooms.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:23:56.508244"}}
{"question": "What is the difference between using a versioned Amazon S3 bucket and regular S3 for AWS CodeDeploy revisions?", "answer": "The context does not explicitly mention any differences between using a versioned Amazon S3 bucket and a regular S3 bucket for AWS CodeDeploy revisions. However, it states that a versioned Amazon S3 bucket allows you to specify the version ID to uniquely identify a revision, which implies that versioning is crucial for managing and rolling back revisions effectively.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:23:56.508397"}}
{"question": "What is the cost of deploying applications to Amazon EC2 instances using AWS CodeDeploy?", "answer": "There is no additional charge for code deployments to Amazon EC2 instances through AWS CodeDeploy.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-04T16:24:02.441222"}}
{"question": "How can you deploy an application to multiple regions using AWS CodeDeploy?", "answer": "To deploy an application to multiple regions using AWS CodeDeploy, you need to define the application in your target regions, copy the application bundle to an Amazon S3 bucket in each region, and then start the deployments using either a serial or parallel rollout across the regions.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-04T16:24:02.441558"}}
{"question": "What is the difference in cost between deploying applications to Amazon EC2 instances and on-premises instances using AWS CodeDeploy?", "answer": "Deploying applications to Amazon EC2 instances using AWS CodeDeploy incurs no additional charge, whereas deploying applications to on-premises instances costs $0.02 per instance update.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-04T16:24:02.442025"}}
{"question": "What programming languages does Amazon CodeGuru Security currently support for scanning?", "answer": "Amazon CodeGuru Security currently supports scanning Java, Python, JavaScript, TypeScript, C#, CloudFormation, Terraform, Go, and Ruby.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-04T16:24:07.851363"}}
{"question": "What are the primary functionalities of Amazon CodeGuru Security?", "answer": "Amazon CodeGuru Security is a machine learning and program analysis-based tool that finds security vulnerabilities in application code and scans for hardcoded credentials. It detects issues related to the OWASP Top Ten, CWE Top 25, log injection, secrets, and secure use of AWS APIs and SDKs.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-04T16:24:07.851664"}}
{"question": "How does Amazon CodeGuru Security differ from Amazon CodeGuru Profiler?", "answer": "Amazon CodeGuru Security focuses on finding security vulnerabilities in application code and scanning for hardcoded credentials, while Amazon CodeGuru Profiler is designed to optimize performance for applications running in production and identifies the most expensive lines of code to reduce operational costs.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-04T16:24:07.852070"}}
{"question": "What type of access does CodeGuru Security require to generate recommendations?", "answer": "CodeGuru Security needs read-only access to your code for the purpose of generating recommendations.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T16:24:12.847546"}}
{"question": "How does CodeGuru Security ensure the privacy and security of your content?", "answer": "CodeGuru Security implements appropriate controls, including encryption in transit, to prevent unauthorized access to, or disclosure of, your content and ensures that its use complies with its commitments to you.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T16:24:12.847845"}}
{"question": "How does CodeGuru Profiler differ from CodeGuru Security in terms of functionality?", "answer": "CodeGuru Profiler helps developers and IT Operators understand the runtime behavior of applications and improve performance, while CodeGuru Security focuses on analyzing code for security vulnerabilities and generating recommendations based on that analysis.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T16:24:12.848250"}}
{"question": "What types of applications can Amazon CodeGuru Profiler work with?", "answer": "Amazon CodeGuru Profiler works with applications hosted on Amazon EC2, containerized applications running on Amazon ECS and Amazon EKS, as well as serverless applications running on AWS Fargate and AWS Lambda. Additionally, it can be run on-premises.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-04T16:24:20.040994"}}
{"question": "How does Amazon CodeGuru Profiler complement traditional APMs?", "answer": "Amazon CodeGuru Profiler complements traditional APMs by providing visualizations of the applications runtime data and actionable recommendations for the performance issues it discovers. It also uses machine learning to detect and alert on anomalies in the application profile, pointing to the anomalous lines of code.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-04T16:24:20.041588"}}
{"question": "In what ways is Amazon CodeGuru Profiler different from standalone profilers?", "answer": "Unlike some standalone profilers that are designed to only run in test environments, Amazon CodeGuru Profiler was designed to continuously run in production, under production traffic loads, and without impacting the application. This allows it to be useful for troubleshooting operational issues in production, including when running on bare metal hosts.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-04T16:24:20.041749"}}
{"question": "What programming languages does Amazon CodeGuru Profiler currently support?", "answer": "Amazon CodeGuru Profiler currently supports Java, Python (in preview), and JVM languages such as Scala and Kotlin.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T16:24:25.220505"}}
{"question": "How does Amazon CodeGuru Profiler minimize its impact on application performance?", "answer": "Amazon CodeGuru Profiler is tuned to have a minimal impact on your application's performance while it runs as an in-process thread. It uses the resources (CPU, memory) allocated to AWS Lambda functions and is designed to function efficiently even when the application consumes most of the resources.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T16:24:25.220804"}}
{"question": "What are the differences between the metrics collected for Java applications and Python applications by CodeGuru Profiler?", "answer": "CodeGuru Profiler profiles both CPU (active CPU and wall clock time) and memory (heap summary) for Java and other JVM languages, while it profiles only CPU (wall clock time) for Python applications.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T16:24:25.221255"}}
{"question": "What are the two scenarios where heap summary is useful?", "answer": "Heap summary is useful in two scenarios: first, to spot potential memory leaks, where a constantly growing memory utilization curve for one or more object types may indicate a leak that could lead to out-of-memory errors and application crashes; second, to optimize the memory footprint of an application, where the breakdown of memory utilization per object type helps identify where to focus optimization efforts.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-04T16:24:31.616380"}}
{"question": "How can heap summary help in optimizing the memory footprint of an application?", "answer": "Heap summary helps in optimizing the memory footprint of an application by providing a breakdown of memory utilization per object type. This information allows developers to identify which object types are using an unexpectedly high amount of memory, enabling them to focus their analysis and optimization efforts on the parts of the application responsible for allocating and referencing those objects.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-04T16:24:31.617047"}}
{"question": "What relationship exists between memory leaks and out-of-memory errors according to the heap summary?", "answer": "According to the heap summary, a relationship exists where a constantly growing memory utilization curve for one or more object types may indicate a memory leak. This leak can lead to out-of-memory errors, which subsequently may cause application crashes.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-04T16:24:31.617198"}}
{"question": "What is AWS CodePipeline?", "answer": "AWS CodePipeline is a continuous delivery service that enables you to model, visualize, and automate the steps required to release your software. It allows you to model the full release process for building your code, deploying to pre-production environments, testing your application, and releasing it to production.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-04T16:24:37.693697"}}
{"question": "How does AWS CodePipeline enhance the speed and quality of software updates?", "answer": "AWS CodePipeline enhances the speed and quality of software updates by automating the build, test, and release processes. It runs all new changes through a consistent set of quality checks, which increases the reliability and efficiency of software updates.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-04T16:24:37.693997"}}
{"question": "What is the relationship between a pipeline and its stages in AWS CodePipeline?", "answer": "A pipeline is a workflow construct that describes how software changes go through a release process, and it is defined by a sequence of stages and actions. A pipeline can have two or more stages, where each stage is a group of one or more actions performed on a revision.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-04T16:24:37.694478"}}
{"question": "What are artifacts in the context of AWS CodePipeline?", "answer": "Artifacts are files or sets of files that actions in a pipeline act upon. They can be worked upon by later actions in the pipeline, such as source artifacts outputting the latest version of code for subsequent build actions to read.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T16:24:42.617313"}}
{"question": "How do transitions function in AWS CodePipeline?", "answer": "Transitions in AWS CodePipeline connect the stages of a pipeline and are represented by arrows in the AWS CodePipeline console. Revisions that successfully complete the actions in a stage are automatically sent to the next stage via these transitions, which can be enabled or disabled as needed.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T16:24:42.617844"}}
{"question": "What is the difference between stopping a pipeline by disabling a transition and simply letting a pipeline run its course?", "answer": "Disabling a transition stops the promotion of revisions to later stages, even though the pipeline will continue to run revisions through the actions. In contrast, letting a pipeline run its course allows revisions to be promoted to later stages as long as the transitions are enabled.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T16:24:42.618108"}}
{"question": "What can you include in your source code repository to release updates to your serverless application?", "answer": "You can include the AWS Serverless Application Model template and its corresponding files in your source code repository to release updates to your serverless application.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-04T16:24:49.482474"}}
{"question": "How does continuous delivery work with AWS CodePipeline and AWS CloudFormation?", "answer": "Continuous delivery with AWS CodePipeline and AWS CloudFormation allows you to automatically build and test changes to your AWS CloudFormation stacks before promoting them to production stacks. This process enables rapid and reliable changes to your AWS infrastructure and can be extended with additional actions such as manual approvals, test actions, or invoking AWS Lambda actions.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-04T16:24:49.482781"}}
{"question": "How does AWS CodePipeline integrate with other AWS services?", "answer": "AWS CodePipeline integrates with various AWS services including AWS CodeCommit, Amazon S3, AWS CodeBuild, AWS CodeDeploy, AWS Elastic Beanstalk, AWS CloudFormation, AWS OpsWorks, Amazon ECS, and AWS Lambda. It also integrates with partner tools and allows for the creation of custom actions to integrate any existing tool with CodePipeline.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-04T16:24:49.483185"}}
{"question": "What notification service is used for events impacting pipelines in AWS CodePipeline?", "answer": "The notification service used for events impacting pipelines in AWS CodePipeline is Amazon SNS notifications.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:24:55.349852"}}
{"question": "How can users configure notifications to be sent to their chat applications?", "answer": "Users can configure notifications to be sent to their chat applications, such as Slack Channels or Amazon Chime chat rooms, by using AWS Chatbot.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:24:55.350129"}}
{"question": "How do resource-level permissions in AWS CodePipeline differ from general access permissions?", "answer": "Resource-level permissions in AWS CodePipeline allow you to specify which user can perform what action on a pipeline, such as granting read-only access to a user, whereas general access permissions are broader and do not specify actions at the resource level.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:24:55.350305"}}
{"question": "What functionalities does Amazon Cognito provide for web and mobile applications?", "answer": "Amazon Cognito provides user sign-up, sign-in, access control, and brokered AWS service access for web and mobile applications. It allows developers to easily add these functionalities within minutes.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-04T16:25:01.321568"}}
{"question": "How does Amazon Cognito improve security for applications?", "answer": "Amazon Cognito improves security by offering tenant-based identity stores, federation options, support for social identity providers, and passwordless login using WebAuthn passkeys or SMS and email one-time-passwords. It also supports various compliance standards and operates on open identity standards.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-04T16:25:01.322368"}}
{"question": "What is the difference between Cognito user pools and identity pools in terms of API operations?", "answer": "Cognito user pools and identity pools have separate API operations for authentication. User pools have specific API operations designed for both server-side and client-side applications, while identity pools are intended for federated identities. This distinction allows developers to choose the appropriate API operations based on their application's architecture.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-04T16:25:01.322511"}}
{"question": "What platforms are supported by the AWS Mobile SDK for Cognito?", "answer": "The AWS Mobile SDK for Cognito supports iOS, Android, Unity, and Kindle Fire.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T16:25:06.590697"}}
{"question": "How does Amazon Cognito enhance security during user sign-up and sign-in?", "answer": "Amazon Cognito enhances security during user sign-up and sign-in by allowing the implementation of features such as email verification, phone number verification, and multi-factor authentication (MFA).", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T16:25:06.590959"}}
{"question": "What is the difference between a user pool and an identity pool in Amazon Cognito?", "answer": "A user pool is a tenant-based user directory that securely stores user profile attributes and supports a custom schema, while an identity pool allows for the creation of multiple identities linked to a key/value pair store without any limit on the number of identities. User pools are used for user management, while identity pools are used for providing temporary AWS credentials to access other AWS services.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T16:25:06.591340"}}
{"question": "What features does Amazon Cognito provide to verify user identities during sign-up?", "answer": "Amazon Cognito requires users' email addresses and phone numbers to be verified prior to providing access to the application. During sign-up, a verification code is sent to the user's phone number or email address, which the user must input to complete the sign-up process and become confirmed.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-04T16:25:16.220832"}}
{"question": "How can developers customize user sign-up and sign-in flows in Amazon Cognito?", "answer": "Developers can customize sign-up and sign-in flows using AWS Lambda. They can create AWS Lambda functions to identify fraud or perform additional validations on user data. These functions can be triggered at various stages such as pre-registration, post-confirmation, pre-authentication, during authentication, and post-authentication. Additionally, Lambda functions can be used to customize messages sent for email or phone number verification and multi-factor authentication.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-04T16:25:16.222203"}}
{"question": "How does Amazon Cognito handle compromised credentials compared to password policies?", "answer": "Amazon Cognito supports compromised credentials checking on every user sign-up, sign-in, and password change to ensure that users are not logging in with a password that has been compromised at another site. In contrast, password policies in Cognito are set up to enforce specific requirements such as length of password, character complexity, and password history. While both features enhance security, compromised credentials checking focuses on the security of the password itself, whereas password policies focus on the complexity and management of user passwords.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-04T16:25:16.222573"}}
{"question": "What are the two ways to migrate users to Amazon Cognito user pools?", "answer": "The two ways to migrate users to Amazon Cognito user pools are just-in-time (JIT) migration and bulk migration.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T16:25:24.867920"}}
{"question": "How does just-in-time (JIT) migration work in Amazon Cognito?", "answer": "Just-in-time (JIT) migration in Amazon Cognito works by migrating users' data as they sign in to your application using a built-in AWS Lambda trigger. This trigger allows you to migrate users' data from an external system without requiring them to reset their password.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T16:25:24.868264"}}
{"question": "What is the difference between user pools and identity pools in Amazon Cognito?", "answer": "User pools in Amazon Cognito are primarily used for managing user profiles and authentication, while identity pools are used to create unique identities for users and securely federate them with AWS service providers. User pools store user profiles, whereas identity pools do not. Additionally, identity pools act as a credential broker, allowing users to obtain temporary AWS credentials for accessing AWS resources.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T16:25:24.868730"}}
{"question": "What does the mobile app receive from the Identity Provider after user authentication?", "answer": "After the user is authenticated with the Identity Provider, the mobile app receives either an OpenID Connect token or a SAML assertion.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-04T16:25:32.682833"}}
{"question": "How does Cognito identity pools enhance security when accessing AWS resources?", "answer": "Cognito identity pools enhance security by assigning users a set of temporary, limited-privilege AWS credentials instead of requiring them to use AWS account credentials. This is controlled through AWS IAM roles that can be customized for each user or group, ensuring only the necessary permissions are granted.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-04T16:25:32.683114"}}
{"question": "How do the permissions for authenticated users differ from those for guest users in Cognito identity pools?", "answer": "Authenticated users in Cognito identity pools are assigned a set of temporary, limited-privilege credentials based on IAM roles that can be defined by the application. In contrast, guest users who are not authenticated can be assigned a separate IAM role with limited permissions, allowing for different access levels depending on user authentication status.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-04T16:25:32.683278"}}
{"question": "What types of users does Cognito identity pools support?", "answer": "Cognito identity pools support both unauthenticated users, who do not authenticate with any identity provider and access the app as guests, and authenticated users, who log in using an identity provider.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:25:37.951113"}}
{"question": "How does Cognito identity pools manage identities for unauthenticated users on a single device?", "answer": "Cognito identity pools allow for separate identities on a single device, such as a family iPad. Each identity is treated separately, giving you complete control over how your app logs users in and out, and how local and remote app data is stored.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:25:37.951499"}}
{"question": "What is the difference in identity creation between authenticated and unauthenticated users when using the GetId API in Cognito identity pools?", "answer": "For authenticated identities, each call to the GetId API will create only a single identity for each user. In contrast, for unauthenticated identities, each call to the GetId API will generate a new identity, which can lead to multiple identities being created for a single user if calls are made multiple times.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T16:25:37.951963"}}
{"question": "How are monthly active users (MAUs) counted in Amazon Cognito user pools?", "answer": "A user is counted as a MAU if, within a calendar month, your app generates an identity operation for that user, such as administrative creation or update, sign-up, sign-in, sign-out, token refresh, password change, a user account attribute update, or an attribute query on a user (AdminGetUser API).", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-04T16:25:47.519756"}}
{"question": "What is the significance of the free tier for Amazon Cognito user pools?", "answer": "The Amazon Cognito user pools SKU and Essentials SKU are free for the first 10,000 MAUs. Additionally, customer accounts with active Amazon Cognito user pools before Nov 21, 2024, are eligible for a free tier of 50,000 MAUs.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-04T16:25:47.520127"}}
{"question": "How does the cost for SMS messaging compare to the charges for monthly active users in Amazon Cognito?", "answer": "While you are charged for Amazon Cognito user pools based on your monthly active users (MAUs) and you are not charged for subsequent sessions or inactive users within that month, the use of SMS messaging for tasks such as verifying phone numbers, sending codes for password resets, or multi-factor authentication is charged separately.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-04T16:25:47.520348"}}
{"question": "What is Amazon Comprehend?", "answer": "Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to find meaning and insights in text. It can identify the language of the text, extract key phrases, places, people, brands, or events, understand sentiment about products or services, and identify main topics from a collection of documents.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T16:25:58.904743"}}
{"question": "How does natural language processing (NLP) benefit users of Amazon Comprehend?", "answer": "Natural Language Processing (NLP) benefits users of Amazon Comprehend by allowing computers to analyze, understand, and derive meaning from textual information in a smart and useful way. It enables the extraction of important phrases, sentiment, syntax, key entities such as brands, dates, locations, and people, which can be utilized for various applications like customer feedback analysis and document categorization.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T16:25:58.904949"}}
{"question": "What are some common use cases of Amazon Comprehend, and how do they differ from one another?", "answer": "Some common use cases of Amazon Comprehend include voice of customer analytics, semantic search, and knowledge management and discovery. Voice of customer analytics focuses on gauging customer sentiment from feedback received through various channels. Semantic search improves search experiences by indexing key phrases and sentiment, allowing for intent-based search results. Knowledge management and discovery involves analyzing collections of documents to automatically organize them by topic, which can help personalize content for customers.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T16:25:58.905065"}}
{"question": "Do you need NLP expertise to use Amazon Comprehend?", "answer": "No, you dont need NLP expertise to use Amazon Comprehend. You only need to call Amazon Comprehends API, and the service will handle the machine learning required to extract the relevant data from the text.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-04T16:26:06.972110"}}
{"question": "How does Amazon Comprehend handle the management of machine learning resources?", "answer": "Amazon Comprehend is a fully managed and continuously trained service, so you dont have to manage the scaling of resources, maintenance of code, or maintaining the training data.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-04T16:26:06.972506"}}
{"question": "What is the difference between a low confidence score and a high confidence score in Amazon Comprehend's results?", "answer": "A low confidence score means that the services confidence is low that it is correct, while a high confidence score indicates that the service is highly confident, with the score being closer to 1.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-04T16:26:06.972958"}}
{"question": "What is the main purpose of storing and using text inputs processed by Amazon Comprehend?", "answer": "The main purpose of storing and using text inputs processed by Amazon Comprehend is solely to provide and maintain the service, as well as to develop and improve the quality of Amazon Comprehend and other Amazon machine-learning and artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T16:26:14.264380"}}
{"question": "How does Amazon Comprehend ensure the security and privacy of user content?", "answer": "Amazon Comprehend ensures the security and privacy of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to or disclosure of the content. The trust, privacy, and security of user content are stated as the highest priority.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T16:26:14.264780"}}
{"question": "How does the use of content in Amazon Comprehend differ from that in Amazon Comprehend Medical and Amazon Comprehend Detect PII?", "answer": "The use of content in Amazon Comprehend is focused on improving and developing the service and related technologies, while this does not apply to Amazon Comprehend Medical and Amazon Comprehend Detect PII, indicating that different rules or practices may be in place for these services.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-04T16:26:14.265264"}}
{"question": "What measures does Amazon Comprehend implement to ensure the security of processed content?", "answer": "Amazon Comprehend implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that their use complies with their commitments to you.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-04T16:26:21.524387"}}
{"question": "How does Amazon Comprehend handle the storage of content processed in different AWS regions?", "answer": "Any content processed by Amazon Comprehend is encrypted and stored at rest in the AWS region where it is used. However, some portion of the content may be stored in another AWS region solely for the purpose of continuous improvement and development of the Amazon Comprehend customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-04T16:26:21.524749"}}
{"question": "What is the difference in handling content between Amazon Comprehend and Amazon Comprehend Medical?", "answer": "The context specifies that the described storage and encryption practices apply to Amazon Comprehend but do not apply to Amazon Comprehend Medical, indicating a difference in how content is managed between the two services.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-04T16:26:21.525187"}}
{"question": "What types of recommendations does AWS Compute Optimizer provide?", "answer": "AWS Compute Optimizer provides recommendations for EC2 instance types, EC2 Auto Scaling group configurations, EBS volume configurations, AWS Lambda function memory sizes, task sizes for Amazon ECS services on AWS Fargate, licensing optimization recommendations, and RDS database instance classes.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-04T16:26:27.209156"}}
{"question": "How does AWS Compute Optimizer help users improve workload performance?", "answer": "AWS Compute Optimizer helps users improve workload performance by delivering intuitive and actionable recommendations that identify optimal AWS resource configurations. This includes selecting the right EC2 instance types, EBS volumes, and other resource settings to reduce costs and enhance the efficiency of workloads.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-04T16:26:27.209382"}}
{"question": "What is the difference between EC2 instance recommendations and EBS volume recommendations in AWS Compute Optimizer?", "answer": "EC2 instance recommendations focus on selecting the optimal types of Amazon EC2 instances for both standalone instances and those in Auto Scaling groups, while EBS volume recommendations are specifically about optimizing the configurations of Amazon Elastic Block Store volumes. Both types of recommendations aim to improve workload performance and reduce costs but target different AWS resources.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-04T16:26:27.209741"}}
{"question": "What is the first step to sign up for AWS Compute Optimizer?", "answer": "To sign up for AWS Compute Optimizer, you need to go to the Compute Optimizer console and click 'opt in.' You must have an AWS account to access this service.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T16:26:32.450899"}}
{"question": "Why does AWS Compute Optimizer require access to AWS resource configuration data and CloudWatch metrics?", "answer": "AWS Compute Optimizer requires access to AWS resource configuration data, CloudWatch metrics, and Amazon RDS Performance Insights data to identify the resources to assess and to ensure it has sufficient metrics history before making recommendations.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T16:26:32.451254"}}
{"question": "How do the recommendations from AWS Compute Optimizer differ from those provided by Cost Explorer Resource Rightsizing Recommendations?", "answer": "AWS Compute Optimizer delivers all recommendations regardless of cost implications, while Cost Explorer Resource Rightsizing Recommendations surfaces a subset of these recommendations that may lead to cost savings and augments them with customer-specific cost and savings information to help identify savings opportunities through infrastructure rightsizing.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T16:26:32.451680"}}
{"question": "What does the Savings Estimation Mode in AWS Compute Optimizer allow users to do?", "answer": "The Savings Estimation Mode allows users to choose whether the estimated savings should consider their specific discounts, such as Reserved Instances and Savings Plans. By default, AWS Compute Optimizer estimates savings with discounts, but users can change the settings to see savings before discounts.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-04T16:26:47.577768"}}
{"question": "How does AWS Compute Optimizer infer the workload types running on EC2 instances?", "answer": "AWS Compute Optimizer infers the workload types running on EC2 instances by analyzing the attributes of the resources, which include resource names, tags, utilization characteristics, and configuration. It can identify if instances are running specific applications such as Amazon EMR, Apache Cassandra, Apache Hadoop, Memcached, NGINX, PostgreSQL, Redis, Kafka, or Microsoft SQL Server.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-04T16:26:47.578132"}}
{"question": "In what ways can users influence EC2 instance rightsizing recommendations in AWS Compute Optimizer?", "answer": "Users can influence EC2 instance rightsizing recommendations by adjusting CPU and memory utilization headroom, as well as CPU utilization thresholds. They can also set a customizable list of EC2 instance types for recommendations to ensure that only specific resource constraints, such as application or business needs, are taken into account.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-04T16:26:47.578704"}}
{"question": "What should you do if you expect higher utilization in the future when adjusting the utilization headroom?", "answer": "If you expect higher utilization in the future, or are unsure, you can set a higher headroom to accommodate that expectation.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-04T16:26:53.123408"}}
{"question": "Why might you want to decrease the utilization threshold in AWS Compute Optimizer?", "answer": "You might want to decrease the utilization threshold if your workloads are less sensitive to spikes, as this can lead to more savings by allowing Compute Optimizer to deliver rightsizing recommendations with the right amount of sensitivity for your performance and savings goals.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-04T16:26:53.123780"}}
{"question": "How do resource-level preferences compare to account-level preferences in AWS Compute Optimizer?", "answer": "Resource-level preferences override account-level preferences in AWS Compute Optimizer. This means that if there are overlapping preferences at the resource, account, or organizational levels, the more granular preference, such as resource-level, takes precedence over broader preferences like account-level.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-04T16:26:53.124288"}}
{"question": "What types of resources does AWS Compute Optimizer provide recommendations for?", "answer": "AWS Compute Optimizer provides recommendations for Amazon Elastic Compute Cloud (EC2) instances, EC2 Auto Scaling groups, Amazon Elastic Block Store (EBS) volumes, Amazon Elastic Container Service (ECS) services on AWS Fargate, AWS Lambda functions, Amazon Relational Database Service (RDS) DB instances, and commercial software licenses.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T16:26:59.419020"}}
{"question": "How does AWS Compute Optimizer generate its recommendations?", "answer": "AWS Compute Optimizer generates its recommendations by analyzing metrics from the past 14 days for Amazon EC2 instances, EC2 Auto Scaling groups, and Amazon RDS DB instances. For other resource types, it also analyzes metrics from the past 14 days, but users can change the settings to analyze metrics from 32 or 93 days.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T16:26:59.420242"}}
{"question": "What is the difference between savings opportunity metrics and performance improvement opportunity metrics provided by AWS Compute Optimizer?", "answer": "Savings opportunity metrics quantify the monthly savings achievable by adopting AWS Compute Optimizer recommendations at the account level, resource type level, or resource level. In contrast, performance improvement opportunity metrics quantify the percentage and number of underprovisioned resources at the account level and resource type levels, helping to address resource bottleneck risks.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T16:26:59.420558"}}
{"question": "What is the maximum duration of utilization metrics history that Enhanced infrastructure metrics can analyze for AWS Compute Optimizer?", "answer": "Enhanced infrastructure metrics can analyze up to six times more utilization metrics history than the default option, which means it can analyze up to three months of history compared to the default 14 days.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T16:27:04.937361"}}
{"question": "How does AWS Compute Optimizer determine if SQL Server instances are optimized?", "answer": "AWS Compute Optimizer analyzes current configurations such as SQL Server edition, licensing options, and specific database level features being used. Based on this analysis, it determines whether the SQL Server instances are optimized and generates recommendations based on pre-defined optimization criteria.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T16:27:04.937719"}}
{"question": "How does the licensing recommendation for SQL Server differ between the Enterprise and Standard editions?", "answer": "The licensing recommendation suggests that if you are not using any enterprise-only features or if there is a viable alternative in the Standard edition, you can downgrade from Enterprise to Standard to save up to 73% of SQL Server license costs. This recommendation applies to both EC2 SQL Server license included (LI) and bring-your-own-license (BYOL) instances.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T16:27:04.938222"}}
{"question": "What metrics does AWS Compute Optimizer analyze to generate EC2 instance type recommendations?", "answer": "AWS Compute Optimizer analyzes default CloudWatch metrics, including CPU utilization, network packets per second, local storage throughput, and local storage IOPS, to generate EC2 instance type recommendations.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-04T16:27:10.991963"}}
{"question": "How does AWS Compute Optimizer determine the performance risk of a recommended instance type?", "answer": "AWS Compute Optimizer determines the performance risk by evaluating each resource specification of the recommended instance type, such as CPU, memory, EBS throughput and IOPS, disk throughput and IOPS, and network throughput and PPS. It calculates a risk score for each specification based on the proportion of time during the lookback period when capacity might be constrained, and then selects the highest risk score as the overall performance risk.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-04T16:27:10.992322"}}
{"question": "What is the difference between how AWS Compute Optimizer considers pricing for EC2 instances and how it approaches transient pricing factors?", "answer": "AWS Compute Optimizer considers EC2 instance pricing information, incorporating various pricing dimensions such as on-demand pricing and discounted pricing through Savings Plans or Reserved Instances when delivering recommendations. However, it does not consider transient pricing factors, such as spot pricing.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-04T16:27:10.992887"}}
{"question": "What does AWS Compute Optimizer analyze to provide recommendations for EC2 Auto Scaling groups?", "answer": "AWS Compute Optimizer analyzes your EC2 Auto Scaling groups and their scaling capabilities, as well as instance type configurations, to provide tailored recommendations.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:27:17.626014"}}
{"question": "How does AWS Compute Optimizer determine performance risk for a recommended instance type?", "answer": "AWS Compute Optimizer determines performance risk by evaluating each resource specification of the recommended instance type, such as CPU, memory, EBS throughput and IOPS, disk throughput and IOPS, and network throughput and PPS. It calculates a risk score for each specification based on the proportion of time during the lookback period when capacity might be constrained and selects the highest risk score as the overall performance risk.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:27:17.626304"}}
{"question": "What is the difference between single-instance-type recommendations and mixed-instance-type recommendations in AWS Compute Optimizer?", "answer": "Single-instance-type recommendations are provided when there is only one type of instance in your EC2 Auto Scaling group, while mixed-instance-type recommendations are given when the group is running with multiple instance types. This customization is based on the current instance type configurations of the EC2 Auto Scaling group.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:27:17.626891"}}
{"question": "What pricing factors does AWS Compute Optimizer consider when making recommendations for EC2 Auto Scaling groups?", "answer": "AWS Compute Optimizer considers on-demand pricing and discounted pricing through Savings Plans or Reserved Instances when making recommendations for EC2 Auto Scaling groups. It does not consider transient pricing factors, such as spot pricing.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-04T16:27:25.795313"}}
{"question": "How does AWS Compute Optimizer determine the performance risk associated with recommended EBS volume configurations?", "answer": "AWS Compute Optimizer determines the performance risk by analyzing the likelihood that the recommended option does not meet the performance requirements of your workload. A higher performance risk indicates that you may need to spend more effort validating whether the recommended EBS volume configuration meets the performance requirements.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-04T16:27:25.796405"}}
{"question": "How does AWS Compute Optimizer provide recommendations for Lambda functions that may be overprovisioned in memory sizes compared to those that may benefit from additional CPU power?", "answer": "AWS Compute Optimizer provides recommendations for two categories of Lambda functions: the first category includes functions that may be overprovisioned in memory sizes, for which it suggests downsizing the memory to save costs. The second category includes compute-intensive functions that may benefit from additional CPU power, for which it suggests increasing their memory sizes to trigger an equivalent increase in available CPU and reduce runtime. For functions not falling under these categories, Compute Optimizer does not deliver recommendations.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-04T16:27:25.796640"}}
{"question": "How does AWS Compute Optimizer calculate the would-be cost for Lambda functions?", "answer": "AWS Compute Optimizer calculates the would-be cost for Lambda functions by first identifying optimal memory sizes. It then incorporates public Lambda pricing, expected function runtime, and the number of function invocations over the past 14 days to derive this cost number. This allows users to understand what their Lambda cost would have been had they set the memory size to the recommended option.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-04T16:27:33.206723"}}
{"question": "What types of recommendations does AWS Compute Optimizer provide for Amazon ECS services on AWS Fargate?", "answer": "AWS Compute Optimizer provides task-level CPU and memory size recommendations for Amazon ECS services running on AWS Fargate. It also projects the would-be CPU and memory utilization based on recommended configurations, allowing users to understand how their workloads would have performed if configured as recommended.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-04T16:27:33.207048"}}
{"question": "What is the difference between the recommendations provided for Lambda functions and those for Amazon ECS services on AWS Fargate?", "answer": "The recommendations for Lambda functions focus on optimal memory sizes and associated would-be costs based on public pricing and invocation metrics. In contrast, recommendations for Amazon ECS services on AWS Fargate include optimal CPU and memory sizes, projected utilization metrics, and would-be costs based on new configurations and runtime history. Both utilize a 14-day historical data analysis, but they apply to different AWS services and metrics.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-04T16:27:33.207264"}}
{"question": "What metrics does AWS Compute Optimizer analyze to generate recommendations for RDS DB instances?", "answer": "AWS Compute Optimizer analyzes CloudWatch metrics such as CPU utilization, network utilization, and database connections, as well as Amazon RDS Performance Insights metrics like DBLoad to generate recommendations.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-04T16:27:38.207534"}}
{"question": "How does AWS Compute Optimizer calculate the performance risk score for a recommended instance?", "answer": "Compute Optimizer calculates an individual performance risk score for each resource dimension of the recommended instance, including CPU, EBS throughput, EBS IOPS, and network throughput. The performance risk score is computed as the proportion of time over the historical lookback period where capacity may be constrained in the given resource dimension. The overall performance risk of the recommended instance is determined as the maximum performance risk score across the analyzed resource specifications.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-04T16:27:38.207896"}}
{"question": "What are the requirements for using AWS Compute Optimizer with AWS Organizations?", "answer": "To use AWS Compute Optimizer with AWS Organizations, your organization must have 'all features' enabled, and you must log in as the primary account of your organization.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-04T16:27:38.208371"}}
{"question": "What is AWS Config and what capabilities does it provide?", "answer": "AWS Config is a fully managed service that provides resource inventory, configuration history, and configuration change notifications for security and governance. With AWS Config, users can discover existing AWS resources, record configurations for third-party resources, export a complete inventory of resources with all configuration details, and determine how a resource was configured at any point in time. Its capabilities include compliance auditing, security analysis, resource change tracking, and troubleshooting.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T16:27:44.782629"}}
{"question": "How do AWS Config rules help in managing compliance and risk?", "answer": "AWS Config rules represent desired configurations for resources and are evaluated against configuration changes recorded by AWS Config. The results are available on a dashboard, allowing users to assess their overall compliance and risk status from a configuration perspective. Users can view compliance trends over time and identify which configuration changes caused a resource to drift out of compliance with a rule.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T16:27:44.782990"}}
{"question": "What is the difference between AWS Config rules and conformance packs?", "answer": "AWS Config rules represent desired configurations for individual resources and are evaluated against configuration changes, providing insights on compliance and risk for those resources. In contrast, a conformance pack is a collection of AWS Config rules and remediation actions that is built using a common framework. Conformance packs simplify the deployment and reporting of governance policies and configuration compliance across multiple accounts and Regions, while AWS Config rules focus on specific resource configurations.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T16:27:44.783492"}}
{"question": "What historical information does AWS Config provide regarding resource configurations?", "answer": "AWS Config gives you access to resource configuration history, allowing you to relate configuration changes with AWS CloudTrail events, which may have contributed to those changes. This information provides full visibility, including details such as who made the change and from what IP address, as well as the effects of this change on AWS resources and related resources.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:27:53.482903"}}
{"question": "How can AWS Config rules assist organizations in maintaining compliance?", "answer": "AWS Config rules can help organizations maintain compliance by allowing them to codify best practices for configuring resources, thereby instilling self-governance among users. They can assess compliance with specific standards, such as PCI-DSS or HIPAA, and generate reports for auditors based on the configuration of AWS infrastructure. This capability is particularly beneficial for information security experts monitoring usage activity and configurations for vulnerabilities.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:27:53.483288"}}
{"question": "How do AWS Config rules differ from conformance packs in terms of compliance evaluation?", "answer": "AWS Config rules evaluate resource configurations against the specified configuration rules either periodically or upon detecting changes, while conformance packs provide a framework to build and deploy compliance packages across several accounts. Although both aim to assess compliance, AWS Config rules focus on evaluating individual resource configurations, whereas conformance packs offer a broader framework for managing compliance across multiple accounts and personas.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:27:53.483516"}}
{"question": "What do AWS Config rules evaluate after a configuration change?", "answer": "AWS Config rules evaluate resource configurations only after a configuration change has been completed and recorded by AWS Config.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-04T16:27:58.815730"}}
{"question": "How can you control what you can provision on AWS and configuration parameters during provisioning?", "answer": "To control what you can provision on AWS and configuration parameters used during provisioning, you should use AWS Identity and Access Management (IAM) Policies and AWS Service Catalog respectively.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-04T16:27:58.816092"}}
{"question": "What is the difference between proactive mode and detective mode in AWS Config rules?", "answer": "AWS Config rules can be set to proactive only, detective only, or both proactive and detective modes. However, the context does not specify the specific functions or outcomes of proactive mode versus detective mode.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-04T16:27:58.816317"}}
{"question": "What type of information does AWS CloudTrail record regarding API activity?", "answer": "AWS CloudTrail records user API activity on your account, providing full details about API actions such as the identity of the caller, the time of the API call, the request parameters, and the response elements returned by the AWS service.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-04T16:28:07.430049"}}
{"question": "How does AWS Config help in monitoring compliance status across accounts and Regions?", "answer": "AWS Config helps in monitoring compliance status across multiple accounts and Regions by using the multi-account, multi-Region data aggregation capability. You can create a configuration aggregator in any account to aggregate compliance details from other accounts, which is also leveraged on AWS Organizations to gather data from all accounts within your organization.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-04T16:28:07.430332"}}
{"question": "How do AWS CloudTrail and AWS Config differ in terms of the information they provide about AWS resources?", "answer": "AWS CloudTrail provides information about user API activity, such as who made an API call to modify a resource, including details like the caller's identity and the time of the API call. In contrast, AWS Config records point-in-time configuration details of AWS resources, allowing you to understand what a resource looked like at a specific time. For example, AWS Config can help detect incorrect configurations, while CloudTrail can identify the user who made changes to those configurations.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-04T16:28:07.430480"}}
{"question": "What does the AWS Service Management Connector for ServiceNow and Jira Service Desk allow users to do?", "answer": "The AWS Service Management Connector for ServiceNow and Jira Service Desk allows end users to provision, manage, and operate AWS resources natively using ServiceNow and Jira Service Desk. ServiceNow users can track resources in a configuration item view powered by AWS Config, while Jira Service Desk users can track resources within the issue request.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-04T16:28:12.615226"}}
{"question": "How does the AWS Service Management Connector improve the experience for ServiceNow and Jira Service Desk users?", "answer": "The AWS Service Management Connector simplifies AWS product request actions for ServiceNow and Jira Service Desk users and provides governance and oversight over AWS products for administrators in these platforms.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-04T16:28:12.615591"}}
{"question": "What are the differences in availability for the AWS Service Management Connector for ServiceNow and Jira Service Desk?", "answer": "The AWS Service Management Connector for ServiceNow is available at no charge in the ServiceNow Store, while the connector for Jira Service Desk is available at no charge in the Atlassian Marketplace. Both features are generally available in all AWS Regions where AWS Service Catalog is available.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-04T16:28:12.616121"}}
{"question": "What does a Configuration Item (CI) consist of?", "answer": "A Configuration Item (CI) consists of five sections: basic information about the resource that is common across different resource types (such as Amazon Resource Names and tags), configuration data specific to the resource (such as EC2 instance type), a map of relationships with other resources (such as EC2::Volume vol-3434df43 is 'attached to instance' EC2 Instance i-3432ee3a), CloudTrail event IDs related to this state (only for AWS resources), and metadata that helps identify information about the CI, such as the version of this CI and when this CI was captured.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T16:28:19.253549"}}
{"question": "How does AWS Config handle changes made to a resource's configuration in quick succession?", "answer": "AWS Config detects changes to a resource's configuration and records the configuration state resulting from that change. In cases where several configuration changes are made in quick succession, AWS Config will record only the latest configuration of that resource that represents the cumulative impact of the set of changes. It will list only the latest change in the relatedEvents field of the Configuration Item, allowing users and programs to continue changing infrastructure configurations without waiting for AWS Config to record intermediate transient states.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T16:28:19.253903"}}
{"question": "What is the difference between a standard Configuration Item (CI) and a custom Configuration Item (CI)?", "answer": "A standard Configuration Item (CI) represents the configuration of AWS resources at a given point-in-time, while a custom Configuration Item (CI) is specifically for a third-party or custom resource, such as on-premises databases, Active Directory servers, version control systems like GitHub, and third-party monitoring tools like Datadog.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T16:28:19.254362"}}
{"question": "What does periodic recording in AWS Config allow you to do?", "answer": "Periodic recording allows you to decide how often to record changes in your environment, reducing configuration items from resources that change frequently. It enables you to receive configuration changes every 24 hours instead of continuously, which can help meet various use cases.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-04T16:28:24.137718"}}
{"question": "In what scenarios might continuous recording be more appropriate than periodic recording?", "answer": "Continuous recording may be more appropriate if your security and compliance needs require ongoing monitoring of your resources. This is essential for environments that need real-time updates and tracking of configuration changes to ensure compliance.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-04T16:28:24.138025"}}
{"question": "How does the notification system in AWS Config differ when a resource's compliance status changes to compliant compared to remaining non-compliant?", "answer": "AWS Config sends notifications only when the compliance status changes. If a resource was previously non-compliant and remains non-compliant, no new notification will be sent. However, if the compliance status changes to 'compliant,' a notification will be sent for that change in status.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-04T16:28:24.138244"}}
{"question": "What are the two types of rules in AWS Config?", "answer": "The two types of rules in AWS Config are AWS-managed rules and customer managed rules. AWS-managed rules are pre-built and managed by AWS, while customer managed rules are custom rules defined and built by the user.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-04T16:28:28.713778"}}
{"question": "How does AWS Config evaluate compliance of a resources configuration?", "answer": "AWS Config evaluates compliance of a resources configuration by using the data included in the Configuration Item (CI) of the resource, along with other relevant information such as attached resources and business hours, to compare the CI attribute values with those defined in the AWS Config rules.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-04T16:28:28.714159"}}
{"question": "What is the difference between AWS-managed rules and customer managed rules in terms of updates?", "answer": "With AWS-managed rules, updates to the rule are automatically applied to any account using that rule. In contrast, customer managed rules are fully maintained by the customers, who have their own copies of the rules and must apply any updates themselves.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-04T16:28:28.714672"}}
{"question": "What are the two types of rules that can be set up in AWS Config?", "answer": "The two types of rules that can be set up in AWS Config are change-triggered rules and periodic rules.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-04T16:28:32.995733"}}
{"question": "How does AWS Config determine if a resource is compliant?", "answer": "A resource is compliant if it observes all rules that apply to it. If it does not comply with all applicable rules, it is considered noncompliant.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-04T16:28:32.996070"}}
{"question": "What is the difference between change-triggered rules and periodic rules in terms of their initiation?", "answer": "Change-triggered rules are applied when AWS Config records a configuration change for specified resources, whereas periodic rules are initiated at a specified frequency, such as every 1 hr, 3 hr, 6 hr, 12 hr, or 24 hrs.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-04T16:28:32.996493"}}
{"question": "What overview does the AWS Config rules dashboard provide?", "answer": "The AWS Config rules dashboard gives you an overview of resources tracked by AWS Config and a summary of current compliance by resource and by rule.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-04T16:28:37.938500"}}
{"question": "How do conformance packs simplify compliance management in AWS?", "answer": "Conformance packs simplify compliance management by packaging rules along with remediation actions into a single entity that can be deployed across an entire organization with a single selection, thereby facilitating aggregated compliance reporting at the pack level and ensuring immutability of managed rules and remediation documents.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-04T16:28:37.938839"}}
{"question": "How do AWS Config rules and AWS Security Hub CSPM relate to each other?", "answer": "AWS Security Hub CSPM uses AWS Config and AWS Config rules as its primary mechanism to evaluate the configuration of AWS resources, indicating a direct relationship where AWS Config rules serve as a foundational component for security and compliance posture management in AWS Security Hub CSPM.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-04T16:28:37.939051"}}
{"question": "What is the purpose of AWS Config conformance packs?", "answer": "AWS Config conformance packs simplify the management of AWS Config rules by packaging a group of AWS Config rules and associated remediation actions into a single entity. This packaging helps in the deployment of rules and remediation actions across an organization and enables aggregated reporting, as compliance summaries can be reported at the pack level.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T16:28:45.164960"}}
{"question": "How do AWS Security Hub CSPM and AWS Config conformance packs support continuous compliance monitoring?", "answer": "Both AWS Security Hub CSPM and AWS Config conformance packs support continuous compliance monitoring by relying on AWS Config and AWS Config rules. The underlying AWS Config rules can be triggered either periodically or upon detecting changes to the configuration of resources, allowing for continuous auditing and assessment of the overall compliance of AWS resource configurations with an organizations policies and guidelines.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T16:28:45.165295"}}
{"question": "What are the differences between AWS Security Hub CSPM and AWS Config conformance packs in terms of compliance standard management?", "answer": "AWS Security Hub CSPM is designed to operationalize existing compliance standards, such as PCI DSS, and provides integration with Amazon Detective for investigating findings and with Amazon EventBridge for remediation actions. In contrast, AWS Config conformance packs allow users to assemble their own compliance or security standards, which can include various checks, and simplify the management of AWS Config rules through packaging. This means Security Hub CSPM focuses on using predefined standards while Config conformance packs enable customization.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T16:28:45.165816"}}
{"question": "What is the primary function of the data aggregation capability in AWS Config?", "answer": "The primary function of the data aggregation capability in AWS Config is to provide visibility into your compliance. It is purely a reporting capability and cannot be used for provisioning rules across multiple accounts.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-04T16:28:50.078472"}}
{"question": "How does an aggregator in AWS Config enhance compliance visibility across multiple accounts and Regions?", "answer": "An aggregator in AWS Config enhances compliance visibility by collecting AWS Config data from multiple accounts and Regions. It allows users to view the resource configuration and compliance data recorded on AWS Config for these accounts and Regions. The aggregated view displays the total count of non-compliant rules, the top five non-compliant rules by number of resources, and the top five AWS accounts with the highest number of non-compliant rules, enabling more detailed analysis of compliance issues.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-04T16:28:50.078723"}}
{"question": "How does the data aggregation capability differ from AWS CloudFormation StackSets in terms of functionality?", "answer": "The data aggregation capability is focused on reporting and providing visibility into compliance across multiple accounts and Regions, while AWS CloudFormation StackSets is used for provisioning rules across multiple accounts and Regions. In summary, data aggregation cannot provision rules but can aggregate compliance data, whereas StackSets can provision resources.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-04T16:28:50.078889"}}
{"question": "What factors determine the charges for using AWS Config?", "answer": "Charges for using AWS Config are based on the number of configuration items recorded, the number of active AWS Config rule evaluations, and the number of conformance pack evaluations in your account.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-04T16:28:54.384952"}}
{"question": "What is the difference between continuous and periodic recording in AWS Config?", "answer": "Continuous recording in AWS Config records and delivers configuration changes whenever a change occurs, while periodic recording delivers configuration data once every 24 hours, but only if a change has occurred.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-04T16:28:54.385292"}}
{"question": "How do managed rules differ from custom rules in AWS Config in terms of maintenance and charges?", "answer": "Managed rules in AWS Config are fully maintained by AWS, and there are no additional Lambda charges to run them, while custom rules provide full control as they are applied as Lambda functions in your account and incur monthly charges for being active, as well as standard Lambda function application rates.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-04T16:28:54.385812"}}
{"question": "Which APN Partner solutions provide offerings that are integrated with AWS Config?", "answer": "APN Partner solutions that provide offerings fully integrated with data from AWS Config include Splunk, ServiceNow, Evident.io, CloudCheckr, Redseal, and Red Hat CloudForms.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-04T16:28:59.806400"}}
{"question": "What are the benefits of using AWS Config Rules in conjunction with partner solutions?", "answer": "The benefits of using AWS Config Rules in conjunction with partner solutions include capabilities such as change management and security analysis, which help users visualize, monitor, and manage AWS resource configurations.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-04T16:28:59.806743"}}
{"question": "How do managed service providers integrate with AWS Config compared to APN Partner solutions?", "answer": "Managed service providers like 2nd Watch and Cloudnexa have announced integrations with AWS Config, while APN Partner solutions offer fully integrated offerings that utilize data from AWS Config. This indicates that both types of providers are leveraging AWS Config, but APN Partners specifically provide solutions with a focus on comprehensive integration with AWS Config data.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-04T16:28:59.806954"}}
{"question": "What is the main purpose of AWS Control Tower?", "answer": "The main purpose of AWS Control Tower is to offer the easiest way to set up and govern a secure, multi-account AWS environment. It establishes a landing zone based on best-practices blueprints and enables governance using controls from a pre-packaged list.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-04T16:29:05.783930"}}
{"question": "How does AWS Control Tower benefit organizations building a new AWS environment?", "answer": "AWS Control Tower benefits organizations building a new AWS environment by providing prescriptive guidance to govern the AWS environment at scale. It allows organizations to control their environment without sacrificing speed and agility, making it suitable for those starting out on their AWS journey or initiating new cloud initiatives.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-04T16:29:05.784270"}}
{"question": "How does AWS Control Tower facilitate governance compared to traditional methods?", "answer": "AWS Control Tower facilitates governance by providing a single location to set up a well-architected multi-account environment and govern AWS workloads with rules for security, operations, and compliance. It allows distributed teams to quickly provision new AWS accounts while ensuring that all accounts align with centrally established company-wide policies, which is more efficient than traditional governance methods that may lack such centralized control.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-04T16:29:05.784469"}}
{"question": "What is the purpose of AWS Control Tower?", "answer": "The purpose of AWS Control Tower is to automate the creation of a landing zone with best-practices blueprints that configure AWS Organizations for a multi-account structure, provide identity management using AWS IAM Identity Center, create a central log archive using AWS CloudTrail and AWS Config, enable security audits, implement network configurations using Amazon VPC, and define workflows for provisioning accounts and associated AWS Control Tower solutions.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-04T16:29:13.125558"}}
{"question": "How does AWS Control Tower manage governance across AWS accounts?", "answer": "AWS Control Tower manages governance across AWS accounts by offering preventive, detective, and proactive controls that help govern resources and monitor compliance. These controls are prepackaged governance rules for security, operations, and compliance that can be applied enterprise-wide or to specific groups of AWS accounts. AWS Control Tower implements these controls using building blocks such as AWS CloudFormation, AWS Organizations service control policies, AWS Config rules, and AWS CloudFormation Hooks.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-04T16:29:13.125895"}}
{"question": "How does the account provisioning process in AWS Control Tower compare to extending governance to existing accounts?", "answer": "The account provisioning process in AWS Control Tower uses the Account Factory to automate the creation of new AWS accounts that are preconfigured to meet business, security, and compliance requirements. In contrast, extending governance to existing accounts involves enrolling those accounts into an organization unit (OU) that is already governed by AWS Control Tower, allowing them to benefit from the governance framework without needing to be provisioned anew.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-04T16:29:13.126388"}}
{"question": "What capabilities does AWS Control Tower provide to help meet digital sovereignty requirements?", "answer": "AWS Control Tower offers a set of AWS-managed controls and enhanced Region deny capabilities that help meet digital sovereignty requirements. Users can select from various digital sovereignty controls in the AWS Control Tower control library to implement controls that prevent actions, enforce configurations, detect resource changes for data residency, granular access restriction, encryption, and resiliency capabilities.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:29:20.117739"}}
{"question": "How can organizations customize the Region deny control in AWS Control Tower?", "answer": "Organizations can customize AWS Control Towers Region deny control to apply regional restrictions that best fit their unique business needs. This customization allows them to address specific requirements regarding where their data can reside and how it can be accessed.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:29:20.118024"}}
{"question": "What is the difference between using AWS Control Tower and AWS Managed Services (AMS) for regulated infrastructure operations?", "answer": "AWS Control Tower helps deploy a multi-account AWS environment based on best practices, but the user is still responsible for day-to-day operations and checking compliance status. In contrast, AWS Managed Services (AMS) is best suited for enterprises that want to move regulated workloads to the cloud quickly and do not have the required AWS skillsets for compliant operations, or those that prefer to keep AWS talent focused on application migration and modernization instead of infrastructure operations.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:29:20.118190"}}
{"question": "What is the primary function of AWS Control Tower?", "answer": "The primary function of AWS Control Tower is to offer an abstracted, automated, and prescriptive experience on top of AWS Organizations, enabling users to set up and govern a secure, multi-account AWS environment based on AWS best practices.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-04T16:29:28.654517"}}
{"question": "How does AWS Control Tower complement AWS Security Hub?", "answer": "AWS Control Tower and AWS Security Hub are complementary services where AWS Control Tower is used by cloud administrators to set up and govern AWS accounts, while AWS Security Hub is used by security teams to continuously monitor and improve security posture. Control Tower applies high-level rules to enforce policies and aligns account configurations with security best practices, which are checked by AWS Security Hub.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-04T16:29:28.654840"}}
{"question": "How does AWS Control Tower's governance at the account level compare to AWS Service Catalog's governance?", "answer": "AWS Control Tower provides central governance at an account level, while AWS Service Catalog offers granular governance at a resource level. This means that Control Tower governs overall account configurations and policies, whereas Service Catalog focuses on the provisioning of specific infrastructure and application stacks that have been preapproved by IT for use within those accounts.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-04T16:29:28.655352"}}
{"question": "What is the primary purpose of AWS Control Tower?", "answer": "The primary purpose of AWS Control Tower is to set up and govern your AWS environment.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-04T16:29:33.257437"}}
{"question": "How does AWS Systems Manager aid in the management of AWS resources?", "answer": "AWS Systems Manager aids in the management of AWS resources by providing a unified user interface to view operational data from multiple AWS services and automate operational tasks across AWS resources.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-04T16:29:33.257729"}}
{"question": "How do AWS Control Tower and AWS Systems Manager differ in their functions?", "answer": "AWS Control Tower is designed for setting up and governing the AWS environment, including customizing accounts and automating resource provisioning, while AWS Systems Manager is focused on managing the day-to-day operations of AWS resources, including grouping resources, monitoring operational data, and automating operational tasks.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-04T16:29:33.258180"}}
{"question": "What does the AWS Copilot CLI help developers do?", "answer": "The AWS Copilot CLI is a tool that helps developers build, release, and operate production-ready containerized applications on Amazon ECS and AWS Fargate. It simplifies the process by providing best practices for infrastructure and continuous delivery directly from the command line.", "question_type": "factual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-04T16:29:39.017868"}}
{"question": "How does AWS Copilot simplify the deployment of containerized applications?", "answer": "AWS Copilot simplifies the deployment of containerized applications by allowing developers to use a single command to provision all the necessary infrastructure for running production-ready services. It eliminates the need to install multiple tools, configure deployment pipelines step by step, or create and stitch together various AWS resources for common architectures like load balanced web applications.", "question_type": "conceptual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-04T16:29:39.018209"}}
{"question": "What resources does AWS Copilot create on behalf of the user, and how can they be configured?", "answer": "AWS Copilot creates several resources on behalf of the user, including ECS clusters, tasks, services (for EC2 and Fargate launch types), load balancers, VPC, and ECR registries. These resources are configured based on AWS's opinionated best practices by default, but they can be changed if required.", "question_type": "comparison", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-04T16:29:39.018661"}}
{"question": "What license does AWS Copilot use?", "answer": "AWS Copilot is licensed under the terms of the Apache 2.0 license.", "question_type": "factual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-04T16:29:43.159909"}}
{"question": "How does AWS Copilot charge customers for its use?", "answer": "Amazon does not charge for the use or distribution of AWS Copilot. Customers only pay for the resources they create through the CLI, which can include Fargate tasks, Amazon VPC, or AWS CodePipeline, and they are billed according to the pricing of those resources.", "question_type": "conceptual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-04T16:29:43.160265"}}
{"question": "How does the deployment capability of AWS Copilot differ between Fargate and EC2?", "answer": "Currently, AWS Copilot deploys applications to AWS Fargate on Amazon ECS. Deployments to the EC2 launch type are expected to be available soon.", "question_type": "comparison", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-04T16:29:43.160695"}}
{"question": "What type of files can AWS Cost and Usage Reports be exported as?", "answer": "AWS Cost and Usage Reports can be exported as either a CSV or Parquet file.", "question_type": "factual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:29:49.304896"}}
{"question": "How can organizations utilize AWS Cost and Usage Reports for cost optimization?", "answer": "Organizations can utilize AWS Cost and Usage Reports to perform detailed cost optimization, reporting, and allocation activities. The reports provide the most comprehensive set of cost and usage data, allowing organizations to break down costs by various dimensions such as hour, day, month, product, resource, or defined tags.", "question_type": "conceptual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:29:49.305210"}}
{"question": "What is the relationship between Split Cost Allocation Data and Amazon ECS in AWS Cost and Usage Reports?", "answer": "Split Cost Allocation Data is a feature that enables cost visibility for all Amazon ECS container objects across an entire consolidated billing family, which includes both payer and linked accounts. By opting into this feature, users can access Amazon ECS task cost and usage data in their AWS Cost and Usage Reports.", "question_type": "comparison", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:29:49.305417"}}
{"question": "What is the purpose of Split Cost Allocation Data for Amazon ECS and AWS Batch?", "answer": "The purpose of Split Cost Allocation Data for Amazon ECS and AWS Batch is to allocate the cost of EC2 instances to containerized workloads running on these instances by generating container-level costs. This is achieved by analyzing each containers resource consumption based on the price of the EC2 instance and the percentage of CPU and memory resources consumed by the containers.", "question_type": "factual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-04T16:29:56.267648"}}
{"question": "How does Split Cost Allocation Data help in understanding costs associated with container workloads?", "answer": "Split Cost Allocation Data helps in understanding costs associated with container workloads by breaking down the costs at the container level. It analyzes the resource consumption of each container on the EC2 instances, allowing users to see how much each container is costing based on the instance pricing and the resources utilized, such as CPU and memory.", "question_type": "conceptual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-04T16:29:56.267996"}}
{"question": "What is the relationship between Cost Management preferences and the visibility of Split Cost Allocation Data in the AWS Cost and Usage Reports?", "answer": "The relationship is that only regular and payer accounts have access to Cost Management preferences, which allows them to opt into Split Cost Allocation Data. Once they opt in, member accounts can view this data in the AWS Cost and Usage Reports (CUR). It is also noted that there may be a delay of up to 24 hours for the data to be visible in the CUR after opting in.", "question_type": "comparison", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-04T16:29:56.268445"}}
{"question": "What is AWS Data Exchange used for?", "answer": "AWS Data Exchange is used for securely exchanging and using third-party data on AWS. It provides access to data for various roles, including data analysts, product managers, and data scientists, to drive analytics, train machine learning models, and make data-driven decisions.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-04T16:30:02.999940"}}
{"question": "Why is AWS Data Exchange beneficial for organizations looking to provide data?", "answer": "AWS Data Exchange is beneficial for organizations looking to provide data because it simplifies the process of making data available for research or commercial purposes. It eliminates the challenges and costs associated with building and maintaining data delivery, entitlement, and billing technology, thereby increasing the supply of valuable data.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-04T16:30:03.000265"}}
{"question": "How does the product catalog in AWS Data Exchange differ from the underlying resources?", "answer": "The product catalog in AWS Data Exchange is a single global catalog offered by providers that is available from any supported AWS Region. In contrast, the underlying resources, such as data sets, revisions, and assets, are regional resources that must be managed programmatically or through the AWS Data Exchange console in specific AWS Regions.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-04T16:30:03.000463"}}
{"question": "What is the main function of AWS Data Exchange?", "answer": "The main function of AWS Data Exchange is to enable customers to discover and access over 100 petabytes of high-value, cloud-optimized data sets available for public use from leading organizations such as NOAA, NASA, or the UK Met Office.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:30:12.860741"}}
{"question": "How do open data sets differ from commercial or free data sets in terms of access requirements?", "answer": "Open data sets can be accessed without any authentication via S3 APIs, while commercial or free data sets require customers to authenticate using an AWS account to subscribe.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:30:12.861067"}}
{"question": "What are the differences in the requirements for becoming a data provider on AWS Data Exchange versus the Registry of Open Data on AWS?", "answer": "To become a data provider on AWS Data Exchange, qualified customers must register as a data provider on the AWS Marketplace Management Portal to list both free and commercial products. In contrast, any customer can add free data to the Registry of Open Data on AWS through GitHub and may apply to the Open Data Sponsorship Program to sponsor costs of storage and bandwidth for select open data sets.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T16:30:12.861528"}}
{"question": "How many data products are available on AWS Data Exchange?", "answer": "Today, AWS Data Exchange contains more than 3,500 data products from a broad range of domains.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 466, "generated_at": "2026-02-04T16:30:19.126830"}}
{"question": "What is the purpose of Amazon CloudWatch Events in relation to AWS Data Exchange subscriptions?", "answer": "As a subscriber with an active subscription to a product, you'll receive an Amazon CloudWatch Events event from AWS Data Exchange every time the provider publishes new revisions. This allows you to automate the consumption of new data.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 466, "generated_at": "2026-02-04T16:30:19.127034"}}
{"question": "What are the differences between public and private offers in terms of auto-renewal on AWS Data Exchange?", "answer": "Auto-renewal is available for both public and private offers that do not have payment schedules. However, the specific terms and conditions may vary between public and private offers, but the text does not provide further distinctions.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 466, "generated_at": "2026-02-04T16:30:19.127180"}}
{"question": "Can data providers change the terms of their offers on AWS Data Exchange?", "answer": "Yes, data providers can update the terms of the offer at any time, but this will not affect existing subscriptions.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T16:30:23.893655"}}
{"question": "What is the shared responsibility model in the context of AWS Data Exchange?", "answer": "Security and Compliance is a shared responsibility among AWS, the data provider, and the subscriber. Each party has a role in ensuring legal compliance and security.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T16:30:23.894007"}}
{"question": "How do the terms for auto-renewing subscriptions differ from original subscription terms?", "answer": "For subscriptions set to auto-renew, AWS Data Exchange will automatically renew the subscription at the latest terms specified by the provider on or by the renewal date, which may be different from the original subscription terms.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-04T16:30:23.894214"}}
{"question": "What should I do if I suspect that AWS Data Exchange resources are being used for abusive or illegal purposes?", "answer": "If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on Report Amazon AWS abuse. AWS may remove the subscribers access to the data product and may suspend or terminate the data provider or the subscriber from future use of AWS Data Exchange if our terms are breached in any way.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-04T16:30:31.467414"}}
{"question": "How does AWS Data Exchange simplify the data acquisition process?", "answer": "AWS Data Exchange centralizes, simplifies, and accelerates the data acquisition process by allowing users to consolidate ingestion across data providers and receive data using a single API. It enables easy subscription to new data products, migration of existing data feeds through the Bring Your Own Subscription feature, and automates ingestion through CloudWatch Events without managing physical media or legacy technology.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-04T16:30:31.467782"}}
{"question": "What are the differences in invoicing when purchasing a data product with upfront payments versus multiple payments on AWS Data Exchange?", "answer": "When you purchase a data product on AWS Data Exchange with upfront payments, you receive an invoice from AWS immediately. In contrast, when you purchase a data product with multiple payments, you receive an invoice based on the dates specified in the payment schedule, which appears as part of your AWS Marketplace charges. Additionally, you can see a breakout of charges for each data product by name in the Detail section of the invoice.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-04T16:30:31.468011"}}
{"question": "What steps should I take to subscribe to an API product on AWS Data Exchange?", "answer": "To subscribe to an API product on AWS Data Exchange, first find the API you want to subscribe to and select the product to view the product detail page. Then, choose 'Continue to subscribe', review the subscription terms, and click the 'Subscribe' button at the bottom of the page. Note that you may need to submit information to the data provider before you can request to subscribe.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-04T16:30:38.579109"}}
{"question": "How can I structure my API calls after subscribing to a product containing an API data set?", "answer": "After successfully subscribing to a product containing an API data set, you should navigate to the products asset detail page to view API schemas and code snippets that will assist you in structuring your API calls. Additionally, you can use the AWS SDK to automatically sign your API requests with your AWS credentials.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-04T16:30:38.579480"}}
{"question": "What is the difference between subscription durations offered by data providers on AWS Data Exchange?", "answer": "Data providers on AWS Data Exchange list product subscriptions with duration terms ranging from 1 to 36 months. This means that the subscription duration options can vary widely, allowing subscribers to choose a term that best fits their needs based on the individual products detail page.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-04T16:30:38.579988"}}
{"question": "Can data providers change the terms of their offers after subscriptions have been made?", "answer": "Yes, data providers can update the terms of the offer at any time, but this will not affect existing subscriptions.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T16:30:43.679880"}}
{"question": "What is the shared responsibility model regarding security and compliance in AWS Data Exchange?", "answer": "Security and Compliance is a shared responsibility among AWS, the data provider, and the subscriber. Each party is responsible for conducting their own additional due-diligence to ensure compliance with any data privacy laws.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T16:30:43.680217"}}
{"question": "How does the auto-renewal of subscriptions differ from the original subscription terms?", "answer": "For subscriptions set to auto-renew, AWS Data Exchange will automatically renew the subscription at the latest terms that the provider specified on or by the renewal date, which may be different from the original subscription terms.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T16:30:43.680732"}}
{"question": "What should you do if you suspect that AWS Data Exchange resources are being used for illegal purposes?", "answer": "If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on Report Amazon AWS abuse.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:30:49.769428"}}
{"question": "How does AWS Data Exchange simplify the data acquisition process?", "answer": "AWS Data Exchange centralizes, simplifies, and accelerates your data acquisition process by allowing you to consolidate your ingestion across data providers and receive your data using a single API. It also enables easy subscription to new data products and migration of existing data feeds through the Bring Your Own Subscription feature.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:30:49.769741"}}
{"question": "What are the differences in billing when purchasing a data product on AWS Data Exchange with upfront payments versus multiple payments?", "answer": "When you purchase a data product on AWS Data Exchange with upfront payments, you'll receive an invoice from AWS immediately. In contrast, when you purchase a data product with multiple payments, you'll receive an invoice based on the dates specified in the payment schedule that will appear as part of your AWS Marketplace charges.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-04T16:30:49.770015"}}
{"question": "What should you do after selecting the product on the product detail page to subscribe to an API?", "answer": "After selecting the product on the product detail page, you should choose 'Continue to subscribe', review the subscription terms, and then choose the 'Subscribe' button at the bottom of the page.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-04T16:30:54.529521"}}
{"question": "Why might you need to submit information to the data provider before subscribing to their product?", "answer": "You may be asked to submit information to the data provider before you can request to subscribe to their product as part of their subscription process.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-04T16:30:54.529865"}}
{"question": "How does the AWS Data Exchange for APIs differ from standard AWS services in terms of service level agreements?", "answer": "The AWS Data Exchange for APIs does not currently offer a Service Level Agreement (SLA), which is a difference compared to some standard AWS services that may offer SLAs.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-04T16:30:54.530291"}}
{"question": "What are the three building blocks used to organize data in AWS Data Exchange?", "answer": "The three building blocks used to organize data in AWS Data Exchange are data sets, revisions, and assets.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T16:31:00.077990"}}
{"question": "How does enabling subscription verification benefit public products in AWS Data Exchange?", "answer": "Enabling subscription verification for public products requires prospective subscribers to fill out a subscription request form, including their identity and intended use-case details, before subscribing. This process allows data providers to evaluate and approve or decline subscription requests, ensuring better control over who accesses the data, especially for products that include personal data, which are mandated to have this verification enabled.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T16:31:00.078350"}}
{"question": "What is the difference between public products and private products in AWS Data Exchange?", "answer": "Public products are available to all subscribers and are listed in the AWS Data Exchange catalog, while private products are custom-made for specific subscribers and are not listed in the public catalog. Private products can be based on existing public products or can be entirely new products designed exclusively for certain customers.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-04T16:31:00.078833"}}
{"question": "What is required of data providers before they can distribute data on AWS Data Exchange?", "answer": "Data providers must attest that they have the legal right to distribute the data they publish, as required by the Terms and Conditions for AWS Marketplace Providers.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-04T16:31:07.607043"}}
{"question": "How does AWS Data Exchange ensure compliance with its acceptable use policy?", "answer": "AWS Data Exchange may suggest corrective action where there is evidence of abuse; however, it is the data providers responsibility to enforce and govern the terms of use.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-04T16:31:07.607295"}}
{"question": "What differentiates data products available for free from those that have a subscription-based pricing on AWS Data Exchange?", "answer": "Data products available for free are typically provided for research, scientific, or other noncommercial use cases, while subscription-based pricing on AWS Data Exchange can range from 1- to 36-month duration terms.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-04T16:31:07.607454"}}
{"question": "Can I unpublish a product on AWS Data Exchange at any time?", "answer": "Yes, you can unpublish a product at any time to ensure that no new subscribers can view and subscribe to your product, including auto-renewal cancellation for existing subscribers. However, you need to keep data current for any existing subscribers until each subscription expires.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-04T16:31:15.131690"}}
{"question": "What happens to existing subscriptions if I change the price or Data Subscription Agreement (DSA) of a product?", "answer": "If you change the price or Data Subscription Agreement (DSA) of a product, existing subscriptions will remain in effect until their next renewal.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-04T16:31:15.132037"}}
{"question": "How does AWS handle customer data privacy in relation to data products listed on AWS Data Exchange?", "answer": "AWS is vigilant about customer privacy. Companies listing data products on the AWS Data Exchange own them and maintain control over who accesses their content. AWS does not access or use data products except as necessary to provide the AWS Data Exchange service.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-04T16:31:15.132547"}}
{"question": "What are the three reusable constructs in the data model for AWS Data Exchange?", "answer": "The three reusable constructs in the data model for AWS Data Exchange are data sets, revisions, and assets.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-04T16:31:20.749475"}}
{"question": "How does AWS Data Exchange simplify the management of data permissions for subscribers?", "answer": "AWS Data Exchange simplifies the management of data permissions by automatically granting entitlements to customers who have an active subscription to the product. This means that providers do not have to manually configure and maintain custom permissions to an Amazon Simple Storage Service (S3) bucket for each subscription.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-04T16:31:20.749808"}}
{"question": "How does the Bring Your Own Subscription (BYOS) feature differ from publishing a new product on AWS Data Exchange?", "answer": "The Bring Your Own Subscription (BYOS) feature allows providers to configure an entitlement to their existing subscribers for no additional cost and without any additional programming work, whereas publishing a new product on AWS Data Exchange involves setting up an AWS account, registering as an AWS Marketplace seller, and following specific steps to publish an API product.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-04T16:31:20.750314"}}
{"question": "What is the response time required for providers of products containing APIs to subscriber support inquiries?", "answer": "Providers of products containing APIs must respond to subscriber support inquiries within 1 business day, as specified in the AWS Data Exchange User Guide.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-04T16:31:26.203554"}}
{"question": "What are the implications of not following the guidelines set forth for AWS Data Exchange?", "answer": "Not following the guidelines may result in products being removed from AWS Data Exchange.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-04T16:31:26.203898"}}
{"question": "How do public products with personal data differ from other public products in terms of subscription verification?", "answer": "Public products that include personal data are required to have subscription verification enabled, which requires prospective subscribers to fill out a subscription request form including their identity and intended use-case details before subscribing. Other public products may not have this requirement.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-04T16:31:26.204320"}}
{"question": "What is the purpose of the Data Subscription Agreement (DSA) template provided by AWS Data Exchange?", "answer": "The Data Subscription Agreement (DSA) template provided by AWS Data Exchange incorporates inputs from multiple AWS customers and data providers. Users can choose to use this template, copy and edit it with their own terms and conditions, or specify custom terms by uploading a DSA of their choice.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T16:31:31.091235"}}
{"question": "What are the options available for pricing terms in AWS Data Exchange?", "answer": "AWS Data Exchange currently supports subscription-based pricing with duration terms ranging from 1 to 36 months.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T16:31:31.091571"}}
{"question": "How does the option to unpublish a product in AWS Data Exchange affect existing subscriptions?", "answer": "When a product is unpublished in AWS Data Exchange, no new subscribers can view and subscribe to the product, including auto-renewal cancellation for existing subscribers. However, data providers must keep the data current for any existing subscribers until each subscription expires.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T16:31:31.092066"}}
{"question": "How often will I receive a disbursement for subscriptions on AWS?", "answer": "You will receive a disbursement for subscriptions once a month.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-04T16:31:35.674680"}}
{"question": "What is the purpose of enabling collection and remittance of US sales and use tax when listing data sets?", "answer": "Enabling collection and remittance of US sales and use tax allows you to configure your tax nexus to account for places where you have a physical presence, directing AWS to collect the appropriate taxes.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-04T16:31:35.675021"}}
{"question": "What control do companies have over their data products listed on AWS Data Exchange compared to AWS's access to these products?", "answer": "Companies listing data products on the AWS Data Exchange own them and maintain control over who accesses their content, while AWS does not access or use the data products except as necessary to provide the AWS Data Exchange service.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-04T16:31:35.675231"}}
{"question": "What are the three reusable constructs of the AWS Data Exchange data model?", "answer": "The three reusable constructs of the AWS Data Exchange data model are data sets, revisions, and assets.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-04T16:31:41.893008"}}
{"question": "How does AWS Data Exchange simplify the management of data publishing for providers?", "answer": "AWS Data Exchange simplifies the management of data publishing for providers by allowing them to publish data simultaneously to all customers through an easy-to-use API and console, reducing the need to manage logistics. Additionally, it automatically grants entitlements to customers with active subscriptions and sends events to subscribers when new revisions are published, which helps in automating data consumption.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-04T16:31:41.894229"}}
{"question": "What is the difference between AWS Data Exchange's entitlement management and the manual configuration of permissions for S3 buckets?", "answer": "AWS Data Exchange automatically grants entitlements to customers with active subscriptions, eliminating the need for providers to manually configure and maintain custom permissions for each subscription in an Amazon Simple Storage Service (S3) bucket. This automated approach streamlines the process compared to the manual configuration required for S3 buckets.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-04T16:31:41.894502"}}
{"question": "What is the maximum response time for providers of products containing APIs to respond to subscriber support inquiries?", "answer": "Providers of products containing APIs must respond to subscriber support inquiries within 1 business day.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-04T16:31:46.597106"}}
{"question": "What are the consequences of not following the guidelines set forth for AWS Marketplace Sellers and the AWS Customer Agreement?", "answer": "Not following the guidelines may result in products being removed from AWS Data Exchange.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-04T16:31:46.597446"}}
{"question": "Can a data provider publish products containing multiple data set types, and how does this relate to the guidelines mentioned?", "answer": "Yes, as a data provider, you can publish products containing multiple data set types, and this is in addition to following the guidelines under the Terms and Conditions for AWS Marketplace Sellers and the AWS Customer Agreement.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-04T16:31:46.597974"}}
{"question": "What does ETL stand for in the context of data processing?", "answer": "ETL stands for extract, transform, and load. It refers to the database functions where extract involves collecting data from some source, transform entails any processes performed on that data, and load means sending the processed data to a destination such as a warehouse, datalake, or analytical tool.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-04T16:31:53.217932"}}
{"question": "How does Amazon Data Firehose facilitate real-time analytics?", "answer": "Amazon Data Firehose facilitates real-time analytics by capturing, transforming, and loading streaming data into various destinations such as Amazon S3, Amazon Redshift, Amazon OpenSearch Service, Snowflake, Apache Iceberg tables, and Splunk. This allows for near real-time analytics with existing business intelligence tools and dashboards.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-04T16:31:53.218150"}}
{"question": "In what ways is Amazon Data Firehose different from traditional ETL processes?", "answer": "Amazon Data Firehose is different from traditional ETL processes in that it is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. Additionally, it can batch, compress, and encrypt data before loading, which minimizes storage usage at the destination and increases security.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-04T16:31:53.218313"}}
{"question": "What are some examples of sources that can generate streaming data for Firehose?", "answer": "Some examples of sources that can generate streaming data for Firehose include a logging server running on Amazon EC2 instances, an application running on mobile devices, and a sensor on an IoT device.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-04T16:32:00.780880"}}
{"question": "How does Firehose connect to sources for streaming data?", "answer": "Firehose can connect to sources using several methods: 1) Amazon Data Firehose API with the AWS SDK for various programming languages, 2) Kinesis Data Stream, 3) Amazon MSK, 4) AWS natively supported services like AWS Cloudwatch, AWS EventBridge, AWS IOT, or AWS Pinpoint, 5) Kinesis Agents, and 6) Fluentbit, as well as 7) AWS Lambda for serverless compute.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-04T16:32:00.781250"}}
{"question": "What is the difference between a source and a destination in the context of Firehose?", "answer": "In the context of Firehose, a source refers to where the streaming data is continuously generated and captured, such as logging servers or IoT devices. A destination, on the other hand, is the data store where the data will be delivered, with options including Amazon S3, Amazon Redshift, and various other data stores.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-04T16:32:00.781754"}}
{"question": "What types of destinations can Data Firehose load data into?", "answer": "Data Firehose can load data into Amazon S3, Amazon Redshift, Amazon OpenSearch Service, Snowflake, Apache Iceberg tables, or Splunk.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T16:32:05.069975"}}
{"question": "How does Data Firehose ensure high availability and durability for data during transportation?", "answer": "Data Firehose ensures high availability and durability for data during transportation by synchronously replicating data across three facilities in an AWS Region.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T16:32:05.070227"}}
{"question": "What is the maximum size of a record sent to a Firehose stream from Direct PUT or Kinesis Data Streams compared to Amazon MSK?", "answer": "The maximum size of a record sent to a Firehose stream is 1024 KB if the data source is Direct PUT or Kinesis Data Streams, while it is 10 MB if the data source is Amazon MSK.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T16:32:05.070383"}}
{"question": "What operating systems does the Amazon Kinesis Agent currently support?", "answer": "Amazon Kinesis Agent currently supports Amazon Linux, Red Hat Enterprise Linux, and Microsoft Windows.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-04T16:32:09.784743"}}
{"question": "How does Kinesis Agent simplify the process of sending data to a Firehose stream?", "answer": "Kinesis Agent simplifies the process by continuously monitoring certain files and automatically sending the collected data to your Firehose stream without requiring additional code.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-04T16:32:09.785075"}}
{"question": "How does using Kinesis Agent compare to directly using Firehose's PutRecord and PutRecordBatch operations for adding data to a Firehose stream?", "answer": "Using Kinesis Agent allows for continuous monitoring and automatic data sending to Firehose streams, which reduces operational complexity, while using Firehose's PutRecord and PutRecordBatch operations requires explicit API calls to add data records, either one at a time or in batches.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-04T16:32:09.785268"}}
{"question": "What requirements must MSK clusters meet to use the feature mentioned in the context?", "answer": "To use this feature, MSK clusters must have public endpoints or private links enabled.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-04T16:32:15.739049"}}
{"question": "How does Firehose determine the starting point for consuming data from an Amazon MSK topic?", "answer": "The checkpoint time to start consuming data from the Amazon MSK topic is the creation time of the Firehose stream. Firehose does not read from custom offset values.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-04T16:32:15.740288"}}
{"question": "What is the difference in how Firehose interacts with Kinesis Data Streams compared to how data is added to Kinesis Data Streams when Firehose is configured as a source?", "answer": "When Firehose is configured as the source of a Kinesis Data Stream, Firehoses PutRecord and PutRecordBatch operations will be disabled, meaning that data cannot be added to the Kinesis Data Stream through Firehose. Instead, data should be added to the Kinesis Data Stream using the Kinesis Data Streams PutRecord and PutRecords operations.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-04T16:32:15.740608"}}
{"question": "What sources can be used to add data to a Firehose stream?", "answer": "You can add data to your Firehose stream from CloudWatch Logs by creating a CloudWatch Logs subscription filter, from CloudWatch Events by creating a CloudWatch Events rule with your Firehose stream as the target, and from the AWS EventBridge console.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-04T16:32:22.504907"}}
{"question": "How does Firehose handle data encryption for data delivered to Amazon S3?", "answer": "Firehose allows you to encrypt your data after its delivered to your Amazon S3 bucket. While creating your Firehose stream, you can choose to encrypt your data with an AWS Key Management Service (KMS) key that you own.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-04T16:32:22.505229"}}
{"question": "What role does Firehose assume to access resources like Amazon S3 and Amazon OpenSearch?", "answer": "Firehose assumes the IAM role you specify to access resources such as your Amazon S3 bucket and Amazon OpenSearch domain.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-04T16:32:22.505699"}}
{"question": "What built-in data formats can Firehose convert to for destination data stores?", "answer": "Firehose can convert data from raw or JSON formats into Apache Parquet and Apache ORC formats required by destination data stores.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-04T16:32:28.258082"}}
{"question": "How does Firehose facilitate the analytics process in S3?", "answer": "Firehose facilitates the analytics process in S3 by allowing users to dynamically partition their streaming data using static or dynamically defined keys like 'customer_id' or 'transaction_id'. It groups data by these keys and delivers it into key-unique S3 prefixes, making it easier to perform high performance, cost-efficient analytics in S3 using services like Athena, EMR, and Redshift Spectrum.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-04T16:32:28.258407"}}
{"question": "What are the differences between the compression formats supported by Firehose for data delivery to S3 and Redshift?", "answer": "Firehose supports GZIP, ZIP, and SNAPPY compression formats for data delivery to Amazon S3. However, when the data is further loaded to Amazon Redshift, only GZIP compression format is supported.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-04T16:32:28.258833"}}
{"question": "What are the three parameters that must be returned to Firehose from Lambda for transformed records?", "answer": "The three parameters that must be returned to Firehose from Lambda for transformed records are recordId, result, and data.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-04T16:32:33.489323"}}
{"question": "What does the result parameter indicate in the context of Firehose data transformation?", "answer": "The result parameter indicates the status of the transformation of each record. The allowed values are 'Ok' if the record is transformed successfully, 'Dropped' if the record is intentionally dropped, and 'ProcessingFailed' if the record cannot be transformed as expected.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-04T16:32:33.489667"}}
{"question": "How does Firehose treat records with different result statuses during data processing?", "answer": "Firehose treats records with 'Ok' and 'Dropped' statuses as successfully processed records, while records with 'ProcessingFailed' status are treated as unsuccessfully processed records when it generates SucceedProcessing.Records and SucceedProcessing.Bytes metrics.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-04T16:32:33.490122"}}
{"question": "What is the main benefit of Firehose dynamic partitioning?", "answer": "The main benefit of Firehose dynamic partitioning is that it eliminates the complexities and delays of manual partitioning, enabling faster analytics for querying optimized data sets. This allows data sets to be immediately available for analytics tools, enhancing fine-grained access control for data.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-04T16:32:39.101046"}}
{"question": "How does Firehose dynamic partitioning improve the efficiency of querying data?", "answer": "Firehose dynamic partitioning improves the efficiency of querying data by allowing users to partition data on-the-fly based on specific keys, such as customer id or event timestamps. This enables customer-specific or time-based queries to access optimized data sets quickly, resulting in faster query results.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-04T16:32:39.101381"}}
{"question": "How does Firehose handle data transformation and backup compared to its delivery of transformed records?", "answer": "Firehose can back up all un-transformed records to your S3 bucket concurrently while delivering transformed records to the destination. This means that while transformed data is being processed and sent to the specified destination, the original un-transformed records are also being stored, ensuring that no data is lost.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-04T16:32:39.101605"}}
{"question": "What is the default buffer size for Amazon S3 when using Apache parquet or dynamic partitioning with Firehose?", "answer": "The default buffer size for Amazon S3 when using Apache parquet or dynamic partitioning with Firehose is 128 MB.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-04T16:32:45.540200"}}
{"question": "How does the buffer size and buffer interval affect data delivery to Amazon S3 in Firehose?", "answer": "The frequency of data delivery to Amazon S3 is determined by the S3 buffer size and buffer interval value configured for the Firehose stream. Firehose buffers incoming data before delivering it to Amazon S3, and data delivery is triggered by the condition that is satisfied first between the buffer size (ranging from 1 MB to 128 MB) or buffer interval (ranging from 0 to 900 seconds). Additionally, if data delivery is falling behind data ingestion, Firehose automatically raises the buffer size to ensure all data is delivered.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-04T16:32:45.540580"}}
{"question": "What is the process for delivering data from Firehose to a Redshift instance compared to delivering data to an S3 bucket?", "answer": "For Redshift destinations, Amazon Data Firehose first delivers data to your Amazon S3 bucket and then issues the Redshift COPY command to load the data from the S3 bucket to the Redshift instance. In contrast, direct delivery to Amazon S3 does not involve a subsequent COPY command, as Firehose delivers the data directly to S3.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-04T16:32:45.541085"}}
{"question": "What delivery semantics does Firehose use for Snowflake?", "answer": "Firehose uses exactly-once delivery semantics for Snowflake, meaning that each record is delivered to Snowflake exactly once, even if there are errors or retries.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T16:32:51.170100"}}
{"question": "What is the significance of exactly-once delivery semantics in Firehose, and what limitation does it have?", "answer": "The significance of exactly-once delivery semantics in Firehose is that it ensures each record is delivered to Snowflake one time only. However, this does not guarantee that there will be no duplicates in the data end to end, as data may be duplicated by the producer or other parts of the ETL pipeline.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T16:32:51.170433"}}
{"question": "How does the configuration process differ when changing the destination endpoint URL for a VPC destination versus changing VPC, subnets, and security groups in Firehose?", "answer": "When changing the destination endpoint URL for a VPC destination, you can do so as long as the new destination is accessible within the same VPC, subnets, and security groups. In contrast, for changes involving VPC, subnets, and security groups, you need to re-create the Firehose stream.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T16:32:51.170932"}}
{"question": "What conditions must be met for Firehose to deliver data to Amazon OpenSearch Service in a different account?", "answer": "Firehose delivery can deliver to a different account in Amazon OpenSearch Service only when Firehose and Amazon OpenSearch Service are connected through a public endpoint.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:32:56.480444"}}
{"question": "How does Amazon Data Firehose determine the frequency of data delivery to Amazon OpenSearch Service?", "answer": "The frequency of data delivery to Amazon OpenSearch Service is determined by the OpenSearch buffer size and buffer interval values that you configured for your Firehose stream. Firehose buffers incoming data before delivering it, and the condition satisfied first triggers data delivery to Amazon OpenSearch Service.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:32:56.480796"}}
{"question": "What are the differences in delivery capabilities of a single Firehose stream for Amazon S3 buckets versus Redshift instances?", "answer": "A single Firehose stream can currently only deliver data to one Amazon S3 bucket, while it can only deliver data to one Redshift instance and one table. To deliver data to multiple S3 buckets or multiple Redshift instances or tables, you need to create multiple Firehose streams.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T16:32:56.480963"}}
{"question": "What is the maximum number of transactions per second that a single Firehose stream can intake by default?", "answer": "By default, each Firehose stream can intake up to 2,000 transactions per second.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-04T16:33:03.828424"}}
{"question": "How does Amazon Data Firehose handle data delivery retries when the source is Direct PUT?", "answer": "If your data source is Direct PUT and the data delivery to your Amazon S3 bucket fails, Amazon Data Firehose will retry to deliver data every 5 seconds for up to a maximum period of 24 hours. If the issue continues beyond the 24-hour maximum retention period, then Amazon Data Firehose discards the data.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-04T16:33:03.828769"}}
{"question": "What is the difference in data delivery retry behavior between Direct PUT and Kinesis Data Streams as data sources for Amazon Data Firehose?", "answer": "For Direct PUT sources, Amazon Data Firehose retries delivery every 5 seconds for up to 24 hours before discarding the data if delivery fails. In contrast, for Kinesis Data Streams sources, the retry behavior is determined by the configuration of Kinesis Data Streams, and the maximum retry duration is not fixed at 24 hours.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-04T16:33:03.829187"}}
{"question": "How long does Amazon Data Firehose retry data delivery to a Redshift instance before skipping the batch?", "answer": "Amazon Data Firehose retries data delivery to a Redshift instance every 5 minutes for up to a maximum period of 120 minutes before skipping the current batch.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-04T16:33:11.050803"}}
{"question": "What happens to the data delivery if it fails when using Amazon OpenSearch Service as a destination?", "answer": "If data delivery to your Amazon OpenSearch domain fails, Amazon Data Firehose retries data delivery for the specified time duration. After the retrial period, it skips the current batch of data and moves on to the next batch. Details on the skipped documents are delivered to your S3 bucket in the opensearch_failed folder for manual backfill.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-04T16:33:11.051139"}}
{"question": "How does the retry behavior differ between Amazon Redshift and Amazon OpenSearch Service when data delivery fails?", "answer": "For Amazon Redshift, Amazon Data Firehose retries data delivery every 5 minutes for up to 120 minutes, after which it skips the batch and delivers a manifest file for manual backfill. In contrast, for Amazon OpenSearch Service, the retry duration can be specified between 0 and 7200 seconds, and after the retrial period, it also skips the current batch but provides details on the skipped documents in the opensearch_failed folder for manual backfill.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-04T16:33:11.051564"}}
{"question": "What happens when Firehose attempts to invoke a Lambda function and the invocation fails due to network timeout or hitting invocation limits?", "answer": "When Firehose attempts to invoke a Lambda function and the invocation fails due to reasons such as reaching network timeout or hitting Lambda invocation limits, Firehose retries the invocation three times by default. If all retries fail, it skips that particular batch of records, treating them as unsuccessfully processed records. You can also configure the number of invocation re-trials between 0 and 300 using the CreateDeliveryStream and UpdateDeliveryStream APIs.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-04T16:33:18.818590"}}
{"question": "How does Firehose handle records that are marked as 'ProcessingFailed' by the Lambda function?", "answer": "When a records transformation result is set to 'ProcessingFailed' by the Lambda function, Firehose treats these records as unsuccessfully processed records. For this type of failure, you can use Lambdas logging feature to emit error logs to CloudWatch Logs.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-04T16:33:18.818912"}}
{"question": "What is the difference between the handling of unsuccessfully processed records and the storage of failed S3 objects in Firehose?", "answer": "Unsuccessfully processed records due to Lambda invocation failures are delivered to the S3 bucket in the processing_failed folder. In contrast, the errors folder stores manifest files that contain information about S3 objects that failed to load to a Redshift instance. These failed objects can be reloaded manually through the Redshift COPY command. Additionally, documents that fail to load to an Amazon OpenSearch domain are stored in the opensearch_failed folder, where they can be re-indexed manually for backfill.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-04T16:33:18.819415"}}
{"question": "What does the processing_failed folder store in AWS Lambda?", "answer": "The processing_failed folder stores the records that failed to transform in your AWS Lambda function. You can re-process these records manually.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 415, "generated_at": "2026-02-04T16:33:24.110285"}}
{"question": "How does Amazon Data Firehose integrate with Amazon CloudWatch?", "answer": "Amazon Data Firehose integrates with Amazon CloudWatch Metrics to collect, view, and analyze metrics for your Firehose streams, and it also integrates with Amazon CloudWatch Logs to allow you to view specific error logs if data transformation or delivery fails.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 415, "generated_at": "2026-02-04T16:33:24.110604"}}
{"question": "How does AWS Identity and Access Management differ from AWS CloudTrail in relation to Amazon Data Firehose?", "answer": "AWS Identity and Access Management enables you to securely control access to your AWS services and resources, allowing you to create policies for user permissions regarding Firehose streams. In contrast, AWS CloudTrail records AWS API calls for your account and delivers log files, providing a way to log API operations related to Amazon Data Firehose.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 415, "generated_at": "2026-02-04T16:33:24.111061"}}
{"question": "What is the pricing model for Amazon Data Firehose?", "answer": "Amazon Data Firehose uses a simple pay-as-you-go pricing model, where there are no upfront costs or minimum fees, and you only pay for the resources you use.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-04T16:33:28.973622"}}
{"question": "How is the data volume calculated for Amazon Data Firehose usage?", "answer": "The data volume for Amazon Data Firehose is calculated based on the data volume (GB) ingested, with each record rounded up to the nearest 5KB for Direct PUT and Kinesis Data Streams as sources. For example, if a PutRecordBatch call contains two 1KB records, the data volume is metered as 10KB (5KB per record).", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-04T16:33:28.973958"}}
{"question": "How does the SLA guarantee for Amazon Data Firehose compare with the billing for associated services?", "answer": "The SLA for Amazon Data Firehose guarantees a Monthly Uptime Percentage of at least 99.9%. In contrast, charges associated with services like Amazon S3, Amazon Redshift, Amazon OpenSearch Service, and AWS Lambda are billed separately, including storage and request costs.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-04T16:33:28.974467"}}
{"question": "What is AWS Glue and what are its main features?", "answer": "AWS Glue is a serverless service designed for data integration, making it simpler, faster, and cheaper. Its main features include the ability to discover and connect to over 100 diverse data sources, manage data in a centralized data catalog, and visually create, run, and monitor data pipelines for loading data into data lakes, data warehouses, and lakehouses. It also has built-in generative AI capabilities for modernizing Apache Spark jobs and providing intelligent assistance for ETL authoring and Spark troubleshooting.", "question_type": "factual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T16:33:36.327124"}}
{"question": "How does AWS Glue assist in the process of data integration?", "answer": "AWS Glue assists in the process of data integration by providing a fully managed, serverless toolkit that allows users to design and automate modern data pipelines. It includes built-in ETL capabilities, schema discovery, and cross-service integration, enabling teams to gain insights and utilize their data quickly without the need for infrastructure management.", "question_type": "conceptual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T16:33:36.327472"}}
{"question": "How does AWS Glue's serverless architecture benefit users compared to traditional infrastructure management?", "answer": "AWS Glue's serverless architecture benefits users by eliminating the need for infrastructure management, allowing teams to focus on building data workflows instead of maintaining servers. It automatically scales to handle resource-intensive data processing jobs, from gigabytes to petabytes, and users only pay for the resources they use, making it more cost-effective than traditional infrastructure management.", "question_type": "comparison", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-04T16:33:36.327694"}}
{"question": "What services can be integrated within Amazon SageMaker for data processing projects?", "answer": "For data processing projects, you can integrate AWS Glue, Amazon Athena, Amazon EMR, and MWAA within Amazon SageMaker.", "question_type": "factual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-04T16:33:40.223696"}}
{"question": "How does AWS Glue simplify data integration for users?", "answer": "AWS Glue simplifies data integration by removing infrastructure management through automatic provisioning and worker management, allowing users to consolidate all their data integration needs into a single service.", "question_type": "conceptual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-04T16:33:40.224028"}}
{"question": "What are the different workloads supported by AWS Glue for data processing?", "answer": "AWS Glue supports various data processing frameworks such as ETL and ELT, as well as different workloads including batch, micro-batch, and streaming.", "question_type": "comparison", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-04T16:33:40.224614"}}
{"question": "What is AWS DataSync and what does it simplify?", "answer": "AWS DataSync is an online data movement service that simplifies and accelerates data migrations to AWS as well as moving data to and from on-premises storage, edge locations, other cloud providers, and AWS Storage services.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T16:33:45.903800"}}
{"question": "Why would someone choose to use AWS DataSync for data transfers?", "answer": "Someone would choose to use AWS DataSync for data transfers to copy large datasets with millions of files securely and quickly, without having to build custom solutions or manage expensive commercial network acceleration software. DataSync is ideal for migrating active data to AWS, archiving data to free up on-premises storage capacity, replicating data for business continuity, or transferring data to the cloud for analysis and processing.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T16:33:45.904129"}}
{"question": "How does AWS DataSync compare to traditional methods of data transfer in terms of solutions required?", "answer": "AWS DataSync simplifies data transfers by allowing users to copy large amounts of data without needing to build custom solutions with open-source tools or license and manage expensive commercial network acceleration software, which is often required in traditional methods of data transfer.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T16:33:45.904530"}}
{"question": "What types of storage location does AWS DataSync support?", "answer": "AWS DataSync supports various storage location types, including Network File System (NFS) shares, Server Message Block (SMB) shares, Hadoop Distributed File Systems (HDFS), self-managed object storage, object storage in other clouds such as Google Cloud Storage and Wasabi Cloud Storage, Azure Files, Azure Blob Storage (including Azure Data Lake Storage Gen2), Amazon S3 compatible storage on Snow, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS) file systems, Amazon FSx for Windows File Server file systems, Amazon FSx for Lustre file systems, Amazon FSx for OpenZFS file systems, and Amazon FSx for NetApp ONTAP file systems.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-04T16:33:53.478060"}}
{"question": "How does AWS DataSync improve the efficiency of data transfers?", "answer": "AWS DataSync improves the efficiency of data transfers by using a purpose-built network protocol and a scale-out architecture that accelerates data transfer between storage systems and AWS services. Additionally, it simplifies the process by handling file and object movement, scheduling data transfers, monitoring transfer progress, encryption, data transfer verification, and notifying users of any issues.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-04T16:33:53.478413"}}
{"question": "What are the differences between the storage types supported by DataSync and those offered by other cloud storage providers?", "answer": "The context does not provide specific comparisons between the storage types supported by DataSync and those offered by other cloud storage providers, so I cannot provide a detailed comparison. However, DataSync does support a wide array of storage types, including NFS, SMB, HDFS, and various Amazon FSx file systems, which may differ from the offerings of other cloud providers.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-04T16:33:53.478853"}}
{"question": "What can AWS DataSync be used for?", "answer": "AWS DataSync can be used to migrate data located on premises, at the edge, or in other clouds to various AWS services including Amazon S3, Amazon EFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon FSx for OpenZFS, and Amazon FSx for NetApp ONTAP.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T16:33:59.527576"}}
{"question": "How does AWS DataSync ensure the security and integrity of data during migration?", "answer": "AWS DataSync includes encryption and integrity validation to help ensure that data arrives securely, intact, and ready to use during migration.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T16:33:59.527946"}}
{"question": "How does AWS DataSync differ in its functionality when migrating cold data compared to regular data?", "answer": "When migrating cold data, AWS DataSync allows for direct transfer to long-term storage solutions like Amazon S3 Glacier Flexible Retrieval or Amazon S3 Glacier Deep Archive. It also enables the use of exclude filters to avoid copying temporary files, while regular data migration focuses on transferring entire datasets with incremental updates.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T16:33:59.528141"}}
{"question": "What storage services can AWS DataSync replicate files into?", "answer": "AWS DataSync can replicate files into any Amazon S3 storage classes, or send the data to Amazon EFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon FSx for OpenZFS, or Amazon FSx for NetApp ONTAP for a standby file system.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-04T16:34:05.650858"}}
{"question": "How does AWS DataSync enhance hybrid cloud storage workflows?", "answer": "AWS DataSync enhances hybrid cloud storage workflows by speeding up the transfer of active files into AWS quickly, which is crucial for industries such as machine learning in life sciences, video production in media and entertainment, big data analytics in financial services, and seismic research in oil and gas. It ensures timely delivery to prevent delays in dependent processes.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-04T16:34:05.651227"}}
{"question": "What is the difference between Enhanced mode and Basic mode when using AWS DataSync?", "answer": "In Enhanced mode, no agent is required to connect to your cloud storage, whereas in Basic mode, you need to deploy the DataSync agent either in your cloud environment or on Amazon EC2 to connect to your cloud storage.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-04T16:34:05.651692"}}
{"question": "What protocols does AWS DataSync use for transferring data?", "answer": "AWS DataSync uses standard storage protocols such as NFS and SMB, operates as an HDFS client, utilizes the Amazon S3 API, and can work with other cloud storage APIs for transferring data.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-04T16:34:11.558888"}}
{"question": "How does AWS DataSync ensure the security and integrity of transferred data?", "answer": "AWS DataSync includes encryption and integrity validation to help ensure that the data arrives securely, intact, and ready to use after transfer.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-04T16:34:11.559238"}}
{"question": "How does transferring data using AWS DataSync within the same AWS account differ from transferring data between Commercial AWS Regions?", "answer": "When transferring data within the same AWS account, DataSync allows you to transfer files or objects between services like Amazon S3, Amazon EFS, and others without deploying a DataSync agent. In contrast, transferring data between Commercial AWS Regions does not require a DataSync agent either, but it is limited to services in different regions, which may involve additional considerations compared to in-account transfers.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-04T16:34:11.559662"}}
{"question": "What is the primary purpose of AWS DataSync in relation to Amazon WorkDocs Migration Service?", "answer": "The primary purpose of AWS DataSync in relation to Amazon WorkDocs Migration Service is to accelerate the required step of automating file uploads to the Amazon S3 bucket that is used for migration, making it easier and faster to migrate home directories and department shares to WorkDocs.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-04T16:34:18.027081"}}
{"question": "How does AWS DataSync simplify the migration process to Amazon WorkDocs?", "answer": "AWS DataSync simplifies the migration process to Amazon WorkDocs by automating the file upload to Amazon S3, which is essential for the migration. This automation makes it easier and faster to migrate various types of data, such as home directories and department shares.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-04T16:34:18.027424"}}
{"question": "What is the difference in the deployment of an agent when transferring data between on-premises and AWS Storage services versus transferring data between other clouds and AWS?", "answer": "When transferring data between on-premises and AWS Storage services, deploying an agent is required to access your NFS server, SMB file share, Hadoop cluster, or self-managed object storage. However, deploying an agent is not required when transferring data between other clouds and AWS, or between AWS Storage services within the same AWS account.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-04T16:34:18.027966"}}
{"question": "What protocols can the AWS DataSync agent use to access a file server?", "answer": "The AWS DataSync agent can access a file server using the NFS and SMB protocols.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:34:23.829109"}}
{"question": "Why might deploying the AWS DataSync agent in a public cloud environment reduce egress fees?", "answer": "Deploying the AWS DataSync agent in a public cloud environment may reduce egress fees because AWS DataSync compresses data in flight between the agent and AWS Storage services, potentially lowering the amount of data that is transferred.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:34:23.829448"}}
{"question": "How does transferring data between AWS Storage services within the same AWS account differ from transferring data that requires a DataSync agent?", "answer": "Transferring data between AWS Storage services within the same AWS account does not require deploying an agent, whereas transferring data to or from a self-managed in-cloud file server or between AWS Storage services in different AWS accounts does require launching an Amazon EC2 instance using a DataSync agent AMI.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-04T16:34:23.829838"}}
{"question": "What are the main differences between Basic mode and Enhanced mode in AWS DataSync?", "answer": "The main differences between Basic mode and Enhanced mode in AWS DataSync are that Basic mode is subject to quotas on the number of files and objects in a dataset, and it sequentially prepares, transfers, and verifies files, making it slower than Enhanced mode. In contrast, Enhanced mode allows for transferring datasets with virtually unlimited numbers of objects at higher performance levels and optimizes the process by handling listing, preparation, transfer, and verification in parallel. Enhanced mode also provides enhanced metrics and reporting capabilities.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-04T16:34:30.547378"}}
{"question": "Why might a user choose Enhanced mode over Basic mode for their data transfers?", "answer": "A user might choose Enhanced mode over Basic mode for their data transfers because Enhanced mode offers higher performance levels, the ability to handle virtually unlimited numbers of objects, and improved metrics and reporting capabilities. This makes it easier to track and manage large data transfers, which is particularly beneficial for workloads that require efficiency and speed.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-04T16:34:30.547721"}}
{"question": "How does the data transfer process in Enhanced mode compare to that in Basic mode regarding performance?", "answer": "The data transfer process in Enhanced mode is faster compared to Basic mode because Enhanced mode transfers data by optimizing and streamlining the process through handling tasks in parallel, while Basic mode prepares, transfers, and verifies files sequentially, resulting in slower performance for most workloads.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-04T16:34:30.548225"}}
{"question": "What information can you obtain from task reports regarding data transfers?", "answer": "From task reports, you can obtain a summary report along with detailed reports for all files transferred, skipped, verified, and deleted for each task execution. Task reports provide the total number of files and bytes transferred, and include file attributes such as size, path, timestamps, file checksums, and object version IDs where applicable.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-04T16:34:36.567855"}}
{"question": "How can AWS Glue, Amazon Athena, and Amazon QuickSight be utilized in relation to task reports?", "answer": "AWS Glue, Amazon Athena, and Amazon QuickSight can be leveraged to automatically catalog, query, and visualize task reports, which helps in gaining critical insights into your data transfer processes.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-04T16:34:36.568183"}}
{"question": "What are the differences between using the AWS Management Console and Amazon CloudWatch Metrics for monitoring data transfers?", "answer": "The AWS Management Console and CLI can be used to monitor the status and progress of data being transferred, while Amazon CloudWatch Metrics specifically provides insights into the number of files and the amount of data that has been copied. Additionally, CloudWatch Logs can be used to log individual files to identify what was transferred at a given time and the results of content integrity verification.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-04T16:34:36.568586"}}
{"question": "What are the purposes of include and exclude filters in DataSync tasks?", "answer": "Include filters specify the file and folder paths or object keys that should be included during the task execution, limiting the scope of what is scanned by DataSync on the source and destination. Exclude filters, on the other hand, specify the file and folder paths or object keys that should be excluded from being copied.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-04T16:34:42.395278"}}
{"question": "How do manifests work in DataSync tasks, and what is their format?", "answer": "Manifests are CSV-formatted files that list the file paths or object keys to be included when the task runs. They limit the scope of what is scanned by DataSync on the source and destination. When creating or updating a task, you can provide a manifest file that can contain millions of source files or objects, and DataSync will only compare and transfer the files listed in the manifest.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-04T16:34:42.395617"}}
{"question": "What is the relationship between filters and manifests in DataSync tasks?", "answer": "Filters and manifests serve the purpose of limiting the scope of files or objects transferred in DataSync tasks, but they cannot be used together. You can configure include and exclude filters for a task, or you can provide a manifest, but not both at the same time.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-04T16:34:42.396198"}}
{"question": "What is the purpose of a manifest in AWS DataSync?", "answer": "A manifest is an explicit list of files or objects to be transferred from the source location. It allows customers to specify millions of source files or objects to be transferred and ensures that DataSync only compares the files listed in the manifest.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T16:34:49.752777"}}
{"question": "How do include filters differ from manifests in AWS DataSync?", "answer": "Include filters are strings that specify patterns of files and folders to be transferred, allowing only those that match the patterns to be copied. In contrast, a manifest is a specific list of files or objects to be transferred, enabling the transfer of a predetermined set of files without scanning the entire storage system.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T16:34:49.753142"}}
{"question": "What happens if a task in AWS DataSync is interrupted, and how does it affect the data transfer?", "answer": "If a task is interrupted, such as due to a network connection failure or the AWS DataSync agent being restarted, the next run of the task will transfer only the missing files. This ensures that the data will be complete and consistent at the end of the next run, as each task performs an incremental copy, transferring only the changes from the source to the destination.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T16:34:49.753599"}}
{"question": "What technology powers VPC endpoints for AWS DataSync?", "answer": "VPC endpoints for DataSync are powered by AWS PrivateLink, which is a highly available, scalable technology that enables private connection of your VPC to supported AWS services.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-04T16:34:55.893103"}}
{"question": "How do VPC endpoints increase the security of data transferred by AWS DataSync agents?", "answer": "VPC endpoints increase the security of data by ensuring that the data transferred between your AWS DataSync agent, whether deployed on-premises or in-cloud, does not traverse the public internet or require public IP addresses, thus keeping network traffic within your Amazon Virtual Private Cloud (Amazon VPC).", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-04T16:34:55.893460"}}
{"question": "What are the differences between using VPC endpoints and transferring data over the public internet with AWS DataSync?", "answer": "Using VPC endpoints allows data to remain within the Amazon Virtual Private Cloud (Amazon VPC), enhancing security by avoiding traversal over the public internet and not requiring public IP addresses. In contrast, transferring data over the public internet would expose the data to potential security risks and dependencies on public network infrastructure.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-04T16:34:55.893901"}}
{"question": "What S3 storage classes are supported by AWS DataSync for storing objects?", "answer": "AWS DataSync supports the following S3 storage classes for storing objects: S3 Standard, S3 Intelligent-Tiering, S3 Standard-Infrequent Access (S3 Standard-IA), S3 One Zone-Infrequent Access (S3 One Zone-IA), Amazon S3 Glacier Instant Retrieval, Amazon S3 Glacier Flexible Retrieval, and Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive).", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:35:03.044404"}}
{"question": "What happens when retrieving objects from S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive storage classes using AWS DataSync?", "answer": "When retrieving objects archived in the S3 Glacier Flexible Retrieval or S3 Glacier Deep Archive storage classes using AWS DataSync, it results in an error. Any errors retrieving archived objects will be logged by DataSync and will result in a failed task completion status.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:35:03.044667"}}
{"question": "How do retrieval fees differ between S3 Standard-IA and S3 Glacier Instant Retrieval when using AWS DataSync?", "answer": "Retrieving objects from S3 Standard-IA and S3 One Zone-IA storage will incur a retrieval fee based on the size of the objects. In contrast, retrieving objects from S3 Glacier Instant Retrieval also incurs higher retrieval fees based on the size of the objects. However, retrieving objects from S3 Glacier Flexible Retrieval or S3 Glacier Deep Archive results in an error, meaning no retrieval fee can be incurred for these classes as the operation fails.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:35:03.044841"}}
{"question": "What role does AWS DataSync assume, and how can it be configured?", "answer": "AWS DataSync assumes an IAM role that you provide. You can either let DataSync auto-generate this role on your behalf or manually configure a role yourself.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:35:10.787069"}}
{"question": "How does AWS DataSync handle file and folder metadata when transferring data to and from Amazon S3?", "answer": "When files or folders are copied to Amazon S3, there is a one-to-one relationship between a file or folder and an object. File and folder timestamps and POSIX permissions, including user ID, group ID, and permissions, are stored in S3 user metadata. When DataSync copies objects containing this user metadata back to an NFS server, the file metadata is restored. Additionally, when copying from an SMB file share, default POSIX permissions are stored in S3 user metadata, and ownership is set based on the user configured in DataSync for that file share.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:35:10.787423"}}
{"question": "What differences exist in how DataSync handles metadata when transferring from NFS compared to SMB file shares?", "answer": "When transferring from NFS shares, file metadata stored in S3 user metadata is fully interoperable with File Gateway, and symbolic links and hard links are restored when copying back from NFS to S3. In contrast, when copying from an SMB file share, default POSIX permissions are stored in S3 user metadata, and upon copying back, ownership is set based on the user configured in DataSync, with default permissions assigned.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:35:10.787855"}}
{"question": "What does AWS DataSync do to minimize data retrieval fees?", "answer": "To minimize data retrieval fees, you can configure AWS DataSync to verify only files that were transferred by a given task.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-04T16:35:14.374341"}}
{"question": "How does AWS DataSync manage small objects in relation to S3 storage classes?", "answer": "AWS DataSync automatically stores small objects in S3 Standard to avoid minimum capacity charges per object.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-04T16:35:14.374679"}}
{"question": "What is the relationship between AWS DataSync and Amazon EFS file systems?", "answer": "AWS DataSync accesses your Amazon EFS file system using the NFS protocol and manages the creation, use, and deletion of Elastic Network Interfaces (ENIs) that mount the file system from within your VPC.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-04T16:35:14.375098"}}
{"question": "What action must your IAM policy allow for DataSync when accessing Amazon EFS?", "answer": "Your IAM policy must allow the action: elasticfilesystem:ClientRootAccess when DataSync accesses Amazon EFS because it mounts EFS file systems as the root user.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-04T16:35:23.773776"}}
{"question": "How does AWS DataSync manage access to an Amazon FSx for Windows File Server file system?", "answer": "AWS DataSync accesses your Amazon FSx for Windows File Server file system using the SMB protocol and authenticates with the username and password configured in the AWS Console or CLI. It mounts the file system from within your VPC using Elastic Network Interfaces (ENIs) that are managed by the DataSync service.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-04T16:35:23.774101"}}
{"question": "What types of metadata does AWS DataSync copy when replicating files from Amazon EFS compared to Amazon FSx for Windows File Server?", "answer": "AWS DataSync copies file and folder timestamps and POSIX permissions, including user ID, group ID, and permissions when replicating from Amazon EFS. In contrast, when replicating from Amazon FSx for Windows File Server, it copies Windows metadata such as file timestamps, file owner, standard file attributes, NTFS discretionary access lists (DACLs), and NTFS system access control lists (SACLs).", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-04T16:35:23.774600"}}
{"question": "Can AWS DataSync replicate an Amazon FSx for Windows File Server file system to another file system within the same AWS account?", "answer": "Yes, AWS DataSync can schedule periodic replication of your Amazon FSx for Windows File Server file system to a second file system within the same AWS account. This capability is available for both same-region and cross-region deployments and does not require using a DataSync agent.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-04T16:35:32.024150"}}
{"question": "What metadata does AWS DataSync copy when transferring files from an FSx for Lustre file system?", "answer": "AWS DataSync copies file and folder timestamps and POSIX permissions, including user ID, group ID, and permissions. A complete list of copied metadata can be found in the AWS documentation.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-04T16:35:32.024436"}}
{"question": "How does AWS DataSync handle network access when creating a task for an FSx for Lustre file system compared to an FSx for Windows File Server file system?", "answer": "When you create a DataSync task for an FSx for Lustre file system, the DataSync service creates Elastic Network Interfaces (ENIs) in the same VPC and subnet as the file system, using the Lustre protocol as the root user. In contrast, for the FSx for Windows File Server, the context does not specify the use of ENIs or the Lustre protocol, suggesting a different mechanism for access. Additionally, the security groups for FSx for Lustre must allow outbound traffic for required network ports as well as inbound access from the assigned DataSync security groups.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-04T16:35:32.024914"}}
{"question": "What does AWS DataSync create to access your FSx for OpenZFS file system?", "answer": "AWS DataSync creates Elastic Network Interfaces (ENIs) in the same VPC and subnet where your file system is located to access your FSx for OpenZFS file system.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T16:35:38.707592"}}
{"question": "How does AWS DataSync ensure it can access the FSx for OpenZFS file system securely?", "answer": "AWS DataSync ensures secure access to the FSx for OpenZFS file system by allowing users to specify up to five security groups for the ENIs, which must be configured to allow outbound traffic on the network ports required by FSx for OpenZFS. Additionally, the security groups on the FSx for OpenZFS file system should allow inbound access from the security groups assigned to the DataSync location resource.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T16:35:38.707898"}}
{"question": "What are the differences in capabilities of AWS DataSync when copying from FSx for OpenZFS to another file system within the same AWS account?", "answer": "AWS DataSync can copy from your FSx for OpenZFS file system to a second file system within the same AWS account for both same-region and cross-region deployments. This process does not require using a DataSync agent. Additionally, you can schedule periodic replication of your FSx for OpenZFS file system to a second file system within the same account, which also does not require a DataSync agent.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T16:35:38.708344"}}
{"question": "What types of network interfaces does DataSync create when a task is set up?", "answer": "DataSync creates Elastic Network Interfaces (ENIs) in the Preferred Subnet of the same VPC where your Amazon FSx for NetApp ONTAP file system is located.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-04T16:35:42.885912"}}
{"question": "How does DataSync handle file and folder timestamps when using the NFS protocol?", "answer": "AWS DataSync copies file and folder timestamps and POSIX permissions, including user ID, group ID, and permissions, when using the NFS protocol.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-04T16:35:42.886155"}}
{"question": "What is the difference in metadata copied by DataSync when using NFS versus SMB protocols?", "answer": "When using the NFS protocol, DataSync copies file and folder timestamps and POSIX permissions, while when using the SMB protocol, it copies file and folder timestamps, ownership, and ACLs.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-04T16:35:42.886634"}}
{"question": "What security style should be configured for FSx for ONTAP volumes when migrating from Windows servers using the SMB protocol?", "answer": "The security style for your FSx for ONTAP volume should be configured for NTFS when migrating from Windows servers using the SMB protocol.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T16:35:48.043586"}}
{"question": "Why is it recommended to use the SMB protocol for multi-protocol migrations to FSx for ONTAP?", "answer": "It is recommended to use the SMB protocol for multi-protocol migrations to FSx for ONTAP to preserve file system metadata with the highest fidelity.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T16:35:48.044755"}}
{"question": "What are the differences in migration requirements between Windows servers using SMB and Unix/Linux servers using NFS to FSx for ONTAP?", "answer": "When migrating from Windows servers using SMB, a DataSync SMB source location must be used, and the FSx for ONTAP volume's security style should be configured for NTFS. In contrast, for Unix/Linux servers using NFS, a DataSync NFS source location must be used, and the FSx for ONTAP volume's security style should be configured for Unix.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T16:35:48.045054"}}
{"question": "What factors influence the rate at which AWS DataSync can copy a dataset?", "answer": "The rate at which AWS DataSync can copy a given dataset is influenced by the amount of data, the I/O bandwidth achievable from the source and destination storage, the network bandwidth available, and the network conditions.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-04T16:35:54.475810"}}
{"question": "How does configuring a bandwidth limit in AWS DataSync benefit data transfer tasks?", "answer": "Configuring a bandwidth limit in AWS DataSync allows you to control the amount of network bandwidth used during data transfer. This can minimize the impact on other users or applications relying on the same network connection, and it can also reduce the I/O against your storage system, thereby lessening the impact on the response time of other clients accessing the same source data store.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-04T16:35:54.476150"}}
{"question": "How does the encryption of data during transfer differ between AWS DataSync and the storage services like S3, EFS, and FSx?", "answer": "AWS DataSync encrypts all data transferred between the source and destination using Transport Layer Security (TLS), while the storage services provide additional encryption options: S3 supports default encryption for buckets, Amazon EFS offers encryption of data at rest, and Amazon FSx provides encryption both at rest and in transit.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-04T16:35:54.476656"}}
{"question": "What is the role of the DataSync agent in accessing a Hadoop cluster?", "answer": "The DataSync agent acts as an HDFS client that communicates with the NameNodes and DataNodes in your Hadoop clusters. It queries the primary NameNode to determine the locations of files and folders on the cluster and then communicates with the DataNodes to copy files and folders to or from HDFS.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-04T16:36:00.035729"}}
{"question": "How does AWS DataSync handle authentication when accessing Azure Blob Storage containers?", "answer": "When accessing Azure Blob Storage containers, AWS DataSync authenticates to your Azure container using a SAS token that you specify when creating a DataSync Azure Blob location.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-04T16:36:00.036009"}}
{"question": "What is the difference between Basic mode and Enhanced mode tasks in AWS DataSync regarding agent deployment?", "answer": "In Basic mode tasks, AWS DataSync requires an agent to be deployed either in your Azure environment or into Amazon EC2 to access objects in Azure Blob Storage, while in Enhanced mode tasks, no agent is required to connect to Azure Blob Storage.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-04T16:36:00.036211"}}
{"question": "What types of endpoints can the AWS DataSync agent connect to?", "answer": "The AWS DataSync agent can connect to public internet facing endpoints, Federal Information Processing Standards (FIPS) validated endpoints, or endpoints within one of your VPCs.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-04T16:36:05.962857"}}
{"question": "How does AWS ensure that updates to the DataSync agent VM are applied?", "answer": "Updates to the agent VM, including both the underlying operating system and the AWS DataSync software packages, are automatically applied by AWS once the agent is activated. These updates are applied non-disruptively when the agent is idle and not executing a data transfer task.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-04T16:36:05.963214"}}
{"question": "How does AWS DataSync's compliance with PCI DSS and HIPAA impact its use for transferring sensitive information?", "answer": "AWS DataSync's compliance with PCI DSS means it can be used to transfer payment information, while its HIPAA eligibility allows it to be used for transferring protected health information (PHI) provided that there is a HIPAA Business Associate Agreement (BAA) in place with AWS.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-04T16:36:05.963639"}}
{"question": "What authority has AWS DataSync received from the Joint Authorization Board?", "answer": "AWS DataSync has received a Provisional Authority to Operate (P-ATO) from the Joint Authorization Board (JAB) at the Federal Risk and Authorization Management Program (FedRAMP) Moderate baseline in the US East/West Regions and a P-ATO at the FedRAMP High baseline in the US GovCloud Region.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T16:36:11.058315"}}
{"question": "How does AWS DataSync ensure the security of data during transfer?", "answer": "AWS DataSync ensures the security of data during transfer by encrypting all data via TLS, integrating directly with AWS storage services, and using built-in AWS security mechanisms such as IAM roles. Additionally, DataSync with VPC endpoints is enabled to ensure that data transferred between an organization and AWS does not traverse the public internet.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T16:36:11.058587"}}
{"question": "What is the difference in the impact level of data that can be handled by AWS DataSync in the US East/West Regions versus the US GovCloud Region?", "answer": "In the US East/West Regions, AWS DataSync can handle data up to the moderate impact level, while in the US GovCloud Region, it can handle data up to the high impact level.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T16:36:11.058991"}}
{"question": "What tool should I use for continuous replication of data to a specific destination bucket?", "answer": "You should use S3 Replication for continuous replication of data to a specific destination bucket.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-04T16:36:16.247052"}}
{"question": "How does AWS DataSync facilitate ongoing data distribution and what are its ideal use cases?", "answer": "AWS DataSync facilitates ongoing data distribution by automating and accelerating online data transfers to AWS Storage services. Its ideal use cases include migrating active data to AWS, transferring data to the cloud for analysis and processing, archiving data to free up on-premises storage capacity, and replicating data to AWS for business continuity.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-04T16:36:16.247390"}}
{"question": "What are the differences between AWS DataSync and AWS Snowball Edge in terms of data transfer methods?", "answer": "AWS DataSync is ideal for online data transfers and is used for ongoing data distribution, while AWS Snowball Edge is ideal for offline data transfers, particularly for customers who are bandwidth constrained or transferring data from remote, disconnected, or austere environments.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-04T16:36:16.247913"}}
{"question": "What service should I use if I want to accelerate the transfer of large files to Amazon S3?", "answer": "You should use S3 Transfer Acceleration to achieve higher throughput for transferring large files to Amazon S3.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-04T16:36:20.860721"}}
{"question": "What are the benefits of using AWS DataSync for data transfer?", "answer": "AWS DataSync automates and simplifies the data transfer process by providing additional functionality, such as built-in retry and network resiliency mechanisms, data integrity verification, and flexible configuration options, including bandwidth throttling.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-04T16:36:20.861054"}}
{"question": "How does AWS Transfer Family differ from AWS DataSync in terms of data transfer protocols?", "answer": "AWS Transfer Family provides a fully managed service for SFTP, FTPS, FTP, and AS2 transfer directly into and out of Amazon S3, while AWS DataSync is used for transferring data between various storage systems and supports online migrations, timely transfers, and replication but does not specify support for these transfer protocols.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-04T16:36:20.861518"}}
{"question": "What types of data does Amazon Detective automatically collect from AWS resources?", "answer": "Amazon Detective automatically collects log data from your AWS resources.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-04T16:36:25.075518"}}
{"question": "How does Amazon Detective assist security teams in conducting investigations?", "answer": "Amazon Detective assists security teams by simplifying the investigative process, allowing for faster and more effective investigations through prebuilt data aggregations, summaries, and context that help quickly analyze and determine the nature and extent of possible security issues.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-04T16:36:25.075757"}}
{"question": "How does the pricing model of Amazon Detective compare to traditional software solutions for security investigations?", "answer": "Amazon Detective has no upfront costs and charges only for the events analyzed, unlike traditional software solutions that may require additional software deployment or log feeds to enable, which can lead to additional costs.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-04T16:36:25.075917"}}
{"question": "What types of time-based events does Amazon Detective extract?", "answer": "Amazon Detective extracts time-based events such as login attempts, API calls, and network traffic from AWS CloudTrail, Amazon VPC Flow Logs, Amazon GuardDuty findings, AWS Security Hub findings, and Amazon Elastic Kubernetes Service (Amazon EKS) audit logs.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T16:36:30.308079"}}
{"question": "How do finding groups in Amazon Detective assist in the investigation of security incidents?", "answer": "Finding groups in Amazon Detective assist in the investigation of security incidents by being collections of security findings and resources associated with a single potential security incident. They help reduce triage time because you dont have to investigate each individual security finding separately. Starting your investigation with finding groups offers a more complete understanding of the incident.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T16:36:30.308420"}}
{"question": "How does the behavior graph created by Amazon Detective differ from individual security findings?", "answer": "The behavior graph created by Amazon Detective provides a unified, interactive view of resource behaviors and their interactions over time, specifically for time-based events, while individual security findings represent isolated incidents. The behavior graph utilizes machine learning to analyze these interactions comprehensively, whereas individual findings may not provide the context of how they relate to each other.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T16:36:30.308820"}}
{"question": "What does automated investigations in AWS Identity and Access Management (IAM) help determine?", "answer": "Automated investigations help determine if IAM entities, such as IAM users or roles, are potentially compromised by querying the behavior graph and using machine learning to identify anomalous behavior or indicators of compromise (IoC).", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T16:36:37.332330"}}
{"question": "How does Amazon Detective utilize data from AWS services for its analysis?", "answer": "Amazon Detective utilizes data from various AWS services, including AWS CloudTrail logs, Amazon VPC Flow Logs, Amazon EKS audit logs, and Amazon GuardDuty findings, to perform its analysis. The pricing is based on the volume of this ingested data, charged per Gigabyte (GB) ingested per account/region/month.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T16:36:37.332693"}}
{"question": "How does the regional availability of Amazon Detective affect its data analysis across accounts?", "answer": "Amazon Detective needs to be enabled on a region by region basis, allowing it to analyze activity across all accounts within each region. This ensures that all analyzed data is regionally based and does not cross AWS regional boundaries.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T16:36:37.333122"}}
{"question": "How can Amazon Detective be enabled?", "answer": "Amazon Detective can be enabled with a few clicks in the AWS Management Console or by using the Amazon Detective API.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:36:41.715398"}}
{"question": "What types of data does Amazon Detective enable customers to analyze?", "answer": "Amazon Detective enables customers to view summaries and analytical data associated with Amazon Virtual Private Cloud (Amazon VPC) Flow Logs, AWS CloudTrail logs, Amazon Elastic Kubernetes Service (Amazon EKS) audit logs, AWS Security Hub findings, and Amazon GuardDuty findings.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:36:41.715691"}}
{"question": "How does Amazon Detective's functionality compare when using it with or without Amazon GuardDuty?", "answer": "You can use Amazon Detective even if Amazon GuardDuty is not activated in the account. However, if you have Amazon GuardDuty enabled, it is recommended to enable Amazon Detective with the same administrative account for the best cross-service experience. Both services provide insights into security issues, but Amazon Detective can also analyze behaviors and interactions among AWS accounts, EC2 instances, AWS users, roles, and IP addresses regardless of whether GuardDuty is active.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:36:41.716099"}}
{"question": "What types of logs does Amazon Detective process once enabled?", "answer": "Once enabled, Amazon Detective processes data from AWS CloudTrail logs, Amazon VPC Flow Logs, Amazon EKS audit logs, findings sent from integrated AWS services to AWS Security Hub, and Amazon GuardDuty findings for any accounts where it has been turned on.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-04T16:36:45.812465"}}
{"question": "How does Amazon Detective assist in investigating security findings?", "answer": "Amazon Detective simplifies the process of investigating security findings by analyzing trillions of events from multiple data sources and automatically creating a graph model that provides a unified, interactive view of resources, users, and their interactions over time.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-04T16:36:45.812764"}}
{"question": "What distinguishes Amazon GuardDuty from Amazon Detective in terms of functionality?", "answer": "Amazon GuardDuty is primarily a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect AWS accounts and workloads, while Amazon Detective focuses on analyzing and visualizing security data to help investigate findings and identify root causes.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-04T16:36:45.813196"}}
{"question": "What services does Amazon Detective support for cross-service user workflows?", "answer": "Amazon Detective supports console integrations with Amazon GuardDuty, AWS Security Hub, and Amazon Security Lake for cross-service user workflows.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T16:36:52.121494"}}
{"question": "How does Amazon Detective enhance the investigation of findings from AWS services?", "answer": "Amazon Detective enhances the investigation of findings from AWS services by providing links from the consoles of Amazon GuardDuty and Security Hub that redirect users to Amazon Detective pages. These pages contain a curated set of visualizations specifically for investigating the selected finding. Additionally, Amazon Detective offers pre-built queries that can query and download log files from Amazon Security Lake, and its findings detail page is aligned to the timeframe of the finding, showing relevant data associated with it.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T16:36:52.121825"}}
{"question": "How does the integration of AWS Security Hub affect the ingestion of findings by Amazon Detective?", "answer": "When AWS Security Hub is turned on and integrated services are enabled, those services automatically send findings to Security Hub. Amazon Detective then ingests these findings and adds them to its graph, allowing users to conduct security investigations across all integrated AWS services. This process occurs automatically and continuously for AWS services integrated with AWS Security Hub, except for sensitive data findings from Amazon Macie, for which users must opt-in.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T16:36:52.122296"}}
{"question": "Are AWS security findings enabled by default for new accounts using Amazon Detective?", "answer": "Yes, by default, AWS security findings are enabled as a data source for new accounts using Amazon Detective.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-04T16:36:55.909785"}}
{"question": "How does Amazon Detective ensure that consuming AWS security findings does not affect the performance of AWS security services?", "answer": "Amazon Detective consumes the security findings using independent and duplicative log streams, which ensures that this consumption will not affect the performance of your AWS security services.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-04T16:36:55.910101"}}
{"question": "What is the difference in pricing for Amazon Detective's consumption of AWS security findings compared to AWS Security Hub?", "answer": "Amazon Detective's consumption of AWS security findings is priced based on the volume of findings processed and analyzed, while the consumption does not increase costs for using AWS Security Hub or any integrated AWS security service.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-04T16:36:55.910502"}}
{"question": "What services can Amazon Detective query and retrieve logs from after integration?", "answer": "After integration, Amazon Detective can query and retrieve AWS CloudTrail logs and Amazon Virtual Private Cloud (Amazon VPC) Flow Logs from Amazon Security Lake for security investigations.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-04T16:37:01.437264"}}
{"question": "How does the integration of Amazon Detective and Amazon Security Lake facilitate security investigations?", "answer": "The integration allows users to start investigations in Amazon Detective and preview or download specific AWS CloudTrail logs or Amazon VPC Flow Logs for additional details. It also provides a pre-built SQL query using Amazon Athena scoped to the time and entity under investigation, simplifying the query and log retrieval process, and saving time by eliminating the need to craft SQL queries from scratch.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-04T16:37:01.437558"}}
{"question": "What are the cost implications of integrating Amazon Detective with Amazon Security Lake?", "answer": "Integrating Amazon Detective with Amazon Security Lake incurs charges according to Amazon Detective pricing and Amazon Security Lake pricing. Additionally, there are charges for each query using Amazon Athena and for the additional AWS services deployed in your account to support the integration.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-04T16:37:01.437959"}}
{"question": "What does Amazon Detective automatically analyze and correlate in relation to Amazon EKS workloads?", "answer": "Amazon Detective automatically and continuously analyzes and correlates user, network, and configuration activity across your Amazon EKS workloads.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-04T16:37:06.592970"}}
{"question": "How does Amazon Detective help in investigating potential malicious behavior associated with Amazon EKS workloads?", "answer": "Amazon Detective provides a data analysis and visualization layer that helps answer common security questions, backed by a behavioral graph database that allows for quicker investigations into potential malicious behavior associated with Amazon EKS workloads.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-04T16:37:06.593350"}}
{"question": "How does the consumption of Amazon EKS audit logs by Amazon Detective compare to the performance and cost of Amazon EKS workloads?", "answer": "Amazon Detective's consumption of Amazon EKS audit logs is designed not to affect the performance of your Amazon EKS workloads, as it uses independent and duplicative audit log streams. Additionally, this consumption will not increase your costs for using Amazon EKS.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-04T16:37:06.593855"}}
{"question": "What types of deployments does the capability currently support?", "answer": "The capability currently supports Amazon EKS deployments running on EC2 instances in your AWS account.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-04T16:37:11.065762"}}
{"question": "How does Detective enhance the monitoring of containerized applications in AWS?", "answer": "Detective enhances monitoring by providing support for Amazon GuardDuty EKS Runtime Monitoring and ECS Runtime monitoring, which includes monitoring for Amazon ECS on Fargate.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-04T16:37:11.066132"}}
{"question": "What is the difference in visibility provided by this capability between managed Kubernetes and non-managed Kubernetes?", "answer": "This capability provides visibility into managed Kubernetes deployments, specifically Amazon EKS on EC2, but does not provide visibility into non-managed Kubernetes on EC2 or Amazon Elastic Kubernetes Service (ES) anywhere.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-04T16:37:11.066589"}}
{"question": "What types of applications does AWS Device Farm support?", "answer": "AWS Device Farm supports native and hybrid Android, iOS, and web apps, as well as cross-platform apps including those created with PhoneGap, Titanium, Xamarin, Unity, and other frameworks.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T16:37:16.506579"}}
{"question": "How does AWS Device Farm improve the application development process for developers and QA teams?", "answer": "AWS Device Farm improves the application development process by allowing developers to test and interact with real Android and iOS devices in the AWS Cloud. It enables automated tests to be run in parallel across hundreds of devices, providing results, screenshots, video, and performance data quickly. This accelerates development by allowing for both automated and manual testing, including reproducing customer issues and exploratory testing.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T16:37:16.506920"}}
{"question": "How does AWS Device Farm compare to maintaining an internal device lab?", "answer": "AWS Device Farm offers significant savings compared to maintaining an internal device lab by eliminating the need for lab managers and the development of automation infrastructure. It allows developers and QA teams to run tests on real devices without the overhead and complexity of managing their own device labs.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T16:37:16.507438"}}
{"question": "What is the maximum duration for which logs, video recordings, and other artifacts are stored in AWS Device Farm?", "answer": "Logs, video recordings, and other artifacts are stored for 400 days in AWS Device Farm.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:37:22.484142"}}
{"question": "Why is it recommended to avoid providing sensitive information during automated test and remote access sessions in AWS Device Farm?", "answer": "It is recommended to avoid providing sensitive information because AWS Device Farm captures video and logs of activity during the use of each device, and there is a possibility for data to persist between sessions, especially if the device system is utilized outside the context of the app.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:37:22.484506"}}
{"question": "How does the app signing process differ between iOS and Android in AWS Device Farm?", "answer": "On iOS, the embedded provisioning profile is replaced with a wildcard profile and the app is resigned, resulting in the removal of certain entitlements. On Android, the app is also resigned, which may break functionality that relies on the app signature and could trigger anti-piracy and anti-tamper detection systems. Additionally, the Android manifest may be modified to include permissions for screenshot capture.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:37:22.484955"}}
{"question": "What types of devices are available in AWS Device Farm?", "answer": "AWS Device Farm has a large and growing selection of Android, iOS, and Fire OS devices. New popular devices are added as they are released by manufacturers, and new devices are also added as new OS versions are released.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:37:28.807302"}}
{"question": "How does AWS Device Farm allow users to interact with devices during Remote Access?", "answer": "During Remote Access, users can select the desired device based on make, model, carrier variant, and operating system version. After selecting, they can optionally upload apps and other data, configure device settings, and then Device Farm locates an available device that matches the request. The device's display is shown in the user's browser, allowing them to interact with the device and capture screenshots and video.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:37:28.807661"}}
{"question": "What is the difference between the connections available for testing in AWS Device Farm and actual carrier connections?", "answer": "In AWS Device Farm, devices do not have actual carrier connections and cannot make phone calls or send SMS messages. However, users can simulate connection types and conditions using the network shaping functionality, selecting curated network profiles like '3G' or 'Lossy LTE', or creating custom profiles to control parameters like throughput, jitter, and loss.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:37:28.807862"}}
{"question": "What types of apps does AWS Device Farm support for testing?", "answer": "AWS Device Farm supports testing on Native, Hybrid, and Web apps for both the Android and iOS platforms.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:37:34.768777"}}
{"question": "How does Fuzz testing work in AWS Device Farm?", "answer": "Fuzz testing in AWS Device Farm works by streaming random user input, such as touches, swipes, and keyboard input, to your app in a rapid fashion immediately after launch. You can configure the number of events, the delay between events, and the seed used to randomize those events. Using the same seed across test runs will produce the same sequence of events.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:37:34.769122"}}
{"question": "How does the screenshot functionality differ when using supported automation frameworks compared to unsupported ones in AWS Device Farm?", "answer": "When using one of the supported automation frameworks in AWS Device Farm, you have full control over when to take screenshots, and those screenshots are automatically included in your reports. In contrast, if you use an unsupported automation framework, you may not have the same level of control or automatic inclusion of screenshots in reports.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T16:37:34.769334"}}
{"question": "What is the maximum size of a .zip archive that can be provided to AWS Device Farm?", "answer": "The maximum size of a .zip archive that can be provided to AWS Device Farm is up to 4 GB.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-04T16:37:39.025359"}}
{"question": "How does AWS Device Farm handle the installation order of multiple apps?", "answer": "In AWS Device Farm, you can select multiple apps and the order in which to install them. The dependent apps will be installed before your tests begin.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-04T16:37:39.025685"}}
{"question": "How do the test reports from AWS Device Farm differ from regular test execution logs?", "answer": "AWS Device Farm test reports contain pass/fail information, crash reports, test logs, device logs, screenshots, videos, and performance data, which are more detailed than regular test execution logs. They include both detailed per-device data and high-level results, such as the number of occurrences of a given error, while regular logs may not provide this level of detail.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-04T16:37:39.026198"}}
{"question": "What types of logs does AWS Device Farm include in its reports?", "answer": "AWS Device Farm reports include complete logcat (Android) and device logs (iOS), as well as logs from the device host and specified test framework.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-04T16:37:43.537813"}}
{"question": "How does AWS Device Farm handle the billing for device minutes?", "answer": "Pricing for AWS Device Farm is based on device minutes, which are determined by the duration of tests on each selected device. Customers are charged $0.17 per device minute after the initial 1000 device minutes provided free of charge, which is a one-time trial that does not renew. Device minutes are the billing unit that measures the time taken to install, execute, and uninstall apps and tests on the selected devices.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-04T16:37:43.538092"}}
{"question": "How do the free trial device minutes compare to the standard billing rate for AWS Device Farm?", "answer": "AWS Device Farm provides the first 1000 device minutes free of charge as a one-time trial that does not renew. Once this trial allocation is depleted, customers are billed at the standard rate of $0.17 per device minute.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-04T16:37:43.538491"}}
{"question": "What is the starting price for unmetered plans in AWS Device Farm?", "answer": "The starting price for unmetered plans in AWS Device Farm is $250 per month.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:37:49.654561"}}
{"question": "How do unmetered plans differ from metered billing in terms of concurrency?", "answer": "Unmetered plans are based on the number of device slots purchased, with concurrency limited to the number of slots, whereas metered billing allows for unlimited concurrency, enabling users to run tests faster than with unmetered device slots.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:37:49.654900"}}
{"question": "What are the differences in subscription pricing between private devices and unmetered plans?", "answer": "The subscription price for private devices starts at $200 per month, while unmetered plans start at $250 per month. Additionally, private devices are physical instances exclusive to your account and can have custom configurations, whereas unmetered plans are based on device slots for testing and remote access.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T16:37:49.655292"}}
{"question": "What is the pricing structure for using Device Farm for Desktop Browser Testing?", "answer": "Pricing for Device Farm is based on instance minutes, which are determined by the duration of tests on each selected browser instance. You will be charged $0.005 per browser instance minute. An instance minute is the billing unit for Desktop Browser Testing on Device Farm, measuring the time it takes (in minutes) to execute your tests on every browser instance selected for your test run.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-04T16:37:55.222212"}}
{"question": "What is the difference between the client-side execution model and the server-side execution model in Device Farm?", "answer": "In Device Farm, the client-side execution model for Selenium testing means that your tests execute on your own local machine, interacting with browsers hosted on AWS Device Farm through the Selenium API. In contrast, for testing web apps on real mobile devices using Appium, Device Farm follows a server-side execution model, requiring you to upload your tests to the service.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-04T16:37:55.222549"}}
{"question": "How do the logging features of Device Farm assist in troubleshooting test failures?", "answer": "Device Farm generates console logs, web driver logs, action logs, and video recordings of the entire test. These logs and recordings help users troubleshoot test failures by providing detailed insights into what occurred during the test execution.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-04T16:37:55.223048"}}
{"question": "What is the primary purpose of Amazon DevOps Guru?", "answer": "The primary purpose of Amazon DevOps Guru is to improve an applications operational performance and availability by detecting behaviors that deviate from normal operating patterns and identifying operational issues before they impact customers.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-04T16:37:59.953988"}}
{"question": "How does DevOps Guru assist in monitoring complex applications?", "answer": "DevOps Guru assists in monitoring complex applications by saving time and effort spent on detecting, debugging, and resolving operational issues. It helps avoid common oversights and errors in monitoring, such as missing alarms, and fetches relevant and specific information from numerous data sources when operational issues occur.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-04T16:37:59.954411"}}
{"question": "What happens when DevOps Guru identifies a critical issue compared to when it does not identify any issues?", "answer": "When DevOps Guru identifies a critical issue, it automatically sends an alert, provides a summary of related anomalies, and context for when and where the issue occurred, along with recommendations for remediation. In contrast, when it does not identify any issues, it does not send alerts or provide summaries, thus not facilitating timely intervention.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-04T16:37:59.954834"}}
{"question": "What types of metrics does Amazon DevOps Guru analyze for identifying anomalous application behavior?", "answer": "Amazon DevOps Guru analyzes metrics such as latency, error rates, and request rates to establish normal operating bounds and identify deviations from this established baseline.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:38:03.853678"}}
{"question": "How does Amazon DevOps Guru assist developers in reducing time to resolution when issues arise?", "answer": "Amazon DevOps Guru assists developers by providing options for remediation or mitigation based on its analysis of operational data, which includes suggestions that help reduce time to resolution without requiring manual configuration or ML expertise.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:38:03.853934"}}
{"question": "How does the analysis coverage boundary selection affect the operational data that DevOps Guru analyzes?", "answer": "The analysis coverage boundary selection determines whether DevOps Guru analyzes the entire AWS account, specific AWS CloudFormation stacks, or resource groupings defined by AWS tags. DevOps Guru analyzes the operational data for all supported AWS resources within the chosen coverage boundary.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-04T16:38:03.854086"}}
{"question": "What operational issues can Amazon DevOps Guru automatically detect?", "answer": "Amazon DevOps Guru can automatically detect operational issues such as missing or misconfigured alarms, early warning of resource exhaustion, and code and configuration changes that could lead to outages.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-04T16:38:08.161989"}}
{"question": "How does Amazon DevOps Guru utilize machine learning in its operations?", "answer": "Amazon DevOps Guru uses machine learning to correlate anomalies in metrics and logs with operational events, providing contextual insights that help users focus on the right remediation steps.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-04T16:38:08.162266"}}
{"question": "In what ways do Amazon DevOps Guru and AWS Systems Manager OpsCenter work together?", "answer": "Amazon DevOps Guru operational insights can be surfaced directly within the AWS Systems Manager OpsCenter dashboard as OpsItems. Additionally, users can configure Amazon DevOps Guru to create an OpsItem for each insight it generates, integrating the operational insights into OpsCenter.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-04T16:38:08.162671"}}
{"question": "How long does it take for Amazon DevOps to baseline an application?", "answer": "Once enabled, Amazon DevOps starts baselining your application, which may range from minutes to an hour depending on the number of resources being analyzed.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-04T16:38:13.079400"}}
{"question": "What is the purpose of Amazon DevOps Guru for RDS?", "answer": "Amazon DevOps Guru for RDS is designed to automatically detect and diagnose performance and operational issues within a database, enabling developers to resolve issues in minutes rather than days. It expands the capabilities of DevOps Guru to detect, diagnose, and remediate a wide variety of database-related issues in Amazon RDS.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-04T16:38:13.079685"}}
{"question": "How does Amazon DevOps Guru for RDS analyze performance issues compared to traditional methods?", "answer": "Amazon DevOps Guru for RDS analyzes performance issues using telemetry data collected by Amazon RDS Performance Insights and employs a combination of rules and ML-based techniques to detect problematic patterns. This approach allows it to quickly notify developers and provide recommendations, significantly reducing the time to detection and resolution compared to traditional manual methods.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-04T16:38:13.080135"}}
{"question": "How can I enable Amazon DevOps Guru for my Amazon Aurora resources?", "answer": "You can enable Amazon DevOps Guru for your Amazon Aurora resources by navigating to the Amazon RDS console and turning on Amazon RDS Performance Insights. Additionally, you can enable the service for your Amazon Aurora resources, other supported resources, or your entire account from the Amazon DevOps Guru console. It can also be enabled while creating or modifying a new database from within the Amazon RDS Console, from the Performance Insights (PI) page, or within the database details page.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-04T16:38:19.845521"}}
{"question": "What is the purpose of Amazon DevOps Guru for RDS?", "answer": "Amazon DevOps Guru for RDS is designed to identify a wide range of performance issues that may affect application service quality, including lock pile ups, connection storms, SQL regressions, CPU and I/O contention, memory issues, and misconfigured parameters. It monitors database performance metrics, detects performance issues, analyzes them, and provides recommendations for resolution.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-04T16:38:19.845900"}}
{"question": "How does Amazon DevOps Guru for Serverless differ from Amazon DevOps Guru for RDS?", "answer": "Amazon DevOps Guru for Serverless is specifically designed for Serverless Applications built using AWS resources, focusing on automatically detecting and diagnosing performance and operational issues such as performance latency degradation and resource exhaustion. In contrast, Amazon DevOps Guru for RDS targets performance issues related to relational databases, offering insights into various database performance metrics and issues like lock pile ups and SQL regressions. Both services provide reactive and proactive insights, but they cater to different types of applications.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-04T16:38:19.846380"}}
{"question": "What is the main purpose of Amazon DevOps Guru for Serverless?", "answer": "The main purpose of Amazon DevOps Guru for Serverless is to monitor serverless applications for performance and operational issues, allowing for quicker detection and resolution of hard-to-find reliability, performance, and operational issues.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-04T16:38:24.313238"}}
{"question": "How does Amazon DevOps Guru for Serverless help in mitigating potential issues?", "answer": "Amazon DevOps Guru for Serverless helps in mitigating potential issues by early detection of problems that may impact the application, allowing operators to address these issues before they affect users.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-04T16:38:24.313479"}}
{"question": "What are the differences in coverage options available when enabling Amazon DevOps Guru for Serverless?", "answer": "When enabling Amazon DevOps Guru for Serverless, users can set the coverage boundary to be either their entire AWS account or specify certain AWS CloudFormation stacks or use AWS tags to create a resource grouping for analysis.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-04T16:38:24.313874"}}
{"question": "What type of insights does Amazon DevOps Guru for Serverless provide to identify potential issues before they impact applications?", "answer": "Amazon DevOps Guru for Serverless provides Proactive Insights to flag potential issues with your applications and infrastructure early, enabling you to respond quickly and help reduce costly downtime or operating costs.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:38:30.636071"}}
{"question": "How does Amazon DevOps Guru for Serverless assist in improving resource utilization for applications?", "answer": "Amazon DevOps Guru for Serverless assists in improving resource utilization by detecting resources that are underutilized. For example, if DynamoDB has provisioned write capacity units that are significantly over what is actually consumed, DevOps Guru detects this and recommends scaling back the provisioned write capacity.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:38:30.636364"}}
{"question": "What is the difference between Proactive Insights and Reactive Insights provided by Amazon DevOps Guru for Serverless?", "answer": "Proactive Insights are focused on flagging potential issues with applications and infrastructure before they impact performance, allowing for early intervention. In contrast, Reactive Insights address ongoing issues that are currently affecting the application, such as latency degradation or 5xx errors, enabling quick resolution of these problems.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-04T16:38:30.636767"}}
{"question": "What determines the charges for using Amazon DevOps Guru?", "answer": "The charges for using Amazon DevOps Guru are determined by two components: charges for AWS resource analysis and charges for DevOps Guru API calls.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T16:38:34.787127"}}
{"question": "How does Amazon DevOps Guru analyze AWS resources within a specified coverage boundary?", "answer": "Instead of choosing specific AWS resources for analysis, you specify the resource analysis coverage boundary. Based on your selection, DevOps Guru will analyze the operational data for all supported AWS resources in your coverage boundary, which can include the entire account, specific AWS CloudFormation stacks, or resource groupings created using AWS tags.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T16:38:34.787464"}}
{"question": "What happens to the analysis and billing of resources when they are removed from the coverage boundary in Amazon DevOps Guru?", "answer": "When you remove resources from your account or CloudFormation stack that DevOps Guru is analyzing, it stops analyzing those resources and ceases billing for them.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T16:38:34.787994"}}
{"question": "Is there an additional charge for using Amazon DevOps Guru for RDS?", "answer": "No, Amazon DevOps Guru for RDS is offered to customers at no additional charge, as part of the existing price that DevOps Guru charges customers for RDS resources.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-04T16:38:40.912211"}}
{"question": "What are the two groups of resource types evaluated by DevOps Guru, and how are they priced?", "answer": "DevOps Guru segments the resource types it evaluates into two groups: Group A includes AWS Lambda and Amazon S3, priced at $0.0028 per resource per hour (approximately $2 per resource for 30 days); Group B includes Amazon RDS, Amazon EC2, Amazon Redshift clusters, and 25 other AWS resource types, priced at $0.0042 per resource per hour (approximately $3 per resource for 30 days).", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-04T16:38:40.912554"}}
{"question": "How does the pricing for Group A resources compare to Group B resources?", "answer": "Group A resources are priced at $0.0028 per resource per hour, while Group B resources are priced at $0.0042 per resource per hour. This means that Group B resources are more expensive than Group A resources, with Group A costing approximately $2 per resource for 30 days and Group B costing approximately $3 per resource for 30 days.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-04T16:38:40.913057"}}
{"question": "In which AWS regions is Amazon DevOps Guru available?", "answer": "Amazon DevOps Guru is available in the following AWS regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (London), Europe (Paris), Asia Pacific (Mumbai), Asia Pacific (Seoul), South America (So Paulo), Asia Pacific (Singapore), Asia Pacific (Sydney), and Asia Pacific (Tokyo).", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-04T16:38:46.480765"}}
{"question": "What does the availability of Amazon DevOps Guru in multiple regions imply about its deployment capabilities?", "answer": "The availability of Amazon DevOps Guru in multiple regions implies that it can be deployed in various geographical locations, allowing users to choose a region that best fits their operational needs and compliance requirements. This regional flexibility is essential for optimizing performance and latency.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-04T16:38:46.481117"}}
{"question": "How does the availability of Amazon DevOps Guru in Europe compare to its availability in Asia Pacific?", "answer": "Amazon DevOps Guru is available in several European regions, including Frankfurt, Ireland, Stockholm, London, and Paris. In the Asia Pacific region, it is available in Mumbai, Seoul, Singapore, Sydney, and Tokyo. This indicates a broader distribution in Europe with five available regions compared to five in Asia Pacific, highlighting an equal focus on both areas for service availability.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-04T16:38:46.481545"}}
{"question": "What is AWS Direct Connect?", "answer": "AWS Direct Connect is a networking service that provides an alternative to using the internet to connect to AWS. It allows data that would have previously been transported over the internet to be delivered through a private network connection between your facilities and AWS.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T16:38:51.033216"}}
{"question": "What are the advantages of using AWS Direct Connect compared to internet-based connections?", "answer": "Using AWS Direct Connect can reduce costs, increase bandwidth, and provide a more consistent network experience compared to internet-based connections.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T16:38:51.033500"}}
{"question": "How does a dedicated connection differ from a hosted connection in AWS Direct Connect?", "answer": "A dedicated connection in AWS Direct Connect is made through a 1 Gbps, 10 Gbps, 100 Gbps, or 400 Gbps Ethernet port that is dedicated to a single customer. In contrast, a hosted connection is sourced from an AWS Direct Connect Partner that has a network link between themselves and AWS.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T16:38:51.033906"}}
{"question": "What information do you need to provide when creating a new AWS Direct Connect connection?", "answer": "When creating a new AWS Direct Connect connection, you need to select an AWS Direct Connect location, specify the number of ports, and choose the port speed.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T16:38:57.164666"}}
{"question": "What is the purpose of an AWS Direct Connect gateway?", "answer": "The purpose of an AWS Direct Connect gateway is to group virtual private gateways (VGWs) and private virtual interfaces (VIFs). It is a globally available resource that can be created in any Region and accessed from all other Regions.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T16:38:57.165001"}}
{"question": "How does a public virtual interface differ from a private virtual interface in AWS Direct Connect?", "answer": "A public virtual interface (VIF) enables access to public services, such as Amazon S3, while a private virtual interface allows access to your Virtual Private Cloud (VPC).", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-04T16:38:57.165522"}}
{"question": "What is a link aggregation group (LAG) in AWS Direct Connect?", "answer": "A link aggregation group (LAG) is a logical interface that uses the link aggregation control protocol (LACP) to aggregate multiple dedicated connections at a single AWS Direct Connect endpoint, allowing you to treat them as a single, managed connection. LAGs streamline configuration because the LAG configuration applies to all connections in the group.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:39:01.876126"}}
{"question": "How does the AWS Direct Connect Resiliency Toolkit assist users?", "answer": "The AWS Direct Connect Resiliency Toolkit provides a connection wizard that helps users choose between multiple resiliency models. These models assist in determining the number of dedicated connections needed to achieve the user's SLA objective. After selecting a resiliency model, the toolkit guides users through the dedicated connection ordering process, ensuring that they have the appropriate number of dedicated connections in multiple locations.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:39:01.876456"}}
{"question": "What is the difference between dynamic and static LACP bundles in AWS Direct Connect?", "answer": "Dynamic LACP bundles are supported in AWS Direct Connect, while static LACP bundles are not supported. This means that users can only utilize dynamic LACP for link aggregation in their configurations.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T16:39:01.876858"}}
{"question": "What is a configurable private autonomous system number (ASN) used for in AWS Direct Connect?", "answer": "A configurable private autonomous system number (ASN) makes it possible to set the ASN on the AWS side of the Border Gateway Protocol (BGP) session for private or transit virtual interfaces (VIFs) on any newly created AWS Direct Connect Gateway.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:39:07.733296"}}
{"question": "How does a transit virtual interface differ from a private virtual interface in AWS Direct Connect?", "answer": "A transit virtual interface is specifically designed to be attached to an AWS Direct Connect gateway and can interface with up to six AWS Transit Gateways, while a private virtual interface is used for direct connections to a single VPC. Additionally, both types of interfaces allow for one IPv4 BGP session and one IPv6 BGP session, but their use cases and attachment capabilities differ.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:39:07.733612"}}
{"question": "What is the purpose of the multi-account support feature for AWS Direct Connect gateways?", "answer": "The multi-account support feature allows you to associate up to 20 Amazon Virtual Private Clouds (Amazon VPCs) or up to six AWS Transit Gateways from multiple AWS accounts with an AWS Direct Connect gateway, enhancing connectivity and resource management across different accounts.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-04T16:39:07.733963"}}
{"question": "What does a LAG protect against in terms of connectivity failures?", "answer": "A LAG will protect against single link failure if you have more than one link in your LAG and your minimum links are set to one. However, it does not protect against a single device failure or device maintenance at AWS where your LAG is terminating.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:39:14.583194"}}
{"question": "What is recommended for achieving high availability connectivity to AWS?", "answer": "To achieve high availability connectivity to AWS, it is recommended to make connections at multiple AWS Direct Connect locations and to follow the resiliency best practices detailed in the AWS Direct Connect Resiliency Recommendations page.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:39:14.583458"}}
{"question": "How does the redundancy of AWS Direct Connect connections differ from a backup IPsec VPN connection?", "answer": "AWS Direct Connect connections are recommended to have a second connection for redundancy, and when requesting multiple ports at the same location, they will be provisioned on redundant AWS equipment. In contrast, if a backup IPsec VPN connection is configured, all VPC traffic will automatically failover to the VPN connection during a failure, while traffic to/from public resources will be routed over the internet. If neither a backup AWS Direct Connect link nor an IPsec VPN link is available, Amazon VPC traffic will be dropped during a failure.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T16:39:14.583861"}}
{"question": "What is the minimum and maximum duration that can be configured for a test?", "answer": "The minimum duration that can be configured for a test is 1 minute, and the maximum duration is 180 minutes.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-04T16:39:17.782801"}}
{"question": "How can you review your test history for AWS Direct Connect?", "answer": "You can review your test history using the AWS Management Console or through AWS CloudTrail. The test history is preserved for 365 days.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-04T16:39:17.783082"}}
{"question": "What is the relationship between AWS Direct Connect SiteLink-enabled virtual interfaces and AWS Direct Connect gateways?", "answer": "To use AWS Direct Connect SiteLink, you must connect AWS Direct Connect SiteLink-enabled virtual interfaces (VIFs) to an AWS Direct Connect gateway. The VIF type can be either private or transit.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-04T16:39:17.783467"}}
{"question": "What is required to enable AWS Direct Connect SiteLink on a private virtual interface (VIF)?", "answer": "To enable AWS Direct Connect SiteLink on a private virtual interface (VIF), you need to configure the VIF and enable AWS Direct Connect SiteLink on that VIF at each site.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T16:39:24.135553"}}
{"question": "Why would someone choose to use AWS Direct Connect SiteLink over Cloud WAN?", "answer": "Someone might choose to use AWS Direct Connect SiteLink over Cloud WAN because AWS Direct Connect SiteLink connects DX locations together, bypassing AWS Regions to improve performance, while Cloud WAN is designed to create and manage networks of VPCs across multiple Regions.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T16:39:24.135802"}}
{"question": "How does the use of multiple AWS Direct Connect gateways affect communication between AWS Direct Connect SiteLink-enabled VIFs?", "answer": "When using multiple AWS Direct Connect gateways, AWS Direct Connect SiteLink-enabled VIFs on one AWS Direct Connect gateway cannot communicate with AWS Direct Connect SiteLink-enabled VIFs on another AWS Direct Connect gateway. This creates a segmented network.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T16:39:24.135951"}}
{"question": "Can you connect AWS Direct Connect to VPCs in AWS Local Zones?", "answer": "Yes, when using AWS Direct Connect, you can connect to VPCs deployed in AWS Local Zones. Your data travels directly to and from AWS Local Zones over an AWS Direct Connect connection, without traversing an AWS Region.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:39:28.668761"}}
{"question": "What are the benefits of using AWS Direct Connect with AWS Local Zones?", "answer": "Using AWS Direct Connect with AWS Local Zones improves performance and can reduce latency as the data travels directly to and from the Local Zones without going through an AWS Region.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:39:28.669104"}}
{"question": "How does the maximum MTU size differ between AWS Regions and AWS Local Zones?", "answer": "In AWS Regions, the maximum MTU size is 9001, while for connections to AWS Local Zones, the maximum MTU size is 1468. This means that the MTU size is significantly smaller when connecting to Local Zones compared to Regions.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:39:28.669631"}}
{"question": "Can an AWS Site-to-Site VPN be used as a backup for an AWS Direct Connect connection to an AWS Local Zone?", "answer": "No, an AWS Site-to-Site VPN cannot be used as a backup to your AWS Direct Connect connection to an AWS Local Zone. For redundancy, you must use two or more AWS Direct Connect connections.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-04T16:39:33.825315"}}
{"question": "What are the configuration options for AWS Direct Connect connections regarding virtual interfaces?", "answer": "Each AWS Direct Connect connection can be configured with one or more virtual interfaces. Virtual interfaces may be configured to access AWS services such as Amazon EC2 and Amazon S3 using public IP space, or resources in a VPC using private IP space.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-04T16:39:33.825632"}}
{"question": "How does the maximum number of links in a Link Aggregation Group (LAG) differ between 1/10 Gbps connections and 100/400 Gbps connections?", "answer": "The maximum number of links in a LAG group is 4 times for 1 or 10 Gbps connections and 2 times for 100 or 400 Gbps connections.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-04T16:39:33.826039"}}
{"question": "What types of ports are available for creating a Link Aggregation Group (LAG)?", "answer": "LAG can be created using 1, 10, 100, and 400 Gbps Dedicated Connection ports.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-04T16:39:39.618851"}}
{"question": "Why is it important to consider the minimum links setting before deleting a port from a LAG?", "answer": "The minimum links setting determines how many ports must remain active in a LAG. If the minimum links are set to four and you have four ports, you won't be able to delete a port. However, if the minimum links are set to three, you can delete a port. Deleting a port while the minimum links requirement is not met will not be allowed.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-04T16:39:39.619147"}}
{"question": "How does the ability to delete ports from a LAG differ when VIFs are configured versus when they are not?", "answer": "When VIFs are configured on a LAG, you cannot delete any ports from that LAG. In contrast, if there are no VIFs configured, you can delete a port as long as the minimum links requirement allows it.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-04T16:39:39.619673"}}
{"question": "What API call can be used to disassociate a connection with a LAG?", "answer": "The API call that can be used to disassociate a connection with a LAG is DisassociateConnectionWithLag.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T16:39:45.591179"}}
{"question": "What is the purpose of the minimum links feature in LACP?", "answer": "The minimum links feature in LACP allows you to set the minimum number of links that must be active in a bundle for that bundle to be active and pass traffic. For example, if you set the minimum links to three and only two ports are active, then the bundle will not be active. Conversely, if three or more links are active, the bundle will be active and can pass traffic if a Virtual Interface (VIF) is configured.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T16:39:45.591462"}}
{"question": "How does the treatment of links in LAG differ from a scenario where link priority is set?", "answer": "In a LAG, all links are treated as equal, meaning that no specific link priority is set on any link. This is in contrast to a scenario where link priority is set, which would designate certain links as more favorable for traffic than others.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T16:39:45.591851"}}
{"question": "What happens to port charges once a Hosted Connection is accepted?", "answer": "Once you have accepted the Hosted Connection, port charges will continue to be billed as long as the Hosted Connection is provisioned for your use.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-04T16:39:50.276077"}}
{"question": "Why might a customer need to work with their AWS Direct Connect Partner regarding their Hosted Connection?", "answer": "A customer might need to work with their AWS Direct Connect Partner to cancel the Hosted Connection if they no longer want to be charged for it.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-04T16:39:50.276368"}}
{"question": "How are port-hour charges for multiple Hosted Connections at the same AWS Direct Connect location summarized on a bill?", "answer": "Port-hour charges for multiple Hosted Connections at the same AWS Direct Connect location are grouped by capacity and summarized under a single item with a label that ends in HCPortUsage followed by the capacity, such as 'HCPortUsage:200M'.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-04T16:39:50.276885"}}
{"question": "What determines the AWS account responsible for Data Transfer Out when using a transit virtual interface?", "answer": "The AWS account responsible for the Data Transfer Out when using a transit virtual interface is determined based on the account that owns the Amazon Virtual Private Cloud(s) attached to the AWS Transit Gateway associated with the AWS Direct Connect gateway attached to the transit virtual interface.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-04T16:39:56.264794"}}
{"question": "How does the granular Data Transfer Out allocation feature impact billing for AWS accounts using private and transit virtual interfaces?", "answer": "With the introduction of the granular Data Transfer Out allocation feature, the billing for Data Transfer Out is based on the type of virtual interface used. For a private virtual interface, the AWS account that owns the AWS resources responsible for the Data Transfer Out will be charged. For a transit virtual interface, the account that owns the Amazon Virtual Private Cloud(s) attached to the associated AWS Transit Gateway will be charged. Additionally, all applicable AWS Transit Gateway specific charges will apply.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-04T16:39:56.265103"}}
{"question": "What is the difference in Data Transfer Out billing between using a private virtual interface and a transit virtual interface?", "answer": "The difference in Data Transfer Out billing between using a private virtual interface and a transit virtual interface lies in the account responsible for the charges. With a private virtual interface, the AWS account that owns the AWS resources responsible for the Data Transfer Out is charged. In contrast, with a transit virtual interface, the AWS account that owns the Amazon Virtual Private Cloud(s) attached to the AWS Transit Gateway associated with the transit virtual interface is charged.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-04T16:39:56.265637"}}
{"question": "How can I cancel my AWS Direct Connect service?", "answer": "You can cancel AWS Direct Connect by deleting your ports from the AWS Management Console. Additionally, you should cancel any service(s) purchased by a third party, such as contacting the colocation provider to disconnect any cross-connects to AWS Direct Connect.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-04T16:40:01.695045"}}
{"question": "What are the port capacity limits for advertising routes using AWS Direct Connect?", "answer": "You can advertise up to 100 routes over each Border Gateway Protocol session using AWS Direct Connect. If you exceed this limit, your session will go down, preventing all network traffic from flowing over that virtual interface until you reduce the number of routes to less than 100.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-04T16:40:01.695365"}}
{"question": "What is the difference between Dedicated Connections and Hosted Connections in terms of port speeds?", "answer": "For Dedicated Connections, available port speeds are 1 Gbps, 10 Gbps, 100 Gbps, and 400 Gbps. In contrast, Hosted Connections offer a wider range of speeds, including 50 Mbps, 100 Mbps, 200 Mbps, 300 Mbps, 400 Mbps, 500 Mbps, 1 Gbps, 2 Gbps, 5 Gbps, 10 Gbps, and 25 Gbps, which may be ordered from approved AWS Direct Connect Partners.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-04T16:40:01.695597"}}
{"question": "What is required to complete the AWS Direct Connect connection?", "answer": "To complete the AWS Direct Connect connection, you need a public or private ASN, a new unused VLAN tag, and public IPs allocated to the BGP session. If using a public ASN, you must own it, while a private ASN must be in the 64512 to 65535 range. Public IPs should be /31 or /30, and AWS will advertise global public IP prefixes via BGP by default.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-04T16:40:08.512496"}}
{"question": "How does the allocation of IP addresses differ when configuring a virtual interface to the public AWS Cloud versus connecting to a VPC?", "answer": "When configuring a virtual interface to the public AWS Cloud, the IP addresses for both ends of the connection must be allocated from public IP space that you own. In contrast, if the virtual interface is connected to a VPC and you choose to have AWS automatically generate the peer IP CIDR, the IP address space for both ends of the connection is allocated by AWS and falls within the 169.254.0.0/16 range.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-04T16:40:08.512729"}}
{"question": "What is the difference between the use of public ASN and private ASN in AWS Direct Connect?", "answer": "The main difference between public ASN and private ASN in AWS Direct Connect is that if you are using a public ASN, you must own it, while a private ASN must be within the range of 64512 to 65535. This means that public ASNs are associated with IP addresses that are globally routable and owned by the user, whereas private ASNs are meant for internal use within a private network.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-04T16:40:08.513118"}}
{"question": "What is required to complete the connection for AWS Direct Connect?", "answer": "To complete the connection for AWS Direct Connect, you will need a public or private ASN (if using a public ASN, you must own it; if using a private ASN, it must be in the 64512 to 65535 range), a new unused VLAN tag that you select, and the VPC Virtual Private Gateway (VGW) ID. Additionally, AWS will allocate private IPs (/30) in the 169.x.x.x range for the BGP session and will advertise the VPC CIDR block over BGP.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-04T16:40:14.143218"}}
{"question": "How does AWS Direct Connect differ from VPN connections in terms of network connectivity?", "answer": "AWS Direct Connect bypasses the internet and uses dedicated, private network connections between your network and AWS, while VPN connections use IPsec to establish encrypted network connectivity over the public internet. This makes AWS Direct Connect preferable for consistent performance, whereas VPN connections may have inherent variability due to their reliance on internet connectivity.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-04T16:40:14.143546"}}
{"question": "Can you attach a transit virtual interface to a Virtual Private Gateway in AWS Direct Connect?", "answer": "No, you cannot attach a transit virtual interface to your Virtual Private Gateway in AWS Direct Connect. Additionally, you cannot attach a private virtual interface to your AWS Transit Gateway.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-04T16:40:14.144056"}}
{"question": "What is the maximum MTU size supported by a transit virtual interface?", "answer": "The maximum transmission unit (MTU) size supported by a transit virtual interface is limited to 8,500.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-04T16:40:19.786999"}}
{"question": "What are the benefits of using an AWS Direct Connect gateway?", "answer": "An AWS Direct Connect gateway allows you to interface with VPCs in any AWS Region (except the AWS China Region) using your AWS Direct Connect connections, enabling you to connect with more than one AWS Region. It also allows you to share a private virtual interface with up to 20 VPCs, reducing the number of Border Gateway Protocol sessions between your on-premises network and AWS deployments. Additionally, by attaching transit virtual interfaces to an AWS Direct Connect gateway and associating AWS Transit Gateways with it, you can connect to multiple AWS Transit Gateways, further reducing the number of BGP sessions.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-04T16:40:19.787345"}}
{"question": "How does the association of AWS Transit Gateway with AWS Direct Connect gateway affect private virtual interfaces?", "answer": "Once a transit virtual interface (VIF) is connected to an AWS Direct Connect gateway, that gateway cannot host another private VIF, as it is dedicated to the transit VIF. This means that the AWS Direct Connect gateway can only support one type of virtual interface at a time when a transit VIF is in use.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-04T16:40:19.787826"}}
{"question": "How many Transit Gateways can be associated with an AWS Direct Connect gateway?", "answer": "You can associate up to six Transit Gateways to an AWS Direct Connect gateway as long as the IP CIDR blocks announced from your Transit Gateways do not overlap.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-04T16:40:25.369067"}}
{"question": "What are the limitations regarding virtual interfaces and AWS Direct Connect gateways in terms of account ownership?", "answer": "Private virtual interfaces and AWS Direct Connect gateways must be in the same AWS account. Similarly, transit virtual interfaces and AWS Direct Connect gateways must be in the same AWS account. However, virtual private gateway(s) and AWS Transit Gateway(s) can be in different AWS accounts than the account that owns the AWS Direct Connect gateway.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-04T16:40:25.369416"}}
{"question": "What is the difference between the support for AWS VPN CloudHub functionality and the use of AWS Site-to-Site VPN connections with an AWS Direct Connect gateway?", "answer": "AWS Direct Connect gateway does not support AWS VPN CloudHub functionality. However, if you are using an AWS Site-to-Site VPN connection to a virtual gateway (VGW) that is associated with your AWS Direct Connect gateway, you can use your VPN connection for failover.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-04T16:40:25.369882"}}
{"question": "Can a virtual private gateway (VGW) be part of more than one AWS Direct Connect gateway?", "answer": "No, a VGW-VPC pair cannot be part of more than one AWS Direct Connect gateway.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-04T16:40:31.990243"}}
{"question": "What is the relationship between AWS Direct Connect gateway and AWS VPN CloudHub?", "answer": "The AWS Direct Connect gateway does not break AWS VPN CloudHub functionality. Instead, it enables connectivity between on-premises networks and VPCs in any AWS Region, while AWS VPN CloudHub enables connectivity between on-premises networks using AWS Direct Connect or a VPN within the same Region.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-04T16:40:31.990586"}}
{"question": "How does attaching a virtual interface (VIF) directly to a virtual private gateway (VGW) differ from using an AWS Direct Connect gateway?", "answer": "Attaching a virtual interface (VIF) directly to a virtual private gateway (VGW) is allowed and supports intra-Region AWS VPN CloudHub. In contrast, you cannot use an AWS Direct Connect gateway for this purpose, as it does not support this direct attachment.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-04T16:40:31.991071"}}
{"question": "What happens to traffic from an on-premises network to a detached VGW associated with a VPC?", "answer": "Traffic from your on-premises network to the detached VGW associated with a VPC will stop.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-04T16:40:37.732338"}}
{"question": "What is required to send traffic between two VPCs using AWS Direct Connect?", "answer": "To send traffic between two VPCs, you must configure a VPC peering connection.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-04T16:40:37.732683"}}
{"question": "How does the AWS Direct Connect gateway handle prefix announcements from on-premises networks to VPCs?", "answer": "AWS Direct Connect gateway allows you to selectively announce prefixes towards your on-premises networks. Each VPC associated with an AWS Direct Connect gateway receives all prefixes announced from your on-premises networks. If you want to limit traffic to and from any specific VPC, you should consider using Access Control Lists (ACLs) for each VPC.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-04T16:40:37.733189"}}
{"question": "What happens if you do not specify Local Preference communities for your private VIF?", "answer": "If you do not specify Local Preference communities for your private VIF, the default local preference is based on the distance to the AWS Direct Connect Locations from the local Region, which may result in arbitrary egress behavior across multiple VIFs from multiple AWS Direct Connect Locations.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-04T16:40:44.253558"}}
{"question": "How can you influence egress traffic behavior between two VIFs on the same physical connection?", "answer": "You can influence egress traffic behavior between two VIFs on the same physical connection by advertising prefixes over the primary/active virtual interface with a community for higher local preference than prefixes advertised over the backup/passive virtual interface.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-04T16:40:44.253969"}}
{"question": "How does the handling of BGP for VPN compare to AWS Direct Connect?", "answer": "VPN BGP will work the same as AWS Direct Connect, meaning both follow the standard approach for path selection and local preferences.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-04T16:40:44.254487"}}
{"question": "What is the range of 16-bit private ASNs that can be assigned to the AWS side during the creation of an AWS Direct Connect gateway?", "answer": "The range for 16-bit private ASNs includes 64512 to 65534.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-04T16:40:50.601647"}}
{"question": "Why does AWS limit the AWS side ASN to private ASNs?", "answer": "AWS limits the AWS side ASN to private ASNs to protect customers from BGP spoofing, as they do not validate ownership of the ASNs.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-04T16:40:50.602064"}}
{"question": "Can you configure different AWS side ASNs for each AWS Direct Connect gateway and Virtual Private Gateway?", "answer": "Yes, you can use different private ASNs for your AWS Direct Connect Gateway and Virtual Private Gateway. Additionally, you can use the same private ASNs for both, as the AWS side ASN you receive depends on your private virtual interface association.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-04T16:40:50.602268"}}
{"question": "What is the range of supported 32-bit ASNs for AWS Direct Connect?", "answer": "The supported range of 32-bit ASNs for AWS Direct Connect is from 4200000000 to 4294967294.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-04T16:40:56.960860"}}
{"question": "What steps must you take if you want to change the AWS side ASN after it has been created?", "answer": "You cannot modify the AWS side ASN after creation. To change it, you must delete the AWS Direct Connect gateway and recreate a new AWS Direct Connect gateway with the desired private ASN.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-04T16:40:56.961224"}}
{"question": "How does MACsec support differ between 1 Gbps and higher dedicated AWS Direct Connect connections?", "answer": "MACsec is supported on 10 Gbps, 100 Gbps, and 400 Gbps dedicated AWS Direct Connect connections, but it is not supported on 1 Gbps dedicated connections or any hosted connections.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-04T16:40:56.961724"}}
{"question": "How can I check if my existing AWS Direct Connect connection is MACsec-capable?", "answer": "You can check if your existing connection is MACsec-capable through the AWS Management Console or by using the DescribeConnections AWS Direct Connect API.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-04T16:41:04.256110"}}
{"question": "What are the benefits of using extended packet numbering in MACsec for high-speed connections?", "answer": "The benefits of using extended packet numbering in MACsec for high-speed connections include the increased numbering space to 64-bits, which helps to ease the timeliness requirement for key rotation, particularly for high-speed connections like 100 Gbps that can quickly exhaust the original 32-bit packet numbering space.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-04T16:41:04.256373"}}
{"question": "What encryption key requirements apply to 10 Gbps connections compared to 100 Gbps and 400 Gbps connections?", "answer": "For 10 Gbps connections, both GCM-AES-256 and GCM-AES-XPN-256 cipher suites are supported, while for 100 Gbps and 400 Gbps connections, only the GCM-AES-XPN-256 cipher suite is supported. Additionally, all connections require the use of 256-bit MACsec keys.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-04T16:41:04.256764"}}
{"question": "How many notifications are provided for scheduled maintenance, and what are their timeframes?", "answer": "For scheduled maintenance, three notifications are provided: one at 14 calendar days, a second at 7 calendar days, and a third at 1 calendar day.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:41:11.648506"}}
{"question": "What are the recommended actions to take during Direct Connect maintenance to manage potential downtime?", "answer": "To manage potential downtime during Direct Connect maintenance, it is recommended to either request a redundant Direct Connect connection or configure an AWS Site-to-Site VPN connection as a backup. Additionally, it is best practice to shift your traffic to another circuit during the maintenance period to prevent any production traffic disruption.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:41:11.648847"}}
{"question": "How does the notification process for planned maintenance differ from emergency maintenance in AWS Direct Connect?", "answer": "The notification process for planned maintenance involves providing customers with at least 14 calendar days of advance notice, followed by notifications at 7 days and 1 day. In contrast, emergency maintenance may be performed at any time, and customers may receive up to 60-minute notification(s) depending on the nature of the maintenance.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-04T16:41:11.649359"}}
{"question": "What does the maintenance scheduling algorithm do if redundant setups are detected?", "answer": "If redundant setups are detected, the maintenance scheduling algorithm will schedule maintenance at different times for each connection.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-04T16:41:16.330531"}}
{"question": "Why is it recommended for customers to consider using two different partners in different Direct Connect locations?", "answer": "It is recommended for customers to consider using two different partners in different Direct Connect locations to minimize the risk of partner maintenance windows overlapping.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-04T16:41:16.330872"}}
{"question": "How does AWS's visibility into partner maintenance activities compare to the notifications they provide to partners?", "answer": "AWS provides planned maintenance notifications to partners so they can plan accordingly; however, AWS does not have visibility into partner maintenance activities.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-04T16:41:16.331383"}}
{"question": "When will AWS discontinue support for AWS DMS Fleet Advisor?", "answer": "AWS will discontinue support for AWS DMS Fleet Advisor on 5/20/2026. After this date, users will no longer be able to access the AWS DMS Fleet Advisor console or resources.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-04T16:41:21.828808"}}
{"question": "What is the primary purpose of AWS Database Migration Service?", "answer": "The primary purpose of AWS Database Migration Service (AWS DMS) is to provide a managed migration and replication service that helps users move their databases and analytics workloads to AWS quickly and securely.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-04T16:41:21.829143"}}
{"question": "How does homogeneous migration differ from heterogeneous migration in AWS DMS?", "answer": "Homogeneous migration in AWS DMS involves migrating databases of the same type, such as Oracle to Oracle, while heterogeneous migration involves migrating between different database types, such as Oracle or Microsoft SQL Server to Amazon Aurora.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-04T16:41:21.829628"}}
{"question": "What are the costs associated with using AWS DMS for database migration?", "answer": "You only pay for the replication instances and any additional log storage when using AWS DMS. Data transfer is free. Full pricing details can be found on the DMS pricing page.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-04T16:41:27.839357"}}
{"question": "What is the role of the AWS DMS Schema Conversion tool in the database migration process?", "answer": "AWS DMS Schema Conversion is free to use as part of DMS, and you only pay for the storage used. It helps in migrating the database schema during the typical database migration process.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-04T16:41:27.839706"}}
{"question": "How does the last step of database migration differ between a typical migration and continuous data replication using AWS DMS?", "answer": "In a typical database migration, the last step involves a switchover of the production environment to the new database once the target database is caught up with the source database. In contrast, this switchover step is absent for continuous data replication, which continues to run until it is changed or terminated.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-04T16:41:27.840202"}}
{"question": "What databases and analytics services are supported by AWS DMS Serverless?", "answer": "AWS DMS Serverless supports popular databases and analytics services including Oracle, Microsoft SQL Server, PostgreSQL, MySQL, Amazon Redshift, Amazon RDS, Amazon Aurora, and more.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-04T16:41:33.414127"}}
{"question": "What is the purpose of the AWS Schema Conversion Tool (AWS SCT)?", "answer": "The AWS Schema Conversion Tool (AWS SCT) is designed to support a range of database and data warehouse conversions, allowing users to automate the conversion of database schemas and code when migrating between different database engines.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-04T16:41:33.414418"}}
{"question": "How does AWS DMS Schema Conversion differ from AWS Schema Conversion Tool?", "answer": "AWS DMS Schema Conversion (DMS SC) is part of the AWS Database Migration Service that automates the conversion of specific code types such as Oracle PL/SQL and SQL Server T-SQL to equivalent code in Amazon RDS for MySQL or PostgreSQL. In contrast, the AWS Schema Conversion Tool (AWS SCT) is a downloadable version that also facilitates schema conversion but is separate from the AWS DMS process.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-04T16:41:33.414830"}}
{"question": "What types of migrations are supported by AWS SCT?", "answer": "AWS SCT can copy database schemas for homogeneous migrations and convert them for heterogeneous migrations. The migrations can be between databases, such as Oracle to PostgreSQL, or between data warehouses, like Netezza to Amazon Redshift.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T16:41:38.707631"}}
{"question": "How does AWS DMS Serverless optimize resource usage during migrations?", "answer": "AWS DMS Serverless optimizes resources to meet demand, which means you only pay for the resources used. It automatically provisions, monitors, and scales resources, eliminating the need to overprovision or manually monitor resources for continuous data replication.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T16:41:38.707952"}}
{"question": "What is the main difference between AWS DMS and AWS SCT in terms of their support for ongoing replication?", "answer": "AWS DMS supports ongoing replication to keep the target in sync with the source, whereas AWS SCT does not provide support for ongoing replication.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T16:41:38.708446"}}
{"question": "What is recommended for homogeneous migrations using AWS DMS?", "answer": "For homogeneous migrations, it is recommended to use DMS built-in native tooling for supported engines due to its familiarity and seamless migration process. You do not need to provision or monitor the migration, and you only pay for the hours used during the migration.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T16:41:45.844880"}}
{"question": "How does AWS DMS Serverless differ from on-demand instances in terms of resource management?", "answer": "AWS DMS Serverless automatically monitors and scales resources to meet demand without manual intervention or over provisioning resources, which saves time and cost. In contrast, on-demand instances are suited for predictable, stable data transfers and can be rightsized for performance and cost.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T16:41:45.845247"}}
{"question": "What is AWS DMS Fleet Advisor and how does it assist in migration planning?", "answer": "AWS DMS Fleet Advisor is a free, fully managed capability of AWS Database Migration Service (AWS DMS) that automates migration planning. It helps users migrate database and analytics fleets to the cloud at scale with minimal effort, and it can discover on-premises databases using either a standalone AWS DMS Fleet Advisor collector or the database and analytics collection module of the AWS Application Discovery Service (ADS) Agentless Collector.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T16:41:45.845692"}}
{"question": "What is the primary purpose of AWS DMS Fleet Advisor?", "answer": "The primary purpose of AWS DMS Fleet Advisor is to assist users in migrating a large number of database and analytics servers to AWS. It helps discover and analyze Online Transaction Processing (OLTP) and Online Analytical Processing (OLAP) database workloads and allows users to build a customized migration plan by determining the complexity of migrating their source databases to target services in AWS.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T16:41:54.329711"}}
{"question": "How does the AWS Application Discovery Service (ADS) contribute to the migration process?", "answer": "The AWS Application Discovery Service (ADS) contributes to the migration process by feeding the AWS Migration Hub, which helps visualize server to server dependencies, create application groups, and track migration progress. It is particularly targeted for broad-based compute and attached block storage discovery, aiding customers in starting their migration journey.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T16:41:54.329954"}}
{"question": "How does the AWS ADS Agentless Collector differ from the AWS DMS Fleet Advisor collector in terms of environment compatibility?", "answer": "The AWS ADS Agentless Collector is recommended for use in VMware vCenter Server environments, while the AWS DMS Fleet Advisor collector can be installed on Microsoft Windows Server 2012 or higher. This indicates that the AWS ADS Agentless Collector is specific to certain virtual environments, whereas the AWS DMS Fleet Advisor collector has a broader compatibility with Windows Server versions.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T16:41:54.330347"}}
{"question": "Where can I find the support timelines for each AWS DMS version release?", "answer": "You can find the support timelines for each AWS DMS version release included in the associated DMS Release Notes, as well as in the new 'Support lifecycle policy' section in your DMS console.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T16:42:00.084061"}}
{"question": "What happens to DMS instances that reach the end of support date after 18 months?", "answer": "All instances that have reached the end of support date of 18 months after release will be automatically upgraded to the latest preferred DMS version regardless of the automatic upgrade setting.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T16:42:00.084405"}}
{"question": "How does AWS DMS handle auto upgrades compared to manual upgrades once an end-of-life date is reached?", "answer": "If you enable auto upgrade, your replication instance will be automatically updated to the latest preferred version as it becomes available. If you opt out of the auto-upgrade, AWS DMS will update your instances to the latest preferred version once the end-of-life date has been reached, which will be communicated via email and console notification prior to upgrade.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T16:42:00.084846"}}
{"question": "What happens to the migration task in AWS DMS when the tables are in the replicating ongoing changes phase while a patch is applied?", "answer": "When the tables in the migration task are in the replicating ongoing changes phase (CDC) and a patch is applied, AWS DMS pauses the task. The migration then continues from where it was left off after the patch is applied.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-04T16:42:06.502712"}}
{"question": "Why is it recommended to upgrade to the latest AWS DMS release as soon as possible?", "answer": "It is recommended to upgrade to the latest AWS DMS release as soon as possible because, after the end of life date for a DMS version has passed, AWS DMS may remove that release version from the console and upgrade your replication instance to the latest preferred version to continue providing support.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-04T16:42:06.503098"}}
{"question": "How does AWS DMS handle migration tasks differently when a patch is applied during a full load operation versus when it is applied during a CDC phase?", "answer": "When a patch is applied during a full load operation, AWS DMS restarts the migration for the table. In contrast, when the patch is applied during the CDC phase, AWS DMS pauses the task and then continues migration from where it left off after the patch is applied.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-04T16:42:06.503518"}}
{"question": "What is Amazon DocumentDB and what are its key features?", "answer": "Amazon DocumentDB is a serverless, fully managed, MongoDB API-compatible document database service. Its key features include the removal of undifferentiated heavy lifting of database management tasks like patching, backups, and monitoring, improved resilience and low latency with Global Clusters, leading security and compliance suitable for high-sensitivity organizations, low total cost of ownership with transparent pricing, and compatibility with MongoDB APIs and drivers for easy application migration.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-04T16:42:12.441023"}}
{"question": "What advantages does Amazon DocumentDB offer for I/O-intensive applications?", "answer": "Amazon DocumentDB offers I/O-Optimized instances that provide improved price performance with up to 40% cost savings specifically for I/O-intensive applications. This makes it a cost-effective choice for applications that require significant input/output operations.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-04T16:42:12.441387"}}
{"question": "How does Amazon DocumentDB's cost savings compare to other popular document databases?", "answer": "Amazon DocumentDB's memory-optimized instances offer up to 43% cost savings compared to other popular document databases, while its I/O-Optimized instances provide up to 40% cost savings for I/O-intensive applications. This indicates that Amazon DocumentDB is generally more cost-effective than competing document databases in these specific areas.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-04T16:42:12.441880"}}
{"question": "What versions of MongoDB APIs are compatible with Amazon DocumentDB?", "answer": "Amazon DocumentDB works with a vast majority of MongoDB APIs, drivers, and tools compatible with MongoDB versions 3.6, 4.0, and 5.0.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-04T16:42:18.110744"}}
{"question": "How does Amazon DocumentDB ensure compatibility with MongoDB APIs?", "answer": "Amazon DocumentDB ensures compatibility with MongoDB APIs by interacting with the Apache 2.0 open-source MongoDB APIs, allowing users to utilize the same MongoDB drivers, applications, and tools with little or no changes.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-04T16:42:18.111078"}}
{"question": "How does the migration process from MongoDB databases to Amazon DocumentDB compare with traditional migration methods?", "answer": "The migration process from MongoDB databases to Amazon DocumentDB using AWS Database Migration Service (DMS) allows for virtually no downtime, which is a significant advantage over traditional migration methods that may require more downtime. Additionally, existing tools such as mongodump/mongorestore, mongoexport/mongoimport, and third-party tools that support Change Data Capture (CDC) via the oplog can also be used.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-04T16:42:18.111287"}}
{"question": "What kind of transactions does Amazon DocumentDB support with MongoDB 4.0 compatibility?", "answer": "Amazon DocumentDB supports atomicity, consistency, isolation, durability (ACID) transactions across multiple documents, statements, collections, and databases with the launch of support for MongoDB 4.0 compatibility.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:42:25.734100"}}
{"question": "How does Amazon DocumentDB's support lifecycle differ from that of MongoDB?", "answer": "Amazon DocumentDB does not follow the same support lifecycles as MongoDB, and MongoDB's end-of-life (EOL) schedule does not apply to Amazon DocumentDB.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:42:25.734448"}}
{"question": "In what ways can Amazon DocumentDB instances be accessed compared to Amazon RDS instances?", "answer": "Amazon DocumentDB instances can be accessed directly by Amazon EC2 instances or other AWS services deployed in the same Amazon Virtual Private Cloud (VPC), and also from different VPCs in the same region or other regions via VPC peering. In contrast, while Amazon RDS instances also operate within a VPC, the specifics of their access mechanisms and any additional features may differ based on their design and intended use cases. The context does not provide detailed access information for Amazon RDS, so a direct comparison in this regard is limited.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-04T16:42:25.734963"}}
{"question": "What is the purpose of the open source DocumentDB project?", "answer": "The open source DocumentDB project aims to provide the developer community with a PostgreSQL-based, 100% MongoDB API-compatible document database.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T16:42:30.124088"}}
{"question": "How does Amazon DocumentDB Serverless manage database capacity for applications with variable workloads?", "answer": "Amazon DocumentDB Serverless automatically scales capacity up or down in fine-grained increments based on the application's demand, offering simplified resource management with no upfront commitments or additional costs, so you only pay for the database capacity used.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T16:42:30.124397"}}
{"question": "What are the differences between open source DocumentDB and Amazon DocumentDB?", "answer": "Open source DocumentDB is an extension of PostgreSQL, while Amazon DocumentDB is built by AWS. Although both are MongoDB API-compatible, they are different software. Additionally, AWS invests in both projects and contributes innovations from Amazon DocumentDB to the open source project.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T16:42:30.124939"}}
{"question": "Can I switch between Serverless and provisioned database resources at any time?", "answer": "Yes, you can switch between Serverless and choosing provisioned database resources at any time. However, it is important to ensure your workload remains sufficiently performant before making the switch.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-04T16:42:34.910950"}}
{"question": "What is a mixed-configuration cluster in Amazon DocumentDB?", "answer": "A mixed-configuration cluster in Amazon DocumentDB is a cluster that contains both provisioned instances as well as Amazon DocumentDB Serverless. You can choose to have any combination of provisioned instances and Amazon DocumentDB Serverless in your cluster.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-04T16:42:34.911298"}}
{"question": "How does the write performance of Amazon DocumentDB compare to traditional databases?", "answer": "Amazon DocumentDB writes are typically faster than traditional databases because it only persists write-ahead logs and does not need to write full buffer page syncs. This optimization does not compromise durability, allowing for improved performance.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-04T16:42:34.911724"}}
{"question": "What is the maximum storage capacity for Amazon DocumentDB Elastic Clusters?", "answer": "The maximum storage capacity for Amazon DocumentDB Elastic Clusters is 4 PiB.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T16:42:38.976408"}}
{"question": "How does Amazon DocumentDB scale its compute resources?", "answer": "Amazon DocumentDB scales its compute resources vertically by creating larger instances and horizontally by adding additional replica instances to the cluster for greater read throughput.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T16:42:38.976773"}}
{"question": "What are the differences between Amazon DocumentDB's standard storage configurations and the I/O-Optimized option?", "answer": "Amazon DocumentDB's standard storage configurations do not focus specifically on I/O costs, while the I/O-Optimized option is ideal for predictable costs or I/O intensive applications, offering enhanced price performance if I/O costs exceed 25% of total database costs.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T16:42:38.977259"}}
{"question": "What does Amazon DocumentDB I/O-Optimized not charge for?", "answer": "Amazon DocumentDB I/O-Optimized does not charge for read and write I/O operations.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-04T16:42:44.369831"}}
{"question": "How does Amazon DocumentDB Elastic Clusters simplify customer interaction with the database?", "answer": "Amazon DocumentDB Elastic Clusters simplifies customer interaction by automatically managing the underlying infrastructure, which removes the need for customers to create, remove, upgrade, or scale instances.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-04T16:42:44.370193"}}
{"question": "What is the relationship between Elastic Clusters and sharding in Amazon DocumentDB?", "answer": "Elastic Clusters uses sharding to partition data across Amazon DocumentDBs distributed storage system. Sharding splits large data sets into smaller data sets across multiple nodes, enabling customers to scale out their database beyond the vertical scaling limits of a single database.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-04T16:42:44.370649"}}
{"question": "What are the key benefits of using Elastic Clusters with Amazon DocumentDB?", "answer": "The key benefits of using Elastic Clusters with Amazon DocumentDB include the ability to scale out or scale in workloads with little to no application downtime or impact on performance, regardless of data size. Additionally, Elastic Clusters offers differentiated management capabilities such as no impact backups and rapid point in time restore, allowing customers to focus more on their applications rather than managing their database.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-04T16:42:51.944846"}}
{"question": "How does choosing a shard key for Elastic Clusters compare to choosing a shard key for other databases?", "answer": "Choosing an optimal shard key for Elastic Clusters is no different than for other databases. A great shard key should have high frequency and high cardinality. For example, if an application stores user orders, the user_id would be a good shard key since it allows for all orders related to a given user to be stored in one shard.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-04T16:42:51.945188"}}
{"question": "What tools can be used to migrate data from MongoDB to Elastic Clusters?", "answer": "You can use the AWS Database Migration Service (AWS DMS) to migrate data from MongoDB to Elastic Clusters. Additionally, native MongoDB tools such as mongodump and mongorestore can also be used for migration. Elastic Clusters supports commonly used MongoDB APIs, providing flexibility to reuse existing tooling and scripts.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-04T16:42:51.945399"}}
{"question": "What is the maximum duration for which you can increase the backup window for point-in-time restores in Amazon DocumentDB?", "answer": "You can increase your backup window for point-in-time restores up to 35 days in Amazon DocumentDB.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-04T16:42:57.477388"}}
{"question": "How does Amazon DocumentDB ensure the durability of data within a Region?", "answer": "Amazon DocumentDB automatically makes your data durable across three Availability Zones (AZs) within a Region and will automatically attempt to recover your instance in a healthy AZ with no data loss.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-04T16:42:57.477727"}}
{"question": "What happens to automated backups when an instance is deleted in Amazon DocumentDB compared to manually created snapshots?", "answer": "Only manually created snapshots are retained after the instance is deleted in Amazon DocumentDB. Automated backups created for point-in-time restore are not kept after deletion.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-04T16:42:57.478206"}}
{"question": "What feature does Amazon DocumentDB provide to help restore a cluster?", "answer": "Amazon DocumentDB allows you to create snapshots of your cluster, which can be used later to restore the cluster.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-04T16:43:02.842624"}}
{"question": "What are the benefits of sharing Amazon DocumentDB snapshots between different AWS accounts?", "answer": "Sharing Amazon DocumentDB snapshots allows you to share data between various environments such as production, dev/test, and staging that have different AWS accounts. It also enables you to keep backups of all your data secure in a separate account in case your main AWS account is ever compromised.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-04T16:43:02.842967"}}
{"question": "How do the accessibility and sharing capabilities of Amazon DocumentDB snapshots differ for user-created snapshots and automatic snapshots?", "answer": "User-created snapshots can be shared with other AWS accounts, but automatic cluster snapshots cannot be shared directly. To share an automatic snapshot, you must first manually create a copy of it and then share the copy.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-04T16:43:02.843486"}}
{"question": "What is the maximum number of read replicas that Amazon DocumentDB supports?", "answer": "Amazon DocumentDB supports up to 15 read replicas.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T16:43:07.078426"}}
{"question": "How does Amazon DocumentDB's database restart time compare to other databases after a crash?", "answer": "Unlike other databases, which typically need to replay the redo log from the last database checkpoint before making the database available for operations, Amazon DocumentDB reduces database restart times to less than 60 seconds in most cases, as it does not require this step.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T16:43:07.078765"}}
{"question": "What benefits do Global Clusters provide in Amazon DocumentDB?", "answer": "Global Clusters in Amazon DocumentDB replicate data across multiple AWS Regions, allowing for faster recovery from Region-wide outages and enabling low-latency global reads, all with little to no impact on performance.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T16:43:07.079295"}}
{"question": "What happens during a primary instance failure in Amazon DocumentDB?", "answer": "In the event of a primary instance failure, a replica instance is automatically promoted to be the new primary with minimal service interruption. Amazon DocumentDB handles the failover automatically, allowing applications to resume database operations quickly without manual intervention.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T16:43:13.150313"}}
{"question": "How do Amazon DocumentDB replicas enhance fault tolerance?", "answer": "Amazon DocumentDB replicas enhance fault tolerance by sharing the same underlying storage as the primary instance. Any replica can be promoted to become primary without data loss, and by creating one to 15 replicas in multiple Availability Zones, they can be included in failover primary selection in case of an instance outage.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T16:43:13.150652"}}
{"question": "What is the difference in failover handling between having replicas and not having replicas in Amazon DocumentDB?", "answer": "If you have an Amazon DocumentDB replica instance, the failover is handled automatically by promoting a healthy replica to become the primary, which typically completes within 30 seconds. However, if you do not have a replica instance (i.e., a single instance cluster), Amazon DocumentDB will attempt to create a new instance in the same Availability Zone as the original instance on a best-effort basis, which may not succeed.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T16:43:13.150869"}}
{"question": "What must all Amazon DocumentDB instances be created in?", "answer": "All Amazon DocumentDB instances must be created in an Amazon VPC.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:43:18.023863"}}
{"question": "How does Amazon DocumentDB support role-based access control (RBAC)?", "answer": "Amazon DocumentDB supports RBAC with built-in roles, which enables users to enforce least privilege as a best practice by restricting the actions that users are authorized to perform.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:43:18.024231"}}
{"question": "What are the differences between encrypting an existing unencrypted Amazon DocumentDB instance and creating a new cluster with encryption enabled?", "answer": "Currently, encrypting an existing unencrypted Amazon DocumentDB instance is not supported. To use Amazon DocumentDB encryption for an existing unencrypted cluster, you must create a new cluster with encryption enabled and migrate your data into it.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-04T16:43:18.024727"}}
{"question": "What versions of Amazon DocumentDB can be upgraded using in-place major version upgrade?", "answer": "In-place major version upgrade (MVU) allows you to upgrade Amazon DocumentDB clusters from version 3.6 or 4.0 to version 5.0.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-04T16:43:24.912306"}}
{"question": "Why is in-place major version upgrade beneficial compared to traditional upgrade methods?", "answer": "In-place major version upgrade is beneficial because it allows seamless upgrades without the need for backup and restore to another cluster or using other data migration tools. This reduces the time and effort typically required for upgrades, which often involve configuring source and target endpoints, migrating indexes and data, and changing application code.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-04T16:43:24.912590"}}
{"question": "What are the limitations of in-place major version upgrade regarding Amazon DocumentDB clusters?", "answer": "In-place major version upgrade is only supported with Amazon DocumentDB versions 3.6 or 4.0 as the source and version 5.0 as the target. It is not supported for Amazon DocumentDB Global Clusters, Elastic Clusters, or when DocumentDB 4.0 is the target.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-04T16:43:24.913195"}}
{"question": "What is vector search used for in machine learning?", "answer": "Vector search is used in machine learning to find similar data points to a given data point by comparing their vector representations using distance or similarity metrics. The closer the two vectors are in the vector space, the more similar the underlying items are considered to be. This technique helps capture the meaning or semantics of the data and is useful in applications such as recommendation systems, natural language processing, and image recognition.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-04T16:43:32.194240"}}
{"question": "How does vector search enhance the capabilities of Amazon DocumentDB?", "answer": "Vector search enhances Amazon DocumentDB by combining the flexibility and rich querying capability of a JSON-based document database with the power of vector search. It allows users to utilize existing Amazon DocumentDB data or a flexible document data structure to build machine learning and generative AI use cases, such as semantic search experiences, product recommendations, personalization, chatbots, fraud detection, and anomaly detection.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-04T16:43:32.194516"}}
{"question": "How does semantic search differ from traditional keyword search in Amazon DocumentDB?", "answer": "Semantic search differs from traditional keyword search in that it captures the meaning, context, and intent behind the data. While keyword search finds documents based on the actual text or pre-defined synonym mappings, semantic search can retrieve results that are contextually related, even if they do not contain the exact keywords. For example, in a traditional e-commerce application, keyword search for a 'red dress' would return products with those exact terms, whereas semantic search could return dresses in different shades of red, thereby improving the user experience.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-04T16:43:32.194664"}}
{"question": "What does the integration of Amazon DocumentDB with Amazon SageMaker Canvas allow users to do?", "answer": "The integration of Amazon DocumentDB with Amazon SageMaker Canvas allows users to build machine learning models and customize foundation models using data stored in Amazon DocumentDB without writing any code. Users can launch SageMaker Canvas from the Amazon DocumentDB console and add existing Amazon DocumentDB databases as data sources.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T16:43:38.248422"}}
{"question": "How does the integration of Amazon DocumentDB with Amazon SageMaker Canvas simplify the machine learning development process?", "answer": "The integration simplifies the machine learning development process by removing the need to develop custom data and ML pipelines between Amazon DocumentDB and SageMaker Canvas. It provides an in-console integration that eliminates the undifferentiated heavy lifting associated with connecting and accessing data, offering a low code no code (LCNC) experience.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T16:43:38.248761"}}
{"question": "What is the difference between using Amazon DocumentDB as a data source in SageMaker Canvas and the zero-ETL integration with Amazon OpenSearch Service?", "answer": "Using Amazon DocumentDB as a data source in SageMaker Canvas allows users to build machine learning models without additional charges for the data source integration. In contrast, the zero-ETL integration with Amazon OpenSearch Service abstracts the operational complexity involved in extracting, transforming, and loading data, eliminating the need to build or manage data pipelines or transform data.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T16:43:38.248964"}}
{"question": "What is the purpose of the zero-ETL integration between Amazon DocumentDB and Amazon OpenSearch Service?", "answer": "The purpose of the zero-ETL integration between Amazon DocumentDB and Amazon OpenSearch Service is to seamlessly move operational data from Amazon DocumentDB to Amazon OpenSearch Service, allowing for efficient searching across collections and the storage and indexing of vectors with more than 2,000 dimensions.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T16:43:43.292027"}}
{"question": "How does Amazon OpenSearch Ingestion enhance the data replication process from Amazon DocumentDB to Amazon OpenSearch Service?", "answer": "Amazon OpenSearch Ingestion enhances the data replication process by automatically understanding the format of the data in Amazon DocumentDB collections and mapping it to Amazon OpenSearch Service, which yields the most performant search results. It also allows for synchronization of data from multiple collections via multiple pipelines into a single managed cluster or serverless collection.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T16:43:43.292367"}}
{"question": "What are the differences between using custom transformation logic and the out-of-the-box blueprints provided by Amazon OpenSearch Ingestion?", "answer": "The difference between using custom transformation logic and the out-of-the-box blueprints provided by Amazon OpenSearch Ingestion is that custom transformation logic allows for bespoke transformational capabilities tailored to specific needs, while the out-of-the-box blueprints enable users to perform integrations quickly and easily with just a few button clicks, without customization.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T16:43:43.292765"}}
{"question": "Where can I view metrics related to my zero-ETL integration with Amazon DocumentDB?", "answer": "You can view all the metrics related to your zero-ETL integration with Amazon DocumentDB on the console dashboards provided by Amazon DocumentDB and the OpenSearch Ingestion pipeline.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-04T16:43:48.286978"}}
{"question": "What functionality does Amazon CloudWatch provide in relation to monitoring zero-ETL integration with Amazon DocumentDB?", "answer": "Amazon CloudWatch allows you to query real-time logs and set up custom alerting that triggers when user-defined thresholds are breached, helping you monitor your zero-ETL integration effectively.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-04T16:43:48.287321"}}
{"question": "How does the monitoring capability of Amazon DocumentDB compare to that of Amazon CloudWatch for zero-ETL integration?", "answer": "Amazon DocumentDB provides console dashboards for viewing metrics related to zero-ETL integration, whereas Amazon CloudWatch offers real-time log querying and custom alerting based on user-defined thresholds. While both tools enable monitoring, they serve different purposes: DocumentDB focuses on metrics visualization, while CloudWatch emphasizes log management and alerting.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-04T16:43:48.287831"}}
{"question": "What type of database service is Amazon DynamoDB?", "answer": "Amazon DynamoDB is a serverless, fully managed, distributed NoSQL database service.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:43:52.512770"}}
{"question": "What are some of the key features that contribute to DynamoDB's high availability and resilience?", "answer": "Key features that contribute to DynamoDB's high availability and resilience include zero infrastructure management, zero downtime maintenance, instant scaling to any application demand, pay-per-request billing, and synchronous data replication across three Availability Zones in an AWS Region.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:43:52.513110"}}
{"question": "How does DynamoDB ensure data availability and consistency across different regions?", "answer": "DynamoDB ensures data availability and consistency across different regions by using global tables, which is a multi-Region, multi-active database that supports multi-Region strong consistency. This means applications always stay available and read the same data from any Region.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-04T16:43:52.513607"}}
{"question": "What are the two table classes available in DynamoDB?", "answer": "The two table classes available in DynamoDB are DynamoDB Standard, which is the default table class designed for workloads that require maximum performance, and DynamoDB Standard-Infrequent Access, which is optimized for tables where storage is the dominant cost and ideal for infrequently accessed data.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T16:43:58.691640"}}
{"question": "What are the factors to consider when choosing a table class in DynamoDB?", "answer": "The factors to consider when choosing a table class in DynamoDB include your datas access patterns, cost considerations, and workload predictability.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T16:43:58.691987"}}
{"question": "How does the cost structure differ between DynamoDB Standard tables and DynamoDB Standard-Infrequent Access tables?", "answer": "DynamoDB Standard tables have lower costs for reads and writes but higher storage costs, while DynamoDB Standard-Infrequent Access tables have lower storage costs but higher costs for reads and writes.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T16:43:58.692487"}}
{"question": "What is the maximum size of an item that can be stored in a DynamoDB table?", "answer": "The maximum size of an item that can be stored in a DynamoDB table is 400 KB.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-04T16:44:03.011801"}}
{"question": "Why is it recommended to store pointers to Amazon S3 objects in a DynamoDB table instead of storing images directly in DynamoDB?", "answer": "It is recommended to store pointers to Amazon S3 objects in a DynamoDB table instead of storing images directly in DynamoDB because of the 400 KB item size limit and the limitations and drawbacks associated with storing images as binary data in DynamoDB.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-04T16:44:03.012145"}}
{"question": "How does the storage capability of DynamoDB for items compare to predefined storage limits?", "answer": "DynamoDB does not have predefined storage limits for the number of items that can be stored in a table. It can scale to hundreds of terabytes or more of data across any number of items, indicating that it is designed to handle large amounts of data without strict limitations.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-04T16:44:03.012355"}}
{"question": "What data types does DynamoDB support for storing lists?", "answer": "DynamoDB supports either a List or a Set as data types for storing lists. When writing items to the table, the value for that attribute can be an array or collection of scalar data types like strings and numbers.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-04T16:44:08.307996"}}
{"question": "How does AWS PrivateLink enhance security when accessing DynamoDB tables?", "answer": "AWS PrivateLink enhances security by allowing DynamoDB tables to be accessed from a private connection. This means that requests do not leave the Amazon network, which reduces exposure to the public internet. Additionally, access can be controlled using IAM policies and security groups.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-04T16:44:08.308359"}}
{"question": "What is the difference between IAM permissions and the use of AWS PrivateLink in terms of accessing DynamoDB?", "answer": "IAM permissions are used to control access to DynamoDB resources through identity-based and resource-based policies, allowing you to attach these policies to users, groups, roles, and tables. In contrast, AWS PrivateLink provides a private network connectivity solution, allowing access to DynamoDB tables over a private connection without traffic leaving the Amazon network, which enhances security. While IAM permissions focus on access control, PrivateLink focuses on secure network connectivity.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-04T16:44:08.308785"}}
{"question": "What types of access permissions can customers define with resource-based policies in DynamoDB?", "answer": "Customers can define fine-grained access permissions for actions like read, write, or delete on specific DynamoDB tables, indexes, and streams using resource-based policies.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T16:44:13.913791"}}
{"question": "How does fine-grained access control (FGAC) enhance the security of DynamoDB tables?", "answer": "Fine-grained access control (FGAC) enhances the security of DynamoDB tables by allowing the table owner to provide granular permissions for access to specific items or attributes of the table, using AWS Identity and Access Management (IAM) policies and conditions.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T16:44:13.914155"}}
{"question": "What is the difference between gateway endpoints and AWS PrivateLink for accessing DynamoDB from a VPC?", "answer": "The difference between gateway endpoints and AWS PrivateLink for accessing DynamoDB is that gateway endpoints allow access from a VPC without requiring an internet gateway or NAT device but do not support access from on-premises networks or peered VPCs in other AWS Regions. In contrast, AWS PrivateLink allows access from these scenarios but incurs an additional cost.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T16:44:13.914670"}}
{"question": "What encryption standard does DynamoDB use for data at rest?", "answer": "DynamoDB encryption at rest uses AES-256, which is the gold standard where the highest levels of security are required.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-04T16:44:17.864706"}}
{"question": "What are the benefits of using customer managed keys for data encryption in AWS?", "answer": "Customer managed keys offer the highest level of control over the encryption keys, including the ability to create, rotate, disable, and define access controls. This allows for greater customization and management of the keys compared to other key types.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-04T16:44:17.865047"}}
{"question": "How do AWS owned keys compare to customer managed keys in terms of control and management?", "answer": "AWS owned keys are managed entirely by AWS and are the simplest to use, requiring no additional setup. In contrast, customer managed keys are created, owned, and managed by the customer, providing the highest level of control but requiring more management overhead.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-04T16:44:17.865557"}}
{"question": "What types of item level changes does DynamoDB's audit logging capture?", "answer": "DynamoDB's audit logging captures creates, updates, deletes, and any conditional check failures at the item level.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-04T16:44:22.682024"}}
{"question": "How does integrating DynamoDB with AWS CloudTrail benefit users?", "answer": "Integrating DynamoDB with AWS CloudTrail benefits users by providing a record of actions taken by a user, role, or an AWS service at the item level, which allows for detailed auditing and monitoring of item level changes.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-04T16:44:22.682365"}}
{"question": "How do global tables in Amazon DynamoDB compare to single Region DynamoDB tables in terms of availability and performance?", "answer": "Global tables in Amazon DynamoDB provide 99.999% availability and improved application resiliency by automatically replicating tables across multiple AWS Regions, allowing for fast local read and write performance, while single Region DynamoDB tables do not offer this multi-Region capability.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-04T16:44:22.682896"}}
{"question": "What are the two versions of DynamoDB global tables mentioned in the context?", "answer": "The two versions of DynamoDB global tables mentioned are version 2019.11.21 (Current) and version 2017.11.29 (Legacy).", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-04T16:44:28.927921"}}
{"question": "Why should customers use version 2019.11.21 (Current) for new global tables?", "answer": "Customers should use version 2019.11.21 (Current) for new global tables because it is more efficient and consumes less write capacity compared to version 2017.11.29 (Legacy).", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-04T16:44:28.928256"}}
{"question": "How does the replication behavior differ between the replica tables in a global table and traditional single-region tables?", "answer": "In a global table, all replica tables in all Regions support both read and write traffic, and there is no primary Region, which means no database failover is required when directing traffic to a different Region. In contrast, traditional single-region tables typically have a primary table that must be managed for failover in case of Region issues.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-04T16:44:28.928782"}}
{"question": "What are the requirements for adding an additional replica in a different region to a DynamoDB global table?", "answer": "Prior to adding an additional replica in a different region to a DynamoDB global table, the table must have DynamoDB Streams enabled, have the same name as all other replicas, have the same partition key as all other replicas, and have the same write capacity settings specified.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-04T16:44:33.618602"}}
{"question": "How does DynamoDB global tables enhance business continuity and application resiliency?", "answer": "DynamoDB global tables enhance business continuity by increasing an applications resiliency and providing strong consistency for a single Region. With multi-Region strong consistency, businesses can build applications with zero RPO and the highest levels of resiliency.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-04T16:44:33.619208"}}
{"question": "What is the difference between DynamoDB Streams and Kinesis Data Streams for DynamoDB in the context of change data capture?", "answer": "DynamoDB Streams and Kinesis Data Streams for DynamoDB are both streaming models that support change data capture (CDC). However, the context does not provide a detailed comparison between the two, so the specific differences in functionality, use cases, or performance are not mentioned.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-04T16:44:33.619389"}}
{"question": "What is a DynamoDB stream?", "answer": "A DynamoDB stream is an ordered flow of information about changes to items in a DynamoDB table. It captures a de-duplicated, time-ordered sequence of item-level modifications in a table and stores this information in a log for up to 24 hours.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-04T16:44:37.763310"}}
{"question": "How does DynamoDB Streams scale capacity?", "answer": "DynamoDB Streams scales capacity automatically, which means users do not need to provision and manage capacity manually.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-04T16:44:37.763553"}}
{"question": "What are the key differences between DynamoDB Streams and Kinesis Data Streams for DynamoDB?", "answer": "DynamoDB Streams provides record ordering and deduplication guarantees, while Kinesis Data Streams for DynamoDB does not guarantee these features and requires client applications to implement record ordering and deduplication. Additionally, Kinesis Data Streams has longer data retention of up to 365 days and allows for customized shard management.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-04T16:44:37.763935"}}
{"question": "What information does a data record from a DynamoDB stream include when changes are made to a table's data?", "answer": "A data record from a DynamoDB stream includes the specific time any item was recently created, updated, or deleted, that items primary key, an image of the item before the modification, and an image of the item after the modification.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-04T16:44:43.199159"}}
{"question": "In what scenarios should I choose DynamoDB Streams over Kinesis Data Streams?", "answer": "You should choose DynamoDB Streams when you specifically need to track DynamoDB table changes. In contrast, Kinesis Data Streams is better suited for broader streaming needs, higher throughput requirements, or when you need longer data retention periods.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-04T16:44:43.199339"}}
{"question": "How does the Amazon DynamoDB Time to Live (TTL) feature differ from the functionality provided by DynamoDB Streams?", "answer": "The Amazon DynamoDB Time to Live (TTL) feature automatically deletes expired items that are no longer relevant from a table, thereby reducing storage usage and lowering costs. In contrast, DynamoDB Streams captures changes made to the data in a table by sending out data records that include details about item creation, updates, or deletions. While TTL focuses on managing the lifecycle of items based on their relevance over time, DynamoDB Streams focuses on tracking real-time changes to the data.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-04T16:44:43.199440"}}
{"question": "What is the primary key in DynamoDB and why is it important?", "answer": "The primary key in DynamoDB is the only required attribute for items in a table, and it uniquely identifies each item. You specify the primary key when you create a table, making it essential for performing GET/PUT operations.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T16:44:49.402512"}}
{"question": "How does a composite partition-sort key differ from a single-attribute partition key in DynamoDB?", "answer": "A composite partition-sort key in DynamoDB consists of a partition key element and a sort key element, allowing for a hierarchy between the two values. In contrast, a single-attribute partition key consists of only one attribute, such as UserID, which allows for quick data reads and writes associated with that user ID.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T16:44:49.403319"}}
{"question": "What types of APIs can be used to insert and retrieve items in a DynamoDB table?", "answer": "To insert items into a DynamoDB table, you can use the PutItem or BatchWriteItem APIs. For retrieving items, you can use the GetItem or BatchGetItem APIs, and if composite primary keys are enabled, you can also use the Query API.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T16:44:49.403475"}}
{"question": "What does the zero-ETL integration with OpenSearch Service enable for DynamoDB customers?", "answer": "The zero-ETL integration with OpenSearch Service enables DynamoDB customers to obtain near real-time search results from their transactional data by offering a fully managed solution for making transactional data from DynamoDB available in OpenSearch Service within seconds of being written.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T16:44:56.363571"}}
{"question": "How does the zero-ETL integration simplify the process of data replication between DynamoDB and OpenSearch Service?", "answer": "The zero-ETL integration simplifies the process of data replication by abstracting away the operational complexity involved in orchestrating the replication of data from a transactional datastore to a search datastore. It allows customers to choose the DynamoDB tables they wish to analyze, then seamlessly replicates the schema and data into OpenSearch Service using OpenSearch Ingestion pipelines, eliminating the challenges and costs associated with building and managing data pipelines.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T16:44:56.363866"}}
{"question": "What are the two methods customers can choose for data replication in the zero-ETL integration, and how do they differ?", "answer": "Customers can choose either DynamoDB Streams for near real-time replication or DynamoDB Incremental Exports for delayed replication as the CDC mechanism to keep the data between DynamoDB and OpenSearch Service in sync. The key difference is that DynamoDB Streams provides immediate updates, allowing for near real-time data availability, while Incremental Exports involves a delay in replication, making it suitable for scenarios where real-time updates are not critical.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T16:44:56.363967"}}
{"question": "What does the zero-ETL integration provide for monitoring the state of the integration?", "answer": "The zero-ETL integration provides a dashboard where users can monitor the state of their end-to-end integration with real-time metrics and logs in Amazon CloudWatch. Additionally, users can set up alerting in case of breach of user-defined thresholds.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:45:02.220815"}}
{"question": "How does the zero-ETL integration ensure data security when moving data between DynamoDB and OpenSearch Service?", "answer": "The zero-ETL integration ensures data security by creating an IAM role with the necessary permissions to read data from DynamoDB tables and write to an OpenSearch domain or collection. This role is then assumed by OpenSearch Ingestion pipelines to maintain the right security posture during data movement.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:45:02.221422"}}
{"question": "What is the difference between using custom logic and the out-of-the-box OpenSearch Ingestion blueprints in the zero-ETL integration?", "answer": "Using custom logic in the zero-ETL integration allows customers to achieve bespoke transformational capabilities for data processing, such as dropping fields or creating new ones based on aggregations. In contrast, the out-of-the-box OpenSearch Ingestion blueprints provide a simpler solution for users who want to move their entire data from source to sink with just a few button clicks, without requiring custom transformations.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-04T16:45:02.221545"}}
{"question": "What additional costs are associated with using DynamoDB zero-ETL integration with OpenSearch Service?", "answer": "There is no additional cost to use DynamoDB zero-ETL integration with OpenSearch Service apart from the cost of the existing underlying components. The cost involved is primarily for OpenSearch Compute Units (OCUs) needed for OpenSearch Ingestion to replicate the data across the systems.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-04T16:45:09.294395"}}
{"question": "What are the two options customers have for Change Data Capture (CDC) when using DynamoDB zero-ETL integration with OpenSearch Service?", "answer": "Customers have the option to choose either DynamoDB streams or incremental exports as the choice of Change Data Capture (CDC) when using DynamoDB zero-ETL integration with OpenSearch Service.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-04T16:45:09.294779"}}
{"question": "How does the cost structure differ between using DynamoDB streams and incremental exports for CDC in DynamoDB zero-ETL integration?", "answer": "For incremental exports, there is a cost associated with writing data to S3 buckets. In contrast, for DynamoDB streams, customers would be charged the standard charges for using DynamoDB streams. Therefore, the cost structure differs in that incremental exports incur S3 writing costs, while DynamoDB streams incur standard charges.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-04T16:45:09.295215"}}
{"question": "What is the main difference between data stored on a local instance store and data stored on an Amazon EBS volume?", "answer": "The main difference is that data stored on a local instance store persists only as long as that instance is alive, while data stored on an Amazon EBS volume can persist independently of the life of the instance.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-04T16:45:17.388868"}}
{"question": "Why is it recommended to use Amazon EBS volumes or back up data to Amazon S3 for data requiring a higher level of durability?", "answer": "It is recommended to use Amazon EBS volumes or back up data to Amazon S3 for data requiring a higher level of durability because EBS volumes can persist independently of the instance, ensuring that the data remains accessible even after the instance is terminated.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-04T16:45:17.389211"}}
{"question": "How do the performance characteristics of Amazon EBS volume types compare to each other?", "answer": "Amazon EBS provides six volume types: Provisioned IOPS SSD (io2 Block Express and io1), General Purpose SSD (gp3 and gp2), Throughput Optimized HDD (st1), and Cold HDD (sc1). These volume types differ in performance characteristics and price, allowing users to tailor their storage performance and cost to the needs of their applications. For instance, the average latency between EC2 instances and EBS is single-digit milliseconds, while the average latency of io2 Block Express volumes is sub-millisecond.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-04T16:45:17.389730"}}
{"question": "What are the two major categories of storage included in Amazon EBS?", "answer": "Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads and HDD-backed storage for throughput workloads.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-04T16:45:20.739458"}}
{"question": "How does the performance of SSD-backed storage differ from that of HDD-backed storage?", "answer": "The performance of SSD-backed storage depends primarily on IOPS, latency, and durability, while the performance of HDD-backed storage depends primarily on throughput, measured in MB/s.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-04T16:45:20.739825"}}
{"question": "What is the difference in durability between io2 Block Express and General Purpose SSD volumes?", "answer": "io2 Block Express offers 100X greater durability at 99.999% compared to General Purpose SSD volumes, which do not provide the same level of durability.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-04T16:45:20.740333"}}
{"question": "What features make Amazon EBS volumes highly available and reliable?", "answer": "Amazon EBS volumes are designed to be highly available, reliable, and durable by replicating volume data across multiple servers in an Availability Zone. This replication helps prevent the loss of data from the failure of any single component.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-04T16:45:25.962056"}}
{"question": "What are some recommended guidelines to achieve high availability for applications using Amazon EBS?", "answer": "To achieve a robust degree of high availability for applications using Amazon EBS, it is recommended to design the system to have no single point of failure, use automated monitoring and failure detection mechanisms, and prepare operating procedures for manual response to failures, including detaching unavailable volumes and attaching backup recovery volumes.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-04T16:45:25.962402"}}
{"question": "How do EBS Magnetic volumes differ from the previously named EBS Standard volumes?", "answer": "EBS Magnetic volumes are the renamed version of EBS Standard volumes. There are no functional differences between the two offerings, and existing volumes will not have been changed as a result of this renaming. The change was made to avoid confusion with the General Purpose SSD (gp2) volume type, which is the recommended default volume type.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-04T16:45:25.962913"}}
{"question": "What is the maximum throughput achievable with io2 Block Express volumes when attached to Nitro System-based instances?", "answer": "The maximum throughput achievable with io2 Block Express volumes when attached to Nitro System-based instances is 4,000 MB/s.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-04T16:45:30.702119"}}
{"question": "How do io2 Block Express volumes compare to General Purpose volumes in terms of outlier latency experience?", "answer": "io2 Block Express volumes deliver a better outlier latency experience compared to General Purpose volumes by reducing the frequency of I/O operations that exceed 800 microseconds by more than 10 times.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-04T16:45:30.702461"}}
{"question": "What is the benefit of using EBS-optimized EC2 instances with io2 Block Express volumes?", "answer": "The benefit of using EBS-optimized EC2 instances with io2 Block Express volumes is that they provide dedicated throughput between Amazon EC2 and Amazon EBS, ensuring consistent and predictable IOPS performance, designed to deliver within 10% of the provisioned IOPS performance 99.9% of the time in a given year.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-04T16:45:30.702970"}}
{"question": "What is the base I/O size for provisioned IOPS volumes?", "answer": "The base I/O size for provisioned IOPS volumes is 16KB.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:45:35.571466"}}
{"question": "How does increasing the I/O size affect the achievable IOPS for io2 Block Express volumes?", "answer": "If the I/O size is increased to 256 KB, the achievable IOPS will decrease to up to 16,000 IOPS, since the maximum throughput of 4000 MiB/s is achieved at 16,000 IOPS.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:45:35.571804"}}
{"question": "How do io2 Block Express volumes compare to General Purpose volumes in terms of outlier latency when attached to Nitro System-based EC2 instances?", "answer": "io2 Block Express volumes deliver a better outlier latency experience compared to General Purpose volumes by reducing the frequency of I/Os that exceed 800 microseconds by more than 10 times.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:45:35.572288"}}
{"question": "What is the expected throughput performance of Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes when attached to EBS-optimized instances?", "answer": "Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes are designed to deliver within 10% of the expected throughput performance 99% of the time in a given year when attached to EBS-optimized instances.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-04T16:45:41.711064"}}
{"question": "How does the I/O size of an application affect the performance of HDD-backed volumes?", "answer": "The throughput rate for HDD-backed volumes depends on the I/O size of the application's reads and writes. These volumes process reads and writes in I/O sizes of 1MB. Sequential I/Os are merged and processed as 1MB units, while non-sequential I/Os are processed as 1MB even if the actual I/O size is smaller. Therefore, workloads with small, random I/Os, like a database, will not perform well on HDD-backed volumes, whereas sequential I/Os and large I/O sizes will achieve the advertised performance for a longer time.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-04T16:45:41.711408"}}
{"question": "How do the performance characteristics of st1 and sc1 volumes compare for different I/O patterns?", "answer": "st1 and sc1 volumes are optimized for sequential I/Os and large I/O sizes, which allows them to achieve the advertised performance for a longer period of time. In contrast, they do not perform well with transactional workloads that involve small, random I/Os, such as those typical of databases.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-04T16:45:41.711916"}}
{"question": "What are the expected throughput performance levels for Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes attached to EBS-optimized instances?", "answer": "Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes attached to EBS-optimized instances are designed to offer consistent performance, delivering within 10% of the expected throughput performance 99% of the time in a given year.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:45:49.932343"}}
{"question": "How does the balance between random and sequential I/O operations affect the performance of EBS volumes?", "answer": "The relative balance between random and sequential I/O operations on the volume can impact performance. Too many random small I/O operations can quickly deplete your I/O credits, lowering your performance down to the baseline rate.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:45:49.932719"}}
{"question": "How does the performance of st1 and sc1 volumes compare when striped together versus using io2 Block Express volumes?", "answer": "Performance for st1 and sc1 scales linearly with volume size, so there may not be as much of a benefit to stripe these volumes together. In contrast, io2 Block Express volumes are recommended for higher performance requirements without the need for operational management of striping multiple volumes.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-04T16:45:49.933226"}}
{"question": "What are the performance characteristics defined for the volume types in EBS?", "answer": "The volume types in EBS, which include gp2, PIOPS, st1, and sc1, all have defined performance characteristics in terms of IOPS and throughput.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:45:57.086737"}}
{"question": "How does EBS ensure that resource contention is avoided?", "answer": "EBS employs rate limiting as a mechanism to avoid resource contention, which starts with having defined performance criteria for the volumes and defining performance at the instance level. By appropriately allocating infrastructure based on the configured performance, EBS can avoid resource contention.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:45:57.087089"}}
{"question": "How does the performance of General Purpose SSD (gp3) volumes compare to General Purpose SSD (gp2) volumes when attached to EBS-optimized instances?", "answer": "Both General Purpose SSD (gp3 and gp2) volumes are designed to deliver within 10% of the provisioned IOPS performance 99% of the time in a given year and can achieve single digit millisecond latencies. However, gp3 volumes include 3,000 IOPS and 125 MB/s of consistent performance at no additional cost, while gp2 volumes may have different provisions based on their configuration.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-04T16:45:57.087493"}}
{"question": "What is the maximum burst IOPS performance for General Purpose SSD (gp2) volumes under 1,000 GB?", "answer": "General Purpose SSD (gp2) volumes that are under 1,000 GB can burst to a maximum performance of 3,000 IOPS for at least 30 minutes of sustained performance.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:46:05.433475"}}
{"question": "How does EBS Block Express achieve low latency and high performance for block storage?", "answer": "EBS Block Express achieves low latency and high performance by using Scalable Reliable Datagrams (SRD), a high-performance lower-latency network protocol, to communicate with Nitro System-based EC2 instances. This architecture is designed for cloud scale and leverages the same high performance and low latency network interface used for inter-instance communication in Elastic Fabric Adapter (EFA) for High Performance Computing (HPC) and Machine Learning (ML) workloads.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:46:05.433647"}}
{"question": "How do io2 Block Express volumes differ from General Purpose SSD (gp2) volumes in terms of workload suitability?", "answer": "io2 Block Express volumes are suited for performance and capacity intensive workloads that require lower latency, better latency consistency, higher IOPS, higher throughput, or larger capacity in a single volume. In contrast, General Purpose SSD (gp2) volumes are primarily designed for general usage and provide consistent performance of 3 IOPS per provisioned GB without the same level of performance and capacity enhancement tailored for specific workloads like relational and NoSQL databases.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-04T16:46:05.433759"}}
{"question": "What should you use for Volume Initialization if you need your volumes to be fully performant within a predictable amount of time?", "answer": "You should use Provisioned Rate for Volume Initialization if you need your volumes to be fully performant within a predictable amount of time.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-04T16:46:11.476540"}}
{"question": "Why would someone choose to use Provisioned Rate for Volume Initialization?", "answer": "Someone would choose to use Provisioned Rate for Volume Initialization if they have workloads that need the underlying EBS volumes to be fully initialized as quickly as possible, or if they want to launch hundreds of EC2 instances or EBS volumes and need them all to be initialized as quickly as possible.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-04T16:46:11.477302"}}
{"question": "How do Amazon EBS gp3 volumes compare to io2 Block Express volumes in terms of application suitability?", "answer": "Amazon EBS gp3 volumes are ideal for applications that require a balance between cost and performance, such as medium-sized, single-instance databases, data analytics solutions, and web servers. In contrast, io2 Block Express volumes are recommended for applications that need higher durability, better latency consistency, or higher IOPS and throughput than what gp3 can provide.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-04T16:46:11.477618"}}
{"question": "What does the ListSnapshotBlocks API operation return?", "answer": "The ListSnapshotBlocks API operation returns the block indexes and block tokens for blocks in the specified snapshot.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-04T16:46:15.083900"}}
{"question": "How does the StartSnapshot operation function regarding snapshots?", "answer": "The StartSnapshot operation starts a snapshot, either as an incremental snapshot of an existing one or as a new snapshot. The started snapshot remains in a pending state until it is completed using the CompleteSnapshot action.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-04T16:46:15.084246"}}
{"question": "What is the difference between the ListSnapshotBlocks and ListChangedBlocks API operations?", "answer": "The ListSnapshotBlocks API operation returns the block indexes and block tokens for blocks in the specified snapshot, while the ListChangedBlocks API operation returns the block indexes and block tokens for blocks that are different between two specified snapshots of the same volume/snapshot lineage.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-04T16:46:15.084742"}}
{"question": "What factors affect the actual time taken to create an EBS Snapshot?", "answer": "The actual time taken to create an EBS Snapshot depends on several factors, including the amount of data that has changed since the last snapshot of the EBS volume.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-04T16:46:20.369541"}}
{"question": "Why would a user enable FSR on their snapshots?", "answer": "A user would enable FSR on their snapshots if they are concerned about latency of data access when restoring data from a snapshot to a volume and want to avoid the initial performance hit during initialization. FSR is intended to improve and provide predictable performance for use cases such as virtual desktop infrastructure (VDI), backup & restore, test/dev volume copies, and booting from custom AMIs.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-04T16:46:20.369874"}}
{"question": "How do Private Snapshots differ from Public Snapshots in the AWS Management Console?", "answer": "Private Snapshots are those that you own or that are shared with you, while Public Snapshots are those that are shared globally. You can find Private Snapshots by selecting them from the list in the Snapshots section of the AWS Management Console, whereas Public Snapshots can be found by selecting that option from the same section.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-04T16:46:20.371585"}}
{"question": "What API do I need to invoke to enable fast snapshot restores on a snapshot?", "answer": "To enable fast snapshot restores, you need to invoke the enable-fast-snapshot-restores API on a snapshot within the availability zone (AZ) where initialized volumes are to be restored.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-04T16:46:25.738614"}}
{"question": "How does the credit bucket size relate to the FSR-enabled snapshot size?", "answer": "The credit bucket size is a function of the FSR-enabled snapshot size, meaning that larger snapshots will have a larger credit bucket. For example, a 100 GiB FSR-enabled snapshot has a maximum balance of 10 credits, while a 4 TiB snapshot has a maximum balance of 1 credit.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-04T16:46:25.738958"}}
{"question": "What is the difference between the credit bucket sizes for a 100 GiB snapshot and a 4 TiB snapshot?", "answer": "A 100 GiB FSR-enabled snapshot has a maximum credit bucket size of 10 credits with a fill rate of 10 credits every hour, while a 4 TiB FSR-enabled snapshot has a maximum credit bucket size of 1 credit with a fill rate of 1 credit every 4 hours.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-04T16:46:25.739469"}}
{"question": "What does the balance of the credit bucket represent in the context of FSR-enabled snapshots?", "answer": "The balance of the credit bucket represents the number of creates available for EBS volumes from FSR-enabled snapshots.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-04T16:46:29.396718"}}
{"question": "How does enabling FSR on a shared snapshot affect billing?", "answer": "When you enable FSR on a shared snapshot, you will be billed at standard FSR rates for the use of that snapshot. However, only your account will be billed for the FSR of the shared snapshot; the owner of the snapshot will not incur any charges.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-04T16:46:29.397051"}}
{"question": "What happens when the owner of a shared snapshot deletes the snapshot in relation to FSR?", "answer": "When the owner of your shared snapshot deletes the snapshot, the FSR for that snapshot is automatically disabled, and FSR billing for the snapshot will be terminated.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-04T16:46:29.397493"}}
{"question": "What encryption algorithm does Amazon EBS encryption use to protect data?", "answer": "Amazon EBS encryption uses the industry-standard AES-256 algorithm to encrypt your data and associated keys.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-04T16:46:33.755692"}}
{"question": "How does Amazon EBS encryption enhance data security in relation to EC2 instances?", "answer": "Amazon EBS encryption enhances data security by providing encryption of data at rest, which is managed through Amazon-managed keys or keys created and managed using AWS Key Management Service (KMS). The encryption occurs on the servers that host EC2 instances, ensuring that data is encrypted as it moves between EC2 instances and EBS storage.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-04T16:46:33.756029"}}
{"question": "What is the relationship between AWS KMS and Amazon EBS encryption?", "answer": "AWS KMS is integrated with Amazon EBS encryption, allowing users to create and control the encryption keys used to encrypt their data. This integration simplifies the process of encrypting data with keys that users manage, and it also provides logging of key usage through AWS CloudTrail to help meet regulatory and compliance needs.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-04T16:46:33.756545"}}
{"question": "Can I share encrypted snapshots and AMIs with other AWS accounts?", "answer": "Yes, you can share encrypted snapshots and AMIs using a customer-managed customer master key (CMK) with other AWS accounts.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-04T16:46:38.052986"}}
{"question": "What is the benefit of enabling EBS encryption by default?", "answer": "Enabling EBS encryption by default ensures that all new volumes are always encrypted with a single setting per region.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-04T16:46:38.053327"}}
{"question": "How does using Provisioned Rate for Volume Initialization compare to other initialization methods?", "answer": "Using Provisioned Rate for Volume Initialization allows your volumes to be fully performant within a predictable amount of time, which is beneficial for workloads that require quick initialization of EBS volumes, such as launching hundreds of EC2 instances or EBS volumes quickly.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-04T16:46:38.053791"}}
{"question": "What determines the deleteOnTermination behavior of a volume?", "answer": "The deleteOnTermination behavior of a volume is determined by the configuration of the last attached instance that is terminated.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-04T16:46:42.466214"}}
{"question": "How can you ensure predictable delete on termination behavior for a volume?", "answer": "To ensure predictable delete on termination behavior, you should enable or disable 'deleteOnTermination' for all of the instances to which the volume is attached.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-04T16:46:42.466549"}}
{"question": "What is the difference in behavior of a volume with deleteOnTermination enabled versus disabled when instances are terminated?", "answer": "If 'deleteOnTermination' is enabled for all attached instances, the volume will be deleted when those instances are terminated. Conversely, if 'deleteOnTermination' is disabled for all attached instances, the volume will be retained after the instances have been terminated.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-04T16:46:42.466771"}}
{"question": "What topics are covered under the Networking and security category in the Amazon EC2 FAQs?", "answer": "The Networking and security category in the Amazon EC2 FAQs covers 6 topics.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-04T16:46:46.226407"}}
{"question": "Why is it important to understand the different Instance Types when using Amazon EC2?", "answer": "Understanding the different Instance Types is important because it allows users to select the appropriate instance based on their specific workload requirements, performance needs, and pricing considerations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-04T16:46:46.226741"}}
{"question": "How many topics are there in the Billing and purchase options category compared to the Management category in Amazon EC2 FAQs?", "answer": "The Billing and purchase options category has 11 topics, while the Management category has 4 topics. Therefore, there are 7 more topics in the Billing and purchase options category than in the Management category.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-04T16:46:46.226969"}}
{"question": "What is the primary function of Amazon EC2?", "answer": "The primary function of Amazon EC2 is to provide resizable compute capacity in the cloud, making web-scale computing easier for developers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:46:49.849162"}}
{"question": "How does Amazon EC2 change the economics of computing for developers?", "answer": "Amazon EC2 changes the economics of computing by allowing developers to pay only for the capacity that they actually use, thus eliminating the need for upfront investment in massive compute resources.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:46:49.849505"}}
{"question": "How does Amazon EC2 enable developers to handle unexpected spikes in load compared to traditional methods?", "answer": "Unlike traditional methods where small developers may not have the capital to acquire massive compute resources, Amazon EC2 allows them to use Amazon's massive scale without upfront investment or performance compromises, enabling them to quickly scale capacity as needed.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-04T16:46:49.849713"}}
{"question": "What allows developers to scale resources instantly in Amazon EC2?", "answer": "The 'Elastic' nature of the service allows developers to instantly scale to meet spikes in traffic or demand.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T16:46:54.679637"}}
{"question": "How does Amazon EC2 respond to changing computing requirements compared to traditional hosting services?", "answer": "Amazon EC2 can instantly respond to changing computing requirements, allowing developers to control how many resources are in use at any given point in time. In contrast, traditional hosting services provide a fixed number of resources for a fixed amount of time, limiting users' ability to respond to rapid changes in usage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T16:46:54.679938"}}
{"question": "How does the ability to scale resources in Amazon EC2 compare with traditional hosting services?", "answer": "In Amazon EC2, developers can instantly scale resources up or down based on demand, providing flexibility in resource management. Traditional hosting services, however, offer a fixed number of resources, which restricts users' ability to adapt to unpredictable or fluctuating usage patterns.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T16:46:54.680150"}}
{"question": "What are the two storage options available for root device data when launching Amazon EC2 instances?", "answer": "The two storage options available for root device data when launching Amazon EC2 instances are Amazon EBS and the local instance store.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-04T16:47:00.432027"}}
{"question": "How does using Amazon EBS for root device storage benefit the persistence of data compared to using the local instance store?", "answer": "Using Amazon EBS for root device storage allows data to persist independently from the lifetime of the instance, meaning you can stop and restart the instance and retain the data. In contrast, the local instance store only retains data during the life of the instance, meaning that any data stored there is lost when the instance is terminated.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-04T16:47:00.432332"}}
{"question": "What is the difference in data persistence between Amazon EBS and local instance store in the context of Amazon EC2?", "answer": "The difference in data persistence is that Amazon EBS allows data on the root device to persist independently from the instance's lifetime, enabling you to stop and restart the instance while retaining data. In contrast, the local instance store only retains data for the duration of the instance, meaning the data is not preserved after the instance is terminated.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-04T16:47:00.432533"}}
{"question": "What is the benefit of choosing a globally available AMI instead of setting up your own AMI from scratch?", "answer": "Choosing a globally available AMI allows you to quickly access useful instances without the need to set up your own AMI from scratch. For example, you can select a standard Linux distribution AMI if you just want a simple Linux server.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:47:06.111261"}}
{"question": "How does Amazon EC2 integrate with Amazon S3 for developers?", "answer": "Amazon EC2 integrates with Amazon S3 by allowing developers to use S3 as a storage solution for their AMIs. Developers can load their AMIs into Amazon S3 and move them between Amazon S3 and Amazon EC2, which provides a highly scalable, reliable, and inexpensive data storage infrastructure.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:47:06.111591"}}
{"question": "How do the capabilities of Amazon EC2 and Amazon S3 complement each other?", "answer": "Amazon EC2 provides cheap, scalable compute resources in the cloud, while Amazon S3 offers reliable data storage. Together, they create a powerful combination, as developers can use EC2 for computation and S3 for storing data efficiently.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-04T16:47:06.111813"}}
{"question": "What types of operating systems does Amazon EC2 currently support?", "answer": "Amazon EC2 currently supports a variety of operating systems including: Amazon Linux, Ubuntu, Windows Server, Red Hat Enterprise Linux, SUSE Linux Enterprise Server, openSUSE Leap, Fedora, Fedora CoreOS, Debian, CentOS, Gentoo Linux, Oracle Linux, and FreeBSD.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-04T16:47:12.737772"}}
{"question": "How does Amazon EC2 provide flexibility compared to traditional hosting services?", "answer": "Amazon EC2 provides flexibility by allowing developers to increase or decrease capacity within minutes, enabling them to control how many resources are in use at any given point in time. In contrast, traditional hosting services provide a fixed number of resources for a fixed amount of time, limiting users' ability to respond to rapidly changing or unpredictable usage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-04T16:47:12.738111"}}
{"question": "How does Amazon EC2's capacity scaling differ from traditional hosting services?", "answer": "Amazon EC2 allows for instant scaling of capacity both up and down within minutes, enabling the commissioning of one, hundreds, or even thousands of server instances simultaneously. Traditional hosting services, however, typically provide a pre-configured resource for a fixed amount of time and do not offer the same level of responsiveness to changes in computing requirements.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-04T16:47:12.738278"}}
{"question": "What level of control do developers have over compute resources when using Amazon EC2?", "answer": "Developers using Amazon EC2 have full control over the compute resources. They can initiate or shut down instances at any time and completely customize the configuration of their instances to suit their needs, with the ability to change it at any time.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-04T16:47:18.564161"}}
{"question": "How does Amazon EC2's pricing model benefit developers compared to traditional hosting services?", "answer": "Amazon EC2 benefits developers by allowing them to pay only for their actual resource consumption at very low rates. In contrast, most traditional hosting services require users to pay a fixed, upfront fee regardless of the actual computing power used, which can lead to overbuying resources.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-04T16:47:18.564494"}}
{"question": "How does the flexibility of Amazon EC2 differ from that of most hosting services?", "answer": "The flexibility of Amazon EC2 differs from that of most hosting services in that EC2 allows developers to customize instance configurations and quickly scale resources as needed. In contrast, most hosting services cater to groups of users with similar system requirements and offer limited ability to change configurations, resulting in less flexibility.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-04T16:47:18.564709"}}
{"question": "What is the new basis for On-Demand Instance limits in Amazon EC2?", "answer": "The new basis for On-Demand Instance limits in Amazon EC2 is transitioning from instance count-based limits to vCPU-based limits. This change aims to simplify the limit management experience for AWS customers, with usage measured in terms of the number of vCPUs for the EC2 Instance Types.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-04T16:47:24.403273"}}
{"question": "Why are vCPU-based limits being implemented for On-Demand Instances?", "answer": "vCPU-based limits are being implemented to simplify the limit management experience for AWS customers. This new system measures usage based on the total number of vCPUs assigned to the running On-Demand instances, allowing for more flexibility in launching instance types that meet application needs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-04T16:47:24.404118"}}
{"question": "How does the vCPU limit for running On-Demand Standard instances compare to that for running On-Demand F and G instances?", "answer": "The vCPU limit for running On-Demand Standard instances is 1152 vCPUs, which is significantly higher than the limits for running On-Demand F and G instances, both of which have a limit of 128 vCPUs each.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-04T16:47:24.404418"}}
{"question": "Are the On-Demand Instance vCPU limits set on a per-region basis?", "answer": "Yes, the On-Demand Instance limits for an AWS account are set on a per-region basis.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T16:47:28.442923"}}
{"question": "How does Amazon EC2 manage the limits for On-Demand Instances over time?", "answer": "Amazon EC2 is constantly monitoring your usage within each region, and your limits are raised automatically based on your use of EC2.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T16:47:28.443267"}}
{"question": "How do vCPU-based limits compare to count-based instance limits in terms of instance launching?", "answer": "The vCPU-based instance limits allow you to launch at least the same number of instances as count-based instance limits.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T16:47:28.443475"}}
{"question": "What will the API no longer return regarding EC2 limits?", "answer": "The API will no longer return the max-instances value.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-04T16:47:32.553945"}}
{"question": "How can I retrieve information about EC2 limits after the change in the API?", "answer": "You can now use the Service Quotas APIs to retrieve information about EC2 limits.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-04T16:47:32.555197"}}
{"question": "Are vCPU limits available in all AWS Regions, and if so, which type of AWS Regions?", "answer": "Yes, vCPU-based instance limits are available in all commercial AWS Regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-04T16:47:32.555486"}}
{"question": "What change regarding email traffic over port 25 was implemented by Amazon EC2 on January 7, 2020?", "answer": "As of January 7, 2020, Amazon EC2 began rolling out a change to restrict email traffic over port 25 by default to protect customers and other recipients from spam and email abuse. Port 25 is typically used as the default SMTP port to send emails.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-04T16:47:38.112411"}}
{"question": "Why did Amazon EC2 decide to restrict email traffic over port 25?", "answer": "Amazon EC2 decided to restrict email traffic over port 25 by default to protect customers and other recipients from spam and email abuse.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-04T16:47:38.112693"}}
{"question": "How does the Amazon EC2 service level agreement (SLA) for uptime compare to the typical restrictions on email traffic over port 25?", "answer": "The Amazon EC2 service level agreement (SLA) guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon EC2 and Amazon EBS within a Region, while the restrictions on email traffic over port 25 are implemented to protect against spam and email abuse, which is unrelated to uptime guarantees.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-04T16:47:38.112865"}}
{"question": "What hardware components do Accelerated Computing instances utilize to improve performance?", "answer": "Accelerated Computing instances utilize hardware accelerators or co-processors, such as GPUs, purpose-built AI chips AWS Trainium and AWS Inferentia, and FPGAs, to perform functions like floating-point number calculation and graphics processing more efficiently than software running on CPUs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-11", "source_tokens": 438, "generated_at": "2026-02-04T16:47:44.033747"}}
{"question": "What advantages do EC2 UltraServers offer for AI training and inference at scale?", "answer": "EC2 UltraServers offer the highest AI training and inference performance for models at the trillion-parameter scale by connecting multiple EC2 instances through a dedicated, high-bandwidth, low-latency accelerator interconnect. This allows for a tightly-coupled mesh of accelerators across EC2 instances, providing significantly more compute and memory than standalone EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-11", "source_tokens": 438, "generated_at": "2026-02-04T16:47:44.034097"}}
{"question": "How do G-series and P-series GPU-based EC2 instances differ in their applications?", "answer": "G-series instances are well suited for graphics, gaming, spatial computing, as well as AI/ML inference and single-node AI/ML training workloads. In contrast, P-series instances are optimized specifically for AI inference and training of large foundation models.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-11", "source_tokens": 438, "generated_at": "2026-02-04T16:47:44.034604"}}
{"question": "What are AWS Trainium and AWS Inferentia designed for?", "answer": "AWS Trainium and AWS Inferentia are purpose built for deep learning and generative AI workloads. They can be used for AI training and inference to achieve high performance while saving up to 50% on training and inference costs compared to comparable EC2 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-04T16:47:50.085633"}}
{"question": "What advantages do AWS Trainium and AWS Inferentia provide for AI workloads?", "answer": "AWS Trainium and AWS Inferentia provide high performance for AI training and inference while offering cost savings of up to 50% over comparable EC2 instances. They also support a diverse set of model architectures through the AWS Neuron SDK.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-04T16:47:50.085855"}}
{"question": "How do Amazon EC2 UltraClusters compare to AWS Trainium and AWS Inferentia in terms of scalability?", "answer": "Amazon EC2 UltraClusters can scale to thousands of GPUs or purpose-built ML chips like AWS Trainium, providing on-demand access to supercomputing-class performance. In contrast, AWS Trainium and AWS Inferentia are specialized for deep learning and generative AI workloads, focusing on cost efficiency and performance for those specific tasks.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-04T16:47:50.085984"}}
{"question": "What are Flex instances and how do they compare in price performance to previous instance generations?", "answer": "Flex instances, specifically M7i-flex and C7i-flex, are lower priced variants of comparable instances (M7i and C7i). They offer 19% better price performance compared to the previous generation of instances (M6i and C6i).", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-04T16:47:57.675462"}}
{"question": "What types of workloads are Flex instances designed for?", "answer": "Flex instances are designed to run a majority of workloads that benefit from the latest generation performance but do not fully utilize compute resources. They are ideal for workloads that fit on instance sizes up to 16xlarge, including web and application servers, databases, virtual desktops, batch processing, microservices, caches, enterprise applications, Apache Kafka, and Elasticsearch.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-04T16:47:57.675802"}}
{"question": "How do Flex instances compare to comparable instances like M7i and C7i in terms of scalability and performance?", "answer": "Flex instances provide a baseline CPU performance of 40% with the ability to scale up to 100% CPU for 95% of the time. In contrast, comparable instances (M7i and C7i) are suitable for workloads that require the largest instance sizes or high sustained CPU, network, or EBS performance, which includes large application servers and databases, among others.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-04T16:47:57.676021"}}
{"question": "What is the maximum CPU Credit balance for a t2.micro instance?", "answer": "The maximum CPU Credit balance for a t2.micro instance is 144 CPU Credits.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-04T16:48:02.500762"}}
{"question": "How do Burstable Performance Instances like T2 differ from Fixed Performance Instances in terms of CPU performance?", "answer": "Burstable Performance Instances like T2 provide a baseline level of CPU performance with the ability to burst above that baseline, whereas Fixed Performance Instances provide a consistent level of performance without the bursting capability.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-04T16:48:02.501096"}}
{"question": "How does the baseline CPU performance of a t2.large instance compare to that of a t2.medium instance?", "answer": "The baseline CPU performance of a t2.large instance is 60% of a core, while the baseline CPU performance of a t2.medium instance is 40% of a core. Therefore, the t2.large instance has a higher baseline CPU performance than the t2.medium instance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-04T16:48:02.501295"}}
{"question": "What is the CPU Credit balance for T2 instances and how can I view it?", "answer": "The CPU Credit balance for T2 instances indicates the balance of CPU Credits available for use. You can view this balance in EC2 per-Instance metrics in Amazon CloudWatch, where T2 instances have four metrics: CPUCreditUsage, CPUCreditBalance, CPUSurplusCreditBalance, and CPUSurplusCreditsCharged.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T16:48:08.998431"}}
{"question": "What are the benefits of using T2 instances for general purpose workloads?", "answer": "T2 instances provide a cost-effective platform for a broad range of general purpose production workloads. They are particularly beneficial as T2 Unlimited instances can sustain high CPU performance for as long as required, making them suitable for workloads that may experience variable CPU usage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T16:48:08.998777"}}
{"question": "How does the CPU performance of T2 instances compare when they are low on CPU Credits versus when they are not?", "answer": "When T2 instances are low on CPU Credits, their CPU performance may degrade as they can no longer burst beyond their baseline performance. In contrast, when they have a sufficient CPU Credit balance, T2 instances can utilize additional CPU Credits to achieve higher performance levels, resulting in better responsiveness for applications.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T16:48:08.998987"}}
{"question": "What happens to the CPU performance of a T2 instance when its CPU Credit balance reaches zero?", "answer": "When a T2 instance has a zero CPU Credit balance, its performance will remain at baseline CPU performance. For instance, the t2.micro provides a baseline CPU performance of 10% of a physical CPU core.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-04T16:48:13.922194"}}
{"question": "What are the advantages of using T4g instances compared to T3 instances?", "answer": "T4g instances deliver up to 40% better price performance over T3 instances. They are designed for general purpose burstable workloads and leverage Arm-based AWS Graviton2 processors, built on the AWS Nitro System.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-04T16:48:13.922536"}}
{"question": "How do the purchasing options for T2 instances compare to those for T4g instances?", "answer": "T2 instances can be purchased as On-Demand Instances, Reserved Instances, or Spot Instances, while the context does not specify the purchasing options for T4g instances. Therefore, we cannot compare the purchasing options directly as the information for T4g instances is not provided.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-04T16:48:13.922714"}}
{"question": "What is the monthly free hour allowance for running a t4g.small instance during the T4g free trial?", "answer": "During the T4g free trial, customers who run a t4g.small instance will automatically get 750 free hours per month deducted from their bill.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:48:19.738115"}}
{"question": "What happens if customers exceed the allocated CPU credits during the 750 free hours of the T4g free trial?", "answer": "Customers must pay for surplus CPU credits when they exceed the instances allocated credits during the 750 free hours of the T4g free trial program.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:48:19.738465"}}
{"question": "How does the T4g free trial availability relate to the existing AWS Free Tier?", "answer": "The T4g free trial is available in addition to the existing AWS Free Tier on t3.micro, t3.small, t4g.micro, t4g.small, C7i-flex.large, and M7i-flex.large. Customers who have exhausted their AWS Free Tier usage can still benefit from the T4g free trial, depending on the region.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-04T16:48:19.738661"}}
{"question": "What is the cumulative limit of free hours for running t4g.small instances during the free trial?", "answer": "The cumulative limit of free hours for running t4g.small instances during the free trial is 750 free hours per month until December 31, 2025.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-04T16:48:25.499663"}}
{"question": "What types of Amazon Machine Images (AMIs) are covered under the t4g.small free trial?", "answer": "Under the t4g.small free trial, there will be no AMI charge for Amazon Linux 2, RHEL, and SUSE Linux AMIs that are available through the EC2 console Quick Start for the first 750 free hours per month.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-04T16:48:25.500030"}}
{"question": "How does the free trial of t4g.small instances differ from regular On-Demand pricing after the free hours are exceeded?", "answer": "The free trial of t4g.small instances allows customers to use 750 free hours per month without incurring AMI charges for specific images. However, after exceeding the 750 free hours, regular On-Demand prices, including any applicable AMI charges, will apply.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-04T16:48:25.500255"}}
{"question": "What is the monthly billing cycle for the T4g free trial?", "answer": "The T4g free trial has a monthly billing cycle that starts on the first of every month and ends on the last day of that month.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-04T16:48:29.462461"}}
{"question": "How are customers notified about their usage during the T4g free trial?", "answer": "Customers will be notified automatically through email using AWS Budgets when their aggregate monthly usage reaches 85% of 750 free hours.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-04T16:48:29.462783"}}
{"question": "How does the T4g free trial interact with a customer's Compute Savings Plan or T4g Instance Savings Plan?", "answer": "For customers with a Compute Savings Plan or T4g Instance Savings Plan, the Savings Plan discount will be applied to On-Demand pricing for hours exceeding the 750 free trial hours.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-04T16:48:29.462998"}}
{"question": "How will customers be billed for t4g.small instances after the free trial ends?", "answer": "After the free trial ends on January 1, 2026, customers running on t4g.small instances will be switched to the On-Demand pricing plan, or the Reserved Instance (RI)/Savings Plan (SV) plan if purchased. Accumulated credits will be set to zero. Customers will be notified via email seven days before the end of the free trial. If no RI plan is purchased, customers will be charged the regular On-Demand pricing. If they have a T4g Instance Savings Plan or a Compute Savings Plan, the Savings Plan discount will apply to their On-Demand pricing.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-04T16:48:36.365473"}}
{"question": "What types of applications are best suited for Compute Optimized instances?", "answer": "Compute Optimized instances are designed for applications that require high compute power. These applications include compute-intensive workloads such as high-performance web servers, high-performance computing (HPC), scientific modeling, distributed analytics, and machine learning inference.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-04T16:48:36.365815"}}
{"question": "How do Amazon EC2 C7g instances compare to C6g instances in terms of performance?", "answer": "Amazon EC2 C7g instances provide up to 25% better performance over the sixth generation AWS Graviton2-based C6g instances. Both instance types are optimized for compute-intensive workloads, but the C7g instances are powered by the latest generation AWS Graviton3 processors, which enhances their performance capabilities.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-04T16:48:36.366046"}}
{"question": "What are some of the ideal use cases for C6g instances?", "answer": "C6g instances are ideal for compute-intensive workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference. They provide significant price performance benefits for these applications, especially for those built on open source software.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-04T16:48:42.495082"}}
{"question": "How do C6g instances support the Arm architecture for application deployment?", "answer": "C6g instances allow Arm developers to build their applications directly on native Arm hardware, eliminating the need for cross-compilation or emulation. Applications built on open source software are likely to be well supported in the Arm ecosystem, and many Linux distributions and container platforms support the Arm architecture, facilitating ease of deployment.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-04T16:48:42.495428"}}
{"question": "How do EBS storage options differ between C6g instances and C6gd instance types?", "answer": "C6g instances are EBS-optimized by default and support the Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. In comparison, C6gd instance types also offer local NVMe instance storage options, which are not available in standard C6g instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-04T16:48:42.495642"}}
{"question": "What types of CPU powered instances are planned for the future C6 instance families?", "answer": "The future C6 instance families are planned to offer both Intel and AMD CPU powered instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-22", "source_tokens": 481, "generated_at": "2026-02-04T16:48:48.349939"}}
{"question": "How does the EBS-optimized feature work for C4 instances?", "answer": "Each C4 instance type is EBS-optimized by default, providing bandwidth from 500 Mbps to 4,000 Mbps to EBS, in addition to the general-purpose network throughput. Since this feature is always enabled, launching a C4 instance explicitly as EBS-optimized will not affect its behavior.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-22", "source_tokens": 481, "generated_at": "2026-02-04T16:48:48.350305"}}
{"question": "How do the C6g instances compare to C5 instances in terms of price performance?", "answer": "C6g instances deliver up to 40% better price performance compared to C5 instances, making them more cost-effective for advanced compute-intensive workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-22", "source_tokens": 481, "generated_at": "2026-02-04T16:48:48.350819"}}
{"question": "What type of processors power C6a instances?", "answer": "C6a instances are powered by 3rd generation AMD EPYC processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-04T16:48:52.299621"}}
{"question": "How do C6i instances enhance memory bandwidth compared to C5 instances?", "answer": "C6i instances provide up to 9% higher memory bandwidth per vCPU compared to C5 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-04T16:48:52.299961"}}
{"question": "What are the differences in vCPU and memory capacity between C6a and C6i instances?", "answer": "C6a instances provide up to 192 vCPUs and 384 GiB of memory, while C6i instances offer a new instance size (c6i.32xlarge) with 128 vCPUs and 256 GiB of memory.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-04T16:48:52.300470"}}
{"question": "What processors do C5 instances use?", "answer": "C5 instances are based on Intel Xeon Platinum processors, part of the Intel Xeon Scalable processor family, codenamed Skylake-SP or Cascade Lake.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-04T16:48:56.905994"}}
{"question": "What improvements do C5 instances offer compared to C4 instances?", "answer": "C5 instances deliver a 25% improvement in price/performance compared to C4 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-04T16:48:56.906330"}}
{"question": "How do C5a instances compare to C5 instances in terms of processor type?", "answer": "C5a instances feature 2nd Gen 3.3GHz AMD EPYC processors, while C5 instances use Intel Xeon Platinum processors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-04T16:48:56.906856"}}
{"question": "What are the benefits of C6i instances compared to C5 instances?", "answer": "C6i instances offer up to 15% better price performance over C5 instances, always-on memory encryption using Intel Total Memory encryption (TME), a new instance size (c6i.32xlarge) with 128 vCPUs and 256 GiB of memory, which is 33% more than the largest C5 instance. Additionally, C6i instances provide up to 9% higher memory bandwidth per vCPU compared to C5 instances and offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, which is twice that of C5 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T16:49:03.299698"}}
{"question": "What features make C5 instances suitable for floating point intensive applications?", "answer": "C5 instances feature Intel AVX-512, which enables significant improvements in delivered TFLOPS by effectively extracting data level parallelism, making them suitable for floating point intensive applications. Additionally, the generational improvement in CPU performance and lower price of C5 instances result in a 25% price/performance improvement relative to C4 instances, benefiting a broad spectrum of workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T16:49:03.300075"}}
{"question": "How do C5 instances compare to C4 instances in terms of price/performance improvement?", "answer": "C5 instances provide a 25% price/performance improvement relative to C4 instances. This improvement is due to the generational enhancement in CPU performance and the lower pricing of C5 instances, which benefit workloads that currently run on C3 or C4 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T16:49:03.300595"}}
{"question": "What type of processors power the Hpc7g instances?", "answer": "Hpc7g instances are powered by AWS Graviton 3E processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-04T16:49:07.868832"}}
{"question": "How do Hpc7g instances improve price performance for HPC workloads compared to previous-generation AWS Graviton-based instances?", "answer": "Hpc7g instances deliver up to 70% better performance and almost 3x better price performance compared to previous-generation AWS Graviton-based instances for compute-intensive HPC workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-04T16:49:07.869174"}}
{"question": "How do the network bandwidth capabilities of Hpc7a instances compare to those of Hpc6a instances?", "answer": "Hpc7a instances feature 300 Gbps of Elastic Fabric Adapter (EFA) network bandwidth, which is higher than the network bandwidth of Hpc6a instances, although the specific bandwidth of Hpc6a instances is not mentioned in the context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-04T16:49:07.869708"}}
{"question": "What type of processors power Hpc6a instances?", "answer": "Hpc6a instances are powered by 96 cores of 3rd Gen AMD EPYC processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-04T16:49:13.087086"}}
{"question": "What are the benefits of EFA networking for Hpc6a instances?", "answer": "Hpc6a instances offer 100 Gbps EFA networking enabled for high throughput internode communications, which helps run HPC workloads at scale.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-04T16:49:13.087421"}}
{"question": "How do Hpc6a instances compare to Hpc7g instances in terms of processor and network capabilities?", "answer": "Hpc6a instances are powered by 3rd Gen AMD EPYC processors with 96 cores and offer 100 Gbps EFA networking, while Hpc7g instances utilize Arm-based Graviton3E processors with 64 physical cores and provide 200 Gbps network bandwidth. Hpc7g instances are optimized for compute-intensive workloads and support low-latency communications in single Availability Zone deployments.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-04T16:49:13.087858"}}
{"question": "What types of applications are Hpc7a instances ideal for?", "answer": "Hpc7a instances are ideal for applications that benefit from high-performance processors, including large, complex simulations such as computational fluid dynamics (CFD), numerical weather prediction, and multiphysics simulations.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-04T16:49:17.112209"}}
{"question": "How do Hpc7a instances compare to Hpc6a instances in terms of performance features?", "answer": "Hpc7a instances feature 4th Gen AMD EPYC processors with 2x higher core density (up to 192 cores), 2.1x higher memory bandwidth throughput (768 GB of memory), and 3x higher network bandwidth compared to Hpc6a instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-04T16:49:17.112554"}}
{"question": "What are the supported operating systems for Hpc7a instances?", "answer": "Hpc7a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.6 or later, SUSE Linux Enterprise Server 12 SP3 or later, CentOS 7 or later, and FreeBSD 11.1 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-04T16:49:17.113055"}}
{"question": "What is the maximum memory bandwidth per vCPU for Hpc6id instances?", "answer": "Hpc6id instances deliver up to 5 GB/s memory bandwidth per vCPU.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T16:49:21.815933"}}
{"question": "Why is hyperthreading disabled on Hpc6id instances?", "answer": "Hyperthreading is disabled on Hpc6id instances to increase per-vCPU CPU throughput.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T16:49:21.816274"}}
{"question": "How do the networking capabilities of Hpc6id instances compare to Hpc6a instances?", "answer": "Hpc6id instances deliver 200 Gbps network bandwidth optimized for traffic between instances in the same virtual private cloud (VPC) and support EFA for increased network performance, whereas Hpc6a instances do not have specified network bandwidth or EFA support mentioned in the context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T16:49:21.816795"}}
{"question": "What performance improvements do AWS Graviton2 processors offer compared to the first generation?", "answer": "AWS Graviton2 processors deliver up to 7x performance, 4x the number of compute cores, 2x larger caches, 5x faster memory, and 50% faster per core encryption performance than first generation AWS Graviton processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-04T16:49:27.420448"}}
{"question": "How does memory encryption in AWS Graviton2 processors enhance security?", "answer": "AWS Graviton2 processors support always-on 256-bit memory encryption, with encryption keys securely generated within the host system. These keys do not leave the host system and are irrecoverably destroyed when the host is rebooted or powered down, enhancing security.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-04T16:49:27.420798"}}
{"question": "How do M6g instances compare to other M instances for applications built on open source software?", "answer": "M6g instances deliver significant performance and price performance benefits for applications built on open source software compared to other M instances. They are particularly appealing because customers can realize the best price performance when deploying general-purpose workloads across the M instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-04T16:49:27.421245"}}
{"question": "What is the EBS bandwidth offered by M6g instances?", "answer": "M6g instances offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-04T16:49:32.612278"}}
{"question": "What types of applications may require modifications to run on M6g instances?", "answer": "Applications developed using compiled languages, such as C, C++, and GoLang, will need to be re-compiled to generate Arm binaries to run on M6g instances. In contrast, applications based on interpreted languages, like Java, Node, and Python, which are not reliant on native CPU instruction sets, should run with minimal to no changes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-04T16:49:32.612621"}}
{"question": "How do M6g instances compare to A1 instances in terms of processor technology?", "answer": "M6g instances are powered by the second-generation AWS Graviton Processors, while Amazon EC2 A1 instances are powered by the first-generation AWS Graviton Processors. This indicates that M6g instances utilize a more advanced generation of the Graviton architecture compared to A1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-04T16:49:32.613145"}}
{"question": "What instruction set are AWS Graviton processors based on?", "answer": "AWS Graviton processors are based on the 64-bit Arm instruction set.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-32", "source_tokens": 460, "generated_at": "2026-02-04T16:49:36.644251"}}
{"question": "What types of applications are ideal for A1 instances?", "answer": "A1 instances are ideal for scale-out applications such as web servers, containerized microservices, and data/log processing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-32", "source_tokens": 460, "generated_at": "2026-02-04T16:49:36.644613"}}
{"question": "How do the AMI requirements differ between A1 instances and M6g instances?", "answer": "Both A1 and M6g instances require the use of 'arm64' AMIs, while x86 AMIs are not compatible with either instance type.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-32", "source_tokens": 460, "generated_at": "2026-02-04T16:49:36.645130"}}
{"question": "What is the maximum instance size supported by A1 instances?", "answer": "A1 instances support a maximum instance size of up to 4xlarge.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-04T16:49:40.939811"}}
{"question": "How do M6g instances compare to A1 instances in terms of memory per vCPU?", "answer": "M6g instances provide 4GB of memory per vCPU, while A1 instances only support 2GB of memory per vCPU.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-04T16:49:40.940144"}}
{"question": "What are the benefits of using M6g instances over A1 instances for certain applications?", "answer": "M6g instances are a better fit for applications that require more compute, memory, and networking resources. They also deliver the best price-performance within their instance family and support larger instance sizes and greater networking bandwidth compared to A1 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-04T16:49:40.940566"}}
{"question": "What are the main performance improvements of EC2 M5 Instances compared to EC2 M4 Instances?", "answer": "EC2 M5 Instances deliver greater compute and storage performance, larger instance sizes for less cost, consistency, and security compared to EC2 M4 Instances. They provide up to 20% improvement in price/performance, have AVX-512 support which offers 2x higher performance in workloads requiring floating point operations, and offer up to 25 Gbps of network bandwidth along with up to 10 Gbps of dedicated bandwidth to Amazon EBS.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-04T16:49:48.210607"}}
{"question": "What advantages do M6i instances have over M5 instances in terms of compute performance and memory?", "answer": "M6i instances are powered by 3rd generation Intel Xeon Scalable processors and offer up to 15% better compute price performance over M5 instances. They provide a new instance size (m6i.32xlarge) with 128 vCPUs and 512 GiB of memory, which is 33% more than the largest M5 instance. Additionally, M6i instances offer up to 20% higher memory bandwidth per vCPU compared to M5 instances, enhancing efficiency for real-time analysis in data-intensive applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-04T16:49:48.210894"}}
{"question": "How does the networking capability of M6i instances compare to M5 instances?", "answer": "M6i instances provide up to 50 Gbps of networking speed and 40 Gbps of bandwidth to Amazon Elastic Block Store, which is twice the networking bandwidth offered by M5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-04T16:49:48.211396"}}
{"question": "What is the benefit of Intel AVX-512 for customers using the EC2 M5 family or M6i family?", "answer": "Intel Advanced Vector Extensions 512 (AVX-512) offers a set of new CPU instructions available on the latest Intel Xeon Scalable processors that can accelerate performance for various workloads, including scientific simulations, financial analytics, artificial intelligence, machine learning/deep learning, 3D modeling, image and video processing, cryptography, and data compression. It specifically enhances the processing of encryption algorithms, reducing performance overhead for cryptography. This allows customers using the EC2 M5 family or M6i family to deploy more secure data and services in distributed environments without compromising performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-04T16:49:57.938323"}}
{"question": "What are the characteristics of M5zn instances?", "answer": "M5zn instances are a variant of the M5 general purpose instances powered by the fastest Intel Xeon Scalable processor in the cloud, featuring an all-core turbo frequency of up to 4.5 GHz. They also offer 100 Gbps networking and support for Amazon EFA. These instances are ideal for workloads such as gaming, financial applications, simulation modeling in industries like automotive, aerospace, energy, and telecommunication, as well as other High Performance Computing applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-04T16:49:57.938669"}}
{"question": "How do M5zn instances compare to z1d instances?", "answer": "M5zn instances differ from z1d instances in that M5zn are general purpose instances featuring a high frequency version of the 2nd Generation Intel Xeon Scalable processors with a turbo frequency of up to 4.5 GHz, alongside up to 100 Gbps networking performance and support for EFA. In contrast, z1d instances are memory-optimized, featuring a high frequency version of the Intel Xeon Scalable processors with a frequency of up to 4.0 GHz and local NVMe storage. Additionally, M5zn instances offer improved price performance compared to z1d instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-04T16:49:57.939185"}}
{"question": "What is the maximum amount of memory that EC2 High Memory instances can offer?", "answer": "Amazon EC2 High Memory instances can offer a maximum of 32 TiB of memory in a single instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-04T16:50:02.444137"}}
{"question": "What types of workloads are EC2 High Memory instances specifically designed to support?", "answer": "EC2 High Memory instances are specifically designed to run large in-memory databases and business applications, including SAP deployments that rely on these databases.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-04T16:50:02.444454"}}
{"question": "How do the processors used in EC2 High Memory (U-1) instances differ from those in U7i instances?", "answer": "EC2 High Memory (U-1) instances with 3, 6, 9, and 12 TiB are powered by Intel Xeon Platinum 8176M or 8280L processors, while U7i instances are powered by 4th Generation Intel Xeon Scalable processors (Sapphire Rapids).", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-04T16:50:02.444998"}}
{"question": "What memory sizes are available for High Memory instances certified by SAP?", "answer": "High Memory instances with 3, 6, 8, 9, 12, 16, 18, 24, 32 TiB of memory are certified by SAP for various applications including Business Suite on HANA, S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, and SAP BW/4HANA in production environments.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-04T16:50:08.177081"}}
{"question": "What are some advantages of using High Memory virtualized instances?", "answer": "High Memory virtualized instances provide several advantages over bare metal instances, including significantly better launch/reboot times, flexible purchase options such as On-Demand and Savings Plans, choice of tenancy type, self-service options, and support for a higher number of EBS volumes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-04T16:50:08.177452"}}
{"question": "In what scenarios should High Memory Metal instances be preferred over High Memory Virtualized instances?", "answer": "High Memory Metal instances should be preferred in specific scenarios such as when using OS versions not supported on High Memory Virtual instances, when applications need to run in non-virtualized mode due to licensing/support requirements, when applications require access to specific hardware features like Intel VT-x, or when using a custom hypervisor such as ESXi.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-04T16:50:08.177959"}}
{"question": "What are the steps to migrate a High Memory metal instance to a virtualized instance?", "answer": "To migrate a High Memory metal instance to a virtualized instance, you need to follow these steps: 1. Stop your instance, 2. Change the instance and tenancy type through the EC2 API, and 3. Start your instance back up.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-04T16:50:15.346788"}}
{"question": "Why is it important to ensure compatibility of operating system and kernel versions when migrating to virtualized High Memory instances?", "answer": "It is important to ensure compatibility of operating system and kernel versions when migrating to virtualized High Memory instances because if you are using Red Hat Enterprise Linux for SAP or SUSE Linux Enterprise Server for SAP, incompatible versions may lead to issues with the operation of the instance after migration.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-04T16:50:15.347093"}}
{"question": "How does the network performance of High Memory instances compare to standard instances?", "answer": "High Memory instances utilize the Elastic Network Adapter (ENA) for networking and enable Enhanced Networking by default, allowing them to utilize up to 100 Gbps (U-1) and up to 200 Gbps (U7i) of network bandwidth. This is typically superior to standard instances, which may not support such high bandwidth capabilities.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-04T16:50:15.347643"}}
{"question": "What types of instances can you configure C-states and P-states on?", "answer": "You can configure C-states and P-states on High Memory (U-1 metal) instances and C-states can also be configured on both U-1 and U7i virtual instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-04T16:50:22.322469"}}
{"question": "How do C-states and P-states affect performance on High Memory instances?", "answer": "C-states can be used to enable higher turbo frequencies, reaching up to 4.0 GHz, while P-states can lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo and allows the CPU to run consistently at the base clock speed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-04T16:50:22.322803"}}
{"question": "What is the difference in purchase options between EC2 High Memory virtualized instances and metal instances?", "answer": "EC2 High Memory virtualized instances are available for purchase via On-Demand, 1-Yr and 3-Yr Savings Plans, and 1-Yr and 3-Yr Reserved Instances. In contrast, EC2 High Memory metal instances are only available for purchase as EC2 Dedicated Hosts on a 1-Yr and 3-Yr Reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-04T16:50:22.323233"}}
{"question": "What type of processors power the Amazon EC2 R6g instances?", "answer": "Amazon EC2 R6g instances are powered by Arm-based AWS Graviton2 Processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-04T16:50:26.487845"}}
{"question": "Why might a user choose R6g instances for their applications?", "answer": "Users might choose R6g instances for their applications because they deliver significant price performance benefits for memory-intensive workloads, such as open-source databases, in-memory caches, and real-time big data analytics. Additionally, R6g instances allow Arm developers to build applications directly on native Arm hardware, avoiding the need for cross-compilation or emulation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-04T16:50:26.488184"}}
{"question": "How do R6g instances compare to R5 instances in terms of price performance?", "answer": "R6g instances deliver up to 40% better price performance over R5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-04T16:50:26.488641"}}
{"question": "What type of networking does R6g instances support?", "answer": "R6g instances support ENA based Enhanced Networking, which allows them to deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-04T16:50:31.894502"}}
{"question": "What changes may be required for applications running on R6g instances?", "answer": "The changes required for applications running on R6g instances depend on the application type. Applications built on open source software are likely to be supported by the Arm ecosystem without significant changes. Most Linux distributions and containers support the Arm architecture. Applications based on interpreted languages should run with minimal to no changes, while those developed using compiled languages will need to be re-compiled to generate Arm binaries.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-04T16:50:31.894843"}}
{"question": "How do R6g instances compare to applications developed using compiled languages in terms of required modifications?", "answer": "Applications developed using compiled languages, such as C, C++, and GoLang, will need to be re-compiled to generate Arm binaries when running on R6g instances. In contrast, applications based on interpreted languages like Java, Node, and Python should run on R6g instances with minimal to no changes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-04T16:50:31.895341"}}
{"question": "What processors do Amazon EC2 R6i instances use?", "answer": "Amazon EC2 R6i instances are powered by 3rd Generation Intel Xeon Scalable processors (Ice Lake).", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-04T16:50:36.051818"}}
{"question": "How do R6i instances improve memory bandwidth compared to R5 instances?", "answer": "R6i instances provide up to 20% higher memory bandwidth per vCPU compared to R5 instances, which allows for more efficient real-time analysis for data-intensive applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-04T16:50:36.052166"}}
{"question": "How do R6i instances compare to R5 instances in terms of networking speed and bandwidth?", "answer": "R6i instances offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, which is twice the bandwidth of R5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-04T16:50:36.052685"}}
{"question": "What types of workloads are R5b instances ideal for?", "answer": "R5b instances are ideal for large relational database workloads, including Microsoft SQL Server, SAP HANA, IBM DB2, and Oracle. They are suitable for performance-intensive applications such as commerce platforms, ERP systems, and health record systems.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-04T16:50:41.555367"}}
{"question": "Why would customers consider using R5b instances for their workloads?", "answer": "Customers should consider using R5b instances for workloads such as large relational databases and data analytics because these instances provide increased EBS storage network performance, which can lead to higher performance and bandwidth. Additionally, customers can lower costs by migrating to smaller size R5b instances or consolidating workloads on fewer R5b instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-04T16:50:41.555734"}}
{"question": "How do the storage options of R5b instances compare to those of High Memory instances?", "answer": "R5b instances are EBS-optimized by default and offer up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS, while High Memory instances also support Amazon EBS volumes and are EBS-optimized by default, offering up to 38Gbps of storage bandwidth. The key difference is that R5b instances provide higher EBS bandwidth and IOPS compared to High Memory instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-04T16:50:41.556210"}}
{"question": "What types of workloads are X2gd instances ideal for?", "answer": "X2gd instances are ideal for customers with Arm-compatible memory bound scale-out workloads such as Redis and Memcached in-memory databases, relational databases like PostgreSQL, MariaDB, MySQL, and RDS Aurora, as well as memory intensive workloads including Apache Hadoop, real-time analytics, and real-time caching servers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-04T16:50:46.276474"}}
{"question": "What advantages do X2gd instances offer for single threaded workloads?", "answer": "X2gd instances provide advantages for single threaded workloads by offering physical core and more memory, allowing users to consolidate more workloads onto a single instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-04T16:50:46.276820"}}
{"question": "How do X2gd instances compare to X1 and R instances in terms of memory and processor architecture?", "answer": "X2gd instances use Arm-compatible architecture and offer a cost-effective solution with the lowest cost per gigabyte of memory within EC2, supporting sizes up to 1 TiB. In contrast, X1 and R instances use x86 processors and are suitable for memory-intensive enterprise-class, scale-up workloads, providing larger memory sizes up to 4 TiB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-04T16:50:46.277305"}}
{"question": "What type of processors power the X2idn and X2iedn instances?", "answer": "X2idn and X2iedn instances are powered by 3rd generation Intel Xeon Scalable processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-04T16:50:50.643306"}}
{"question": "What are the advantages of using X2idn and X2iedn instances over X1 instances?", "answer": "X2idn and X2iedn instances deliver up to 50% higher compute price performance than comparable X1 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-04T16:50:50.643670"}}
{"question": "How do the memory capacities of X2idn and X2iedn instances compare?", "answer": "X2idn offers up to 2 TiB of memory, while X2iedn offers up to 4 TiB of memory, indicating that X2iedn has double the memory capacity of X2idn.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-04T16:50:50.644199"}}
{"question": "What types of applications are X1 instances ideal for running?", "answer": "X1 instances are ideal for running in-memory databases like SAP HANA, big data processing engines like Apache Spark or Presto, and high performance computing (HPC) applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-04T16:50:56.334172"}}
{"question": "How can users manage CPU power states on X1 and X1e instances?", "answer": "Users can configure C-states and P-states on x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge, and x1.16xlarge instances. C-states allow enabling higher turbo frequencies, while P-states can be used to lower performance variability by pinning all cores at P1 or higher P states.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-04T16:50:56.334505"}}
{"question": "What is the difference in Windows Server support between x1e.32xlarge and x1.16xlarge instances?", "answer": "The x1e.32xlarge instance supports Windows Server 2012 R2 and 2012 RTM. In contrast, the x1.16xlarge instance supports Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit, but does not support Windows Server 32bit versions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-04T16:50:56.335092"}}
{"question": "Are Previous Generation instances still being supported?", "answer": "Yes. Previous Generation instances are still fully supported.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-04T16:51:00.571259"}}
{"question": "What are the advantages of using Dense-storage instances?", "answer": "Dense-storage instances are designed for workloads that require high sequential read and write access to very large data sets, such as Hadoop distributed computing, massively parallel processing data warehousing, and log processing applications. They offer the best price per GB of storage and price per disk throughput compared to other EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-04T16:51:00.571609"}}
{"question": "How do Previous Generation instances compare to the latest generation instances?", "answer": "Previous Generation instances are still fully functional and supported, but the latest generation typically provides the best performance for the price. AWS encourages customers to take advantage of technological advancements found in the latest generation instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-04T16:51:00.572130"}}
{"question": "What types of workloads are High I/O instances targeted at?", "answer": "High I/O instances (Im4gn, Is4gen, I4i, I3, I3en) are targeted at workloads that demand low latency and high random I/O in addition to moderate storage density.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:51:05.386647"}}
{"question": "What are the key advantages of using Dense-storage instances compared to High I/O instances?", "answer": "Dense-storage instances (D3, D3en, D2) are optimized for applications that require high sequential read/write access and low cost storage for very large data sets, providing the best price/GB-storage and price/disk-throughput across other EC2 instances. In contrast, High I/O instances focus on low latency and high random I/O performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:51:05.386987"}}
{"question": "How does the disk throughput of Dense-storage instances compare to that of High I/O instances?", "answer": "The context does not provide specific details about the disk throughput of High I/O instances, but it states that Dense-storage instances can deliver up to 6.2 GiB/s read and 6.2 GiB/s write disk throughput. Therefore, a direct comparison of disk throughput between Dense-storage and High I/O instances cannot be made based on the provided information.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-04T16:51:05.387541"}}
{"question": "What type of storage do High I/O instances use?", "answer": "High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-04T16:51:10.451097"}}
{"question": "What are the advantages of using High I/O instances for applications?", "answer": "High I/O instances are optimized for applications that require millions of IOPS, providing very high, low latency, I/O capacity, which is beneficial for high-performance applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-04T16:51:10.451374"}}
{"question": "How do the storage capabilities of High I/O instances compare to those of dense-storage instances?", "answer": "High I/O instances use NVMe based local instance storage optimized for high IOPS and low latency, while dense-storage instances, such as H1, D2, D3, and D3en, provide high sequential read/write access to large data sets on local storage, geared more towards Hadoop distributed computing and data warehousing.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-04T16:51:10.451756"}}
{"question": "What types of applications are ideal for High I/O instances?", "answer": "High I/O instances are ideal for applications that require access to millions of low latency IOPS and can leverage data stores and architectures that manage data redundancy and availability. Example applications include NoSQL databases like Cassandra and MongoDB, in-memory databases like Aerospike, Elasticsearch and analytics workloads, and OLTP systems.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-04T16:51:16.943380"}}
{"question": "Why is it recommended to back up data periodically to Amazon S3 when using High I/O instances?", "answer": "It is recommended to back up data periodically to Amazon S3 for improved data durability because, like other Amazon EC2 instance types, the instance storage on Im4gn, Is4gen, I4i, I3, and I3en instances persists only during the life of the instance. Customers are expected to build resilience into their applications and utilize databases and file systems that support redundancy and fault tolerance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-04T16:51:16.943750"}}
{"question": "How do D3 and D3en instances improve upon D2 instances in terms of disk throughput?", "answer": "D3 and D3en instances improve upon D2 instances by providing up to 45% higher disk throughput for D3 instances and up to 100% higher disk throughput for D3en instances compared to D2 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-04T16:51:16.944255"}}
{"question": "What is the total storage capacity of D3en instances?", "answer": "D3en instances offer a total storage capacity of 336 TB, with 7 TB of storage per vCPU across 48 vCPUs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-04T16:51:21.034811"}}
{"question": "How do the memory specifications of D3en instances compare to D2 instances?", "answer": "D3en instances have half the memory per vCPU compared to D2 instances, despite offering a larger total storage capacity.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-04T16:51:21.035147"}}
{"question": "What encryption methods are used for storage volumes and network traffic in D3 and D3en instances?", "answer": "Data written onto the storage volumes of D3 and D3en instances is encrypted at rest using AES-256-XTS. Additionally, network traffic between D3 and D3en instances in the same VPC or a peered VPC is encrypted by default using a 256-bit key.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-04T16:51:21.035652"}}
{"question": "What are Flex instances in Amazon EC2 designed for?", "answer": "Flex instances in Amazon EC2 are designed to deliver baseline CPU performance with the ability to scale up to full CPU performance 95% of the time. They are ideal for workloads that don't fully utilize compute resources and can be used for instance sizes up to 16xlarge, which includes up to 64 vCPUs and 512 GiB memory. Suitable workloads for Flex instances include web and application servers, databases, virtual desktops, batch processing, microservices, caches, enterprise applications, Apache Kafka, and Elasticsearch.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-04T16:51:28.051935"}}
{"question": "When should I consider using Flex instances over comparable non-flex instances?", "answer": "You should consider using Flex instances over comparable non-flex instances when your workloads do not fully utilize compute resources and can benefit from lower pricing. Flex instances are particularly suitable for workloads that can operate effectively with baseline CPU performance, while non-flex instances are better for workloads requiring larger instance sizes or sustained performance in CPU, network, or EBS.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-04T16:51:28.052324"}}
{"question": "How do Flex instances compare to non-flex instances in terms of performance for specific workloads?", "answer": "Flex instances provide a baseline CPU performance of 40% and can scale up to 100% CPU for 95% of the time, making them suitable for workloads that fit within their instance sizes. In contrast, non-flex instances are recommended for workloads that require the largest instance sizes or have high demands for sustained CPU, network, or EBS performance, such as large application servers, high-performance computing, or CPU-based machine learning.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-04T16:51:28.052769"}}
{"question": "What determines the baseline performance and ability to burst for T2 instances?", "answer": "The baseline performance and ability to burst for T2 instances are governed by CPU Credits. Each T2 instance receives CPU Credits continuously, and the rate at which they receive these credits depends on the instance size.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-04T16:51:32.455164"}}
{"question": "How do Burstable Performance Instances like T2 utilize CPU Credits?", "answer": "Burstable Performance Instances like T2 utilize CPU Credits by accruing them when they are idle and consuming them when they are active. Each CPU Credit allows the instance to use the performance of a full CPU core for one minute.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-04T16:51:32.455435"}}
{"question": "How does the baseline CPU performance of a t2.large instance compare to that of a t2.medium instance?", "answer": "The baseline CPU performance of a t2.large instance is 60% of a core, while the baseline CPU performance of a t2.medium instance is 40% of a core. This means that the t2.large instance has a higher baseline performance compared to the t2.medium instance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-04T16:51:32.455932"}}
{"question": "What percentage of CPU can multithreaded applications use on a t2.2xlarge instance?", "answer": "Multithreaded applications can use 67.5% each of 2 cores on a t2.2xlarge instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-04T16:51:36.446361"}}
{"question": "Why might a user choose a t2.micro instance size instead of a t2.nano for running Microsoft Windows?", "answer": "A user might choose a t2.micro instance size instead of a t2.nano for running Microsoft Windows because operating systems with Graphical User Interfaces, like Microsoft Windows, consume significant memory and CPU, which may require a larger instance size to meet the minimum memory requirements for many use cases.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-04T16:51:36.446717"}}
{"question": "How do T2 Unlimited instances differ from dedicated CPU instances like M or C?", "answer": "T2 Unlimited instances differ from dedicated CPU instances like M or C in that T2 Unlimited instances provide a cost-effective platform that can sustain high CPU performance for as long as required, while dedicated CPU instances are recommended for workloads that consistently require CPU usage much higher than the baseline.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-04T16:51:36.447213"}}
{"question": "What happens to the CPU performance of a T2 instance when its CPU Credit balance reaches zero?", "answer": "When a T2 instance has a zero CPU Credit balance, its performance will remain at baseline CPU performance. For example, the t2.micro provides baseline CPU performance of 10% of a physical CPU core, and if the CPU Credit balance is approaching zero, CPU performance will be lowered to baseline performance over a 15-minute interval.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-04T16:51:43.237730"}}
{"question": "What are the advantages of using T4g instances over T3 instances?", "answer": "T4g instances deliver up to 40% better price performance over T3 instances, making them a more cost-effective option for burstable general purpose workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-04T16:51:43.238057"}}
{"question": "How do T2 instances compare to T4g instances in terms of pricing and performance?", "answer": "T2 instances can be purchased as On-Demand Instances, Reserved Instances, or Spot Instances, but they do not have the same performance efficiency as T4g instances. T4g instances provide up to 40% better price performance compared to T3 instances, while T2 instances have a baseline CPU performance that is limited to their CPU Credit balance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-04T16:51:43.238664"}}
{"question": "What benefit do customers receive during the T4g free trial period for running a t4g.small instance?", "answer": "Customers who run a t4g.small instance during the free-trial period will automatically get 750 free hours per month deducted from their bill for each month. These 750 hours are calculated in aggregate across all Regions where the t4g.small instances are used.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-04T16:51:50.684490"}}
{"question": "How does the T4g free trial program relate to the existing AWS Free Tier?", "answer": "The T4g free trial program is available in addition to the existing AWS Free Tier. Customers can take advantage of both the T4g free trial and the AWS Free Tier on eligible instances like t3.micro, t3.small, t4g.micro, t4g.small, C7i-flex.large, and M7i-flex.large.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-04T16:51:50.684828"}}
{"question": "How does the T4g free trial differ from the AWS Free Tier regarding customer eligibility?", "answer": "All existing and new customers with an AWS account are eligible for the T4g free trial, which is available even to those who have exhausted their AWS Free Tier usage. In contrast, the AWS Free Tier has its own usage limits and conditions that may not apply to customers who have exceeded them.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-04T16:51:50.685335"}}
{"question": "What is the limit of free hours available for t4g.small instances per month during the free trial?", "answer": "Customers can run t4g.small instances for a total of 750 free hours per month during the free trial.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-04T16:51:55.721927"}}
{"question": "What types of Amazon Machine Images (AMIs) are exempt from charges during the t4g.small free trial?", "answer": "Under the t4g.small free trial, there will be no Amazon Machine Image (AMI) charge for Amazon Linux 2, RHEL, and SUSE Linux AMIs available through the EC2 console Quick Start for the first 750 free hours per month.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-04T16:51:55.722269"}}
{"question": "How does using t4g.small instances in different Regions affect the free trial hour allocation?", "answer": "Using t4g.small instances in different Regions does not affect the free trial hour allocation, as customers can run instances across one or multiple Regions from a single cumulative bucket of 750 free hours per month.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-04T16:51:55.722801"}}
{"question": "What is the maximum number of free hours customers can use under the T4g free trial each month?", "answer": "Customers can use a maximum of 750 aggregate hours of usage under the T4g free trial each month.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-04T16:52:02.565221"}}
{"question": "How does the T4g free trial billing plan work for customers who exceed the 750 free hours?", "answer": "When the aggregate instance usage exceeds 750 hours for the monthly billing cycle, customers will be charged based on regular On-Demand pricing for the exceeded hours for that month. Additionally, if customers have a Compute Savings Plan or T4g Instance Savings Plan, the Savings Plan discount will be applied to On-Demand pricing for those hours exceeding the free trial hours.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-04T16:52:02.565558"}}
{"question": "What is the difference in access to the T4g free trial for customers using consolidated billing versus individual accounts?", "answer": "Customers using consolidated billing will have access to one free trial per Organization, which means each payer account gets a total aggregate of 750 free hours a month. In contrast, individual accounts not tied to consolidated billing can each access their own T4g free trial, allowing multiple accounts to have their own separate 750 free hours.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-04T16:52:02.566059"}}
{"question": "What happens to customers running t4g.small instances at the end of the free trial?", "answer": "At the end of the free trial on January 1, 2026, customers running on t4g.small instances will be automatically switched from the free trial plan to the On-Demand pricing plan or to the Reserved Instance (RI)/Savings Plan (SV) plan if they have purchased one. Accumulated credits will be set to zero.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-04T16:52:08.146916"}}
{"question": "What notification do customers receive before the free trial ends for t4g.small instances?", "answer": "Customers will receive an email notification seven days before the end of the free trial period, informing them that the free trial period will be ending in seven days.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-04T16:52:08.147255"}}
{"question": "How does billing for t4g.small instances differ for customers with the T4g Instance Savings Plan compared to those without it?", "answer": "For customers who have the T4g Instance Savings Plan or a Compute Savings Plan, the billing for t4g.small instances will apply the Savings Plan discount on their On-Demand pricing. In contrast, customers without these plans will be charged regular On-Demand pricing after the free trial ends.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-04T16:52:08.147863"}}
{"question": "What are some applications that benefit from using Compute Optimized instances?", "answer": "Compute Optimized instances are designed for applications that benefit from high compute power, including compute-intensive applications such as high-performance web servers, high-performance computing (HPC), scientific modeling, distributed analytics, and machine learning inference.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-04T16:52:14.372947"}}
{"question": "Why are Amazon EC2 C7g instances considered ideal for compute-intensive workloads?", "answer": "Amazon EC2 C7g instances are powered by the latest generation AWS Graviton3 processors, which provide the best price performance in Amazon EC2 for compute-intensive workloads. They are ideal for high performance computing (HPC), batch processing, electronic design automation (EDA), gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad-serving.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-04T16:52:14.374074"}}
{"question": "How do Amazon EC2 C6g instances compare to C5 instances in terms of price performance?", "answer": "Amazon EC2 C6g instances deliver up to 40% better price performance over C5 instances, making them a more cost-effective option for compute-intensive workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-04T16:52:14.374307"}}
{"question": "What is the default optimization for C6g instances?", "answer": "C6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-04T16:52:19.632261"}}
{"question": "How do C6g instances handle EBS storage access?", "answer": "C6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes, and options with local NVMe instance storage are also available through the C6gd instance types.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-04T16:52:19.632529"}}
{"question": "How does the network bandwidth of C6g instances compare to the bandwidth offered by EBS?", "answer": "C6g instances can deliver up to 25 Gbps of network bandwidth between instances with ENA when launched within a Placement Group, while they offer up to 19,000 Mbps of dedicated EBS bandwidth, indicating that network bandwidth is higher than EBS bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-04T16:52:19.632892"}}
{"question": "Are C4 instances EBS-optimized by default?", "answer": "Yes, each C4 instance type is EBS-optimized by default.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-04T16:52:23.802176"}}
{"question": "What are the benefits of changing C-state or P-state settings on a c4.8xlarge instance?", "answer": "Changing C-state or P-state settings on a c4.8xlarge instance can increase processor performance consistency, reduce latency, or tune the instance for a specific workload. This allows users to optimize performance based on their application needs, whether that be lower latency at the cost of higher core frequencies or lower-frequency sustained performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-04T16:52:23.802376"}}
{"question": "How do C6g instances compare to C5 instances in terms of price performance?", "answer": "C6g instances deliver up to 40% better price performance over C5 instances, making them more efficient for running advanced compute-intensive workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-04T16:52:23.802737"}}
{"question": "What are the maximum vCPUs and memory available with C6a instances?", "answer": "C6a instances provide up to 192 vCPUs and 384 GiB of memory.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T16:52:29.564547"}}
{"question": "How do C6i instances improve upon price performance compared to C5 instances?", "answer": "C6i instances offer up to 15% better price performance over C5 instances for a wide variety of workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T16:52:29.564801"}}
{"question": "What are the main differences in networking speed and bandwidth to Amazon Elastic Block Store between C5 and C6i instances?", "answer": "Both C5 and C6i instances provide up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store. However, C6i instances also offer improvements in price performance and memory specifications compared to C5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T16:52:29.564988"}}
{"question": "What are the main features of C5a instances?", "answer": "C5a instances deliver leading x86 price-performance for a broad set of compute-intensive workloads including batch processing, distributed analytics, data transformations, log analysis, and web applications. They feature 2nd Gen 3.3GHz AMD EPYC processors with up to 96 vCPUs and up to 192 GiB of memory. Additionally, C5ad instances come with local NVMe storage for workloads that require very low latency and high random read and write IOPS ability.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-04T16:52:36.542555"}}
{"question": "What types of applications are C5n instances best suited for?", "answer": "C5n instances are ideal for applications that require high network bandwidth and packet rate. They are suitable for high-performance computing (HPC), data lakes, network appliances, and applications that require inter-node communication and the Message Passing Interface (MPI).", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-04T16:52:36.542870"}}
{"question": "How do C5a instances compare to C4 instances in terms of vCPUs and memory?", "answer": "C5a instances offer up to 96 vCPUs and up to 192 GiB of memory, while C4 instances offer up to 36 vCPUs and 60 GiB of memory. This means that C5a instances provide significantly more vCPUs and memory compared to C4 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-04T16:52:36.543079"}}
{"question": "What percentage improvement in price/performance do C5 instances offer compared to C4 instances?", "answer": "C5 instances offer a 25% price/performance improvement relative to C4 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-04T16:52:40.943625"}}
{"question": "How does Intel AVX-512 contribute to the performance of floating point intensive applications on C5 instances?", "answer": "Intel AVX-512 enables significant improvements in delivered TFLOPS for floating point intensive applications by effectively extracting data level parallelism.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-04T16:52:40.943968"}}
{"question": "How do C5 instances compare to C3 and C4 instances regarding workload performance improvements?", "answer": "C5 instances provide a 25% price/performance improvement over C4 instances, benefiting a broad spectrum of workloads that currently run on C3 or C4 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-04T16:52:40.944191"}}
{"question": "What are the performance benefits of Hpc7g instances compared to previous-generation AWS Graviton-based instances?", "answer": "Hpc7g instances deliver up to 70% better performance and almost 3x better price performance compared to previous-generation AWS Graviton-based instances for compute-intensive HPC workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-04T16:52:46.423126"}}
{"question": "How do Hpc7a instances enhance core density and memory bandwidth compared to Hpc6a instances?", "answer": "Hpc7a instances feature 2x higher core density with up to 192 cores and offer 2.1x higher memory bandwidth throughput with up to 768 GB of memory compared to Hpc6a instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-04T16:52:46.423494"}}
{"question": "What is the network bandwidth provided by Hpc7g instances in comparison to Hpc7a instances?", "answer": "Hpc7g instances provide 200 Gbps network bandwidth, while Hpc7a instances offer 300 Gbps of Elastic Fabric Adapter (EFA) network bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-04T16:52:46.424007"}}
{"question": "What are the specifications of Hpc6a instances?", "answer": "Hpc6a instances are powered by 96 cores of 3rd Gen AMD EPYC processors with an all-core turbo frequency of 3.6 GHz and have 384 GiB RAM. They offer 100 Gbps EFA networking for high throughput internode communications to help run HPC workloads at scale.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-04T16:52:53.163544"}}
{"question": "What advantages do Hpc6a instances provide for HPC workloads?", "answer": "Hpc6a instances provide high throughput internode communications with 100 Gbps EFA networking, which is essential for running HPC workloads at scale. Their powerful 96-core processors and substantial RAM also contribute to their ability to handle compute-intensive tasks effectively.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-04T16:52:53.163805"}}
{"question": "How do Hpc6a instances compare to Hpc7g instances in terms of processor and network capabilities?", "answer": "Hpc6a instances are powered by 3rd Gen AMD EPYC processors with 96 cores, while Hpc7g instances are based on Arm-based Graviton3E processors with 64 physical cores. In terms of network capabilities, Hpc6a instances offer 100 Gbps EFA networking, whereas Hpc7g instances provide 200 Gbps network bandwidth optimized for traffic within the same VPC and also support EFA for increased performance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-04T16:52:53.164234"}}
{"question": "What are Hpc7a instances designed for?", "answer": "HPC-optimized EC2 Hpc7a instances are designed for applications that benefit from high-performance processors, such as large, complex simulations including computational fluid dynamics (CFD), numerical weather prediction, and multiphysics simulations.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-04T16:52:57.826830"}}
{"question": "How do Hpc7a instances enhance performance for HPC workloads compared to Hpc6a instances?", "answer": "Hpc7a instances enhance performance for HPC workloads compared to Hpc6a instances by featuring 4th Gen AMD EPYC processors with 2x higher core density (up to 192 cores), 2.1x higher memory bandwidth throughput (768 GB of memory), and 3x higher network bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-04T16:52:57.827169"}}
{"question": "How do the pricing models for Hpc7a instances compare to those of Hpc6id instances?", "answer": "Both Hpc7a instances and Hpc6id instances support similar pricing models, including the 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, EC2 On-Demand Instances, and EC2 Reserved Instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-04T16:52:57.827683"}}
{"question": "What are the supported AMIs for Hpc6id instances?", "answer": "Hpc6id instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-04T16:53:06.035476"}}
{"question": "What is the purpose of disabling hyperthreading in Hpc6id instances?", "answer": "Hyperthreading is disabled in Hpc6id instances to increase per-vCPU CPU throughput, which is essential for optimizing performance in memory-bound, data-intensive HPC workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-04T16:53:06.035830"}}
{"question": "How do the supported AMIs of Hpc6id instances compare to those of Hpc6a instances?", "answer": "Both Hpc6id and Hpc6a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, and FreeBSD 11.1 or later. However, Hpc6a instances additionally support Windows Server 2012, 2012 R2, 2016, and 2019, which are not supported by Hpc6id instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-04T16:53:06.036347"}}
{"question": "What are Amazon EC2 M6g instances powered by?", "answer": "Amazon EC2 M6g instances are powered by Arm-based AWS Graviton2 Processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-04T16:53:09.836108"}}
{"question": "How do M6g instances improve price/performance compared to M5 instances?", "answer": "M6g instances deliver up to 40% better price/performance over M5 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-04T16:53:09.836471"}}
{"question": "What advantages do AWS Graviton2 processors have over the first generation AWS Graviton processors?", "answer": "AWS Graviton2 processors deliver up to 7x performance, 4x the number of compute cores, 2x larger caches, 5x faster memory, and 50% faster per core encryption performance compared to first generation AWS Graviton processors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-04T16:53:09.836969"}}
{"question": "What is the maximum EBS bandwidth available on M6g instances?", "answer": "M6g instances offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-71", "source_tokens": 497, "generated_at": "2026-02-04T16:53:14.459476"}}
{"question": "What advantages do M6g instances provide for customers using open source software?", "answer": "Customers deploying applications built on open source software across the M instances will find the M6g instances an appealing option to realize the best price performance. Additionally, Arm developers can build their applications directly on native Arm hardware, which eliminates the need for cross-compilation or emulation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-71", "source_tokens": 497, "generated_at": "2026-02-04T16:53:14.459819"}}
{"question": "How does the network performance of M6g instances compare to other instance types?", "answer": "M6g instances support ENA based Enhanced Networking, which allows them to deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group. The context does not provide specific performance comparisons to other instance types, so a direct comparison cannot be made.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-71", "source_tokens": 497, "generated_at": "2026-02-04T16:53:14.460284"}}
{"question": "What is the architecture of the first-generation AWS Graviton Processors?", "answer": "The first-generation AWS Graviton Processors are based on the 64-bit Arm instruction set and feature Arm Neoverse cores, as well as custom silicon designed by AWS. The cores operate at a frequency of 2.3 GHz.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-72", "source_tokens": 497, "generated_at": "2026-02-04T16:53:19.465722"}}
{"question": "In what scenarios are A1 instances particularly beneficial?", "answer": "A1 instances are particularly beneficial for scale-out workloads that can fit within the available memory footprint. They are ideal for scale-out applications such as web servers, containerized microservices, and data/log processing. Additionally, they appeal to developers, enthusiasts, and educators within the Arm developer community.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-72", "source_tokens": 497, "generated_at": "2026-02-04T16:53:19.466056"}}
{"question": "How do the AMI requirements differ between M6g and A1 instances compared to other instances?", "answer": "Both M6g and A1 instances require the use of 'arm64' AMIs, while x86 AMIs are not compatible with these instances. This means that users must ensure they are using the correct architecture-specific AMIs when launching M6g and A1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-72", "source_tokens": 497, "generated_at": "2026-02-04T16:53:19.466590"}}
{"question": "What are the memory and networking capabilities of M6g instances compared to A1 instances?", "answer": "M6g instances support up to 16xlarge instance size and have 4GB of memory per vCPU, whereas A1 instances support up to 4xlarge and have 2GB of memory per vCPU. Additionally, M6g instances provide up to 25 Gbps of networking bandwidth compared to A1's 10 Gbps.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-04T16:53:24.048620"}}
{"question": "What storage interface do A1 instances support for EBS volumes?", "answer": "A1 instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes and do not support the blkfront interface.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-04T16:53:24.048960"}}
{"question": "In what scenarios should customers consider using A1 instances over M6g instances?", "answer": "Customers should use A1 instances for scale-out workloads that can run on multiple smaller cores and fit within the available memory footprint, as they offer significant cost benefits for such use cases.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-04T16:53:24.049492"}}
{"question": "What is the main performance improvement of EC2 M5 Instances compared to M4 Instances?", "answer": "The main performance improvement of EC2 M5 Instances compared to M4 Instances is based on their usage of the latest generation of Intel Xeon Scalable processors, delivering up to 20% improvement in price/performance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-04T16:53:30.824907"}}
{"question": "What advantages do M6i instances have over M5 instances in terms of compute performance and memory capabilities?", "answer": "M6i instances offer up to 15% better compute price performance over M5 instances and provide a new instance size with 128 vCPUs and 512 GiB of memory, which is 33% more than the largest M5 instance. Additionally, M6i instances have up to 20% higher memory bandwidth per vCPU compared to M5 instances, allowing for more efficient real-time analysis in data-intensive applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-04T16:53:30.825260"}}
{"question": "How do the networking capabilities of M6i instances compare to those of M5 instances?", "answer": "M6i instances provide up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, which is twice the networking bandwidth of M5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-04T16:53:30.825775"}}
{"question": "What is required for optimal networking performance on the EC2 M6i instances?", "answer": "For optimal networking performance on the EC2 M6i instances, an Elastic Network Adapter (ENA) driver update may be required.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-04T16:53:35.766784"}}
{"question": "What advantages does Intel AVX-512 provide for customers using the EC2 M5 and M6i families?", "answer": "Intel AVX-512 provides advantages such as accelerating performance for various workloads including scientific simulations, financial analytics, artificial intelligence, machine learning, 3D modeling, image and video processing, cryptography, and data compression. It also enhances the processing of encryption algorithms, reducing performance overhead for cryptography, allowing customers to deploy more secure data and services in distributed environments without compromising performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-04T16:53:35.767123"}}
{"question": "How do M5zn instances compare to z1d instances in terms of processor frequency and networking capabilities?", "answer": "M5zn instances feature a high frequency version of the 2nd Generation Intel Xeon Scalable processors with up to 4.5 GHz, while z1d instances have a high frequency version of the Intel Xeon Scalable processors with up to 4.0 GHz. Additionally, M5zn instances offer up to 100 Gbps networking performance, whereas the context does not specify the networking capabilities of z1d instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-04T16:53:35.767534"}}
{"question": "What types of processors power the EC2 High Memory (U-1) instances?", "answer": "EC2 High Memory (U-1) instances with 3 and 6 TiB are powered by Intel Xeon Platinum 8176M (Skylake) or 8280L (Cascade Lake) processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-04T16:53:41.530713"}}
{"question": "What are the primary use cases for Amazon EC2 High Memory instances?", "answer": "Amazon EC2 High Memory instances are purpose built to run large in-memory databases and business applications, including SAP deployments that rely on these databases.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-04T16:53:41.531077"}}
{"question": "How do U7i instances differ from U-1 instances in terms of memory and certification?", "answer": "U7i instances support up to 32 TiB of DDR5 memory and are the first 32TB virtualized instance in the cloud with SAP certification for standard sizing for both OLTP and OLAP workloads, while U-1 instances have a maximum memory of 32 TiB but do not specify DDR5 and are not highlighted for this specific certification in the context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-04T16:53:41.531519"}}
{"question": "What are the storage options available with High Memory instances?", "answer": "High Memory instances support Amazon EBS volumes for storage, and they are EBS-optimized by default.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-04T16:53:46.294735"}}
{"question": "What are the benefits of using High Memory virtualized instances compared to High Memory bare metal instances?", "answer": "Benefits of High Memory virtual instances over High Memory Metal instances include significantly better launch/reboot times, flexible purchase options (such as On-Demand, Savings Plan, Reserved Instances, Dedicated Hosts), choice of tenancy type, self-service options, and support for a higher number of EBS volumes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-04T16:53:46.295072"}}
{"question": "In what situations should a High Memory 'Metal' instance be used instead of a High Memory 'Virtualized' instance?", "answer": "High Memory 'Metal' instances should be used in specific situations such as when using OS versions that are not supported on High Memory Virtual instances, when applications need to run in non-virtualized mode to meet licensing/support requirements, when applications require access to hardware feature sets (like Intel VT-x), or when using a custom hypervisor (e.g., ESXi).", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-04T16:53:46.295570"}}
{"question": "What is the underlying hypervisor used by High Memory instances?", "answer": "High Memory instances use the lightweight Nitro Hypervisor that is based on core KVM technology.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-04T16:53:52.201821"}}
{"question": "How do C-states and P-states enhance performance management on High Memory instances?", "answer": "C-states allow for higher turbo frequencies, enabling speeds of up to 4.0 GHz, while P-states help lower performance variability by allowing users to pin all cores at P1 or higher P states, which is similar to disabling Turbo and running consistently at the base CPU clock speed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-04T16:53:52.202038"}}
{"question": "How do the purchase options differ between EC2 High Memory virtualized instances and EC2 High Memory metal instances?", "answer": "EC2 High Memory virtualized instances are available for purchase via On-Demand, 1-Yr and 3-Yr Savings Plan, and 1-Yr and 3-Yr Reserved Instance. In contrast, EC2 High Memory metal instances are only available for purchase as EC2 Dedicated Hosts on a 1-Yr and 3-Yr Reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-04T16:53:52.202210"}}
{"question": "What can you do with a Dedicated Host once it is allocated within your account?", "answer": "Once a Dedicated Host is allocated within your account, it will be standing by for your use. You can then launch an instance with a tenancy of 'host' using the RunInstances API, and can also stop, start, or terminate the instance through the API. Additionally, you can use the AWS Management Console to manage the Dedicated Host and the instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-04T16:53:59.126381"}}
{"question": "What is the purpose of the AWS Quick Start reference for SAP HANA deployments on High Memory instances?", "answer": "The AWS Quick Start reference for SAP HANA deployments allows you to rapidly deploy all the necessary SAP HANA building blocks on High Memory instances, following SAPs recommendations for high performance and reliability. These Quick Starts are modular and customizable, enabling you to layer additional functionality on top or modify them for your own implementations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-04T16:53:59.126726"}}
{"question": "How do the u-3tb1 and u-6tb1 High Memory instances compare to the u-9tb1, u-12tb1, u-18tb1, and u-24tb1 instances regarding their End of Sale status?", "answer": "The u-9tb1, u-12tb1, u-18tb1, and u-24tb1 High Memory instance types are reaching End of Sale as of June 20, 2025. However, there is no information provided regarding the End of Sale status for the u-3tb1 and u-6tb1 instances, so a comparison cannot be made based on the available context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-04T16:53:59.127275"}}
{"question": "What does End Of Sale (EOS) mean in the context of AWS High Memory U-1 instances?", "answer": "End-of-Sale (EOS) means that following the EOS date, the purchase of affected High Memory U-1 instances will be restricted. Access will be limited exclusively to existing U-1 customers, who are defined as those with documented U-1 instance usage within the 12-month period preceding the EOS date. These qualified customers will retain the ability to restart or launch impacted U-1 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-04T16:54:06.446026"}}
{"question": "Who qualifies as an existing Amazon EC2 High Memory U-1 instance customer?", "answer": "Existing Amazon EC2 High Memory U-1 instance customers are those who meet any of the following criteria: they have Amazon EC2 High Memory U-1 Instance Savings Plans (SP) or Standard Reserved Instances (RI) expiring on or after May 1, 2024; they have Amazon EC2 High Memory U-1 Compute SP or Convertible RI expiring on or after May 1, 2024, and have run Amazon EC2 High Memory U-1 instances on or after May 1, 2024; they have existing Amazon EC2 High Memory U-1 On-Demand Capacity Reservations (ODCR); or they have active Amazon EC2 High Memory U-1 on-demand (OD) instances at the EOS date.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-04T16:54:06.446375"}}
{"question": "How does the availability of U-1 instances change after the End Of Sale (EOS) date compared to before?", "answer": "After the End Of Sale (EOS) date, the purchase of affected High Memory U-1 instances will be restricted. Unlike before the EOS date, where purchasing was open to all customers, access will now be limited exclusively to existing U-1 customers who have documented usage within the 12-month period before the EOS date. These qualified customers will still have the ability to restart or launch impacted U-1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-04T16:54:06.446875"}}
{"question": "What improvements do the new U7i instances offer compared to the U-1 instances?", "answer": "The new U7i instances provide substantial improvements, including up to 140% better compute performance and twice the network and EBS bandwidth compared to their U-1 predecessors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-04T16:54:10.561132"}}
{"question": "Why should new customers choose U7i instances over U-1 instances?", "answer": "New customers should choose U7i instances because they are the latest offering and provide substantially better performance and value compared to the U-1 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-04T16:54:10.561475"}}
{"question": "How does the support for U-1 instances after the end-of-sale (EOS) dates compare for existing customers versus new customers?", "answer": "Existing customers will continue to have support for U-1 instances as long as their requests were submitted before the EOS date, while new customers are recommended to use U7i instances and do not have support for U-1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-04T16:54:10.561671"}}
{"question": "Will software and firmware updates still be provided for existing U-1 instances after the end-of-sales date?", "answer": "Yes, software updates and firmware updates will be provided for existing U-1 instances according to the standard support policies.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-04T16:54:14.974948"}}
{"question": "What are the benefits of migrating from U-1 instances to U7i instances?", "answer": "Migrating from U-1 instances to U7i instances provides significant performance improvements, including up to 140% more compute performance, 2X higher networking bandwidth, and 2X higher EBS bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-04T16:54:14.975284"}}
{"question": "How do the U-1 instances compare to U7i instances in terms of performance capabilities?", "answer": "U7i instances deliver significant performance improvements compared to U-1 instances, providing up to 140% more compute performance, as well as 2X higher networking and EBS bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-04T16:54:14.975884"}}
{"question": "What should existing Amazon EC2 High Memory U-1 customers do to migrate to U7i instances?", "answer": "Existing Amazon EC2 High Memory U-1 customers interested in migrating to U7i instances should reference the provided table that guides their migration options. Additionally, it is strongly encouraged to engage with their AWS account team to discuss specific requirements and explore available migration options tailored to their needs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-04T16:54:26.500140"}}
{"question": "Why is it important for customers to engage with their AWS account team during the migration process?", "answer": "It is important for customers to engage with their AWS account team during the migration process because each customer's requirements and configurations may be unique. The AWS account team can provide tailored guidance and explore all available migration options that best suit the customer's specific situation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-04T16:54:26.500495"}}
{"question": "How does the migration from U-1 instances to U7i instances differ based on instance size?", "answer": "The migration from U-1 instances to U7i instances differs based on the size of the instance. For example, a u-9tb1 can migrate to either U7i 8TB or 12TB, a u-12tb1 can migrate to U7i 12TB, a u-18tb1 can migrate to either U7i 16TB or 24TB, and a u-24tb1 can migrate to U7i 24TB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-04T16:54:26.500920"}}
{"question": "What are some ideal use cases for Amazon EC2 R6g instances?", "answer": "Amazon EC2 R6g instances are ideal for running memory-intensive workloads such as open-source databases, in-memory caches, and real-time big data analytics. They deliver significant price performance benefits for these memory-intensive workloads and are particularly appealing for customers deploying applications built on open source software across R instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-04T16:54:33.032457"}}
{"question": "Why would someone choose R6g instances over R5 instances?", "answer": "Someone would choose R6g instances over R5 instances because R6g instances deliver up to 40% better price performance compared to R5 instances. This significant improvement in price performance makes R6g instances a more cost-effective option for memory-intensive applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-04T16:54:33.032816"}}
{"question": "How do the storage options of R6g instances compare to those of other instance types?", "answer": "R6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. They only support Non-Volatile Memory Express (NVMe) interface for accessing EBS storage volumes. This may differ from other instance types that might have different bandwidth capabilities or support for various storage interfaces.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-04T16:54:33.033352"}}
{"question": "What processors power Amazon R6i instances?", "answer": "Amazon R6i instances are powered by 3rd Generation Intel Xeon Scalable processors, specifically the Ice Lake processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-04T16:54:36.208007"}}
{"question": "What advantages do R6i instances have over R5 instances in terms of compute price performance?", "answer": "R6i instances offer up to 15% better compute price performance compared to R5 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-04T16:54:36.208358"}}
{"question": "How does the memory bandwidth per vCPU of R6i instances compare to that of R5 instances?", "answer": "R6i instances provide up to 20% higher memory bandwidth per vCPU compared to R5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-04T16:54:36.208790"}}
{"question": "What is the maximum IOPS performance that R5b instances can deliver?", "answer": "R5b instances can deliver up to 260K IOPS of EBS performance, which is the fastest block storage performance on EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-04T16:54:40.669755"}}
{"question": "Why are R5b instances considered ideal for certain workloads?", "answer": "R5b instances are considered ideal for large relational database workloads because they are EBS-optimized and deliver up to 3x better EBS performance compared to the same sized R5 instances. They provide the necessary bandwidth and IOPS for performance-intensive applications like commerce platforms, ERP systems, and health record systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-04T16:54:40.670099"}}
{"question": "How do the storage capabilities of R5b instances compare to R5 instances?", "answer": "R5b instances deliver up to 3x better EBS performance compared to the same sized R5 instances, with up to 60 Gbps bandwidth and 260K IOPS, making them significantly more capable for workloads that require high storage performance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-04T16:54:40.670602"}}
{"question": "What type of storage do High Memory instances support?", "answer": "High Memory instances support Amazon EBS volumes for storage. They are EBS-optimized by default and offer up to 38Gbps of storage bandwidth to both encrypted and unencrypted EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-04T16:54:46.073464"}}
{"question": "What are the benefits of using X2gd instances for memory-bound workloads?", "answer": "X2gd instances are ideal for customers with Arm-compatible memory bound scale-out workloads, such as Redis and Memcached in-memory databases, as they provide low latency memory access and benefit from more memory per vCPU. They also suit relational databases like PostgreSQL, MariaDB, MySQL, and RDS Aurora, and are beneficial for memory intensive workloads like Apache Hadoop and real-time analytics due to their 1:16 vCPU to memory ratio.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-04T16:54:46.073821"}}
{"question": "How do X2gd instances compare to X1 instances in terms of price performance?", "answer": "X2gd instances deliver up to 55% better price performance compared to x86-based X1 instances. Additionally, X2gd instances offer the lowest cost per GiB of memory in Amazon EC2, making them more cost-effective for memory-intensive workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-04T16:54:46.074293"}}
{"question": "What types of workloads are suitable for X2gd instances?", "answer": "X2gd instances are suitable for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-04T16:54:51.421381"}}
{"question": "What are the advantages of using X2idn and X2iedn instances over X1 instances?", "answer": "X2idn and X2iedn instances deliver up to 50% higher compute price performance than comparable X1 instances and offer up to 3.8 TB of local NVMe SSD storage and up to 100 Gbps of networking bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-04T16:54:51.421780"}}
{"question": "How do X2gd instances differ from R5 and R6 instances in terms of memory capacity?", "answer": "X2gd instances offer sizes up to 1 TiB of memory, while R5 and R6 instances are suitable for memory bound workloads that need less than 1 TiB memory.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-04T16:54:51.422290"}}
{"question": "What are the key features of X2iezn instances?", "answer": "X2iezn instances feature the fastest Intel Xeon Scalable processors in the cloud, with an all-core turbo frequency up to 4.5 GHz. They have a 32:1 ratio of memory to vCPU and deliver up to 55% higher compute price performance compared to X1e instances. They are well-suited for workloads that require high single-threaded performance, high memory-to-vCPU ratio, and high speed networking, making them ideal for electronic design automation (EDA) workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-04T16:54:56.954515"}}
{"question": "In what scenarios would you recommend using X1 instances?", "answer": "X1 instances are recommended for running in-memory databases like SAP HANA, big data processing engines such as Apache Spark or Presto, and high performance computing (HPC) applications. They are certified by SAP to run production environments for next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS cloud.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-04T16:54:56.954860"}}
{"question": "How do X2iezn instances compare to X1e instances in terms of compute price performance?", "answer": "X2iezn instances deliver up to 55% higher compute price performance compared to X1e instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-04T16:54:56.955376"}}
{"question": "Which instances support configuring C-states and P-states?", "answer": "The instances that support configuring C-states and P-states are x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge, and x1.16xlarge.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-04T16:55:03.436157"}}
{"question": "What is the purpose of using C-states and P-states on the specified instances?", "answer": "C-states can be used to enable higher turbo frequencies, reaching up to 3.1 GHz with one or two core turbo. P-states can be used to lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo and running consistently at the base CPU clock speed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-04T16:55:03.436478"}}
{"question": "How do the supported Windows Server versions differ between x1.16xlarge and x1e.32xlarge instances?", "answer": "The x1.16xlarge instance supports Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit. In contrast, the x1e.32xlarge instance supports only Windows Server 2012 R2 and 2012 RTM.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-04T16:55:03.436991"}}
{"question": "Where can I find M1, C1, CC2, and HS1 instances now?", "answer": "M1, C1, CC2, and HS1 instances have been moved to the Previous Generation Instance page.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-04T16:55:06.818498"}}
{"question": "What does it mean for Previous Generation instances to be fully supported?", "answer": "Being fully supported means that Previous Generation instances are still operational and can be used without any limitations, despite being listed on a separate page.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-04T16:55:06.818838"}}
{"question": "How do Previous Generation instances compare to the latest generation in terms of performance?", "answer": "The latest generation typically provides the best performance for the price compared to Previous Generation instances, which may not offer the same level of performance due to technological advancements.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-04T16:55:06.819280"}}
{"question": "What types of workloads are Dense-storage instances designed for?", "answer": "Dense-storage instances are designed for workloads that require high sequential read and write access to very large data sets, such as Hadoop distributed computing, massively parallel processing data warehousing, and log processing applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-04T16:55:14.342911"}}
{"question": "What are the main differences between Dense-storage instances and High I/O instances?", "answer": "Dense-storage instances are optimized for applications that require high sequential read/write access and low-cost storage for very large data sets, providing the best price/GB-storage and price/disk-throughput across other EC2 instances. In contrast, High I/O instances are targeted at workloads that demand low latency and high random I/O with moderate storage density, providing the best price/IOPS across other EC2 instance types.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-04T16:55:14.343269"}}
{"question": "What is the maximum disk throughput that the d3en.12xlarge Dense HDD-storage instance can deliver?", "answer": "The largest current generation of Dense HDD-storage instances, d3en.12xlarge, can deliver up to 6.2 GiB/s read and 6.2 GiB/s write disk throughput with a 128k block size.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-04T16:55:14.343875"}}
{"question": "What type of notifications do D2 and H1 instances provide?", "answer": "D2 and H1 instances provide notifications for hardware failures.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-04T16:55:19.151429"}}
{"question": "Why is it recommended to build a degree of redundancy when using Dense HDD-storage volumes?", "answer": "It is recommended to build a degree of redundancy, such as using RAID 1/5/6 or file systems like HDFS and MapR-FS, because Dense HDD-storage volumes persist only for the life of the instance. This helps ensure fault tolerance and data protection.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-04T16:55:19.151785"}}
{"question": "How do Dense HDD-storage instances and Amazon EBS differ in terms of storage characteristics?", "answer": "Dense HDD-storage instances provide directly attached, high performance storage that is intended for high sequential read/write access to large data sets, making them suitable for applications like Hadoop distributed computing. In contrast, Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2, abstracting the details of the underlying storage media.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-04T16:55:19.152281"}}
{"question": "What types of applications are ideal for High I/O instances?", "answer": "High I/O instances are ideal for applications that require access to millions of low latency IOPS. Example applications include NoSQL databases like Cassandra and MongoDB, in-memory databases like Aerospike, Elasticsearch and analytics workloads, and OLTP systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-04T16:55:24.709353"}}
{"question": "Do High I/O instances support the TRIM command?", "answer": "Yes, Im4gn, Is4gen, I4i, I3, and I3en instances support the TRIM command, which allows the operating system to inform SSDs about blocks of data that are no longer in use.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-04T16:55:24.709695"}}
{"question": "How do High I/O instances compare to previous generation I2 instances in terms of storage access?", "answer": "High I/O instances, specifically Im4gn, Is4gen, I4i, I3, and I3en, offer NVMe only storage, which provides very high and low latency I/O capacity. In contrast, previous generation I2 instances allow legacy blkfront storage access.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-04T16:55:24.710209"}}
{"question": "What is the price difference between D3 instances and D2 instances?", "answer": "D3 instances are available at a price that is 5% lower than D2 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-04T16:55:30.588196"}}
{"question": "How do D3en instances compare to D2 instances in terms of disk throughput?", "answer": "D3en instances provide up to 100% higher disk throughput than D2 instances, while D3 instances provide up to 45% higher disk throughput than D2 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-04T16:55:30.588531"}}
{"question": "What performance benefits do D3 and D3en instances offer compared to D2 instances?", "answer": "D3 and D3en instances offer up to 30% higher compute performances than equivalent D2 instances, up to 45% and 100% higher disk throughput respectively, and they both offer Intel Advanced Vector Extensions (AVX 512), which provide up to 2X the FLOPS per cycle compared to AVX 2 on D2.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-04T16:55:30.589068"}}
{"question": "What happens to data stored on a local instance store when the instance terminates?", "answer": "Data stored on a local instance store will persist only as long as that instance is alive. Once the instance terminates, the data will no longer be available.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-04T16:55:35.596384"}}
{"question": "Why is it recommended to use Amazon EBS volumes for data requiring a higher level of durability?", "answer": "Amazon EBS volumes are recommended for data requiring a higher level of durability because they persist independently of the life of the instance, unlike data stored on a local instance store, which is lost when the instance terminates.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-04T16:55:35.596732"}}
{"question": "How do Throughput Optimized HDD (st1) volumes compare to Cold HDD (sc1) volumes in terms of performance?", "answer": "Throughput Optimized HDD (st1) volumes are designed for frequently accessed, throughput intensive workloads and can deliver a maximum throughput of 500 MB/s per volume, while Cold HDD (sc1) volumes are typically used for less frequently accessed data and have lower performance characteristics that are not detailed in the provided context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-04T16:55:35.597242"}}
{"question": "What is the primary use case for SC1 volumes?", "answer": "SC1 volumes are ideal for less frequently accessed workloads with large, cold datasets, as they provide extremely inexpensive storage for infrequently accessed data.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-04T16:55:40.923602"}}
{"question": "How do SSD-backed and HDD-backed EBS volumes differ in terms of their design focus?", "answer": "SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, while HDD-backed volumes are designed for throughput-intensive and big-data workloads, focusing on large I/O sizes and sequential I/O patterns.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-04T16:55:40.923938"}}
{"question": "What are the throughput capabilities of SC1 volumes compared to ST1 volumes?", "answer": "SC1 volumes can burst up to 80 MB/s per TB with a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. In contrast, the context does not provide specific throughput numbers for ST1 volumes, so a direct comparison of their throughput capabilities cannot be made.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-04T16:55:40.924450"}}
{"question": "Are EBS snapshots available through the Amazon EC2 APIs?", "answer": "Yes, EBS snapshots are only available through the Amazon EC2 APIs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-98", "source_tokens": 499, "generated_at": "2026-02-04T16:55:46.412608"}}
{"question": "What is the recommended procedure for taking consistent snapshots of Amazon EBS volumes attached to an instance?", "answer": "To ensure consistent snapshots on volumes attached to an instance, it is recommended to cleanly detach the volume, issue the snapshot command, and then reattach the volume. For Amazon EBS volumes that serve as root devices, it is recommended to shut down the machine to take a clean snapshot.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-98", "source_tokens": 499, "generated_at": "2026-02-04T16:55:46.412944"}}
{"question": "What happens to the original data in a shared snapshot when another user makes a copy of it?", "answer": "When another user makes a copy of your shared snapshot, they will first create a copy of the snapshot into their account. They can then modify their own copies of the data, but the data on your original snapshot and any other volumes created by other users from your original snapshot will remain unmodified.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-98", "source_tokens": 499, "generated_at": "2026-02-04T16:55:46.413448"}}
{"question": "What feature does EBS provide for data volumes and snapshots?", "answer": "EBS offers seamless encryption of data volumes and snapshots.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-04T16:55:50.533357"}}
{"question": "Why is EBS encryption important for users?", "answer": "EBS encryption better enables you to meet security and encryption compliance requirements.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-04T16:55:50.533726"}}
{"question": "How does the process of obtaining a list of Public Data Sets differ from learning more about EBS?", "answer": "To obtain a list of Public Data Sets, you can use the Public Data Sets Resource Center or view them in the AWS Management Console by choosing 'Amazon Snapshots.' In contrast, to learn more about EBS, you would refer to the Amazon EBS FAQ.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-04T16:55:50.533936"}}
{"question": "How do I mount an Amazon EFS file system on an EC2 instance?", "answer": "To mount an Amazon EFS file system on an Amazon EC2 Linux-based instance, you use the standard Linux mount command along with the file systems DNS name. Once mounted, you can work with the files and directories in your file system just like you would with a local file system.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-04T16:56:00.572554"}}
{"question": "What protocols does Amazon EFS use for file system access?", "answer": "Amazon EFS uses the NFSv4.1 protocol for file system access.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-04T16:56:00.572912"}}
{"question": "What is the difference between accessing Amazon EFS from an EC2 instance versus an on-premises server?", "answer": "Amazon EFS can be accessed from Amazon EC2 instances within a VPC directly using the standard Linux mount command. In contrast, on-premises servers can also mount Amazon EFS file systems, but they do so via AWS Direct Connect. Both types of access allow reading and writing to the file system using standard Linux tools.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-04T16:56:00.573388"}}
{"question": "How many Amazon EC2 instances can connect to a file system using Amazon EFS?", "answer": "Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-04T16:56:07.482744"}}
{"question": "What is Amazon EFS and what feature does it provide regarding EC2 instance connections?", "answer": "Amazon EFS is a file storage service that allows one to thousands of Amazon EC2 instances to connect to a file system concurrently.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-04T16:56:07.483107"}}
{"question": "How does the number of EC2 instances that can connect to Amazon EFS compare to traditional file systems?", "answer": "The context does not provide specific information about how the number of EC2 instances connecting to Amazon EFS compares to traditional file systems.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-04T16:56:07.483656"}}
{"question": "Is data stored on Amazon EC2 NVMe instance storage encrypted?", "answer": "Yes, all data is encrypted in an AWS Nitro hardware module prior to being written on the locally attached SSDs offered via NVMe instance storage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-04T16:56:11.842594"}}
{"question": "What encryption algorithm is used for Amazon EC2 NVMe instance storage?", "answer": "Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-04T16:56:11.842893"}}
{"question": "How does the lifetime of encryption keys on NVMe instance storage compare to traditional storage solutions?", "answer": "All keys on NVMe instance storage are irrecoverably destroyed on any de-allocation of the storage, including instance stop and instance terminate actions, which may differ from traditional storage solutions where keys might not be destroyed in such scenarios.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-04T16:56:11.843057"}}
{"question": "What is ENA Express?", "answer": "ENA Express is an enhancement on the Elastic Network Adapter that introduces the Scalable Reliable Datagram (SRD) protocol to traditional TCP and UDP networking. It operates transparently to the application and improves single flow bandwidths while reducing tail latencies in throughput intensive workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-04T16:56:16.901654"}}
{"question": "When should I use ENA Express?", "answer": "You should use ENA Express for applications that require high, single-flow throughput, such as distributed storage systems and live media encoding. These workloads benefit from high single flow bandwidth and low tail latency.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-04T16:56:16.902003"}}
{"question": "What is the relationship between ENA Express and the supported EC2 instance types?", "answer": "ENA Express is supported on Graviton-, Intel-, and AMD-based EC2 instances. It is compatible with compute-optimized, memory-optimized, general purpose, and storage-optimized based instances, indicating its versatility across different instance types.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-04T16:56:16.902542"}}
{"question": "What is EFA and what applications is it built for?", "answer": "EFA is a network interface built for high-performance computing (HPC) and machine learning (ML) applications, and it leverages the SRD protocol.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-04T16:56:22.151112"}}
{"question": "How does ENA Express operate differently compared to EFA?", "answer": "ENA Express helps you run your application transparently on TCP and UDP, while EFA requires a different network programming model that uses the LibFabric interface to pass communication to the Elastic Network Interface (ENI).", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-04T16:56:22.151457"}}
{"question": "What happens when one instance uses ENA Express and communicates with another instance that doesn't support it?", "answer": "When one instance runs ENA Express and communicates with another instance that doesn't support or hasn't enabled ENA Express, the instance running ENA Express will fallback to normal ENA operation. Consequently, you will not achieve any of the SRD performance benefits, but there will be no adverse effects.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-04T16:56:22.151974"}}
{"question": "What types of applications can benefit from using EFA?", "answer": "HPC applications can benefit from using EFA. These applications distribute computational workloads across a cluster of instances for parallel processing. Examples include computational fluid dynamics (CFD), crash simulations, and weather simulations. They are generally written using the Message Passing Interface (MPI) and have stringent requirements for inter-instance communication in terms of both latency and bandwidth. Applications using MPI and other HPC middleware that supports the libfabric communication stack can leverage EFA.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-04T16:56:27.516345"}}
{"question": "How does EFA enhance performance compared to traditional TCP channels?", "answer": "EFA enhances performance for tightly coupled HPC applications by providing lower and more consistent latency and higher throughput than traditional TCP channels. This capability allows tightly coupled HPC applications to scale better, thereby improving overall performance and efficiency in handling computational workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-04T16:56:27.516703"}}
{"question": "What is the relationship between EFA and the Message Passing Interface (MPI)?", "answer": "EFA works in conjunction with the Message Passing Interface (MPI) as most applications will use existing middleware like MPI to interface with EFA. This relationship is crucial because MPI is commonly used in HPC applications, which require stringent communication requirements that EFA is designed to meet, thereby enhancing the performance and scalability of these applications.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-04T16:56:27.517232"}}
{"question": "What additional functionality does an EFA ENI provide compared to an ENA ENI?", "answer": "An EFA ENI provides all the functionality of an ENA ENI, plus hardware support for applications to communicate directly with the EFA ENI without involving the instance kernel, enabling OS-bypass communication using an extended programming interface.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-04T16:56:32.391119"}}
{"question": "What is the primary reason EFA ENIs can only be attached at launch or to stopped instances?", "answer": "EFA ENIs can only be attached at launch or to stopped instances due to their advanced capabilities, which require specific conditions to be met for proper functionality.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-04T16:56:32.391467"}}
{"question": "How do the attachment options for EFA ENIs differ from those for ENA ENIs?", "answer": "EFA ENIs can only be attached at launch or to stopped instances, whereas the context does not specify restrictions for ENA ENIs, implying that they may have more flexible attachment options.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-04T16:56:32.391890"}}
{"question": "What are the benefits of using Enhanced Networking for applications?", "answer": "Enhanced Networking provides significantly improved performance, consistency of performance, and scalability for applications that benefit from high packet-per-second performance and/or low latency networking.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-04T16:56:36.693330"}}
{"question": "Which instance types support Enhanced Networking using the Intel 82599 Virtual Function interface?", "answer": "The instance types that support Enhanced Networking using the Intel 82599 Virtual Function interface include C3, C4, D2, I2, M4 (excluding m4.16xlarge), and R3 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-04T16:56:36.693688"}}
{"question": "How does Enhanced Networking compare to traditional networking implementations in terms of performance?", "answer": "Enhanced Networking using SR-IOV provides higher I/O performance and lower CPU utilization compared to traditional implementations, resulting in higher packet per second (PPS) performance, lower inter-instance latencies, and very low network jitter.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-04T16:56:36.694205"}}
{"question": "What is the maximum network speed supported by the Elastic Network Adapter (ENA) for certain instance types?", "answer": "The Elastic Network Adapter (ENA) supports network speeds of up to 200 Gbps for supported instance types.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-04T16:56:41.228438"}}
{"question": "Why are multiple network cards needed for EC2 instances?", "answer": "Multiple network cards are needed for EC2 instances to provide higher network bandwidth and improved packet-rate performance. By configuring specific EC2 instances to use multiple network cards for packet processing, the overall system performance can be increased.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-04T16:56:41.228724"}}
{"question": "How do accelerated instances compare to high network instances in terms of the number of network interfaces they can launch?", "answer": "Accelerated instances, such as p4d.24xlarge, can scale up to 15 network interfaces per network card. In comparison, high network instances like the c6in instances support an aggregate of 14 network interfaces, split evenly across two network cards (7 and 7).", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-04T16:56:41.229267"}}
{"question": "What are the two types of load balancers offered by the Elastic Load Balancing service?", "answer": "The two types of load balancers offered by the Elastic Load Balancing service are the Classic Load Balancer and the Application Load Balancer.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-04T16:56:44.979190"}}
{"question": "What are the ideal use cases for the Classic Load Balancer and the Application Load Balancer?", "answer": "The Classic Load Balancer is ideal for simple load balancing of traffic across multiple EC2 instances, while the Application Load Balancer is ideal for applications that require advanced routing capabilities, microservices, and container-based architectures.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-04T16:56:44.979537"}}
{"question": "How does the routing capability of the Classic Load Balancer differ from that of the Application Load Balancer?", "answer": "The Classic Load Balancer routes traffic based on either application or network level information, while the Application Load Balancer routes traffic based on advanced application level information, including the content of the request.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-04T16:56:44.980018"}}
{"question": "Why is there a limit of 5 Elastic IP addresses per region?", "answer": "There is a limit of 5 Elastic IP addresses per region because public (IPV4) internet addresses are a scarce resource, and Amazon EC2 is committed to using that space efficiently. If more than 5 Elastic IP addresses are needed, users must apply for a limit increase and provide justification for the additional addresses.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-04T16:56:51.083938"}}
{"question": "What is the reason for charging users when an Elastic IP address is not associated with a running instance?", "answer": "Users are charged when an Elastic IP address is not associated with a running instance to encourage efficient use of Elastic IP addresses. The charge is imposed as a small hourly fee for each address that is not actively connected to a running instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-04T16:56:51.084288"}}
{"question": "How does the public IP address provided by an instance differ from an Elastic IP address?", "answer": "The public IP address provided by an instance is associated exclusively with that instance until it is stopped, terminated, or replaced with an Elastic IP address. In contrast, an Elastic IP address is a static IP designed for long-lived internet routable endpoints, and it can be remapped to different instances as needed.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-04T16:56:51.084829"}}
{"question": "How can I configure the reverse DNS record for my Elastic IP address?", "answer": "You can configure the reverse DNS record of your Elastic IP address by filling out the designated form.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-04T16:56:55.661146"}}
{"question": "What is the purpose of configuring reverse DNS settings for internet-facing applications using IP-based mutual authentication?", "answer": "The purpose of configuring reverse DNS settings for internet-facing applications using IP-based mutual authentication is to ensure proper identification and validation of the IP address when sending emails from EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-04T16:56:55.661490"}}
{"question": "What is the difference between managing reverse DNS records directly and delegating management to AWS Customer Support?", "answer": "If you manage reverse DNS records directly, you can control your own reverse DNS PTR records using your authoritative DNS name servers, such as Amazon Route 53. In contrast, delegating management to AWS Customer Support allows AWS to handle the reverse DNS management for your Elastic IPs, but you will not have direct control over the records.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-04T16:56:55.661972"}}
{"question": "How can I control access to my EC2 instances?", "answer": "You can control access to your EC2 instances by using the Amazon EC2 security systems, which allow you to place your running instances into arbitrary groups of your choice. You can then specify which groups may communicate with which other groups, as well as which IP subnets on the Internet may talk to those groups.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-04T16:57:02.388840"}}
{"question": "Why is it important to secure my instances like any other server?", "answer": "It is important to secure your instances like any other server because despite having control over visibility and access through groups and IP subnets, your instances may still be vulnerable to unauthorized access and threats. Ensuring proper security measures helps protect your systems in a dynamic environment.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-04T16:57:02.389228"}}
{"question": "What is the difference between controlling access through EC2 security systems and using CloudTrail?", "answer": "Controlling access through EC2 security systems involves placing instances into groups and specifying communication rules between those groups and IP subnets, thus managing who can access your instances. On the other hand, using CloudTrail provides a history of all EC2 API calls made on your account, which is useful for security analysis and operational troubleshooting, but does not directly manage access controls.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-04T16:57:02.389740"}}
{"question": "What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?", "answer": "Metrics are received and aggregated at 1 minute intervals.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-04T16:57:07.551163"}}
{"question": "How does the granularity of the time period affect the representation of data points in Amazon CloudWatch graphs?", "answer": "When viewing the same time window in a 5 minute period versus a 1 minute period, the data points are displayed in different places on the graph. In a 5 minute period, a single aggregate data point is placed at the beginning of the time window, while in a 1 minute period, it is placed at the 1 minute mark. This difference can lead to variations in how the graph appears.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-04T16:57:07.551501"}}
{"question": "How does the Amazon CloudWatch monitoring charge vary by Amazon EC2 instance type compared to the metrics data retention for terminated instances?", "answer": "The Amazon CloudWatch monitoring charge does not vary by Amazon EC2 instance type. In contrast, metrics data for terminated Amazon EC2 instances is stored for 2 weeks, regardless of the instance type.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-04T16:57:07.552067"}}
{"question": "What does Amazon EC2 Auto Scaling do?", "answer": "Amazon EC2 Auto Scaling is a fully managed service designed to launch or terminate Amazon EC2 instances automatically. It helps ensure you have the correct number of EC2 instances available to handle the load for your application, maintain application availability through fleet management, detect and replace unhealthy instances, and scale your EC2 capacity up or down automatically according to defined conditions.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-04T16:57:14.744978"}}
{"question": "How does EC2 Auto Scaling help maintain application performance?", "answer": "EC2 Auto Scaling helps maintain application performance by automatically increasing the number of Amazon EC2 instances during demand spikes to handle increased load and automatically decreasing capacity during lulls to reduce costs. This ensures that the application can maintain its performance levels without unnecessary expenses.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-04T16:57:14.745338"}}
{"question": "What is the difference between the capacity-optimized and lowest-price allocation strategies in EC2 Auto Scaling?", "answer": "The capacity-optimized allocation strategy in EC2 Auto Scaling attempts to provision Spot Instances from the most available Spot Instance pools by analyzing capacity metrics, making it suitable for workloads that have a higher cost of interruption. In contrast, the lowest-price allocation strategy launches Spot Instances based strictly on diversification across the lowest-priced pools, focusing on cost rather than availability.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-04T16:57:14.745731"}}
{"question": "What happens to the data when I hibernate my instance?", "answer": "When you hibernate an instance, data from your EBS root volume and any attached EBS data volumes is persisted. Additionally, contents from the instances memory (RAM) are persisted to the EBS root volume. When the instance is restarted, it returns to its previous state and reloads the RAM contents.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-04T16:57:21.950139"}}
{"question": "Why is hibernating an instance beneficial for applications that take a long time to bootstrap?", "answer": "Hibernating an instance is beneficial because it allows you to get your instance and applications up and running quickly without the need to go through the long boot process each time. By starting instances, bringing them to a desired state, and then hibernating them, you create 'pre-warmed' instances that can be resumed quickly, thus reducing the time it takes for the instance to return to service.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-04T16:57:21.950489"}}
{"question": "What are the key differences between hibernating and stopping an instance?", "answer": "The key differences between hibernating and stopping an instance are that when you hibernate an instance, the RAM data is persisted, allowing the instance to resume from its previous state, while stopping an instance clears the RAM. In both cases, data from the EBS root volume and attached EBS data volumes is persisted, and the private IP address remains the same, as does the elastic IP address if applicable. Both options are available only for Amazon EBS backed instances, and local instance storage is not persisted.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-04T16:57:21.950977"}}
{"question": "How can I resume a hibernated instance?", "answer": "You can resume a hibernated instance by calling the StartInstances API as you would for a regular stopped instance. Additionally, you can do this through the console by selecting your instance, then clicking Actions > Instance State > Start.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-04T16:57:26.981127"}}
{"question": "What happens to the memory (RAM) data when an instance is hibernated?", "answer": "When an instance is hibernated, the memory (RAM) data is saved and stored on the EBS root volume. This RAM data is always encrypted during this process to ensure the protection of any sensitive content.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-04T16:57:26.981479"}}
{"question": "What is the difference between a hibernated instance and a stopped instance?", "answer": "A hibernated instance is in the 'Stopped' state, similar to a stopped instance. However, the key difference is that a hibernated instance saves the contents of its memory (RAM) to the EBS root volume, while a regular stopped instance does not save RAM contents.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-04T16:57:26.981995"}}
{"question": "What is the maximum duration an instance can remain hibernated?", "answer": "An instance cannot remain hibernated for more than 60 days. To keep the instance around for a longer duration, you need to resume the instance and go through Stop and Start without hibernation.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-04T16:57:31.881691"}}
{"question": "Why is it necessary to resume a hibernated instance for critical updates?", "answer": "It is necessary to resume a hibernated instance for critical updates because some upgrades and security patches can conflict with old hibernated instances. Resuming the instance allows you to perform a shutdown or reboot as needed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-04T16:57:31.882038"}}
{"question": "How does the support for hibernation differ between Windows and other operating systems?", "answer": "Hibernation is supported for Windows instances with up to 16 GB of RAM, while for other operating systems, it is supported for instances with less than 150 GB of RAM.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-04T16:57:31.882639"}}
{"question": "What is required for an AMI to support hibernation?", "answer": "To support hibernation, you can use any AMI that is configured for it. This includes AWS published AMIs that support hibernation by default, or you can create a custom image from an instance after following the hibernation pre-requisite checklist and configuring your instance appropriately.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-04T16:57:39.767959"}}
{"question": "Why is it important for the EBS root volume to be large enough when enabling hibernation?", "answer": "It is important for the EBS root volume to be large enough when enabling hibernation because space is allocated on the root volume to store the instance's memory (RAM). If the root volume does not have enough space to store the RAM contents and accommodate expected usage, such as the operating system and applications, hibernation will fail and the instance will shut down instead.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-04T16:57:39.768252"}}
{"question": "How do AWS published AMIs that support hibernation differ from custom images regarding configuration?", "answer": "AWS published AMIs that support hibernation come configured to support this feature by default, while custom images require the user to follow a hibernation pre-requisite checklist and configure the instance appropriately before they can support hibernation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-04T16:57:39.768880"}}
{"question": "What is VM Import/Export?", "answer": "VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. This service allows customers to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-04T16:57:47.936211"}}
{"question": "Why would a customer want to use VM Import/Export?", "answer": "A customer would want to use VM Import/Export to leverage their previous investments in building virtual machines by migrating them to Amazon EC2, thereby allowing them to create EC2 instances from their existing VM images and export EC2 instances back to VM formats.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-04T16:57:47.936555"}}
{"question": "How does the VMDK file format compare to the VHD file format?", "answer": "Both VMDK and VHD are file formats that specify a virtual machine hard disk encapsulated within a single file. VMDK is typically used by VMware's virtual IT infrastructures, while VHD is used by Microsoft Hyper-V and Citrix Xen. This indicates that VMDK is more aligned with VMware environments, whereas VHD is associated with Microsoft and Citrix virtualization platforms.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-04T16:57:47.936990"}}
{"question": "What steps should I follow to export a virtual machine using Citrix XenCenter?", "answer": "To export a virtual machine using Citrix XenCenter, open Citrix XenCenter and select the virtual machine you want to export. Then, under the Tools menu, choose 'Virtual Appliance Tools' and select 'Export Appliance' to initiate the export task. Once the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-04T16:57:55.859746"}}
{"question": "What are the key requirements for importing a virtual machine into Amazon EC2?", "answer": "The key requirements for importing a virtual machine into Amazon EC2 include ensuring that the virtual machine is in a stopped state before generating the VMDK or VHD image, as it cannot be in a paused or suspended state. It is also suggested to export the virtual machine with only the boot volume attached, while additional disks can be imported using the ImportVolume command and attached to the virtual machine using AttachVolume. Encrypted disks and encrypted image files are not supported, and you must ensure that you have all necessary rights and licenses to import into AWS and run any software included in your VM image.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-04T16:57:55.860117"}}
{"question": "What configurations are necessary for remote access after importing a VM to Amazon EC2?", "answer": "To ensure remote access after importing a VM to Amazon EC2, you must enable Remote Desktop (RDP) or Secure Shell (SSH) for remote access and verify that your host firewall allows access to RDP or SSH. Additionally, Windows VMs should be configured to use strong passwords for all users, including the administrator, while Linux VMs should be configured with a public key for SSH access.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-04T16:57:55.862532"}}
{"question": "What command is used to import a VMDK, VHD, or RAW file into Amazon EC2?", "answer": "The command used to import a VMDK, VHD, or RAW file into Amazon EC2 is ec2-import-instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-04T16:58:03.589223"}}
{"question": "What is the main purpose of the ec2-import-instance API?", "answer": "The main purpose of the ec2-import-instance API is to capture the parameters necessary to properly configure the Amazon EC2 instance properties, such as instance size, Availability Zone, and security groups, and to upload the disk image into Amazon S3.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-04T16:58:03.589559"}}
{"question": "How does using the AWS Management Portal for vCenter differ from using the ec2-import-instance API for importing a virtual machine?", "answer": "Using the AWS Management Portal for vCenter allows for a graphical user interface to import a virtual machine, where you can right-click on a VM and select 'Migrate to EC2'. This process handles exporting the VM from vCenter, uploading it to S3, and converting it into an EC2 instance automatically, while with the ec2-import-instance API, you must manually manage the import process through command-line tools.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-04T16:58:03.590076"}}
{"question": "What command is used to cancel an export task for an EC2 instance?", "answer": "The command used to cancel an export task for an EC2 instance is ec2-cancel-export-task.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-04T16:58:10.794350"}}
{"question": "What are the main restrictions when exporting an EC2 instance using VM Import/Export?", "answer": "When exporting an EC2 instance using VM Import/Export, the main restrictions are that you cannot export EBS data volumes, and EC2 instances with more than one network interface cannot be exported. If the instance is running, it will be momentarily stopped to snapshot the boot volume.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-04T16:58:10.794672"}}
{"question": "How do the costs associated with importing a VM compare to exporting a VM?", "answer": "When importing a VM, you are charged standard Amazon S3 data transfer and storage fees for uploading and storing your VM image file, along with standard Amazon EC2 instance hour and EBS service fees once the VM is imported. In contrast, when exporting a VM, you incur standard Amazon S3 storage fees for storing the exported VM image file, standard S3 data transfer charges when downloading the exported VM file, and standard EBS charges for storing a temporary snapshot of the EC2 instance. Additionally, to minimize storage charges, it is advised to delete the VM image file in S3 after downloading it, which is not mentioned for the import process.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-04T16:58:10.794884"}}
{"question": "What happens to my on-premise Microsoft Windows license key when I import a VM of Windows Server that has reached Microsoft EOS?", "answer": "Your on-premise Microsoft Windows license key that was associated with the VM is not used when running your imported VM as an EC2 instance. Therefore, you can reuse the license key for another VM within your on-premise environment.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-04T16:58:17.145866"}}
{"question": "What is license portability when importing Red Hat Enterprise Linux (RHEL) VM images?", "answer": "License portability allows you to maintain the RHEL licenses for imported instances. When you import RHEL VM images, you are responsible for supplying the operating system license, which can be managed using Cloud Access subscriptions for Red Hat Enterprise Linux.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-04T16:58:17.146232"}}
{"question": "How does the time it takes to import a VM vary based on disk image size and network speed?", "answer": "The time to import a virtual machine depends on the size of the disk image and the speed of your network connection. For example, importing a 10 GB Windows Server 2008 SP2 VMDK image takes about 2 hours over a 10 Mbps network connection, but it may take significantly longer with a slower network connection or a larger disk to upload.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-04T16:58:17.146732"}}
{"question": "What tools are available for importing VMs into Amazon EC2?", "answer": "You can use the EC2 CLI and API, as well as the AWS Management Portal for vCenter to import VMs into Amazon EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-04T16:58:22.504887"}}
{"question": "How can imported VMs be accessed after they are brought into Amazon EC2?", "answer": "Once the VMs are imported into Amazon EC2, the resulting instances are available for use via the AWS Management Console.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-04T16:58:22.505231"}}
{"question": "What are the differences between using the EC2 CLI and the AWS Management Portal for vCenter for VM imports?", "answer": "The context does not provide specific differences between using the EC2 CLI and the AWS Management Portal for vCenter for VM imports; it only states that both options are available for importing VMs into Amazon EC2.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-04T16:58:22.505768"}}
{"question": "How does Amazon EC2 billing commence and end?", "answer": "Billing for Amazon EC2 begins when the boot sequence of an AMI instance is initiated. It ends when the instance is terminated, which can happen through a web services command, by running 'shutdown -h', or due to instance failure. When an instance is stopped, it is shut down and no hourly usage charges or data transfer fees are incurred, but storage charges for Amazon EBS volumes still apply.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-04T16:58:29.674649"}}
{"question": "What factors determine how I am charged for my Amazon EC2 usage?", "answer": "You are charged based on your actual usage of Amazon EC2. Pricing is displayed as an hourly rate, but you may be billed by the hour or by the second (with a minimum of 60 seconds) depending on the instance type you choose. Partial instance-hours are billed according to actual usage, and data transferred between AWS services in different regions incurs standard inter-region data transfer rates.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-04T16:58:29.674999"}}
{"question": "How is data transfer charged when using two EC2 instances in different availability zones compared to different regions?", "answer": "When using two EC2 instances in different availability zones, each instance is charged for its data in and out at corresponding Data Transfer rates. However, when instances are in different regions, the first instance is charged at 'Data Transfer Out from EC2 to Another AWS Region' and the second instance is charged at 'Data Transfer In from Another AWS Region'. This indicates that data transfer charges differ based on whether the instances are in the same availability zone or different regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-04T16:58:29.675485"}}
{"question": "How does data transfer between two instances get charged?", "answer": "Data transferred between two instances is charged at Inter-Region Data Transfer Out for the first instance and at Inter-Region Data Transfer In for the second instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-04T16:58:34.863463"}}
{"question": "What is the billing method for EC2 usage in a monthly bill?", "answer": "EC2 charges in the monthly bill are calculated on a per second basis, but for consistency, the bill shows cumulative usage for each instance in decimal hours. For example, an instance running for 1 hour 10 minutes and 4 seconds would appear as 1.1677 in the bill.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-04T16:58:34.863798"}}
{"question": "What is the difference in billing for data transfer charges between two instances and EC2 usage charges?", "answer": "Data transfer charges between two instances are specifically based on Inter-Region Data Transfer rates, with charges applied for data transfer out for the first instance and data transfer in for the second. In contrast, EC2 usage charges are calculated on a per second basis but displayed in cumulative decimal hours on the monthly bill.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-04T16:58:34.864320"}}
{"question": "What steps do I need to take to request free data transfer out to the internet when moving my data out of AWS?", "answer": "To request free data transfer out to the internet when moving your data out of AWS, you should follow these steps: 1) Contact your dedicated AWS account team, if applicable, to inform them of your plans. 2) Review the criteria and process on the relevant page, especially if you are an EU customer under the EU Data Act. 3) Contact AWS Customer Support and indicate your request is for 'free data transfer to move off AWS.' Provide the necessary information for them to evaluate your eligibility for free data transfer. 4) Wait for AWS Customer Support to approve your move; if approved, you will receive a temporary credit for the cost of data transfer based on your stored data volume. You then have 90 days to complete your move off AWS.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-04T16:58:44.935124"}}
{"question": "What is the importance of contacting AWS Customer Support before starting my move off AWS?", "answer": "It is important to contact AWS Customer Support before starting your move off AWS because they need to review your moving plans, evaluate your eligibility for free data transfer out, and calculate the appropriate credit amount. Starting your move before receiving approval for your credit request could result in incurring charges for data transfer out, which you are attempting to avoid.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-04T16:58:44.935472"}}
{"question": "How does the approval process for free data transfer out differ for EU customers under the EU Data Act?", "answer": "The approval process for free data transfer out for EU customers under the EU Data Act involves additional criteria and processes mentioned in the AWS EU Data Act Addendum. While all customers must contact AWS Customer Support and follow the same general steps, EU customers specifically need to review the provisions in the EU Data Act Addendum to understand their rights and obligations, especially regarding the switching process.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-04T16:58:44.936012"}}
{"question": "What are the eligibility requirements for free data transfer out from AWS?", "answer": "Only customers with an active AWS account in good standing are eligible for free data transfer out.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-04T16:58:51.435503"}}
{"question": "What should I do if I have less than 100 GB of data stored in my AWS account and I want to transfer more data off AWS?", "answer": "If you currently have less than 100GB of data stored in your AWS account but may need to transfer more data as part of your move off AWS, you should contact Customer Support.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-04T16:58:51.435854"}}
{"question": "How does the process for free data transfer out differ for customers with less than 100 GB of data compared to those with more?", "answer": "Customers with less than 100 GB of data stored in their AWS account can move their data off AWS for free under the existing 100 GB monthly free tier without following the process described on the page, while customers with more than 100 GB are required to request pre-approval for free data transfer out.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-04T16:58:51.436237"}}
{"question": "Will I incur any data transfer inter-region charges when migrating data from Singapore to Malaysia or Thailand?", "answer": "AWS offers eligible customers free data transfer inter-region (DTIR) when they migrate all or a portion of their data from Singapore region to Malaysia or Thailand region.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-04T16:58:59.081804"}}
{"question": "What steps do I need to take to request free data transfer inter-region when migrating from Singapore to Malaysia or Thailand?", "answer": "To request free DTIR when migrating from Singapore to Malaysia or Thailand, follow these steps: 1) Contact your dedicated AWS account team to inform them of your plans. 2) Review the criteria and process outlined in the documentation. 3) Contact AWS Customer Support and indicate your request is for free DTIR to migrate data. Provide the necessary information for them to evaluate your eligibility. 4) If approved, you will receive a temporary credit for DTIR costs based on the volume of data you want to migrate, and you will have 60 days to complete the migration. 5) After migration, delete the migrated data from Singapore within 30 days. 6) You can repeat the process for multiple rounds of data transfers.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-04T16:58:59.082156"}}
{"question": "What are the criteria for eligibility for free DTIR when migrating from Singapore to Malaysia or Thailand?", "answer": "The criteria for eligibility for free DTIR when migrating from Singapore to Malaysia or Thailand include: 1) Only customers with an active AWS account in good standing are eligible. 2) If your plans change or you cannot complete your inter-region migration within 60 days, you must notify AWS Customer Support.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-04T16:58:59.082589"}}
{"question": "What charges are eligible for credits when migrating from Singapore to Malaysia or Thailand region?", "answer": "Only DTIR charges in support of your Singapore to Malaysia or Thailand region migration are eligible for credits. Standard service charges for the use of AWS services are not included.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-04T16:59:04.060996"}}
{"question": "Why is it necessary to request AWS pre-approval for free DTIR before migrating data?", "answer": "It is necessary to request AWS pre-approval for free DTIR because AWS customers make hundreds of millions of data transfers each day, and AWS generally does not know the reason for any given data transfer. By informing AWS beforehand, they can verify that your data transfer is specifically to support your Singapore to Malaysia or Thailand inter-region migration.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-04T16:59:04.061359"}}
{"question": "What could happen if AWS determines that DTIR was used for purposes other than migrating data?", "answer": "If AWS determines that your use of DTIR was for a purpose other than migrating data and workloads from Singapore to Malaysia or Thailand region, they may charge you for the DTIR that had been credited.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-04T16:59:04.061864"}}
{"question": "What is a Convertible RI?", "answer": "A Convertible RI is a type of Reserved Instance with attributes that can be changed during the term.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-04T16:59:09.633521"}}
{"question": "Why would a customer choose to purchase a Convertible RI instead of a Standard RI?", "answer": "A customer would choose to purchase a Convertible RI instead of a Standard RI if they can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-04T16:59:09.633866"}}
{"question": "What is the difference between the term length options available for Convertible RIs and Standard RIs?", "answer": "Both Convertible RIs and Standard RIs are available for purchase for a one-year or three-year term, so there is no difference in the term length options available for these two types of Reserved Instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-04T16:59:09.634369"}}
{"question": "What is the total value of a Convertible RI?", "answer": "The total value is the sum of all expected payments that youd make during the term for the RI.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-04T16:59:16.797286"}}
{"question": "How does EC2 ensure the value is maintained when converting Convertible RIs?", "answer": "When you exchange one Convertible RI for another, EC2 ensures that the total value of the Convertible RIs is maintained through a conversion. This means that if you are converting your RI with a total value of $1000 for another RI, you will receive a quantity of Convertible RIs with a value thats equal to or greater than $1000. You cannot convert your Convertible RI for Convertible RI(s) of a lesser total value.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-04T16:59:16.797630"}}
{"question": "What is the difference in cost handling between converting All Upfront Convertible RIs and No Upfront Convertible RIs?", "answer": "When converting All Upfront Convertible RIs, there is a true-up charge that is calculated based on the difference in upfront value between the original and desired Convertible RIs. In contrast, when converting No Upfront Convertible RIs, there is no true-up charge; however, the amount you pay on an hourly basis before the exchange must be greater than or equal to the amount you pay on a total hourly basis after the exchange.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-04T16:59:16.797846"}}
{"question": "What happens when I exchange a No Upfront Convertible RI for another RI that costs less per hour?", "answer": "When you exchange a No Upfront Convertible RI (A) for another RI (B) that costs $0.06/hr, you will receive two RIs of B because the amount you pay on an hourly basis for B must be greater than or equal to what you were paying for A.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-04T16:59:28.031763"}}
{"question": "How does the exchange process work for Convertible RIs?", "answer": "The exchange process for Convertible RIs involves calculating the minimal number of Convertible RIs you will receive based on the value of the RIs you are trading in, ensuring that the result of the exchange provides RIs of equal or greater value.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-04T16:59:28.032149"}}
{"question": "What are the limitations when choosing instance types for exchanging Convertible RIs compared to their payment options?", "answer": "When exchanging Convertible RIs, you can only exchange into RIs that are currently offered by AWS, while you have the option to upgrade the payment option associated with your RI, such as exchanging No Upfront RIs for Partial or All Upfront RIs for better pricing. However, you cannot downgrade from All Upfront to No Upfront or from Partial Upfront to No Upfront.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-04T16:59:28.032576"}}
{"question": "What does Amazon EC2 Fleet allow users to do?", "answer": "Amazon EC2 Fleet allows users to provision compute capacity across different instance types, Availability Zones, and across On-Demand, Reserved Instances (RI), and Spot Instances purchase models with a single API call to help optimize scale, performance, and cost.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-04T16:59:34.147204"}}
{"question": "How does Amazon EC2 Fleet utilize Reserved Instance discounts?", "answer": "Amazon EC2 Fleet utilizes Reserved Instance discounts by applying them to On-Demand instances launched by EC2 Fleet if they match an existing RI. For example, if a user owns Regional RIs for M4 instances and specifies only M4 instances in their EC2 Fleet, the RI discounts will be automatically applied to that usage of M4.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-04T16:59:34.147567"}}
{"question": "What is the difference between Amazon EC2 Fleet and Spot Fleet?", "answer": "Amazon EC2 Fleet and Spot Fleet offer the same functionality and there is no requirement to migrate from Spot Fleet to EC2 Fleet if you are already using Spot Instances with Spot Fleet. Therefore, the main difference lies in the fact that users can choose to use either service without losing functionality.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-04T16:59:34.148005"}}
{"question": "What are the three allocation strategies provided by EC2 Fleet for Spot Instances?", "answer": "The three allocation strategies provided by EC2 Fleet for Spot Instances are capacity-optimized, lowest price, and diversified.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-04T16:59:38.833250"}}
{"question": "Why would one choose the capacity-optimized allocation strategy for Spot Instances?", "answer": "One would choose the capacity-optimized allocation strategy for Spot Instances because it attempts to provision Spot Instances from the most available Spot Instance pools by analyzing capacity metrics, making it a good choice for workloads that have a higher cost of interruption, such as big data and analytics, image and media rendering, machine learning, and high performance computing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-04T16:59:38.833582"}}
{"question": "How does the diversified strategy for Spot Instances differ from the lowest price strategy?", "answer": "The diversified strategy for Spot Instances allows you to provision Spot Instances across multiple Spot pools to maintain your fleets target capacity, while the lowest price strategy allows you to provision Spot Instances in pools that provide the lowest price per unit of capacity at the time of the request.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-04T16:59:38.834035"}}
{"question": "What is the maximum duration for which you can reserve GPU capacity using Amazon EC2 Capacity Blocks?", "answer": "You can reserve GPU capacity using Amazon EC2 Capacity Blocks for durations up to 6 months.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-04T16:59:44.779436"}}
{"question": "Why are Amazon EC2 Capacity Blocks beneficial for machine learning workloads?", "answer": "Amazon EC2 Capacity Blocks are beneficial for machine learning workloads because they provide easy access to the highest-performing GPU instances in Amazon EC2, ensuring capacity availability even during industry-wide GPU shortages. They enable you to plan your ML development with confidence and are delivered in EC2 UltraClusters, which offer the best network latency and throughput performance available in EC2.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-04T16:59:44.779800"}}
{"question": "How do EC2 Capacity Blocks differ from On-Demand Capacity Reservations in terms of use cases?", "answer": "EC2 Capacity Blocks should be used when you need short-term capacity assurance for tasks such as training or fine-tuning ML models, running experiments, building prototypes, or managing surges in demand for ML applications. In contrast, On-Demand Capacity Reservations are recommended for all other workload types that require capacity assurance, such as business-critical applications, regulatory requirements, or disaster recovery.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-04T16:59:44.780282"}}
{"question": "What happens when the start time of an EC2 Capacity Block arrives?", "answer": "When the start time of an EC2 Capacity Block arrives, EC2 will emit an event through Amazon EventBridge to indicate that the reservation is now active and available for use.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-04T16:59:50.027306"}}
{"question": "How can I utilize an active EC2 Capacity Block once it is available?", "answer": "To use an active EC2 Capacity Block, you need to select the 'Capacity Block' purchase option and target the capacity reservation ID for your EC2 Capacity Block while launching EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-04T16:59:50.027540"}}
{"question": "What is the relationship between the expiration of an EC2 Capacity Block and the termination of running instances?", "answer": "As the EC2 Capacity Block end time approaches, EC2 will emit an event through EventBridge to notify you that your reservation is ending soon. Around 30 minutes before the EC2 Capacity Block expires, AWS will begin terminating any running instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-04T16:59:50.027934"}}
{"question": "What is the latest date I can purchase an EC2 Capacity Block?", "answer": "You can purchase an EC2 Capacity Block as far out as eight weeks into the future.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-04T16:59:54.110338"}}
{"question": "Why is it recommended to use the widest date range possible when searching for EC2 Capacity Blocks?", "answer": "It is recommended to use the widest date range possible in your search requests for the best chance at finding an EC2 Capacity Block that meets your specifications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-04T16:59:54.110674"}}
{"question": "How do EC2 Capacity Blocks differ from Savings Plans and Reserved Instances in terms of discounts?", "answer": "EC2 Capacity Blocks are not covered by Savings Plans or Reserved Instances (RI) discounts, meaning you cannot apply these discounts to EC2 Capacity Blocks.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-04T16:59:54.110883"}}
{"question": "What is the purpose of Capacity Reservations in Amazon EC2?", "answer": "The purpose of Capacity Reservations in Amazon EC2 is to allow users to reserve compute capacity for their instances in a specific Availability Zone for any duration. This ensures that users always have access to Amazon EC2 capacity when needed, for as long as required.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-04T17:00:01.598089"}}
{"question": "In what scenarios should I consider using Capacity Reservations?", "answer": "You should consider using Capacity Reservations if you have strict capacity requirements for current or future business-critical workloads that demand a certain level of long or short-term capacity assurance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-04T17:00:01.598452"}}
{"question": "How do the costs compare between using Capacity Reservations and running EC2 instances on-demand?", "answer": "Capacity Reservations are charged at the equivalent On-Demand rate, regardless of whether you run instances in the reserved capacity or not. If you do not use the reservation, it will appear as an unused reservation on your Amazon EC2 bill. Conversely, when you run an instance that matches the reservation attributes, you only pay for the instance and not for the reservation itself, while with On-Demand instances, you pay for the instances you run without a reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-04T17:00:01.598960"}}
{"question": "What is a Regional RI in the context of AWS EC2?", "answer": "A Regional RI is an EC2 RI that is scoped to an AWS Region. Unlike Zonal RIs, which are scoped to an Availability Zone within a Region, Regional RIs can provide benefits that apply across the entire region.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-04T17:00:06.712301"}}
{"question": "How does an 'Open' match criteria for Capacity Reservations work?", "answer": "An 'Open' match criteria for Capacity Reservations will automatically cover matching running instances or newly launched instances, as long as there is enough excess capacity in the reservation. This means that instances that meet the specified criteria can utilize the reservation without needing to be explicitly designated.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-04T17:00:06.712545"}}
{"question": "What can be modified in a Capacity Reservation after it has started?", "answer": "You can modify the number of instances, the match criteria, and the end date of a Capacity Reservation after it has started. However, running instances remain unaffected by any changes made to the Capacity Reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-04T17:00:06.712987"}}
{"question": "What are the steps to share EC2 Capacity Reservations using AWS RAM?", "answer": "To share EC2 Capacity Reservations using AWS RAM, you need to follow three steps: first, create a Resource Share using AWS RAM; second, add the resources (Capacity Reservations) to the Resource Share; and third, specify the target accounts that you wish to share the resources with.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-04T17:00:12.067169"}}
{"question": "What is the purpose of AWS RAM in the context of EC2 Capacity Reservations?", "answer": "AWS RAM (Resource Access Manager) is used to share EC2 Capacity Reservations among different accounts, allowing users to manage and allocate resources more effectively across their organization.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-04T17:00:12.067503"}}
{"question": "How does the process of sharing EC2 Capacity Reservations differ from simply creating them?", "answer": "Creating EC2 Capacity Reservations involves reserving capacity for your EC2 instances, while sharing these reservations using AWS RAM involves creating a Resource Share, adding the reservations to it, and specifying target accounts. The former focuses on resource allocation, while the latter focuses on resource sharing among multiple accounts.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-04T17:00:12.067898"}}
{"question": "What is a Reserved Instance (RI)?", "answer": "A Reserved Instance (RI) is an EC2 offering that provides you with a significant discount on EC2 usage when you commit to a one-year or three-year term.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-04T17:00:17.790317"}}
{"question": "What are the advantages of purchasing a regional RI over a zonal RI?", "answer": "The advantages of purchasing a regional RI over a zonal RI include not requiring a capacity reservation and having AZ and instance size flexibility, which allows for broader applicability of the RIs discounted rate across different Availability Zones and instance sizes within the region.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-04T17:00:17.790657"}}
{"question": "How do Standard RIs and Convertible RIs differ in terms of flexibility?", "answer": "Standard RIs offer a significant discount on EC2 instance usage when you commit to a particular instance family, while Convertible RIs allow you the option to change your instance configuration during the term and still receive a discount on your EC2 usage.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-04T17:00:17.791166"}}
{"question": "What does AZ flexibility allow you to do with your regional RIs?", "answer": "AZ flexibility allows you to apply your regional RIs discounted rate to usage in any Availability Zone (AZ) within a Region.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-143", "source_tokens": 507, "generated_at": "2026-02-04T17:00:22.881467"}}
{"question": "Why is instance size flexibility beneficial for users of regional RIs?", "answer": "Instance size flexibility is beneficial because it allows the discounted rate of a regional RI to apply to usage of any size within an instance family, enabling users to optimize their resource usage without being limited to a specific instance size.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-143", "source_tokens": 507, "generated_at": "2026-02-04T17:00:22.881747"}}
{"question": "How does the flexibility of regional RIs compare to zonal RIs regarding the application of discounted rates?", "answer": "Regional RIs provide AZ and instance size flexibility, allowing discounted rates to apply across any AZ in a Region and to any size within an instance family. In contrast, zonal RIs do not have this flexibility and are tied to a specific AZ.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-143", "source_tokens": 507, "generated_at": "2026-02-04T17:00:22.882136"}}
{"question": "What is the normalization factor for a large instance in EC2's instance size flexibility?", "answer": "The normalization factor for a large instance in EC2's instance size flexibility is 4.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-04T17:00:28.802248"}}
{"question": "How does instance size flexibility benefit users with Reserved Instances (RIs) in EC2?", "answer": "Instance size flexibility allows users with Reserved Instances (RIs) to apply the discounted rate of RIs to the normalized usage of different instance sizes within the same instance family, enabling them to utilize their RIs more effectively across various instance sizes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-04T17:00:28.802606"}}
{"question": "What modifications can be made to a Reserved Instance (RI) during its term, and how do they compare?", "answer": "During its term, you can modify the Availability Zone (AZ) of the RI, change the scope of the RI from AZ to Region or vice versa, and modify instance sizes within the same instance family. In contrast, Convertible RIs allow you to change the instance type, operating system, tenancy, or payment option of your RI. This shows that while standard RIs have limited modification options, Convertible RIs offer more flexibility in terms of instance type and payment.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-04T17:00:28.803093"}}
{"question": "What are the three payment options available when purchasing a Reserved Instance (RI)?", "answer": "The three payment options when purchasing a Reserved Instance (RI) are: 1) All Upfront option, where you pay for the entire RI term with one upfront payment; 2) Partial Upfront option, which requires a low upfront payment followed by a discounted hourly rate for the duration of the RI term; and 3) No Upfront option, which does not require any upfront payment and provides a discounted hourly rate for the entire term.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-04T17:00:39.894506"}}
{"question": "How does the payment structure of Reserved Instances (RIs) influence the cost management for users?", "answer": "The payment structure of Reserved Instances (RIs) influences cost management by offering different payment options that can align with a user's budget and cash flow. The All Upfront option requires a single payment, which may be beneficial for those who prefer to manage costs upfront. The Partial Upfront option allows for lower initial payments while still receiving a discount on hourly rates, making it easier to manage ongoing operational costs. The No Upfront option provides flexibility by not requiring any initial payment and still offering discounted hourly rates, which can help users manage costs without an immediate financial commitment.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-04T17:00:39.894857"}}
{"question": "How do the discounts for Reserved Instances (RIs) differ based on the total list value across different tiers?", "answer": "The discounts for Reserved Instances (RIs) vary based on the total list value, which is the sum of all expected payments for an RI within the term. For list values less than $500k, there is no discount. For list values between $500k and $4M, users receive a 5% discount on both upfront and hourly payments. For list values between $4M and $10M, the discount increases to 10% on both payments. For list values exceeding $10M, users are advised to call for further assistance, implying that specific terms may apply at that level.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-04T17:00:39.895374"}}
{"question": "What happens to the first $100,000 when purchasing RIs worth $150,000 in the US-east-1 region?", "answer": "The first $100,000 of the purchase would not receive a discount.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-04T17:00:46.449248"}}
{"question": "How does Consolidated Billing affect the calculation of volume discounts for Reserved Instances?", "answer": "If you leverage Consolidated Billing, AWS will use the aggregate total list price of active RIs across all of your consolidated accounts to determine which volume discount tier to apply. It is important to activate Consolidated Billing prior to purchasing RIs to ensure that you benefit from the largest possible volume discount that your consolidated accounts are eligible to receive.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-04T17:00:46.449575"}}
{"question": "How do volume discounts differ between standard RIs and Convertible RIs?", "answer": "Standard RIs qualify for volume discounts, while Convertible RIs do not qualify for volume discounts. However, the value of each Convertible RI that you purchase still contributes to your volume discount tier standing.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-04T17:00:46.450153"}}
{"question": "Will the cost of my Reserved Instances (RIs) change if my future volume qualifies me for other discount tiers?", "answer": "No, the cost of your RIs will remain the same even if you qualify for other discount tiers in the future. Volume discounts are determined at the time of purchase.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-04T17:00:52.389528"}}
{"question": "How are volume discounts applied when purchasing Reserved Instances?", "answer": "Volume discounts are applied automatically when you use the existing PurchaseReservedInstance API or the EC2 Management Console interface to purchase RIs. There is no action needed from the user to receive these discounts.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-04T17:00:52.389834"}}
{"question": "What happens if I purchase more than $10M worth of Reserved Instances?", "answer": "If you purchase more than $10M worth of RIs, you should contact AWS about receiving discounts that go beyond those automatically provided for your purchases.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-04T17:00:52.390321"}}
{"question": "What is the function of the RI Marketplace?", "answer": "The RI Marketplace is an online marketplace that provides AWS customers the flexibility to sell their Amazon EC2 RIs to other businesses and organizations. Customers can also browse the RI Marketplace to find a wider selection of RI term lengths and pricing options sold by other AWS customers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-04T17:00:57.761845"}}
{"question": "What are the requirements for listing an RI on the RI Marketplace?", "answer": "To list an RI on the RI Marketplace, you must be registered as a seller, have paid for your RI, and have owned the RI for longer than 30 days.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-04T17:00:57.762187"}}
{"question": "How do the transferability rules of EC2 Reserved Instances relate to the RI Marketplace?", "answer": "EC2 Reserved Instances are only transferrable in accordance with the requirements of the RI Marketplace as specified in the AWS Service Terms, and cannot otherwise be transferred.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-04T17:00:57.762699"}}
{"question": "What tax information is required if I exceed $20,000 in sales of RIs?", "answer": "If you exceed $20,000 in sales of RIs or plan to sell 50 or more RIs, you will need to provide tax information before you can list your RIs. You should choose 'Continue with Tax Interview,' where you will be prompted to enter your company name, contact name, address, and Tax Identification Number using the TIMS workflow.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-04T17:01:06.571315"}}
{"question": "What steps do I need to follow to list an RI for sale in the Amazon EC2 console?", "answer": "To list an RI for sale, you need to follow these steps in the Amazon EC2 console: First, select the RIs that you wish to sell and choose 'Sell Reserved Instances.' If you have not completed the registration process, you will be prompted to register using the registration pipeline. Next, for each RI type, set the number of instances youd like to sell and the one-time fee you want to set. You can set the one-time price to different amounts based on the time remaining. Then, after configuring your listing, a final confirmation screen will appear, and you should choose 'Sell Reserved Instance.'", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-04T17:01:06.571605"}}
{"question": "How do the requirements for providing tax information differ based on sales amounts of RIs?", "answer": "The requirements for providing tax information differ based on sales amounts as follows: If you exceed $20,000 in sales of RIs or plan to sell 50 or more RIs, you need to provide tax information before listing your RIs. Additionally, if you plan to sell RIs worth more than $50,000 per year, you will also need to file a limit increase. This indicates that the threshold for tax information and filing increases based on the sales figures.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-04T17:01:06.572231"}}
{"question": "Where can I view RIs that have been listed on the RI Marketplace?", "answer": "RIs that have been listed on the RI Marketplace can be viewed in the 'Reserved Instances' section of the Amazon EC2 console. Additionally, you can use the DescribeReservedInstancesListings API call to access this information.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-04T17:01:12.592610"}}
{"question": "What happens to my reservation benefits while my RI is listed on the RI Marketplace?", "answer": "While your RI is listed on the RI Marketplace, you will continue to receive the capacity and billing benefit of your reservation until it is sold. After the sale, any running instance that was being charged at the discounted rate will switch to the On-Demand rate unless you purchase a new reservation or terminate the instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-04T17:01:12.592969"}}
{"question": "What are some key differences between RIs purchased directly from AWS and those purchased from the RI Marketplace?", "answer": "Both RIs purchased from AWS and those from the RI Marketplace can be resold, but when listing RIs on the Marketplace, you can set an upfront price but cannot change the hourly price, which remains the same as originally set. Additionally, RIs listed on the Marketplace may be subject to different listing and removal conditions compared to standard RIs.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-04T17:01:12.593512"}}
{"question": "Do I need a US bank account to sell RIs in the RI Marketplace?", "answer": "Yes, you must have a US bank account to sell RIs in the RI Marketplace. Support for non-US bank accounts will be coming soon.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-04T17:01:20.017146"}}
{"question": "What happens if a buyer is only interested in purchasing a subset of my listed RIs?", "answer": "If a buyer is only interested in purchasing a subset of your listed RIs, AWS may potentially sell that subset. For example, if you list 100 RIs and a buyer is interested in 50, AWS will sell those 50 instances while continuing to list your remaining 50 RIs until you decide not to list them anymore.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-04T17:01:20.017435"}}
{"question": "What is the difference in payment methods for selling RIs versus receiving funds from a sale?", "answer": "Payment for completed RI sales is done via ACH wire transfers to a US bank account, while the seller receives funds via wire transfer to the bank account specified when registering for the RI Marketplace after AWS has received funds from the buyer.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-04T17:01:20.017813"}}
{"question": "What information will be provided to the seller via a disbursement report?", "answer": "The buyers city, state, zip+4, and country information will be provided to the seller via a disbursement report.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-04T17:01:25.551281"}}
{"question": "Why is the buyer's information important for sellers?", "answer": "The buyer's information is important for sellers because it enables them to calculate any necessary transaction taxes they need to remit to the government, such as sales tax or value-added tax.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-04T17:01:25.551630"}}
{"question": "How does the purchase of RIs relate to Premium Support charges?", "answer": "If you are a Premium Support customer, you will be charged for Premium Support when you purchase an RI through the RI Marketplace, indicating that the Premium Support fees are applicable regardless of the purchase method.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-04T17:01:25.552139"}}
{"question": "What is the commitment requirement for Savings Plans?", "answer": "Savings Plans require a commitment to a consistent amount of usage, measured in $/hour, for a one- or three-year term.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-04T17:01:32.221020"}}
{"question": "What are the main advantages of using Compute Savings Plans?", "answer": "Compute Savings Plans offer the most flexibility and can help reduce costs by up to 66%. They automatically apply to EC2 instance usage regardless of instance family, size, AZ, region, OS, or tenancy, and also apply to AWS Fargate and Lambda usage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-04T17:01:32.221265"}}
{"question": "How do Compute Savings Plans and EC2 Instance Savings Plans differ in terms of flexibility and savings?", "answer": "Compute Savings Plans provide more flexibility as they apply to a wide range of services and instance types, allowing users to change instances and workloads freely while still benefiting from the discounted rates. In contrast, EC2 Instance Savings Plans offer the lowest prices but require a commitment to usage of individual instance families in a specific region, reducing costs only for the selected instance family.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-04T17:01:32.221656"}}
{"question": "What are the maximum savings percentages offered by Compute Savings Plans and EC2 Instance Savings Plans?", "answer": "Compute Savings Plans provide savings of up to 66%, while EC2 Instance Savings Plans offer savings of up to 72%.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-04T17:01:37.815165"}}
{"question": "How do Savings Plans differ from EC2 RIs in terms of flexibility?", "answer": "Savings Plans automatically reduce your bills on compute usage across any AWS region and allow you to use the compute option that best suits your needs, offering greater flexibility compared to EC2 RIs, which require you to reserve specific instances in specific regions.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-04T17:01:37.815508"}}
{"question": "Can you use Savings Plans and EC2 RIs together, and how do they affect your overall bill?", "answer": "Yes, you can use Savings Plans alongside EC2 RIs to reduce your overall bill. While both offer savings, Savings Plans provide additional flexibility, and your RIs will continue to work with Savings Plans until they expire.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-04T17:01:37.816106"}}
{"question": "What are Spot Instances and how much can they save compared to On-Demand prices?", "answer": "Spot Instances are spare EC2 capacity that can save you up to 90% off of On-Demand prices. They are best suited for fault-tolerant, flexible workloads and provide an additional option for obtaining compute capacity.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-04T17:01:46.326963"}}
{"question": "What are the main differences between Spot Instances and On-Demand instances?", "answer": "The main differences between Spot Instances and On-Demand instances are that Spot Instances typically offer a significant discount off the On-Demand prices, can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification, and have prices that adjust gradually based on long-term supply and demand for spare EC2 capacity.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-04T17:01:46.327309"}}
{"question": "How does the request limit for Spot Instances differ for new AWS customers compared to existing ones?", "answer": "New AWS customers might start with a lower Spot limit for each region compared to existing customers. If a customer would like a higher limit, they can complete the Amazon EC2 instance request form with their use case, and their instance increase will be considered.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-04T17:01:46.327825"}}
{"question": "What is a Spot capacity pool?", "answer": "A Spot capacity pool is a set of unused EC2 instances with the same instance type, operating system, and Availability Zone. Each spot capacity pool can have a different price based on supply and demand.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-04T17:01:52.011596"}}
{"question": "Why is it recommended to use multiple Spot capacity pools?", "answer": "Using multiple Spot capacity pools is recommended to maximize the amount of Spot capacity available to you. EC2 provides built-in automation to find the most cost-effective capacity across these pools using EC2 Auto Scaling, EC2 Fleet, or Spot Fleet.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-04T17:01:52.011943"}}
{"question": "How do Spot Instances compare to On-Demand Instances in terms of stopping them?", "answer": "You can stop your running Spot Instances when they are not needed and keep these stopped instances for later use, which is similar to stopping On-Demand Instances. Both types allow you to use the StopInstances API and the AWS Management Console to stop them.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-04T17:01:52.012455"}}
{"question": "How can I start the stopped Spot Instances?", "answer": "You can start the stopped Spot Instances by calling the StartInstances API and providing Instance Ids of the Spot Instances similar to starting your On-Demand Instances. Alternatively, you can do this through the AWS Management Console by selecting your instance, then clicking Actions > Instance State > Start. However, note that the Spot Instances will only start if Spot capacity is still available within your maximum price.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-04T17:02:01.346063"}}
{"question": "What does the Spot Request Status code indicate about the state of a Spot Instance?", "answer": "The Spot Request Status code indicates whether the Spot Instance has been stopped by the user or interrupted by Amazon EC2. You can check this status on the Spot Requests page of the AWS Management Console or in the DescribeSpotInstanceRequests API response as the 'status-code' field. If the status code is 'instance-stopped-by-user', it means that you have stopped your Spot Instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-04T17:02:01.346412"}}
{"question": "What is the difference in charges for a Spot instance that is stopped by the user versus one that is terminated by Amazon EC2?", "answer": "If a Spot instance is stopped or terminated by Amazon EC2 within the first instance hour, you will not be charged for that usage. However, if you stop or terminate the Spot instance yourself, you will be charged to the nearest second. For any subsequent hour, if the Spot instance is terminated or stopped by Amazon EC2, you will also be charged for your usage to the nearest second. Additionally, if you are running on Windows or Red Hat Enterprise Linux (RHEL) and you stop or terminate the Spot instance yourself, you will be charged for an entire hour.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-04T17:02:01.346919"}}
{"question": "What are the two possible reasons for Amazon EC2 to reclaim a Spot Instance?", "answer": "Amazon EC2 may reclaim a Spot Instance primarily due to capacity requirements, such as the usage of On-Demand or Reserved Instances. Alternatively, if you have set a maximum Spot price and the Spot price rises above this value, your instance will also be reclaimed with a two-minute notification.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-04T17:02:09.621501"}}
{"question": "What options do I have for handling interruptions of my Spot instances?", "answer": "You can choose to have your Spot instances terminated, stopped, or hibernated upon interruption. The stop and hibernate options are available for persistent Spot requests and Spot Fleets with the 'maintain' option enabled, but by default, your instances are terminated.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-04T17:02:09.621875"}}
{"question": "How do the behaviors of Stop and Hibernate differ for Spot instances during interruptions?", "answer": "In the case of Hibernate, the instance gets hibernated and the RAM data is persisted, while in the case of Stop, the instance is shut down and the RAM is cleared. In both cases, the data from your EBS root volume and any attached EBS data volumes is persisted, and the private IP address remains the same, along with the elastic IP address if applicable.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-04T17:02:09.622382"}}
{"question": "What is required to enable hibernation for my Spot instances?", "answer": "To enable hibernation for your Spot instances, you should refer to the documentation on Spot Hibernation.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-04T17:02:15.165893"}}
{"question": "Why would I want to use hibernation for my Spot instances?", "answer": "You would want to use hibernation for your Spot instances when your applications depend on contextual, business, or session data stored in RAM, and you need to retain instance state across shutdown-startup cycles.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-04T17:02:15.166238"}}
{"question": "How does resuming a hibernated Spot instance work compared to a regular instance?", "answer": "You will not be able to resume a hibernated Spot instance directly, as the hibernate-resume cycle is controlled by Amazon EC2. In contrast, for a regular instance, you typically have direct control over resuming it. For a hibernated Spot instance, it will be resumed by Amazon EC2 when capacity becomes available.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-04T17:02:15.166665"}}
{"question": "What is a Spot Fleet used for?", "answer": "A Spot Fleet is used to automatically request and manage multiple Spot instances that provide the lowest price per unit of capacity for various applications, such as batch processing jobs, Hadoop workflows, or HPC grid computing jobs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-04T17:02:22.407799"}}
{"question": "How does a Spot Fleet maintain target capacity?", "answer": "A Spot Fleet maintains target capacity by automatically requesting resources to replace any Spot instances that are disrupted or manually terminated, ensuring that the defined target capacity based on application needs is met.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-04T17:02:22.408113"}}
{"question": "What happens if a Spot Fleet request exceeds the regional Spot request limit compared to a standard Spot Instance request?", "answer": "If a Spot Fleet request exceeds the regional Spot request limit, individual Spot instance requests will fail with a 'Spot request limit exceeded request status', whereas a standard Spot Instance request would also fail under the same conditions. Both are subject to availability and prices, meaning neither request type is guaranteed to be fulfilled if resources are unavailable.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-04T17:02:22.408520"}}
{"question": "What are the three allocation strategies provided by the RequestSpotFleet API?", "answer": "The three allocation strategies provided by the RequestSpotFleet API are capacity-optimized, lowestPrice, and diversified.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-04T17:02:28.094926"}}
{"question": "Why is the capacity-optimized allocation strategy a good choice for certain workloads?", "answer": "The capacity-optimized allocation strategy is a good choice for workloads that have a higher cost of interruption, such as big data and analytics, image and media rendering, machine learning, and high performance computing, because it attempts to provision Spot Instances from the most available Spot Instance pools by analyzing capacity metrics.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-04T17:02:28.096184"}}
{"question": "How does the diversified allocation strategy differ from the lowestPrice strategy in Spot Fleet?", "answer": "The diversified allocation strategy allows you to provision your Spot Fleet resources across multiple Spot Instance pools to maintain the fleets target capacity and increase application availability as Spot capacity fluctuates. In contrast, the lowestPrice strategy focuses on provisioning resources in instance pools that provide the lowest price per unit of capacity at the time of the request.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-04T17:02:28.096480"}}
{"question": "What features can be used with Auto Scaling in Spot Fleet?", "answer": "You can use Auto Scaling features with Spot Fleet such as target tracking, health checks, CloudWatch metrics, etc., and can attach instances to your Elastic load balancers (both classic and application load balancers).", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-04T17:02:35.081782"}}
{"question": "How does Spot Fleet handle the termination of Spot Instances?", "answer": "Spot Fleet requests do not automatically terminate and relaunch instances while they are running. However, if you terminate a Spot Instance, Spot Fleet will replenish it with a new Spot Instance in the new lowest priced pool or capacity-optimized pool based on your allocation strategy.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-04T17:02:35.082010"}}
{"question": "How does Elastic MapReduce's 'Instance fleets' compare to Spot Fleet?", "answer": "Elastic MapReduce has a feature named 'Instance fleets' that provides capabilities similar to Spot Fleet.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-04T17:02:35.082195"}}
{"question": "What is the link-local IP address provided by the Amazon Time Sync Service?", "answer": "The Amazon Time Sync Service provides a link-local IP address of 169.254.169.123.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-04T17:02:53.668168"}}
{"question": "Why is it important to have a consistent and accurate reference time source for applications?", "answer": "A consistent and accurate reference time source is crucial for many applications and services as it ensures synchronization and reliability in operations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-04T17:02:53.668536"}}
{"question": "How do Availability Zones compare in terms of infrastructure and reliability?", "answer": "Each Availability Zone runs on its own physically distinct, independent infrastructure, engineered to be highly reliable, with no common points of failures like generators and cooling equipment shared across them. They are also physically separate, meaning that extreme disasters such as fires, tornados, or flooding would only affect a single Availability Zone.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-04T17:02:53.669045"}}
{"question": "What are Cluster Compute Instances designed for?", "answer": "Cluster Compute Instances are designed to combine high compute resources with high performance networking specifically for HPC applications and other demanding network-bound applications. They provide high performance networking and significantly increased network throughput, making them suitable for network-intensive operations.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-04T17:03:00.879857"}}
{"question": "How do Cluster GPU Instances differ in functionality from Cluster Compute Instances?", "answer": "Cluster GPU Instances provide general-purpose graphics processing units (GPUs) along with high CPU and increased network performance, specifically for applications that benefit from parallelized processing using CUDA and OpenCL programming models. This gives customers with HPC workloads an additional option to customize their high performance clusters for GPU-accelerated applications, whereas Cluster Compute Instances are focused on high compute resources and networking for HPC applications without dedicated GPU capabilities.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-04T17:03:00.880175"}}
{"question": "What network throughput can be expected for EC2 instances launched in a cluster placement group?", "answer": "When launched in a cluster placement group, select EC2 instances can utilize up to 10 Gbps for single-flow traffic. Additionally, inter-instance traffic within the same region can utilize 5 Gbps for single-flow and up to 25 Gbps for multiflow traffic, depending on the instance type and its networking performance specification.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-04T17:03:00.880537"}}
{"question": "What are High Memory Cluster Instances primarily used for?", "answer": "High Memory Cluster Instances are primarily used for memory intensive workloads including in-memory analytics systems, graph analysis, and many science and engineering applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-04T17:03:07.149981"}}
{"question": "How do Cluster Compute and Cluster GPU Instances differ from other Amazon EC2 instance types regarding virtualization?", "answer": "Cluster Compute and Cluster GPU Instances differ from other Amazon EC2 instance types in that they use Hardware Virtual Machine (HVM) based virtualization and can only run Amazon Machine Images (AMIs) based on HVM virtualization. This means that Paravirtual Machine (PVM) based AMIs cannot be used with these instance types.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-04T17:03:07.150331"}}
{"question": "What is the relationship between Cluster Compute Instances and cluster placement groups?", "answer": "Cluster Compute Instances must be launched into a cluster placement group to fully benefit from the available low latency and full bisection bandwidth between instances. This allows for optimal performance in tightly coupled node-to-node communication.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-04T17:03:07.150827"}}
{"question": "What is the recommended approach to optimize the likelihood of receiving the full number of instances for a cluster via a cluster placement group?", "answer": "To optimize the likelihood of receiving the full number of instances for a cluster via a cluster placement group, it is recommended to launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, you should launch multiple placement groups, such as two placement groups of 128 instances each, and combine them to create a larger, 256 instance cluster.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-04T17:03:13.976602"}}
{"question": "What are the current limitations regarding the types of instances that can be launched into a single cluster placement group?", "answer": "Currently, the limitation is that while it may be possible to launch different cluster instance types into a single placement group, only homogenous placement groups are supported at this time.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-04T17:03:13.976975"}}
{"question": "What happens to an instance in a cluster placement group if it is stopped and then started again?", "answer": "If an instance in a cluster placement group is stopped and then started again, it will maintain its presence in the cluster placement group it was in when it stopped. However, if capacity is not available for it to start within its cluster placement group, the start will fail.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-04T17:03:13.977584"}}
{"question": "What types of processors does EC2 offer for its instances?", "answer": "EC2 offers a choice in CPU options including AWS Graviton/Graviton2 processors (Arm), AMD processors (x86), and Intel processors (x86).", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-04T17:03:20.150962"}}
{"question": "What are the benefits of using non-intrusive maintenance technologies in EC2?", "answer": "Non-intrusive maintenance technologies such as live update and live migration improve application uptime and reduce operational effort. They allow maintenance to occur without requiring instances to be stopped or rebooted and ensure that workloads run on servers with up-to-date software, including security patches and performance improvements.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-04T17:03:20.151305"}}
{"question": "How does live update differ from live migration in EC2 maintenance?", "answer": "Live update is used to deploy software to servers quickly with minimal impact to customer instances, ensuring workloads are up-to-date with security patches and new features. In contrast, live migration involves moving running instances from one server to another for hardware maintenance or to optimize resource placement, without interrupting the instance's operation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-04T17:03:20.151471"}}
{"question": "What are the five families of Amazon EC2 instances?", "answer": "The five families of Amazon EC2 instances are General Purpose, Compute Optimized, Memory Optimized, Storage Optimized, and Accelerated Computing instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-04T17:03:25.852787"}}
{"question": "What factors should you consider when choosing an EC2 instance type?", "answer": "When choosing EC2 instance types, you should consider the characteristics of your application with regards to resource utilization, specifically CPU, Memory, and Storage, and select the optimal instance family and instance size based on those considerations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-04T17:03:25.853130"}}
{"question": "How do Compute Optimized instances differ from Memory Optimized instances?", "answer": "Compute Optimized instances have proportionally more CPU resources than memory and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads, while Memory Optimized instances offer larger memory sizes specifically for memory-intensive applications, including database and memory caching applications.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-04T17:03:25.853622"}}
{"question": "What is an Amazon EC2 Compute Unit (ECU) used for?", "answer": "An Amazon EC2 Compute Unit (ECU) is used to express the amount of CPU allocated to a particular EC2 instance, providing a relative measure of the integer processing power of that instance. It helps developers compare CPU capacity between different instance types.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-04T17:03:31.931088"}}
{"question": "Why is the EC2 Compute Unit important for developers?", "answer": "The EC2 Compute Unit is important for developers because it provides a standardized way to compare the CPU capacity across different instance types, allowing them to make informed decisions regarding instance selection based on performance needs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-04T17:03:31.931436"}}
{"question": "How does the performance benchmarking of EC2 instance types relate to the consistency of ECUs?", "answer": "Performance benchmarking of EC2 instance types is conducted regularly to ensure that the performance from an EC2 Compute Unit remains consistent and predictable over time. This benchmarking helps in maintaining the reliability of the performance metrics associated with ECUs.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-04T17:03:31.931951"}}
{"question": "What is the maximum CPU capacity that Micro instances can burst to?", "answer": "Micro instances can burst CPU capacity up to 2 ECUs when additional cycles are available.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-04T17:03:37.870690"}}
{"question": "Why might someone choose a Micro instance over a Standard Small instance?", "answer": "Someone might choose a Micro instance over a Standard Small instance because Micro instances are well suited for lower throughput applications and websites that consume significant compute cycles periodically but very little CPU at other times. They can also burst up to 2 ECUs, which is beneficial for applications with occasional high compute needs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-04T17:03:37.871022"}}
{"question": "How do Micro instances and Standard Small instances differ in terms of steady state compute resources?", "answer": "At steady state, Micro instances receive a fraction of the compute resources that Standard Small instances do. For applications with compute-intensive or steady state needs, a Small instance (or larger) is recommended, whereas Micro instances are suitable for applications with lower throughput and occasional bursts.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-04T17:03:37.871526"}}
{"question": "What is the primary function of the Nitro Hypervisor in Amazon EC2?", "answer": "The primary function of the Nitro Hypervisor in Amazon EC2 is to provide CPU and memory isolation for EC2 instances. It is a component of the Nitro system, which also includes dedicated hardware components for VPC networking and EBS storage resources.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-04T17:03:44.388123"}}
{"question": "How does the Nitro Hypervisor improve performance for EC2 instances?", "answer": "The Nitro Hypervisor improves performance for EC2 instances by providing consistent performance and increased compute and memory resources. It achieves this by removing host system software components, allowing AWS to offer larger instance sizes that provide practically all of the resources from the server to customers.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-04T17:03:44.388442"}}
{"question": "How does the Nitro Hypervisor compare to the Xen-based hypervisor in terms of AWS's future plans?", "answer": "AWS plans for all new instance types to eventually use the Nitro Hypervisor, while some new instance types will still use the Xen-based hypervisor depending on platform requirements. However, AWS will continue to invest in its Xen-based hypervisor, ensuring it remains a core component of EC2 instances for the foreseeable future.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-04T17:03:44.388861"}}
{"question": "What is the maximum number of PCI devices supported by the Nitro Hypervisor for EBS volumes and VPC ENIs?", "answer": "The Nitro Hypervisor supports a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-04T17:03:50.564148"}}
{"question": "Why might the 'hypervisor' field in the DescribeInstances response be significant for users?", "answer": "The 'hypervisor' field in the DescribeInstances response is significant because it continues to report 'xen' for all EC2 instances, even those running under the Nitro Hypervisor. This could impact software that assumes EC2 instances will run under the Xen hypervisor, as it relies on this detection.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-04T17:03:50.564365"}}
{"question": "How do the boot methods differ between instances using the Nitro Hypervisor and those using the Xen hypervisor?", "answer": "Instances running under the Nitro Hypervisor boot from EBS volumes using an NVMe interface, whereas instances running under the Xen hypervisor boot from an emulated IDE hard drive and switch to the Xen paravirtualized block device drivers.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-04T17:03:50.564509"}}
{"question": "What is required for a Linux instance to respond correctly to shutdown signals from the Nitro Hypervisor?", "answer": "For a Linux instance to respond correctly to shutdown signals from the Nitro Hypervisor, the acpid service must be installed and functioning correctly. If acpid is not functioning, termination events will be delayed by multiple minutes and will execute as a hard reset or power off.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-04T17:03:58.255326"}}
{"question": "What are the key differences in how NVMe drivers and Xen paravirtual block drivers behave when accessing EBS volumes?", "answer": "The key differences in how NVMe drivers and Xen paravirtual block drivers behave when accessing EBS volumes include the naming of NVMe devices, which are enumerated by Linux based operating systems as /dev/nvme0n1, /dev/nvme1n1, etc., compared to the parameters for EBS volume attachment requests that use names like /dev/xvda and /dev/xvdf. Additionally, NVMe device names are not persistent mappings to volumes, so methods like file system UUIDs or labels should be used for configuring automatic mounting of file systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-04T17:03:58.255672"}}
{"question": "How do the EC2 instance metadata services differ between instances running on Xen and those running on the Nitro Hypervisor?", "answer": "The EC2 instance metadata services do not differ between instances running on Xen and those running on the Nitro Hypervisor; they work the same way on both types of hypervisors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-04T17:03:58.256179"}}
{"question": "What happens by default when an I/O does not complete in the NVMe drivers included in most operating systems?", "answer": "By default, if an I/O does not complete in an implementation specific amount of time, usually tens of seconds, the NVMe driver will attempt to cancel the I/O, retry it, or return an error to the component that issued the I/O.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-04T17:04:04.843495"}}
{"question": "How can the behavior of the Linux NVMe driver regarding I/O timeout be modified?", "answer": "The behavior of the Linux NVMe driver can be modified by specifying a higher value for the nvme.io timeout kernel module parameter.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-04T17:04:04.843832"}}
{"question": "How does the I/O performance of the NVMe interface compare to the Xen PV block interface in terms of data transfer and outstanding I/O requests?", "answer": "The NVMe interface can transfer much larger amounts of data per I/O and may support more outstanding I/O requests compared to the Xen PV block interface. This can lead to higher I/O latency in scenarios where very large I/Os or a large number of I/O requests are issued, especially with volumes designed for throughput workloads like EBS Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-04T17:04:04.844326"}}
{"question": "What does the Optimize CPUs feature allow you to do when launching new EC2 instances?", "answer": "The Optimize CPUs feature allows you to specify a custom number of vCPUs when launching new EC2 instances, which can help save on vCPU-based licensing costs, and it also enables you to disable Intel Hyper-Threading Technology for workloads that perform well with single-threaded CPUs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-04T17:04:10.481431"}}
{"question": "In what scenarios should I consider using the Optimize CPUs feature?", "answer": "You should consider using the Optimize CPUs feature if you are running EC2 workloads that are not compute bound and are incurring vCPU-based licensing costs, as well as if you are running workloads that will benefit from disabling hyper-threading on EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-04T17:04:10.481774"}}
{"question": "How do the pricing of CPU optimized instances compare to full-sized instances?", "answer": "CPU optimized instances will be priced the same as equivalent full-sized instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-04T17:04:10.482297"}}
{"question": "How is billing calculated for Amazon EC2 running IBM?", "answer": "Billing for Amazon EC2 running IBM is based on the instance-hour consumed for each instance type, and you only pay for what you use with no minimum fee. Partial instance-hours consumed are billed as full hours. Additionally, data transfer for Amazon EC2 running IBM is billed and tiered separately from Amazon EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-04T17:04:17.689885"}}
{"question": "What are the considerations for using existing Windows Server licenses with Amazon EC2?", "answer": "You can use your existing Windows Server licenses with Amazon EC2 after importing your own Windows Server machine images using the ImportImage tool. You can launch instances from these images on EC2 Dedicated Hosts, which allows you to effectively manage instances and report usage. Microsoft requires tracking usage of licenses against physical resources, and Dedicated Hosts facilitate this tracking.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-04T17:04:17.690262"}}
{"question": "What is the difference in data transfer charges between AWS services in the same region and different regions?", "answer": "There is no Data Transfer charge between two Amazon Web Services within the same Region, such as between Amazon EC2 US West and another AWS service in the US West. However, data transferred between AWS services in different regions will incur charges as Internet Data Transfer on both sides of the transfer.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-04T17:04:17.690760"}}
{"question": "What are the key benefits of using Amazon EC2 Mac instances for Apple developers?", "answer": "Amazon EC2 Mac instances provide flexibility, scalability, and cost benefits, allowing Apple developers to run on-demand macOS workloads in the cloud. Developers can provision and access macOS environments within minutes, dynamically scale capacity as needed, and take advantage of AWS's pay-as-you-go pricing.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-04T17:04:23.888849"}}
{"question": "What types of applications can be built and tested using EC2 Mac instances?", "answer": "EC2 Mac instances are designed for building, testing, signing, and publishing applications for Apple platforms including iOS, iPadOS, watchOS, tvOS, macOS, and Safari.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-04T17:04:23.889347"}}
{"question": "How do x86-based EC2 Mac instances differ from EC2 M1 Mac instances?", "answer": "x86-based EC2 Mac instances are built on Apple Mac mini computers featuring Intel Core i7 processors, while EC2 M1 Mac instances are built on Apple M1 Mac mini computers. Both types are powered by the AWS Nitro System, but they use different processor architectures.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-04T17:04:23.889568"}}
{"question": "What operating systems do EC2 M1 Mac instances support as Amazon Machine Images?", "answer": "EC2 M1 Mac instances support macOS Big Sur (11) and macOS Monterey (12) as Amazon Machine Images (AMIs).", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-04T17:04:28.034767"}}
{"question": "How do EC2 M2 Mac instances compare in performance to EC2 M1 Mac instances?", "answer": "EC2 M2 Mac instances are up to 10% more performant than EC2 M1 Mac instances for iOS and macOS application build workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-04T17:04:28.035099"}}
{"question": "What is the significance of EC2 M1 Mac instances in the AWS environment?", "answer": "EC2 M1 Mac instances enable ARM64 macOS environments for the first time in AWS, providing enhanced price performance over x86-based EC2 Mac instances for iOS and macOS application build workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-04T17:04:28.035484"}}
{"question": "What are EC2 M2 Pro Mac instances built on?", "answer": "EC2 M2 Pro Mac instances are built on Apple M2 Pro Mac mini computers and powered by the AWS Nitro System.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-04T17:04:34.310939"}}
{"question": "What advantages do EC2 M2 Pro Mac instances offer compared to EC2 M1 Mac instances?", "answer": "EC2 M2 Pro Mac instances are up to 35% more performant than EC2 M1 Mac instances specifically for iOS and macOS application build workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-04T17:04:34.311279"}}
{"question": "How do the pricing models for EC2 Mac instances differ from the standard EC2 instances?", "answer": "EC2 Mac instances are available as Dedicated Hosts through both On-Demand and Savings Plans pricing models, while standard EC2 instances may offer additional pricing models such as Spot Instances. The billing for EC2 Mac instances is per second with a 24-hour minimum allocation period, which is specific to comply with the Apple macOS Software License Agreement.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-04T17:04:34.311838"}}
{"question": "Can you share EC2 Mac Dedicated Hosts with other AWS accounts?", "answer": "Yes, you can share EC2 Mac Dedicated Hosts with AWS accounts inside your AWS organization, an organizational unit inside your AWS organization, or your entire AWS organization via AWS Resource Access Manager.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-04T17:04:40.189582"}}
{"question": "What is the recommended method for encrypting boot and data volumes on EC2 Mac instances?", "answer": "The recommended method for encrypting boot and data volumes on EC2 Mac instances is to use Amazon EBS encryption, rather than enabling FileVault, as enabling FileVault could lead to losing access to data on the boot volume at instance reboot, stop, or termination.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-04T17:04:40.189928"}}
{"question": "How does access to audio output differ between the built-in Apple Remote Desktop VNC server and third-party software on EC2 Mac instances?", "answer": "The built-in Apple Remote Desktop VNC server does not support audio output, while third-party remote desktop software, such as Teradici CAS, supports remote audio on macOS.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-04T17:04:40.190426"}}
{"question": "What type of hardware do EC2 Mac instances use to run macOS?", "answer": "EC2 Mac instances use physical Mac mini hardware to run macOS.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-04T17:04:46.134362"}}
{"question": "Why can't older versions of macOS run on EC2 M1 Mac instances?", "answer": "Older versions of macOS cannot run on EC2 M1 Mac instances because macOS Big Sur is the first macOS version to support Apple Silicon, and therefore, older versions will not run even under virtualization.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-04T17:04:46.134633"}}
{"question": "How do EC2 Mac instances differ from EC2 Linux and Windows instances in terms of user data handling?", "answer": "EC2 Mac instances differ from EC2 Linux and Windows instances in that they use an open-source launch daemon called ec2-macos-init to handle user data, whereas EC2 Linux and Windows instances utilize cloud-init.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-04T17:04:46.135144"}}
{"question": "What is the recommended action after installing Xcode on an EC2 Mac instance?", "answer": "Once you have Xcode installed on your EC2 Mac instance, it is recommended to create a snapshot of your AMI for future use.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-04T17:04:52.279888"}}
{"question": "Why are automatic macOS software updates disabled on EC2 Mac instances?", "answer": "Automatic macOS software updates are disabled on EC2 Mac instances to encourage users to use the officially vended macOS AMIs to launch the version of macOS they need.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-04T17:04:52.280250"}}
{"question": "How does the update process for macOS differ between EC2 Mac instances and typical macOS systems?", "answer": "On typical macOS systems, users can rely on automatic software updates, while on EC2 Mac instances, these updates are disabled, and users must use the Software Update preferences pane or the software update CLI command to update the version of macOS.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-04T17:04:52.280752"}}
{"question": "What command can be used to poll an EC2 instance and determine when it is ready for SSH access?", "answer": "After launching your instance and receiving an instance id, you can use a specific command to poll the instance to determine when it is ready for SSH access. However, the exact command is not provided in the context.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-04T17:04:57.914357"}}
{"question": "What is required to connect to an EC2 Mac instance using SSH?", "answer": "To connect to an EC2 Mac instance using SSH, you need to launch the instance using a key pair and a security group that allows SSH access. Additionally, you must provide the .pem file for the key pair when connecting to the instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-04T17:04:57.914686"}}
{"question": "How do the EBS volume and ENI attachment limits differ between x86-based and EC2 M1 Mac instances?", "answer": "x86-based EC2 Mac instances support 16 EBS volumes and 8 ENI attachments, while EC2 M1 Mac instances support up to 10 EBS volumes and also 8 ENI attachments.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-04T17:04:57.915188"}}
{"question": "Do EC2 Mac instances support Amazon FSx?", "answer": "Yes, EC2 Mac instances support FSx using the SMB protocol. You will need to enroll the EC2 Mac instance into a supported directory service, such as Active Directory or the AWS Directory Service, to enable FSx on EC2 Mac instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-04T17:05:03.275795"}}
{"question": "What protocol do EC2 Mac instances use to support Amazon Elastic File System (Amazon EFS)?", "answer": "EC2 Mac instances support EFS over the NFSv4 protocol.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-04T17:05:03.276134"}}
{"question": "How do the support mechanisms for Amazon FSx and Amazon EFS differ on EC2 Mac instances?", "answer": "EC2 Mac instances support Amazon FSx using the SMB protocol and require enrollment in a supported directory service, while they support Amazon EFS using the NFSv4 protocol without the need for directory service enrollment.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-04T17:05:03.276662"}}
{"question": "Which previous-generation EC2 instances are eligible for Nitro System support?", "answer": "The previous-generation EC2 instances that are eligible for Nitro System support include Amazon EC2 C1, H1, M1, T1, D2, M2, T2, C3, I3, M3, R3, C4, M4, and R4 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-04T17:05:12.940858"}}
{"question": "What benefits does Nitro System support provide to customers running older generation EC2 instances?", "answer": "Nitro System support provides modern hardware and software components for previous generation EC2 instances, allowing customers to extend the length of service beyond the typical lifetime of the underlying hardware. This means customers can continue running their workloads and applications on the instance families they were built on.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-04T17:05:12.941238"}}
{"question": "How does the stop/start action affect an instance during the scheduled maintenance window compared to the regular maintenance process?", "answer": "If an instance is stopped and started during the scheduled maintenance window, it will migrate to a new host and will not have to undergo the scheduled maintenance. In contrast, during the regular maintenance process, the instance would typically undergo maintenance without this migration.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-04T17:05:12.941730"}}
{"question": "What happens to the IP address and DNS name of an instance after it is rebooted during maintenance?", "answer": "After the reboot, your instance retains its IP address, DNS name, and any data on local instance-store volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-04T17:05:18.951697"}}
{"question": "What is the significance of the Nitro hardware for the migration of previous generation instances?", "answer": "The Nitro hardware allows for the migration of previous generation instances without requiring customers to rebuild or recertify their workloads, and all existing features and AMIs will be supported during this migration.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-04T17:05:18.952039"}}
{"question": "How does the migration to AWS Nitro System affect the billing and pricing models for previous generation instances?", "answer": "There will be no change to billing and pricing when migrating to AWS Nitro System. The same pricing models, including On-Demand, 1yr/3yr Reserved Instance, Savings Plan, and Spot, will continue to be supported.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-04T17:05:18.952545"}}
{"question": "What resources are available to learn how to build with Amazon EC2?", "answer": "There are many resources available to help you learn how to build with Amazon EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-04T17:05:23.307691"}}
{"question": "What is the benefit of using the AWS Free Tier when starting with Amazon EC2?", "answer": "The AWS Free Tier allows you to instantly get access to resources, which is beneficial for getting started with Amazon EC2 without incurring costs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-04T17:05:23.308018"}}
{"question": "How do you begin building with Amazon EC2?", "answer": "You can begin building with Amazon EC2 by accessing the AWS Management Console.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-04T17:05:23.308532"}}
{"question": "What is Amazon ECR?", "answer": "Amazon ECR is a fully managed container registry that makes it easy for developers to share and deploy container images and artifacts. It is integrated with Amazon Elastic Container Service (Amazon ECS), Amazon Elastic Kubernetes Service (Amazon EKS), and AWS Lambda, simplifying the development to production workflow.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T17:05:29.281943"}}
{"question": "How does Amazon ECR ensure the security of container images?", "answer": "Amazon ECR transfers container images over HTTPS and automatically encrypts images at rest. Additionally, it integrates with AWS Identity and Access Management (IAM) to provide resource-level control of each repository, allowing users to configure policies that manage permissions and restrict access to IAM users, roles, or other AWS accounts.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T17:05:29.282403"}}
{"question": "How does Amazon ECR compare to operating your own container repositories?", "answer": "Amazon ECR eliminates the need to operate your own container repositories by managing the infrastructure for you, which means you do not have to worry about scaling it. It provides a highly available and scalable architecture for hosting your images, whereas operating your own container repositories would require you to handle the infrastructure and scaling yourself.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T17:05:29.282717"}}
{"question": "What is the primary purpose of Amazon ECR?", "answer": "The primary purpose of Amazon ECR is to provide a highly available container registry that allows users to push and pull container images, offering flexibility in how these images are deployed across different AWS Regions.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T17:05:36.263038"}}
{"question": "What are the differences in access and capabilities between private and public repositories in Amazon ECR?", "answer": "A private repository in Amazon ECR requires Amazon IAM-based authentication using AWS account credentials to allow images to be pulled, and it does not offer content search capabilities. In contrast, a public repository allows anyone, regardless of whether they have an AWS account, to pull images without needing IAM credentials, and it includes descriptive content and is searchable in the Amazon ECR public gallery.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T17:05:36.263550"}}
{"question": "How does accessing images from a private repository differ from a public repository in terms of authentication and accessibility?", "answer": "Accessing images from a private repository requires Amazon IAM-based authentication with AWS account credentials, making it less accessible for users without an account. In contrast, a public repository does not require any authentication, allowing anyone to pull images without needing an AWS account or IAM credentials, thus being more accessible.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-04T17:05:36.263787"}}
{"question": "What is the format of image URLs in Amazon ECR?", "answer": "Image URLs in Amazon ECR are in the format public.ecr.aws/<alias>/<image>:<tag>, for example public.ecr.aws/eks/aws-alb-ingress-controller:v1.1.5.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T17:05:42.289826"}}
{"question": "How does Amazon ECR facilitate multi-Region deployments?", "answer": "Amazon ECR allows you to create deployment pipelines that build images and push them to Amazon ECR in one Region. It can then automatically replicate those images to other Regions and accounts for deployment to multi-Region clusters.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T17:05:42.290298"}}
{"question": "What is the relationship between Amazon ECR and Amazon ECS?", "answer": "Amazon ECR is integrated with Amazon ECS, which allows you to easily store, run, and manage container images for applications running on Amazon ECS. You simply specify the Amazon ECR repository in your task definition, and Amazon ECS retrieves the appropriate images for your applications.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-04T17:05:42.290588"}}
{"question": "Does Amazon ECR integrate with any CI/CD solutions?", "answer": "Yes, Amazon ECR integrates with a number of popular CI/CD solutions to provide this capability. For more information, you can visit the Amazon ECR Partners page.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T17:05:50.581141"}}
{"question": "What image formats does Amazon ECR support, and how does it handle compatibility?", "answer": "Amazon ECR supports the Docker Image Manifest V2, Schema 2 format, and it maintains backwards compatibility with Schema 1 images by continuing to accept images uploaded in that format. Additionally, Amazon ECR can down-translate from a Schema 2 to a Schema 1 image when pulling with an older version of Docker Engine (1.9 and below). It is also compatible with the Open Container Initiative (OCI) image specification, allowing users to push and pull OCI images and artifacts.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T17:05:50.581332"}}
{"question": "How does Amazon ECR handle image encryption compared to access management?", "answer": "Amazon ECR automatically encrypts images at rest using Amazon S3 server-side encryption or AWS KMS encryption and transfers container images over HTTPS. In contrast, access management is handled through IAM resource-based policies, which allow you to control and monitor who and what can access your container images, as well as how, when, and where they can access them.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-04T17:05:50.581469"}}
{"question": "What is Amazon ECS?", "answer": "Amazon ECS, or Amazon Elastic Container Service, is a fully managed opinionated container orchestration service that provides the easiest way for organizations to build, deploy, and manage containerized applications at any scale on AWS. It can run on traditional Amazon Elastic Cloud Compute (EC2) instances or on a serverless compute plane with AWS Fargate.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T17:05:57.647457"}}
{"question": "What are some key features of Amazon ECS?", "answer": "Key features of Amazon ECS include being fully managed and versionless, offering tooling and built-in support for building and running containerized applications on AWS. It includes Amazon ECS Service Connect for service discovery, connectivity, and traffic observability, as well as Amazon CloudWatch Container Insights for collecting, aggregating, and summarizing metrics and logs. Users can also specify CPU and memory requirements, networking and IAM policies, and manage data volumes.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T17:05:57.648533"}}
{"question": "How does Amazon ECS compare to traditional server management?", "answer": "Unlike traditional server management, where users must provision and scale servers or clusters and choose the types of servers for their containers, Amazon ECS is fully managed and simplifies these processes. Users do not have to worry about optimizing cluster packing and can instead focus on defining the operating properties of their containers, such as resource requirements and networking policies.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T17:05:57.648921"}}
{"question": "What is Amazon ECS?", "answer": "Amazon ECS is a fully managed container orchestration service that makes it easy to use containers to deploy and manage long-running applications, services, and batch processes without needing to install, operate, and scale your own cluster management infrastructure.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-04T17:06:03.167304"}}
{"question": "How does Amazon ECS help in managing application availability and scalability?", "answer": "Amazon ECS maintains application availability and allows users to scale their containers up or down to meet their application's capacity requirements.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-04T17:06:03.167641"}}
{"question": "What are the differences between using Amazon ECS with AWS Fargate and managing your own compute infrastructure?", "answer": "When using Amazon ECS with AWS Fargate, you can deploy applications without needing to provision, manage, or scale compute infrastructure, which reduces the time for building, deploying, or migrating containerized applications. In contrast, managing your own compute infrastructure requires you to handle provisioning, management, and scaling, which can be more time-consuming and complex.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-04T17:06:03.168160"}}
{"question": "What is Amazon ECS and what does it provide for organizations?", "answer": "Amazon ECS is a fully managed opinionated container orchestration service that delivers the easiest way for organizations to build, deploy, and manage containerized applications at any scale. It is fully managed and versionless, providing tooling and built-in support that simplifies the process of building and running containerized applications on AWS.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:06:13.568237"}}
{"question": "How does Amazon ECS with AWS Fargate enhance the management of containerized applications?", "answer": "Amazon ECS with AWS Fargate supports serverless container orchestration, allowing users to leverage more of AWSs operational excellence in scaling, maintaining availability, and securing their containerized workloads. It enables organizations to modernize their container-based applications with little to no re-factoring while benefiting from the scalability, agility, and cost-effectiveness of serverless compute.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:06:13.568588"}}
{"question": "What are the differences between Amazon ECS on AWS Fargate and Amazon ECS on Amazon EC2?", "answer": "Amazon ECS on AWS Fargate provides a serverless compute option that abstracts the underlying infrastructure management, allowing users to focus more on their applications without managing servers or clusters. In contrast, Amazon ECS on Amazon EC2 offers more control over the operating properties of containers, as users can specify CPU and memory requirements, networking, IAM policies, and more, thus allowing for more customized configurations for their applications.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:06:13.569293"}}
{"question": "What are the two compute choices mentioned in the context that can be used with AWS serverless options?", "answer": "The two compute choices mentioned are Amazon ECS with AWS Fargate and AWS Lambda.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-04T17:06:18.609147"}}
{"question": "What advantages do AWS serverless choices provide according to the context?", "answer": "AWS serverless choices provide the advantages of scale, agility, and cost.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-04T17:06:18.609476"}}
{"question": "How do Amazon ECS with AWS Fargate and AWS Lambda relate in terms of their use in serverless compute?", "answer": "Both Amazon ECS with AWS Fargate and AWS Lambda are compute choices that can be used in AWS serverless options, allowing users to choose one or more depending on their use case.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-04T17:06:18.610055"}}
{"question": "What are the charge models associated with Amazon ECS?", "answer": "There are two different charge models for Amazon ECS: the Amazon EC2 Launch Type Model and the AWS Fargate Launch Type Model. Both models do not have an additional charge for Amazon ECS itself; instead, you pay for the AWS resources you create, such as Amazon EC2 instances or Amazon EBS volumes.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:06:25.707172"}}
{"question": "How does AWS Fargate charge for resources used by a containerized application?", "answer": "With AWS Fargate, you pay for the amount of vCPU and memory resources that your containerized application requests. These resources are calculated from the time your container images are pulled until the Amazon ECS Task terminates, rounded up to the nearest second, with a minimum charge of one minute.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:06:25.707531"}}
{"question": "What is the relationship between Amazon ECS and AWS Lambda regarding their use in applications?", "answer": "Amazon ECS is a highly scalable container orchestration service that allows for the management of distributed applications running in containers, while AWS Lambda is an event-driven task compute service that runs code in response to events without managing any compute infrastructure. Many applications in production utilize both Amazon ECS and AWS Lambda to leverage their respective benefits.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:06:25.708040"}}
{"question": "What is the smallest unit of compute in Amazon ECS?", "answer": "The smallest unit of compute in Amazon ECS is called a task. Tasks allow you to define a set of containers you would like to place together, their properties, and how they may be linked.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-04T17:06:31.960107"}}
{"question": "How does the Amazon ECS service scheduler contribute to application availability?", "answer": "The Amazon ECS service scheduler contributes to application availability by managing long-running applications and services. It maintains application availability by allowing you to scale your containers up or down to meet your application's capacity requirements, distributing traffic across containers using ELB, and automatically recovering unhealthy containers that fail ELB health checks.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-04T17:06:31.960432"}}
{"question": "What happens to containers when you update your application in Amazon ECS?", "answer": "When you update your application in Amazon ECS, you can change its definition or use a new image. The scheduler will automatically start new containers using the new definition and stop containers running the previous version, ensuring that connections to the ELB are drained if ELB is used.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-04T17:06:31.960994"}}
{"question": "What metrics does Amazon ECS publish to CloudWatch for measuring service utilization?", "answer": "Amazon ECS publishes two CloudWatch metrics for measuring service utilization: ECSServiceAverageCPUUtilization and ECSServiceAverageMemoryUtilization.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-04T17:06:37.708434"}}
{"question": "Why might a services average CPU and memory usage not be reliable for scaling actions?", "answer": "A services average CPU and memory usage may not be reliable indicators for scaling actions because these metrics alone may not accurately reflect the specific needs for scaling at a given time. Therefore, Application Auto Scaling supports scaling based on custom metrics that may better represent the desired application performance.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-04T17:06:37.708777"}}
{"question": "How do CloudWatch metrics compare to Prometheus metrics in the context of Application Auto Scaling?", "answer": "In the context of Application Auto Scaling, both CloudWatch metrics and Prometheus metrics can be used for scaling. This allows users to choose the metric type that best suits their application's needs, providing flexibility in monitoring and scaling based on different data sources.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-04T17:06:37.709284"}}
{"question": "What are the compute options available for running applications with Amazon ECS?", "answer": "Amazon ECS enables you to run applications using AWS Fargate, Amazon EC2, and on-premises virtual machines or servers through Amazon ECS Anywhere.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T17:06:44.963967"}}
{"question": "How does AWS Fargate simplify the management of containerized applications?", "answer": "AWS Fargate simplifies the management of containerized applications by removing the burden of server provisioning, cluster management, and orchestration. It automatically provisions, scales, and updates the compute infrastructure needed for applications, providing a serverless experience.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T17:06:44.964246"}}
{"question": "What is the difference between using AWS Fargate and Amazon EC2 with Amazon ECS in terms of infrastructure management?", "answer": "With AWS Fargate, you do not have to manage the underlying infrastructure as it is serverless and automatically handled, allowing you to focus on building applications. In contrast, with Amazon EC2, you own the EC2 instances and have complete control over infrastructure management, including the ability to select specific EC2 instance types and customize the operating system.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T17:06:44.964932"}}
{"question": "What are Amazon ECS capacity providers and how do they function?", "answer": "Amazon ECS capacity providers are the interface through which you can define the capacity needs for your applications. They allow you to define flexible rules for how your applications run on different types of compute capacity and manage the scaling of that capacity. Capacity providers work with both Amazon EC2 and AWS Fargate, providing predefined capacity providers for AWS Fargate and Fargate-Spot capacities for every cluster. For Amazon EC2, you can create your own Auto Scaling Group (ASG) capacity providers to manage scaling.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T17:06:52.682993"}}
{"question": "How does AWS Fargate differ from using Amazon EC2 instances with Amazon ECS?", "answer": "AWS Fargate offers serverless compute to run containers with Amazon ECS, allowing customers to launch their containers without the need to provision or manage Amazon EC2 instances. In contrast, when using Amazon ECS with Amazon EC2 instances, customers have greater control over their EC2 instances, which can be necessary for compliance, governance requirements, or broader customization options.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T17:06:52.683341"}}
{"question": "What is the recommended AMI for Amazon ECS and what other options are available?", "answer": "The recommended AMI for Amazon ECS is the Amazon ECS-enabled Amazon Linux AMI. Additionally, partner AMIs that are compatible with Amazon ECS are also available. Users can utilize any AMI that meets the Amazon ECS AMI specification, which can be reviewed in the documentation.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T17:06:52.683750"}}
{"question": "What are the two types of load balancers that Amazon ECS can use for distributing traffic across containers?", "answer": "Amazon ECS can use Application Load Balancers or Network Load Balancers to distribute traffic across your containers.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-04T17:06:57.257187"}}
{"question": "How does Amazon ECS support Docker networking and what benefit does it provide?", "answer": "Amazon ECS supports Docker networking by integrating with Amazon VPC, which provides isolation for containers. This integration allows users to control how containers connect with other services and external traffic.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-04T17:06:57.257407"}}
{"question": "What is the main difference between VPC Mode and Host Mode in Amazon ECS networking?", "answer": "The main difference is that VPC Mode assigns each running Amazon ECS task a dedicated elastic networking interface, allowing full networking features in a VPC, similar to Amazon EC2 instances. In contrast, Host Mode adds containers directly to the hosts network stack, exposing them on the host's network with no isolation.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-04T17:06:57.257890"}}
{"question": "What does Amazon ECS Service Connect simplify for Amazon ECS?", "answer": "Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability for Amazon ECS.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-04T17:07:01.665664"}}
{"question": "How does Amazon ECS Service Connect enhance the deployment of services?", "answer": "Amazon ECS Service Connect enhances the deployment of services by allowing you to set the way client applications connect to their dependencies in just one step, enabling faster service deployment, and delivering seamless integration of Amazon ECS microservices comprising an application.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-04T17:07:01.665952"}}
{"question": "What is the relationship between Amazon ECS and AWS Cloud Map in terms of service discovery?", "answer": "Amazon ECS is integrated with AWS Cloud Map to facilitate service discovery, allowing containerized services to easily discover and connect with each other by defining custom names for application resources, which increases application availability.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-04T17:07:01.666339"}}
{"question": "What is the purpose of Amazon CloudWatch in relation to Amazon ECS?", "answer": "Amazon CloudWatch is used to monitor Amazon ECS resources by collecting and processing raw data into readable, near real-time metrics. It records these statistics for a period of two weeks, allowing users to access historical information about the performance of their clusters or services. There is no additional charge for using CloudWatch for this monitoring.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:07:08.486860"}}
{"question": "How does CloudWatch Container Insights enhance the monitoring of Amazon ECS?", "answer": "CloudWatch Container Insights enhances the monitoring of Amazon ECS by collecting, aggregating, and summarizing metrics and logs specifically from containerized applications and microservices. It provides detailed diagnostic information, such as container restart failures, to help users isolate and resolve issues quickly. Container Insights collects metrics at the cluster, task, and service levels on both Linux and Windows Server instances, while instance-level metrics are collected only on Linux instances.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:07:08.487209"}}
{"question": "What are the differences in network metrics availability between the various network modes in Amazon ECS?", "answer": "In Amazon ECS, network metrics are available only for containers in bridge network mode and awsvpc network mode. They are not available for containers operating in host network mode. This indicates a limitation in monitoring network performance based on the network mode configuration used for the containers.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:07:08.487678"}}
{"question": "What is the purpose of the Amazon ECS Partners page?", "answer": "The Amazon ECS Partners page is designed to provide information about partners that offer solutions and services related to Amazon Elastic Container Service (ECS).", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-04T17:07:12.502823"}}
{"question": "How can partnering with companies listed on the Amazon ECS Partners page benefit AWS users?", "answer": "Partnering with companies listed on the Amazon ECS Partners page can benefit AWS users by providing them with access to specialized solutions and services that enhance their experience with Amazon ECS, potentially improving efficiency and effectiveness in their container management.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-04T17:07:12.503140"}}
{"question": "In what ways might Amazon ECS Partners differ from standard AWS service offerings?", "answer": "Amazon ECS Partners may differ from standard AWS service offerings in that they provide specialized solutions and tailored services that are specifically designed to work with Amazon ECS, whereas standard AWS offerings may be broader and not specifically focused on container management.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-04T17:07:12.503571"}}
{"question": "Where can I find costs for Amazon ECS tasks running on AWS Fargate?", "answer": "Costs for Amazon ECS tasks running on AWS Fargate are available in AWS Cost and Usage Reports (CUR) and AWS Cost Explorer automatically.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T17:07:20.348011"}}
{"question": "What is the purpose of Split Cost Allocation Data for Amazon ECS tasks running on Amazon EC2?", "answer": "Split Cost Allocation Data generates task-level costs for Amazon ECS tasks running on Amazon EC2 instances by analyzing each tasks resource consumption based on the price of the instance and the percentage of CPU and memory resources consumed by the containers running on the instance.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T17:07:20.348374"}}
{"question": "How does cost allocation differ between Amazon ECS tasks running on AWS Fargate and those running on Amazon EC2?", "answer": "For Amazon ECS tasks running on AWS Fargate, costs are available in AWS Cost and Usage Reports and AWS Cost Explorer automatically without the need for additional configuration. In contrast, for Amazon ECS tasks running on Amazon EC2, you need to opt into Split Cost Allocation Data to generate task-level costs, which involves analyzing resource consumption and allows for tagging to allocate costs.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-04T17:07:20.348868"}}
{"question": "What is the role of IAM for Amazon EC2 instances and Amazon ECS tasks?", "answer": "Your Amazon EC2 instances use an IAM role to access the Amazon ECS service, while your Amazon ECS tasks use an IAM role to access services and resources.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T17:07:26.554360"}}
{"question": "How does using AWS Fargate enhance security for Amazon ECS tasks?", "answer": "Using Amazon ECS with AWS Fargate enhances security by allowing you to assign granular permissions to each task, providing a higher degree of isolation, network access control, and IAM control when building applications. Each task runs in a separate virtual machine (VM), which offers more isolation than tasks sharing the same host, and each task has its own network interface, allowing for specific security group application and control over incoming and outgoing traffic.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T17:07:26.554791"}}
{"question": "How do Amazon EC2 instances and AWS Fargate differ in terms of task isolation?", "answer": "Amazon EC2 instances can run multiple tasks on the same host, which may lead to shared resources, while AWS Fargate runs each task in a separate virtual machine (VM), providing more isolation between tasks. This means that with AWS Fargate, tasks have their own network interfaces and security groups, enhancing the isolation and security compared to EC2 instances.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T17:07:26.555012"}}
{"question": "What role do you need to create for an Amazon ECS task?", "answer": "You need to create an IAM role using the 'Amazon EC2 Container Service Task Role service role and attach a policy with the required permissions.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-04T17:07:31.140532"}}
{"question": "How can you specify a role when creating a new task definition in Amazon ECS?", "answer": "When you create a new task definition or a task definition revision, you can specify a role by selecting it from the 'Task Role' drop-down or using the 'taskRoleArn' field in the JSON format.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-04T17:07:31.140814"}}
{"question": "How does the usage of AWS GovCloud (US) region differ from standard regions in terms of Amazon ECS compliance?", "answer": "By using the AWS GovCloud (US) region, Amazon ECS can meet the requirements for sensitive data and regulated workloads, which may not be the case in standard regions.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-04T17:07:31.141356"}}
{"question": "What is the Monthly Uptime Percentage guaranteed by the Compute SLA for Amazon ECS?", "answer": "The Compute SLA guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon ECS.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-04T17:07:37.048325"}}
{"question": "What are the two SLA commitments made by AWS for Amazon ECS and AWS Fargate?", "answer": "The two SLA commitments made by AWS for Amazon ECS and AWS Fargate are: (1) a Multi-AZ Included Container Service SLA that governs Included Container Services deployed across multiple Availability Zones (AZs), and (2) a Single Task/Pod SLA that governs Included Container Service tasks and pods individually.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-04T17:07:37.048665"}}
{"question": "How does the eligibility for an SLA credit differ between the Multi-AZ Included Container Service SLA and the Single Task/Pod SLA?", "answer": "The eligibility for an SLA credit under the Compute SLA for Amazon ECS applies if more than one Availability Zone in which you are running a task, within the same region, has a Monthly Uptime Percentage of less than 99.99% during any monthly billing cycle. The context does not explicitly compare how eligibility criteria differ between the Multi-AZ and Single Task/Pod SLAs, as both are governed by the same conditions for SLA credit eligibility regarding uptime percentage.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-04T17:07:37.049327"}}
{"question": "What types of AWS services can access Amazon EFS file systems?", "answer": "Amazon EFS file systems can be accessed by Amazon Elastic Compute Cloud (EC2) instances, Amazon container services such as Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS), AWS Fargate, and AWS Lambda functions through a file system interface using standard operating system file I/O APIs.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T17:07:42.790300"}}
{"question": "What are the benefits of using Amazon EFS for workloads that require high durability and availability?", "answer": "Amazon EFS is designed to be highly durable and highly available, making it suitable for workloads that require the highest levels of durability and availability. It also provides consistent performance to each compute instance and allows for automatic scaling from gigabytes to petabytes of data without the need for provisioning storage.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T17:07:42.790642"}}
{"question": "How do the Amazon EFS Standard storage classes differ from EFS One Zone storage classes?", "answer": "Amazon EFS Standard storage classes are ideal for workloads that require the highest levels of durability and availability, while EFS One Zone storage classes are suited for workloads such as development, build, staging environments, analytics, simulation, and media transcoding, as well as backups or replicas of on-premises data that do not require Multi-AZ resilience.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T17:07:42.791144"}}
{"question": "What type of storage service is Amazon EFS?", "answer": "Amazon EFS is a file storage service for use with Amazon compute (EC2, containers, serverless) and on-premises servers.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-04T17:07:48.161443"}}
{"question": "How does Amazon EFS differ from Amazon EBS in terms of accessibility?", "answer": "Amazon EFS provides concurrently accessible storage for up to thousands of EC2 instances, allowing multiple instances to access the file system simultaneously. In contrast, Amazon EBS is a block-level storage service designed for use with a single EC2 instance, delivering performance for workloads that require the lowest-latency access to data.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-04T17:07:48.161775"}}
{"question": "What is required to use Amazon EFS?", "answer": "To use Amazon EFS, you must have an AWS account. If you dont already have one, you can sign up for an AWS account to gain access to the AWS Free Tier.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-04T17:07:48.162265"}}
{"question": "What is Amazon EFS and what does it manage for users?", "answer": "Amazon EFS is a fully managed service that manages all of the file storage infrastructure for users. This means that when using Amazon EFS, users avoid the complexity of deploying and maintaining complex file system infrastructure.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-04T17:07:53.383068"}}
{"question": "How does Amazon EFS handle storage size management?", "answer": "Amazon EFS automatically grows and shrinks as you add and remove files, which means there is no need for users to manage storage procurement or provisioning.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-04T17:07:53.383396"}}
{"question": "How does using AWS DataSync compare to using standard Linux copy tools for moving data to Amazon EFS?", "answer": "AWS DataSync provides a fast and secure way to sync existing file systems with Amazon EFS over any network connection, while standard Linux copy tools can also be used to move data files to Amazon EFS, but they may not offer the same speed and security features as DataSync.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-04T17:07:53.383885"}}
{"question": "What is the default throughput mode for Amazon EFS and what are its characteristics?", "answer": "The default throughput mode for Amazon EFS is Elastic Throughput. This mode is suitable for most file workloads as it automatically scales performance with your workload activity. Users only pay for the throughput they use, which is based on the data transferred for their file systems per month. Elastic Throughput is ideal for applications with uncertain peak throughput needs or for those that have very spiky workloads with low baseline activity, using less than 5% of capacity on average when provisioned for peak needs.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-04T17:08:00.748460"}}
{"question": "When would you choose Provisioned Throughput over Elastic Throughput in Amazon EFS?", "answer": "You would choose Provisioned Throughput over Elastic Throughput if you know your workloads peak throughput requirements and expect that your workload will consume a higher share, specifically more than 5% on average, of your applications peak throughput capacity.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-04T17:08:00.748801"}}
{"question": "How do EFS Regional file systems differ from EFS One Zone file systems in terms of data durability and availability?", "answer": "EFS Regional file systems are recommended as they offer the highest levels of durability and availability by storing data with and across multiple Availability Zones (AZs). In contrast, EFS One Zone file systems store data redundantly within a single AZ, which means that data in these file systems may become unavailable and could be lost during a disaster or fault within that AZ.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-04T17:08:00.749374"}}
{"question": "What is the durability percentage provided by Amazon EFS over a given year?", "answer": "Amazon EFS is designed to provide 99.999999999% (11 nines) of durability over a given year.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:08:08.775250"}}
{"question": "What are the best practices recommended for protecting Amazon EFS data?", "answer": "The best practices for protecting Amazon EFS data include replicating your file system across Regions using Amazon EFS Replication and implementing a functioning, regularly tested backup using AWS Backup. Additionally, it is recommended to have a backup and safeguards against accidental deletion.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:08:08.775706"}}
{"question": "How do the availability features differ between EFS Regional file systems and EFS One Zone file systems?", "answer": "EFS Regional file systems support concurrent access from EFS mount targets in all Availability Zones (AZs) in the Region, allowing for application failover to achieve higher availability. In contrast, EFS One Zone file systems only support one highly available EFS mount target in a single AZ, which means that during a disaster or fault within that AZ, data may become unavailable.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:08:08.776196"}}
{"question": "What are the three storage classes offered by Amazon EFS?", "answer": "Amazon EFS offers three storage classes: EFS Standard, EFS Infrequent Access (IA), and EFS Archive.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-04T17:08:15.303163"}}
{"question": "How does EFS Lifecycle Management assist in managing file storage?", "answer": "EFS Lifecycle Management automatically tiers files between storage classes based on access patterns. The default lifecycle policy will transition files from EFS Standard to EFS IA after 30 consecutive days without access, and to EFS Archive after 90 consecutive days without access. Users can also specify a custom policy for transitioning files based on the number of days since a files last access.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-04T17:08:15.303501"}}
{"question": "How do the costs of EFS Infrequent Access compare to EFS Archive?", "answer": "EFS Infrequent Access offers up to 95% lower costs than EFS Standard for infrequently accessed data, while EFS Archive provides up to 50% lower costs than EFS Infrequent Access, but it comes with a higher request charge when the data is accessed.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-04T17:08:15.303920"}}
{"question": "What is the minimum storage duration for data that is tiered to EFS Archive?", "answer": "Data that is tiered to EFS Archive has a minimum storage duration of 90 days. Files deleted or truncated prior to the minimum duration will incur a pro-rated charge for the remaining days, based on the size of the file prior to the corresponding action.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-04T17:08:21.477532"}}
{"question": "What are the intended use cases for EFSs cost-optimized storage classes (IA and Archive)?", "answer": "EFSs cost-optimized storage classes (IA and Archive) are designed for storing colder, inactive data, which is typically comprised of larger files.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-04T17:08:21.477857"}}
{"question": "How do EFS IA and Archive compare to EFS Standard in terms of read latencies?", "answer": "EFS IA and Archive offer higher first-byte latencies compared to EFS Standard, with low double-digit millisecond read latencies for IA and Archive versus sub-millisecond read latencies for EFS Standard.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-04T17:08:21.478198"}}
{"question": "What is the purpose of using EFS Replication?", "answer": "EFS Replication is used to maintain a replica of your file system many miles apart for disaster recovery, compliance, or business continuity planning. It allows you to failover to your replica file system during a disaster and resume operations for your business-critical applications within minutes.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T17:08:27.095565"}}
{"question": "How does EFS Replication support cost optimization?", "answer": "With EFS Replication, you can configure your replica file system independent of your original file system to use cost-optimized storage classes and a shorter age-off lifecycle management policy, which can save you up to 92% on your costs.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T17:08:27.095834"}}
{"question": "What is the difference between EFS Replication and Amazon EFS Backup?", "answer": "EFS Replication is designed for maintaining a live replica of your file system for disaster recovery and business continuity, allowing access to the replica in read-only mode and monitoring with Amazon CloudWatch. In contrast, Amazon EFS Backup, powered by AWS Backup, focuses on creating incremental copies of your file system for data protection against loss events, with automated scheduling and centralized management.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T17:08:27.095972"}}
{"question": "What feature allows you to enable automatic backups of Amazon EFS?", "answer": "Amazon EFS is natively integrated with AWS Backup, which you can use to enable automatic backups through the EFS console, API, and AWS Command Line Interface (AWS CLI).", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-04T17:08:32.889221"}}
{"question": "How do EFS Access Points enhance file system access control?", "answer": "EFS Access Points enhance file system access control by providing a network endpoint for users and applications to access an EFS file system. They enforce file- and folder-level permissions (POSIX) based on fine-grained access control and policy-based permissions defined in IAM.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-04T17:08:32.889513"}}
{"question": "What are the differences between using VPC security groups and IAM policies for controlling access to an EFS file system?", "answer": "VPC security groups are used to control the network traffic to and from your file system, while IAM policies are used to control which clients can mount your file system and dictate their permissions. VPC security groups focus on network access, whereas IAM policies manage user permissions and access rights.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-04T17:08:32.889914"}}
{"question": "What is the purpose of EFS Access Points in Amazon EFS?", "answer": "EFS Access Points give you the flexibility to create and manage multi-tenant environments for your file applications in a cloud-native way, helping you simplify data sharing.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-04T17:08:39.700736"}}
{"question": "How does EFS Access Points differ from traditional POSIX ACLs and Kerberos in managing access control?", "answer": "Unlike traditional POSIX ACLs and Kerberos, which require complex set-up, management, and maintenance, and often introduce risk, EFS Access Points integrate with IAM to enable cloud-native applications to use POSIX-based shared file storage.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-04T17:08:39.701131"}}
{"question": "What security features does Amazon EFS offer regarding data encryption, and how do they compare?", "answer": "Amazon EFS offers the ability to encrypt data at rest and in transit. Data encrypted at rest is transparently encrypted while being written and decrypted while being read, using keys managed by AWS KMS. Data encryption in transit uses industry-standard Transport Layer Security (TLS) 1.2 to encrypt data sent between clients and EFS file systems. Both encryption types can be configured together or separately to meet unique security requirements.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-04T17:08:39.701257"}}
{"question": "What services is AWS KMS integrated with for easier data encryption?", "answer": "AWS KMS is integrated with AWS services including EFS, EBS, and S3, making it simpler to encrypt your data with encryption keys that you manage.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-04T17:08:44.593834"}}
{"question": "How does AWS KMS help with regulatory and compliance needs?", "answer": "AWS KMS is integrated with AWS CloudTrail to provide logs of all key usage, which helps meet regulatory and compliance needs.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-04T17:08:44.594162"}}
{"question": "What are the differences between encrypting data at rest and encrypting data in transit in Amazon EFS?", "answer": "Encryption of data at rest and data in transit can be configured together or separately in Amazon EFS to help meet unique security requirements. This allows users to choose whether they want to encrypt data when it is stored or when it is being transmitted.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-04T17:08:44.594751"}}
{"question": "What are the three use cases for moving file data to and from Amazon EFS?", "answer": "The three use cases for moving file data to and from Amazon EFS are: first, migrating data from on-premises datacenters to reside permanently in EFS file systems; second, supporting cloud bursting workloads by off-loading application processing to the cloud and analyzing data on a cluster of EC2 instances; and third, periodically copying on-premises file data to Amazon EFS for backup and disaster recovery scenarios.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-04T17:08:51.732694"}}
{"question": "How does Amazon EFS ensure consistency and access for both on-premises servers and EC2 instances?", "answer": "Amazon EFS provides the same file system access semantics, including strong data consistency and file locking, across all EC2 instances and on-premises servers accessing a file system. This ensures that both types of servers can access the file system concurrently with consistent behavior.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-04T17:08:51.733735"}}
{"question": "How does network latency affect file operations between on-premises datacenters and Amazon EFS compared to parallelized operations?", "answer": "Network latency can impact file operations between on-premises datacenters and Amazon EFS because it can be tens of milliseconds, which directly affects the read and write throughput if file operations are serialized. In contrast, if file operations are parallelized, multiple reads and writes can be processed concurrently, helping to maximize throughput despite the latency.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-04T17:08:51.734025"}}
{"question": "What is AWS DataSync used for?", "answer": "AWS DataSync is an online data transfer service that makes it faster and simpler to move data between on-premises storage and Amazon EFS. It is designed to accelerate and secure data transfer over the internet or AWS Direct Connect, allowing for one-time data migrations, timely in-cloud analysis, and automated replication for data protection and recovery.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-04T17:08:58.901647"}}
{"question": "How does AWS DataSync enhance data transfer speed compared to standard tools?", "answer": "AWS DataSync uses a purpose-built protocol to accelerate data transfer, enabling it to operate at speeds up to 10 times faster than standard Linux copy tools and open-source tools. This acceleration applies whether transferring data over the internet or through AWS Direct Connect.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-04T17:08:58.902037"}}
{"question": "What are the key differences between AWS DataSync and AWS Transfer Family?", "answer": "AWS DataSync is primarily focused on online data transfer for moving data between on-premises storage and Amazon EFS, using a specialized protocol for speed and security. In contrast, AWS Transfer Family is a fully managed file transfer service that supports protocols like SFTP, FTPS, and FTP, and is designed to handle file transfers without requiring management of the underlying infrastructure. While DataSync emphasizes data migration and replication, AWS Transfer Family focuses on managing file transfer workflows.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-04T17:08:58.902531"}}
{"question": "What protocol does DataSync use to connect to file systems?", "answer": "DataSync uses the Network File System (NFS) protocol to connect the agent to on-premises or in-cloud file systems.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:09:04.537307"}}
{"question": "How does AWS Transfer Family ensure that users can access data in Amazon EFS?", "answer": "AWS Transfer Family ensures that users can access data in Amazon EFS by requiring that the file systems directories are accessible by the POSIX users assigned to AWS Transfer. Users can then connect using their SFTP, FTP, or FTPS clients.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:09:04.537640"}}
{"question": "What is the difference in regional requirements between DataSync and AWS Transfer Family when accessing Amazon EFS?", "answer": "DataSync can transfer files between two Amazon EFS file systems across different AWS Regions, while AWS Transfer Family endpoints must be located in the same Region as the Amazon EFS file system they are accessing.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:09:04.538227"}}
{"question": "What are the three storage classes offered by Amazon EFS?", "answer": "Amazon EFS offers three storage classes: EFS Standard, which delivers sub-millisecond latency performance for actively-used data; EFS Infrequent Access (EFS IA), which is cost-optimized for data accessed only a few times a quarter; and EFS Archive, which is cost-optimized for long-lived data accessed a few times a year or less.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-04T17:09:13.783425"}}
{"question": "How does Amazon EFS charge for data storage and access?", "answer": "With Amazon EFS, you pay only for the primary and backup storage you use and for your metadata and data read, write, and tiering activity to your EFS file system. You pay for read and write access using Elastic Throughput, but you can optionally provision throughput performance up-front using Provisioned Throughput, and for tiering data to EFSs Infrequent Access and Archive storage classes.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-04T17:09:13.783765"}}
{"question": "What is the difference between EFS Infrequent Access and EFS Archive storage classes?", "answer": "EFS Infrequent Access (EFS IA) is cost-optimized for data accessed only a few times a quarter, while EFS Archive is cost-optimized for long-lived data accessed a few times a year or less. This indicates that EFS IA is intended for data that has infrequent access but may still be accessed more regularly than data stored in EFS Archive.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-04T17:09:13.784275"}}
{"question": "Are there any setup charges or commitments required to start using Amazon EFS?", "answer": "No, there are no setup charges or commitments required to begin using Amazon EFS.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-04T17:09:19.739447"}}
{"question": "How is the usage for the AWS Free Tier calculated for Amazon EFS?", "answer": "The usage for the Free Tier is calculated each month across all AWS Regions except the AWS GovCloud Region and is automatically applied to your bill. Unused monthly usage does not roll over to the next month.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-04T17:09:19.739783"}}
{"question": "What happens to any remaining Free Tier credit balance if I upgrade to a paid plan after signing up?", "answer": "If you upgrade to a paid plan, any remaining Free Tier credit balance will automatically apply to your AWS bills.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-04T17:09:19.740204"}}
{"question": "What is the total EFS Standard storage usage in GB-Hours for the month?", "answer": "The total EFS Standard storage usage for the month is 108,000 GB-Hours, which is calculated by adding 67,200 GB-Hours for the first 14 days and 40,800 GB-Hours for the remaining 17 days.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-04T17:09:28.185385"}}
{"question": "How does EFS Lifecycle Management impact the movement of files between storage classes?", "answer": "EFS Lifecycle Management moves files between EFS Standard, EFS Infrequent Access (IA), and EFS Archive classes based on access patterns. Specifically, in this scenario, it moves 50% of EFS Standard files to the EFS IA class and 10% of EFS IA files to the EFS Archive class after 14 days of not being accessed.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-04T17:09:28.185890"}}
{"question": "How does the storage of files change from EFS Standard to EFS IA and EFS Archive during the month?", "answer": "At the beginning of the month, there are 200 GB of files on EFS Standard, 500 GB on EFS IA, and 2 TB on EFS Archive. After 14 days, EFS Lifecycle Management moves 50% of the EFS Standard files (which is 100 GB) to EFS IA, resulting in 100 GB remaining in EFS Standard and a total of 600 GB in EFS IA. Additionally, 10% of the EFS IA files (which is 50 GB) are moved to EFS Archive, resulting in 1.95 TB in EFS Archive.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-04T17:09:28.186085"}}
{"question": "How many GB-Hours are calculated for 100 GB of files from EFS Standard to EFS IA over 17 days?", "answer": "The calculation for 100 GB of files from EFS Standard to EFS IA over 17 days is 100 GB x 17 x (24 hours / day), which equals 40,800 GB-Hours.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-04T17:09:34.393552"}}
{"question": "What is the significance of converting storage usage into GB-months for calculating storage charges?", "answer": "Converting storage usage into GB-months allows for the calculation of storage charges based on the monthly billing cycle. It uses the total GB-Hours in relation to the number of hours in a month (744 hours) to determine the cost per GB-month.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-04T17:09:34.393812"}}
{"question": "How does the charge for EFS IA compare to the charge for EFS Archive based on the calculated GB-Hours?", "answer": "The charge for EFS IA is based on 392,400 GB-Hours calculated to be $8.70, while the charge for EFS Archive is based on 1,508,400 GB-Hours calculated to be $16.22. Therefore, despite having a lower rate per GB-month, the higher usage in GB-Hours results in a greater total charge for EFS Archive compared to EFS IA.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-04T17:09:34.393970"}}
{"question": "What is the total EFS storage charge calculated in the provided context?", "answer": "The total EFS storage charge is $68.47, which is calculated as $43.55 + $8.70 + $16.22.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-04T17:09:42.984145"}}
{"question": "How are the access charges for files in EFS IA and EFS Archive determined?", "answer": "The access charges for files in EFS IA and EFS Archive are determined by calculating the data tiering charges based on the amount of data moved between tiers and the read access charges based on the volume of data accessed. For EFS IA, the total access charges are calculated as $1.00 for data tiering, $2.00 for read access, and $6.00 for Elastic Throughput read charge, totaling $9.00. For Archive, the data tiering charge is $1.50, read access charge is $3.00, and Elastic Throughput read charge is $3.00, totaling $7.50.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-04T17:09:42.985546"}}
{"question": "What is the total EFS tiering and access charge compared to the total EFS storage charge?", "answer": "The total EFS tiering and access charge is $16.50, which is the sum of $9.00 from EFS IA and $7.50 from EFS Archive. This total access charge is significantly lower than the total EFS storage charge of $68.47.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-04T17:09:42.985837"}}
{"question": "What is the total monthly charge for Elastic Throughput based on the example provided?", "answer": "The total monthly Elastic Throughput charge is $486.00.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-04T17:09:48.688950"}}
{"question": "How does Elastic Throughput scale with workload activity?", "answer": "Elastic Throughput automatically scales performance with your workload activity, meaning that the throughput adjusts based on the amount of data being read and written during the operations.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-04T17:09:48.689310"}}
{"question": "What is the difference in charges between read data and write data for Elastic Throughput?", "answer": "The charge for Elastic Throughput Read Data is $0.03 per GB, resulting in a total charge of $291.60 for 9,720 GB, while the charge for Write Data is $0.06 per GB, leading to a total charge of $194.40 for 3,240 GB. Therefore, the write data charge is higher than the read data charge.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-04T17:09:48.689711"}}
{"question": "What is the total monthly charge for Provisioned Throughput in the given example?", "answer": "The total monthly Provisioned Throughput charge is $570.00.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-20", "source_tokens": 389, "generated_at": "2026-02-04T17:09:54.956201"}}
{"question": "How is the amount billed for Provisioned Throughput determined?", "answer": "The amount billed for Provisioned Throughput is based on the average throughput provisioned in excess of what your EFS Standard storage allows for the month, up to the prevailing Bursting baseline throughput limits in the AWS Region, and is measured in 'MB/s-Month.'", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-20", "source_tokens": 389, "generated_at": "2026-02-04T17:09:54.956488"}}
{"question": "How does Provisioned Throughput compare to Baseline throughput in the example provided?", "answer": "In the example, the Provisioned Throughput configured is 100 MB/s-Month, while the Baseline throughput is 5 MB/s-Month. This means that the Provisioned Throughput exceeds the Baseline throughput by 95 MB/s-Month.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-20", "source_tokens": 389, "generated_at": "2026-02-04T17:09:54.956684"}}
{"question": "What types of metadata operations incur EFS data transfer charges?", "answer": "EFS data transfer charges apply to metadata operations such as list (ls), remove (rm), and create directory (mkdir).", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T17:10:00.712571"}}
{"question": "How are metadata operations metered in terms of data transfer for Elastic Throughput?", "answer": "For Elastic Throughput, metadata operations are metered at a minimum of 4 KiB. This means that any metadata operation will incur a charge based on this minimum measurement.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T17:10:00.712875"}}
{"question": "How does the data transfer charge for viewing the details of a directory with 10 files compare to creating a new directory?", "answer": "Viewing details of a directory with 10 files will be metered at 10 x 4 KiB, resulting in a total of 40 KiB. In contrast, creating a new directory will be metered at the minimum of 4 KiB. Therefore, viewing directory details incurs a higher charge than creating a new directory.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T17:10:00.713405"}}
{"question": "What are the costs associated with using EFS Replication for data protection?", "answer": "When using EFS Replication, you pay for the storage, access charges from Infrequent Access and Archive classes, and data transfer charges if your destination file system is in a different AWS Region.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-04T17:10:08.317057"}}
{"question": "How does the EFS Lifecycle Management Policy affect the movement of files in the destination file system?", "answer": "The EFS Lifecycle Management Policy dictates that if files arent accessed for the duration of the policy (7 days in this scenario), they will move from the EFS Standard class to the EFS Infrequent Access (IA) class.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-04T17:10:08.317396"}}
{"question": "How do the storage charges differ between EFS Standard and EFS IA classes in the context of EFS Replication?", "answer": "In the context of EFS Replication, the storage charge for EFS Standard class is $0.30 per GB-month, while for the EFS IA class, it is $0.025 per GB-month. This indicates a significant difference in cost, as EFS Standard is more expensive than EFS IA.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-04T17:10:08.317808"}}
{"question": "What is the total charge for the initial sync including both storage and data transfer?", "answer": "The total charge for the initial sync, including both storage and data transfer, is $107.10.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T17:10:14.651845"}}
{"question": "How is the pro-rated storage usage for the new data calculated in incremental replication?", "answer": "The pro-rated storage usage for the new data in incremental replication is calculated by multiplying the amount of new data (150 GB) by the number of days it resides in the EFS Standard class (7 days) and then by the number of hours in a day (24 hours). This results in a total of 25,200 GB-hours for EFS Standard usage.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T17:10:14.652205"}}
{"question": "How do the charges for EFS Standard and EFS IA differ in terms of the total charges for incremental replication?", "answer": "In the total charges for incremental replication, the EFS Standard charge is $10.16, while the EFS IA charge is $2.06. This shows that the EFS Standard charge is significantly higher than the EFS IA charge for the storage usage in this scenario.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-04T17:10:14.652749"}}
{"question": "What are the total charges for incremental replication?", "answer": "The total charges for incremental replication are $15.22, which includes $12.22 for total storage charges and $3.00 for total data transfer charges.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-04T17:10:20.094861"}}
{"question": "How is the total charge related to EFS Replication calculated?", "answer": "The total charge related to EFS Replication is calculated by adding the total charges for initial sync, which is $107.10, to the total charges for incremental replication, which is $15.22. This results in a total of $122.32.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-04T17:10:20.095097"}}
{"question": "How do the charges for incremental replication and initial sync compare in the context of EFS Replication?", "answer": "The charges for incremental replication amount to $15.22, while the charges for initial sync are significantly higher at $107.10. This indicates that the initial sync incurs a greater cost compared to incremental replication.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-04T17:10:20.095238"}}
{"question": "Are the prices listed for AWS services inclusive of taxes and duties?", "answer": "No, the prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-04T17:10:24.142385"}}
{"question": "What tax applies to customers with a Japanese billing address using AWS services?", "answer": "Customers with a Japanese billing address are subject to Japanese Consumption Tax when using AWS services.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-04T17:10:24.142710"}}
{"question": "How do the tax implications differ for AWS customers based on their billing address?", "answer": "For customers with a Japanese billing address, they are subject to Japanese Consumption Tax, while other customers are subject to applicable taxes and duties, but the prices listed do not include these taxes.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-04T17:10:24.143222"}}
{"question": "What is the effective TCO of Amazon EFS compared to a non-elastic cloud solution?", "answer": "The effective TCO of Amazon EFS is up to 60% cheaper compared to a non-elastic (provisioned) cloud solution.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-04T17:10:30.312352"}}
{"question": "How does Amazon EFS optimize costs through its storage and throughput features?", "answer": "Amazon EFS optimizes costs by automatically replicating data across multiple availability zones for high availability and durability, and by automatically tiering the data across hot and cold storage classes. This means that users only pay for the storage and throughput they actually use, without incurring costs for unused capacity.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-04T17:10:30.312729"}}
{"question": "How does the storage and throughput management of EFS differ from a non-elastic (provisioned) cloud solution?", "answer": "EFS automatically scales storage and throughput up and down based on usage, meaning users do not pay for unused capacity. In contrast, a non-elastic (provisioned) cloud solution requires users to manage storage and throughput capacity at peak usage levels and does not allow for capacity reduction, often recommending to maintain a 30-50% storage utilization for growth and a 50% throughput utilization for spikes.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-04T17:10:30.313045"}}
{"question": "What is the total storage size after applying compression optimizations in the provisioned cloud solution?", "answer": "The total storage size after applying compression optimizations in the provisioned cloud solution is 1,350 TB, which represents a 50% reduction in storage size.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-04T17:10:35.452547"}}
{"question": "Why is it recommended to operate at 50% storage utilization in the provisioned cloud solution?", "answer": "It is recommended to operate at 50% storage utilization in the provisioned cloud solution because it does not automatically scale up or down, allowing for better management of resources and costs while ensuring enough capacity for expected data usage.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-04T17:10:35.452880"}}
{"question": "How does the total storage cost of the provisioned cloud solution compare to that of the EFS solution?", "answer": "The total storage cost of the provisioned cloud solution is $90.15, while the total storage cost of the EFS solution is $68.47. This indicates that the provisioned cloud solution has a higher total storage cost compared to the EFS solution.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-04T17:10:35.453352"}}
{"question": "What is the storage cost for the SSD class in the example provided?", "answer": "The storage cost for the SSD class is $25.60 per month.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-04T17:10:39.968331"}}
{"question": "How does EFS's elasticity benefit affect the total cost of ownership (TCO) compared to the provisioned solution?", "answer": "EFS's elasticity benefit allows you to only pay for what you use, resulting in a total cost of ownership (TCO) savings of 84% compared to the provisioned solution.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-04T17:10:39.968662"}}
{"question": "How does the total storage size in GB-mo for EFS compare to the provisioned solution?", "answer": "The total storage size for EFS is 1,024 GB-mo, while the total storage size for the provisioned solution is 666 GB-mo.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-04T17:10:39.969248"}}
{"question": "What is the total cost associated with the EFS data usage?", "answer": "The total cost associated with the EFS data usage is $222.48.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-04T17:10:44.145766"}}
{"question": "How does the effective cost per GB for EFS compare to the other service mentioned?", "answer": "The effective cost per GB for EFS is $0.2172, which is significantly lower than the other service's effective cost of $1.3822 per GB.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-04T17:10:44.146067"}}
{"question": "What savings percentage can be attributed to using EFS compared to the other service?", "answer": "The savings percentage attributed to using EFS compared to the other service is 84%.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-04T17:10:44.146613"}}
{"question": "Can you access EFS from Amazon ECS using the Fargate launch type?", "answer": "Yes, you can access EFS from containerized applications launched by Amazon ECS using the Fargate launch type by referencing an EFS file system in your task definition.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-04T17:10:49.177030"}}
{"question": "What is the method used to access EFS from Amazon EKS?", "answer": "You can access EFS from containerized applications launched by Amazon EKS using the EFS CSI driver, regardless of whether you are using the EC2 or Fargate launch types.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-04T17:10:49.177369"}}
{"question": "How does accessing EFS differ between Amazon ECS and Lambda?", "answer": "In Amazon ECS, you access EFS by referencing an EFS file system in your task definition, while in Lambda, you access EFS by referencing an EFS file system in your function settings.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-04T17:10:49.177899"}}
{"question": "What is Amazon EKS?", "answer": "Amazon EKS is a managed service that makes it easy for you to run Kubernetes on AWS without installing and operating your own Kubernetes control plane or worker nodes.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T17:10:54.489635"}}
{"question": "How does Kubernetes help in managing containerized applications?", "answer": "Kubernetes is an open-source container orchestration system that allows you to deploy and manage containerized applications at scale. It arranges containers into logical groupings for management and discoverability and launches them onto clusters of Amazon Elastic Compute Cloud (Amazon EC2) instances.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T17:10:54.489989"}}
{"question": "What are the differences in control plane management between Amazon EKS and running Kubernetes on your own?", "answer": "Amazon EKS provisions and scales the Kubernetes control plane across multiple AWS Availability Zones for high availability and fault tolerance, automatically detects and replaces unhealthy control plane nodes, and patches the control plane. In contrast, running Kubernetes on your own requires you to install, operate, and manage your own control plane without these automated features.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-04T17:10:54.490629"}}
{"question": "What are the two major components of Kubernetes as described in the context?", "answer": "The two major components of Kubernetes are a cluster of 'worker nodes' running your containers, and the control plane that manages when and where containers are started on your cluster while monitoring their status.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T17:11:00.939880"}}
{"question": "How does Amazon EKS reduce operational burden for users compared to running Kubernetes without EKS?", "answer": "Amazon EKS reduces operational burden by handling the provisioning, scaling, and management of the Kubernetes control plane in a highly available and secure configuration. This allows users to focus on building applications instead of managing AWS infrastructure, which they would have to do themselves without EKS.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T17:11:00.940229"}}
{"question": "How does the compatibility of applications running on Amazon EKS compare to those running in standard Kubernetes environments?", "answer": "Applications running on Amazon EKS are fully compatible with applications running on any standard Kubernetes environment, whether in on-premises data centers or public clouds. This means that users can easily migrate any standard Kubernetes application to Amazon EKS without any code modifications.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-04T17:11:00.940658"}}
{"question": "What is the primary function of Amazon EKS add-ons?", "answer": "The primary function of Amazon EKS add-ons is to provide one-click installation and management of Kubernetes operational software, facilitating the process from cluster creation to running applications with ease while keeping the operational software up to date.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-04T17:11:06.753518"}}
{"question": "How does Amazon EKS Auto Mode simplify Kubernetes cluster management?", "answer": "Amazon EKS Auto Mode simplifies Kubernetes cluster management by fully automating infrastructure provisioning, resource scaling, core add-on management, and cost optimization, thereby reducing operational overhead and ensuring secure and scalable cluster infrastructure managed by AWS.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-04T17:11:06.753864"}}
{"question": "How does Amazon EKS Auto Mode differ from standard EKS cluster management?", "answer": "Amazon EKS Auto Mode differs from standard EKS cluster management by providing fully automated operations, including automatic provisioning of infrastructure and scaling resources, while standard management requires more manual intervention for these tasks. Additionally, EKS Auto Mode offers integrated Kubernetes capabilities and is designed to optimize costs with minimal operational overhead.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-04T17:11:06.754310"}}
{"question": "What are the primary capabilities provided by Amazon EKS Auto Mode for Kubernetes applications?", "answer": "Amazon EKS Auto Mode provides a combination of integrated Kubernetes capabilities and AWS-managed infrastructure, which includes compute, storage, networking, and monitoring. These capabilities are essential for running Kubernetes applications.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-04T17:11:13.125151"}}
{"question": "How does Amazon EKS Auto Mode enhance the management of AWS infrastructure in EKS clusters?", "answer": "Amazon EKS Auto Mode enhances the management of AWS infrastructure in EKS clusters by allowing AWS to take responsibility for securing, configuring, and managing the infrastructure required for applications to run. This includes continuously observing the applications and optimizing AWS-managed resources to meet their needs.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-04T17:11:13.125477"}}
{"question": "What limitations do EC2 instances managed by EKS Auto Mode have compared to customer-managed EC2 instances?", "answer": "EC2 instances managed by EKS Auto Mode have several limitations compared to customer-managed instances. Specifically, you cannot connect remotely via SSH or SSM, modify the instance IAM role, replace the root volume, or attach additional elastic network interfaces. These restrictions are in place to allow AWS to effectively secure and manage the instances.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-04T17:11:13.125983"}}
{"question": "What is the recommended approach for running Amazon EKS moving forward?", "answer": "The recommended approach for running Amazon EKS moving forward is Amazon EKS Auto Mode.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:11:20.410042"}}
{"question": "How does EKS Auto Mode improve the security of EKS clusters?", "answer": "EKS Auto Mode improves the security of EKS clusters in three ways: 1) It is configured according to AWS security best practices and hardened according to CIS Level 1 benchmarks, including no remote access, an immutable root file system, and kernel-level mandatory access controls. 2) Its AWS-managed EC2 instances are automatically updated with the latest security and bug fixes as soon as they become available, with patches applied in place when possible. 3) It sets a default maximum instance lifetime of 14 days for AWS-managed EC2 instances, which helps meet security and compliance best practices, although this can be configured for shorter or longer durations up to a maximum of 21 days.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:11:20.410320"}}
{"question": "What are the capabilities that EKS Auto Mode supports compared to EKS with Fargate?", "answer": "EKS Auto Mode supports all upstream Kubernetes primitives and platform tools like Istio, which Fargate does not support. Additionally, EKS Auto Mode fully supports all EC2 runtime purchase options, including GPU and Spot instances, allowing customers to leverage negotiated EC2 discounts and savings mechanisms, which are not available with EKS using Fargate. Furthermore, EKS Auto Mode allows customers to achieve a similar isolation model as Fargate, using standard Kubernetes scheduling capabilities.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T17:11:20.410836"}}
{"question": "What happens to existing instances after upgrading the EKS control plane to a new Kubernetes version?", "answer": "After upgrading the EKS control plane to a new Kubernetes version, existing instances are gradually updated with Kubernetes software for the new version. This process occurs simultaneously with new instances launched by EKS Auto Mode, which run with the latest Kubernetes software that matches the control plane version.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-04T17:11:30.853805"}}
{"question": "What are the benefits of using Amazon EKS Auto Mode?", "answer": "Amazon EKS Auto Mode provides integrated and managed versions of essential Kubernetes capabilities, which include compute, storage, and networking. This includes managed versions of the EKS Auto Modes agent, the containerd container runtime, the kubelet, a network proxy, a managed Karpenter controller, the Amazon EBS CSI controller, the AWS VPC CNI, CoreDNS, and the AWS Load Balancer Controller. With EKS Auto Mode, users do not need to install or manage certain EKS add-ons because the cluster includes integrated versions of the capabilities those add-ons provide.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-04T17:11:30.854151"}}
{"question": "How do the integrated capabilities of EKS Auto Mode compare to traditional EKS add-ons?", "answer": "The integrated capabilities of EKS Auto Mode replace certain EKS add-ons, such as the VPC CNI, CoreDNS, kube-proxy, and the CloudWatch Observability agent, meaning users do not need to manage these separately. However, for workloads that have not yet migrated to EKS Auto Mode, users must continue to use those EKS add-ons. Other EKS add-ons, besides those replaced by EKS Auto Modes integrated capabilities, can still be run on clusters using EKS Auto Mode.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-04T17:11:30.854655"}}
{"question": "How can I view the managed EC2 instances launched by EKS Auto Mode?", "answer": "You can view the managed EC2 instances launched by EKS Auto Mode using the EC2 DescribeInstances API or through the AWS Console by default.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T17:11:36.545152"}}
{"question": "What are the benefits of using Amazon EKS managed in-place cluster upgrades?", "answer": "Amazon EKS performs managed, in-place cluster upgrades for both Kubernetes and Amazon EKS platform versions, which simplifies cluster operations and allows you to take advantage of the latest Kubernetes features and updates to Amazon EKS configuration and security patches.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T17:11:36.546220"}}
{"question": "How do Amazon EKS platform versions relate to Kubernetes minor versions?", "answer": "Amazon EKS platform versions represent the capabilities of the cluster control plane and are independent for different Kubernetes minor versions. Each minor version has one or more associated Amazon EKS platform versions, and when a new minor version is available, the initial platform version starts at eks.1.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-04T17:11:36.546437"}}
{"question": "What is the maximum duration for which a Kubernetes minor version can be used under Amazon EKS extended support?", "answer": "A Kubernetes minor version can be used for up to 26 months from the time the version is generally available from Amazon EKS under extended support.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T17:11:41.500941"}}
{"question": "Why is manual control over Kubernetes cluster versioning important for application behavior?", "answer": "Manual control over Kubernetes cluster versioning is important because it allows you to test applications against new versions of Kubernetes before upgrading production clusters, helping to ensure compatibility and stability.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T17:11:41.501280"}}
{"question": "How do the EKS-optimized Amazon Machine Images (AMIs) differ from custom AMIs built by users?", "answer": "EKS-optimized Amazon Machine Images (AMIs) are regularly updated by AWS and include the most up-to-date versions of necessary worker node binaries like Docker and Kubelet, while custom AMIs built by users require the use of Packer scripts provided by AWS to document build steps and identify included binaries.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T17:11:41.501754"}}
{"question": "What are the three Amazon EKS options for hybrid deployments?", "answer": "The three Amazon EKS options for hybrid deployments are Amazon EKS, Amazon EKS Anywhere, and Amazon EKS Connector.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-04T17:11:46.485283"}}
{"question": "What is the purpose of Amazon EKS Anywhere?", "answer": "Amazon EKS Anywhere is designed to run in isolated or air-gapped environments. It is customer-managed, AWS-supported Kubernetes management software that operates on infrastructure that you manage.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-04T17:11:46.485823"}}
{"question": "How does Amazon EKS on AWS Outposts differ from Amazon EKS Hybrid Nodes?", "answer": "Amazon EKS on AWS Outposts allows you to run self-managed nodes on AWS-managed infrastructure in your facilities, while Amazon EKS Hybrid Nodes runs on bare metal or virtualized infrastructure that you manage in your facilities.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-04T17:11:46.486047"}}
{"question": "What is the main function of Amazon EKS Hybrid Nodes?", "answer": "The main function of Amazon EKS Hybrid Nodes is to use on-premises and edge infrastructure as nodes in Amazon EKS clusters, while AWS manages the AWS-hosted Kubernetes control plane.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:11:51.864992"}}
{"question": "How does Amazon EKS Hybrid Nodes differ from Amazon EKS Anywhere in terms of management responsibility?", "answer": "Amazon EKS Hybrid Nodes is managed by AWS for the Kubernetes control plane, while Amazon EKS Anywhere is a customer-managed product where customers are responsible for the cluster lifecycle operations and maintenance.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:11:51.865362"}}
{"question": "What are the key differences in infrastructure support between Amazon EKS Hybrid Nodes and Amazon EKS Anywhere?", "answer": "Amazon EKS Hybrid Nodes works with any on-premises hardware or virtual machines, whereas Amazon EKS Anywhere supports specific infrastructures including VMware vSphere, bare metal, Nutanix, Apache CloudStack, and AWS Snow.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:11:51.865990"}}
{"question": "What can you do with the Amazon EKS Connector once a Kubernetes cluster is connected?", "answer": "Once a Kubernetes cluster is connected using the Amazon EKS Connector, you can view its status, configuration, and workloads in the Amazon EKS console. However, the Amazon EKS Connector does not enable management or mutating operations for the connected clusters through the Amazon EKS console.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-04T17:11:58.319233"}}
{"question": "How does Amazon EKS Hybrid Nodes differ from Amazon EKS Anywhere in terms of management responsibilities?", "answer": "With Amazon EKS Hybrid Nodes, AWS manages the security, availability, and scalability of the Kubernetes control plane, which is hosted in the AWS Cloud, while only the nodes run on your infrastructure. In contrast, with Amazon EKS Anywhere, you are responsible for managing the Kubernetes clusters that run entirely on your own infrastructure.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-04T17:11:58.319619"}}
{"question": "What are the payment structures for Amazon EKS Hybrid Nodes compared to Amazon EKS Anywhere?", "answer": "With Amazon EKS Hybrid Nodes, there are no upfront commitments or minimum fees, and you pay for the hourly use of your cluster and nodes as you use them. On the other hand, Amazon EKS Anywhere allows you to purchase Amazon EKS Anywhere Enterprise Subscriptions for a one-year or three-year term.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-04T17:11:58.320186"}}
{"question": "What are the payment structures for Amazon EKS on AWS Outposts and Amazon EKS Hybrid Nodes?", "answer": "With Amazon EKS on AWS Outposts, you pay for the Amazon EKS cluster and AWS Outposts capacity. In contrast, with Amazon EKS Hybrid Nodes, you pay for the Amazon EKS cluster and node usage.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T17:12:04.157444"}}
{"question": "How does the EKS Dashboard enhance visibility and governance of Kubernetes infrastructure?", "answer": "The EKS Dashboard centralizes your view of Kubernetes clusters across AWS Regions and accounts, displaying information such as clusters running specific Kubernetes versions, managed node groups with specific AMI versions, and EKS add-ons with their version distributions. It allows interaction with widgets to filter resources, presents an inventory in a tabular format, and enables customization according to operational needs. Additionally, it supports further analysis and integration with other visualization tools by allowing data to be downloaded in CSV format.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T17:12:04.157789"}}
{"question": "What is the difference in add-on support between Amazon EKS Hybrid Nodes and Amazon EKS on AWS Outposts?", "answer": "Amazon EKS Hybrid Nodes and Amazon EKS on AWS Outposts support different Amazon EKS add-ons for networking and storage.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-04T17:12:04.158297"}}
{"question": "What is the primary function of the EKS Dashboard in AWS?", "answer": "The primary function of the EKS Dashboard is to centralize your view of Kubernetes clusters across AWS Regions and accounts, enabling unified visibility, governance, and operational planning. It allows users to observe cluster inventory, monitor compliance, and forecast EKS control plane extended support costs.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-04T17:12:10.820723"}}
{"question": "How does the EKS Dashboard enhance Kubernetes infrastructure management?", "answer": "The EKS Dashboard enhances Kubernetes infrastructure management by providing a comprehensive view of raw and aggregated cluster metadata, allowing users to easily access information without switching between AWS Regions and accounts. Its filtering and search capabilities enable quick identification of clusters based on specific criteria, which aids in optimizing management processes.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-04T17:12:10.820944"}}
{"question": "How does the EKS Dashboard differ from traditional observability tools like Amazon CloudWatch?", "answer": "The EKS Dashboard differs from traditional observability tools like Amazon CloudWatch in that it provides a centralized view of Kubernetes cluster metadata but is not designed for deep cluster-level metrics or troubleshooting time-sensitive operational incidents. While the EKS Dashboard offers unified visibility and governance, tools like Amazon CloudWatch and Prometheus provide granular operational insights and are better suited for addressing immediate monitoring and security needs.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-04T17:12:10.821125"}}
{"question": "What types of protocols are supported by Amazon ElastiCache?", "answer": "Amazon ElastiCache is protocol compliant with Valkey, Memcached, and Redis OSS, allowing existing code, applications, and popular tools used with these environments to work seamlessly with the service.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:12:16.511464"}}
{"question": "How does Amazon ElastiCache improve application performance?", "answer": "Amazon ElastiCache improves application performance by allowing retrieval of information from a fast, managed, in-memory system instead of relying on slower disk-based systems. It stores critical pieces of data in memory for low-latency access, which is particularly beneficial for read-heavy application workloads and compute-intensive workloads.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:12:16.511701"}}
{"question": "How does the management of in-memory environments differ when using ElastiCache compared to traditional methods?", "answer": "Using Amazon ElastiCache simplifies and offloads the management, monitoring, and operation of in-memory environments, whereas traditional methods often require more manual administrative tasks. ElastiCache automates these common tasks and allows users to add a caching or in-memory layer to their application architecture quickly through the AWS Management Console.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:12:16.512218"}}
{"question": "What types of caching technologies does ElastiCache offer?", "answer": "ElastiCache offers fully managed Valkey, Memcached, and Redis OSS for demanding applications that require submillisecond response times.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-04T17:12:22.178677"}}
{"question": "How does Amazon ElastiCache Serverless simplify the management of infrastructure?", "answer": "Amazon ElastiCache Serverless simplifies the management of infrastructure by eliminating the need for users to configure and manage any infrastructure, allowing them to focus on utilizing the service without administrative overhead.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-04T17:12:22.179047"}}
{"question": "How does the process of creating a cache differ between using ElastiCache Serverless and designing your own ElastiCache cluster?", "answer": "When using ElastiCache Serverless, caches can be created quickly with the default recommended settings and can be operational in under a minute, whereas designing your own ElastiCache cluster involves provisioning resources and may require more time for setup and configuration.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-04T17:12:22.179645"}}
{"question": "What is the service level agreement (SLA) provided by ElastiCache Serverless?", "answer": "ElastiCache Serverless provides a 99.99% availability service level agreement (SLA) for each cache.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T17:12:30.630443"}}
{"question": "How does ElastiCache Serverless manage capacity planning for its cache?", "answer": "ElastiCache Serverless removes the need for time-consuming capacity planning by continuously monitoring a caches compute, memory, and network utilization. This allows it to instantly scale to meet demand without downtime or performance degradation.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T17:12:30.631673"}}
{"question": "How does the scaling capability of ElastiCache Serverless compare to traditional ElastiCache solutions?", "answer": "ElastiCache Serverless scales without downtime or performance degradation by allowing the cache to scale up and initiating scale-out in parallel to meet application requirements just in time, whereas traditional ElastiCache solutions may require manual capacity planning and could experience downtime during scaling operations.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T17:12:30.631973"}}
{"question": "What are the benefits of using Reserved Nodes for ElastiCache?", "answer": "Reserved Nodes provide a significant discount over on-demand usage when you commit to a one-year or three-year term. You can make a one-time, up-front payment to create a reservation to run your cache in a specific Region and receive a discount off the ongoing hourly usage charge.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:12:37.399570"}}
{"question": "How does the Valkey engine differ from Redis OSS in terms of pricing and reservation benefits?", "answer": "The Valkey engine is priced 20% lower than Redis OSS. If you have an existing Redis OSS reserved node, upgrading to the Valkey engine allows you to continue receiving your reservation benefits while also getting 20% more value, as you can create an additional node at no extra cost.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:12:37.400041"}}
{"question": "How does ElastiCache Serverless compare to Reserved Nodes in terms of compatibility?", "answer": "ElastiCache Serverless is not compatible with Reserved Nodes. While Reserved Nodes provide discounts for on-demand usage, ElastiCache Serverless operates on a pay-for-what-you-use model, which does not involve reservations.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:12:37.400339"}}
{"question": "What happens to the pricing of a Reserved Node if the one-time payment cannot be authorized by the next billing period?", "answer": "If the one-time payment cannot be successfully authorized by the next billing period, the discounted price will not take effect.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-04T17:12:43.364468"}}
{"question": "How does the ElastiCache billing system handle reservations when calculating charges for nodes?", "answer": "The ElastiCache billing system automatically applies your reservations, such that all eligible nodes are charged at the lower hourly Reserved Cache Node rate when computing your bill.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-04T17:12:43.364835"}}
{"question": "What are the differences between the All Upfront, No Upfront, and Partial Upfront payment options for Reserved Nodes?", "answer": "With the All Upfront payment option, you pay for the entire term of the Reserved Node in one upfront payment. The No Upfront option allows you to pay nothing upfront, with the entire value spread across every hour in the term, and you will be billed for every hour regardless of usage. The Partial Upfront option requires a small upfront payment and a low hourly rate for every hour in the term, regardless of usage.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-04T17:12:43.365334"}}
{"question": "What encryption methods does ElastiCache support for data at rest and in transit?", "answer": "ElastiCache allows you to configure encryption of data at rest using AWS Key Management Service (AWS KMS) and encryption of data in transit using Transport Layer Security (TLS).", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T17:12:48.476481"}}
{"question": "How does ElastiCache ensure network access control when not using Amazon VPC?", "answer": "When not using Amazon VPC, ElastiCache controls access to caches through network security groups, which act like a firewall to control network access. By default, network access is turned off, and access must be explicitly enabled from specific Amazon EC2 security groups.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T17:12:48.477307"}}
{"question": "What is the relationship between ElastiCache and the HIPAA compliance program?", "answer": "ElastiCache is a HIPAA-eligible service and is covered under the AWS Business Associate Addendum (BAA), allowing users to process, maintain, and store protected health information (PHI) if they have an executed BAA with AWS.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T17:12:48.477654"}}
{"question": "Is ElastiCache a FedRAMP-authorized service?", "answer": "Yes, ElastiCache is included in the AWS FedRAMP compliance program as a FedRAMP-authorized service.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T17:12:54.985940"}}
{"question": "What benefits does ElastiCache for Valkey offer compared to traditional Redis OSS?", "answer": "ElastiCache for Valkey offers a fully managed experience built on open source technology, leveraging AWS's security, operational excellence, a 99.99% availability SLA, and reliability. Additionally, it allows for cost optimization with a 33% reduced price and a minimum data storage requirement of 100 MB, which is 90% lower than ElastiCache Redis OSS.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T17:12:54.986864"}}
{"question": "How does the cost of ElastiCache for Valkey compare to ElastiCache Redis OSS?", "answer": "ElastiCache for Valkey has a 33% reduced price compared to ElastiCache Redis OSS, and it also offers a minimum data storage of 100 MB, which is 90% lower than what is required for ElastiCache Redis OSS.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-04T17:12:54.987032"}}
{"question": "What versions of Redis OSS can be directly upgraded to Valkey without downtime?", "answer": "You can directly upgrade your existing Redis OSS engine version 5.0 and above to the most recent version of Valkey without downtime.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:13:01.946951"}}
{"question": "How does ElastiCache ensure high availability when using ElastiCache Serverless?", "answer": "When using ElastiCache Serverless, data is automatically stored redundantly across multiple availability zones (AZs) for high availability.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:13:01.947185"}}
{"question": "What are the differences in features and functionality when upgrading from ElastiCache for Redis OSS to ElastiCache for Valkey?", "answer": "You will have the same features, SLAs, and functionality if you upgrade from ElastiCache for Redis OSS to ElastiCache for Valkey.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:13:01.947541"}}
{"question": "What are the three main differences between ElastiCache for Valkey and ElastiCache for Redis OSS?", "answer": "The three main differences are: first, ElastiCache for Valkey allows for faster scaling and 20% more memory efficiency compared to ElastiCache for Redis OSS. Second, ElastiCache for Valkey is priced up to 33% lower than ElastiCache for Redis OSS. Finally, ElastiCache for Valkey uses Valkey, the open source project, which helps avoid vendor lock-in.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-04T17:13:09.965605"}}
{"question": "How does the upgrade process from Redis OSS to ElastiCache for Valkey work?", "answer": "You can upgrade your existing Redis OSS engine version to the most recent version of Valkey in-place without downtime and in just a few clicks. The upgrade can be performed from any version of Redis OSS supported on ElastiCache to any version of ElastiCache for Valkey. However, if you are upgrading from Redis OSS versions earlier than 5.0.6, it requires DNS propagation that may experience a failover time of 30 to 60 seconds.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-04T17:13:09.966028"}}
{"question": "How does the pricing of ElastiCache for Valkey compare to ElastiCache for Redis OSS?", "answer": "ElastiCache for Valkey is priced up to 33% lower than ElastiCache for Redis OSS, making it a more cost-effective option.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-04T17:13:09.966222"}}
{"question": "What discount is offered when switching from Redis OSS to Valkey with reserved nodes?", "answer": "Valkey is priced at a 20% discount relative to Redis OSS, and with reserved node flexibility, you can apply your Redis OSS reserved nodes to 20% more Valkey reserved nodes.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:13:18.087834"}}
{"question": "What are the performance benefits of using ElastiCache for Valkey compared to ElastiCache version 7.0 for Redis OSS?", "answer": "ElastiCache for Valkey delivers up to 100% more throughput and 50% lower P99 latency than ElastiCache version 7.0 for Redis OSS. It also provides enhanced I/O threads that improve performance by using more cores for processing I/O and dynamically adjusting to the workload, as well as improving the throughput of TLS-enabled clusters by offloading encryption to the enhanced I/O threads.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:13:18.088073"}}
{"question": "How does the memory usage of ElastiCache version 8.1 for Valkey compare to that of ElastiCache version 7.2 for Valkey and version 7.1 for Redis OSS?", "answer": "ElastiCache version 8.1 for Valkey results in up to 40% lower memory usage for node-based clusters with Cluster Mode compared to ElastiCache version 7.2 for Valkey and version 7.1 for Redis OSS.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-04T17:13:18.088231"}}
{"question": "What metric is used to monitor CPU utilization in ElastiCache Serverless?", "answer": "In ElastiCache Serverless, the CPU utilization is monitored using the ElastiCache Processing Units (ECPU) metric.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-04T17:13:24.211003"}}
{"question": "Why is it recommended to use both CPUUtilization and EngineCPUUtilization metrics when designing your own cluster?", "answer": "It is recommended to use both CPUUtilization and EngineCPUUtilization metrics together because the CPUUtilization metric measures the CPU utilization for the instance as a whole, while the EngineCPUUtilization metric measures the utilization at the engine process level. Since the main engine process is single threaded and uses only one CPU core, relying solely on CPUUtilization does not provide precise visibility into the CPU utilization rates at the process level.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-04T17:13:24.212184"}}
{"question": "How do the roles of the primary and read replica differ in a cache setup?", "answer": "In a cache setup, the primary serves both writes and reads, while the read replica serves exclusively read traffic. Additionally, the read replica functions as a warm standby, ready to take over if the primary becomes impaired.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-04T17:13:24.212559"}}
{"question": "How many read replicas can you create for a given primary cache node in ElastiCache?", "answer": "You can create up to five (5) read replicas for a given primary cache node in ElastiCache.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-04T17:13:30.628054"}}
{"question": "What are some common reasons for deploying read replicas in an ElastiCache setup?", "answer": "Common reasons for deploying read replicas include scaling beyond the compute or I/O capacity of a single primary node for read-heavy workloads, serving read traffic while the primary is unavailable, and data protection scenarios such as promoting a read replica in a different availability zone (AZ) if the primary node fails.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-04T17:13:30.628413"}}
{"question": "What happens to read replicas during a failover in ElastiCache, and how do they resume replication?", "answer": "During a failover in ElastiCache, any associated and available read replicas should automatically resume replication once the failover has completed. They will acquire updates from the newly promoted primary node.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-04T17:13:30.628891"}}
{"question": "What happens to updates made on a primary cache node in ElastiCache?", "answer": "Updates to a primary cache node will automatically be replicated to any associated read replicas.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-04T17:13:35.185915"}}
{"question": "What factors can cause a read replica to fall behind its primary cache node?", "answer": "A read replica can fall behind its primary cache node due to several reasons, including when the write I/O volume to the primary cache node exceeds the rate at which changes can be applied to the read replica, network partitions or latency between the primary cache node and the read replica, and the inherent strengths and weaknesses of Valkey or Redis OSS replication.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-04T17:13:35.186344"}}
{"question": "How is the billing for a read replica in ElastiCache determined in comparison to a standard cache node?", "answer": "A read replica is billed as a standard cache node and at the same rates. The rate per cache node hour for a read replica is determined by the cache node class of the read replica, just like a standard cache node.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-04T17:13:35.186738"}}
{"question": "What is the purpose of initiated failover in ElastiCache?", "answer": "The purpose of initiated failover in ElastiCache is to resume cache operations as quickly as possible by flipping the DNS record for the cache node to point at the read replica, which is then promoted to become the new primary.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-04T17:13:40.990095"}}
{"question": "How does the Global Datastore feature enhance ElastiCache functionality?", "answer": "The Global Datastore feature enhances ElastiCache functionality by allowing for fully managed, fast, reliable, and security-focused replication across AWS Regions. This enables the creation of cross-Region read replica clusters for low-latency reads and disaster recovery.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-04T17:13:40.990444"}}
{"question": "What are the differences between failing over to a read replica and adding or removing a read replica in a cluster environment?", "answer": "Failing over to a read replica involves the primary node being replaced by a replica node, which is promoted to primary to ensure continuity of operations during a failure. In contrast, adding or removing a read replica in a cluster environment can be done without taking the cluster offline, allowing it to continue serving incoming I/O during the operation.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-04T17:13:40.990843"}}
{"question": "What happens during an initiated failover in ElastiCache?", "answer": "During an initiated failover in ElastiCache, the DNS record for your cache node is flipped to point at the read replica, which is then promoted to become the new primary. This process is designed to resume cache operations as quickly as possible.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-04T17:13:46.286017"}}
{"question": "Why is it recommended to implement cache node connection retry at the application layer during failover?", "answer": "It is recommended to implement cache node connection retry at the application layer during failover to ensure that your application can handle the transition smoothly and maintain continuous access to the cache, especially since the failover process may take some time.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-04T17:13:46.287056"}}
{"question": "How does the failover process in a Multi-AZ configuration differ from a standard configuration in ElastiCache?", "answer": "In a Multi-AZ configuration, ElastiCache requires at least one read replica per primary node, which enhances availability. During a failure, ElastiCache automatically detects the failure of a primary node, selects a read replica, and promotes it to primary, while also propagating the DNS changes. In contrast, a standard configuration may not have the same level of redundancy and automatic promotion.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-04T17:13:46.287350"}}
{"question": "What is the availability SLA for ElastiCache when running in Multi-AZ mode?", "answer": "When running ElastiCache in a Multi-AZ configuration, your caches are eligible for the 99.99% availability SLA.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T17:13:51.106450"}}
{"question": "How does automatic failover work in ElastiCache when the primary node fails?", "answer": "When the primary node fails, ElastiCache automatically detects the failure, selects one from the available read replicas, and promotes it to become the new primary. It also propagates the DNS changes of the promoted replica so that your application can continue writing to the primary endpoint. Additionally, ElastiCache will spin up a new node to replace the promoted read replica in the same Availability Zone (AZ) as the failed primary.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T17:13:51.106678"}}
{"question": "What happens if both the primary and replicas of ElastiCache are placed in the same AZ?", "answer": "Placing both the primary and the replicas in the same AZ will not make your ElastiCache replication group resilient to an AZ disruption.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-04T17:13:51.107070"}}
{"question": "What feature allows users to create snapshots of their ElastiCache caches?", "answer": "The feature that allows users to create snapshots of their ElastiCache caches is called Backup and Restore. ElastiCache stores these snapshots, which can be used to restore caches later.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T17:13:56.002851"}}
{"question": "Why is it important to architect applications with redundancy across multiple Availability Zones (AZs)?", "answer": "It is important to architect applications with redundancy across multiple Availability Zones (AZs) to ensure resilience in the event of an AZ disruption. This design provides low latency network connectivity and helps maintain application availability.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T17:13:56.003190"}}
{"question": "How do the retention policies differ for manual snapshots and automatic cache snapshots when deleting an ElastiCache cache?", "answer": "When deleting an ElastiCache cache, manual snapshots are retained, and users have the option to create a final snapshot before deletion. In contrast, automatic cache snapshots are not retained when the cache is deleted.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-04T17:13:56.003700"}}
{"question": "What enhancements does the ElastiCache engine provide over Valkey and Redis OSS?", "answer": "The ElastiCache engine provides enhancements that include more usable memory, improved synchronization under heavy load and during network disconnections, and smoother failovers. These enhancements allow for safe allocation of more memory without increased swap usage, faster synchronization without using disk for operations, and faster recovery of shards during failovers without flushing data for a full resync with the primary.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T17:14:01.917470"}}
{"question": "How does ElastiCache ensure data security during operations?", "answer": "ElastiCache ensures data security through features such as encryption in transit and encryption at rest. Encryption in transit secures communications between clients and ElastiCache, as well as between servers. Encryption at rest protects data during sync, backup, and swap operations, and also encrypts backups stored in Amazon S3. Users can select additional security options like Valkey AUTH or Role-Based Access Control (RBAC) when enabling in-transit encryption.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T17:14:01.917853"}}
{"question": "How does the cost of using the enhanced ElastiCache engine compare to using encryption features?", "answer": "There are no additional costs for using the enhanced ElastiCache engine, nor are there additional costs for using encryption features. Users can benefit from improved performance and security without incurring extra charges.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T17:14:01.918167"}}
{"question": "What is the primary function of Global Datastore in ElastiCache?", "answer": "The primary function of Global Datastore in ElastiCache is to provide fully managed, fast, reliable, and security-focused cross-Region replication, allowing for data to be written in one Region and available for read in up to two other cross-Region replica clusters.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-04T17:14:07.215456"}}
{"question": "How does Global Datastore enhance the responsiveness of applications?", "answer": "Global Datastore enhances the responsiveness of applications by typically replicating data across Regions in under one second, which enables low-latency reads from geolocal replicas that are closer to end users.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-04T17:14:07.215700"}}
{"question": "How does the failover process work in Global Datastore when the primary cluster is degraded?", "answer": "In the event of primary cluster degradation, Global Datastore does not automatically promote a secondary cluster. Instead, a user must manually initiate the failover by promoting a secondary cluster to become the primary, and this promotion typically completes in less than one minute.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-04T17:14:07.215880"}}
{"question": "What is the typical RPO of Global Datastore in ElastiCache?", "answer": "The typical RPO of Global Datastore in ElastiCache is under one second, meaning that data written in a primary Region is available in secondary Regions within one second.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-04T17:14:14.024389"}}
{"question": "How does ElastiCache enhance performance for applications with high request rates?", "answer": "ElastiCache serves as an ideal front end for data stores like Amazon RDS or DynamoDB by providing a high-performance middle tier for applications that have extremely high request rates or low latency requirements.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-04T17:14:14.024728"}}
{"question": "What are the differences in RPO and RTO for Global Datastore in ElastiCache?", "answer": "The RPO for Global Datastore is typically under one second, while the RTO is typically under a minute. This means that the data can be replicated to secondary Regions quickly, but in the case of a failover event, it may take up to a minute to promote the secondary cluster to full read and write capabilities.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-04T17:14:14.025367"}}
{"question": "What standard operations can you perform with ElastiCache that are compliant with Memcached?", "answer": "With ElastiCache, you can perform standard Memcached operations such as get, set, incr, and decr in the same manner as you would in your existing Memcached deployments.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-04T17:14:20.006140"}}
{"question": "Why is it beneficial to use ElastiCache without recompiling or relinking applications?", "answer": "It is beneficial to use ElastiCache without recompiling or relinking applications because the libraries you use will continue to work, allowing for a smoother transition to ElastiCache without needing significant changes to your existing application code.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-04T17:14:20.007102"}}
{"question": "How does accessing ElastiCache clusters differ between Amazon VPC and non-VPC installations?", "answer": "Accessing ElastiCache clusters in an Amazon VPC can be done from either the Amazon EC2 network or from your own data center, while in non-VPC installations, the IP address of a node can change over time due to autoreplacements after a failure, whereas the DNS name for a node remains constant.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-04T17:14:20.007261"}}
{"question": "What factors should be considered when choosing the initial configuration for ElastiCache?", "answer": "When choosing the initial configuration for ElastiCache, you should consider the total memory required for your data to achieve your target cache-hit rate and the number of nodes required to maintain acceptable application performance without overloading the database backend in the event of node failures.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-04T17:14:25.489049"}}
{"question": "How does ElastiCache Serverless help in managing a Memcached cache?", "answer": "ElastiCache Serverless simplifies running a highly available Memcached cache, allowing users to operate without the need to worry about the exact number of nodes required, as nodes can be quickly added or removed later.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-04T17:14:25.489417"}}
{"question": "What is the difference in node configuration if a memory requirement is 13 GB?", "answer": "If the memory requirement is 13 GB, it is advisable to use two cache.m4.large nodes instead of one cache.m4.xlarge node to improve fault tolerance and ensure the application can survive the loss of one or two nodes.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-04T17:14:25.489622"}}
{"question": "What steps does ElastiCache take to react to a node failure?", "answer": "When a node failure is detected, ElastiCache will repair the node by acquiring new service resources and redirecting the node's existing DNS name to point to these new resources. For Amazon VPC installations, both the DNS name and IP address of the node remain the same during recovery, while for non-Amazon VPC installations, the DNS name remains unchanged but the IP address may change.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T17:14:34.349039"}}
{"question": "How does ElastiCache improve application performance in conjunction with other AWS services?", "answer": "ElastiCache is ideally suited as a front end for AWS services like Amazon RDS and DynamoDB, providing extremely low latency for high-performance applications. It offloads some of the request volume from these services, which in turn provide long-lasting data durability. Additionally, ElastiCache can enhance performance when used with Amazon EC2 and Amazon EMR.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T17:14:34.349336"}}
{"question": "What is the difference in DNS and IP address handling for ElastiCache node recovery between Amazon VPC and non-Amazon VPC installations?", "answer": "For Amazon VPC installations, ElastiCache ensures that both the DNS name and the IP address of the node remain the same when the node is recovered after a failure. In contrast, for non-Amazon VPC installations, while the DNS name remains unchanged, the underlying IP address of the node can change during recovery.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T17:14:34.349688"}}
{"question": "What is the purpose of the Auto Discovery feature in ElastiCache?", "answer": "The purpose of the Auto Discovery feature in ElastiCache is to save developers time and effort while reducing the complexity of their applications. It enables automatic discovery of cache nodes by clients when they are added to or removed from an ElastiCache cluster, eliminating the need for manual updates to the list of cache node endpoints.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-04T17:14:40.304014"}}
{"question": "How does Auto Discovery enhance the client application's ability to handle cache cluster changes?", "answer": "Auto Discovery enhances the client application's ability to handle cache cluster changes by allowing clients to automatically reconfigure themselves without needing initialization, such as shutting down and restarting the application. This is accomplished through the provision of a unique configuration endpoint that provides the necessary information on cache cluster membership.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-04T17:14:40.304379"}}
{"question": "What is the difference between using Auto Discovery and manually updating cache node endpoints in an ElastiCache cluster?", "answer": "The difference between using Auto Discovery and manually updating cache node endpoints in an ElastiCache cluster is that Auto Discovery automates the process of discovering cache nodes, eliminating the need for manual updates and reducing downtime. In contrast, manually updating cache node endpoints requires developers to handle cluster membership changes, which often involves shutting down and restarting the application, leading to potential downtime.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-04T17:14:40.304571"}}
{"question": "What must you have before downloading the ElastiCache Cluster Client?", "answer": "You must have an ElastiCache account before you can download the ElastiCache Cluster Client. If you do not already have one, you can sign up from the ElastiCache detail page.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-04T17:14:46.262384"}}
{"question": "How can a user take advantage of the Auto Discovery feature in ElastiCache?", "answer": "To take advantage of Auto Discovery, a client capable of Auto Discovery must be used to connect to an ElastiCache Cluster. ElastiCache currently supports clients capable of Auto Discovery for .Net, Java, and PHP, which can be downloaded from the ElastiCache console.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-04T17:14:46.262739"}}
{"question": "How does the use of the ElastiCache Cluster Client differ from using traditional Memcached clients in terms of Auto Discovery?", "answer": "The ElastiCache Cluster Client is specifically designed to take advantage of the Auto Discovery feature, while traditional Memcached clients can still connect to the ElastiCache cluster without requiring changes. However, to fully utilize Auto Discovery, enhancements to the Memcached client capabilities are needed, or users can add support for Auto Discovery to their own Memcached client libraries.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-04T17:14:46.263164"}}
{"question": "How can you disable Auto Discovery in ElastiCache?", "answer": "You can disable Auto Discovery by specifying the mode of operation during the ElastiCache Cluster client initialization.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-04T17:14:51.044074"}}
{"question": "What flexibility does ElastiCache provide regarding Memcached version upgrades?", "answer": "ElastiCache allows you to control if and when the Memcached protocol-compliant software powering your cluster is upgraded to new versions. This means you can maintain compatibility with specific Memcached versions, test new versions with your application before deploying in production, and perform version upgrades on your own terms and timelines.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-04T17:14:51.044459"}}
{"question": "What is the difference between initiating a version upgrade and having ElastiCache patch your cluster automatically?", "answer": "Initiating a version upgrade requires you to specify the version you wish to upgrade to and can be done using the Modify option for your cluster, whereas having ElastiCache patch your cluster automatically occurs only when there is a determined security vulnerability in the system or cache software, without requiring user action.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-04T17:14:51.044879"}}
{"question": "What should you ensure about the max_chunk_size values when upgrading to Memcached version 1.4.33 or newer?", "answer": "When upgrading from an older version of Memcached to Memcached version 1.4.33 or newer, you should ensure that your existing parameter max_chunk_size values satisfy the conditions needed for the slab_chunk_max parameter.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-04T17:14:57.159733"}}
{"question": "How does ElastiCache handle node failures in a cache cluster?", "answer": "In scenarios where the primary node fails, ElastiCache will automatically promote an existing read replica to the primary role. Additionally, if a node fails, ElastiCache will provision a new node to ensure continuity.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-04T17:14:57.160017"}}
{"question": "What is the difference between upgrading to a newer engine version and rolling back to a previous version in ElastiCache?", "answer": "To upgrade to a newer engine version in ElastiCache, you can use the console, API, or CloudFormation, and the process is designed to retain your existing data. In contrast, rolling back to a previous version, such as from ElastiCache version 7.2 for Valkey to version 7.1 for Redis OSS, is performed in the same way as an upgrade, using the console, API, or CloudFormation.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-04T17:14:57.160546"}}
{"question": "What significant improvements do enhanced I/O threads provide in ElastiCache?", "answer": "Enhanced I/O threads in ElastiCache deliver significant improvements to throughput and latency at scale through multiplexing, presentation layer offloading, and by using more cores for processing I/O while dynamically adjusting to the workload.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-04T17:15:00.868509"}}
{"question": "How do enhanced I/O threads improve performance in ElastiCache version 7.1 for Redis OSS?", "answer": "In ElastiCache version 7.1 for Redis OSS, enhanced I/O threads improve performance by handling presentation layer logic in addition to reading client input. They parse the input into a binary command format, which is then forwarded to the main thread for execution, resulting in performance gains.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-04T17:15:00.868849"}}
{"question": "How does the performance of ElastiCache version 7.1 for Redis OSS compare to prior versions in terms of throughput and latency?", "answer": "ElastiCache version 7.1 for Redis OSS can achieve up to 100% more throughput and 50% lower P99 latency compared to prior versions.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-04T17:15:00.869351"}}
{"question": "What metric is used to monitor CPU utilization when using ElastiCache Serverless?", "answer": "When using ElastiCache Serverless, the metric used to monitor CPU utilization is the ElastiCache Processing Units (ECPU) metric.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-04T17:15:08.287164"}}
{"question": "Why is it important to use both CPUUtilization and EngineCPUUtilization metrics when designing your own cluster?", "answer": "It is important to use both CPUUtilization and EngineCPUUtilization metrics because the CPUUtilization metric measures overall CPU usage for the instance, while the EngineCPUUtilization metric provides visibility into the CPU utilization at the engine process level. Since the main Redis OSS process is single-threaded and uses only one CPU core, relying solely on CPUUtilization does not provide precise insights into the CPU utilization rates at the engine process level.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-04T17:15:08.287447"}}
{"question": "How do the metrics for ElastiCache Serverless differ from those used for designing your own cluster?", "answer": "The metrics for ElastiCache Serverless include the ElastiCache Processing Units (ECPU) metric, which measures CPU utilization based on the vCPU time and data transferred. In contrast, when designing your own cluster, you use the CPUUtilization metric, which measures overall CPU utilization for the instance, and the EngineCPUUtilization metric, which measures utilization at the engine process level. The ECPU metric is specific to serverless deployments, while the CPUUtilization and EngineCPUUtilization metrics are used for cluster designs.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-04T17:15:08.287957"}}
{"question": "What are the two primary purposes of read replicas in Redis OSS?", "answer": "The two primary purposes of read replicas in Redis OSS are failure handling and read scaling.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-04T17:15:14.254896"}}
{"question": "Why might deploying one or more read replicas for a primary node be beneficial in a cache design?", "answer": "Deploying one or more read replicas for a primary node can be beneficial for several reasons: it allows scaling beyond the compute or I/O capacity of a single primary node for read-heavy workloads, serves read traffic while the primary is unavailable (for instance, during backups or maintenance), and provides data protection scenarios by allowing the promotion of a read replica in a different availability zone (AZ) if the primary node fails.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-04T17:15:14.255231"}}
{"question": "How does the connection method differ when using read replicas in Redis OSS with cluster mode disabled versus enabled?", "answer": "In Redis OSS with cluster mode disabled, you connect to read replicas using the individual node endpoints for read operations. In contrast, in Redis OSS with cluster mode enabled, you use the cluster's configuration endpoint for all operations, although you can still read from individual node endpoints.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-04T17:15:14.255708"}}
{"question": "What happens to read replicas during a failover?", "answer": "In the event of a failover, any associated and available read replicas should automatically resume replication once the failover has completed, acquiring updates from the newly promoted read replica.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-04T17:15:19.568996"}}
{"question": "What factors can cause a read replica to fall behind its primary cache node?", "answer": "A read replica can fall behind its primary cache node due to several factors, including when the write I/O volume to the primary cache node exceeds the rate at which changes can be applied to the read replica, network partitions, or latency between the primary cache node and the read replica.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-04T17:15:19.569276"}}
{"question": "How does the billing of a read replica compare to that of a standard cache node?", "answer": "A read replica is billed as a standard cache node and at the same rates. The rate per cache node hour for both a read replica and a standard cache node is determined by the cache node class. However, you are not charged for data transfer incurred in replicating data between the primary cache node and the read replica.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-04T17:15:19.569845"}}
{"question": "What is the main purpose of initiated failover in ElastiCache?", "answer": "The main purpose of initiated failover in ElastiCache is to allow you to resume cache operations as quickly as possible by flipping the DNS record for your cache node to point at the read replica, which is then promoted to become the new primary.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-04T17:15:25.186643"}}
{"question": "What best practices should be followed during an ElastiCache failover?", "answer": "It is encouraged to implement cache node connection retry at the application layer during an ElastiCache failover to ensure smooth operation.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-04T17:15:25.186885"}}
{"question": "How does the provisioning of read replicas differ between the same Availability Zone and across AWS Regions in ElastiCache?", "answer": "A read replica can only be provisioned in the same or different Availability Zone (AZ) of the same Region as the cache node primary. However, by using the Global Datastore feature, you can create cross-Region read replica clusters for ElastiCache, which enables low-latency reads and disaster recovery across AWS Regions.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-04T17:15:25.187273"}}
{"question": "What is required for an ElastiCache replication group when Multi-AZ is enabled?", "answer": "When Multi-AZ is enabled for an ElastiCache replication group, at least one read replica is required per primary node.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T17:15:33.358077"}}
{"question": "What are the main benefits of running ElastiCache in Multi-AZ mode?", "answer": "The main benefits of running ElastiCache in Multi-AZ mode are enhanced availability and a smaller need for administration. Additionally, caches in this configuration are eligible for a 99.99% availability SLA.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T17:15:33.358409"}}
{"question": "How does ElastiCache handle a primary node failure in a Multi-AZ configuration compared to a non-Multi-AZ configuration?", "answer": "In a Multi-AZ configuration, if a primary node fails, ElastiCache automatically detects the failure, selects a read replica, and promotes it to become the new primary without requiring any administration. In contrast, a non-Multi-AZ configuration may not have automatic failover capabilities, potentially leading to longer downtimes and requiring manual intervention.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-04T17:15:33.358859"}}
{"question": "What happens if both the primary and replicas of an ElastiCache replication group are placed in the same Availability Zone (AZ)?", "answer": "Placing both the primary and the replicas in the same AZ will not make your ElastiCache replication group resilient to an AZ disruption. Additionally, having replicas in the same AZ as the primary will not be allowed if Multi-AZ is turned on.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-04T17:15:39.333860"}}
{"question": "Why is it recommended to architect applications with redundancy across multiple Availability Zones?", "answer": "It is recommended to architect applications with redundancy across multiple Availability Zones (AZs) because AZs are engineered to provide low latency network connectivity to other AZs in the same Region. This design helps ensure that the application will be resilient in the event of an AZ disruption.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-04T17:15:39.334209"}}
{"question": "How does ElastiCache determine which read replica to promote during a failover event?", "answer": "In the event of a failover, if there is more than one read replica, ElastiCache will promote the read replica with the smaller asynchronous replication lag to the primary.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-04T17:15:39.334704"}}
{"question": "What happens when a backup is initiated in ElastiCache?", "answer": "When a backup is initiated in ElastiCache, a snapshot of a specified cache is taken, which can later be used for recovery or archiving.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-04T17:15:43.571762"}}
{"question": "Why is it recommended to enable backup on a cache's read replicas?", "answer": "It is recommended to enable backup on one of the caches read replicas to minimize any potential impact on the primary cache.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-04T17:15:43.572091"}}
{"question": "How does the snapshot retention differ between manual snapshots and automatic snapshots when an ElastiCache cache is deleted?", "answer": "When you delete an ElastiCache cache, your manual snapshots are retained, and you have the option to create a final snapshot before the cache is deleted. In contrast, automatic cache snapshots are not retained.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-04T17:15:43.572577"}}
{"question": "What enhancements does the ElastiCache engine provide over Redis OSS?", "answer": "The ElastiCache engine provides several enhancements over Redis OSS, including more usable memory, improved synchronization, smoother failovers, and better CPU resource utilization through TLS offload and IO multiplexing. More usable memory allows for safer allocation without increased swap usage. Improved synchronization ensures robustness under heavy load and faster syncs without using disk resources. Smoother failovers result in faster recovery of shards without data flushing, and the engine optimizes CPU usage for network processes.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-04T17:15:51.131229"}}
{"question": "How does ElastiCache ensure data security during operations?", "answer": "ElastiCache ensures data security through features like encryption at rest and encryption in transit. Encryption at rest protects data during sync, backup, and swap operations, as well as backups stored in Amazon S3. Encryption in transit secures communications between clients and ElastiCache, as well as between primary and read replica servers. Users can also enable additional security measures like Redis OSS AUTH and Role-Based Access Control (RBAC) when creating their cache.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-04T17:15:51.131716"}}
{"question": "What is the difference between encryption at rest and encryption in transit in ElastiCache?", "answer": "Encryption at rest in ElastiCache protects data stored on disk during sync, backup, and swap operations, as well as backups in Amazon S3. In contrast, encryption in transit secures the communications between clients and ElastiCache, as well as communications between primary and read replicas. Both features enhance data security but operate at different stages: encryption at rest secures data when it is stored, while encryption in transit safeguards data during transmission.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-04T17:15:51.132024"}}
{"question": "What is the primary function of the Global Datastore feature in ElastiCache?", "answer": "The primary function of the Global Datastore feature in ElastiCache is to provide fully managed, fast, reliable, and security-focused cross-Region replication, allowing data to be written in one Region and made available for read in up to two other cross-Region replica clusters.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-04T17:15:56.679074"}}
{"question": "How does Global Datastore enhance the performance of real-time applications with a global footprint?", "answer": "Global Datastore enhances the performance of real-time applications with a global footprint by replicating data across Regions in under one second, which increases application responsiveness by providing geolocal reads closer to end users.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-04T17:15:56.679416"}}
{"question": "What is the difference between automatic and manual promotion of a secondary cluster in Global Datastore during Regional degradation?", "answer": "In Global Datastore, the automatic promotion of a secondary cluster does not occur when a primary cluster is degraded; instead, you must manually initiate the failover by promoting a secondary cluster to become the primary. This manual promotion typically completes in less than one minute, whereas automatic promotion is not supported.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-04T17:15:56.679891"}}
{"question": "What is the typical RPO of Global Datastore in ElastiCache?", "answer": "The typical RPO of Global Datastore in ElastiCache is under one second, meaning that data written in a primary Region is available in secondary Regions within one second.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-04T17:16:02.058034"}}
{"question": "How does data tiering in ElastiCache improve cost-effectiveness for certain workloads?", "answer": "Data tiering in ElastiCache improves cost-effectiveness by using lower-cost solid state drives (SSDs) in each cluster node alongside memory storage. It is particularly ideal for workloads that access up to 20% of their overall dataset and can tolerate additional latency, allowing for nearly 5x more total storage capacity and over 60% savings in price when running at maximum use compared to ElastiCache R6g nodes with memory only.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-04T17:16:02.058366"}}
{"question": "What is the difference in latency for accessing data stored on SSD compared to data in memory in ElastiCache?", "answer": "Accessing data stored on SSD in ElastiCache results in an average additional latency of 300s compared to accessing data stored in memory.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-04T17:16:02.058812"}}
{"question": "What versions of ElastiCache for Redis support data tiering?", "answer": "ElastiCache for Redis OSS versions 6.2 and above support data tiering.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-04T17:16:06.237148"}}
{"question": "What are the requirements for using data tiering in ElastiCache?", "answer": "To use data tiering in ElastiCache, it must be on clusters using R6gd nodes.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-04T17:16:06.237439"}}
{"question": "How does the cost of using data tiering in ElastiCache compare to standard usage?", "answer": "There are no additional costs for using data tiering beyond the nodes hourly cost, which is the same as standard usage. Nodes with data tiering are available with on-demand pricing and as reserved nodes.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-04T17:16:06.237600"}}
{"question": "What programming languages and development stacks are supported by AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker web applications. Specifically, it supports Apache Tomcat for Java applications, Apache HTTP Server for PHP and Python applications, Nginx or Apache HTTP Server for Node.js applications, Passenger or Puma for Ruby applications, and Microsoft IIS for .NET applications.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-04T17:16:12.303188"}}
{"question": "How does AWS Elastic Beanstalk simplify the deployment process for developers?", "answer": "AWS Elastic Beanstalk simplifies the deployment process by allowing developers to simply upload their application. It automatically handles the deployment details, including capacity provisioning, load balancing, auto-scaling, and application health monitoring, which means developers do not need extensive experience with cloud computing to get started.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-04T17:16:12.303531"}}
{"question": "In what way is AWS Elastic Beanstalk designed for future development stack support compared to its current capabilities?", "answer": "AWS Elastic Beanstalk is designed to be extended to support multiple development stacks and programming languages beyond its current offerings. While it currently supports several languages and stacks, AWS is actively working with solution providers to develop the APIs and capabilities needed for additional Elastic Beanstalk offerings in the future.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-04T17:16:12.304167"}}
{"question": "What tasks does AWS Elastic Beanstalk automate for application deployment?", "answer": "AWS Elastic Beanstalk automates capacity provisioning, load balancing, auto scaling, and application deployment, creating an environment that runs a version of your application.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-04T17:16:17.613619"}}
{"question": "How does AWS Elastic Beanstalk provide flexibility and control to developers compared to other platform-as-a-service solutions?", "answer": "Unlike most existing application containers or platform-as-a-service solutions that limit developers' flexibility and control, AWS Elastic Beanstalk allows developers to retain full control over the AWS resources powering their application. Developers can manage some or all elements of their infrastructure using Elastic Beanstalks management capabilities.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-04T17:16:17.613936"}}
{"question": "What are the differences in control over application infrastructure between AWS Elastic Beanstalk and other platform-as-a-service solutions?", "answer": "AWS Elastic Beanstalk provides developers with full control over the AWS resources powering their application, allowing them to manage infrastructure elements as needed. In contrast, other platform-as-a-service solutions often force developers to accept predetermined decisions made by the vendor with little to no opportunity for control over their applications infrastructure.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-04T17:16:17.614383"}}
{"question": "What operating systems are currently supported by AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk currently uses the Amazon Linux AMI and the Windows Server 2019.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-04T17:16:22.582640"}}
{"question": "Why is AWS Elastic Beanstalk considered ideal for web applications?", "answer": "AWS Elastic Beanstalk is considered ideal for web applications because it supports multiple programming languages such as Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker, and it uses proven AWS features and services like Amazon EC2 and Elastic Load Balancing to create a robust environment for running applications.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-04T17:16:22.582977"}}
{"question": "How does the support for Amazon Linux AMI compare to that of Windows Server AMI in AWS Elastic Beanstalk?", "answer": "Both the Amazon Linux AMI and the Windows Server AMI are supported and maintained by Amazon Web Services, designed to provide a stable, secure, and high-performance execution environment for Amazon EC2 Cloud computing in AWS Elastic Beanstalk.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-04T17:16:22.583488"}}
{"question": "What storage service does AWS Elastic Beanstalk use to store application files and server log files?", "answer": "AWS Elastic Beanstalk stores your application files and, optionally, server log files in Amazon S3.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-04T17:16:26.905800"}}
{"question": "How can you configure Elastic Beanstalk to manage server log files in Amazon S3?", "answer": "You can configure Elastic Beanstalk to copy your server log files every hour to Amazon S3 by editing the environment configuration settings.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-04T17:16:26.906163"}}
{"question": "How does the data persistence technology options differ between AWS Elastic Beanstalk and Amazon RDS?", "answer": "AWS Elastic Beanstalk does not restrict you to any specific data persistence technology, allowing you to choose from options like Amazon RDS, Amazon DynamoDB, or other relational databases. In contrast, Amazon RDS is specifically designed for relational database services.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-04T17:16:26.906332"}}
{"question": "What templates does Elastic Beanstalk offer for granting IAM user access?", "answer": "Elastic Beanstalk offers two templates for granting IAM user access: a read-only access template and a full-access template. The read-only template grants read access to Elastic Beanstalk resources, while the full-access template grants full access to all Elastic Beanstalk operations and permissions to manage dependent resources such as Elastic Load Balancing, Auto Scaling, and Amazon S3.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:16:32.822295"}}
{"question": "How does IAM control access to AWS Elastic Beanstalk for users?", "answer": "IAM allows you to manage users and groups in a centralized manner, enabling you to control which IAM users have access to AWS Elastic Beanstalk. You can limit permissions to read-only access for operators who should not be able to perform actions against Elastic Beanstalk resources. By default, IAM users have no access to AWS services until permissions are granted through policies.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:16:32.822672"}}
{"question": "What is the difference in access permissions between the read-only access template and the full-access template for IAM users?", "answer": "The read-only access template allows IAM users to view all applications, application versions, environments, and any associated resources in the account without the ability to perform any actions. In contrast, the full-access template grants IAM users the ability to create, modify, and terminate any Elastic Beanstalk resources under that account, providing them with complete operational control over those resources.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:16:32.823200"}}
{"question": "Can an IAM user access the AWS Elastic Beanstalk console?", "answer": "Yes, an IAM user can access the AWS Elastic Beanstalk console using their username and password.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T17:16:39.171314"}}
{"question": "What is the process to enable managed platform updates in AWS Elastic Beanstalk?", "answer": "To enable managed platform updates in AWS Elastic Beanstalk, you must go to the Configuration tab of the Elastic Beanstalk console or use the EB CLI or API. After enabling the feature, you can configure which types of updates to allow and when updates can occur.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T17:16:39.171673"}}
{"question": "How do automatic platform updates differ from major version updates in AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk can automatically perform platform updates for new patch and minor platform versions, while it does not automatically perform major platform version updates due to backwards incompatible changes and the need for additional testing. Major version updates must be manually initiated.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-04T17:16:39.172097"}}
{"question": "What mechanism does AWS Elastic Beanstalk use to apply updates during managed platform updates?", "answer": "AWS Elastic Beanstalk uses an immutable deployment mechanism to apply updates, which ensures that no changes are made to the existing environment until a parallel fleet of Amazon EC2 instances, with the updates installed, is ready to be swapped with the existing instances.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T17:16:44.228183"}}
{"question": "How does the immutable deployment mechanism benefit users during a maintenance window?", "answer": "The immutable deployment mechanism benefits users by keeping the application available during the maintenance window, ensuring that consumers of the application are not impacted by the update. If the Elastic Beanstalk health system detects any issues during the update, traffic is redirected to the existing fleet of instances.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T17:16:44.228521"}}
{"question": "How do the maintenance windows differ for various application components in AWS Elastic Beanstalk?", "answer": "The maintenance windows can differ for various application components in AWS Elastic Beanstalk because the maintenance window is set on a per-environment basis. This allows users to stagger environment updates and set different maintenance windows for different components or applications, rather than updating all at the same time.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T17:16:44.229037"}}
{"question": "What types of workloads do not require recompilation to use Graviton?", "answer": "Workloads that are based on interpreted programming languages such as Node.js, Python, Tomcat, PHP, or Ruby do not need to be recompiled to use Graviton.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-04T17:16:50.649508"}}
{"question": "What are the potential benefits of transitioning a workload to Graviton?", "answer": "Transitioning a workload to Graviton can provide performance and cost benefits, particularly for Linux-based workloads built primarily on open-source technologies, containerized and microservices-based applications, and applications written in portable programming languages.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-04T17:16:50.649848"}}
{"question": "How does deploying an application with arm64-based processors differ when using the Elastic Beanstalk console versus the Elastic Beanstalk CLI?", "answer": "When using the Elastic Beanstalk console, you can select processor architecture and instance type from the capacity tab in the Configure more options settings. In contrast, when deploying with the Elastic Beanstalk CLI, AWS CLI, CFN, or AWS CDK, you need to refer to the Elastic Beanstalk Developer Guide for deployment instructions.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-04T17:16:50.650369"}}
{"question": "Is there any additional charge for using AWS Elastic Beanstalk?", "answer": "No, there is no additional charge for AWS Elastic Beanstalk. You only pay for the AWS resources actually used to store and run your application.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-04T17:16:55.998131"}}
{"question": "How does AWS Elastic Beanstalk pricing work?", "answer": "AWS Elastic Beanstalk pricing works on a pay-as-you-go model where you only pay for the AWS resources that you actually use, with no minimum fee for using any AWS resources.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-04T17:16:55.999316"}}
{"question": "How does AWS Elastic Beanstalk support compare to general AWS Support?", "answer": "AWS Support covers issues related to your use of AWS Elastic Beanstalk, while general AWS Support encompasses a broader range of services and issues that may not be specific to Elastic Beanstalk. For further details and pricing on AWS Support, you can refer to the AWS Support page.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-04T17:16:55.999743"}}
{"question": "What are some open source frameworks that Amazon EMR supports for data processing and analysis?", "answer": "Amazon EMR supports open source frameworks such as Apache Spark, Apache Hive, and Presto for data processing and interactive analysis.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:17:00.365379"}}
{"question": "How does Amazon EMR benefit users in terms of capacity management and cost savings?", "answer": "Amazon EMR allows users to focus on transforming and analyzing their data without worrying about managing compute capacity or open-source applications, thus saving money. Users can instantly provision as much or as little capacity as needed on Amazon EC2 and set up scaling rules to manage changing compute demand.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:17:00.365702"}}
{"question": "How does the cost and speed of Amazon EMR compare to traditional on-premises solutions?", "answer": "Amazon EMR enables petabyte-scale analysis at less than half the cost of traditional on-premises solutions and performs over 1.7 times faster than standard Apache Spark.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-04T17:17:00.366216"}}
{"question": "What must you be signed up for in order to access Amazon EMR?", "answer": "You must be signed up for Amazon EC2 and Amazon S3 to access Amazon EMR.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T17:17:04.304841"}}
{"question": "What are some programming languages supported for developing applications in Amazon EMR Studio?", "answer": "You can develop, visualize, and debug data science and data engineering applications written in R, Python, Scala, and PySpark in Amazon EMR Studio.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T17:17:04.305178"}}
{"question": "How does the AWS Management Console differ from the Command Line Tools or APIs for managing Amazon EMR?", "answer": "The AWS Management Console provides an easy-to-use graphical interface for launching and monitoring your clusters directly from a web browser, while the Command Line Tools or APIs allow for programmatically launching and monitoring clusters, creating custom functionality, and building value-added tools or applications for other Amazon EMR customers.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-04T17:17:04.305603"}}
{"question": "What can you do to receive notifications when your Amazon EMR cluster finishes processing?", "answer": "You can sign up for Amazon SNS and have the cluster post to your SNS topic when it is finished.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-04T17:17:08.946941"}}
{"question": "How does using a custom AMI based on Amazon Linux 2 benefit Amazon EMR users?", "answer": "Using a custom AMI that you create based on Amazon Linux 2 allows you to perform sophisticated pre-configuration for virtually any application, providing flexibility and customization options for your cluster setup.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-04T17:17:08.947303"}}
{"question": "What are the differences between Amazon EMR 5.30.0 and later versions and EMR 6.x regarding container launching?", "answer": "Amazon EMR 6.x supports Hadoop 3, which allows the YARN NodeManager to launch containers either directly on the EMR cluster host or inside a Docker container, while earlier versions may not have this capability.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-04T17:17:08.947812"}}
{"question": "What programming languages can you use in EMR Studio?", "answer": "In EMR Studio, you can develop applications written in R, Python, Scala, and PySpark.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:17:14.049888"}}
{"question": "How does EMR Studio facilitate collaboration among data scientists and analysts?", "answer": "EMR Studio facilitates collaboration by allowing users to share notebooks via code repositories like GitHub and BitBucket, collaborate on custom kernels and libraries, and execute parameterized notebooks as part of scheduled workflows with orchestration services.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:17:14.050354"}}
{"question": "What are the benefits of using EMR Studio kernels and applications on EMR clusters compared to running them locally?", "answer": "Using EMR Studio kernels and applications on EMR clusters provides the benefit of distributed data processing, leveraging the performance optimized Amazon EMR runtime for Apache Spark, which is not available when running applications locally.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:17:14.050652"}}
{"question": "What is a key benefit of EMR Studio in relation to the AWS Management Console?", "answer": "A key benefit of EMR Studio is that there is no need to access the AWS Management Console to use it. EMR Studio is hosted outside of the AWS Management Console, which is useful for not providing data scientists or data engineers access to the AWS Management Console.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-04T17:17:20.745460"}}
{"question": "How does EMR Studio simplify the process of running code on a cluster?", "answer": "EMR Studio simplifies the process of running code on a cluster by allowing users to attach the notebook to an existing cluster or provision a new one easily, leveraging the distributed data processing capabilities of the performance optimized Amazon EMR runtime for Apache Spark.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-04T17:17:20.745708"}}
{"question": "What are the main differences between EMR Studio and SageMaker Studio?", "answer": "EMR Studio provides an integrated development environment that focuses on data engineering and data science applications using languages like R, Python, Scala, and PySpark, while SageMaker Studio offers a web-based visual interface for machine learning development with complete access and visibility into each step required to build, train, and deploy models. Additionally, EMR Studio has features like simplified debugging and hardware configuration abstraction, whereas SageMaker Studio allows for quick data uploads and model training and tuning.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-04T17:17:20.746423"}}
{"question": "What is the role of AWS IAM Identity Center in relation to EMR Studio?", "answer": "AWS IAM Identity Center, which is the successor to AWS SSO, serves as the single sign-on service provider for EMR Studio.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-04T17:17:26.856008"}}
{"question": "How do Workspaces function in EMR Studio, particularly concerning Jupyter Notebooks?", "answer": "Workspaces help organize Jupyter Notebooks by saving all notebooks in the same Amazon S3 location and running them on the same cluster. Users can link a code repository, such as a GitHub repository, to all notebooks in a workspace, and they can create and configure a workspace before attaching it to a cluster, although they must connect to a cluster before running any notebooks.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-04T17:17:26.857249"}}
{"question": "What are the differences between creating a workspace and executing notebooks in EMR Studio?", "answer": "You can create or open a workspace without attaching it to a cluster, but you must connect the workspace to a cluster before executing a notebook. This means that while the workspace can be configured independently, execution relies on the connection to an EMR cluster where Spark queries run and data processing occurs.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-04T17:17:26.857667"}}
{"question": "What are the two ways to create EMR clusters in EMR Studio?", "answer": "You can create EMR clusters in EMR Studio in two ways: by using a pre-configured cluster template via AWS Service Catalog, or by specifying the cluster name, number of instances, and instance type.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-04T17:17:32.403051"}}
{"question": "How does EMR Studio handle permissions for users and groups?", "answer": "EMR Studio requires permissions to interoperate with other AWS services. Administrators need to create an EMR Studio service role with the necessary policies and specify a user role for defining Studio-level permissions. They can also add users and groups from AWS IAM Identity Center to EMR Studio and assign a session policy to apply fine-grained permission controls, allowing for refined user permissions without creating multiple IAM roles.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-04T17:17:32.403385"}}
{"question": "What types of clusters are not supported in Amazon EMR Studio compared to regular clusters?", "answer": "High Availability (Multi-master) clusters, Kerberized clusters, and AWS Lake Formation clusters are currently not supported in Amazon EMR Studio.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-04T17:17:32.403879"}}
{"question": "What is the main recommendation for new customers regarding EMR usage?", "answer": "The main recommendation for new customers is to use Amazon EMR Studio, not EMR Notebooks.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-04T17:17:38.008350"}}
{"question": "What are some of the capabilities of EMR Notebooks?", "answer": "EMR Notebooks provide a managed environment for data scientists, analysts, and developers to prepare and visualize data, collaborate with peers, build applications, and perform interactive analysis using EMR clusters. They allow users to build Apache Spark applications, run interactive queries, create serverless notebooks, attach them to existing clusters, and provision new clusters. Notebooks are auto-saved to S3 buckets and come prepackaged with libraries from the Anaconda repository, along with integrated Spark monitoring capabilities.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-04T17:17:38.008659"}}
{"question": "How do EMR Notebooks compare to EMR Studio in terms of usage recommendations?", "answer": "EMR Notebooks are supported for compatibility but are not recommended for new customers, who are advised to use EMR Studio instead.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-04T17:17:38.009140"}}
{"question": "What is the most common way to get data onto an Amazon EMR cluster?", "answer": "The most common way to get data onto an Amazon EMR cluster is to upload the data to Amazon S3 and use the built-in features of Amazon EMR to load the data onto your cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-04T17:17:43.074189"}}
{"question": "How does Amazon EMR handle log files after an application terminates?", "answer": "Hadoop system logs as well as user logs are placed in the Amazon S3 bucket specified when creating a cluster. Additionally, logs for Persistent application UIs, Spark History Server, Tez UI, and YARN timeline servers are available for 30 days after an application terminates.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-04T17:17:43.074496"}}
{"question": "What is the difference in billing commencement between Amazon EMR and Amazon EC2?", "answer": "Amazon EMR billing commences when the cluster is ready to execute steps, while Amazon EC2 billing begins according to its own billing policies, which are detailed in the Amazon EC2 Billing FAQ. This means that the start of billing for Amazon EMR is directly tied to the readiness of the cluster, rather than the instance launch.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-04T17:17:43.074897"}}
{"question": "What does the Normalized Instance Hours column in the AWS Management Console represent?", "answer": "The Normalized Instance Hours column in the AWS Management Console represents the approximate number of compute hours the cluster has used, rounded up to the nearest hour.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-04T17:17:48.832148"}}
{"question": "How is the Normalized Instance Hours calculated for a cluster?", "answer": "Normalized Instance Hours are calculated based on the standard of 1 hour of m1.small usage equating to 1 hour of normalized compute time. For example, if you run a 10-node r3.8xlarge cluster for an hour, the total number of Normalized Instance Hours displayed will be calculated as 10 (number of nodes) x 64 (normalization factor) x 1 (number of hours that the cluster ran), resulting in 640 Normalized Instance Hours.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-04T17:17:48.832432"}}
{"question": "How do On-Demand, Spot, and Reserved Instances differ in terms of Amazon EMR support?", "answer": "Amazon EMR seamlessly supports On-Demand, Spot, and Reserved Instances, indicating that users can utilize any of these instance types when running their EMR clusters without restriction.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-04T17:17:48.832872"}}
{"question": "What are the security groups used by Amazon EMR for its instances?", "answer": "Amazon EMR starts instances in two Amazon EC2 security groups: one for the master instance and another for the other cluster nodes. The master security group has a port open for communication with the service and the SSH port open for SSH access. The other nodes are in a separate security group that only allows interaction with the master instance.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-04T17:17:54.739725"}}
{"question": "How does Amazon S3 ensure the security of the data stored by customers?", "answer": "Amazon S3 provides authentication mechanisms to ensure that stored data is secured against unauthorized access. By default, only the customer who uploads the data can access it unless specified otherwise. Additionally, Amazon EMR customers can choose to send data to Amazon S3 using HTTPS for secure transmission, and they may encrypt the input data before uploading it.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-04T17:17:54.740203"}}
{"question": "How do the security groups for the master instance and other cluster nodes differ in Amazon EMR?", "answer": "The security group for the master instance has a port open for communication with the service and the SSH port open to allow SSH access. In contrast, the security group for the other cluster nodes only allows interaction with the master instance and does not permit any external access, including from other customers' EC2 instances.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-04T17:17:54.740472"}}
{"question": "What are the three options Amazon EMR offers to manage user access to Amazon S3 data?", "answer": "Amazon EMR offers three options to manage user access to Amazon S3 data: integration with AWS Lake Formation, native integration with Apache Ranger, and the Amazon EMR User Role Mapper.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:17:59.862821"}}
{"question": "How does integration with AWS Lake Formation enhance security for Amazon EMR applications?", "answer": "Integration with AWS Lake Formation enhances security by allowing you to define and manage fine-grained authorization policies to access databases, tables, and columns in the AWS Glue Data Catalog. It also enables enforcement of these authorization policies on jobs submitted through Amazon EMR Notebooks and Apache Zeppelin, and sends auditing events to AWS CloudTrail.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:17:59.863159"}}
{"question": "What is the difference between the authorization policies defined in Apache Ranger and those managed through AWS Lake Formation?", "answer": "The authorization policies defined in Apache Ranger allow for three types of policies: table, column, and row level authorization for Hive; table and column level authorization for Spark; and prefix and object level authorization for Amazon S3. In contrast, AWS Lake Formation focuses on managing fine-grained authorization policies for databases, tables, and columns in the AWS Glue Data Catalog, with enforcement on jobs submitted via Amazon EMR Notebooks and Apache Zeppelin.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:17:59.863672"}}
{"question": "What is the default behavior of Amazon EMR regarding the Availability Zone for launching clusters?", "answer": "By default, Amazon EMR chooses the Availability Zone with the most available resources in which to run your cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-04T17:18:04.296044"}}
{"question": "Why is it beneficial to run an Amazon EMR cluster in the same Availability Zone?", "answer": "Running a cluster in the same Availability Zone improves the performance of the job flows.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-04T17:18:04.296504"}}
{"question": "How does launching an EMR cluster in the AWS GovCloud region differ from other regions in terms of features?", "answer": "In the AWS GovCloud (US) region, EMR does not support spot instances or the enable-debugging feature, and the EMR Management Console is not yet available.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-04T17:18:04.296769"}}
{"question": "What is the primary function of the master node in an Amazon EMR cluster?", "answer": "The master node manages the cluster by running software components that coordinate the distribution of data and tasks among other nodes for processing. It tracks the status of tasks and monitors the health of the cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-04T17:18:08.191189"}}
{"question": "How do core nodes differ from task nodes in an Amazon EMR cluster?", "answer": "Core nodes have software components that run tasks and store data in the Hadoop Distributed File System (HDFS) on the cluster, while task nodes only run tasks and do not store data in HDFS. Additionally, multi-node clusters require at least one core node, whereas task nodes are optional.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-04T17:18:08.191530"}}
{"question": "What does the 'RUNNING' status indicate for an Amazon EMR cluster step?", "answer": "The 'RUNNING' status indicates that a step for the cluster is currently being executed.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-04T17:18:08.192039"}}
{"question": "What information do you need to provide when launching a cluster through the AWS Management Console?", "answer": "When launching a cluster through the AWS Management Console, you need to specify the name of your cluster, the location in Amazon S3 of your input data, your processing application, your desired data output location, and the number and type of Amazon EC2 instances youd like to use. Optionally, you can also specify a location to store your cluster log files and an SSH Key to login to your cluster while it is running.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-04T17:18:14.033176"}}
{"question": "What happens if you terminate a running cluster in Amazon EMR?", "answer": "If you terminate a running cluster in Amazon EMR, any results that have not been persisted to Amazon S3 will be lost, and all Amazon EC2 instances associated with the cluster will be shut down.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-04T17:18:14.033448"}}
{"question": "How does launching a cluster through the AWS Management Console compare to using the RunJobFlow API?", "answer": "Launching a cluster through the AWS Management Console involves filling out a simple cluster request form, while using the RunJobFlow API allows you to launch a cluster programmatically. Both methods require you to specify the same details about the cluster, such as the name, input data location, processing application, output location, and the number and type of Amazon EC2 instances, but they cater to different user preferences: graphical interface versus API usage.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-04T17:18:14.033835"}}
{"question": "What programming model does Amazon EMR use for computations?", "answer": "Amazon EMR uses the MapReduce programming model for computations.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-04T17:18:18.952883"}}
{"question": "How does Amazon EMR ensure high availability for applications like YARN Resource Manager and HDFS Name Node?", "answer": "Amazon EMR ensures high availability by allowing the launch of an EMR cluster with three master nodes. It automatically fails over to a standby master node if the primary master node fails or if critical processes crash, thus preventing the master node from being a single point of failure.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-04T17:18:18.953228"}}
{"question": "What happens to the processing of input data if a core node in an Amazon EMR cluster fails?", "answer": "If a core node in an Amazon EMR cluster fails, the service will provision a new node to continue job execution. However, if all nodes in the cluster are lost, Amazon EMR will not replace them.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-04T17:18:18.953797"}}
{"question": "What is the purpose of Bootstrap Actions in Amazon EMR?", "answer": "Bootstrap Actions in Amazon EMR are used to run custom set-up prior to the execution of a cluster. They can be utilized to install software or configure instances before running the cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-04T17:18:24.335004"}}
{"question": "How can users customize their cluster settings using Bootstrap Actions?", "answer": "Users can customize their cluster settings by writing a Bootstrap Action script in any language already installed on the cluster instance, such as Bash, Perl, Python, Ruby, C++, or Java. Once the script is written, it must be uploaded to Amazon S3, and its location should be referenced when starting the cluster. Additionally, there are pre-defined Bootstrap Actions available to configure clusters based on specific requirements.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-04T17:18:24.335336"}}
{"question": "What are the differences between core nodes and task nodes in an EMR cluster?", "answer": "Core nodes in an EMR cluster host persistent data using the Hadoop Distributed File System (HDFS) and run Hadoop tasks, while task nodes only run Hadoop tasks. Core nodes are essential for data storage and processing, whereas task nodes are used solely for executing tasks without data storage capabilities.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-04T17:18:24.335826"}}
{"question": "What is the purpose of core nodes in an Amazon EMR cluster?", "answer": "Core nodes host persistent data in HDFS and cannot be removed, so they should be reserved for the capacity that is required until your cluster completes.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-04T17:18:29.750845"}}
{"question": "Why are task nodes considered ideal for temporary capacity needs in an Amazon EMR cluster?", "answer": "Task nodes can be added or removed and do not contain HDFS, making them suitable for capacity that is only needed on a temporary basis. Additionally, you can launch task instance fleets on Spot Instances to increase capacity while minimizing costs.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-04T17:18:29.751334"}}
{"question": "How can you change the visibility of an existing Amazon EMR cluster to all IAM users?", "answer": "To make an existing cluster visible to all IAM users, you must use the EMR CLI. You need to use the command --set-visible-to-all-users and specify the cluster identifier, for example: elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx. This action can only be performed by the creator of the cluster.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-04T17:18:29.751725"}}
{"question": "How many tags can you add to an Amazon EMR cluster?", "answer": "You can add up to ten tags on an Amazon EMR cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-04T17:18:35.097814"}}
{"question": "What happens to the tags added to an Amazon EMR cluster regarding its associated EC2 instances?", "answer": "Amazon EMR propagates the tags added to a cluster to that cluster's underlying EC2 instances. If you add a tag to an Amazon EMR cluster, it will also appear on the related Amazon EC2 instances. Likewise, if you remove a tag from an Amazon EMR cluster, it will also be removed from its associated Amazon EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-04T17:18:35.098060"}}
{"question": "What are the differences in tagging between Amazon EMR and Amazon EC2 instances?", "answer": "Amazon EMR does not support resource-based permissions by tag, while tags propagated to Amazon EC2 instances behave as normal Amazon EC2 tags. If you are using IAM policies for Amazon EC2, they will act on tags propagated from Amazon EMR if they match conditions in that policy. Additionally, it is recommended to manage tags for Amazon EMR clusters through the Amazon EMR console, CLI, or API, rather than directly on the associated EC2 instances, to ensure synchronization.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-04T17:18:35.098206"}}
{"question": "What frameworks can be used with EMR Serverless for building applications?", "answer": "EMR Serverless allows data engineers, analysts, and scientists to build applications using open-source frameworks such as Apache Spark and Apache Hive.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-04T17:18:40.518682"}}
{"question": "How can users interact with EMR Serverless to submit jobs and build data pipelines?", "answer": "Users can interact with EMR Serverless using EMR Studio, AWS CLI, or APIs to submit jobs, track job status, and build their data pipelines.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-04T17:18:40.519020"}}
{"question": "What are the differences in the supported frameworks between EMR Serverless and other EMR offerings?", "answer": "EMR Serverless currently supports Apache Spark and Apache Hive. If users want support for additional frameworks such as Apache Presto or Apache Flink, they need to send a request to emr-feedback@amazon.com. This indicates that EMR Serverless has a more limited set of supported frameworks compared to the broader EMR offerings.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-04T17:18:40.519443"}}
{"question": "What types of clusters can Amazon EMR applications run on?", "answer": "Amazon EMR provides the option to run applications on EC2 based clusters, EKS clusters, Outposts, or Serverless.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-04T17:18:44.408404"}}
{"question": "Why would a customer choose EMR on EC2 clusters?", "answer": "Customers would choose EMR on EC2 clusters for maximum control and flexibility over running their application. This allows them to select the EC2 instance type to meet application-specific performance needs, customize the Linux AMI, configure EC2 instances, extend open-source frameworks, and install additional custom software on cluster instances.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-04T17:18:44.408697"}}
{"question": "How does EMR Serverless differ from EMR on EC2 in terms of cluster management?", "answer": "EMR Serverless is suitable for customers who want to avoid managing and operating clusters, while EMR on EC2 requires customers to manage the clusters themselves, providing maximum control and flexibility.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-04T17:18:44.409104"}}
{"question": "What EMR release labels are supported by EMR Serverless?", "answer": "EMR Serverless supports EMR release labels 6.6 and above.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-04T17:18:49.219857"}}
{"question": "How does BilledResourceUtilization differ from TotalResourceUtilization in EMR Serverless?", "answer": "BilledResourceUtilization only factors in the duration for which pre-initialized capacity was utilized for the job and does not account for any idle time. Additionally, it counts a worker's runtime duration of less than 60 seconds as 60 seconds. In contrast, TotalResourceUtilization rounds up to the nearest second without the same limitations.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-04T17:18:49.221061"}}
{"question": "How does EMR Serverless manage worker resources compared to traditional EMR deployment options?", "answer": "EMR Serverless automatically scales workers up or down based on workload and parallelism required for each job, eliminating the need for users to estimate the number of workers needed. Traditional EMR deployment options do not have this automatic scaling feature.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-04T17:18:49.221380"}}
{"question": "What is the maximum time an EMR Serverless application without pre-initialized workers takes to determine the required resources?", "answer": "An EMR Serverless application without pre-initialized workers takes up to 120 seconds to determine the required resources and provision them.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-04T17:18:54.883101"}}
{"question": "Why would you want to use pre-initialized capacity in an EMR Serverless application?", "answer": "Pre-initialized capacity allows jobs to start immediately, making it ideal for implementing time-sensitive jobs. It keeps workers initialized and ready to respond in seconds, effectively creating an on-call pool of workers for an application.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-04T17:18:54.883576"}}
{"question": "How does the management of pre-initialized workers differ from the management of additional workers in EMR Serverless?", "answer": "Pre-initialized workers are specified at the start of the EMR Serverless application and are used immediately when users submit jobs. If a job requires more workers than pre-initialized, EMR Serverless automatically adds more workers up to the maximum concurrent limit specified. After the job finishes, the system reverts to maintaining the pre-initialized workers, while additional workers are added as needed during job execution.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-04T17:18:54.883930"}}
{"question": "What types of storage options does EMR Serverless offer for workers?", "answer": "EMR Serverless offers two ephemeral storage options for workers: Standard storage, which comes with 20 GB of ephemeral storage per worker by default and can be customized to increase up to 200 GB, and Shuffle-optimized Disk storage, which provides up to 2 TB of ephemeral storage per worker, optimized for shuffle-intensive workloads.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-04T17:19:01.208036"}}
{"question": "How do on-demand workers in EMR Serverless help manage costs?", "answer": "On-demand workers in EMR Serverless are launched only when needed for a job and are released automatically when the job is complete. This approach helps save costs by allowing users to pay only for the resources actually used and avoids additional costs for idle capacity, as it scales the application up or down based on the workload.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-04T17:19:01.208396"}}
{"question": "What is the difference between on-demand workers and pre-initialized workers in EMR Serverless?", "answer": "The main difference between on-demand workers and pre-initialized workers in EMR Serverless is that on-demand workers are launched only when needed for a job and are released after completion, optimizing costs and resource management. In contrast, pre-initialized workers are kept ready to respond in seconds, creating a warm pool that allows jobs to start instantly, making them ideal for iterative applications and time-sensitive jobs.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-04T17:19:01.208878"}}
{"question": "What happens if an AZ fails when using On-Demand workers in EMR Serverless?", "answer": "If an AZ fails when using On-Demand workers, EMR Serverless automatically runs your job in another healthy AZ.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:19:06.896227"}}
{"question": "How does EMR Serverless handle job submissions when using Pre-Initialized workers?", "answer": "When using Pre-Initialized workers, EMR Serverless selects a healthy AZ from the subnets that you specify, and jobs are submitted in that AZ until you stop the application. If the AZ becomes impaired, you can restart the application to switch to another healthy AZ.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:19:06.896471"}}
{"question": "What is the difference between the handling of jobs in On-Demand workers and Pre-Initialized workers regarding AZ failures?", "answer": "With On-Demand workers, jobs are distributed across multiple AZs by default, but each job runs only in one AZ, and if an AZ fails, EMR Serverless automatically runs the job in another healthy AZ. In contrast, with Pre-Initialized workers, jobs are submitted in a selected healthy AZ until the application is stopped, and if that AZ becomes impaired, the application must be restarted to switch to another healthy AZ.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:19:06.897006"}}
{"question": "What are the two cost controls provided by EMR Serverless?", "answer": "EMR Serverless provides two cost controls: 1) The maximum concurrent vCPUs per account quota, which is applied across all EMR Serverless applications in a Region within your account, and 2) The maximumCapacity parameter, which limits the vCPU of a specific EMR Serverless application.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-04T17:19:13.436142"}}
{"question": "How should you use the vCPU-based quota and maximumCapacity property in EMR Serverless?", "answer": "You should use the vCPU-based quota to limit the maximum concurrent vCPUs used by all applications in a Region, and the maximumCapacity property to limit the resources used by a specific application. For example, if you have 5 applications and each application can scale up to 1000 vCPUs, you would set the maximumCapacity property to 1000 vCPUs for each application and configure the account-level vCPU-based quota to 5000 vCPUs (5 applications * 1000 vCPUs).", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-04T17:19:13.436479"}}
{"question": "What happens if you exceed your account-level vCPU quota in EMR Serverless?", "answer": "If you exceed your account-level vCPU quota, EMR Serverless will stop provisioning new capacity. Creating a new application after exceeding the quota will fail with an error message stating, 'Application failed to create as you have exceeded the maximum concurrent vCPUs per account service quota.' Submitting a new job after exceeding the quota will also fail with a message, 'Job failed as you have exceeded the maximum concurrent vCPUs per account service quota.'", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-04T17:19:13.436936"}}
{"question": "What are the three ways Amazon EMR Serverless can help save costs?", "answer": "Amazon EMR Serverless helps save costs in three ways: First, it eliminates the operational overhead of managing, securing, and scaling clusters. Second, it automatically scales workers up during job processing and scales them down when not needed, charging only for the resources used during the job. Third, it includes the Amazon EMR performance-optimized runtime for Apache Spark, Apache Hive, and Presto, which is API-compatible and over twice as fast as standard open-source engines, leading to faster job execution and lower compute costs.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-04T17:19:20.345771"}}
{"question": "How does EMR Serverless's automatic scaling feature benefit cost management?", "answer": "The automatic scaling feature of EMR Serverless benefits cost management by scaling workers up as needed for job processing and scaling them down when they are not required. This means that users only incur costs for the vCPU, memory, and storage resources utilized during the time workers are actively running, which prevents payment for underutilized resources.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-04T17:19:20.346243"}}
{"question": "In what scenarios is EMR Serverless more cost-effective compared to EMR on EC2 using On-Demand Instances, Savings Plans, and Spot Instances?", "answer": "EMR Serverless is more cost-effective than EMR on EC2 using On-Demand Instances when the current cluster utilization is less than 70%. It is more cost-effective than using EC2 Savings Plans when the cluster utilization is less than 50%. However, if you are using EC2 Spot Instances, Amazon EMR on EC2 and Amazon EMR on EKS will continue to be more cost-effective than EMR Serverless.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-04T17:19:20.346508"}}
{"question": "What tool can be used to package Python dependencies for PySpark?", "answer": "You can use virtualenv to package your Python dependencies for PySpark.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-04T17:19:25.012161"}}
{"question": "How can you ensure that your workers use specific dependencies during a PySpark job run?", "answer": "You can ensure that your workers use specific dependencies during a PySpark job run by passing the archive file containing the dependencies using the --archives option.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-04T17:19:25.012489"}}
{"question": "What is the difference between packaging dependencies for PySpark and for Scala or Java in an EMR Serverless job run?", "answer": "For PySpark, you package your dependencies using virtualenv and pass the archive file with the --archives option. In contrast, for Scala or Java, you package your dependencies as jars, upload them to Amazon S3, and pass them using the --jars or --packages options.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-04T17:19:25.012876"}}
{"question": "What is Amazon EventBridge?", "answer": "Amazon EventBridge is a service that provides real-time access to changes in data from AWS services, your own applications, and software as a service (SaaS) applications without requiring any code to be written.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:19:29.669883"}}
{"question": "How does Amazon EventBridge handle event delivery?", "answer": "Amazon EventBridge automatically delivers events in near real-time after you select an event source and a target from AWS services such as AWS Lambda, Amazon SNS, or Amazon Kinesis Data Firehose.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:19:29.670223"}}
{"question": "What are the differences between using partner SaaS applications and AWS services as event sources in Amazon EventBridge?", "answer": "When using partner SaaS applications as event sources in Amazon EventBridge, you must verify that your SaaS account is configured to emit events and is accepted in the offered event sources section of the EventBridge console. In contrast, when using AWS services as event sources, this additional verification step is not necessary.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:19:29.670648"}}
{"question": "What are the top-level envelope fields that every event in AWS EventBridge has?", "answer": "Every event in AWS EventBridge has the same top-level envelope fields, which include the source of the event, timestamp, and Region.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:19:34.393673"}}
{"question": "How can rules in AWS EventBridge help different application components?", "answer": "Rules in AWS EventBridge help different application components by matching incoming events for a given event bus and routing them to targets for processing. A single rule can route to multiple targets, all of which are processed in parallel, allowing components to look for and process the events that are of interest to them.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:19:34.394008"}}
{"question": "What is the difference between AWS services available as event sources and event targets in EventBridge?", "answer": "AWS services available as event sources in EventBridge include services like AWS Lambda, Amazon Kinesis, AWS Fargate, and Amazon S3, with over 90 services total. In contrast, AWS services available as event targets include Lambda, Amazon SQS, Amazon SNS, Amazon Kinesis Streams, and Kinesis Data Firehose, with over 15 services total.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:19:34.394618"}}
{"question": "What is the primary purpose of the Event Replay feature in EventBridge?", "answer": "The primary purpose of the Event Replay feature in EventBridge is to help developers reprocess past events back to an event bus or a specific EventBridge rule. This feature aids in debugging applications, extending them by hydrating targets with historic events, and recovering from errors.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-04T17:19:40.013711"}}
{"question": "How does API Destinations enhance the functionality of EventBridge for developers?", "answer": "API Destinations enhance the functionality of EventBridge by allowing developers to send events back to any on-premises or SaaS applications while providing control over throughput and authentication. It enables input transformations to map event formats to the receiving service's format, and ensures security and delivery without requiring developers to write authentication components.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-04T17:19:40.014015"}}
{"question": "What are the differences between Event Replay and API Destinations in EventBridge?", "answer": "Event Replay focuses on reprocessing past events to aid debugging and error recovery, while API Destinations is designed to send events to on-premises or SaaS applications with controlled throughput and authentication. Event Replay allows developers to access any event published to EventBridge, whereas API Destinations involves configuring rules with authorization settings and connection details for sending events securely.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-04T17:19:40.014556"}}
{"question": "What is the minimum Monthly Uptime Percentage that AWS aims to provide for EventBridge in each AWS Region?", "answer": "AWS aims to provide a Monthly Uptime Percentage of at least 99.99% for EventBridge in each AWS Region during any monthly billing cycle.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:19:44.454278"}}
{"question": "Why is the schema of an event important in EventBridge?", "answer": "The schema of an event is important because it shows what information is contained in the event and helps you write code based on that data. It commonly includes details such as the title, format of each piece of data, and patterns like the requirement for a phone number to be 10 digits in length.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:19:44.454569"}}
{"question": "How does schema discovery differ from manually adding schemas to the registry?", "answer": "Schema discovery automates the processes of finding schemas and adding them to the registry, while manually adding schemas requires you to do this without automation. With schema discovery enabled, the schema of each event sent to the event bus is automatically added to the registry, and if the schema changes, a new version is automatically created. In contrast, manual addition does not offer this automation.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:19:44.454975"}}
{"question": "Is there any cost associated with using the schema registry?", "answer": "There is no cost to use the schema registry itself; however, there is a cost per ingested event when schema discovery is turned on. Schema discovery has a free tier of 5 million ingested events per month, with a fee of $0.10 per million ingested events for usage beyond the free tier.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-04T17:19:51.468529"}}
{"question": "What are the main benefits of using the schema registry in event-driven applications?", "answer": "The schema registry reduces the amount of code developers need to write by automatically identifying and storing schemas for events sent to the EventBridge event bus, thus eliminating the need for manual schema management. It allows developers to generate and download code bindings for schemas, enabling the use of strongly-typed objects directly in their code. This reduces overhead for de-serialization, validation, and guesswork for event handlers, allowing developers to focus more on their application code instead of searching for available events and their structures.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-04T17:19:51.468865"}}
{"question": "How does the schema registry compare to traditional methods of managing event schemas?", "answer": "The schema registry automates the identification and management of event schemas, which saves time and reduces the need for coordination between development teams. In contrast, traditional methods typically require manual management of event schemas and can lead to more time spent searching for available events and writing code to interpret them. The schema registry streamlines this process, allowing developers to focus more on application development.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-04T17:19:51.469442"}}
{"question": "What functionality does the latest version of the AWS SAM CLI provide for creating serverless applications?", "answer": "The latest version of the AWS SAM CLI includes an interactive mode that helps you create new serverless applications on EventBridge for any schema as an event type. It allows you to choose the EventBridge Starter App template and the schema of your event, and SAM will automatically generate an application with a Lambda function invoked by EventBridge, including handling code for the event.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-04T17:19:57.297342"}}
{"question": "How does EventBridge Pipes simplify the integration process between event producers and consumers?", "answer": "EventBridge Pipes provides a simpler, consistent, and cost-effective way to create point-to-point integration between event producers and consumers. Creating a pipe is straightforward, as it involves selecting a source and a target, with options to customize batching, starting position, concurrency, and more. It also allows for optional filtering and enrichment steps to manage event flow and transformation without the need to write and manage complex integration code.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-04T17:19:57.297616"}}
{"question": "In what programming languages is code generation for EventBridge available, and how do they compare?", "answer": "Code generation for EventBridge is available in Java (8+), Python (3.6+), TypeScript (3.0+), and Go (1+). Each of these languages has a minimum version requirement, with Java starting from version 8, Python from version 3.6, TypeScript from version 3.0, and Go from version 1.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-04T17:19:57.298104"}}
{"question": "What are some of the sources that EventBridge Pipes can use?", "answer": "EventBridge Pipes introduces several sources, including Amazon SQS, Amazon Kinesis, Amazon DynamoDB, Amazon Managed Streaming Kafka, self-managed Kafka, and Amazon MQ.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-04T17:20:01.214432"}}
{"question": "How does EventBridge Pipes handle transformations of events?", "answer": "EventBridge Pipes supports basic transformations using Velocity Template Language (VTL). For more powerful transformations, it allows you to specify a Lambda function or Step Functions workflow to transform your event. Additionally, if you want to use a container service, you can specify the API endpoint and authentication scheme for your container cluster.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-04T17:20:01.214707"}}
{"question": "How do the target services of EventBridge Pipes compare to those of event buses?", "answer": "EventBridge Pipes supports the same target services as event buses, which include Amazon SQS, AWS Step Functions, Amazon Kinesis Data Streams, Amazon Kinesis Data Firehose, Amazon SNS, Amazon ECS, and event buses themselves.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-04T17:20:01.215156"}}
{"question": "What event producers can EventBridge Pipes receive events from?", "answer": "EventBridge Pipes can receive events from other event producers such as Kinesis, SQS, or Amazon MSK.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-04T17:20:07.229827"}}
{"question": "What is the primary purpose of using EventBridge Pipes compared to EventBridge event buses?", "answer": "The primary purpose of using EventBridge Pipes is for point-to-point integrations between event publishers and consumers, while EventBridge event buses are well suited for many-to-many routing of events between event-driven services.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-04T17:20:07.230074"}}
{"question": "How does AWS Lambdas Event Source Mapping (ESM) compare to EventBridge Pipes in terms of event processing?", "answer": "AWS Lambdas Event Source Mapping (ESM) is ideal for customers who want to use Lambda as a target to process received events, while EventBridge Pipes is ideal for customers who prefer a simple, managed resource to connect their source to one of over 14 targets without having to create, maintain, and scale Lambda code.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-04T17:20:07.230461"}}
{"question": "What is Amazon EventBridge Scheduler?", "answer": "Amazon EventBridge Scheduler is a serverless task scheduler that simplifies creating, executing, and managing millions of schedules across AWS services without provisioning or managing underlying infrastructure.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-04T17:20:13.725008"}}
{"question": "How does EventBridge Scheduler differ from Scheduled Rules?", "answer": "EventBridge Scheduler builds upon the scheduling functionality offered within Scheduled Rules by providing a richer feature set, including support for time zones, increased scale, customized target payloads, added time expressions, and a dashboard for monitoring schedules. While scheduled rules will continue to be available, EventBridge Scheduler offers more flexibility when creating, executing, and managing schedules.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-04T17:20:13.725384"}}
{"question": "In what ways can schedules created with EventBridge Scheduler be monitored compared to Scheduled Rules?", "answer": "Schedules created with EventBridge Scheduler can be monitored more easily through the EventBridge Scheduler console, which provides a dashboard view of schedules or information through a 'ListSchedule' API request, showing critical details such as start time, last run, and the assigned AWS target. In contrast, the context does not specify how monitoring is conducted for Scheduled Rules, indicating that EventBridge Scheduler offers a more streamlined approach.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-04T17:20:13.725751"}}
{"question": "What options does EventBridge Scheduler provide to meet business requirements regarding event delivery?", "answer": "EventBridge Scheduler provides options to set retries, time windows, and timeouts to meet your business requirements regarding event delivery.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-04T17:20:19.952546"}}
{"question": "How does the delete upon completion feature work in EventBridge Scheduler?", "answer": "The delete upon completion feature in EventBridge Scheduler is available for all currently supported scheduling patterns: cron, rate, and one-time schedules. You can update your schedule to configure delete upon completion at any time before the schedule is invoked. Once invoked, if you disable the schedule, it will remain in a disabled state until the last invocation time, and will not automatically delete until an end date is configured.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-04T17:20:19.953016"}}
{"question": "How do global endpoints enhance the resilience of event-driven applications compared to using a single Region?", "answer": "Global endpoints enhance the resilience of event-driven applications by allowing you to replicate your events across primary and secondary Regions, which helps implement failover with minimum data loss. This capability enables automatic failover to a backup Region during service disruptions, simplifying the adoption of multi-Region architectures and providing a better experience for end-customers by minimizing data at risk.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-04T17:20:19.953383"}}
{"question": "What happens to incoming events if errors are detected in the primary Region?", "answer": "If errors are detected in the primary Region, your health check is marked as unhealthy and incoming events are routed to the secondary Region.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-04T17:20:24.773114"}}
{"question": "Why are global endpoints considered suitable for applications that do not require idempotency?", "answer": "Global endpoints are suitable for applications that do not require idempotency or can handle idempotency across Regions because they may have events that could be stuck in the primary Region for up to 420 seconds until the service or Region recovers. This means that these applications can tolerate temporary delays in event replication.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-04T17:20:24.773452"}}
{"question": "How does the health check mechanism for global endpoints prevent unnecessary failovers?", "answer": "The health check mechanism prevents unnecessary failovers by recommending against including subscriber metrics in the health checks. If a single subscriber encounters an issue, it could cause the publisher to failover to the backup Region, even if all other subscribers are healthy in the primary Region. This ensures that only significant health issues warrant a failover.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-04T17:20:24.773963"}}
{"question": "What is the Recovery Time Objective (RTO) for global endpoints according to the prescriptive guidance?", "answer": "The Recovery Time Objective (RTO) for global endpoints, according to the prescriptive guidance, is 360 seconds, with a maximum of 420 seconds.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:20:28.956004"}}
{"question": "Why is it important to turn on replication for your architecture in the secondary Region?", "answer": "It is important to turn on replication for your architecture in the secondary Region to minimize the data at risk during a service disruption and to verify automatic recovery after the issue has been mitigated.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:20:28.956472"}}
{"question": "How does the Recovery Point Objective (RPO) relate to the events that are not replicated during a failure?", "answer": "The Recovery Point Objective (RPO) measures the data that remains unprocessed during a failure, which includes events that are not replicated to the secondary Region and are stuck in the primary Region until the service or Region recovers.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-04T17:20:28.956727"}}
{"question": "What types of events are currently supported by global endpoints?", "answer": "Global endpoints are currently available for custom events only. Support for events from AWS services, opt-in events from S3, and third-party events will be added in the future.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-04T17:20:33.302030"}}
{"question": "How does the pricing model work for Amazon EventBridge?", "answer": "Amazon EventBridge offers a flexible pricing model based on a pay per use approach. Users are charged for events published by their event bus, events ingested for Schema Discovery, Event Replay, and API Destinations. Additionally, there is a charge of $1 per million events for replication of cross Region events.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-04T17:20:33.302387"}}
{"question": "What is the difference between custom events and cross-account events in Amazon EventBridge?", "answer": "Custom events are specific events that users create and publish to the global endpoint, while cross-account events allow users to centralize events from multiple accounts into a single event bus. Cross-account events can be targeted to the default event bus or any other event bus in another account, facilitating easier monitoring and data synchronization between accounts.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-04T17:20:33.302879"}}
{"question": "What is Amazon EventBridge primarily recommended for?", "answer": "Amazon EventBridge is recommended when you want to build an application that reacts to events from your own applications, SaaS applications, and AWS services. It is the only event-based service that integrates directly with third-party SaaS partners.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-04T17:20:37.730095"}}
{"question": "How does EventBridge handle event ingestion compared to SNS?", "answer": "EventBridge automatically ingests events from over 200 AWS services without requiring developers to create any resources in their account, while SNS does not have this automatic event ingestion feature and typically relies on other AWS services to send messages.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-04T17:20:37.730441"}}
{"question": "What types of targets does Amazon SNS support for forwarding messages?", "answer": "Amazon SNS supports forwarding messages to six different types of targets, including Lambda, SQS, HTTP/S endpoints, SMS, mobile push, and email.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-04T17:20:37.731088"}}
{"question": "What is AWS AppFabric used for?", "answer": "AWS AppFabric is a no-code service that enhances companies existing investment in software as a service (SaaS) applications with improved security, management, and productivity. It aggregates and normalizes SaaS log data from apps like Asana, Slack, and Zoom, as well as productivity suites such as Microsoft 365 and Google Workspace.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-04T17:20:44.060702"}}
{"question": "How does EventBridge facilitate the integration of SaaS services into AWS architectures?", "answer": "EventBridge facilitates the integration of SaaS services into AWS architectures by providing a serverless integration service that uses events to connect application components. It allows developers to route events from sources such as custom applications, AWS services, and third-party SaaS applications to consumer applications across the organization, making it easier to build scalable event-driven applications.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-04T17:20:44.060994"}}
{"question": "What are the advantages of using EventBridge for SaaS vendors compared to traditional integration methods?", "answer": "The advantages of using EventBridge for SaaS vendors compared to traditional integration methods include making their product directly accessible to millions of AWS developers, unlocking new use cases, and providing a fully auditable, secure, and scalable pathway to send events without the need for the SaaS vendor to manage any event infrastructure.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-04T17:20:44.061400"}}
{"question": "What is AWS Fargate?", "answer": "AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). It allows users to focus on building applications by eliminating the need to provision and manage servers.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:20:49.685231"}}
{"question": "How does AWS Fargate improve security for applications?", "answer": "AWS Fargate improves security through application isolation by design, which enhances the security posture of applications running on this serverless compute engine.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:20:49.685564"}}
{"question": "What are the differences between Amazon ECS and Amazon EKS in relation to AWS Fargate?", "answer": "Amazon ECS is a highly scalable, high performance container management service, while Amazon EKS is a fully managed Kubernetes service. Both services can schedule containers onto AWS Fargate, allowing for automatic scaling, load balancing, and optimized container availability through managed scheduling.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:20:49.686168"}}
{"question": "What is the isolation model used by AWS Fargate for each workload?", "answer": "AWS Fargate uses a single use, single tenant compute instance for each workload, which is isolated by a virtualization boundary. Each Amazon ECS Task or Kubernetes pod runs on a newly provisioned instance.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:20:55.562335"}}
{"question": "Why should one choose AWS Fargate over Amazon EC2 for container management?", "answer": "One should choose AWS Fargate over Amazon EC2 if they want to launch containers without having to provision or manage EC2 instances. Fargate offers built-in integrations with AWS services and third-party tools for monitoring applications, and it charges only for compute resources used, with no upfront expenses.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:20:55.562703"}}
{"question": "How does AWS Fargate compare to Amazon EC2 in terms of managing compute instances?", "answer": "AWS Fargate is a serverless compute engine that does not require customers to manage the underlying compute instances, while Amazon EC2 requires users to have greater control and manage their instances. This allows AWS Fargate to handle patching, updating, and licensing, providing a more automated and simplified environment for running applications.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:20:55.563227"}}
{"question": "What is the Monthly Uptime Percentage guaranteed by AWS for AWS Fargate under the Compute SLA?", "answer": "The Monthly Uptime Percentage guaranteed by AWS for AWS Fargate under the Compute SLA is at least 99.99%.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T17:21:00.576440"}}
{"question": "Why might new AWS accounts have lower service quotas initially?", "answer": "New AWS accounts might have initial lower service quotas that can increase over time, and users can request to raise these soft limits through the standard AWS service quota increase process.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T17:21:00.576782"}}
{"question": "How do the Multi-AZ Included Container Service SLA and the Single Task/Pod SLA differ in AWS Fargate?", "answer": "The Multi-AZ Included Container Service SLA governs Included Container Services deployed across multiple Availability Zones (AZs), while the Single Task/Pod SLA governs Included Container Service tasks and pods individually.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-04T17:21:00.577215"}}
{"question": "What type of storage is provided to each workload running on AWS Fargate?", "answer": "Each workload that runs on AWS Fargate is given full access to 20 GiB of ephemeral storage to use as temporary storage while the workload is running. Once the workload has stopped, any data stored in this 20 GiB volume is erased.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-04T17:21:06.133274"}}
{"question": "How can VPC Security Groups and VPC network ACLs be utilized in AWS Fargate?", "answer": "VPC Security Groups and VPC network ACLs can be used to secure the dedicated elastic network interface (ENI) that is attached to each ECS Task or Kubernetes Pod running on AWS Fargate, as all traffic in and out of the containerized workload goes through this ENI.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-04T17:21:06.134498"}}
{"question": "How does the ephemeral storage limit differ between Amazon ECS and Amazon EKS on AWS Fargate?", "answer": "The ephemeral storage volume on AWS Fargate can be expanded up to 200 GiB on Amazon ECS and up to 175 GiB on Amazon EKS.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-04T17:21:06.134912"}}
{"question": "Is AWS Fargate HIPAA-eligible for processing Protected Health Information (PHI)?", "answer": "Yes, AWS Fargate is HIPAA-eligible. If you have an executed Business Associate Addendum (BAA) with AWS, you can process encrypted Protected Health Information (PHI) using containers deployed onto AWS Fargate.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T17:21:12.119947"}}
{"question": "What is the significance of having an executed Business Associate Addendum (BAA) with AWS when using AWS Fargate?", "answer": "Having an executed Business Associate Addendum (BAA) with AWS is significant because it allows you to process encrypted Protected Health Information (PHI) using AWS Fargate. Without a BAA, you should contact AWS for more information if you plan to process, store, or transmit PHI.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T17:21:12.120254"}}
{"question": "How does AWS Fargate enable integration with third-party solutions?", "answer": "AWS Fargate enables integration with third-party solutions through a flexible integration model that includes both first-party AWS services and third-party Amazon Partner Network (APN) solutions. A common integration mechanism is to run a sidecar container within an AWS Fargate task, which can interact with the primary application container.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-04T17:21:12.120886"}}
{"question": "What resources do you pay for when using AWS Fargate?", "answer": "With AWS Fargate, you pay only for the amount of vCPU, memory, and storage resources provisioned by your containerized applications.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-04T17:21:16.739517"}}
{"question": "How do Spot instances for AWS Fargate tasks benefit users financially?", "answer": "Spot instances for AWS Fargate tasks utilize spare compute capacity available at a lower price than on-demand instances, allowing users to run interruption tolerant Amazon ECS Tasks at up to a 70 percent discount off the AWS Fargate price.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-04T17:21:16.739845"}}
{"question": "How do AWS Graviton processors compare to x86-based instances in terms of price performance?", "answer": "AWS Graviton processors provide up to 40 percent better price performance over comparable x86-based instances.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-04T17:21:16.740329"}}
{"question": "What are AWS Graviton processors designed to improve?", "answer": "AWS Graviton processors are custom built by Amazon Web Services to deliver the best price performance for your cloud workloads.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-04T17:21:20.776939"}}
{"question": "How does AWS Fargate powered by AWS Graviton processors enhance price/performance compared to Intel x86-based Fargate?", "answer": "AWS Fargate powered by AWS Graviton processors delivers up to 40% improved price/performance at 20% lower cost over comparable Intel x86-based Fargate.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-04T17:21:20.777271"}}
{"question": "What are the advantages of using AWS Graviton processors with AWS Fargate compared to using Intel x86-based Fargate?", "answer": "The advantages of using AWS Graviton processors with AWS Fargate include up to 40% improved price/performance and 20% lower cost compared to Intel x86-based Fargate, while still providing the same serverless benefits.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-04T17:21:20.777694"}}
{"question": "What is AWS Firewall Manager?", "answer": "AWS Firewall Manager is a security management service that allows you to centrally configure and manage firewall rules across your accounts and applications in AWS Organization.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-04T17:21:25.692241"}}
{"question": "How does AWS Firewall Manager help with compliance for new applications?", "answer": "AWS Firewall Manager helps with compliance for new applications by making it easy to bring them and their resources into compliance by enforcing a common set of security rules as they are created.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-04T17:21:25.692578"}}
{"question": "In what way does AWS Firewall Manager enforce security policies compared to managing them individually for each application?", "answer": "AWS Firewall Manager enforces security policies in a consistent, hierarchical manner across your entire infrastructure, unlike managing them individually for each application, which can lead to inconsistencies and increased complexity.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-04T17:21:25.692771"}}
{"question": "What security features can be centrally configured using AWS Firewall Manager?", "answer": "Using AWS Firewall Manager, you can centrally configure AWS WAF rules, AWS Shield Advanced protections, Amazon Virtual Private Cloud (VPC) security groups and network access control lists (ACLs), AWS Network Firewalls, and Amazon Route 53 Resolver DNS Firewall rules across accounts and resources in your organization.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-04T17:21:31.261210"}}
{"question": "How does AWS Firewall Manager ensure compliance with security policies for new resources or accounts?", "answer": "AWS Firewall Manager monitors for new resources or accounts created to ensure they comply with a mandatory set of security policies from day one. This ensures that any new resources or accounts are automatically aligned with the established security standards.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-04T17:21:31.261549"}}
{"question": "In what ways does AWS Firewall Manager allow for delegation of rule creation while maintaining global security policies?", "answer": "AWS Firewall Manager allows for delegation of the creation of application-specific rules within an account while retaining the ability to enforce global security policies across accounts. This means that individual accounts can create tailored rules while still adhering to overarching security requirements set by the organization.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-04T17:21:31.262100"}}
{"question": "What types of resources can AWS Firewall Manager create protections for?", "answer": "AWS Firewall Manager can create AWS Shield Advanced protections for Application Load Balancers, ELB Classic Load Balancers, Elastic IP Addresses, and CloudFront distributions.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:21:37.493277"}}
{"question": "Why is it important to enable AWS Config on accounts when using AWS Firewall Manager?", "answer": "Enabling AWS Config on accounts is important because it is a mandatory prerequisite for using AWS Firewall Manager, ensuring that the configurations of resources in each member account are tracked and managed.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:21:37.493654"}}
{"question": "How does the role of the AWS Firewall Manager Administrator Account differ from the member accounts in an AWS Organization?", "answer": "The AWS Firewall Manager Administrator Account is either the management account of the AWS organization or a member account with the appropriate permissions, and it is responsible for configuring and managing Firewall Manager settings, while the member accounts are those accounts that are part of the organization and must have AWS Config enabled to comply with Firewall Manager's requirements.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:21:37.493878"}}
{"question": "What are the two modes in which you can configure a Firewall Manager policy?", "answer": "You can configure a Firewall Manager policy in two modes: Automatic remediation, which allows you to automatically monitor for drift in policy and apply rules on non-compliant resources, and Manual remediation, which creates a new policy and the associated rules/protections in each account but does not enforce the rules on the resources in the account.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T17:21:42.874365"}}
{"question": "What is the purpose of specifying the scope of a Firewall Manager policy?", "answer": "The purpose of specifying the scope of a Firewall Manager policy is to choose the accounts, resource type, and optionally, resource tags, where you want the policy to be deployed.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T17:21:42.875733"}}
{"question": "How does the limit of accounts in a Firewall Manager policy compare to the limit on the number of resources managed by Firewall Manager?", "answer": "Each Firewall Manager policy can be scoped to have at most 2,500 accounts, which is the default limit for the number of accounts in AWS Organizations, while there is no limit on the number of resources managed by Firewall Manager at this time.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T17:21:42.876063"}}
{"question": "What types of firewalls does Firewall Manager support?", "answer": "Firewall Manager supports AWS WAF, AWS Shield Advanced, VPC security groups, AWS Network Firewall, Amazon Route 53 Resolver DNS Firewall, and AWS Marketplace third-party firewalls.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T17:21:50.186114"}}
{"question": "How does Firewall Manager help users monitor compliance for their policies?", "answer": "Firewall Manager allows users to quickly view the compliance status for each policy by showing how many accounts are included in the policy's scope and how many of those accounts are compliant. It provides a compliance dashboard that details which accounts and specific resources are non-compliant and the reasons for non-compliance.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T17:21:50.186458"}}
{"question": "What is the difference in notification mechanisms for non-compliant resources between Firewall Manager and AWS Security Hub?", "answer": "Firewall Manager allows users to create new SNS notification channels to receive real-time notifications for non-compliant resources. In contrast, AWS Security Hub notifies each account scoped under a Firewall Manager policy for non-compliant events, indicating that both systems provide notifications but use different methods for delivery.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T17:21:50.189224"}}
{"question": "What is Amazon Forecast primarily used for?", "answer": "Amazon Forecast is primarily used for forecasting business outcomes easily and accurately using machine learning by analyzing time-series data related to business metrics.", "question_type": "factual", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-04T17:21:53.483896"}}
{"question": "How does Amazon Forecast help in optimizing inventory?", "answer": "Amazon Forecast helps optimize inventory by providing accurate forecasts at a granular level, which reduces waste, increases inventory turns, and improves in-stock availability by forecasting product demand at specific probability levels.", "question_type": "conceptual", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-04T17:21:53.484190"}}
{"question": "In what ways does Amazon Forecast support workforce staffing compared to product demand forecasting?", "answer": "Amazon Forecast supports workforce staffing by allowing forecasts at 15-minute increments to optimize for high and low demand periods, whereas product demand forecasting focuses on predicting demand levels for inventory management.", "question_type": "comparison", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-04T17:21:53.484784"}}
{"question": "What types of fraud can Amazon Fraud Detector help identify?", "answer": "Amazon Fraud Detector can help identify various types of fraud including new account fraud during the account sign-up process, online identity fraud, payment fraud for online orders, guest checkout fraud, loyalty account protection, account takeover detection, and seller fraud in online marketplaces.", "question_type": "factual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T17:21:59.490370"}}
{"question": "How does Amazon Fraud Detector utilize machine learning for fraud detection?", "answer": "Amazon Fraud Detector utilizes machine learning by allowing users to upload historical event datasets to Amazon S3 and selecting a fraud detection model type. The service then automatically trains, tests, and deploys a customized fraud detection model based on the user's information. This model outputs a score that predicts the likelihood of fraud risk, which can be interpreted through decision logic to assign outcomes.", "question_type": "conceptual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T17:21:59.490868"}}
{"question": "How does the process of setting up a fraud detection model differ from traditional infrastructure management?", "answer": "Unlike traditional infrastructure management, which often requires upfront payments, long-term commitments, and ongoing management, Amazon Fraud Detector is a fully managed service that requires no infrastructure management. Users only pay for actual usage, and the service automatically handles the training, testing, and deployment of fraud detection models based on unique information provided by the user.", "question_type": "comparison", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T17:21:59.491137"}}
{"question": "What types of data can be used as inputs for fraud evaluation in Amazon Fraud Detector?", "answer": "The relevant risk data that can be used as inputs for fraud evaluation in Amazon Fraud Detector include email addresses, phone numbers, and IP addresses.", "question_type": "factual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T17:22:03.568618"}}
{"question": "How does Amazon Fraud Detector enhance the performance of its ML models?", "answer": "Amazon Fraud Detector enhances the performance of its ML models by using a series of models trained on patterns from AWS and Amazons own fraud expertise during the automated model training process.", "question_type": "conceptual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T17:22:03.568973"}}
{"question": "How does rule-based fraud detection with Amazon Fraud Detector compare to using machine learning models?", "answer": "Rule-based fraud detection with Amazon Fraud Detector can be performed with or without machine learning models. Users can author detection rules using a simple rule-writing language, while machine learning models are automatically trained, tested, and deployed based on historical fraud data. This allows for flexibility in detection methods, depending on the user's expertise and requirements.", "question_type": "comparison", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-04T17:22:03.569569"}}
{"question": "What are the four file systems that Amazon FSx supports?", "answer": "Amazon FSx supports four widely-used file systems: NetApp ONTAP, OpenZFS, Windows File Server, and Lustre.", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:22:09.350437"}}
{"question": "How does Amazon FSx simplify the management of file systems for users?", "answer": "Amazon FSx simplifies the management of file systems by being a fully managed service that handles hardware provisioning, patching, and backups. This allows users to focus on their applications, end users, and business instead of managing the underlying infrastructure.", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:22:09.350769"}}
{"question": "What are the main benefits of using Amazon FSx compared to traditional file systems?", "answer": "The main benefits of using Amazon FSx compared to traditional file systems include its ease of launching and scaling, high performance, lower total cost of ownership (TCO), and being a fully managed service that reduces the operational burden by handling hardware provisioning, patching, and backups. Additionally, Amazon FSx supports industry-standard protocols for connectivity and delivers sub-millisecond latencies and high throughput for demanding workloads.", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:22:09.351333"}}
{"question": "How does Amazon FSx ensure high availability and durability of data?", "answer": "Amazon FSx ensures high availability and durability by automatically replicating your data within or across AWS Availability Zones to protect it from component failure. It continuously monitors for hardware failures, automatically replaces infrastructure components, or switches to a stand-by file server in the event of a failure.", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T17:22:16.057553"}}
{"question": "What are the benefits of using Amazon FSx for data storage?", "answer": "The benefits of using Amazon FSx for data storage include high availability through data replication and monitoring, support for multiple storage options (SSD and HDD), independent provisioning and scaling of throughput performance, and a rich set of storage efficiency features such as data deduplication and compression. Additionally, it facilitates easy data migration and synchronization from on-premises to AWS, and integration with AWS services, while offering enhanced security through data encryption at-rest and in-transit.", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T17:22:16.057894"}}
{"question": "How does Amazon FSx compare to traditional on-premises storage solutions in terms of agility and scalability?", "answer": "Amazon FSx offers similar capabilities and performance to traditional on-premises storage solutions, allowing organizations to leverage the agility and scalability of cloud storage for file shares, database, and application workloads without needing to modify their application code or data management practices.", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T17:22:16.058396"}}
{"question": "What types of applications require highly performant and scalable file storage?", "answer": "Many machine learning, analytics, and HPC applications require highly performant and scalable file storage to support large clusters of compute resources and huge volumes of data.", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-04T17:22:19.809128"}}
{"question": "How does Amazon FSx facilitate backup and disaster recovery for on-premises file storage?", "answer": "Amazon FSx lets you easily and securely backup, archive, or replicate your on-premises file storage to AWS in order to meet regulatory, data retention, or disaster recovery requirements.", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-04T17:22:19.809461"}}
{"question": "In what ways does Amazon FSx storage support Media & Entertainment workloads compared to traditional storage solutions?", "answer": "Amazon FSx storage offers high-performance storage that is broadly accessible by end users who create and edit media from various operating systems and supports compute-intensive rendering and transcoding jobs, providing the scalability and flexibility needed to deliver media projects on time and within budget.", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-04T17:22:19.810074"}}
{"question": "What is AWS Global Accelerator and what does it do?", "answer": "AWS Global Accelerator is a networking service that helps improve the availability and performance of applications offered to global users. It provides static IP addresses that serve as a fixed entry point to applications, simplifying the management of IP addresses across different AWS Regions and Availability Zones. It routes user traffic to the optimal endpoint based on performance, reacting instantly to changes in application health, user location, and configured policies.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:22:25.248528"}}
{"question": "How does AWS Global Accelerator enhance the performance of applications?", "answer": "AWS Global Accelerator enhances application performance by always routing user traffic to the optimal endpoint based on performance metrics. It reacts instantly to changes in application health and user locations, ensuring that users are connected to the best possible endpoint for their requests. Additionally, it allows users to test performance benefits using a speed comparison tool.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:22:25.248917"}}
{"question": "What are the differences in functionality between AWS Global Accelerator and traditional DNS management?", "answer": "AWS Global Accelerator simplifies the management of IP addresses by providing static IP addresses that serve as a fixed entry point, eliminating the need for updating DNS configurations when moving endpoints between Availability Zones or AWS Regions. In contrast, traditional DNS management often requires manual updates to DNS settings whenever there are changes to the IP addresses or endpoints, which can lead to complexity and potential downtime.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:22:25.249192"}}
{"question": "What percentage reduction in first byte latency can AWS Global Accelerator achieve for TCP traffic as measured at the 90th percentile?", "answer": "AWS Global Accelerator can decrease first byte latency by up to 49% for TCP traffic as measured by third party real user measurement tools at the 90th percentile.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-04T17:22:29.442475"}}
{"question": "How does AWS Global Accelerator improve application performance compared to the public internet?", "answer": "AWS Global Accelerator improves application performance by lowering first byte latency and jitter, as well as increasing throughput compared to the public internet.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-04T17:22:29.443792"}}
{"question": "How does the performance improvement experienced by the multinational customer using AWS Global Accelerator compare to the improvement experienced by Skyscanner?", "answer": "The multinational customer saw a 51.2 percent reduction in mean end-to-end app load times by enabling AWS Global Accelerator, while Skyscanner decreased response time from more than 200 milliseconds to less than 4 milliseconds, achieving a 98 percent improvement.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-04T17:22:29.444227"}}
{"question": "What are the three steps to set up AWS Global Accelerator?", "answer": "The three steps to set up AWS Global Accelerator are: 1) Create an accelerator, where AWS provisions two static IP addresses and you configure listeners for inbound connections; 2) Configure endpoint groups, where you choose regional endpoint groups, specify AWS Regions for traffic distribution, and set health check settings; 3) Register endpoints for endpoint groups, where you register regional resources like Application Load Balancers or EC2 Instances and set weights for traffic routing.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-04T17:22:34.553959"}}
{"question": "How does AWS Global Accelerator monitor the health of endpoints within an endpoint group?", "answer": "AWS Global Accelerator monitors the health of endpoints within an endpoint group using the health check settings defined for each endpoint.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-04T17:22:34.554304"}}
{"question": "What is the default traffic dial percentage for regional endpoint groups in AWS Global Accelerator?", "answer": "The default traffic dial percentage for all regional endpoint groups in AWS Global Accelerator is set to 100%.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-04T17:22:34.554598"}}
{"question": "What is the primary function of AWS Global Accelerator?", "answer": "The primary function of AWS Global Accelerator is to route user requests to healthy application endpoints and provide traffic management across multiple AWS Regions.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:22:39.122259"}}
{"question": "How does AWS Global Accelerator differ from ELB in terms of regional capabilities?", "answer": "AWS Global Accelerator extends the load balancing capabilities of ELB by providing traffic management across multiple Regions, while ELB only offers load balancing within a single Region.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:22:39.124143"}}
{"question": "In what scenarios should you use AWS Global Accelerator instead of an Application Load Balancer?", "answer": "You should use AWS Global Accelerator if you have workloads that cater to a global client base, as it provides a global interface across multiple Regions. In contrast, if your workloads are hosted in a single AWS Region and used by clients in and around that Region, an Application Load Balancer or Network Load Balancer would be more suitable.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:22:39.124447"}}
{"question": "What is the purpose of using a custom routing accelerator in AWS?", "answer": "The purpose of using a custom routing accelerator in AWS is to enable the use of your own application logic to route user traffic to a specific Amazon EC2 IP and port across one or multiple AWS Regions. This is particularly useful in scenarios like multi-player games where player assignments to specific game servers can be based on factors like geographic location, player skill, and gaming configuration.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-04T17:22:44.146200"}}
{"question": "How do Amazon S3 Multi-Region Access Points integrate with Global Accelerator?", "answer": "Amazon S3 Multi-Region Access Points integrate with Global Accelerator by using it transparently to provide a single global endpoint for accessing a data set that spans multiple S3 buckets located in different AWS Regions. This integration allows for the construction of multi-region applications with a simple architecture similar to that used in a single region.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-04T17:22:44.146504"}}
{"question": "What benefits do S3 Multi-Region Access Points provide compared to traditional single-region S3 bucket access?", "answer": "S3 Multi-Region Access Points provide the benefit of automatically routing application requests over the AWS global network to the S3 bucket with the lowest network latency, which helps to avoid congested network segments on the public internet. This improves application performance and reliability compared to traditional single-region S3 bucket access.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-04T17:22:44.146899"}}
{"question": "What does AWS Global Accelerator do to ensure high availability for applications?", "answer": "AWS Global Accelerator ensures high availability for applications by using a fault-isolating design that increases application availability. When an accelerator is created, it is allocated two IPv4 static IP addresses serviced by independent network zones. These network zones are isolated units with their own physical infrastructure, allowing for fault tolerance. If one static IP address becomes unavailable, AWS Global Accelerator reroutes traffic to a healthy static IP address from the other isolated network zone.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T17:22:51.038727"}}
{"question": "How does AWS Global Accelerator handle changes in application routing without being affected by client IP address caching?", "answer": "AWS Global Accelerator handles changes in application routing by eliminating reliance on the IP address caching settings of client devices. When a configuration update or application failure occurs, change propagation takes a matter of seconds, which significantly reduces application downtime. This means that users receive updated IP addresses quickly, regardless of how long client devices cache DNS answers.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T17:22:51.039017"}}
{"question": "In what ways does AWS Global Accelerator improve performance compared to traditional routing methods?", "answer": "AWS Global Accelerator improves performance by ingressing traffic from the edge location closest to end clients through anycast static IP addresses. It then routes the traffic over the congestion-free and redundant AWS global network, optimizing the path to the application running in an AWS Region. Additionally, AWS Global Accelerator selects the optimal AWS Region based on the geography of end clients, which reduces first-byte latency and can improve performance by as much as 60%.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-04T17:22:51.039444"}}
{"question": "What is the purpose of the static IP addresses provided by AWS Global Accelerator?", "answer": "The static IP addresses provided by AWS Global Accelerator serve as fixed entry points to your applications, allowing you to move your endpoints between Availability Zones or between AWS Regions without needing to update your DNS configuration or client-facing applications.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-04T17:22:56.139585"}}
{"question": "How does AWS Global Accelerator facilitate the management of traffic during application updates?", "answer": "AWS Global Accelerator allows you to set a traffic dial for your regional endpoint groups, enabling you to increase or decrease traffic to a specific AWS Region during performance testing or application updates. This feature provides fine-grained control over traffic management.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-04T17:22:56.139916"}}
{"question": "What are the differences between the capabilities of AWS Global Accelerator for A/B testing and failover simulations?", "answer": "The capabilities of AWS Global Accelerator for A/B testing and failover simulations both utilize static IP addresses for a consistent entry point. However, A/B testing involves directing different traffic to multiple versions of an application to evaluate performance, while failover simulations test the resilience of your application by redirecting traffic in case of a failure. Both use the same static IP addresses but serve different purposes in application management.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-04T17:22:56.140406"}}
{"question": "What are the advantages of using static IP addresses with AWS Global Accelerator?", "answer": "The advantages of using static IP addresses with AWS Global Accelerator include increasing the Quality of Service (QoS) for users by onboarding their traffic onto the AWS global network as close to them as possible, the ability to easily move applications between AWS Regions without changing the public interface, and improved application availability and performance due to leveraging the AWS globally redundant network.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-04T17:23:01.892369"}}
{"question": "How does AWS Global Accelerator improve application availability and performance?", "answer": "AWS Global Accelerator improves application availability and performance by providing a network layer that can perform health checks on application endpoints. It automatically routes traffic around failed endpoints, ensuring that internet traffic is directed to the closest available endpoint, which enhances the overall user experience.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-04T17:23:01.892788"}}
{"question": "How does AWS Global Accelerator handle endpoint failures compared to traditional routing methods?", "answer": "AWS Global Accelerator handles endpoint failures by automatically detecting unhealthy endpoints and redirecting traffic to the next optimal AWS Region in less than one minute, which provides high availability and disaster recovery. In contrast, traditional routing methods may require manual intervention and could lead to longer downtimes and disruptions for clients.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-04T17:23:01.892917"}}
{"question": "What certifications does AWS Global Accelerator comply with?", "answer": "AWS Global Accelerator complies with PCI DSS, ISO 9001, ISO 27001, ISO 27017, ISO 27018, and SOC (System & Organization Control), and it is also HIPAA-eligible.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:23:09.347035"}}
{"question": "How does bringing your own IP address ranges (BYOIP) benefit applications with hardcoded IP address dependencies?", "answer": "Bringing your own IP address ranges (BYOIP) to AWS Global Accelerator allows you to use your own IP addresses as a fixed entry point to your application endpoints. This enables the migration of on-premises applications with hardcoded IP address dependencies to AWS without making any client-facing changes, which is particularly beneficial in regulated environments that require allow-listing of IP address ranges.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:23:09.347395"}}
{"question": "What are the key differences between Global Accelerator's IP addresses and EC2 Elastic IP addresses?", "answer": "The key differences between Global Accelerator's IP addresses and EC2 Elastic IP addresses are: 1) Global Accelerator's IP addresses can be associated with multiple endpoints in various AWS Regions, allowing for easier scaling across multiple Availability Zones or Regions, while Elastic IPs are tied to a single resource in one AWS Region. 2) Global Accelerator's IP addresses support only client-generated connections, whereas Elastic IPs support both client and server-generated connections. 3) Global Accelerator's IP addresses are advertised from AWS's extensive network of edge locations for optimal performance, while Elastic IPs are advertised from a single AWS Region at a time.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:23:09.347877"}}
{"question": "What is the most specific address range that you can bring via BYOIP to AWS Global Accelerator?", "answer": "The most specific address range that you can bring via BYOIP to AWS Global Accelerator is /24.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:23:14.621109"}}
{"question": "How does a custom routing accelerator differ from a standard accelerator in AWS Global Accelerator?", "answer": "A custom routing accelerator allows you to deterministically route one or more users to a specific Amazon EC2 instance destination based on your application logic, while a standard accelerator automatically routes traffic to the nearest healthy endpoint and does not allow for deterministic routing of multiple users to a specific EC2 destination. Additionally, standard accelerators support various endpoint types such as Network Load Balancers and Application Load Balancers, whereas custom routing accelerators only support VPC subnet endpoints containing EC2 instances.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:23:14.621450"}}
{"question": "What types of endpoints do standard accelerators and custom routing accelerators support in AWS Global Accelerator?", "answer": "Standard accelerators support Network Load Balancers, Application Load Balancers, EC2 instances, and Elastic IPs as endpoints. In contrast, custom routing accelerators support only VPC subnet endpoints, each containing one or more EC2 instances running your application.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:23:14.622084"}}
{"question": "What is the purpose of a custom routing accelerator in AWS?", "answer": "The purpose of a custom routing accelerator in AWS is to deterministically route multiple users to a specific destination IP address and port that an application session is running on, allowing users to connect to static anycast IP addresses allocated to the accelerator.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-04T17:23:21.934941"}}
{"question": "How does a custom routing accelerator handle traffic routing to EC2 instances?", "answer": "A custom routing accelerator maps a specific accelerator port to a specific EC2 instance and port within a VPC subnet, routing user traffic there. The mapping is preconfigured and static, allowing the application to query for this mapping using an API and control how Global Accelerator routes client traffic.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-04T17:23:22.283755"}}
{"question": "What is the difference between custom routing accelerators and traditional external health checks?", "answer": "Custom routing accelerators do not provide external health checks for VPC subnet endpoints or the EC2 instances within them, whereas traditional external health checks typically monitor the health status of services externally. Instead, with custom routing accelerators, the application itself must monitor the health of EC2 instances and manage traffic failover to healthy instances.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-04T17:23:22.284243"}}
{"question": "What types of traffic does AWS Global Accelerator support?", "answer": "AWS Global Accelerator supports IPv4 traffic towards all endpoints and IPv6 traffic towards Application Load Balancer Endpoints.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-04T17:23:26.923560"}}
{"question": "How does AWS Global Accelerator improve the management of IP address changes compared to traditional methods?", "answer": "AWS Global Accelerator improves the management of IP address changes by allowing change propagation to take a matter of seconds, eliminating reliance on the DNS caching settings of client devices. This significantly reduces application downtime when updates are made.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-04T17:23:26.924829"}}
{"question": "How does AWS Global Accelerator's use of static IP addresses benefit application deployment compared to using dynamic IP addresses?", "answer": "AWS Global Accelerator's use of static IP addresses benefits application deployment by providing a fixed entry point to applications. This allows users to easily move their endpoints between Availability Zones or between AWS Regions without needing to update the DNS configuration or client-facing applications, which is typically required when using dynamic IP addresses.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-04T17:23:26.925543"}}
{"question": "What is AWS Glue?", "answer": "AWS Glue is a serverless data integration service that simplifies the process of discovering, preparing, and combining data for analytics, machine learning (ML), and application development.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T17:23:32.143732"}}
{"question": "How does AWS Glue facilitate data integration for users?", "answer": "AWS Glue facilitates data integration by providing all the necessary capabilities for data integration, allowing users to analyze their data and utilize it in minutes instead of months. It offers both visual and code-based interfaces, helping users find and access data easily through the AWS Glue Data Catalog, and enabling data engineers and ETL developers to visually create, run, and monitor ETL workflows in AWS Glue Studio. Additionally, data analysts and data scientists can use AWS Glue DataBrew to enrich, clean, and normalize data without writing code.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T17:23:32.144204"}}
{"question": "How do AWS Glue Studio and AWS Glue DataBrew differ in their approach to data integration?", "answer": "AWS Glue Studio allows data engineers and ETL developers to visually create, run, and monitor ETL workflows, while AWS Glue DataBrew is designed for data analysts and data scientists to visually enrich, clean, and normalize data without the need to write code.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T17:23:32.144402"}}
{"question": "What are the main components of AWS Glue?", "answer": "The main components of AWS Glue include a Data Catalog, which serves as a central metadata repository; a data processing engine that runs Scala or Python code; and a flexible scheduler that manages dependency resolution, job monitoring, and retries.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-04T17:23:37.935735"}}
{"question": "How does AWS Glue help in data preparation for analytics?", "answer": "AWS Glue helps in data preparation for analytics by automating the discovery, categorization, cleaning, enriching, and movement of data, allowing users to spend more time analyzing their data. It can automatically discover both structured and semi-structured data and provides a unified view of the data through the Data Catalog for ETL, querying, and reporting.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-04T17:23:37.936231"}}
{"question": "In what ways is AWS Glue similar to Amazon Athena and Amazon Redshift Spectrum?", "answer": "AWS Glue is similar to Amazon Athena and Amazon Redshift Spectrum in that it provides a unified view of data and supports querying and reporting. All three services can work with data stored in various locations, including Amazon S3 and data warehouses, facilitating data analysis across different sources.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-04T17:23:37.936414"}}
{"question": "What types of databases does AWS Glue natively support within an Amazon VPC?", "answer": "AWS Glue natively supports the following databases within an Amazon VPC: Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for Oracle, Amazon RDS for PostgreSQL, Amazon RDS for SQL Server, Amazon Redshift, Amazon DynamoDB, Amazon S3, MySQL, Oracle, Microsoft SQL Server, and PostgreSQL.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T17:23:42.869119"}}
{"question": "What additional capabilities does AWS Lake Formation provide compared to AWS Glue?", "answer": "AWS Lake Formation encompasses AWS Glue features and provides additional capabilities designed to help build, secure, and manage a data lake, while AWS Glue is focused primarily on ETL functions.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T17:23:42.869463"}}
{"question": "How does AWS Glue's support for data sources compare to the data sources supported by AWS Lake Formation?", "answer": "The context does not explicitly compare the data sources supported by AWS Glue and AWS Lake Formation; however, it mentions that Lake Formation uses a shared infrastructure with AWS Glue, including a common Data Catalog. Therefore, while specific data sources supported by Lake Formation are not mentioned, it can be inferred that it likely includes those supported by AWS Glue.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-04T17:23:42.869877"}}
{"question": "What services does Amazon SageMaker Data Processing and Analytics integrate with for data processing capabilities?", "answer": "Amazon SageMaker Data Processing and Analytics integrates with Amazon Athena, Amazon EMR, AWS Glue, and Amazon Managed Workflows for Apache Airflow for its data processing capabilities.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-04T17:23:47.450153"}}
{"question": "What is the purpose of the Data Catalog in AWS services?", "answer": "The Data Catalog serves as a central repository to store structural and operational metadata for all data assets, allowing users to store table definitions and physical locations for datasets, add business-relevant attributes, and track changes over time.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-04T17:23:47.450479"}}
{"question": "How does the Data Catalog compare to the Apache Hive Metastore in terms of compatibility?", "answer": "The Data Catalog is Apache Hive Metastore compatible and acts as a drop-in replacement for the Apache Hive Metastore specifically for Big Data applications running on Amazon EMR.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-04T17:23:47.450964"}}
{"question": "What does an AWS Glue crawler do?", "answer": "An AWS Glue crawler connects to a data store, progresses through a prioritized list of classifiers to extract the schema of your data and other statistics, and then populates the Data Catalog with this metadata.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T17:23:52.286194"}}
{"question": "How does AWS Glue integrate with Amazon Athena and Amazon Redshift Spectrum?", "answer": "AWS Glue integrates with Amazon Athena and Amazon Redshift Spectrum by allowing the Data Catalog to serve as a common metadata repository. However, before using the AWS Glue Data Catalog with Amazon Athena, you must upgrade your Amazon Athena data catalog to the AWS Glue Data Catalog.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T17:23:52.286479"}}
{"question": "How does the AWS Glue Data Catalog compare to the Hive Metastore?", "answer": "The AWS Glue Data Catalog is Hive Metastore compatible, meaning you can point to the Data Catalog endpoint and use it as a Hive Metastore replacement. This allows for seamless integration and use of the Data Catalog in place of the Hive Metastore.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T17:23:52.287086"}}
{"question": "What programming languages can the AWS Glue ETL script recommendation system generate code in?", "answer": "The AWS Glue ETL script recommendation system can generate code in Scala or Python.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-04T17:23:56.622154"}}
{"question": "How does AWS Glue facilitate the management of dependencies between multiple ETL jobs?", "answer": "AWS Glue facilitates the management of dependencies between multiple ETL jobs by using triggers. These triggers can watch one or more jobs and invoke one or more jobs, allowing for scheduled triggers that invoke jobs periodically, on-demand triggers, or job completion triggers.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-04T17:23:56.622464"}}
{"question": "What are the differences between scheduled triggers and job completion triggers in AWS Glue?", "answer": "Scheduled triggers in AWS Glue invoke jobs periodically based on a set schedule, while job completion triggers invoke jobs based on the completion of another job. This allows for different ways to manage when jobs are executed within an ETL workflow.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-04T17:23:56.622990"}}
{"question": "What service does AWS Glue use to push job event metrics and errors?", "answer": "AWS Glue pushes all job event metrics and errors to Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-04T17:24:00.435780"}}
{"question": "How can you trigger actions in response to notifications from AWS Glue?", "answer": "You can configure a host of actions in Amazon CloudWatch that can be triggered based on specific notifications from AWS Glue, such as triggering an AWS Lambda function upon receiving an error or a success notification.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-04T17:24:00.436206"}}
{"question": "What are the differences between using AWS Glue's Data Catalog and ETL independently?", "answer": "While using both the Data Catalog and ETL together provides a complete ETL experience, you can use either the Data Catalog or ETL independently without the need to use the other.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-04T17:24:00.436412"}}
{"question": "What is the primary use case for AWS Glue?", "answer": "The primary use case for AWS Glue is ETL (Extract, Transform, Load) processing, particularly for jobs that run on a serverless Apache Spark-based platform.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-04T17:24:04.785037"}}
{"question": "How does AWS Glue support advanced ETL on streaming data?", "answer": "AWS Glue supports advanced ETL on streaming data by using a serverless pay-as-you-go platform, generating customizable ETL code to prepare data while in transit, and having built-in functionality to process streaming data that is semi-structured or has an evolving schema.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-04T17:24:04.785430"}}
{"question": "What are the main differences between AWS Glue and Kinesis Data Analytics regarding their recommended use cases?", "answer": "AWS Glue is recommended for ETL use cases and operates on a serverless Apache Spark-based platform, while Kinesis Data Analytics is recommended for analytics use cases and operates on a serverless Apache Flink-based platform.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-04T17:24:04.785650"}}
{"question": "What is AWS Glue recommended for in terms of ETL?", "answer": "AWS Glue is recommended for complex ETL, including joining streams and partitioning the output in Amazon S3 based on the data content.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:24:10.790997"}}
{"question": "How does AWS Glue's streaming ETL differ from Kinesis Data Firehose's capabilities?", "answer": "AWS Glue's streaming ETL enables advanced ETL on streaming data, including applying complex transforms, enriching records with information from other streams and persistent data stores, and loading records into a data lake or data warehouse. In contrast, Kinesis Data Firehose focuses on data delivery and includes serverless data transformation through AWS Lambda, but lacks the advanced ETL capabilities that AWS Glue supports.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:24:10.791288"}}
{"question": "What features are included in AWS Glue Data Quality compared to Kinesis Data Firehose?", "answer": "AWS Glue Data Quality includes features that automatically measure and monitor the quality of data in data lakes and pipelines, recommend data quality rules, and allow modification of these rules. It also evaluates these rules to calculate data quality scores and can alert teams when quality issues occur. Kinesis Data Firehose, on the other hand, does not include these advanced data quality monitoring and management features.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-04T17:24:10.791676"}}
{"question": "What are the four categories of built-in rule types supported by AWS Glue Data Quality?", "answer": "AWS Glue Data Quality supports four categories of built-in rule types: Consistency rules, Accuracy rules, Integrity rules, and Completeness rules.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-04T17:24:15.044900"}}
{"question": "How does AWS Glue Data Quality automate the process of data quality checks?", "answer": "AWS Glue Data Quality automates the process by analyzing data to determine appropriate data quality rules and then applying those checks on a schedule that you choose. It also provides built-in options for monitoring and alerting.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-04T17:24:15.045188"}}
{"question": "What is the relationship between Deequ and AWS Glue Data Quality?", "answer": "AWS Glue Data Quality uses Deequ, an Amazon developed open-source framework that helps manage the quality of Amazon internal datasets at petabyte scale. Deequ utilizes Apache Spark to gather data statistics and identify the right set of checks or rules to validate data quality.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-04T17:24:15.045609"}}
{"question": "What can you do in the Data Catalog to address a data quality issue?", "answer": "In the Data Catalog, you can write the metrics to Amazon CloudWatch and set up alerts in CloudWatch to notify you when scores go below a threshold.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T17:24:19.245385"}}
{"question": "How do data quality tasks help in managing data quality in workflows?", "answer": "Data quality tasks allow you to evaluate your data quality as data is brought into your data lake through your pipelines. You can create these tasks in the Data Catalog, run them immediately, or schedule them to run at certain intervals, which helps in making confident data-driven decisions.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T17:24:19.245727"}}
{"question": "How do the data quality rule requirements differ between data engineers and business analysts?", "answer": "Data engineers need more technical data quality rules compared to business analysts, who write functional rules. This difference indicates that data quality features are tailored to meet the unique requirements of each user type.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T17:24:19.246277"}}
{"question": "What types of users are primarily targeted by AWS Glue DataBrew?", "answer": "AWS Glue DataBrew primarily targets data analysts and data scientists. For data analysts, examples of job functions include business intelligence analysts, operations analysts, market intelligence analysts, legal analysts, financial analysts, economists, quants, or accountants. For data scientists, examples include materials scientists, bioanalytical scientists, and scientific researchers.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T17:24:24.763155"}}
{"question": "How does AWS Glue DataBrew facilitate data preparation for users?", "answer": "AWS Glue DataBrew facilitates data preparation by providing a visual data preparation tool that allows users to prepare data through an interactive, point-and-click visual interface without the need to write code. It enables users to visualize, clean, and normalize large volumes of data from various sources, while offering over 250 built-in transformations and automatic recommendations for data cleaning and normalization.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T17:24:24.763509"}}
{"question": "How does AWS Glue Studio enhance the functionality of DataBrew recipes?", "answer": "AWS Glue Studio enhances the functionality of DataBrew recipes by allowing users to select a data preparation node that offers a visual data preparation tool, import their existing DataBrew recipes, and continue to author them within Glue Studio. Additionally, users can run these recipes and take advantage of the additional transformations that AWS Glue Studio offers.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-04T17:24:24.763937"}}
{"question": "What is the cost for the first 40 interactive sessions for new users of AWS Glue DataBrew?", "answer": "The first 40 interactive sessions for new users of AWS Glue DataBrew are free.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-04T17:24:28.870828"}}
{"question": "How does using the Data Catalog or Lake Formation affect the selection of datasets in AWS Glue DataBrew?", "answer": "If users employ either the Data Catalog or Lake Formation, DataBrew users can select the datasets available to them from their centralized data catalog.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-04T17:24:28.871168"}}
{"question": "What are the benefits of integrating streaming data applications with the Schema Registry in AWS Glue?", "answer": "Integrating streaming data applications with the Schema Registry in AWS Glue allows for improved data quality and safeguards against unexpected changes through compatibility checks that govern schema evolution. Additionally, it enables the creation or updating of AWS Glue tables and partitions using Apache Avro schemas stored within the registry.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-04T17:24:28.871686"}}
{"question": "What data formats does the Schema Registry support?", "answer": "The Schema Registry supports Apache Avro and JSON Schema data formats.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-04T17:24:33.183533"}}
{"question": "How does the Schema Registry improve data quality?", "answer": "The Schema Registry improves data quality by ensuring that serializers validate schemas used by data producers against those stored in the registry. This validation occurs at the origin of the data, which helps reduce downstream issues resulting from unexpected schema drift.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-04T17:24:33.183895"}}
{"question": "What is the difference between the 'Backward' and 'Forward' compatibility modes in the Schema Registry?", "answer": "The 'Backward' compatibility mode allows schemas to evolve in a way that new consumers can read data produced with older schemas. In contrast, the 'Forward' compatibility mode allows older consumers to read data produced with newer schemas. These modes help manage schema evolution differently, ensuring compatibility in different directions.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-04T17:24:33.184102"}}
{"question": "What is AWS PrivateLink used for in relation to AWS Glue?", "answer": "AWS PrivateLink is used to connect your data producers virtual private cloud (VPC) to AWS Glue by defining an interface VPC endpoint for AWS Glue. This allows communication between your VPC and AWS Glue to be conducted entirely within the AWS network.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T17:24:37.997903"}}
{"question": "What are the differences between the standard and flexible execution classes in AWS Glue?", "answer": "The standard execution class in AWS Glue is ideal for time-sensitive workloads, starting jobs immediately and providing dedicated resources while they run. In contrast, the flexible execution class is designed for nonurgent jobs, running on non-dedicated compute resources that can be reclaimed while a job is running, which leads to variable start and completion times.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T17:24:37.998284"}}
{"question": "How does the cost structure of AWS Glue Flex compare to the standard execution class?", "answer": "AWS Glue Flex can reduce the cost of nonurgent data integration workloads by up to 35% compared to the standard execution class, which is ideal for time-sensitive workloads that require fast job startup and dedicated resources. This makes the flexible execution class less expensive and more suitable for jobs where variance in start and completion times is acceptable.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T17:24:37.998808"}}
{"question": "How do you change the execution class for AWS Glue Spark jobs?", "answer": "To change the execution class for AWS Glue Spark jobs, you need to change the default setting of the execution class parameter from STANDARD to FLEX. This can be done through AWS Glue Studio or a command line interface (CLI).", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-04T17:24:41.842716"}}
{"question": "Why is AWS Glue Flex not recommended for long-running data integration workloads?", "answer": "AWS Glue Flex is not recommended for long-running data integration workloads because these workloads are more likely to get interrupted, which can result in frequent cancellations of jobs.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-04T17:24:41.842951"}}
{"question": "What factors influence the availability and interruption frequency of AWS Glue Flex jobs?", "answer": "The availability and interruption frequency of AWS Glue Flex jobs depend on several factors, including the AWS Region and Availability Zone, time of day, and day of the week.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-04T17:24:41.843097"}}
{"question": "What types of jobs does the flexible execution class support in AWS Glue?", "answer": "The flexible execution class supports only AWS Glue Spark jobs. It does not support Python Shell and streaming jobs.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-04T17:25:11.535783"}}
{"question": "How does AWS Glue simplify the process of creating and maintaining ETL jobs?", "answer": "AWS Glue simplifies the process of creating and maintaining ETL jobs by inferring, evolving, and monitoring the jobs, which allows users to focus on data transformation without managing the underlying infrastructure.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-04T17:25:11.885231"}}
{"question": "How does AWS Glue differ from Amazon EMR in terms of access to the computing environment?", "answer": "AWS Glue provides a fully managed ETL service with a serverless Apache Spark environment, which abstracts the underlying infrastructure. In contrast, Amazon EMR provides direct access to the Hadoop environment, allowing for lower-level access and greater flexibility in using tools beyond Spark.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-04T17:25:11.885676"}}
{"question": "What is the minimum number of DPUs required for an AWS Glue ETL job?", "answer": "An AWS Glue ETL job requires a minimum of 2 DPUs.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-04T17:25:16.962433"}}
{"question": "How does AWS Glue Usage Profiles help with cost control?", "answer": "AWS Glue Usage Profiles allow admins to set preventative controls and limits over resources consumed by their Glue jobs and Notebook sessions. Each profile is a unique set of parameters that can be assigned to different types of users, enabling the creation of different cost profiles for them.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-04T17:25:16.962739"}}
{"question": "How does the billing system for AWS Glue jobs differ from the environment provisioning time?", "answer": "Billing for AWS Glue jobs commences as soon as the job is scheduled for execution and continues until the job completes. You only pay for the time the job runs, not for the environment provisioning or shutdown time.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-04T17:25:16.963378"}}
{"question": "What is the Monthly Uptime Percentage threshold for eligibility for an SLA credit for AWS Glue?", "answer": "The Monthly Uptime Percentage threshold for eligibility for an SLA credit for AWS Glue is less than 99.9%.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-04T17:25:22.511839"}}
{"question": "Under what conditions can you claim an SLA credit for AWS Glue?", "answer": "You can claim an SLA credit for AWS Glue if more than one Availability Zone in which you are running a task, within the same Region, has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-04T17:25:22.512145"}}
{"question": "How does the SLA eligibility for AWS Glue relate to Availability Zones?", "answer": "The SLA eligibility for AWS Glue requires that more than one Availability Zone must have a Monthly Uptime Percentage of less than 99.9% during the same monthly billing cycle.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-04T17:25:22.512360"}}
{"question": "What types of malicious activities does Amazon GuardDuty detect?", "answer": "Amazon GuardDuty detects potential malicious activities such as anomalous behavior, credential exfiltration, and command and control infrastructure (C2) communication.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-04T17:25:26.990746"}}
{"question": "How does Amazon GuardDuty ensure it does not impact the performance or availability of AWS workloads?", "answer": "Amazon GuardDuty is designed to operate completely independently from your resources, ensuring that it has no performance or availability impact on your workloads.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-04T17:25:26.991050"}}
{"question": "How does the cost structure of Amazon GuardDuty work compared to traditional security solutions?", "answer": "Amazon GuardDuty has no upfront costs and you only pay for the events analyzed, unlike traditional security solutions that may require additional software deployments or threat intelligence feed subscriptions.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-04T17:25:26.991582"}}
{"question": "What factors determine the pricing of GuardDuty?", "answer": "GuardDuty pricing is based on the volume of analyzed service logs, virtual CPUs (vCPUs) or Aurora Serverless v2 instance Aurora capacity units (ACUs) for Amazon RDS event analysis, the number and size of Amazon Elastic Kubernetes Service (Amazon EKS) or Amazon Elastic Container Service (Amazon ECS) workloads being monitored at runtime, and the volume of data scanned for malware.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:25:33.456619"}}
{"question": "How does enabling EKS Runtime Monitoring affect the charges for VPC Flow Logs?", "answer": "If EKS Runtime Monitoring is enabled for your account, you will not be charged for the analysis of VPC Flow Logs from instances where the GuardDuty agent is deployed and active. This is because the runtime security agent provides similar network telemetry data, and to avoid double charging customers, there will be no charge for VPC Flow Logs from Amazon Elastic Compute Cloud (Amazon EC2) instances where the agent is installed.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:25:33.457077"}}
{"question": "How does the billing process differ for individual accounts versus the GuardDuty administrator account?", "answer": "The estimated cost represents the cost for the individual payer account, and the billed usage and average daily cost for each member account can be seen in the GuardDuty administrator account. However, to view the detailed usage information, you must go to the individual account.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:25:33.457492"}}
{"question": "How long can new accounts try GuardDuty for free?", "answer": "New accounts to GuardDuty can try the service for 30 days at no cost, with access to the full feature set and detections during the free trial.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T17:25:37.874937"}}
{"question": "What is the purpose of GuardDuty?", "answer": "GuardDuty provides broad security monitoring of your AWS accounts, workloads, and data to help identify threats, such as attacker reconnaissance; instance, account, bucket, or Amazon EKS cluster compromises; and malware.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T17:25:37.875244"}}
{"question": "How does GuardDuty handle security findings across multiple AWS Regions?", "answer": "GuardDuty is a Regional service, meaning that security findings remain in the same Regions where the underlying data was generated. However, you can aggregate security findings across Regions using Amazon EventBridge or by pushing findings to a data store like Amazon S3, and you can also send findings to AWS Security Hub for cross-Region aggregation.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T17:25:37.875484"}}
{"question": "What foundational data sources does GuardDuty analyze?", "answer": "GuardDuty analyzes foundational data sources including AWS CloudTrail management event logs, CloudTrail management events, and Amazon EC2 VPC Flow Logs and DNS query logs.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T17:25:42.879352"}}
{"question": "How does GuardDuty help organizations meet security compliance requirements?", "answer": "GuardDuty assists organizations in meeting security compliance requirements by providing intrusion detection techniques at critical points in the network, as highlighted in a white paper published by Foregenix that assesses GuardDuty's effectiveness in fulfilling PCI DSS requirement 11.4.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T17:25:42.879720"}}
{"question": "What is the relationship between GuardDuty and AWS Organizations in terms of account management?", "answer": "GuardDuty is integrated with AWS Organizations, allowing users to delegate an administrator account for GuardDuty for their organization. This delegated administrator (DA) account consolidates all findings from multiple AWS accounts and can configure all member accounts, facilitating centralized management and review of security findings.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-04T17:25:42.879884"}}
{"question": "What data sources does GuardDuty analyze for threats?", "answer": "GuardDuty analyzes data from independent streams directly from CloudTrail, VPC Flow Logs, DNS query logs, and Amazon EKS.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-04T17:25:47.673790"}}
{"question": "How does GuardDuty manage permissions and what is the benefit of using service-linked roles?", "answer": "GuardDuty manages permissions using service-linked roles, which simplifies the process of enabling the service by avoiding complex configuration. This approach also minimizes the risk of misconfiguration in AWS Identity and Access Management (IAM) permissions or changes in Amazon S3 bucket policies that could affect service operation.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-04T17:25:47.674086"}}
{"question": "How does GuardDuty's operation change when Runtime Monitoring is configured compared to its default operation?", "answer": "When GuardDuty is enabled for the first time, it operates completely independent of AWS resources. However, if GuardDuty Runtime Monitoring is configured to automatically deploy the GuardDuty security agent, it may lead to additional resource utilization and the creation of VPC endpoints in the VPCs used to run the monitored workloads.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-04T17:25:47.674581"}}
{"question": "What happens when you suspend the GuardDuty service?", "answer": "When you suspend the GuardDuty service, it immediately stops analyzing data, but it does not delete your existing findings or configurations.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-04T17:25:51.729988"}}
{"question": "What is the difference between suspending and disabling the GuardDuty service?", "answer": "Suspending the GuardDuty service stops the analysis of data without deleting existing findings or configurations, while disabling the service deletes all remaining data, including existing findings and configurations, before relinquishing service permissions and resetting the service.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-04T17:25:51.730340"}}
{"question": "Can you selectively disable certain capabilities of GuardDuty, and if so, how?", "answer": "Yes, you can selectively disable capabilities like GuardDuty S3 Protection or GuardDuty EKS Protection through the Management Console or via the AWS CLI.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-04T17:25:51.730872"}}
{"question": "What are the primary detection categories used by GuardDuty?", "answer": "The primary detection categories used by GuardDuty include Reconnaissance, Instance compromise, Account compromise, Bucket compromise, Malware, and Container compromise.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T17:25:55.712966"}}
{"question": "How does GuardDuty maintain its detection algorithms?", "answer": "GuardDuty maintains its detection algorithms by continually improving them through the work of GuardDuty engineers.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T17:25:55.713303"}}
{"question": "What is the difference between the detection of instance compromise and bucket compromise in GuardDuty?", "answer": "Instance compromise detection involves identifying activities such as cryptocurrency mining, malware using domain generation algorithms, and unusual network traffic, while bucket compromise detection focuses on suspicious data access patterns, unusual Amazon S3 API activity, and unauthorized access from known malicious IP addresses.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T17:25:55.713833"}}
{"question": "What is GuardDuty?", "answer": "GuardDuty is a threat detection service that continuously monitors for malicious or unauthorized behavior to help protect AWS accounts and workloads.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-04T17:25:59.963561"}}
{"question": "Why is it important to understand the different finding types in GuardDuty?", "answer": "Understanding the different finding types in GuardDuty is important because it helps users identify and respond to various security threats effectively, ensuring better protection of AWS resources.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-04T17:25:59.963916"}}
{"question": "How do the different finding types in GuardDuty relate to threat detection?", "answer": "The different finding types in GuardDuty are specifically designed to categorize various types of threats, allowing users to understand the nature of the potential security incidents and prioritize their responses accordingly.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-04T17:25:59.964309"}}
{"question": "What types of threat intelligence does GuardDuty utilize?", "answer": "GuardDuty utilizes threat intelligence made up of IP addresses and domains known to be used by attackers, which is provided by AWS and third-party providers such as Proofpoint and CrowdStrike. These threat intelligence feeds are pre-integrated and continuously updated in GuardDuty at no additional cost.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-04T17:26:05.562648"}}
{"question": "How does GuardDuty enhance the actionability of security findings?", "answer": "GuardDuty enhances the actionability of security findings by delivering detailed findings to the GuardDuty console and EventBridge when a potential threat is detected. These findings include the category, resource affected, and associated metadata such as severity level, which makes them more easily integrated into existing event management or workflow systems.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-04T17:26:05.562962"}}
{"question": "How does the retention of GuardDuty findings compare with long-term storage options?", "answer": "GuardDuty retains security findings for 90 days, after which the findings are discarded. However, to retain findings for longer than 90 days, you can enable EventBridge to automatically push findings to an Amazon S3 bucket or another data store for long-term retention.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-04T17:26:05.563397"}}
{"question": "What is the purpose of the feedback mechanisms built into GuardDuty?", "answer": "The feedback mechanisms, such as the thumbs-up and thumbs-down in each security finding found in the GuardDuty user interface, allow users to provide feedback that might be incorporated into future iterations of GuardDuty detections.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T17:26:12.796711"}}
{"question": "How does GuardDuty handle the development and maintenance of custom rule sets?", "answer": "GuardDuty removes the heavy lifting and complexity of developing and maintaining your own custom rule sets by continually adding new detections based on customer feedback and research from AWS security engineers and the GuardDuty engineering team. However, customers can still configure customizations, such as adding their own threat lists and trusted IP address lists.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T17:26:12.797050"}}
{"question": "What happens when a new account enables GuardDuty through the console or API regarding S3 Protection?", "answer": "When a new account enables GuardDuty through the console or API, S3 Protection is turned on by default. However, if the account is created using the AWS Organizations auto-enable feature, S3 Protection will not be turned on unless the auto-enable for S3 option is specifically activated.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T17:26:12.797537"}}
{"question": "What feature of GuardDuty monitors Amazon EKS cluster control plane activity?", "answer": "The feature of GuardDuty that monitors Amazon EKS cluster control plane activity is called GuardDuty EKS Protection. It analyzes Amazon EKS audit logs to conduct this monitoring.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-04T17:26:18.499354"}}
{"question": "How does GuardDuty EKS Protection utilize Amazon EKS audit logs for security monitoring?", "answer": "GuardDuty EKS Protection utilizes Amazon EKS audit logs by analyzing them to monitor Amazon EKS API activity continuously. It applies proven threat intelligence and anomaly detection to identify malicious activity or configuration changes that could expose the Amazon EKS cluster to unauthorized access.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-04T17:26:18.499720"}}
{"question": "What is the difference between how GuardDuty accesses Amazon EKS audit logs and how these logs are stored?", "answer": "GuardDuty has direct access to Amazon EKS audit logs for analysis and does not store them. In contrast, users do not need to enable or pay for these logs to be shared with GuardDuty, as it only uses them for analysis.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-04T17:26:18.500223"}}
{"question": "What is the duration of the free trial for GuardDuty EKS Protection?", "answer": "The duration of the free trial for GuardDuty EKS Protection is 30 days for each new GuardDuty account in each Region.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-04T17:26:23.514832"}}
{"question": "How can GuardDuty EKS Protection be activated across multiple accounts?", "answer": "GuardDuty EKS Protection can be activated across multiple accounts by using the GuardDuty administrator account. You can activate it from the GuardDuty EKS Protection page, which will enable continuous monitoring for Amazon EKS in all individual member accounts.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-04T17:26:23.515184"}}
{"question": "How does the activation of GuardDuty EKS Protection differ for new accounts created through the console versus those created using the AWS Organizations auto-enable feature?", "answer": "For new accounts that turn on GuardDuty through the console or API, GuardDuty EKS Protection is turned on by default. However, for new GuardDuty accounts created using the AWS Organizations auto-enable feature, you need to explicitly enable the auto-enable for EKS Protection option.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-04T17:26:23.515717"}}
{"question": "How can I re-enable GuardDuty EKS Protection if I previously disabled it?", "answer": "You can re-enable GuardDuty EKS Protection in the console or by using the API. In the GuardDuty console, you can enable it for your accounts on the GuardDuty EKS Protection console page.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-04T17:26:29.615678"}}
{"question": "What happens when GuardDuty EKS Protection is enabled for an account?", "answer": "Once GuardDuty EKS Protection is enabled for an account, all existing and future Amazon EKS clusters in the account will be monitored for threats automatically, and no manual configuration is required on your Amazon EKS clusters.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-04T17:26:29.615888"}}
{"question": "How does enabling GuardDuty EKS Protection in a multi-account configuration differ from enabling it in a single account?", "answer": "In a multi-account configuration, enabling GuardDuty EKS Protection can be done with a single click on the GuardDuty administrator account's console page, which will enable threat detection for Amazon EKS in all individual member accounts. In contrast, for a single account, you must enable GuardDuty EKS Protection individually for that specific account.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-04T17:26:29.617146"}}
{"question": "What does GuardDuty Runtime Monitoring do?", "answer": "GuardDuty Runtime Monitoring uses a lightweight, fully managed security agent to add visibility into runtime activity such as file access, process execution, and network connections at the pod or instance level for covered resources. It collects runtime events and delivers them to GuardDuty for security analytics processing, helping to identify potentially compromised instances or containers and detect attempts to escalate privileges.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-04T17:26:37.365228"}}
{"question": "Why is the GuardDuty Runtime Monitoring feature important for AWS security?", "answer": "GuardDuty Runtime Monitoring is important for AWS security because it provides visibility into runtime activities that could indicate security threats. By detecting compromised instances or containers and identifying privilege escalation attempts, it helps organizations respond to potential security incidents proactively and maintain the integrity of their AWS environment.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-04T17:26:37.365597"}}
{"question": "How does the activation of GuardDuty Runtime Monitoring differ from other GuardDuty features?", "answer": "The activation of GuardDuty Runtime Monitoring differs from other GuardDuty features in that it is the only protection plan not enabled by default when GuardDuty is first turned on. While other features may be automatically activated, Runtime Monitoring must be specifically activated from the GuardDuty console or through the API, and new GuardDuty accounts created with the AWS Organizations auto-enable feature will not have it turned on unless the Auto-enable for Runtime Monitoring option is selected.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-04T17:26:37.366117"}}
{"question": "How can you update to the latest GuardDuty agent version for Amazon ECS on Amazon EC2?", "answer": "You can update to the latest GuardDuty agent version for Amazon ECS on Amazon EC2 by updating to the latest ECS optimized AMI or ECS agent.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-04T17:26:43.517571"}}
{"question": "What happens when you enable Amazon ECS Runtime Monitoring in relation to GuardDuty?", "answer": "When you enable Amazon ECS Runtime Monitoring, GuardDuty becomes ready to consume the runtime events from a task, which runs within the Amazon ECS clusters on AWS Fargate instances.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-04T17:26:43.517919"}}
{"question": "What is the difference in updating the GuardDuty agent for Amazon ECS on Fargate compared to Amazon ECS on EC2?", "answer": "For Amazon ECS on Fargate, the Fargate agent automatically pulls the latest GuardDuty agent version, whereas for Amazon ECS on EC2, you need to update to the latest ECS optimized AMI or ECS agent manually.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-04T17:26:43.518338"}}
{"question": "What types of clusters can be monitored using GuardDuty Runtime Monitoring?", "answer": "GuardDuty Runtime Monitoring allows you to monitor Amazon EKS clusters and Amazon ECS clusters for threat detection.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-04T17:26:51.193980"}}
{"question": "How does GuardDuty Runtime Monitoring handle resource utilization when enabled?", "answer": "The GuardDuty security agent, which is part of GuardDuty Runtime Monitoring, introduces some resource utilization overhead. However, it is designed to be lightweight and is monitored by GuardDuty to minimize its impact on covered workloads. Exact resource utilization metrics can be monitored in Amazon CloudWatch.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-04T17:26:51.194343"}}
{"question": "What are the differences in removing the GuardDuty security agent if it was deployed automatically versus manually?", "answer": "If the GuardDuty security agent was deployed automatically by GuardDuty, it will be removed automatically when GuardDuty Runtime Monitoring is disabled. However, if the agent was deployed manually, the user must manually remove it, and any VPC endpoints created must also be manually deleted.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-04T17:26:51.194844"}}
{"question": "What types of malicious software can GuardDuty detect during its malware scans of Amazon EBS volumes?", "answer": "GuardDuty can detect trojans, worms, crypto miners, rootkits, bots, and more during its malware scans of Amazon EBS volumes.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-04T17:26:57.704806"}}
{"question": "How does GuardDuty handle newly uploaded files in an S3 bucket configured for malware protection?", "answer": "Once a bucket is configured for malware protection, GuardDuty automatically scans newly uploaded files. If malware is detected, it generates an Amazon EventBridge notification with details about the malware, allowing for integration with existing security event management or workflow systems.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-04T17:26:57.705035"}}
{"question": "How does malware protection for Amazon EBS volumes differ from that for S3 buckets regarding the types of files scanned?", "answer": "Malware protection for Amazon EBS volumes scans files attached to Amazon EC2 instances, while malware protection for S3 buckets scans files belonging to various synchronous S3 storage classes, including formats like executables, .pdf files, archives, and more. Both systems use GuardDutys malware scanning engine but focus on different storage types.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-04T17:26:57.705157"}}
{"question": "What types of threats does Malware Protection scan for?", "answer": "Malware Protection scans for threats such as trojans, worms, crypto miners, rootkits, and bots, which might be used to compromise workloads, repurpose resources for malicious use, and gain unauthorized access to data.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-04T17:27:03.552089"}}
{"question": "How does GuardDuty Malware Protection scan for malware without using security agents?", "answer": "GuardDuty Malware Protection creates and scans a replica based on the snapshot of Amazon EBS volumes attached to the potentially infected Amazon EC2 instance or container workload. It uses permissions granted through a service-linked role to create an encrypted volume replica in the GuardDuty service account from that snapshot, which remains in the user's account.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-04T17:27:03.552442"}}
{"question": "What is the relationship between GuardDuty and the Malware Protection feature?", "answer": "The Malware Protection feature is part of GuardDuty, which is an AWS service that utilizes intelligence from integrated internal and external sources. GuardDuty facilitates the scanning and protection processes, including creating volume replicas and scanning objects in Amazon S3.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-04T17:27:03.552964"}}
{"question": "What is the duration of the free trial for GuardDuty, and what feature does it include?", "answer": "Each new GuardDuty account in each Region receives a 30-day free trial of GuardDuty, which includes the Malware Protection feature for GuardDuty-initiated scanning of EBS data volumes only.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-04T17:27:10.825049"}}
{"question": "How can Malware Protection be enabled in GuardDuty, and what is the process for a multi-account configuration?", "answer": "Malware Protection can be enabled in the GuardDuty console by going to the Malware Protection page or using the API. In a GuardDuty multi-account configuration, the feature can be enabled across the entire organization through the GuardDuty administrator accounts Malware Protection console page, which will monitor malware in all individual member accounts.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-04T17:27:10.825405"}}
{"question": "How does the Malware Protection for EBS data volumes differ from that for Amazon S3 according to the context?", "answer": "The Malware Protection feature is available for GuardDuty-initiated scanning of EBS data volumes and includes a free trial, while there is no free trial for GuardDuty Malware Protection for Amazon S3. Additionally, integrating malware scanning for S3 involves specific steps such as setting up bucket protection configurations and using EventBridge for scan metrics, which is not mentioned for EBS data volumes.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-04T17:27:10.825608"}}
{"question": "What happens to newly created GuardDuty accounts regarding Malware Protection?", "answer": "Any new account that enables GuardDuty using the console or API will have GuardDuty Malware Protection enabled by default for EBS volumes scanning. However, for new GuardDuty accounts created using the AWS Organizations auto-enable feature, you need to explicitly enable the auto-enable for Malware Protection option.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-04T17:27:18.290304"}}
{"question": "How does GuardDuty Malware Protection ensure that it does not affect workload performance?", "answer": "GuardDuty Malware Protection is designed to not affect the performance of your workloads. For example, Amazon EBS volume snapshots created for malware analysis can only be generated once in a 24-hour period, and GuardDuty retains the encrypted replicas and snapshots for a few minutes after it completes a scan. Additionally, it uses GuardDuty compute resources for malware scanning instead of customer compute resources.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-04T17:27:18.290594"}}
{"question": "How does the management of GuardDuty Malware Protection differ between single accounts and multiple accounts using AWS Organizations?", "answer": "For single accounts, GuardDuty Malware Protection can be enabled or disabled directly in the console or using the API. In contrast, for multiple accounts managed through AWS Organizations, the administrator account can manage Malware Protection settings across all member accounts, ensuring full coverage of the feature throughout the organization.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-04T17:27:18.290785"}}
{"question": "What does GuardDuty Malware Protection scan in relation to Amazon EC2 instances?", "answer": "GuardDuty Malware Protection scans a replica based on the snapshot of Amazon EBS volumes attached to the potentially infected Amazon EC2 instance or container workload in your account.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-04T17:27:23.979672"}}
{"question": "How does GuardDuty handle encryption for replica Amazon EBS volumes based on customer managed keys?", "answer": "If your Amazon EBS volumes are encrypted with a customer managed key, you have the option to share your AWS Key Management Service (KMS) key with GuardDuty, and the service uses the same key to encrypt the replica Amazon EBS volume.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-04T17:27:23.979934"}}
{"question": "How does GuardDuty's handling of encrypted and unencrypted Amazon EBS volumes differ?", "answer": "For encrypted Amazon EBS volumes, GuardDuty uses the customer managed key provided through AWS Key Management Service (KMS) to encrypt the replica Amazon EBS volume. In contrast, for unencrypted Amazon EBS volumes, GuardDuty uses its own key to encrypt the replica Amazon EBS volume.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-04T17:27:23.980075"}}
{"question": "How long is the free trial period for new GuardDuty accounts?", "answer": "Each new GuardDuty account receives a 30-day free trial of GuardDuty, including the Malware Protection feature.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-04T17:27:28.546019"}}
{"question": "What factors influence the pricing for malware scanning of EBS volumes in GuardDuty?", "answer": "Pricing for malware scanning of EBS volumes is based on the GB of data scanned in a volume. You can also customize scan options to include or exclude specific Amazon EC2 instances using tags, which helps control the costs.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-04T17:27:28.546393"}}
{"question": "How does the scanning frequency differ between EBS and S3 in GuardDuty?", "answer": "GuardDuty will only scan an Amazon EC2 instance once every 24 hours, scanning only for the first relevant finding if multiple findings occur within that time. In contrast, for S3 buckets, GuardDuty scans only newly-uploaded files in designated buckets and does not scan existing files or files in buckets not configured for malware scanning.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-04T17:27:28.546602"}}
{"question": "How long does GuardDuty Malware Protection retain each replica Amazon EBS volume after a scan?", "answer": "GuardDuty Malware Protection retains each replica Amazon EBS volume it generates and scans for up to 24 hours by default. However, it may retain the volume for up to seven days if there is a service outage or connection problem that interferes with the malware scan.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-04T17:27:33.713735"}}
{"question": "What happens if GuardDuty generates multiple findings within 24 hours?", "answer": "If GuardDuty generates multiple findings that qualify for a malware scan within 24 hours of the last scan, it will not initiate additional scans. GuardDuty only scans once every 24 hours, so even with multiple findings, no new scans are started until 24 hours have passed since the last scan.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-04T17:27:33.714113"}}
{"question": "How does GuardDuty S3 Malware Protection differ from the base GuardDuty service?", "answer": "GuardDuty S3 Malware Protection allows application owners to set up Malware Protection for their S3 buckets even when base GuardDuty is not enabled for the account. In contrast, base GuardDuty includes default monitoring of foundational sources such as AWS CloudTrail management events, VPC Flow Logs, and DNS query logs.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-04T17:27:33.714557"}}
{"question": "How can GuardDuty RDS Protection be activated?", "answer": "GuardDuty RDS Protection can be activated with a single action in the GuardDuty console on the RDS Protection page, or through the API.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-04T17:27:38.269058"}}
{"question": "What is the purpose of GuardDuty RDS Protection?", "answer": "The purpose of GuardDuty RDS Protection is to analyze and profile login attempts to existing and new Amazon Aurora databases, identifying suspicious behaviors or attempts by known malicious actors. When such activities are detected, it issues actionable security findings to various consoles and services for further action.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-04T17:27:38.269394"}}
{"question": "How does the activation of GuardDuty RDS Protection differ between current and new GuardDuty accounts?", "answer": "Current GuardDuty accounts can activate RDS Protection manually from the GuardDuty console or through the API. In contrast, any new accounts that activate GuardDuty through the console or API will have RDS Protection turned on by default, unless the AWS Organizations auto-enable feature is used without enabling the auto-enable for RDS option.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-04T17:27:38.269912"}}
{"question": "How can the GuardDuty Lambda Protection feature be activated for current GuardDuty accounts?", "answer": "The GuardDuty Lambda Protection feature can be activated from the GuardDuty console on the Lambda Protection page, or through the API.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-04T17:27:43.183353"}}
{"question": "What advantages does Amazon GuardDuty's Extended Threat Detection provide for AWS users?", "answer": "The Extended Threat Detection capabilities provide faster threat detection and response by automatically correlating disparate threat signals, improved visibility into attack sequences that span multiple resources and accounts, and streamlined response with prescriptive remediation recommendations based on AWS best practices and MITRE ATT&CK tactic and technique mappings.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-04T17:27:43.183668"}}
{"question": "How does the detection of attack sequences differ between GuardDuty's standard detection and its Extended Threat Detection?", "answer": "GuardDuty's standard detection may identify individual threats, while Extended Threat Detection is designed to recognize complex, multi-stage attack sequences, such as credential compromise followed by data exfiltration, and represents them as a single, high-priority finding with detailed summaries and remediation recommendations.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-04T17:27:43.184114"}}
{"question": "Do I need to enable all GuardDuty protection plans to benefit from Extended Threat Detection?", "answer": "No, you do not need to enable all GuardDuty protection plans to benefit from Extended Threat Detection. However, enabling more GuardDuty protection plans will increase the breadth of security signals available, allowing for more comprehensive threat detection and analysis.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T17:27:49.000393"}}
{"question": "What is the significance of enabling GuardDuty S3 Protection in relation to Extended Threat Detection?", "answer": "Enabling GuardDuty S3 Protection is significant because it allows GuardDuty to identify data compromises that can be part of a ransomware event. It enhances detection by adding indications of potential data exfiltration activity to attack sequences, providing a more comprehensive view of potential threats targeting S3 resources.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T17:27:49.000733"}}
{"question": "How does enabling GuardDuty S3 Protection affect the detection capabilities compared to only having foundational threat detection enabled?", "answer": "When only foundational threat detection is enabled, GuardDuty can identify a potential attack sequence starting with IAM privilege discovery and progressing to S3 control plane alterations. However, with S3 Protection enabled, GuardDuty enhances this detection by adding the ability to identify potential data exfiltration activities after S3 bucket access becomes more permissive, resulting in a more comprehensive attack sequence detection.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T17:27:49.000948"}}
{"question": "What types of attack sequences can GuardDuty detect with S3 Protection?", "answer": "GuardDuty can detect multi-stage attack sequences involving Amazon S3 resources, including scenarios such as IAM privilege discovery activities on S3 APIs followed by S3 bucket policy changes to increase permissions, suspicious API calls to list or modify S3 buckets followed by anomalous data access or transfer activities, attempts to exploit misconfigurations in S3 bucket policies to gain unauthorized access, and initial reconnaissance of S3 resources followed by attempts to exfiltrate data.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-04T17:27:56.329480"}}
{"question": "How does enabling EKS Protection enhance security for Amazon EKS clusters?", "answer": "Enabling EKS Protection for Extended Threat Detection allows GuardDuty to correlate security signals across Amazon EKS audit logs, runtime behaviors, and AWS API activity. This enables the detection of sophisticated attack sequences, including multi-stage attacks such as initial container exploitation followed by privilege escalation, and helps automatically identify potential compromises to EKS clusters, pods, and associated AWS resources.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-04T17:27:56.329790"}}
{"question": "What is the difference between EKS Protection and Runtime Monitoring in GuardDuty?", "answer": "EKS Protection monitors control plane activities, while Runtime Monitoring observes behaviors within containers. Together, they provide a holistic view of Amazon EKS clusters, allowing GuardDuty to detect complex attack patterns, such as compromise of containers running vulnerable web applications and unauthorized access through misconfigured credentials.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-04T17:27:56.329967"}}
{"question": "What is AWS HealthLake and what does it enable healthcare companies to do?", "answer": "AWS HealthLake is a HIPAA-eligible service that enables healthcare and life sciences companies to securely store and transform their data into a queryable format, and further analyze this data in the cloud at petabyte scale.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-04T17:28:01.145918"}}
{"question": "How does AWS HealthLake utilize machine learning in its services?", "answer": "AWS HealthLake uses machine learning (ML) models that enable customers to understand and extract meaningful medical information from raw data, such as medications, procedures, and diagnoses.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-04T17:28:01.146401"}}
{"question": "In what regions is AWS HealthLake available?", "answer": "AWS HealthLake is available in the US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Europe West (London), Europe (Ireland), and Asia Pacific SouthEast (Sydney) regions.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-04T17:28:01.146660"}}
{"question": "What format does AWS HealthLake currently ingest data in?", "answer": "AWS HealthLake currently ingests data in FHIR R4 format.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T17:28:05.777935"}}
{"question": "How does AWS HealthLake enable developers and data scientists to utilize machine learning?", "answer": "AWS HealthLake integrates with ML services like Amazon SageMaker, allowing developers and data scientists to build, train, and deploy their own predictive analytics using machine learning models. For instance, they can build disease predictive models using Amazon SageMaker with AWS HealthLake normalized data.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T17:28:05.778287"}}
{"question": "What are the key features included in the HealthLake Advanced tier compared to the standard tier?", "answer": "The key features included in the HealthLake Advanced tier are standard resource validation, SMART on FHIR authorization, and Bulk data FHIR API export capabilities. The context does not provide details about the features of the standard tier for comparison.", "question_type": "comparison", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-04T17:28:05.778498"}}
{"question": "What security standards does AWS HealthLake meet to protect patients' sensitive health data?", "answer": "AWS HealthLake meets HIPAA eligibility and rigorous security and access control standards to protect patients' sensitive health data and ensure regulatory compliance.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-04T17:28:12.684702"}}
{"question": "How does AWS HealthLake handle data deletion according to the FHIR specification?", "answer": "According to the FHIR specification, when a customer deletes a piece of data in AWS HealthLake, it is only hidden from analysis and results; the data is not actually deleted from the service but is versioned instead.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-04T17:28:12.684920"}}
{"question": "What is the relationship between AWS HealthLake, Glue, and Lake Formation?", "answer": "AWS HealthLake uses Lake Formation in conjunction with Glue and Resource Access Manager (RAM) to provide a managed experience, where the customers Glue catalog is shared with their account. This allows AWS HealthLake to transform FHIR data into a format that can be queried using Athena, with tables created as FHIR resource types owned by AWS HealthLake service accounts and shared with customer accounts.", "question_type": "comparison", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-04T17:28:12.685058"}}
{"question": "What is the primary function of AWS Identity and Access Management (IAM)?", "answer": "The primary function of AWS Identity and Access Management (IAM) is to provide fine-grained access control across all of AWS. IAM allows you to control access to services and resources under specific conditions and manage permissions to ensure least privilege.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T17:28:18.595485"}}
{"question": "What does the term 'granting least privilege' mean in the context of IAM?", "answer": "'Granting least privilege' in the context of IAM means setting permissions to allow only the permissions required to perform a specific task. This involves defining actions that can be taken on specific resources under specific conditions.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T17:28:18.595752"}}
{"question": "How do AWS managed policies differ from customer managed policies in IAM?", "answer": "AWS managed policies provide predefined permissions that help users get started quickly and are available in all AWS accounts, while customer managed policies are specific to the user's use cases and allow for further reduction of permissions based on needs.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T17:28:18.595930"}}
{"question": "What do IAM roles rely on for access to AWS?", "answer": "IAM roles rely on temporary security credentials for access to AWS.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-04T17:28:23.417671"}}
{"question": "Why is it recommended to use IAM roles instead of IAM users for certain access scenarios?", "answer": "It is recommended to use IAM roles instead of IAM users for certain access scenarios because IAM roles rely on short-term credentials, which is a security best practice, and they can be assumed by trusted entities like AWS services or identity providers, providing a more flexible approach to managing access.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-04T17:28:23.417930"}}
{"question": "How do IAM roles differ from IAM users in terms of credential types?", "answer": "IAM roles use temporary security credentials, while IAM users have long-term credentials. This difference highlights that IAM roles are designed for short-term access without being tied to a specific user or group, whereas IAM users are typically used for workforce users with persistent access needs.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-04T17:28:23.418126"}}
{"question": "What are AWS managed policies and how do they differ from customer managed policies?", "answer": "AWS managed policies are owned and updated by AWS and cover common use cases, making them available in all AWS accounts. In contrast, customer managed policies are created by users to define specific permissions tailored to their use cases and resources. This allows users to refine permissions to achieve least-privilege access, whereas AWS managed policies provide broader permissions for general use.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-04T17:28:29.679766"}}
{"question": "What is the purpose of resource-based policies in AWS?", "answer": "Resource-based policies allow you to grant direct, cross-account access to AWS resources, such as Amazon S3 buckets. These policies are attached to the resources themselves, enabling them to define access permissions that can be shared with other AWS accounts.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-04T17:28:29.680161"}}
{"question": "How can permissions be assigned to a role or resource in AWS?", "answer": "Permissions can be assigned to a role or resource in AWS by creating a policy, which is a JSON document that defines specific permissions. This document includes statements that grant or deny access to particular service actions, resources, and conditions. Once created, the policy can be attached to one or more AWS roles to grant the necessary permissions.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-04T17:28:29.680401"}}
{"question": "What are resource-based policies in AWS?", "answer": "Resource-based policies are permissions policies that are attached to resources in AWS. They allow you to define who has access to a resource and which actions they can perform with it. Examples of resources to which you can attach these policies include Amazon S3 buckets, Amazon SQS queues, VPC endpoints, and AWS Key Management Service (AWS KMS) encryption keys.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-04T17:28:36.743289"}}
{"question": "How does RBAC differ from ABAC in AWS?", "answer": "RBAC (Role-Based Access Control) assigns permissions based on a person's job function by defining IAM roles with specific permissions. Users can assume these roles to perform their job functions, and access can be audited by examining the IAM roles and their attached permissions. In contrast, ABAC (Attribute-Based Access Control) defines permissions based on attributes called tags. ABAC allows for fine-grained permissions to specific resources by matching the tags on roles or sessions with those on the resources, making it more adaptable in dynamic environments.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-04T17:28:36.743626"}}
{"question": "What is the best practice for granting access in AWS?", "answer": "The best practice for granting access in AWS is known as granting least privilege. This means that you should only grant access to the specific service actions and resources required for each task. Additionally, when employees add new resources, it is important to update policies to allow access to those new resources.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-04T17:28:36.743863"}}
{"question": "What is the first step to grant access using ABAC in AWS?", "answer": "The first step to grant access using ABAC in AWS is to define the tag keys and values you want to use for access control.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-04T17:28:40.897857"}}
{"question": "How do Deny statements in IAM policies interact with Allow statements?", "answer": "Deny statements in IAM policies always prevail over Allow statements. If a Deny statement applies to an access request, that request is denied regardless of any Allow statements.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-04T17:28:40.898180"}}
{"question": "How do SCPs differ from IAM policies in terms of granting permissions?", "answer": "SCPs do not grant permissions; instead, they allow or deny access to AWS services for individual AWS accounts or groups of accounts within an organizational unit. In contrast, IAM policies are used to grant permissions.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-04T17:28:40.898400"}}
{"question": "What is the goal of refining permissions according to AWS?", "answer": "The goal of refining permissions is to grant only the permissions required with the aim of achieving least-privilege permissions.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-04T17:28:45.138903"}}
{"question": "What are AWS managed policies and how do they assist users?", "answer": "AWS managed policies are created and administered by AWS, and they include permissions for common use cases. They assist users by providing a starting point for granting permissions as they explore and experiment.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-04T17:28:45.139241"}}
{"question": "How do customer managed policies differ from AWS managed policies in terms of permission definition?", "answer": "Customer managed policies are defined by the user and allow for more specific permissions compared to AWS managed policies, which are broader and created by AWS for common use cases.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-04T17:28:45.139459"}}
{"question": "What does IAM Access Analyzer do for policy generation?", "answer": "IAM Access Analyzer generates a fine-grained policy based on the access activity captured in your logs. This allows you to generate policies that grant only the required permissions to operate your application after you build and run it.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-04T17:28:51.860909"}}
{"question": "How does IAM Access Analyzer assist in policy validation?", "answer": "IAM Access Analyzer assists in policy validation by using more than 100 policy checks to guide you in authoring and validating secure and functional policies. These checks can be applied while creating new policies or validating existing ones. Additionally, custom policy checks, which are a paid feature, help ensure that developer-authored policies comply with specified security standards before deployments.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-04T17:28:51.861255"}}
{"question": "What types of findings does IAM Access Analyzer provide regarding access permissions?", "answer": "IAM Access Analyzer provides public and cross-account findings that help verify and refine access allowed by resource policies from outside your AWS organization or account. It also identifies internal findings, which reveal who within your AWS organization has access to critical AWS resources. Furthermore, it continuously analyzes accounts to identify unused access, highlighting unused roles, access keys, and passwords for IAM users.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-04T17:28:51.861495"}}
{"question": "What is the recommended action for IAM users, roles, and permissions that are no longer required in an AWS account?", "answer": "The recommended action is to remove IAM users, roles, and permissions that are no longer required with the goal of achieving least-privilege access.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-04T17:28:57.639858"}}
{"question": "How does the IAM Access Analyzer assist security teams in managing IAM roles and users?", "answer": "The IAM Access Analyzer continuously analyzes accounts to identify unused access and creates a centralized dashboard with findings. Security teams can use this dashboard to review findings and prioritize which accounts to review based on the volume of findings, highlighting unused roles, unused access keys for IAM users, and unused passwords for IAM users.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-04T17:28:57.640218"}}
{"question": "What is the difference between the IAM Access Analyzer and the IAM policy simulator?", "answer": "The IAM Access Analyzer identifies unused access and provides a dashboard for security teams to review findings related to IAM roles and users, while the IAM policy simulator evaluates policies and determines the effective permissions for specified actions, helping to test and troubleshoot identity-based and resource-based policies.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-04T17:28:57.640429"}}
{"question": "What does IAM Access Analyzer custom policy checks validate?", "answer": "IAM Access Analyzer custom policy checks validate that your IAM policies adhere to your security standards before deployments.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-04T17:29:02.100585"}}
{"question": "How do custom policy checks enhance security assurance in IAM policies?", "answer": "Custom policy checks enhance security assurance in IAM policies by using automated reasoning, which provides provable security assurance backed by mathematical proof. This allows security teams to proactively detect nonconformant updates to policies, such as changes that are more permissive than their previous version.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-04T17:29:02.100895"}}
{"question": "What is the relationship between IAM Access Analyzer and unused access in AWS accounts?", "answer": "IAM Access Analyzer simplifies inspecting unused access to guide users toward least privilege by continuously analyzing accounts to identify unused access. It creates a centralized dashboard with findings that highlight unused roles, access keys, and passwords for IAM users, allowing security teams to prioritize reviews based on the volume of findings.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-04T17:29:02.101077"}}
{"question": "What types of resources does Amazon Inspector continually scan for vulnerabilities?", "answer": "Amazon Inspector continually scans Amazon Elastic Compute Cloud (EC2), AWS Lambda functions, and container images in Amazon ECR, as well as resources within continuous integration and continuous delivery (CI/CD) tools.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-04T17:29:06.351220"}}
{"question": "How does Amazon Inspector reduce operational overhead for vulnerability management?", "answer": "Amazon Inspector reduces operational overhead by allowing users to deploy it across all accounts with a single step, thus eliminating the need for extensive deployment and configuration efforts typically associated with vulnerability management solutions.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-04T17:29:06.351546"}}
{"question": "How does the new Amazon Inspector differ from Amazon Inspector Classic in terms of activation?", "answer": "To activate the new Amazon Inspector, users can follow a few steps in the AWS Management Console or use the new Amazon Inspector APIs, whereas Amazon Inspector Classic requires users to deactivate it by deleting all assessment templates in their account.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-04T17:29:06.353009"}}
{"question": "What new feature allows Amazon Inspector to scan container images and Lambda functions?", "answer": "The new Amazon Inspector has been enhanced to support scanning container images residing in Amazon ECR and within CI/CD tools, as well as Lambda functions for software vulnerabilities.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:29:11.828693"}}
{"question": "How does the new Amazon Inspector improve vulnerability management compared to the classic version?", "answer": "The new Amazon Inspector improves vulnerability management by being built for scale without limits on the number of instances or images scanned, supporting multi-account management through AWS Organizations, eliminating the need for a standalone agent by utilizing the AWS Systems Manager Agent, providing automated and continual scanning of resources, calculating a risk score based on up-to-date CVE information, enhancing vulnerability assessment coverage, and offering a software bill of materials (SBOM) export for all monitored resources.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:29:11.829006"}}
{"question": "How does the vulnerability assessment coverage differ between the new Amazon Inspector and Amazon Inspector Classic?", "answer": "The new Amazon Inspector enhances vulnerability assessment coverage by seamlessly scanning EC2 instances and offering the ability to switch between agent-based and agentless scanning, whereas the classic version did not provide this level of flexibility.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:29:11.829240"}}
{"question": "What platforms does the new Amazon Inspector integrate with for scanning code repositories?", "answer": "The new Amazon Inspector integrates natively with GitHub and GitLab for scanning code repositories.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-04T17:35:16.030794"}}
{"question": "What is the primary purpose of using Amazon Inspector in relation to code repositories?", "answer": "The primary purpose of using Amazon Inspector is to rapidly identify and prioritize security vulnerabilities and misconfigurations across your application source code, dependencies, and infrastructure as code (IaC).", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-04T17:35:16.031064"}}
{"question": "How does Amazon Inspector help in managing security across application source code and dependencies compared to infrastructure as code (IaC)?", "answer": "The context does not explicitly compare how Amazon Inspector helps in managing security across application source code and dependencies versus infrastructure as code (IaC). It only states that it helps identify and prioritize security vulnerabilities and misconfigurations across both areas.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-04T17:35:16.031238"}}
{"question": "Can you use both services simultaneously in the same AWS account?", "answer": "Yes, you can use both simultaneously in the same account.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-04T17:35:22.967936"}}
{"question": "What does it mean to use both services simultaneously in an AWS account?", "answer": "Using both services simultaneously in an AWS account means that you can operate and utilize both services at the same time without any restrictions within that single account.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-04T17:35:22.968307"}}
{"question": "What is the relationship between using both services and account restrictions in AWS?", "answer": "The relationship is that there are no restrictions preventing you from using both services at the same time in the same AWS account, meaning they can function independently while coexisting.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-04T17:35:22.968821"}}
{"question": "What types of vulnerabilities does Amazon Inspector identify in container images?", "answer": "Amazon Inspector identifies vulnerabilities in both operating system (OS) packages and programming language packages, such as Python, Java, and Ruby.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-04T17:35:28.477772"}}
{"question": "How does Amazon Inspector differ from Amazon ECR's native container image scanning in terms of vulnerability intelligence provided?", "answer": "Amazon Inspector provides enhanced vulnerability intelligence, including whether an exploit is available for a CVE, fixed in package version remediation guidance, EPSS scores, and malware kits being used to exploit a CVE. In contrast, Amazon ECR's native scanning only provides basic information about a software vulnerability.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-04T17:35:28.478121"}}
{"question": "What scanning frequency options does Amazon Inspector offer compared to Amazon ECR's basic scanning?", "answer": "Amazon Inspector offers both continual scanning and on-push scanning, whereas Amazon ECR's basic scanning offers only on-push scanning.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-04T17:35:28.478642"}}
{"question": "What is the duration of the free trial offered to new Amazon Inspector accounts?", "answer": "New Amazon Inspector accounts are eligible for a 15-day free trial to evaluate the service and estimate its cost.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T17:35:33.373793"}}
{"question": "What types of resources does Amazon Inspector scan during the free trial?", "answer": "During the free trial, Amazon Inspector continually scans eligible Amazon EC2 instances, AWS Lambda functions, and container images pushed to Amazon ECR at no cost.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T17:35:33.374079"}}
{"question": "How does the management of Amazon Inspector differ between a DA account and a regular account within AWS Organizations?", "answer": "The DA account for Amazon Inspector acts as the primary administrator account and can manage and configure Amazon Inspector centrally for all accounts in the AWS organization, whereas a regular account does not have these centralized management capabilities.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T17:35:33.374519"}}
{"question": "Do I need an agent to perform vulnerability scanning on Amazon EC2 instances?", "answer": "No, you dont need an agent for scanning. However, for an agent-based solution, you can use the AWS Systems Manager Agent (SSM Agent).", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:35:39.721292"}}
{"question": "What are the benefits of using the AWS Systems Manager Agent for scanning Amazon EC2 instances?", "answer": "Using the AWS Systems Manager Agent (SSM Agent) for scanning Amazon EC2 instances allows for an agent-based solution and is recommended by Amazon Inspector for successfully scanning these instances for software vulnerabilities. It ensures that the instances are managed by AWS Systems Manager.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:35:39.721632"}}
{"question": "How does agentless scanning differ from using the SSM Agent for vulnerability scanning?", "answer": "Agentless scanning does not require the SSM Agent to be deployed or configured, allowing instances without the agent to be scanned. In contrast, using the SSM Agent is part of an agent-based solution that is recommended for vulnerability scanning of Amazon EC2 instances.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:35:39.722050"}}
{"question": "What triggers rescans for Amazon EC2 instances that use the SSM agent?", "answer": "Rescans for Amazon EC2 instances using the SSM agent are triggered when a new software package is installed or uninstalled on an instance, when a new CVE is published, and after a vulnerable package is updated to confirm there are no additional vulnerabilities.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-7", "source_tokens": 419, "generated_at": "2026-02-04T17:35:48.530909"}}
{"question": "How does Amazon Inspector determine the rescan frequency for Amazon ECR container images?", "answer": "Amazon Inspector determines the rescan frequency for Amazon ECR container images based on the rescan durations configured for the image's last in use date and push date. Automated rescans for eligible container images start when a new CVE affecting an image is published, and the image will continue to be monitored if its push date is less than the configured 'Push date rescan duration' and its last in use date is within the configured 'last in use rescan duration'.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-7", "source_tokens": 419, "generated_at": "2026-02-04T17:35:48.531244"}}
{"question": "How do the scanning processes for Lambda functions compare to those for Amazon EC2 instances?", "answer": "The scanning process for Lambda functions involves an initial assessment upon discovery and continuous reassessment whenever there is an update or a new CVE published. In contrast, Amazon EC2 instances are scanned initially upon discovery and rescanned based on specific triggers such as software package changes or new CVEs, particularly for those using the SSM agent. This shows that while both are initially assessed, Lambda functions are continuously reassessed, whereas EC2 instances have specific conditions that trigger rescans.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-7", "source_tokens": 419, "generated_at": "2026-02-04T17:35:48.531727"}}
{"question": "What is the default rescan duration for container images in Amazon ECR configured for continual scanning?", "answer": "The default rescan duration for container images in Amazon ECR configured for continual scanning is 14 days.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:35:54.027849"}}
{"question": "How does Amazon Inspector determine whether to continue scanning an image after activation?", "answer": "Amazon Inspector continues to scan an image after activation if the image was pushed in the last configured rescan duration for push date and if it has been last in use on a running container at least once within the same configured duration for last in use date.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:35:54.028127"}}
{"question": "What happens to images that haven't been pushed or last used in a running container within the configured 30 days rescan duration?", "answer": "If an image hasnt been pushed or last in use on a running container in the last 30 days, Amazon Inspector will stop monitoring it.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:35:54.028578"}}
{"question": "What are the available rescan duration configurations for image last in use date?", "answer": "The available rescan duration configurations for image last in use date are 14 days, 30 days, 60 days, 90 days, or 180 days.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-04T17:36:00.772152"}}
{"question": "How does Amazon Inspector determine whether to continue scanning an image after activating ECR scanning?", "answer": "Amazon Inspector determines whether to continue scanning an image based on the rescan duration configuration selected and the last push or last in use date of the container image. If the selected rescan duration is 180 days, for example, Amazon Inspector will continue to scan images that were pushed in the last 180 days or have been last in use on a running container at least once in the last 180 days.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-04T17:36:00.772495"}}
{"question": "What happens to an image if it hasn't been pushed or used in a running container in the last 180 days compared to one that has been pushed or used?", "answer": "If an image hasn't been pushed or last in use on a running container in the last 180 days, Amazon Inspector will stop monitoring it. In contrast, if an image has been pushed or used within the last 180 days, it will continue to be monitored and scanned by Amazon Inspector.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-04T17:36:00.773023"}}
{"question": "How can an EC2 instance be excluded from scanning?", "answer": "An EC2 instance can be excluded from scanning by adding a resource tag with the key 'InspectorEc2Exclusion' and an optional value.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-04T17:36:07.065414"}}
{"question": "What is the difference between Lambda standard scanning and Lambda code scanning?", "answer": "Lambda standard scanning provides fundamental security protection against vulnerable dependencies used in the application deployed as Lambda functions and association layers. In contrast, Lambda code scanning offers additional security by scanning custom proprietary application code within a Lambda function for vulnerabilities such as injection flaws, data leaks, weak cryptography, or embedded secrets.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-04T17:36:07.065788"}}
{"question": "Can Amazon Inspector be activated for Lambda vulnerabilities assessments across multiple accounts in an AWS Organization?", "answer": "Yes, in a multi-account structure, you can activate Amazon Inspector for Lambda vulnerabilities assessments for all your accounts within the AWS Organization from the Amazon Inspector console or APIs through the Delegated Administrator (DA) account. Member accounts can also activate Amazon Inspector for their own account if the central security team hasnt already activated it for them.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-04T17:36:07.066321"}}
{"question": "What is the default SSM inventory collection frequency for Amazon Inspector?", "answer": "The default SSM inventory collection frequency for Amazon Inspector is 30 minutes.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T17:36:12.352188"}}
{"question": "How does Amazon Inspector determine the risk score for a finding?", "answer": "Amazon Inspector determines the risk score for a finding by correlating common vulnerabilities and exposures (CVE) information with network reachability results, exploitability data, and social media trends. This contextualized score helps prioritize findings and focus on the most critical findings and vulnerable resources.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T17:36:12.352561"}}
{"question": "What happens to the Amazon Inspector risk score if a CVE is found on an EC2 instance that is not reachable from the internet?", "answer": "If a CVE is found on an EC2 instance that is not reachable from the internet, Amazon Inspector correlates the scan results with the CVE and adjusts the risk score downward. This adjustment reflects that the vulnerability is less likely to be exploited due to the instance's network reachability.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-04T17:36:12.353014"}}
{"question": "What formats can SBOMs be exported in using Amazon Inspector?", "answer": "SBOMs can be exported in multiple formats, specifically CycloneDx or SPDX, using the Amazon Inspector console or through the Amazon Inspector APIs.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-04T17:36:20.582440"}}
{"question": "What is the default scan mode for new Amazon Inspector customers when enabling EC2 scanning?", "answer": "For new Amazon Inspector customers, hybrid scan mode is turned on by default when you enable EC2 scanning.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-04T17:36:20.582793"}}
{"question": "How does agentless scanning differ for existing Amazon Inspector customers using a single account versus those using AWS Organizations?", "answer": "For existing Amazon Inspector customers using a single account, agentless scanning can be enabled by visiting the account management page or using APIs. In contrast, customers using AWS Organizations require their Delegated Admin to either completely migrate the organization to an agentless solution or continue using the SSM agent-based solution exclusively.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-04T17:36:20.583308"}}
{"question": "Who can set up scan mode configuration in a multi-account setup for Amazon Inspector?", "answer": "In a multi-account setup, only delegated admins can set up scan mode configuration for the complete organization.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-04T17:36:26.932033"}}
{"question": "What are the benefits of integrating Amazon Inspector into CI/CD pipelines?", "answer": "Integrating Amazon Inspector into CI/CD pipelines allows application and platform teams to perform assessments of container images and take actions based on the assessment results, such as blocking the pipeline if vulnerabilities are detected. It generates actionable security findings that include vulnerability details, remediation recommendations, and exploitability details, which can be returned to the CI/CD tool in both JSON and CSV formats.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-04T17:36:26.932372"}}
{"question": "How does Amazon Inspector's integration with AWS CloudTrail differ from its integration with Security Hub?", "answer": "Amazon Inspector integrates with AWS CloudTrail for call logging, which tracks API calls made to Amazon Inspector, while it integrates with Security Hub to send findings for a comprehensive view across the organization and services. Essentially, CloudTrail focuses on logging API activities, whereas Security Hub focuses on consolidating security findings.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-04T17:36:26.932861"}}
{"question": "How can you deactivate scanning types in Amazon Inspector?", "answer": "You can deactivate all scanning types, including Amazon EC2 scanning, Amazon ECR container image scanning, and Lambda function scanning, by deactivating the Amazon Inspector service. Alternatively, you can deactivate each scanning type individually for an account.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-04T17:36:33.075427"}}
{"question": "What are the key features provided by Amazon Inspector for application security?", "answer": "Amazon Inspector provides three key features for application security: Static Application Security Testing (SAST), which analyzes application source code for vulnerabilities; Software Composition Analysis (SCA), which evaluates third-party dependencies to identify hidden risks; and Infrastructure as Code (IaC) scanning, which validates infrastructure definitions to prevent misconfigurations before deployment. These features work together to provide a complete view of application security, from code to infrastructure.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-04T17:36:33.075763"}}
{"question": "What is the difference between default scan configuration and general scan configuration in Amazon Inspector?", "answer": "The default scan configuration in Amazon Inspector can automatically be attached to new projects discovered and is embedded into the integration workflow during the connection to your Source Code Management (SCM) platform. In contrast, a general scan configuration is applied only to existing projects that were present at the time of its creation and does not automatically apply to new projects.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-04T17:36:33.076379"}}
{"question": "What types of content can Amazon Kendra search through?", "answer": "Amazon Kendra can search through various types of content including manuals, research reports, FAQs, human resources (HR) documentation, and customer service guides. This information can be stored across different systems such as Amazon Simple Storage Service (S3), Microsoft SharePoint, Salesforce, ServiceNow, RDS databases, or Microsoft OneDrive.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-04T17:36:40.049873"}}
{"question": "How does Amazon Kendra utilize machine learning in its search capabilities?", "answer": "Amazon Kendra utilizes machine learning algorithms to understand the context of the questions posed by users. It then returns the most relevant results, which can either be a precise answer or an entire document, based on the content available across various systems.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-04T17:36:40.050221"}}
{"question": "How does Amazon Kendra compare to other AI services like Amazon Comprehend and Amazon Transcribe in terms of functionality?", "answer": "Amazon Kendra specifically provides ML-powered search capabilities for unstructured data, while other AI services like Amazon Comprehend and Amazon Transcribe are used to pre-process documents, generate searchable text, extract entities, and enrich metadata. Thus, Amazon Kendra focuses on search capabilities, while the other services enhance the content to improve search experiences.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-04T17:36:40.050738"}}
{"question": "What types of questions does Amazon Kendra support?", "answer": "Amazon Kendra supports factoid questions, descriptive questions, and keyword searches. Factoid questions require fact-based answers and can be returned as a single word or phrase. Descriptive questions can be answered with a sentence, passage, or document. Keyword searches may return relevant documents based on intent and scope.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:36:47.065999"}}
{"question": "How does Amazon Kendra handle questions that do not have precise answers in the data?", "answer": "When Amazon Kendra encounters questions that do not have precise answers in the data, it returns a list of the most-relevant documents ranked by its deep learning models.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:36:47.066347"}}
{"question": "How does the implementation of Amazon Kendra using the visual UI editor compare to using the Amazon Kendra API?", "answer": "Using the visual UI editor in Amazon Kendra's Experience Builder requires no code and provides an easy way to get started, while implementing the Amazon Kendra API requires a few lines of code for more precise control. Both methods allow users to deploy Amazon Kendra search after ingesting documents.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-04T17:36:47.066827"}}
{"question": "What types of data formats does Amazon Kendra support?", "answer": "Amazon Kendra supports unstructured and semi-structured data in .html, MS Office formats such as .doc and .ppt, PDF, and text formats.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T17:36:52.199495"}}
{"question": "How does Amazon Kendra keep its index up to date?", "answer": "Amazon Kendra provides two methods for keeping the index up to date: first, it offers connectors that provide scheduling to automatically sync data sources regularly; second, it provides the Amazon Kendra API, which allows users to build their own connectors to send data directly from their data sources via existing ETL jobs or applications.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T17:36:52.199855"}}
{"question": "What is the difference in data encryption options for Amazon Kendra's data at rest?", "answer": "Amazon Kendra offers three choices for encryption keys for data at rest: an AWS-owned KMS key, an AWS-managed KMS key in your account, and a customer-managed KMS key. This allows users to choose the level of control they have over their encryption keys.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T17:36:52.200336"}}
{"question": "What is the primary purpose of the Amazon Kendra GenAI Index?", "answer": "The primary purpose of the Amazon Kendra GenAI Index is to facilitate retrieval-augmented generation (RAG) and intelligent search, helping enterprises build digital assistants and intelligent search experiences more efficiently and effectively.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-04T17:36:58.418438"}}
{"question": "How does the Kendra GenAI Index improve semantic accuracy?", "answer": "The Kendra GenAI Index improves semantic accuracy by integrating vector search and enhanced semantic models, which have been rigorously evaluated across diverse datasets.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-04T17:36:58.418798"}}
{"question": "What are the differences between using Kendra GenAI Index with Q Business and with Bedrock Knowledge Bases?", "answer": "When using Kendra GenAI Index with Q Business, you benefit from a fully managed approach to building a generative AI assistant, which offers a streamlined experience without extensive configuration. In contrast, using the GenAI Index with Bedrock Knowledge Bases provides greater configurability over aspects such as prompt customization, foundational model choice, and orchestration to tailor the solution to your specific needs.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-04T17:36:58.419321"}}
{"question": "What type of database service is Amazon Keyspaces?", "answer": "Amazon Keyspaces is a scalable, highly available, and managed Apache Cassandracompatible database service.", "question_type": "factual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:37:02.877357"}}
{"question": "How does Amazon Keyspaces handle server management compared to traditional database services?", "answer": "Amazon Keyspaces is serverless, meaning you dont have to provision, patch, or manage servers, and you dont have to install, maintain, or operate software, unlike traditional database services that require such management.", "question_type": "conceptual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:37:02.877704"}}
{"question": "In what ways does Amazon Keyspaces differ from traditional Apache Cassandra in terms of server management?", "answer": "Amazon Keyspaces is a managed, serverless offering that eliminates the need to provision, patch, or manage servers, while traditional Apache Cassandra requires users to handle these tasks themselves.", "question_type": "comparison", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:37:02.878210"}}
{"question": "What are the performance metrics provided by Keyspaces for read and write operations?", "answer": "Keyspaces offers consistent single-digit-millisecond, server-side read and write performance.", "question_type": "factual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-04T17:37:08.476359"}}
{"question": "What are the two capacity modes offered by Keyspaces, and how do they differ in terms of payment?", "answer": "Keyspaces offers on-demand and provisioned capacity modes. In on-demand capacity mode, you pay for only the reads and writes that your application actually performs. In provisioned capacity mode, you can optimize the price of throughput if you have predictable application traffic and can forecast capacity requirements in advance.", "question_type": "conceptual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-04T17:37:08.476679"}}
{"question": "How does the on-demand capacity mode of Keyspaces compare with the provisioned capacity mode in terms of usage scenarios?", "answer": "The on-demand capacity mode of Keyspaces is suitable for applications where the read and write demands are unpredictable, as you only pay for the operations performed. In contrast, the provisioned capacity mode is ideal for applications with predictable traffic, allowing you to forecast capacity requirements and optimize throughput costs.", "question_type": "comparison", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-04T17:37:08.477610"}}
{"question": "What types of data can be added to Kinesis Data Streams?", "answer": "You can add various types of data such as clickstreams, application logs, and social media to a Kinesis data stream from hundreds of thousands of sources.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-04T17:37:13.297126"}}
{"question": "How does Kinesis Data Streams ensure high availability and data durability?", "answer": "Kinesis Data Streams ensures high availability and data durability by synchronously replicating data across three Availability Zones.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-04T17:37:13.297437"}}
{"question": "How does the automatic scaling of Kinesis Data Streams compare to using provisioned mode?", "answer": "By default, Kinesis Data Streams scales capacity automatically, which frees users from provisioning and managing capacity. In contrast, users who choose provisioned mode must manually provision and manage throughput on their own.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-04T17:37:13.297848"}}
{"question": "What is the primary function of Kinesis Data Streams?", "answer": "The primary function of Kinesis Data Streams is to rapidly move data off data producers and continuously process that data, which may include transforming it before emitting it to a data store, running real-time metrics and analytics, or deriving more complex data streams for further processing.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-04T17:37:19.577469"}}
{"question": "How does Kinesis Data Streams improve data intake compared to traditional methods?", "answer": "Kinesis Data Streams improves data intake by allowing data producers to push data to a stream immediately upon production, rather than waiting to batch the data. This approach prevents data loss in case of producer failure and enables system and application logs to be continuously added and available for processing within seconds.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-04T17:37:19.577772"}}
{"question": "What are the differences between using Kinesis Data Streams for real-time metrics and reporting versus real-time data analytics?", "answer": "Using Kinesis Data Streams for real-time metrics and reporting focuses on extracting metrics and generating reports as data is streamed in, particularly for system and application logs. In contrast, real-time data analytics involves adding clickstreams to the data stream and running analytics in real time to gain insights from the data much faster, allowing insights to be obtained in minutes instead of hours or days.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-04T17:37:19.578213"}}
{"question": "What are the maximum write and read limits for a shard in Kinesis Data Streams?", "answer": "A shard supports a maximum write limit of 1 MB/second and 1,000 records per second, and a read limit of 2 MB/second.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-04T17:37:23.852519"}}
{"question": "How does the shard limit benefit the performance of Kinesis Data Streams?", "answer": "The shard limits ensure predictable performance, which makes it easy to design and operate a highly reliable data streaming workflow.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-04T17:37:23.852816"}}
{"question": "What roles do producers and consumers play in relation to shards in Kinesis Data Streams?", "answer": "Producers put data records into shards, while consumers get data records from shards. Consumers use shards for parallel data processing and for consuming data in the exact order in which they are stored.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-04T17:37:23.853331"}}
{"question": "What is the purpose of a partition key in a Kinesis data stream?", "answer": "A partition key is used to isolate and route records to different shards of a data stream. It is specified by the data producer when adding data to a Kinesis data stream, allowing records with the same key to be directed to the same shard.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-04T17:37:30.259251"}}
{"question": "How does the capacity mode affect the management and charging of a Kinesis Data Stream?", "answer": "The capacity mode of Kinesis Data Streams determines how capacity is managed and how usage is charged. In provisioned mode, users specify the number of shards and pay an hourly rate for them, while in on-demand mode, AWS manages the shards and users pay only for the actual throughput used. This means on-demand mode automatically adjusts to workload needs as they change.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-04T17:37:30.259597"}}
{"question": "What is the difference between provisioned mode and on-demand mode in Kinesis Data Streams regarding cost structure?", "answer": "In provisioned mode, you pay for the number of shards at an hourly rate, while in on-demand mode, you only pay for the actual throughput used. Provisioned mode requires you to specify the number of shards, whereas on-demand mode allows AWS to manage the necessary throughput without user intervention.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-04T17:37:30.260022"}}
{"question": "What is the primary use case for on-demand mode in Amazon Kinesis Data Streams?", "answer": "On-demand mode is best suited for workloads with unpredictable and highly variable traffic patterns. It is recommended if you prefer AWS to manage capacity on your behalf or if you prefer pay-per-throughput pricing.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-04T17:37:35.111391"}}
{"question": "How does provisioned mode differ from on-demand mode in terms of capacity management?", "answer": "Provisioned mode is best suited for predictable traffic, where capacity requirements are easy to forecast, allowing for fine-grained control over data distribution across shards. In contrast, on-demand mode allows AWS to automatically manage capacity based on traffic patterns.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-04T17:37:35.111751"}}
{"question": "What happens to the shard count when switching between provisioned mode and on-demand mode?", "answer": "The shard count of your data stream remains the same when you switch from provisioned mode to on-demand mode and vice versa. The data stream retains whatever shard count it had before the transition.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-04T17:37:35.112182"}}
{"question": "What are the required parameters for a PutRecord or PutRecords call in Amazon Kinesis?", "answer": "The required parameters for a PutRecord or PutRecords call in Amazon Kinesis are your data blob, partition key, and data stream name.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-04T17:37:41.310828"}}
{"question": "What is the primary advantage of using enhanced fan-out consumers in Kinesis Data Streams?", "answer": "The primary advantage of using enhanced fan-out consumers in Kinesis Data Streams is that each consumer gets its own 2 MB/second allotment of read throughput, allowing multiple consumers to read data from the same stream in parallel without contending for read throughput with other consumers.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-04T17:37:41.311128"}}
{"question": "How do shared fan-out consumers differ from enhanced fan-out consumers in terms of read throughput?", "answer": "Shared fan-out consumers share a shards 2 MB/second of read throughput and have a limit of five transactions per second, while enhanced fan-out consumers receive their own 2 MB/second allotment of read throughput, allowing them to operate independently without sharing resources with other consumers.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-04T17:37:41.311622"}}
{"question": "What is the primary purpose of the SubscribeToShard API?", "answer": "The primary purpose of the SubscribeToShard API is to provide a high-performance streaming service that pushes data from shards to consumers over a persistent connection without requiring a request cycle from the client.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:37:46.538233"}}
{"question": "Why would a user choose to implement enhanced fan-out in Kinesis Data Streams?", "answer": "A user would choose to implement enhanced fan-out if they have, or expect to have, multiple consumers retrieving data from a stream in parallel or if at least one consumer requires the use of the SubscribeToShard API to achieve sub-200 millisecond data delivery speeds between producers and consumers.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:37:46.538578"}}
{"question": "How does the data delivery speed of the SubscribeToShard API compare to that of the GetRecords API?", "answer": "The SubscribeToShard API typically delivers data within 70 milliseconds, which offers approximately 65% faster delivery compared to the GetRecords API.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-04T17:37:46.538985"}}
{"question": "What happens when a data stream in on-demand mode hits a new peak write throughput?", "answer": "When a data stream in on-demand mode hits a new peak write throughput, Kinesis Data Streams automatically scales the streams capacity to accommodate up to double its previous peak write throughput observed in the last 30 days.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-04T17:37:52.510351"}}
{"question": "How does on-demand mode ensure adequate read throughput for consuming applications?", "answer": "On-demand modes aggregate read capacity increases proportionally to write throughput, ensuring that consuming applications always have adequate read throughput to process incoming data in real time. This means you get at least twice the write throughput to read data using the GetRecords API.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-04T17:37:52.510705"}}
{"question": "How does the scaling of read throughput differ between on-demand mode and provisioned mode?", "answer": "In on-demand mode, the aggregate read capacity increases proportionally to write throughput to ensure real-time processing, while in provisioned mode, the throughput is designed to scale without limits by increasing the number of shards within a data stream.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-04T17:37:52.511064"}}
{"question": "How is the throughput of a Kinesis data stream determined?", "answer": "The throughput of a Kinesis data stream is determined by the number of shards within the data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T17:37:57.929780"}}
{"question": "What factors should be considered when estimating the initial number of shards needed for a Kinesis data stream?", "answer": "When estimating the initial number of shards needed for a Kinesis data stream, you should consider the average size of the record written to the data stream in kilobytes, the number of records written per second, and the number of Amazon Kinesis Applications consuming data concurrently and independently from the data stream.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T17:37:57.930135"}}
{"question": "What is the difference between the default shard quota in US Regions and other Regions?", "answer": "The default shard quota is 20,000 shards per stream for the US East (N. Virginia), US West (Oregon), and Europe (Ireland) Regions, while for all other Regions, the default shard quota is either 1,000 or 6,000 shards per stream.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T17:37:57.930577"}}
{"question": "What happens when the capacity limits of a Kinesis data stream are exceeded?", "answer": "When the capacity limits of a Kinesis data stream are exceeded, the put data call will be rejected with a ProvisionedThroughputExceeded exception. This can occur due to either data throughput or the number of PUT records.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-04T17:38:03.801173"}}
{"question": "How should you respond if there is a sustained rise in the data stream's input data rate?", "answer": "If there is a sustained rise in the data stream's input data rate, you should increase the number of shards within your data stream to provide enough capacity for the put data calls to consistently succeed.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-04T17:38:03.801380"}}
{"question": "How do the causes for ProvisionedThroughputExceeded exceptions differ between put data calls and read data calls?", "answer": "Both put data calls and read data calls can exceed capacity limits, resulting in ProvisionedThroughputExceeded exceptions. For put data calls, this can occur due to data throughput or the number of PUT records, while for read data calls, it can occur due to data throughput or the number of read data calls. In both cases, temporary rises can be retried, but sustained rises require increasing the number of shards.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-04T17:38:03.801565"}}
{"question": "What APIs can be used to read data retained for more than seven days in AWS Kinesis Data Streams?", "answer": "You can use the getShardIterator, GetRecords, and SubscribeToShard APIs to read data retained for more than seven days.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-04T17:38:10.414297"}}
{"question": "How do the TimeStamp parameter enhancements in the ListShards API improve data retrieval performance?", "answer": "The TimeStamp filter in the ListShards API allows applications to discover and enumerate shards from a specific point in time for reprocessing data, eliminating the need to start at the trim horizon and thereby improving the performance of reading old data.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-04T17:38:10.414546"}}
{"question": "What is the relationship between stream scaling operations and the total number of shards in AWS Kinesis Data Streams?", "answer": "Stream scaling operations close existing shards and open new child shards, which leads to a linear increase in the total number of shards with a longer retention period and multiple scaling operations. This increase in the shard map necessitates the use of ListShards with the TimeStamp filter and the ChildShards field in GetRecords and SubscribeToShard for efficient shard discovery.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-04T17:38:10.414674"}}
{"question": "What are the two ways to change the throughput of your data stream in Amazon Kinesis?", "answer": "The two ways to change the throughput of your data stream in Amazon Kinesis are by using the UpdateShardCount API or the AWS Management Console to scale the number of shards in a data stream, or by adjusting the number of shards within the data stream through a process called resharding.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-04T17:38:15.488814"}}
{"question": "How does Kinesis Data Streams integrate with Amazon CloudWatch?", "answer": "Kinesis Data Streams integrates with Amazon CloudWatch to allow users to collect, view, and analyze CloudWatch metrics for their data streams and shards within those data streams. This integration helps in monitoring key operational and performance metrics such as throughput of data input and output.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-04T17:38:15.489056"}}
{"question": "What is the difference between stream-level metrics and shard-level metrics in terms of cost?", "answer": "Stream-level metrics in Amazon Kinesis Data Streams are free of charge, while all enabled shard-level metrics incur charges according to Amazon CloudWatch pricing.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-04T17:38:15.489226"}}
{"question": "What service does Kinesis Data Streams integrate with for recording AWS API calls?", "answer": "Kinesis Data Streams integrates with Amazon CloudTrail, a service that records AWS API calls for your account and delivers log files to you.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-04T17:38:22.046184"}}
{"question": "How do tags help in managing Kinesis Data Streams resources?", "answer": "Tags are user-defined labels expressed as a key-value pair that help organize AWS resources. In the context of Kinesis Data Streams, you can tag your streams and enhanced fan-out consumers to categorize and track costs based on cost centers, making resource and cost management easier.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-04T17:38:22.046840"}}
{"question": "What is the relationship between AWS PrivateLink and VPC Endpoints in the context of Kinesis Data Streams?", "answer": "AWS PrivateLink powers the latest generation of VPC Endpoints used by Kinesis Data Streams, enabling private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. VPC Endpoints allow private access to Kinesis Data Streams APIs without the need for an internet gateway, NAT gateway, or VPN connection.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-04T17:38:22.047096"}}
{"question": "What are the two options for encrypting data in Kinesis Data Streams?", "answer": "The two options for encrypting data in Kinesis Data Streams are server-side encryption and client-side encryption. Server-side encryption is a fully managed feature that automatically encrypts and decrypts data as it is put and retrieved from a data stream, while client-side encryption involves encrypting and decrypting data on the client side.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-04T17:38:27.972095"}}
{"question": "Why might one choose server-side encryption over client-side encryption?", "answer": "One might choose server-side encryption over client-side encryption for several reasons: it is hard to enforce client-side encryption, there is a desire for a second layer of security on top of client-side encryption, and it is difficult to implement client-side key management schemes.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-04T17:38:27.972389"}}
{"question": "How does server-side encryption differ from client-side encryption in terms of key management?", "answer": "With server-side encryption, the client-side applications do not need to manage KMS keys or cryptographic operations, as encryption and decryption are handled automatically by the Kinesis Data Streams service. In contrast, client-side encryption requires the user to manage the encryption keys and the cryptographic processes themselves.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-04T17:38:27.973003"}}
{"question": "What happens if you use the AWS-managed KMS key for Kinesis regarding encryption?", "answer": "If you use the AWS-managed KMS key for Kinesis (key alias = aws/kinesis), your applications will not be impacted by enabling or disabling encryption with this key.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-04T17:38:33.547173"}}
{"question": "What must be configured before using server-side encryption with a custom KMS key in Kinesis?", "answer": "Before you can use server-side encryption with a custom KMS key, you must configure AWS KMS key policies to allow encryption and decryption of messages.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-04T17:38:33.547523"}}
{"question": "How do the costs differ between using the AWS-managed KMS key for Kinesis and customer managed KMS keys?", "answer": "The AWS-managed KMS key for Kinesis (alias = aws/kinesis) is free, while customer managed KMS keys are subject to KMS key costs. Additionally, API usage costs apply for every KMS key, including custom ones, which can lead to costs for Kinesis Data Streams calls to KMS, especially as the number of user credentials increases.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-04T17:38:33.548049"}}
{"question": "What encryption algorithm does Kinesis Data Streams use for server-side encryption?", "answer": "Kinesis Data Streams uses an AES-GCM 256 algorithm for encryption.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-04T17:38:37.927555"}}
{"question": "How does server-side encryption work in Kinesis Data Streams?", "answer": "Server-side encryption encrypts the payload of the message along with the partition key, which is specified by the data stream producer applications. It is also a stream specific feature, meaning it applies only to the specific data stream where it is enabled.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-04T17:38:37.927908"}}
{"question": "How does the availability of Kinesis Data Streams compare to the AWS Free Tier?", "answer": "Kinesis Data Streams is not currently available in the AWS Free Tier, which offers a free trial for a group of AWS services. Therefore, users cannot utilize Kinesis Data Streams under the Free Tier program.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-04T17:38:37.928324"}}
{"question": "What is the pricing model for on-demand capacity mode in Kinesis Data Streams?", "answer": "In on-demand capacity mode, pricing is based on the volume of data ingested and retrieved, along with a per-hour charge for each data stream in your account.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-04T17:38:42.475648"}}
{"question": "How does on-demand capacity mode benefit users in terms of throughput management?", "answer": "On-demand capacity mode benefits users by eliminating the need to specify how much read and write throughput they expect their application to perform, allowing for a more flexible and scalable approach to managing data streams.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-04T17:38:42.475958"}}
{"question": "What additional charges may apply to Kinesis Data Streams beyond the standard pricing?", "answer": "Additional charges may apply for optional features such as Extended data retention (beyond the first 24 hours and within the first seven days), Long-Term data retention (beyond seven days and up to one year), and Enhanced Fan-Out.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-04T17:38:42.476300"}}
{"question": "What is a shard in the context of Kinesis Data Streams and what are its throughput capabilities?", "answer": "A shard is a unit of capacity in Kinesis Data Streams that provides 1 MB/second of write throughput and 2 MB/second of read throughput.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-04T17:38:50.243289"}}
{"question": "How does the provisioned capacity mode determine the cost associated with Kinesis Data Streams?", "answer": "In provisioned capacity mode, the cost is determined by the number of shards in the Amazon Kinesis data stream, with an hourly shard cost, and by the number of PUT payload units, which is based on the 25 KB payload units added by data producers. Additional charges apply for optional features like extended retention and enhanced fan-out.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-04T17:38:50.243603"}}
{"question": "How does the cost structure of Enhanced Fan-Out compare to Extended Data Retention in Kinesis Data Streams?", "answer": "Enhanced Fan-Out incurs costs based on consumer-shard hours and data retrievals, which are determined by the number of shards and the amount of data delivered to consumers. In contrast, Extended Data Retention incurs costs based on the number of shard hours for the data stream when extended retention is enabled, resulting in a charge for each shard in the stream at the extended retention rate. Therefore, while both are optional costs, they are based on different metrics: Enhanced Fan-Out focuses on consumer usage, whereas Extended Data Retention focuses on shard usage over time.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-04T17:38:50.243948"}}
{"question": "How is a consumer-shard hour calculated in AWS?", "answer": "A consumer-shard hour is calculated by multiplying the number of registered stream consumers with the number of shards in the stream. For example, if a consumer-shard hour costs $0.015 and a data stream has 10 shards, a single consumer using enhanced fan-out would incur a charge of $0.15 per hour (1 consumer * 10 shards * $0.015).", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-04T17:38:57.414637"}}
{"question": "What are the primary factors to consider when choosing between Kinesis Data Streams and Amazon MSK?", "answer": "When choosing between Kinesis Data Streams and Amazon MSK, it is important to consider factors such as familiarity with streaming technologies, existing applications running on Apache Kafka, and preference for open-source technologies. For those new to streaming, Kinesis Data Streams is recommended, while MSK is suitable for those with existing Kafka applications. Additionally, MSK is recommended for users who prefer open-source technologies.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-04T17:38:57.414982"}}
{"question": "How do Kinesis Data Streams and Amazon MSK compare in terms of open-source compatibility?", "answer": "Kinesis Data Streams does not have an emphasis on open-source compatibility, while Amazon MSK is fully compatible with open-source Apache Kafka and Kafka Connect. Therefore, if you have a preference for using open-source technologies, MSK is the recommended option.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-04T17:38:57.415493"}}
{"question": "What main functionality does Kinesis Data Streams provide for big data?", "answer": "Kinesis Data Streams enables real-time processing of streaming big data and provides ordering of records, as well as the ability to read and/or replay records in the same order to multiple Amazon Kinesis Applications.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-04T17:39:02.818318"}}
{"question": "How does the Amazon Kinesis Client Library (KCL) enhance the use of Kinesis Data Streams?", "answer": "The Amazon Kinesis Client Library (KCL) delivers all records for a given partition key to the same record processor, which makes it easier to build multiple applications that read from the same Kinesis data stream, allowing for functionalities such as counting, aggregation, and filtering.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-04T17:39:02.818688"}}
{"question": "How do Amazon Kinesis Data Streams and Amazon Simple Queue Service (SQS) differ in their message processing capabilities?", "answer": "Amazon Kinesis Data Streams provides real-time processing of streaming data with ordered record delivery to applications, while Amazon Simple Queue Service (SQS) offers a reliable, highly scalable hosted queue for storing messages and allows for independent processing of messages with message-level acknowledgment and failure semantics.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-04T17:39:02.819202"}}
{"question": "What is one of the key recommendations for using Kinesis Data Streams?", "answer": "One of the key recommendations for using Kinesis Data Streams is for use cases that require routing related records to the same record processor, such as in streaming MapReduce where counting and aggregation are simpler when all records for a given key are routed to the same record processor.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-04T17:39:08.801123"}}
{"question": "What advantage does Amazon SQS provide for handling message acknowledgment and failure tracking?", "answer": "Amazon SQS provides messaging semantics such as message-level acknowledgment and failure tracking, allowing applications to track the successful completion of each work item independently without needing to maintain a persistent checkpoint or cursor. Amazon SQS deletes acknowledged messages and redelivers failed messages after a configured visibility timeout.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-04T17:39:08.801475"}}
{"question": "How does Kinesis Data Streams compare to Amazon SQS in terms of record ordering?", "answer": "Kinesis Data Streams allows for the ordering of records, which is important for use cases such as transferring log data while maintaining the order of log statements. In contrast, Amazon SQS does not emphasize record ordering but focuses on message acknowledgment and independent processing, making it suitable for use cases where message order is not as critical.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-04T17:39:08.801919"}}
{"question": "What is the purpose of buffering requests in Amazon SQS?", "answer": "The purpose of buffering requests in Amazon SQS is to manage load changes that may occur due to occasional load spikes or the natural growth of a business.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-04T17:39:12.052418"}}
{"question": "How does Amazon SQS handle load without requiring provisioning instructions?", "answer": "Amazon SQS handles load without requiring provisioning instructions by processing each buffered request independently, allowing it to scale transparently as needed.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-04T17:39:12.052708"}}
{"question": "What are the benefits of using buffered requests in Amazon SQS compared to other messaging services?", "answer": "The context does not provide specific comparisons to other messaging services regarding buffered requests in Amazon SQS, so a different question type is needed.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-04T17:39:12.053236"}}
{"question": "What is AWS Key Management Service (KMS) used for?", "answer": "AWS Key Management Service (KMS) is a managed service that helps you create and control the keys used for cryptographic operations. It provides a highly available solution for key generation, storage, management, and auditing to encrypt or digitally sign data within applications or control the encryption of data across AWS services.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-04T17:39:16.489388"}}
{"question": "Why should developers use the AWS Encryption SDK with AWS KMS?", "answer": "Developers should use the AWS Encryption SDK with AWS KMS to more easily generate, use, and protect symmetric encryption keys in their code. This integration simplifies the encryption process within applications.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-04T17:39:16.489736"}}
{"question": "How does AWS KMS support compliance compared to managing encryption keys manually?", "answer": "AWS KMS facilitates proving that data is consistently protected, which is beneficial for regulatory or compliance purposes. In contrast, managing encryption keys manually may not provide the same level of centralized management and auditing capabilities that AWS KMS offers.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-04T17:39:16.489953"}}
{"question": "What is the easiest way to get started with AWS KMS?", "answer": "The easiest way to get started with AWS KMS is to choose to encrypt your data with an AWS service that uses AWS owned root keys that are automatically created by each service.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:39:21.010910"}}
{"question": "What are the benefits of creating your own AWS KMS customer managed keys?", "answer": "Creating your own AWS KMS customer managed keys allows you full control over the management of your keys, including the ability to share access to keys across accounts or services, and use the KMS keys directly within your own applications.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:39:21.011288"}}
{"question": "How do AWS KMS customer managed keys compare to AWS owned root keys in terms of control?", "answer": "AWS KMS customer managed keys provide full control over key management, including sharing access, while AWS owned root keys are automatically created by each service and do not offer the same level of management control.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:39:21.012172"}}
{"question": "What is the first step to start using AWS KMS?", "answer": "The first step to start using AWS KMS is to request the creation of an AWS KMS key.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T17:39:26.879834"}}
{"question": "How does envelope encryption work in AWS KMS?", "answer": "Envelope encryption in AWS KMS involves generating data keys that are used to encrypt data locally in the AWS service or your application. These data keys are themselves encrypted under an AWS KMS key you define, and AWS services encrypt your data and store an encrypted copy of the data key along with the encrypted data.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T17:39:26.880162"}}
{"question": "What are the differences between using AWS KMS APIs directly and using AWS services for encryption?", "answer": "When using AWS KMS APIs directly, you encrypt and decrypt data using your KMS keys stored in the service. In contrast, when using AWS services for encryption, the services encrypt your data using data keys that are protected by your KMS keys.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-04T17:39:26.880559"}}
{"question": "What types of keys does AWS KMS provide for managing encryption?", "answer": "AWS KMS provides three types of keys for managing encryption: customer managed KMS keys, AWS managed KMS keys, and AWS owned keys. Customer managed KMS keys are fully controlled by you, allowing you to define access control and usage policies. AWS managed KMS keys are created in your account but managed by AWS, and while you can track them and see usage logs in CloudTrail, you do not have direct control over these keys. AWS owned keys are fully owned and operated by AWS accounts, providing automation for encryption but lacking policy controls and CloudTrail logs.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-04T17:39:34.476865"}}
{"question": "How does envelope encryption improve performance when using AWS KMS?", "answer": "Envelope encryption improves performance by reducing the network load when encrypting data with AWS KMS. When you encrypt data directly with AWS KMS, the entire block of data must be transferred over the network, which can lead to latency. In contrast, envelope encryption only requires the transfer of a much smaller data key over the network, while the actual data is encrypted locally in your application or the encrypting AWS service. This approach minimizes the amount of data sent over the network, resulting in significant performance benefits.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-04T17:39:34.477198"}}
{"question": "What is the difference between customer managed KMS keys and AWS managed KMS keys?", "answer": "The main difference between customer managed KMS keys and AWS managed KMS keys lies in control and management. Customer managed KMS keys are owned and fully controlled by you, allowing you to define access control and usage policies and grant permissions to other accounts and services. In contrast, AWS managed KMS keys are created in your account but are managed by AWS. While you can track AWS managed keys and see their usage logged in CloudTrail, you do not have direct control over them.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-04T17:39:34.477629"}}
{"question": "What types of key management options does AWS KMS provide?", "answer": "AWS KMS provides flexibility to choose between customer managed keys, AWS managed keys, and AWS owned keys. Additionally, you can decide where to create and protect your keys, which can be within the KMS HSMs, within the CloudHSM, or in an external key manager.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-04T17:39:41.599821"}}
{"question": "Why are customer managed keys in the KMS HSMs recommended?", "answer": "Customer managed keys created and stored in the KMS HSMs are recommended because they offer the most flexibility, policy control, lifecycle management (including automatic and on-demand rotation for symmetric encryption keys), and complete audibility. Furthermore, these keys provide higher performance, lower latency, and a service level agreement for KMS cryptographic operations compared to keys in the custom key store (CloudHSM) or external key store (XKS).", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-04T17:39:41.600175"}}
{"question": "How does the key rotation process differ between automatic rotation in AWS KMS and manual rotation for imported or custom key store keys?", "answer": "With automatic key rotation in AWS KMS, you do not have to re-encrypt your data, as AWS KMS automatically keeps previous versions of keys for decryption of data encrypted under older versions. In contrast, when you manually rotate imported or custom key store keys, you may have to re-encrypt your data depending on whether you choose to keep old versions of the keys available.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-04T17:39:41.600680"}}
{"question": "What is the default waiting period for deleting an AWS KMS key?", "answer": "The default waiting period for deleting an AWS KMS key is 30 days.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-04T17:39:46.188298"}}
{"question": "Why does AWS KMS allow a waiting period before a key is permanently deleted?", "answer": "AWS KMS allows a waiting period before a key is permanently deleted to help you verify the impact of deleting a key on your applications and users that depend on it.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-04T17:39:46.188591"}}
{"question": "How do the limits on KMS keys differ between AWS managed KMS keys and customer-created KMS keys?", "answer": "AWS managed KMS keys created on your behalf for use within supported AWS services do not count against the limit of 100,000 KMS keys per account per Region, while both enabled and disabled customer-created KMS keys do count towards this limit.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-04T17:39:46.188933"}}
{"question": "Can the private portion of an asymmetric KMS key be exported in plain text from AWS KMS?", "answer": "No, the private portion of an asymmetric KMS key cannot be exported in plain text from the HSMs.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-04T17:39:50.729303"}}
{"question": "What are the methods available to export symmetric data keys from AWS KMS?", "answer": "Symmetric data keys can be exported using either the GenerateDataKey API or the GenerateDataKeyWithoutPlaintext API.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-04T17:39:50.729644"}}
{"question": "How does the export process differ between symmetric data keys and the private portion of asymmetric data keys?", "answer": "Symmetric data keys can be exported using the GenerateDataKey API or GenerateDataKeyWithoutPlaintext API, while the private portion of asymmetric data keys is encrypted under the symmetric KMS key when generated, and can be exported using the GenerateDataKeyPair API or GenerateDataKeypairWithoutPlaintext API.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-04T17:39:50.730027"}}
{"question": "What is the primary purpose of the AWS Private CA service?", "answer": "The primary purpose of the AWS Private CA service is to provide a public key infrastructure (PKI) for the purpose of identifying entities and securing network connections.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:39:55.681031"}}
{"question": "How does AWS Private CA differ from AWS KMS in terms of the services they provide?", "answer": "AWS Private CA focuses on issuing certificates to establish identities and secure communications, while AWS KMS is geared towards generating, managing, and using asymmetric keys for digital signing and encryption operations that do not require certificates.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:39:55.681372"}}
{"question": "In what scenarios would you use AWS Private CA instead of AWS KMS?", "answer": "You would use AWS Private CA instead of AWS KMS when you need to issue certificates for identifying web and application servers, service meshes, VPN users, internal API endpoints, and AWS IoT Core devices, as well as to create encrypted TLS/SSL communications channels. In contrast, AWS KMS is more suitable for raw asymmetric operations when identity proof is not necessary.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:39:55.681858"}}
{"question": "What is the purpose of AWS KMS in relation to plaintext keys?", "answer": "AWS KMS is designed so that no one, including AWS employees, can retrieve your plaintext KMS keys from the service.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-04T17:40:01.180879"}}
{"question": "How does AWS KMS ensure the confidentiality and integrity of KMS keys?", "answer": "AWS KMS uses hardware security modules (HSMs) that have been validated under FIPS 140-3 to protect the confidentiality and integrity of your keys. The plaintext KMS keys never leave the HSMs, are never written to disk, and are only used in the volatile memory of the HSMs for the time needed to perform cryptographic operations.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-04T17:40:01.181217"}}
{"question": "What is the difference in HSM certification for AWS KMS in China Regions compared to other AWS Regions?", "answer": "In AWS Regions outside of China, AWS KMS uses NIST FIPS HSMs that are validated under FIPS 140-3. However, by regulation, AWS KMS in China Regions cannot use NIST FIPS HSMs and instead uses HSMs certified by China's Office of the State Commercial Cryptographic Administration (OSCCA).", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-04T17:40:01.181438"}}
{"question": "What type of connection do AWS KMS API endpoints use to receive client requests?", "answer": "AWS KMS API endpoints receive client requests over an HTTPS connection using only TLS ciphersuites that support perfect forward secrecy.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-04T17:40:05.911346"}}
{"question": "How does AWS KMS ensure the security of its data keys?", "answer": "AWS KMS ensures the security of its data keys by encrypting them under a root key defined by the user in AWS KMS. This allows the user to safely store the encrypted data key alongside their encrypted data, and only users with permissions to use the original root key can decrypt the encrypted data key.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-04T17:40:05.911684"}}
{"question": "What is the difference between a single-Region KMS key and a multi-Region KMS key?", "answer": "A single-Region KMS key generated by AWS KMS is stored and used only in the Region in which it was created, whereas a multi-Region KMS key can be replicated into multiple Regions within the same AWS partition.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-04T17:40:05.912190"}}
{"question": "What types of requests are logged in AWS CloudTrail?", "answer": "AWS CloudTrail logs all AWS KMS API requests, which include both management requests such as create, rotate, disable, and policy edits, as well as cryptographic requests like encrypt and decrypt.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T17:40:10.683270"}}
{"question": "What are the main benefits of using AWS KMS for key management?", "answer": "The main benefits of using AWS KMS include centralized management of encryption keys, the ability to enforce usage policies, auditing capabilities through integration with CloudTrail, and flexibility in accessing keys via the AWS SDK, other AWS services, or the AWS Encryption SDK.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T17:40:10.683616"}}
{"question": "How does AWS KMS differ from CloudHSM in terms of key management?", "answer": "AWS KMS provides centralized management of encryption keys with a focus on integration with other AWS services and ease of use, while CloudHSM offers a validated single-tenant HSM cluster that provides exclusive control over key usage through an independent authentication mechanism, suitable for specific use cases like Digital Rights Management and Public Key Infrastructure.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-04T17:40:10.684042"}}
{"question": "What is included in the AWS Free Tier for AWS KMS?", "answer": "The AWS Free Tier for AWS KMS allows you to get started with AWS KMS for free in all Regions. It includes free storage for AWS managed AWS KMS keys created on your behalf by AWS services and a free tier for usage that provides a specific number of requests to the service each month. However, API requests involving asymmetric KMS keys and requests to the GenerateDataKeyPair and GenerateDataKeyPairWithoutPlaintext APIs are excluded from the Free Tier.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-04T17:40:23.039857"}}
{"question": "Why would a customer choose to import a key to AWS KMS?", "answer": "A customer might choose to import a key to AWS KMS to gain greater control over the creation, lifecycle management, and durability of their key. Imported keys can help meet compliance requirements by allowing the customer to maintain a secure copy of the key in their own infrastructure and providing the ability to delete the imported copy of the key from AWS infrastructure immediately if needed.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-04T17:40:23.040212"}}
{"question": "How do imported keys differ from AWS managed keys in AWS KMS?", "answer": "Imported keys differ from AWS managed keys in that imported keys allow for greater control over key creation, lifecycle management, and durability. While AWS managed keys are created by AWS services and are free to store, imported keys can be symmetric, asymmetric (RSA and elliptic curve), or HMAC keys that the customer wraps using an AWS KMS-provided public key. Additionally, customers can maintain a secure copy of imported keys in their own infrastructure and immediately delete them from AWS infrastructure, which is not a feature of AWS managed keys.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-04T17:40:23.040746"}}
{"question": "What is the responsibility of a user regarding imported keys in AWS KMS?", "answer": "You are responsible for maintaining a copy of your imported keys in your key management infrastructure so that you can re-import them at any time.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-04T17:40:29.251733"}}
{"question": "How does AWS KMS handle the expiration of imported key material compared to keys generated by AWS KMS?", "answer": "You may set an expiration period for an imported key, and AWS KMS will automatically delete the key material after that period. In contrast, keys generated by AWS KMS do not have an expiration time and cannot be deleted immediately, as there is a mandatory 7 to 30 day wait period before deletion can occur.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-04T17:40:29.251992"}}
{"question": "What are the differences in deletion processes for imported key material and AWS KMS generated keys?", "answer": "For imported key material, you can delete it on demand or it will be automatically deleted after the expiration period, but the KMS key reference and associated metadata are retained. In contrast, keys generated by AWS KMS cannot be deleted immediately and require a wait period of 7 to 30 days before deletion, and when you disable or schedule deletion of a customer managed KMS key, the KMS key itself is deleted, not just the key material.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-04T17:40:29.252364"}}
{"question": "What asymmetric key types are supported by AWS KMS?", "answer": "AWS KMS supports the following asymmetric key types: RSA 2048, RSA 3072, RSA 4096, ECC NIST P-256, ECC NIST P-384, ECC NIST-521, and ECC SECG P-256k1.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T17:40:37.003553"}}
{"question": "What are the encryption algorithms supported by AWS KMS for RSA key types?", "answer": "AWS KMS supports the RSAES_OAEP_SHA_1 and RSAES_OAEP_SHA_256 encryption algorithms with RSA 2048, RSA 3072, and RSA 4096 key types. However, encryption algorithms cannot be used with the elliptic curve key types.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T17:40:37.003893"}}
{"question": "How do the signing algorithms differ between RSA key types and elliptic curve key types in AWS KMS?", "answer": "When using RSA key types, AWS KMS supports the following signing algorithms: RSASSA_PSS_SHA_256, RSASSA_PSS_SHA_384, RSASSA_PSS_SHA_512, RSASSA_PKCS1_V1_5_SHA_256, RSASSA_PKCS1_V1_5_SHA_384, and RSASSA_PKCS1_V1_5_SHA_512. In contrast, when using elliptic curve key types, AWS KMS supports ECDSA_SHA_256, ECDSA_SHA_384, and ECDSA_SHA_512 signing algorithms.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T17:40:37.004414"}}
{"question": "What is the size limit for data that can be digitally signed using AWS KMS?", "answer": "The size limit for data that can be digitally signed using AWS KMS is 4 KB.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-04T17:40:41.035388"}}
{"question": "Why is automatic key rotation not supported for asymmetric or HMAC KMS keys?", "answer": "Automatic key rotation is not supported for asymmetric or HMAC KMS keys because rotation can be highly disruptive to existing workloads. This is due to the need to retire and replace all instances of keys that have been shared with other parties in the past.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-04T17:40:41.035756"}}
{"question": "How do the request per second rate limits differ between key types in AWS KMS?", "answer": "The request per second rate limits are different for different key types and algorithms in AWS KMS. Specific details can be found on the AWS KMS limits page.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-04T17:40:41.036155"}}
{"question": "What is the main feature of AWS KMS custom key store?", "answer": "The main feature of AWS KMS custom key store is that it combines the controls provided by CloudHSM with the integration and ease of use of AWS KMS, allowing you to configure your own CloudHSM cluster and authorize AWS KMS to use it as a dedicated key store for your keys.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T17:40:47.137557"}}
{"question": "Why might a user choose to use a custom key store in AWS KMS?", "answer": "A user might choose to use a custom key store for three reasons: to protect keys in a single tenant HSM or in an HSM under their direct control, to have the ability to immediately remove key material from AWS KMS and prove it independently, and to audit all use of their keys independently of AWS KMS or CloudTrail.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T17:40:47.137931"}}
{"question": "What are the differences between managing keys in a custom key store and the default AWS KMS key store?", "answer": "The differences between managing keys in a custom key store backed by CloudHSM and the default AWS KMS key store are that you cannot import key material into your custom key store and you cannot have AWS KMS automatically rotate keys. In all other respects, keys in a custom key store are managed like any other AWS KMS customer managed KMS key.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T17:40:47.138120"}}
{"question": "How does AWS KMS handle API requests for using a KMS key in relation to a custom key store backed by CloudHSM?", "answer": "API requests to AWS KMS to use a KMS key to encrypt and decrypt data are handled in the same way, regardless of whether the key is stored in a custom key store or the default AWS KMS key store. Authentication and authorization processes operate independently of the storage location of the key.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-04T17:40:53.594492"}}
{"question": "What additional auditing mechanisms does a custom key store provide beyond the activity logged to CloudTrail by AWS KMS?", "answer": "In addition to the activity logged to CloudTrail by AWS KMS, a custom key store provides three further auditing mechanisms: first, CloudHSM logs all API activity to CloudTrail; second, each cluster captures its own local logs for user and key management activity; and third, each CloudHSM instance copies its local user and key management activity logs to AWS CloudWatch.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-04T17:40:53.594732"}}
{"question": "How does the performance of keys stored in a custom key store backed by CloudHSM compare to keys stored in the default AWS KMS key store?", "answer": "The rate at which keys stored in an AWS KMS custom key store backed by CloudHSM can be used through AWS KMS API calls is lower than for keys stored in the default AWS KMS key store.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-04T17:40:53.594908"}}
{"question": "What must AWS KMS users do to use a custom key store?", "answer": "AWS KMS users that want to use a custom key store will need to set up an AWS CloudHSM cluster, add HSMs, manage HSMs users, and potentially restore HSMs from backup. These are security sensitive tasks and users should verify that they have the appropriate resources and organizational controls in place.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-04T17:41:01.758176"}}
{"question": "Why can't users import their own key material into an AWS KMS custom key store?", "answer": "The ability to import your own key material into an AWS KMS custom key store is not supported. Keys that are stored in a custom key store can only be generated in the HSMs that form your CloudHSM cluster.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-04T17:41:01.758523"}}
{"question": "How does the use of a CloudHSM cluster for AWS KMS keys impact other applications?", "answer": "AWS KMS does not require exclusive access to your CloudHSM cluster, allowing it to be used as a custom key store while still supporting other applications. However, if the cluster is supporting high, non-AWS KMS workloads, it may experience reduced throughput for operations using KMS keys in the custom key store. Conversely, a high AWS KMS request rate to the custom key store could impact performance for other applications.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-04T17:41:01.758964"}}
{"question": "What is the purpose of the XKS Proxy in the context of AWS KMS?", "answer": "The XKS Proxy is an open source API specification that helps you and your key management vendor build a service that accepts requests to AWS KMS and forwards them to your key management infrastructure to use its keys for encryption and decryption.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T17:41:09.975042"}}
{"question": "How does the XKS Proxy enhance the integration of external key managers with AWS services?", "answer": "The XKS Proxy enhances integration by allowing external key managers to accept requests from AWS services through a standardized API specification. This enables the use of external keys for encryption and decryption operations in AWS services that integrate with AWS KMS, thus providing flexibility in key management.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T17:41:09.975389"}}
{"question": "What are the differences in the encryption process between using AWS KMS and an external key manager with XKS Proxy?", "answer": "When using AWS KMS, the plaintext data key is encrypted by a key stored in AWS KMS unique to your AWS account, resulting in an encrypted data key. This encrypted data key is then forwarded to the XKS Proxy implementation, where it is encrypted a second time under the key defined in your external key manager. In contrast, if only AWS KMS were used, the data key would only be encrypted once. Thus, the key difference lies in the double-encryption process involving both AWS KMS and the external key manager.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-04T17:41:09.975601"}}
{"question": "What protocol should be used to protect the network connection between AWS KMS and the external key manager?", "answer": "The network connection between AWS KMS, your XKS Proxy implementation, and your external key manager should be protected with a point-to-point encryption protocol like TLS.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T17:41:17.028574"}}
{"question": "Why is double encryption used when transferring data from AWS KMS to the external key manager?", "answer": "Double encryption is used to ensure that no ciphertext can ever be decrypted without using the key material in your external key manager, providing an additional security control. It also ensures that the ciphertext leaving the AWS network is encrypted using the FIPS 140 certified AWS KMS HSMs.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T17:41:17.028855"}}
{"question": "How do XKS keys differ from existing KMS keys in terms of migration?", "answer": "XKS keys must be created as new keys in KMS, and you cannot migrate existing KMS keys into XKS keys hosted in your external key manager.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-04T17:41:17.029024"}}
{"question": "What is the purpose of automatic key rotation in the context of XKS keys?", "answer": "Automatic key rotation for XKS keys is a capability supported by the XKS specification and provided by most vendors. It occurs entirely in the external key manager and operates similarly to automatic key rotation for AWS KMS keys. This process allows for the use of current key material for encryption and the appropriate version of key material for decryption, as long as previous XKS keys are enabled in the external key manager.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-04T17:41:25.016795"}}
{"question": "How does the key rotation process ensure that decryption remains successful?", "answer": "The key rotation process ensures successful decryption by allowing the external key manager to use the version of the key material that was used to encrypt the ciphertext. As long as the previous XKS keys that were used to create earlier ciphertexts are still enabled in the external key manager, decryption requests will be able to succeed.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-04T17:41:25.017172"}}
{"question": "What happens to API calls using an XKS KMS key if the service does not cache keys, and how does this compare to services that do cache keys?", "answer": "If a service does not cache keys, the next API call using the XKS KMS key will fail. In contrast, services that implement data key caching or other key derivation schemes can continue to operate successfully for a certain period, as they may cache keys for durations ranging from 5 minutes to 24 hours. Therefore, if a key is denied access, protected resources currently in use will respond differently based on whether the service caches keys or not.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-04T17:41:25.017691"}}
{"question": "What authorization mechanisms can be used with KMS keys in external key stores?", "answer": "All of the usual AWS KMS authorization mechanisms, including IAM policies, AWS KMS key policies, and grants, work the same way for KMS keys in external key stores.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-04T17:41:33.423953"}}
{"question": "How can additional authorization controls be implemented when using KMS keys in external key stores?", "answer": "You and/or your external key manager partners can implement a secondary layer of authorization controls based on request metadata included with each request sent from AWS KMS to the XKS Proxy. This metadata includes the calling AWS user/role, the KMS key ARN, and the specific KMS API that was requested, allowing for fine-grained authorization policies.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-04T17:41:33.424179"}}
{"question": "How does the unique ID generated for requests involving XKS keys relate to logging and request reconciliation?", "answer": "The unique ID generated for every request coming to AWS KMS involving XKS keys is forwarded to the XKS proxy. This allows you to use the log data from your XKS proxy or external key manager to reconcile requests made to AWS KMS with those made to your external key manager, verifying that all requests to use keys in your external key manager originated from a call you initiated to AWS KMS.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-04T17:41:33.424562"}}
{"question": "What must be available for AWS KMS to successfully connect to the XKS Proxy?", "answer": "The XKS Proxy and external key material must have high availability to ensure that AWS KMS can successfully connect to the XKS Proxy whenever an XKS key is needed for decryption or encryption operations.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-04T17:41:40.638940"}}
{"question": "Why is it important to maintain the availability of the XKS Proxy and external key manager?", "answer": "Maintaining the availability of the XKS Proxy and external key manager is crucial because if they are unavailable, AWS KMS cannot perform the necessary cryptographic operations to decrypt or encrypt data. This can lead to failures, such as the inability to launch an EC2 instance that requires decryption of an encrypted EBS volume, resulting in a KMSInvalidStateException error.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-04T17:41:40.639243"}}
{"question": "How does the availability risk of the XKS Proxy compare to the durability risk of external keys?", "answer": "The availability risk of the XKS Proxy concerns the immediate accessibility of the proxy and external key manager for cryptographic operations, while the durability risk relates to the long-term preservation of external keys. If the XKS Proxy is unavailable, it can prevent operations from being completed, whereas if an external key is lost or deleted, all associated ciphertext becomes unrecoverable, indicating a permanent risk.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-04T17:41:40.639423"}}
{"question": "What happens if a request from AWS KMS to the XKS Proxy takes more than 500ms?", "answer": "If the elapsed time of a single request from AWS KMS to your XKS Proxy takes more than 500ms, AWS KMS will return a 400 error to its calling client. This indicates that your XKS key is unavailable and that the calling client should not retry the request.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-04T17:41:47.282463"}}
{"question": "Why is it important to ensure that the XKS Proxy and external key store infrastructure have sufficient performance characteristics?", "answer": "It is important to ensure that the XKS Proxy and external key store infrastructure have sufficient performance characteristics because every request using XKS keys requires a connection to the external key store. If the request rate from AWS KMS exceeds the request rate that your XKS Proxy or external key manager can support, it can become a bottleneck, leading to increased latency and potential errors for clients.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-04T17:41:47.282759"}}
{"question": "How does the request handling differ when a request takes 250ms compared to one that takes more than 500ms?", "answer": "When a request takes more than 250ms, AWS KMS will attempt a single retry. If the retry request also takes more than 250ms, a 400 error will be returned to the calling client. However, if a request takes more than 500ms, AWS KMS directly returns a 400 error without any retry, indicating that the XKS key is unavailable.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-04T17:41:47.283141"}}
{"question": "What does AWS specifically exclude from its public KMS availability SLA?", "answer": "AWS excludes the use of XKS in its public KMS availability SLA due to the inability to control the end-to-end availability of the connection between AWS KMS and the external key store infrastructure.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-04T17:41:52.649546"}}
{"question": "Why are XKS keys excluded from the availability SLA for AWS services?", "answer": "XKS keys are excluded from the availability SLA for any AWS service because these keys are configured by the user to encrypt data within the service, and AWS cannot control the end-to-end availability of the connection between AWS KMS and the external key store infrastructure.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-04T17:41:52.649921"}}
{"question": "How does the availability SLA for AWS KMS differ for XKS keys compared to standard KMS keys?", "answer": "The availability SLA for AWS KMS specifically excludes XKS keys, meaning that the availability of these keys is not guaranteed by AWS. In contrast, standard KMS keys are included in the availability SLA and have availability guarantees provided by AWS.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-04T17:41:52.650490"}}
{"question": "What is the primary purpose of AWS Lake Formation?", "answer": "The primary purpose of AWS Lake Formation is to make it easier to centrally govern, secure, and globally share data for analytics and machine learning. It allows for centralized data security and governance using the AWS Glue Data Catalog, enabling management of metadata and data permissions in one place.", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-04T17:41:58.373279"}}
{"question": "How does AWS Lake Formation ensure fine-grained data access control?", "answer": "AWS Lake Formation ensures fine-grained data access control by allowing you to manage permissions down to the row and column level, ensuring that users have access to the right data. This capability helps organizations maintain strict access control over their data resources.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-04T17:41:58.373653"}}
{"question": "How does AWS Lake Formation relate to AWS Glue and Amazon DataZone?", "answer": "AWS Lake Formation shares console controls and the AWS Glue Data Catalog with AWS Glue, which focuses on data integration and ETL. Additionally, AWS Lake Formation is integral to Amazon DataZone, where it manages permissions and facilitates the sharing of data products, ensuring access to Data Catalog tables that are managed in Lake Formation.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-04T17:41:58.374179"}}
{"question": "What third-party tools integrate with Lake Formation?", "answer": "The third-party tools that integrate with Lake Formation include Ahana, Dremio, Privacera, Collibra, and Starburst.", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T17:42:03.903803"}}
{"question": "How does Lake Formation help in managing permissions for data and metadata?", "answer": "Lake Formation centralizes permission management on resources in the AWS Glue Data Catalog, allowing users to manage permissions for data and metadata in one place. It allows defining and managing access for users and applications by role using familiar database-like grants, simplifying the management of permissions similar to those in data warehouses and databases.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T17:42:03.904147"}}
{"question": "How do IAM and Lake Formation work together in permissions management?", "answer": "IAM and Lake Formation are complementary to each other in permissions management. Lake Formation permissions combine with IAM permissions to control access to data in data lakes and the metadata describing that data. For a request to access AWS Glue Data Catalog resources or underlying data to succeed, it must pass permission checks by both IAM and Lake Formation. Lake Formation does not impact existing IAM permissions.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T17:42:03.904569"}}
{"question": "What capabilities does AWS Lake Formation offer for cross-account data sharing?", "answer": "AWS Lake Formation simplifies cross-account data sharing by allowing users to share distributed data across multiple AWS accounts, AWS Organizations, AWS Regions, or directly with IAM principals in another account, all while ensuring proper data governance so that data owners control who has data access.", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T17:42:10.544782"}}
{"question": "How does the AWS Glue Data Catalog enhance data access control?", "answer": "The AWS Glue Data Catalog acts as a hub for managing and sharing data, allowing users to set up and enforce permissions on datasets presented through the catalog. This facilitates easier control of access to data, regardless of its location, whether natively in the Glue Data Catalog or as a connector to other catalogs like Hive Metastore.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T17:42:10.545128"}}
{"question": "What is the relationship between AWS Lake Formation and AWS CloudTrail in terms of data access monitoring?", "answer": "AWS Lake Formation provides comprehensive audit logs with AWS CloudTrail, which allows users to monitor access and demonstrate compliance with centrally defined policies. This integration enables auditing of data access history across analytics and ML services that read data in the data lake, showing which users or roles attempted to access what data, with which services, and when.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T17:42:10.545556"}}
{"question": "What does AWS Lambda allow you to do with your code?", "answer": "AWS Lambda lets you run code without provisioning or managing servers. You can run code for virtually any type of application or backend service with zero administration.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T17:42:13.976354"}}
{"question": "How does AWS Lambda handle the scaling and availability of your code?", "answer": "AWS Lambda automatically takes care of everything required to run and scale your code with high availability, ensuring that you do not have to manage these aspects manually.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T17:42:13.976609"}}
{"question": "What is the main difference between using AWS Lambda and traditional server management?", "answer": "The main difference is that AWS Lambda requires no provisioning or managing of servers, whereas traditional server management involves handling the infrastructure and resources needed to run the applications.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-04T17:42:13.976997"}}
{"question": "What is the primary function of AWS Lambda in serverless computing?", "answer": "The primary function of AWS Lambda in serverless computing is to allow you to run your code without provisioning or managing servers. It executes code in response to events and handles all operational and administrative activities on your behalf, including capacity provisioning and monitoring.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T17:42:19.303012"}}
{"question": "How does serverless computing differ from traditional server management?", "answer": "Serverless computing differs from traditional server management in that users do not need to think about server management or provisioning capacity. While applications still run on servers, all server management tasks are handled by AWS, allowing developers to focus on coding rather than infrastructure management.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T17:42:19.303352"}}
{"question": "How does AWS Lambda compare to Amazon EC2 in terms of server management responsibilities?", "answer": "AWS Lambda differs from Amazon EC2 in that Lambda handles all server management responsibilities, including capacity provisioning and monitoring, whereas with Amazon EC2, users are responsible for provisioning capacity, monitoring fleet health and performance, and managing fault tolerance and scalability.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T17:42:19.303913"}}
{"question": "What programming languages are natively supported by AWS Lambda?", "answer": "AWS Lambda natively supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby code.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-04T17:42:25.214833"}}
{"question": "Why is it important for code running on AWS Lambda to be written in a stateless style?", "answer": "It is important for code running on AWS Lambda to be written in a stateless style because the code should assume there is no affinity to the underlying compute infrastructure. This means that local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, ensuring that any persistent state is stored in services like Amazon S3, Amazon DynamoDB, or Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-04T17:42:25.215065"}}
{"question": "How does AWS Lambda ensure security and separation for its functions compared to Amazon EC2?", "answer": "AWS Lambda ensures security and separation for its functions by running each function in its own isolated environment, with its own resources and file system view. It uses the same techniques as Amazon EC2 to provide security and separation at both the infrastructure and execution levels.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-04T17:42:25.215229"}}
{"question": "What is the range of ephemeral storage that can be configured for each Lambda function?", "answer": "You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T17:42:31.249894"}}
{"question": "What are the use cases for AWS Lambda ephemeral storage?", "answer": "You can use AWS Lambda ephemeral storage as a transient cache for storing data needed by code in a single function invocation. However, if your application needs durable, persistent storage, it is recommended to use Amazon S3 or Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T17:42:31.250137"}}
{"question": "How does AWS Lambda's ephemeral storage pricing compare to AWS Fargate's ephemeral storage pricing?", "answer": "AWS Lambda's ephemeral storage pricing is $0.0000000309 per GB-second, which translates to $0.000111 per GB-hour and $0.08 per GB-month. In comparison, AWS Fargate's ephemeral storage price is $0.000111 per GB-hour or $0.08 per GB-month. Therefore, both AWS Lambda and AWS Fargate have the same pricing of $0.08 per GB-month, but AWS Lambda's pricing is also presented in GB-seconds.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T17:42:31.250476"}}
{"question": "What is the maximum size of ephemeral storage that can be configured for an AWS Lambda function?", "answer": "The maximum size of ephemeral storage that can be configured for an AWS Lambda function is 10,240MB.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:42:35.927283"}}
{"question": "Why is it important to keep functions stateless in AWS Lambda?", "answer": "Keeping functions stateless enables AWS Lambda to rapidly launch as many copies of the function as needed to scale to the rate of incoming events.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:42:35.927561"}}
{"question": "How does AWS Lambda handle initialization code when Provisioned Concurrency is enabled compared to when it is not enabled?", "answer": "When Provisioned Concurrency is enabled, the function's initialization code runs during allocation and every few hours as running instances are recycled. This initialization is billed even if the instance does not process a request. Without Provisioned Concurrency, there is no specific mention of initialization behavior in the context.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-04T17:42:35.927951"}}
{"question": "What is the maximum size for uploads when packaging code as a ZIP for AWS Lambda?", "answer": "Uploads must be no larger than 50MB (compressed) when packaging code as a ZIP for AWS Lambda.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T17:42:40.071668"}}
{"question": "What are the recommended practices for managing sensitive information in AWS Lambda functions?", "answer": "For managing sensitive information, such as database passwords, it is recommended to use client-side encryption with AWS Key Management Service and store the resulting values as ciphertext in your environment variable. Additionally, you will need to include logic in your AWS Lambda function code to decrypt these values.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T17:42:40.071970"}}
{"question": "How does uploading code using the AWS CLI compare to using the AWS Lambda console?", "answer": "Both the AWS CLI and the AWS Lambda console allow you to upload packaged code (as a ZIP file) from your local environment or from an Amazon S3 location. However, using the AWS CLI may provide a command-line interface for automation, while the AWS Lambda console offers a user-friendly, IDE-like environment for authoring and testing functions.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-04T17:42:40.072471"}}
{"question": "What types of real-time metrics does AWS Lambda report through Amazon CloudWatch?", "answer": "AWS Lambda reports several real-time metrics through Amazon CloudWatch, including total requests, account-level and function-level concurrency usage, latency, error rates, and throttled requests.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-04T17:42:45.150278"}}
{"question": "How does AWS Lambda handle scaling for functions?", "answer": "AWS Lambda automatically scales functions on your behalf. Every time an event notification is received, AWS Lambda quickly locates free capacity within its compute fleet to run your code. Since the functions are stateless, AWS Lambda can start as many copies of the function as needed without lengthy deployment and configuration delays, dynamically allocating capacity to match the rate of incoming events.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-04T17:42:45.150558"}}
{"question": "How does the memory allocation affect the CPU power assigned to AWS Lambda functions?", "answer": "In the AWS Lambda resource model, the amount of memory chosen for a function directly affects the CPU power allocated. For example, choosing 256MB of memory allocates approximately twice as much CPU power as requesting 128MB of memory and half as much CPU power as choosing 512MB of memory.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-04T17:42:45.150972"}}
{"question": "What is the maximum execution time for AWS Lambda functions?", "answer": "AWS Lambda functions can be configured to run up to 15 minutes per execution. You can set the timeout to any value between 1 second and 15 minutes.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-04T17:42:50.564444"}}
{"question": "Why are larger memory functions in AWS Lambda beneficial for certain applications?", "answer": "Larger memory functions help multithreaded applications run faster, making them ideal for data and computationally intensive applications like machine learning, batch and ETL jobs, financial modeling, genomics, HPC, and media processing.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-04T17:42:50.564794"}}
{"question": "How do Compute Savings Plans for AWS Lambda compare to standard pricing?", "answer": "Compute Savings Plans offer up to a 17% discount on Duration, Provisioned Concurrency, and Duration (Provisioned Concurrency) for AWS Lambda, but they do not offer a discount on Requests in your Lambda bill. However, the commitment from Compute Savings Plans can apply to Requests at regular rates.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-04T17:42:50.565261"}}
{"question": "What are the pricing tiers for AWS Lambda functions running on x86 architecture in the US East (Ohio) region?", "answer": "For AWS Lambda functions running on x86 architecture in the US East (Ohio) region, the pricing tiers are as follows: You will pay $0.0000166667 for every GB-second for the first 6 billion GB-seconds per month, $0.0000150000 for every GB-second for the next 9 billion GB-seconds per month, and $0.0000133334 for every GB-second over 15 billion GB-seconds per month.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:42:56.710610"}}
{"question": "How does AWS Lambda handle pricing for functions running under consolidated billing in AWS Organizations?", "answer": "Under consolidated billing in AWS Organizations, the pricing tiers for AWS Lambda are applied to the aggregate monthly duration of functions running on the same architecture, in the same region, across all accounts in the organization.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:42:56.710893"}}
{"question": "How does the event source for AWS Lambda differ between services that directly invoke functions and those that require polling?", "answer": "Event sources for AWS Lambda differ in that some services, like Amazon S3, publish events directly to Lambda by invoking the cloud function, while other services, such as Amazon Kinesis and Amazon SQS, require Lambda to poll resources to pull records and execute a function for each fetched message.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-04T17:42:56.711092"}}
{"question": "What types of event sources can pass events to a Lambda function as an event input parameter?", "answer": "Events can be passed to a Lambda function from event sources such as Amazon SQS, Amazon Kinesis, and Amazon DynamoDB Streams. These event sources can deliver multiple events in a single call based on the batch size requested.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T17:43:05.871355"}}
{"question": "How can you trigger a Lambda function on updates to a DynamoDB table?", "answer": "You can trigger a Lambda function on DynamoDB table updates by subscribing your Lambda function to the DynamoDB Stream associated with the table. This can be done using the Amazon DynamoDB console, the AWS Lambda console, or Lambdas registerEventSource API.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T17:43:05.871635"}}
{"question": "What is the relationship between Amazon S3 notifications and Lambda functions?", "answer": "You can associate a Lambda function with notifications from an Amazon S3 bucket. This can be done from the AWS Lambda console by selecting a function and associating it with the notifications or by configuring the buckets notifications to send to the Lambda function using the Amazon S3 console. Additionally, this functionality is also available through the AWS SDK and CLI.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T17:43:05.872104"}}
{"question": "What is the maximum time window for aggregations that AWS Lambda allows over data in Amazon Kinesis or Amazon DynamoDB Streams?", "answer": "AWS Lambda allows aggregations over a maximum time window of 15 minutes for data in Amazon Kinesis or Amazon DynamoDB Streams.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-04T17:43:11.179933"}}
{"question": "How does AWS Lambda ensure the order of record processing within a shard?", "answer": "AWS Lambda ensures the order of record processing within a shard by strictly serializing the records. This means that if two records are put in the same shard, Lambda guarantees that the function will be invoked with the first record before it is invoked with the second record. If there are any issues with the invocation of the first record, Lambda will retry until it succeeds before moving on to the next record.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-04T17:43:11.180203"}}
{"question": "How does the aggregation scope differ between AWS Lambda and Amazon Kinesis Data Analytics?", "answer": "The aggregation scope for AWS Lambda is limited to a single partition or shard, while Amazon Kinesis Data Analytics allows aggregation over an entire data stream across multiple logical partitions.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-04T17:43:11.180372"}}
{"question": "What can you do from the AWS Lambda console regarding Amazon SNS topics?", "answer": "From the AWS Lambda console, you can select a Lambda function and associate it with an Amazon SNS topic. This functionality is also available through the AWS SDK and CLI.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:43:16.573258"}}
{"question": "How does AWS Lambda handle the invocation of functions using a custom event?", "answer": "You can invoke a Lambda function using a custom event through AWS Lambdas invoke API. Only the function owner or another AWS account that the owner has granted permission can invoke the function.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:43:16.573601"}}
{"question": "How does invoking a Lambda function over HTTPS using Amazon API Gateway compare to invoking it through the AWS Lambda SDK?", "answer": "Invoking a Lambda function over HTTPS using Amazon API Gateway involves defining a custom RESTful API that gives you an endpoint for your function, which can respond to REST calls like GET, PUT, and POST. In contrast, invoking it through the AWS Lambda SDK can involve both direct (synchronous) calls for real-time data retrieval and asynchronous calls, but does not require setting up a REST API.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-11", "source_tokens": 510, "generated_at": "2026-02-04T17:43:16.574031"}}
{"question": "What types of public login providers can users authenticate with when using Amazon Cognito?", "answer": "Users can authenticate themselves using a variety of public login providers such as Amazon, Facebook, Google, and other OpenID Connect-compatible services when using Amazon Cognito.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-04T17:43:22.191554"}}
{"question": "How does AWS Lambda handle function execution in case of an error when triggered by Amazon S3 bucket notifications?", "answer": "AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit when triggered by Amazon S3 bucket notifications.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-04T17:43:22.191929"}}
{"question": "How does the execution behavior of AWS Lambda differ between Amazon S3 bucket notifications and ordered event sources like Amazon DynamoDB Streams?", "answer": "For Amazon S3 bucket notifications, AWS Lambda attempts execution of the function three times in case of an error. In contrast, for ordered event sources like Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-04T17:43:22.192358"}}
{"question": "What is the AWS Serverless Application Model (AWS SAM)?", "answer": "The AWS Serverless Application Model (AWS SAM) is a specification that prescribes the rules for expressing serverless applications on AWS. It aligns with the syntax used by AWS CloudFormation and is supported natively within AWS CloudFormation as a set of resource types known as 'serverless resources'.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:43:28.839700"}}
{"question": "How does AWS CodePipeline facilitate the release process for serverless applications?", "answer": "AWS CodePipeline is a continuous delivery service that enables users to model, visualize, and automate the steps required to release their serverless applications. This automation helps streamline the release process and ensures consistency in deployments.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:43:28.839953"}}
{"question": "What are the differences between AWS CodeDeploy and AWS Step Functions in terms of their functionality for serverless applications?", "answer": "AWS CodeDeploy provides a deployment automation engine specifically for Lambda-based applications and allows users to orchestrate deployments using methodologies like canary and linear deployments. In contrast, AWS Step Functions is designed to coordinate a series of AWS Lambda functions in a specific order, enabling sequential or parallel execution while maintaining state during these executions. Both services serve different aspects of managing serverless applications.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:43:28.840292"}}
{"question": "What permissions need to be added to enable AWS X-Ray for a Lambda function?", "answer": "You need to add X-Ray permissions to your Lambda function execution role to enable AWS X-Ray for your Lambda function.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-04T17:43:34.905838"}}
{"question": "How does enabling X-Ray for a Lambda function benefit users?", "answer": "Enabling X-Ray for a Lambda function provides insights such as Lambda service overhead, function initialization time, and function execution time by emitting tracing information to X-Ray regarding the Lambda service overhead incurred when invoking the function.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-04T17:43:34.906176"}}
{"question": "What are the differences between AWS Lambda's support for the X-Ray SDK and RDS Proxy?", "answer": "AWS Lambda's support for the X-Ray SDK allows users to create their own trace segments, annotate traces, and view trace segments for downstream calls, while RDS Proxy is a highly available database proxy that manages thousands of concurrent connections to relational databases like MySQL and Aurora, and is used to facilitate serverless applications connecting to these databases.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-04T17:43:34.906699"}}
{"question": "What types of images can be used to create a function in AWS Lambda?", "answer": "You can start with either AWS provided base images for Lambda or use your preferred community or private enterprise images. Additionally, you can deploy third-party Linux base images such as Alpine or Debian.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-04T17:43:40.711916"}}
{"question": "What are the image manifest formats supported by AWS Lambda for container images?", "answer": "AWS Lambda supports images based on Docker Image Manifest V2 Schema 2 (used with Docker version 1.10 and newer) and Open Container Initiative (OCI) Spec (v1.0 and up).", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-04T17:43:40.712285"}}
{"question": "How does AWS Lambda treat images once they are deployed compared to traditional functions?", "answer": "Once deployed, AWS Lambda treats an image as immutable, which means that the image cannot be changed. In contrast, traditional functions may allow for updates and changes to the code or configuration without redeploying the entire function.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-04T17:43:40.712791"}}
{"question": "What is the maximum image size for functions created using container images in AWS Lambda?", "answer": "The maximum image size for functions created using container images in AWS Lambda is 10 GB.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-04T17:43:46.447350"}}
{"question": "Why are functions defined as container images in AWS Lambda considered immutable?", "answer": "Functions defined as container images in AWS Lambda are considered immutable because AWS Lambda does not patch or update the image once it is deployed. Customers are responsible for the components packaged in their function, and they must use curated base images provided by AWS, which are regularly updated for security and bug fixes.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-04T17:43:46.447631"}}
{"question": "How does the performance of functions packaged as container images compare to those packaged as ZIP archives in AWS Lambda?", "answer": "The performance profiles for functions packaged as container images are the same as for those packaged as ZIP archives in AWS Lambda, including typically sub-second start-up times.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-04T17:43:46.448024"}}
{"question": "What is the main function of the Lambda Runtime Interface Emulator?", "answer": "The main function of the Lambda Runtime Interface Emulator is to serve as a proxy for the Lambda Runtime API, allowing customers to locally test their Lambda functions that are packaged as container images. It converts HTTP requests to JSON events and emulates the Lambda Runtime API.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-04T17:43:52.428846"}}
{"question": "How does the Lambda Runtime Interface Emulator simplify local testing of Lambda functions?", "answer": "The Lambda Runtime Interface Emulator simplifies local testing of Lambda functions by allowing developers to use familiar tools such as cURL and the Docker CLI to test their functions. It enables the function packaged as a container image to accept HTTP requests directly, which can be tested using commands like 'docker run' or 'docker-compose up'.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-04T17:43:52.429192"}}
{"question": "What is the difference between the Lambda Runtime Interface Emulator and the actual Lambda Runtime API?", "answer": "The Lambda Runtime Interface Emulator emulates the Lambda Runtime API by allowing local testing with HTTP requests, whereas the actual Lambda Runtime API accepts JSON events and returns responses when running in the Lambda service. However, the emulator does not emulate the Lambda orchestrator or the security and authentication configurations.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-04T17:43:52.429706"}}
{"question": "What are the requirements for deploying a containerized application to AWS Lambda?", "answer": "To deploy a containerized application to AWS Lambda, the container image must implement the Lambda Runtime API, be able to run on a read-only filesystem, and the execution files must be accessible by the default Lambda user. Additionally, the container image must be a Linux-based image.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-04T17:43:59.358431"}}
{"question": "How does AWS SnapStart improve the startup performance of Lambda functions?", "answer": "AWS SnapStart improves startup performance by snapshotting the function's initialized memory and disk state, caching this snapshot for low-latency access. When the function is invoked again, Lambda resumes the execution environment from this pre-initialized snapshot instead of starting from scratch, which significantly decreases startup latency.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-04T17:43:59.358753"}}
{"question": "What is the relationship between Lambda SnapStart and function versions in AWS Lambda?", "answer": "When Lambda SnapStart is configured for a function, every version of that function published thereafter benefits from the improved startup performance provided by SnapStart. This means that the configuration applies to all future versions, ensuring they all utilize the cached snapshot for quicker startup times.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-04T17:43:59.359130"}}
{"question": "What is the main benefit of using Lambda SnapStart?", "answer": "The main benefit of using Lambda SnapStart is that it helps your functions achieve faster start-up times by reducing the variable latency incurred during the execution of one-time initialization code.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-04T17:44:05.213903"}}
{"question": "Why might an application with strict latency requirements prefer to use PC instead of Lambda SnapStart?", "answer": "An application with strict latency requirements might prefer to use PC because Lambda SnapStart works as a best-effort optimization and does not guarantee the elimination of cold starts, whereas PC is recommended for achieving double-digit millisecond startup times.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-04T17:44:05.214251"}}
{"question": "How does Lambda SnapStart interact with Amazon EFS and ephemeral storage larger than 512 MB?", "answer": "Lambda SnapStart cannot be enabled with Amazon EFS, and it also cannot be enabled with larger ephemeral storage beyond 512 MB at this time.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-04T17:44:05.214492"}}
{"question": "How long will I be charged for caching a snapshot when using Lambda SnapStart?", "answer": "You will be charged for caching a snapshot over the period that your function version is active, for a minimum of 3 hours and per milli-second thereafter.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-04T17:44:09.794782"}}
{"question": "What is the purpose of Provisioned Concurrency in AWS Lambda?", "answer": "Provisioned Concurrency gives you greater control over the performance of your serverless applications by keeping functions initialized and hyper-ready to respond in double-digit milliseconds.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-04T17:44:09.795123"}}
{"question": "How does the initialization duration for Lambda SnapStart compare to the execution timeout duration?", "answer": "The maximum allowed initialization duration for Lambda SnapStart will match the execution timeout duration that you have configured for your function, which has a maximum configurable limit of 15 minutes.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-04T17:44:09.795604"}}
{"question": "What changes need to be made to existing code to use Provisioned Concurrency?", "answer": "You dont need to make any changes to your code to use Provisioned Concurrency. It works seamlessly with all existing functions and runtimes.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T17:44:15.977371"}}
{"question": "Why is Provisioned Concurrency considered ideal for latency-sensitive applications?", "answer": "Provisioned Concurrency is ideal for building latency-sensitive applications because it allows you to keep functions initialized, which reduces latency for web or mobile backends, synchronously invoked APIs, and interactive microservices. You can configure the appropriate amount of concurrency based on your application's unique demand and adjust it during times of varying demand.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T17:44:15.977596"}}
{"question": "How does the behavior of a Lambda function change once it reaches the configured level of Provisioned Concurrency?", "answer": "Once the concurrency of a function reaches the configured level of Provisioned Concurrency, subsequent invocations of the function exhibit the latency and scale characteristics of regular Lambda functions. This means that the function can be restricted to only scale up to the configured level to prevent exceeding the anticipated demand.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-04T17:44:15.977778"}}
{"question": "What are the performance benefits of using AWS Lambda functions powered by Graviton2 compared to x86 processors?", "answer": "AWS Lambda functions powered by Graviton2 deliver up to 34% better price performance, have lower latency, up to 19% better performance, and a 20% lower cost compared to functions running on x86 processors.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-04T17:44:21.464722"}}
{"question": "How can customers configure their AWS Lambda functions to use the Graviton2 processor?", "answer": "Customers can configure their AWS Lambda functions to target the Graviton2 processor through the AWS Management Console, the AWS Lambda API, the AWS CLI, and AWS CloudFormation by setting the architecture flag to arm64 for their function.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-04T17:44:21.465097"}}
{"question": "What is the difference in architecture support for AWS Lambda functions regarding version changes?", "answer": "An application can contain functions running on both architectures (x86_64 and arm64), but once a specific version of a function is created, the architecture cannot be changed. Additionally, each function version can only use a single container image.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-04T17:44:21.465558"}}
{"question": "What are the compatible architectures for layers and extensions in AWS Lambda?", "answer": "Layers and extensions in AWS Lambda can be targeted to 'x86_64' or 'arm64' compatible architectures.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-04T17:44:28.737029"}}
{"question": "Why might customers consider using AWS Graviton2 processors for AWS Lambda functions?", "answer": "Customers might consider using AWS Graviton2 processors for AWS Lambda functions because they are 20% cheaper compared to x86-based Lambda functions, potentially leading to cost savings.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-04T17:44:28.737367"}}
{"question": "How does using Amazon EFS for AWS Lambda differ from the previous method of handling data?", "answer": "Using Amazon EFS for AWS Lambda allows customers to securely read, write, and persist large volumes of data without needing to download data from S3 or databases to local temporary storage, which was previously limited to 512MB. In contrast, the previous method required developers to add code to their functions for downloading data to temporary storage.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-04T17:44:28.737888"}}
{"question": "What encryption method is used for data in transit between AWS Lambda functions and Amazon EFS?", "answer": "Data encryption in transit uses industry-standard Transport Layer Security (TLS) 1.2 to encrypt data sent between AWS Lambda functions and the Amazon EFS file systems.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:44:33.757868"}}
{"question": "What are the benefits of using Amazon EFS with AWS Lambda in a stateful microservice architecture?", "answer": "Using EFS for Lambda is ideal for keeping state between invocations within a stateful microservice architecture, in a Step Functions workflow, or sharing files between serverless applications and instance or container-based applications.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:44:33.758137"}}
{"question": "How does the access to Amazon EFS differ between AWS Lambda functions and EC2 instances?", "answer": "Each Lambda function will be able to access one EFS file system, while Amazon EFS supports Lambda functions, ECS and Fargate containers, and EC2 instances, allowing them to share the same file system and use IAM policy and Access Points to control access.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-04T17:44:33.758645"}}
{"question": "What is the default authorization method for Lambda function URLs?", "answer": "Lambda function URLs are secured with IAM authorization by default.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T17:44:37.853806"}}
{"question": "How can you implement custom domain names with Lambda function URLs?", "answer": "Custom domain names are not currently supported with function URLs. However, you can use a custom domain with your function URL by creating an Amazon CloudFront distribution and a CNAME to map your custom domain to your CloudFront distribution name. Then, you map your CloudFront distribution domain name to be routed to your function URL as an origin.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T17:44:37.854139"}}
{"question": "How does Lambda@Edge differ from standard AWS Lambda in terms of invocation?", "answer": "Lambda@Edge allows you to run code across AWS locations globally in response to Amazon CloudFront requests, whereas standard AWS Lambda does not inherently provide global invocation based on CloudFront events.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-04T17:44:37.854641"}}
{"question": "What is Lambda@Edge optimized for?", "answer": "Lambda@Edge is optimized for latency-sensitive use cases where end viewers are distributed globally.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-04T17:44:42.665538"}}
{"question": "How does Lambda@Edge enhance content delivery based on user characteristics?", "answer": "Lambda@Edge allows decisions on how to serve content based on user characteristics, such as location and client device, to be executed and served close to the users without needing to route the requests back to a centralized server.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-04T17:44:42.665894"}}
{"question": "What is the difference between Lambda@Edge and regional services like API Gateway and Lambda?", "answer": "The difference is that API Gateway and Lambda are regional services, while Lambda@Edge and Amazon CloudFront allow you to execute logic across multiple AWS locations based on where your end viewers are located.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-04T17:44:42.666408"}}
{"question": "What happens when the maximum concurrent executions limit is exceeded for AWS Lambda functions invoked synchronously?", "answer": "When the maximum concurrent executions limit is exceeded for AWS Lambda functions invoked synchronously, they will return a throttling error, specifically a 429 error code.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-04T17:44:49.355934"}}
{"question": "How does AWS Lambda handle traffic for functions invoked asynchronously when the maximum concurrent executions limit is reached?", "answer": "AWS Lambda functions being invoked asynchronously can absorb reasonable bursts of traffic for approximately 15-30 minutes. After this period, incoming events will be rejected as throttled if the limit is still exceeded.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-04T17:44:49.356195"}}
{"question": "How does the concurrency scaling for AWS Lambda functions work in comparison to other functions within the same account?", "answer": "The concurrency scaling limit for AWS Lambda functions is a function-level limit, meaning each function in your account can scale independently of other functions. This allows each function to handle its own traffic and scaling requirements without being affected by the scaling of other functions.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-04T17:44:49.356586"}}
{"question": "What happens when a Lambda function is invoked synchronously and fails?", "answer": "When a Lambda function is invoked synchronously and fails, it will respond with an exception.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-04T17:44:55.060249"}}
{"question": "How does the retry policy differ between asynchronous invocations and stream-based invocations for Lambda functions?", "answer": "Asynchronous invocations for Lambda functions are retried at least 3 times, and if the retry policy is exceeded, a dead letter queue (DLQ) can be configured. In contrast, stream-based invocations from Amazon Kinesis streams and Amazon DynamoDB streams are retried until the Lambda function succeeds or the data expires, but if the retry policy is exceeded, the data would have already expired and therefore rejected.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-04T17:44:55.060610"}}
{"question": "What role does the IAM role play in managing access controls for an AWS Lambda function compared to resource policy settings?", "answer": "The IAM role assigned to an AWS Lambda function grants permissions to access other resources and determines which resource(s) AWS Lambda can poll on its behalf. In contrast, resource policy settings can also manage access controls, and if both the IAM role and resource policy are present, the more restrictive of the two permissions will be applied.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-04T17:44:55.061099"}}
{"question": "How can you enable AWS Lambda functions to access resources in your VPC?", "answer": "You can enable AWS Lambda functions to access resources in your VPC by specifying the subnet and security group as part of your function configuration.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-04T17:45:00.313027"}}
{"question": "What is the purpose of Code Signing for AWS Lambda?", "answer": "The purpose of Code Signing for AWS Lambda is to offer trust and integrity controls that enable you to verify that only unaltered code from approved developers is deployed in your Lambda functions.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-04T17:45:00.313309"}}
{"question": "What are the differences between the types of signature checks that AWS Lambda performs at deployment?", "answer": "AWS Lambda performs several types of signature checks at deployment: a corrupt signature check occurs if the code artifact has been altered since signing; a mismatched signature check occurs if the code artifact is signed by a signing profile that is not approved; an expired signature check occurs if the signature is past the configured expiry date; and a revoked signature check occurs if the signing profile owner revokes the signing jobs.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-04T17:45:00.313517"}}
{"question": "What methods can be used to enable code signing for existing AWS Lambda functions?", "answer": "You can enable code signing for existing functions by attaching a code signing configuration to the function using the AWS Lambda console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-04T17:45:06.466883"}}
{"question": "What are the benefits of capturing Lambda function logs in JSON structured format?", "answer": "Capturing Lambda function logs in JSON structured format makes it easier to search, filter, and analyze large volumes of log entries. It also allows users to control the log level filtering of Lambda function logs without making any code changes, enabling them to choose the required logging granularity level when debugging and troubleshooting errors.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-04T17:45:06.467227"}}
{"question": "How do AWS Lambda's advanced logging controls compare to using your own logging libraries?", "answer": "AWS Lambda's advanced logging controls allow for capturing logs in JSON structured format without needing to use your own logging libraries, making it easier to manage logging. However, if you choose to use your own logging libraries, Lambda will not double-encode any logs that are already JSON encoded, ensuring compatibility with its native logging capabilities.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-04T17:45:06.467717"}}
{"question": "Is there an additional charge for using advanced logging controls on AWS Lambda?", "answer": "No, there is no additional charge for using advanced logging controls on Lambda. However, you will still be charged for ingestion and storage of your Lambda logs by Amazon CloudWatch Logs.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-04T17:45:12.854493"}}
{"question": "What is CloudWatch Application Signals and how does it benefit serverless applications built with Lambda?", "answer": "CloudWatch Application Signals is an application performance monitoring (APM) solution that enables developers and operators to easily monitor the health and performance of serverless applications built with Lambda. It provides pre-built, standardized dashboards for critical application metrics, correlated traces, and interactions between Lambda functions and their dependencies, all without requiring manual instrumentation or code changes from developers.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-04T17:45:12.854844"}}
{"question": "How does CloudWatch Logs Live Tail compare to CloudWatch Application Signals in terms of functionality for Lambda?", "answer": "CloudWatch Logs Live Tail provides real-time visibility into logs, allowing developers to quickly test and validate code or configuration changes, whereas CloudWatch Application Signals offers pre-built dashboards and performance monitoring for serverless applications. Live Tail focuses on interactive log streaming to detect and debug failures, while Application Signals provides a broader view of application performance metrics and correlations.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-04T17:45:12.855368"}}
{"question": "What tools can be used to compile a Lambda function written in Java?", "answer": "You can use standard tools like Maven or Gradle to compile your Lambda function.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-04T17:45:19.118782"}}
{"question": "What is the process for deploying a Lambda function written in Node.js?", "answer": "To deploy a Lambda function written in Node.js, you need to package your Javascript code and dependent libraries as a ZIP file. You can then upload the ZIP from your local environment or specify an Amazon S3 location where the ZIP file is located.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-04T17:45:19.119148"}}
{"question": "How does the process of creating a C# Lambda function compare to deploying a Lambda function written in Node.js?", "answer": "Creating a C# Lambda function can be done using the Visual Studio IDE by selecting 'Publish to AWS Lambda' in the Solution Explorer or by running the 'dotnet lambda publish' command from the dotnet CLI. In contrast, deploying a Lambda function written in Node.js involves packaging Javascript code and libraries as a ZIP file and uploading it. Both methods result in the function being uploaded to AWS Lambda, but they utilize different tools and processes.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-04T17:45:19.119666"}}
{"question": "What is included in a PowerShell Lambda deployment package?", "answer": "A PowerShell Lambda deployment package is a ZIP file that contains your PowerShell script, PowerShell modules required for your PowerShell script, and the assemblies needed to host PowerShell Core.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-04T17:45:25.974269"}}
{"question": "How does AWS Lambda handle multiple invoking functions with Amazon Step Functions?", "answer": "You can use Amazon Step Functions to coordinate multiple invoking Lambda functions. This allows you to invoke multiple Lambda functions either serially, passing the output of one to the other, or in parallel.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-04T17:45:25.974585"}}
{"question": "How does the deployment process differ between PowerShell and Go for AWS Lambda functions?", "answer": "For PowerShell, you create a deployment package as a ZIP file containing the script, required modules, and assemblies, and use the AWSLambdaPSCore module for deployment. In contrast, for Go, you upload the Go executable artifact as a ZIP file and select the go1.x runtime, using Go's native tools to build and package the code.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-04T17:45:25.975016"}}
{"question": "What is Amazon Lex primarily used for?", "answer": "Amazon Lex is primarily used for building conversational interfaces using voice and text, allowing users to create sophisticated, natural language chatbots for applications.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:45:30.925339"}}
{"question": "How does Amazon Lex reduce multi-platform development effort?", "answer": "Amazon Lex reduces multi-platform development effort by allowing users to easily publish their speech or text chatbots to mobile devices and multiple chat services, such as Facebook Messenger, Slack, Kik, or Twilio SMS.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:45:30.925707"}}
{"question": "How does the functionality of Amazon Lex compare to Amazon Alexa?", "answer": "Amazon Lex is powered by the same conversational engine as Amazon Alexa, providing high-quality speech recognition and language understanding capabilities, which allows for the creation of sophisticated chatbots, similar to the voice interactions enabled by Alexa.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:45:30.926262"}}
{"question": "What is required from developers to create a bot using Amazon Lex?", "answer": "Developers need to declaratively specify the conversation flow and provide some sample utterances in plain English, along with the different parameters (slots) they would like to collect from the user with the corresponding prompts. The language model gets built automatically by Amazon Lex.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:45:35.901721"}}
{"question": "How does Amazon Lex differ from traditional machine learning services in terms of user expertise requirements?", "answer": "Amazon Lex does not require any machine learning expertise from developers to use it, whereas traditional machine learning services typically require a higher level of expertise to implement and manage algorithms and models.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:45:35.902062"}}
{"question": "How does Amazon Lex ensure scalability compared to traditional resource management methods?", "answer": "Amazon Lex is a completely managed service that automatically scales to the user's needs without imposing bandwidth constraints. In contrast, traditional resource management methods often require manual scaling of resources and maintenance of code.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T17:45:35.902468"}}
{"question": "What is an 'utterance' in the context of Amazon Lex?", "answer": "An 'utterance' is the spoken or typed phrase used to invoke an intent. For example, to invoke the intent to make reservations, a sample utterance could be, 'Can I make a reservation?'", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-04T17:45:41.098185"}}
{"question": "How does Amazon Lex gather information from users to fulfill intents?", "answer": "Amazon Lex gathers information from users to fulfill intents by capturing this information in 'slots'. For example, when making reservations, slots like show name and time would be defined.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-04T17:45:41.098454"}}
{"question": "How does the automated chatbot designer differ from manually creating a bot in Amazon Lex?", "answer": "The automated chatbot designer helps create a bot design in just a few clicks by processing conversation transcripts to surface a chatbot design that includes user intents and sample phrases. In contrast, manually creating a bot would typically involve defining intents and slots without the assistance of automated processing.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-04T17:45:41.098582"}}
{"question": "What locales are supported by Amazon Lex for the automated chatbot designer?", "answer": "All English locales supported by Amazon Lex, including US, UK, AU, IN, and SA, are supported by the automated chatbot designer.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T17:45:47.150098"}}
{"question": "How does Amazon Lex handle versioning for bots, and what is the significance of an immutable version?", "answer": "Building a bot triggers machine learning and creates models for your bot, resulting in a new version of your intents and slot types. Once created, a version is immutable, meaning it cannot be changed. This ensures stability for each version of the bot as it is deployed.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T17:45:47.150393"}}
{"question": "What are the differences in interaction types supported by Amazon Lex bots?", "answer": "Amazon Lex bots support two types of interactions: request and response interaction, which allows for up to 15 seconds of speech input, and continuous streaming conversation, which processes all user inputs across multiple turns in one streaming API call, also up to 15 seconds of speech input including silence.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-04T17:45:47.150561"}}
{"question": "What languages does Amazon Lex currently support?", "answer": "Amazon Lex currently supports US English, Spanish, French, German, Italian, Japanese, Australian English, British English, Canadian French, Latin American Spanish, and US Spanish.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-04T17:45:52.576941"}}
{"question": "What are the differences between the request and response interaction and the streaming conversation in Amazon Lex?", "answer": "In a request and response interaction, each user input, whether voice or text, is processed as a separate API call. In contrast, a streaming conversation allows all user inputs across multiple turns to be processed in one streaming API call, enabling a more continuous interaction where the bot can respond proactively to user interruptions and pauses.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-04T17:45:52.577293"}}
{"question": "How do Amazon Lex V2 APIs differ from V1 APIs in terms of bot migration?", "answer": "Amazon Lex V2 APIs use an updated information architecture that enables simplified resource versioning and support for multiple languages within a bot, making them incompatible with V1 APIs. If you want to take advantage of V2 features, you must recreate your bot using V2 APIs, as Lex V1 APIs do not support these enhancements.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-04T17:45:52.577692"}}
{"question": "What languages are supported by the Amazon Lex V2 APIs?", "answer": "The Amazon Lex V2 APIs support US English, Spanish, French, German, Italian, Japanese, Australian English, British English, Canadian French, Latin American Spanish, and US Spanish.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-04T17:45:58.109232"}}
{"question": "What are the key differences between the V1 and V2 consoles in Amazon Lex?", "answer": "The key differences include that the V1 console allows access to bots created in V1, which are not visible in the V2 console unless they are recreated. The V2 APIs offer enhanced features not available in V1, and users can migrate to V2 by following a migration guide.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-04T17:45:58.109480"}}
{"question": "How does the support for voice functionality differ between Amazon Lex and Alexa Skills Kit?", "answer": "Amazon Lex does not support wake word functionality and relies on the integrating app to trigger the microphone. In contrast, the Alexa Skills Kit (ASK) is specifically designed for building skills within the Alexa ecosystem, allowing developers to leverage various Alexa capabilities.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-04T17:45:58.109886"}}
{"question": "What file format can you export your Amazon Lex bot schema into?", "answer": "You can export your Amazon Lex bot schema into a JSON file that is compatible with Amazon Alexa.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T17:46:02.403863"}}
{"question": "What is the purpose of Amazon Lex storing and using voice and text inputs?", "answer": "Amazon Lex may store and use voice and text inputs to provide and maintain the service, as well as to improve and develop the quality of Amazon Lex and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T17:46:02.404205"}}
{"question": "How does the use of voice and text inputs in Amazon Lex differ from targeting products or services?", "answer": "Amazon Lex uses voice and text inputs solely for service improvement and development, and does not use any personally identifiable information contained in the content to target products, services, or marketing to you or your end users.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T17:46:02.404633"}}
{"question": "What measures does Amazon Lex implement to protect user content?", "answer": "Amazon Lex implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to or disclosure of user content. Their highest priority is the trust, privacy, and security of user content.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-04T17:46:08.781594"}}
{"question": "What rights do users retain regarding their content processed by Amazon Lex?", "answer": "Users always retain ownership of their content processed by Amazon Lex, and Amazon will only use this content with the user's consent.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-04T17:46:08.781877"}}
{"question": "How does Amazon Lex handle content from applications directed at children under age 13 compared to general applications?", "answer": "Amazon Lex does not store or retain voice or text utterance information from applications that are identified by customers as being directed or targeted at children under age 13, in accordance with COPPA. In contrast, for general applications, content may be processed and stored unless specified otherwise by the user.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-04T17:46:08.782248"}}
{"question": "What programming languages and platforms does Amazon Lex support for building bots?", "answer": "Amazon Lex supports SDKs for building bots in the following programming languages and platforms: Java, JavaScript, Python, CLI, .NET, Ruby on Rails, PHP, Go, and CPP.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T17:46:14.670945"}}
{"question": "How does the billing for requests to an Amazon Lex bot work?", "answer": "Every input to an Amazon Lex bot is counted as a request. For example, if an end user provides 5 inputs to the bot as part of a conversation, these are billed as 5 requests. Usage is metered and billed per request.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T17:46:14.671194"}}
{"question": "What is the difference between the free plan and paid plan when signing up for AWS services?", "answer": "The free plan allows new AWS customers to process up to 10,000 text requests and 5,000 speech requests per month for free during the first year, and it is available for 6 months after account creation. In contrast, the paid plan requires payment for usage beyond the free tier limits, and any remaining Free Tier credit balance will automatically apply to AWS bills if the customer upgrades to a paid plan.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-04T17:46:14.671588"}}
{"question": "What is the purpose of AWS License Manager?", "answer": "AWS License Manager helps in managing software licenses, ensuring compliance, and automating the discovery of licenses across AWS and on-premises environments.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-04T17:46:19.487934"}}
{"question": "How does AWS License Manager assist in compliance management?", "answer": "AWS License Manager assists in compliance management by providing tools to track licenses, manage entitlements, and ensure that users adhere to licensing agreements.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-04T17:46:19.488459"}}
{"question": "What are the differences between managed entitlements and user-based license subscriptions in AWS License Manager?", "answer": "Managed entitlements refer to the automated management of software licenses provided by AWS, while user-based license subscriptions are specific licenses assigned to individual users. Managed entitlements focus on overall license management, whereas user-based subscriptions cater to individual user needs.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-04T17:46:19.488663"}}
{"question": "What is the first step to get started with License Manager?", "answer": "The first step to get started with License Manager is to define licensing rules. Administrators work with relevant stakeholders in the organization to review licensing agreements and create licensing rules that reflect the terms of the enterprise agreement.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-04T17:46:26.686426"}}
{"question": "How does License Manager help in enforcing licensing rules?", "answer": "License Manager helps in enforcing licensing rules by allowing administrators to apply the created rules in different ways to track license usage and compliance. These rules can be attached to specific Amazon Machine Images (AMIs), included in AWS CloudFormation templates, used in Amazon Elastic Compute Cloud (EC2) launch templates, or attached to applications in the AWS Service Catalog. This ensures that end users can launch AWS resources like Amazon EC2 instances with the assurance that they are licensed correctly.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-04T17:46:26.687389"}}
{"question": "How does License Manager integrate with AWS Systems Manager, and what are the benefits?", "answer": "License Manager integrates seamlessly with AWS Systems Manager to help discover software installed on AWS resources and on-premises environments. This integration allows administrators to manage instances running on AWS and in their on-premises data center through a single interface. The benefit of this integration is that it enables secure communication with a lightweight agent installed on servers, facilitating the management of both Windows and Linux operating systems. Additionally, after instances are attached to License Manager, administrators can search for any operating system or application software across AWS resources and on-premises servers and apply licensing rules to the discovered software.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-04T17:46:26.687537"}}
{"question": "What Linux distributions can be onboarded to License Manager for subscription information?", "answer": "The Linux distributions that can be onboarded to License Manager for subscription information are Red Hat Enterprise Linux (RHEL), SUSE Linux Enterprise Server (SLES), and Ubuntu Pro.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-04T17:46:30.419559"}}
{"question": "How does License Manager discover subscriptions for Linux instances?", "answer": "License Manager discovers subscriptions for Linux instances via instance metadata and does not require the use of AWS Systems Manager.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-04T17:46:30.419843"}}
{"question": "What are the capabilities of License Manager regarding cross account and cross region discovery?", "answer": "License Manager allows configuration of cross account and cross region discovery from within a single account, and it also enables delegation of another account to act as a License administrator.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-04T17:46:30.420098"}}
{"question": "What types of software can be tracked using AWS License Manager?", "answer": "AWS License Manager can track software that is licensed based on virtual cores (vCPUs), physical cores, sockets, or number of instances. This includes a variety of software products from vendors such as Microsoft, Oracle, IBM, and SAP, including Oracle databases, Microsoft Windows Servers, and SQL Server licenses.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-04T17:46:36.654807"}}
{"question": "How does AWS License Manager assist in managing software licenses across different environments?", "answer": "AWS License Manager assists in managing software licenses by allowing users to track licenses and subscriptions across various AWS services such as EC2 instances, Amazon RDS, AWS Marketplace, and Systems Manager. It also supports tracking licenses for on-premises servers when used with AWS Systems Manager Agent, facilitating centralized license management and compliance.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-04T17:46:36.655179"}}
{"question": "How does AWS License Manager handle licenses for BYOL AMIs compared to traditional license activation methods?", "answer": "AWS License Manager helps associate licensing rules with AWS Marketplace BYOL AMI products and allows for centralized license management tracking and compliance. However, it does not change the traditional process of obtaining or activating BYOL AMIs; users still need to provide the license key obtained directly from the seller to activate the software when launching an EC2 instance.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-04T17:46:36.655571"}}
{"question": "What is the primary function of License Manager in AWS?", "answer": "The primary function of License Manager in AWS is to reduce the risk of non-compliance by increasing transparency and enforcing and tracking licensing rules that administrators define.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-04T17:46:41.810830"}}
{"question": "How does License Manager assist in vendor audits?", "answer": "License Manager assists in vendor audits by providing built-in dashboards that can be used for reporting to procurement and by offering a rich report that provides valuable insights, which help attain more accuracy and transparency during the auditing process.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-04T17:46:41.811107"}}
{"question": "What are the differences between managing licenses in AWS Marketplace and on-premises environments?", "answer": "When you purchase licenses in AWS Marketplace, you can manage distribution and track entitlements using managed entitlements specifically designed for AWS. In contrast, when extending license management to on-premises environments, you can also manage licenses from independent software vendors (ISVs) purchased through AWS Marketplace, allowing for a unified approach across both AWS Cloud accounts and on-premises setups.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-04T17:46:41.811274"}}
{"question": "How can you create a key pair for onboarding through AWS License Manager?", "answer": "You can create a public and private key pair for onboarding through AWS License Manager by using the console or application programming interface (API).", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T17:46:47.673247"}}
{"question": "What is the purpose of the short-lived token in AWS License Manager?", "answer": "The short-lived token in AWS License Manager is used to identify the customer to whom a license is given. It is shared with the customer, who enters it to activate the license when launching the software, allowing the software to pass the token to the API operations and exchange it for a long-lived customer identifier.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T17:46:47.673594"}}
{"question": "How does License Manager track software usage compared to the customer's entitlements?", "answer": "License Manager helps enforce license use by tracking the number of software capabilities customers are using against the amount they are entitled. It monitors usage across all customer identities with access to the licenses, ensuring that when customers stop using the software, they can return the licenses back to the pool or let them expire automatically.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T17:46:47.674056"}}
{"question": "What is the purpose of having an organization-wide tagging strategy in AWS?", "answer": "An organization-wide tagging strategy helps you organize your resources, allocate costs, automate processes, control access, and manage security risk.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-04T17:46:54.340884"}}
{"question": "How does automated discovery work in AWS License Manager?", "answer": "Automated discovery helps you track all instances as you install software. If software is specified in automated discovery rules, License Manager will automatically track those instances. Once you uninstall software, License Manager will automatically stop tracking those instances and make the licenses available for reuse.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-04T17:46:54.341235"}}
{"question": "What happens to license tracking when software is uninstalled in AWS License Manager, and how does this relate to license affinity?", "answer": "When software is uninstalled, License Manager will automatically stop tracking the instances and make the licenses available for reuse. However, if your licenses are node-locked to a physical server, you can use the license affinity property to specify a time period for which your licenses need to be node-locked. During this period, License Manager will continue to account for the usage until the license affinity period has elapsed, even if the software is uninstalled.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-04T17:46:54.341686"}}
{"question": "How does AWS bill for Microsoft Office and Visual Studio instances?", "answer": "AWS bills through a monthly subscription based on the number of users associated with the license for Microsoft Office or Visual Studio instances. These per-user charges are billed per calendar month, starting from the time you subscribe to the product. If you remove access to a user during the existing month, you will still be billed for that user for the remainder of the month, but will stop incurring charges the following month.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-04T17:47:00.165095"}}
{"question": "What is the purpose of Linux subscriptions in AWS License Manager?", "answer": "Linux subscriptions in AWS License Manager help users view and manage commercial Linux subscriptions that their Amazon EC2 instances use. It allows tracking of utilization for the Linux subscriptions across specified AWS Regions and accounts within AWS Organizations. License Manager provides a comprehensive view of the running instances utilizing Linux subscriptions.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-04T17:47:00.165380"}}
{"question": "How are users charged differently for Microsoft Office and Visual Studio compared to Windows Server licenses?", "answer": "Users are charged per user for Microsoft Office and Visual Studio irrespective of the number of EC2 instances they connect to; each user is only counted once. In contrast, Windows Server licenses are bundled with the EC2 instances and are charged per vCPU along with the instance charges.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-04T17:47:00.165881"}}
{"question": "How can I see the usage of Linux subscriptions and set up notifications?", "answer": "To see the usage of Linux subscriptions and set up notifications based on thresholds, you should look at the subscriptions view of the subscription you are interested in. There, you can see usage over time and create alarms based on the thresholds you set. These alarms are set as AWS Cloud Watch notifications, allowing you to receive them in the same way you do other notifications.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-04T17:47:07.520326"}}
{"question": "What is the process for converting the license type of eligible Ubuntu LTS instances?", "answer": "To convert the license type of eligible Ubuntu LTS instances, you can use either the License Manager Console or the AWS CLI. However, the instances must be stopped and associated by AWS Systems Manager Inventory before you can proceed with the conversion.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-04T17:47:07.520680"}}
{"question": "What are the costs associated with using License Manager compared to the resources created in your account?", "answer": "There is no additional charge for using License Manager itself. You only pay for the resources created in your account, which can include Amazon Elastic Compute Cloud (EC2) instances, an Amazon Simple Storage Service (S3) bucket for storing software based on AWS Systems Manager, Amazon Athena queries, AWS Glue jobs for centralized discovery of Systems Manager data, and Amazon Simple Notification Service (SNS) notifications.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-04T17:47:07.521107"}}
{"question": "What is the primary function of Amazon Lookout for Equipment?", "answer": "The primary function of Amazon Lookout for Equipment is to use data from sensors to detect abnormal equipment behavior, allowing users to take action before machine failures occur and avoid unplanned downtime.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:47:13.349926"}}
{"question": "How does Amazon Lookout for Equipment improve the process of monitoring industrial equipment compared to current methods?", "answer": "Amazon Lookout for Equipment improves the process by reducing the number of alerts and avoiding overgeneralized models that do not adapt to unique operating conditions. It allows customers to build custom models tailored to their equipment's specific behavior, thus enhancing detection of abnormal behavior such as failure patterns or inefficient processes.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:47:13.350233"}}
{"question": "In what ways does Amazon Lookout for Equipment provide cost effectiveness compared to traditional methods of model deployment?", "answer": "Amazon Lookout for Equipment is priced based on usage, allowing customers to set up and automate training and inferencing processes in a cost-effective manner. This contrasts with traditional methods which may involve higher fixed costs and less flexibility in deployment.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-04T17:47:13.350664"}}
{"question": "What types of data can Lookout for Equipment work with?", "answer": "Lookout for Equipment is designed to work with any time series analog data, commonly referred to as data tags. This can include data such as temperature, flow rates, and rpms from components including sensors and actuators, as long as the tags vary over time and are relevant to the machines condition and/or process characteristics.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-04T17:47:20.322719"}}
{"question": "How does Lookout for Equipment differ from other machine learning products that use pre-trained models?", "answer": "Lookout for Equipment does not use pre-trained models due to the wide variety of industrial equipment types and operating environments. Instead, it builds a custom model on every data set it is given, learning the normal operating behavior specific to the equipment and its unique operating environment.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-04T17:47:20.323017"}}
{"question": "What is the maximum number of sensors that Lookout for Equipment allows for one model compared to its intended application?", "answer": "Lookout for Equipment allows up to a maximum of 300 sensors (tags) for one model. It is built for applications involving stationary equipment that operate continuously with limited variability in their operating conditions, such as rotating equipment like pumps and compressors.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-04T17:47:20.323429"}}
{"question": "What types of files does Lookout for Equipment work with?", "answer": "Lookout for Equipment works with CSV files.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-04T17:47:24.413074"}}
{"question": "What is the primary purpose of Amazon Lookout for Equipment?", "answer": "The primary purpose of Amazon Lookout for Equipment is to provide real-time abnormal state detection for industrial process equipment that operates continuously and with low variability in operating conditions.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-04T17:47:24.413417"}}
{"question": "How does Lookout for Equipment differ in its effectiveness between industrial process equipment and construction equipment?", "answer": "Lookout for Equipment is effective for industrial process equipment that operates continuously and has low variability in operating conditions, such as compressors and turbines. In contrast, it may not be effective for construction equipment, such as cranes and trucks, as well as highly variable equipment, vehicles, robots, and CNC machines.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-04T17:47:24.413871"}}
{"question": "What types of data should be used for Amazon Lookout for Equipment?", "answer": "The data set should be time series data generated from an industrial asset such as a pump, compressor, or motor. Each asset should be generating data from sensors (tags) that are representative of the condition and/or operation of the asset.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-04T17:47:29.582687"}}
{"question": "Why is it important to ensure the relevance of data when using Amazon Lookout for Equipment?", "answer": "Ensuring the relevance of data is crucial because the success of using Amazon Lookout for Equipment is highly dependent on the relevancy of your data to the equipment issues. If the data is not relevant, it may lead to inadequate detection of equipment problems.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-04T17:47:29.583005"}}
{"question": "How does the number of inputs affect the effectiveness of Amazon Lookout for Equipment?", "answer": "Having too few inputs may result in missing critical information, while having too many inputs might dilute the impact of key inputs on the detection process. Therefore, it is essential to choose the inputs that are crucial to the equipment.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-04T17:47:29.583417"}}
{"question": "What is the main purpose of storing and using content processed by Amazon Lookout for Equipment?", "answer": "The main purpose of storing and using content processed by Amazon Lookout for Equipment is to provide and maintain the service, and to improve and develop the quality of the service and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T17:47:34.904986"}}
{"question": "How does Amazon Lookout for Equipment ensure the security and privacy of user content?", "answer": "Amazon Lookout for Equipment ensures the security and privacy of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, the content. They prioritize trust, privacy, and security in their operations.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T17:47:34.905303"}}
{"question": "What happens to content processed by Amazon Lookout for Equipment if a user opts out of having their content used for improvement?", "answer": "If a user opts out of having their content used for improvement, the content will not be stored in another AWS region. Additionally, the user can request deletion of content associated with their account by contacting AWS Support.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-04T17:47:34.905907"}}
{"question": "What is the first step to start using Amazon Lookout for Equipment?", "answer": "The first step to start using Amazon Lookout for Equipment is to visit the Amazon Lookout for Equipment pricing page.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-04T17:47:39.309220"}}
{"question": "What benefits does the AWS Free Tier provide to new users of Amazon Lookout for Equipment?", "answer": "The AWS Free Tier provides new users with instant access to Amazon Lookout for Equipment, allowing them to start building without incurring costs immediately.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-04T17:47:39.309520"}}
{"question": "How does access to the AWS Management Console relate to using Amazon Lookout for Equipment?", "answer": "Access to the AWS Management Console is essential for getting started with Amazon Lookout for Equipment, as it allows users to build and manage their equipment monitoring solutions.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-04T17:47:39.309954"}}
{"question": "What does Amazon Lookout for Metrics do?", "answer": "Amazon Lookout for Metrics uses machine learning to accurately detect anomalies in customer metrics after they upload their data. It automatically inspects the data, creates anomaly detection models, groups related anomalies, and provides a severity score for quick diagnosis of issues or maximization of opportunities.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T17:47:45.858641"}}
{"question": "How does Amazon Lookout for Metrics support customers who have little to no historical data?", "answer": "Amazon Lookout for Metrics can learn as it goes, meaning that customers do not need to provide historical data for training the models to get started. The time it takes for Lookout for Metrics to learn and detect anomalies will vary based on the customer's data.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T17:47:45.858877"}}
{"question": "In what ways does Amazon Lookout for Metrics improve the user experience compared to traditional anomaly detection methods?", "answer": "Amazon Lookout for Metrics improves the user experience by automating the anomaly detection process using machine learning, allowing users without machine learning experience to get started quickly. It also groups concurrent anomalies into logical groups and sends a single alert for the group, ranking anomalies by severity, which helps customers focus on the most critical issues immediately. Additionally, it continuously improves its accuracy and performance through human-in-the-loop feedback.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T17:47:45.859267"}}
{"question": "What format does Lookout for Metrics support for data input?", "answer": "Lookout for Metrics uses data in CSV or JSON format.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 446, "generated_at": "2026-02-04T17:47:50.339681"}}
{"question": "How does Lookout for Metrics learn and provide results to customers?", "answer": "Lookout for Metrics learns from the customer's live data and starts showing results after an initialization period, which depends on the frequency of the data being provided (for example, every 5 minutes, 10 minutes, 1 hour, or 24 hours).", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 446, "generated_at": "2026-02-04T17:47:50.340003"}}
{"question": "How does the pricing model of Lookout for Metrics work compared to traditional software models?", "answer": "The pricing model of Lookout for Metrics differs from traditional software models as customers only pay for what they use, with no up-front commitment or minimum fee required.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 446, "generated_at": "2026-02-04T17:47:50.340509"}}
{"question": "When will new customers no longer have access to Lookout for Vision?", "answer": "New customers will no longer have access to Lookout for Vision effective October 10, 2024.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-04T17:47:54.784943"}}
{"question": "What should existing customers do before October 31, 2025?", "answer": "Existing customers should move their application to an alternative solution and migrate their data off of Lookout for Vision before October 31, 2025.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-04T17:47:54.785982"}}
{"question": "How does the functionality of edge applications running Lookout for Vision change after the cloud service is discontinued?", "answer": "After the cloud service is discontinued on October 31, 2025, edge applications running Lookout for Vision will continue to run but will not be able to be updated with new model training.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-04T17:47:54.786167"}}
{"question": "What will happen to images stored in S3 for import into Lookout for Vision after the service is discontinued?", "answer": "Images that are stored in S3 for import into Lookout for Vision will not be impacted and will remain available after the Lookout for Vision service is discontinued.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:47:59.704275"}}
{"question": "What is the primary purpose of Amazon Lookout for Vision?", "answer": "The primary purpose of Amazon Lookout for Vision is to help increase industrial production quality and reduce operational costs by identifying visual defects in objects. It allows users to automate the quality inspection process using computer vision.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:47:59.704537"}}
{"question": "How does the ability to use models change after the Lookout for Vision service is discontinued?", "answer": "After the Lookout for Vision service is discontinued, you will not have the ability to train or deploy a new or updated model. However, any models that were packaged before the service is discontinued can continue to be used, and you can still build new models until the discontinuation date on October 31, 2025.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-04T17:47:59.704930"}}
{"question": "What are some common use cases for Amazon Lookout for Vision?", "answer": "The most common use cases for Amazon Lookout for Vision include detecting damages to parts such as welds, dents, cracks, bubbles, surface color, and shape of objects; identifying missing components related to absence, presence, and placement of objects within a certain tolerance; and uncovering process issues by detecting defects with a repeating pattern that may indicate a process issue.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-04T17:48:09.281578"}}
{"question": "How does Amazon Lookout for Vision simplify the process of anomaly detection compared to traditional deep learning methods?", "answer": "Amazon Lookout for Vision simplifies the process of anomaly detection by being fully managed, which means users do not have to build, maintain, or understand machine learning or deep learning pipelines. Traditional deep learning methods require proper tuning, training with labeled ground truth data, and significant investment in sourcing, cleaning, and labeling data, as well as training using custom hardware like GPUs. Lookout for Vision provides anomaly detection techniques out of the box, allowing users to focus on maximizing business value without investing time and resources into creating a deep learning pipeline.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-04T17:48:09.281855"}}
{"question": "How does the number of images required for training affect the accuracy of an anomaly detection model in Amazon Lookout for Vision?", "answer": "The number of images required to train an anomaly detection model in Amazon Lookout for Vision depends on the variability in the production line and the quality of the training data. For scenarios with constant conditions like lighting and alignment, as few as 30 images can be sufficient to start, while more complex cases with many variations may require hundreds of high-quality training examples. Although a high number of images is beneficial for achieving high accuracy, users can initially train a model with fewer images, review test results, and iteratively improve the model by adding new training images.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-04T17:48:09.282320"}}
{"question": "Will I be charged for compute resources if my training fails in Amazon Lookout for Vision?", "answer": "No, you will not be charged for the compute resources if your training fails.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T17:48:14.177863"}}
{"question": "What factors influence the throughput of a single inference compute resource in Amazon Lookout for Vision?", "answer": "The throughput of a single resource depends on factors including the size of the images, the complexity of those images, and the complexity of the defect detection model.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T17:48:14.178107"}}
{"question": "How does the process of provisioning models in Amazon Lookout for Vision relate to image processing and potential charges?", "answer": "You should monitor the frequency at which you need to provision your model and the number of images that need to be processed at a single time to schedule provisioning efficiently. After completing production line integration, you should provision your model at a scheduled time, process all your images, and then stop provisioning. If you dont stop provisioning, you will be charged even if no images are processed.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-04T17:48:14.178519"}}
{"question": "What types of hardware devices can Amazon Lookout for Vision models be deployed on?", "answer": "Amazon Lookout for Vision models can be deployed on any NVIDIA Jetson edge appliance or x86 compute platform running Linux with an NVIDIA GPU accelerator.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-04T17:48:18.679641"}}
{"question": "How does the AWS Free Tier benefit users of Amazon Lookout for Vision?", "answer": "The AWS Free Tier allows users to get started with Amazon Lookout for Vision for free for 3 months, which includes 10 free cloud training hours, up to 4 free cloud inference hours per month, and up to 5 free edge inference units per month.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-04T17:48:18.679919"}}
{"question": "How does the pricing for Amazon Lookout for Vision differ based on model usage?", "answer": "Amazon Lookout for Vision charges are based on the duration of training and inference minutes, meaning you are only charged when your Lookout for Vision model is actively being used to detect anomalies.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-04T17:48:18.680130"}}
{"question": "What is the primary purpose of storing and using image inputs processed by Amazon Lookout for Vision?", "answer": "The primary purpose of storing and using image inputs processed by Amazon Lookout for Vision is to provide and maintain the service, as well as to improve and develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T17:48:26.127483"}}
{"question": "How does Amazon Lookout for Vision ensure the security and privacy of user content?", "answer": "Amazon Lookout for Vision ensures the security and privacy of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, user content. They prioritize trust, privacy, and security and ensure that their use complies with commitments made to users.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T17:48:26.127857"}}
{"question": "What happens to your content if you opt out of having it used for improving Amazon Lookout for Vision?", "answer": "If you opt out of having your content used to develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies, your content will not be stored in another AWS region. Additionally, you can request deletion of content associated with your account by contacting AWS Support.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-04T17:48:26.128391"}}
{"question": "What can you access instantly with the AWS Free Tier?", "answer": "You can instantly get access to the AWS Free Tier.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-04T17:48:29.352746"}}
{"question": "What can you start building with in the AWS Management Console?", "answer": "You can start building with Amazon Lookout for Vision in the AWS Management Console.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-04T17:48:29.353083"}}
{"question": "How does accessing the AWS Free Tier relate to using Amazon Lookout for Vision?", "answer": "Accessing the AWS Free Tier allows you to get started building with Amazon Lookout for Vision in the AWS Management Console.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-04T17:48:29.353503"}}
{"question": "What type of data does Amazon Macie help discover?", "answer": "Amazon Macie helps discover sensitive data types, including personally identifiable information (PII) such as names, addresses, and credit card numbers.", "question_type": "factual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:48:35.861207"}}
{"question": "How does Amazon Macie provide visibility into data security risks?", "answer": "Amazon Macie provides visibility into data security risks by using machine learning and pattern matching to discover sensitive data at scale, allowing users to see the data stored in Amazon Simple Storage Service (Amazon S3) and the associated risks.", "question_type": "conceptual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:48:35.861547"}}
{"question": "How does the cost structure of Amazon Macie differ for single accounts versus multi-account configurations?", "answer": "In a single account, Amazon Macie charges based on the number of S3 buckets evaluated, the number of S3 objects monitored, and the quantity of data inspected. In a multi-account configuration, the cost estimate is rolled up across all accounts, providing a total cost estimate after each accounts free trial ends.", "question_type": "comparison", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-04T17:48:35.862148"}}
{"question": "How can Macie be enabled for use in AWS?", "answer": "Macie can be enabled with one selection in the AWS Management Console or through a single API call.", "question_type": "factual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:48:40.080414"}}
{"question": "What is the purpose of adding custom-defined data types in Macie?", "answer": "The purpose of adding custom-defined data types using regular expressions in Macie is to help discover proprietary or unique sensitive data specific to your business, such as a specific format for employee IDs.", "question_type": "conceptual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:48:40.080763"}}
{"question": "How does the 30-day free trial for Macie differ for new and existing accounts?", "answer": "The 30-day free trial for Macie offers the same benefit of no charge for automated sensitive data discovery to both new and existing accounts, allowing them to try the service without cost during this period.", "question_type": "comparison", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:48:40.081154"}}
{"question": "What is Amazon Managed Grafana?", "answer": "Amazon Managed Grafana is a fully managed multicloud, cross-project service that provides rich, interactive data visualizations. It helps customers analyze, monitor, and set alarms on metrics, logs, and traces across multiple data sources. Users can create interactive dashboards, manage user and team access, and securely access various AWS services.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:48:46.794242"}}
{"question": "How does Amazon Managed Grafana enhance the user experience for managing data sources?", "answer": "Amazon Managed Grafana enhances the user experience by providing an intuitive resource discovery experience that helps users easily onboard their AWS accounts across multiple regions. It allows secure access to various AWS services, facilitating the integration of multiple data sources for analysis and visualization.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:48:46.794579"}}
{"question": "What is the difference between a workspace in Amazon Managed Grafana and the open source Grafana?", "answer": "A workspace in Amazon Managed Grafana is a logically isolated Grafana server that can be integrated with data sources for querying and visualization. While both Amazon Managed Grafana and the open source Grafana utilize the same visualization capabilities, Amazon Managed Grafana is a fully managed service developed in partnership with Grafana Labs, allowing for easier management and scaling compared to self-hosted open source Grafana.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-04T17:48:46.795101"}}
{"question": "What services does Amazon Managed Grafana integrate with to discover AWS accounts and resources?", "answer": "Amazon Managed Grafana integrates with AWS Organizations to discover the AWS accounts and resources in your Organizational Units.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-04T17:48:51.742571"}}
{"question": "How does Amazon Managed Grafana facilitate access to AWS Services data for different accounts and Regions?", "answer": "Amazon Managed Grafana uses AWS CloudFormation StackSets to automatically create the IAM policies needed to grant read-only access to your AWS Services data for the accounts and Regions you choose.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-04T17:48:51.742914"}}
{"question": "What is the difference between the core plugins and the Enterprise plugins offered by Amazon Managed Grafana?", "answer": "Amazon Managed Grafana ships with core plugins to connect to commonly used data sources like Amazon Managed Service for Prometheus and Amazon CloudWatch, while the Enterprise plugins include access to additional data source plugins such as AppDynamics, Atlassian Jira, Datadog, and more. To access Enterprise plugins, users must upgrade their Amazon Managed Grafana workspace.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-04T17:48:51.743124"}}
{"question": "What user permissions do Administrators have in Amazon Managed Grafana?", "answer": "Administrators have add, edit, and delete permissions to manage data sources, users, teams, folders, and dashboards in Amazon Managed Grafana.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T17:48:56.809965"}}
{"question": "How can you manage Amazon Managed Grafana workspaces using AWS CloudFormation?", "answer": "You can use AWS CloudFormation templates to create, update, and delete your Amazon Managed Grafana workspaces, as well as manage or update workspace SAML authentication settings.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T17:48:56.810304"}}
{"question": "How do the permissions of Editors differ from those of Viewers in Amazon Managed Grafana?", "answer": "Editors have view, add, edit, and delete permissions to dashboards and alerts, while Viewers can only view dashboards to which they have been granted access, and cannot add, edit, or delete data sources, dashboards, or alerts.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T17:48:56.810846"}}
{"question": "What feature allows users to group individuals for shared access to resources in Amazon Managed Grafana?", "answer": "Teams provide a grouping mechanism to organize users in Amazon Managed Grafana, allowing users to group individual users into entities that are granted access to shared resources such as dashboards, data sources, and alerts.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-04T17:49:02.256685"}}
{"question": "How does Team Sync work in Amazon Managed Grafana?", "answer": "With Team Sync enabled, you can keep team membership and user identities in sync with your Identity Provider's user directories, such as Azure Active Directory, Microsoft Active Directory, CyberArk, Okta, OneLogin, and Ping Identity.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-04T17:49:02.257013"}}
{"question": "What are the differences in connectivity options for Amazon Managed Grafana workspaces in relation to VPCs?", "answer": "Currently, you can connect one Amazon Managed Grafana workspace to one VPC endpoint in the same region and same account. However, by using Virtual Private Cloud peering or AWS Transit Gateway, you can connect cross-region or cross-account VPCs and then select a VPC endpoint thats in the same account and same region as your Amazon Managed Grafana workspace. This allows data sources from different accounts or regions to be connected to a single Amazon Managed Grafana workspace.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-04T17:49:02.257578"}}
{"question": "Can I connect to public data sources after configuring a VPC connection in Amazon Managed Grafana?", "answer": "Yes, you can still connect to public data sources after you configure the VPC connection in Amazon Managed Grafana workspace. However, requests to public data sources must traverse your VPC, and you must ensure that the VPC is able to reach the previously connected data sources since all traffic will now route through the VPC connection.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T17:49:08.806663"}}
{"question": "What are the two modes of access for Amazon Managed Grafana workspaces?", "answer": "Amazon Managed Grafana supports two modes for user and host access of your Grafana workspace: open access and restricted access. The open access mode is the default setting when there are no VPC endpoints or managed prefix list restrictions, allowing users to access the workspace after authenticating with identity providers. The restricted access mode allows you to specify the inbound network traffic that can reach your workspace, using prefix lists to define allowed IP address ranges.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T17:49:08.807017"}}
{"question": "How does open access mode differ from restricted access mode in Amazon Managed Grafana workspaces?", "answer": "In open access mode, which is the default setting, there are no VPC endpoints or managed prefix list restrictions, allowing users to access the Grafana workspace after authenticating with identity providers. In contrast, restricted access mode enables you to control and specify the inbound network traffic allowed to access the workspace, using customer-managed prefix lists to define the IP address ranges from which access is permitted.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-04T17:49:08.807230"}}
{"question": "How many plugins can you install in Amazon Managed Grafana?", "answer": "You can install up to 50 data source, app, or visualization panel plugins from the Plugin catalog, in addition to the core plugins that are pre-installed in your workspace.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-04T17:49:15.158702"}}
{"question": "What is the primary way to authenticate applications that interact with Grafana as of version 9?", "answer": "As of Grafana version 9, Service accounts have replaced API keys as the primary way to authenticate applications that interact with Grafana using Service Account Tokens.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-04T17:49:15.159011"}}
{"question": "What is the difference in user roles and pricing between Editor and Viewer users in Amazon Managed Grafana?", "answer": "Editor users can be assigned Administrator or Editor roles and are priced at the Editor user price, while Viewer users can only be assigned a Viewer role and are priced at the Viewer user price. Additionally, if you upgrade your workspace with Amazon Managed Grafana Enterprise Plugins, you will incur an additional fee per active user per month for both types of users.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-04T17:49:15.159569"}}
{"question": "How are users billed when they belong to multiple workspaces in Amazon Managed Grafana?", "answer": "Users are billed per workspace per month. For example, if User A belongs to both Workspace 1 and Workspace 2, User A will be billed for using Workspace 1 and separately billed for using Workspace 2.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T17:49:21.371280"}}
{"question": "What are the three types of API requests when working with an Amazon Managed Grafana workspace?", "answer": "The three types of API requests are: 1) Amazon Managed Grafana APIs, which are used to create, edit, and delete workspaces and do not incur charges; 2) Grafana HTTP API requests, which manage workspace resources like dashboards and alerts, billed per API user license; and 3) Amazon Managed Grafana data queries made to other AWS services and third-party ISVs, which may charge fees that are not charged by Amazon Managed Grafana.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T17:49:21.371664"}}
{"question": "What is the difference in billing between using API user licenses and making data queries to AWS Services or third-party ISVs?", "answer": "API user licenses are billed per user license, whether for API keys or Service accounts, and these charges appear on your AWS bill under the Amazon Managed Grafana section. In contrast, data queries made to AWS Services or third-party ISVs may incur additional API fees that are charged by the respective AWS service or third-party ISV, not by Amazon Managed Grafana.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-04T17:49:21.371878"}}
{"question": "What do new versions of Grafana introduce that may impact visualizations or automation workflows?", "answer": "New versions of Grafana introduce breaking changes, which may impact your visualizations or automation workflows.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-04T17:49:25.809681"}}
{"question": "Why is manual control over Grafana workspace versioning important?", "answer": "Manual control over Grafana workspace versioning is important because it allows you to validate your Grafana experience against new versions of Grafana before upgrading production workspaces.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-04T17:49:25.810015"}}
{"question": "How does manual control over Grafana workspace versioning compare to automatic upgrades?", "answer": "Manual control over Grafana workspace versioning allows you to validate your experience against new versions before upgrading, whereas automatic upgrades do not provide this opportunity for validation and may lead to unexpected impacts on visualizations or automation workflows due to breaking changes.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-04T17:49:25.810540"}}
{"question": "What is the primary function of the Amazon Managed Service for Apache Flink?", "answer": "The primary function of the Amazon Managed Service for Apache Flink is to transform and analyze streaming data in real time using Apache Flink, which is an open source framework and engine for processing data streams.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-04T17:49:31.063476"}}
{"question": "How does Amazon Managed Service for Apache Flink simplify the use of Apache Flink applications?", "answer": "Amazon Managed Service for Apache Flink simplifies the use of Apache Flink applications by reducing the complexity involved in building, managing, and integrating these applications with other AWS services.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-04T17:49:31.063720"}}
{"question": "In what ways does Amazon Managed Service for Apache Flink differ from traditional server management?", "answer": "Unlike traditional server management, Amazon Managed Service for Apache Flink does not require users to manage servers, has no minimum fee or setup cost, and users only pay for the resources their streaming applications consume. Additionally, it automatically scales to match the volume and throughput of incoming data.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-04T17:49:31.063869"}}
{"question": "What are the four most common use cases for Amazon Managed Service for Apache Flink?", "answer": "The four most common use cases for Amazon Managed Service for Apache Flink are streaming extract-transform-load (ETL), continuous metric generation, responsive real-time analytics, and interactive querying of data streams.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-04T17:49:36.442215"}}
{"question": "How does streaming ETL with Amazon Managed Service for Apache Flink differ from traditional batch ETL processes?", "answer": "Streaming ETL with Amazon Managed Service for Apache Flink allows for real-time processing of data, cleaning, enriching, organizing, and transforming raw data before loading it into a data lake or data warehouse, thereby reducing or eliminating the need for batch ETL steps. This contrasts with traditional batch ETL processes which typically involve waiting for large volumes of data to be collected before processing occurs, resulting in delays.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-04T17:49:36.442562"}}
{"question": "In what ways are continuous metric generation applications beneficial compared to traditional data reporting methods?", "answer": "Continuous metric generation applications provide real-time insights by aggregating streaming data into critical information and integrating it seamlessly with reporting databases and monitoring services. This allows applications and users to receive timely updates, such as live leaderboards or real-time website traffic tracking, compared to traditional methods that may only provide updates at scheduled intervals or after batch processes.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-04T17:49:36.443067"}}
{"question": "What is the purpose of responsive real-time analytics applications?", "answer": "The purpose of responsive real-time analytics applications is to send real-time alarms or notifications when certain metrics reach predefined thresholds or detect anomalies using machine learning algorithms. This allows businesses to respond immediately to changes, such as predicting user abandonment in mobile apps and identifying degraded systems.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-04T17:49:41.917230"}}
{"question": "How does interactive analysis of data streams benefit stream processing applications?", "answer": "Interactive analysis of data streams benefits stream processing applications by allowing for real-time data exploration through ad hoc queries or programs. It enables users to inspect streams from Amazon MSK or Amazon Kinesis Data Streams, visualize data within those streams, and continuously update queries as new data arrives. This facilitates iterative development and ensures that the queries can run continuously with features like auto scaling and durable state backups.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-04T17:49:41.917574"}}
{"question": "How do Amazon Kinesis Data Streams and Amazon SNS work together in responsive real-time analytics applications?", "answer": "Amazon Kinesis Data Streams and Amazon Simple Notification Service (Amazon SNS) work together in responsive real-time analytics applications by allowing an application to look for events that meet specific criteria and then automatically notify the right customers. Kinesis Data Streams helps in processing streams of data, while SNS is used to send notifications based on the processed data.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-04T17:49:41.918069"}}
{"question": "What can you use to create a new stream processing application in Amazon Managed Service for Apache Flink?", "answer": "You can create a new stream processing application in Amazon Managed Service for Apache Flink by signing in to the Flink console, or you can use the AWS CLI and AWS SDKs.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:49:46.456129"}}
{"question": "What are the benefits of using Amazon Managed Service for Apache Flink for real-time applications?", "answer": "The benefits of using Amazon Managed Service for Apache Flink for real-time applications include automatic scaling to match the volume and throughput of incoming data, as well as taking care of everything required to continuously run your applications.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:49:46.456477"}}
{"question": "How does creating an application using Apache Beam compare to creating one using Apache Flink directly?", "answer": "Creating an application using Apache Beam is very similar to creating one using Apache Flink directly, as both require following similar instructions to get started. However, it is important to note that Amazon Managed Service for Apache Flink only supports Java SDK when running on Apache Beam.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-04T17:49:46.456989"}}
{"question": "What is the purpose of Amazon Managed Service for Apache Flink?", "answer": "The purpose of Amazon Managed Service for Apache Flink is to elastically scale your application to accommodate the data throughput of your source stream and your query complexity for most scenarios. It allows for the continuous reading and processing of streaming data in real time.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T17:49:52.109623"}}
{"question": "How do Apache Flink applications utilize AWS Glue Schema Registry?", "answer": "Apache Flink applications can utilize AWS Glue Schema Registry through Apache Flink DataStream Connectors. This allows the applications to use AWS Glue Schema Registry as a serverless feature, enabling integration with data sources such as Apache Kafka, Amazon MSK, and Amazon Kinesis Data Streams.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T17:49:52.109972"}}
{"question": "How does the input component of an Amazon Managed Service for Apache Flink application differ from the output component?", "answer": "The input component of an Amazon Managed Service for Apache Flink application is the streaming source that maps to data streams, allowing data to flow from data sources into these streams. In contrast, the output component is where you can optionally configure the application to persist data to an external destination after processing. Inputs are added in the application code and API, while outputs can also be configured in the same way but focus on data persistence.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T17:49:52.110457"}}
{"question": "What programming languages does Amazon Managed Service for Apache Flink support for application development?", "answer": "Amazon Managed Service for Apache Flink supports applications built using Java, Scala, and Python with the open source Apache Flink libraries and your own custom code. It also supports applications built using Java with the open source Apache Beam libraries and your own custom code.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T17:49:56.940924"}}
{"question": "Why is it important to create IAM roles for Amazon Managed Service for Apache Flink?", "answer": "It is important to create IAM roles for Amazon Managed Service for Apache Flink because the service needs permissions to read records from the streaming data sources specified in the application and to write application output to specified destinations. The permissions granted to these roles determine what actions the service can perform when it assumes the role.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T17:49:56.941261"}}
{"question": "How does Amazon Managed Service for Apache Flink Studio differ from Amazon Managed Service for Apache Flink in terms of supported code?", "answer": "Amazon Managed Service for Apache Flink Studio supports code built using Apache Flinkcompatible SQL, Python, and Scala, whereas Amazon Managed Service for Apache Flink supports applications built using Java, Scala, and Python with Apache Flink libraries, as well as Java applications using Apache Beam libraries.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-04T17:49:56.941759"}}
{"question": "What is the capacity provided by one KPU in Amazon Managed Service for Apache Flink?", "answer": "One KPU provides you with 1 vCPU and 4 GB of memory.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-04T17:50:00.039449"}}
{"question": "How does Amazon Managed Service for Apache Flink handle application scaling?", "answer": "Amazon Managed Service for Apache Flink elastically scales your application to accommodate the data throughput of your source stream and your query complexity for most scenarios.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-04T17:50:00.039831"}}
{"question": "What happens if multiple subnets are specified for Amazon Managed Service for Apache Flink?", "answer": "If multiple subnets are specified, they must all be in the same VPC.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-04T17:50:00.040256"}}
{"question": "What is the default internet access configuration for Amazon Managed Service for Apache Flink applications in a VPC?", "answer": "Amazon Managed Service for Apache Flink applications and Amazon Managed Service for Apache Flink Studio notebooks that are configured to access resources in a particular VPC do not have access to the internet as a default configuration.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:50:06.179812"}}
{"question": "How does Amazon Managed Service for Apache Flink determine the number of KPUs required for a streaming application?", "answer": "Amazon Managed Service for Apache Flink automatically scales the number of KPUs required by your stream processing application as the demands of memory and compute vary in response to processing complexity and the throughput of streaming data processed.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:50:06.180105"}}
{"question": "How do the minimum KPU charges differ between Apache Flink applications and Amazon Managed Service for Apache Flink Studio notebooks?", "answer": "For Apache Flink and Apache Beam applications, there is a minimum charge of 2 KPUs and 50 GB running application storage if the application is running. In contrast, for Amazon Managed Service for Apache Flink Studio notebooks, the minimum charge is 3 KPUs and 50 GB running application storage if the application is running.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-04T17:50:06.180661"}}
{"question": "Is Amazon Managed Service for Apache Flink available in the AWS Free Tier?", "answer": "No, Amazon Managed Service for Apache Flink is not currently available in the AWS Free Tier.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T17:50:12.994614"}}
{"question": "What are the main functions of Apache Flink in stream processing?", "answer": "Apache Flink provides powerful operators for stream and batch data processing, offering solutions to core streaming problems such as duplicate processing. It also facilitates data distribution, communication, and fault tolerance for distributed computations over data streams.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T17:50:12.994952"}}
{"question": "How do application data streams and operators interact in Apache Flink?", "answer": "Application data streams are the data structures that you perform processing against using your code, where data continuously flows from the sources into these streams. Stream operators take an application data stream as input and send processed data to an application data stream as output. Operators can be connected to build applications with multiple steps, allowing for both serial and parallel processing without requiring advanced knowledge of distributed systems.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-04T17:50:12.995447"}}
{"question": "What operators does Amazon Managed Service for Apache Flink support?", "answer": "Amazon Managed Service for Apache Flink supports all operators from Apache Flink, including map, KeyBy, aggregations, windows, joins, and more.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-04T17:50:17.917334"}}
{"question": "How does the KeyBy operator function in Amazon Managed Service for Apache Flink?", "answer": "The KeyBy operator logically organizes data using a specified key, allowing you to process similar data points together.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-04T17:50:17.917685"}}
{"question": "How do the streaming data sources and destinations differ in Amazon Managed Service for Apache Flink?", "answer": "Streaming data sources in Amazon Managed Service for Apache Flink include Amazon Managed Streaming for Apache Kafka (Amazon MSK) and Amazon Kinesis Data Streams, while destinations or sinks include Amazon Kinesis Data Streams, Amazon Kinesis Data Firehose, Amazon DynamoDB, Amazon Elasticsearch Service, and Amazon S3 through file sink integrations.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-04T17:50:17.918114"}}
{"question": "What is the default delivery model used by Apache Flink applications in Amazon Managed Service for Apache Flink?", "answer": "The default delivery model used by Apache Flink applications in Amazon Managed Service for Apache Flink is an exactly-once delivery model, provided that the application is built using idempotent operators, including sources and sinks.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-04T17:50:23.639591"}}
{"question": "How does the running application storage in Amazon Managed Service for Apache Flink support application state and data caching?", "answer": "Amazon Managed Service for Apache Flink provides 50 GB of running application storage per KPU, which is used for saving application state through checkpoints. This storage is also accessible to application code for temporary disk use, such as caching data or other purposes. Furthermore, all data stored in running application storage is encrypted at rest.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-04T17:50:23.639930"}}
{"question": "What is the difference between checkpoints and snapshots in Apache Flink applications?", "answer": "Checkpoints save the current application state and enable Amazon Managed Service for Apache Flink applications to recover the application position to provide the same semantics as a failure-free execution, using running application storage. In contrast, snapshots save a point-in-time recovery point for applications and use durable application backups. Snapshots are analogous to Flink savepoints.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-04T17:50:23.640442"}}
{"question": "What does Amazon Managed Service for Apache Flink allow you to do with snapshots?", "answer": "Amazon Managed Service for Apache Flink allows you to create and restore your application to a previous point in time using snapshots. You can maintain previous application state and roll back your application at any time. Additionally, you control how many snapshots you have at any given time, from zero to thousands.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-04T17:50:29.812684"}}
{"question": "How does Amazon Managed Service for Apache Flink handle data security in snapshots?", "answer": "Amazon Managed Service for Apache Flink encrypts data saved in snapshots by default, ensuring that your application data is secure.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-04T17:50:29.813027"}}
{"question": "What is the relationship between Apache Beam and Amazon Managed Service for Apache Flink?", "answer": "Amazon Managed Service for Apache Flink supports streaming applications built using Apache Beam. You can build Apache Beam streaming applications in Java and run them on Amazon Managed Service for Apache Flink, among other engines and services.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-04T17:50:29.813542"}}
{"question": "What languages can you use to write code in the Amazon Managed Service for Apache Flink Studio notebook?", "answer": "You can write code in SQL, Python, or Scala in the Amazon Managed Service for Apache Flink Studio notebook.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-04T17:50:35.854088"}}
{"question": "What is the purpose of the Table API in Apache Flink, and what operations does it support?", "answer": "The Table API in Apache Flink is a high-level abstraction and relational API that supports a superset of SQLs capabilities. It offers familiar operations such as select, filter, join, group by, aggregate, and also includes stream-specific concepts like windowing.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-04T17:50:35.854431"}}
{"question": "How does the transition from a notebook to a stream processing application work in the Amazon Managed Service for Apache Flink?", "answer": "Once the code is ready to run as a production application, you can transition to a stream processing application by either clicking 'Deploy as stream processing application' in the notebook interface or issuing a single command in the CLI. Studio manages all the necessary infrastructure for running the application at scale, including features like auto scaling and durable state.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-04T17:50:35.854869"}}
{"question": "What SQL operations can you perform with Apache Flink?", "answer": "You can perform SQL operations such as Scan and filter (SELECT, WHERE), Aggregations (GROUP BY, GROUP BY WINDOW, HAVING), Set operations (UNION, UNIONALL, INTERSECT, IN, EXISTS), Order operations (ORDER BY, LIMIT), Joins (INNER, OUTER, Timed Window  BETWEEN, AND, Joining with Temporal Tables), Top-N, Deduplication, and Pattern recognition.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:50:46.105620"}}
{"question": "How does Apache Flink handle results for certain queries when processing streaming data?", "answer": "For streaming data, certain queries such as GROUP BY, OUTER JOIN, and Top-N are results updating, which means that the results are continuously updated as the streaming data is processed.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:50:46.106135"}}
{"question": "What are the differences in data sources and destinations supported by Apache Flink?", "answer": "The data sources supported by Apache Flink include Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, and Amazon S3. The destinations or sinks also include Amazon MSK, Amazon Kinesis Data Streams, and Amazon S3.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-04T17:50:46.106265"}}
{"question": "What is the guaranteed Monthly Uptime Percentage for Amazon Managed Service for Apache Flink?", "answer": "The guaranteed Monthly Uptime Percentage for Amazon Managed Service for Apache Flink is at least 99.9%.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-04T17:50:51.844245"}}
{"question": "Under what conditions can a user be eligible for an SLA Service Credit for Amazon Managed Service for Apache Flink?", "answer": "A user can be eligible for an SLA Service Credit for Amazon Managed Service for Apache Flink if more than one Availability Zone in which they are running a task, within the same AWS Region, has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-04T17:50:51.844606"}}
{"question": "How does the SLA Service Credit eligibility relate to Availability Zones and Monthly Uptime Percentage?", "answer": "The SLA Service Credit eligibility is related to Availability Zones in that it requires more than one Availability Zone to have a Monthly Uptime Percentage of less than 99.9% within the same AWS Region for the user to qualify for the credit.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-04T17:50:51.845085"}}
{"question": "What is Amazon Managed Service for Prometheus?", "answer": "Amazon Managed Service for Prometheus is a serverless monitoring service for metrics that is compatible with open source Prometheus. It is designed to securely monitor and alert on container environments and is a fully managed AWS service that supports monitoring across AWS, on-premises, and hybrid and multicloud environments.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-04T17:50:58.485178"}}
{"question": "How does Amazon Managed Service for Prometheus simplify the monitoring of applications?", "answer": "Amazon Managed Service for Prometheus reduces the heavy lifting required to get started with monitoring applications across various platforms, including Amazon Elastic Kubernetes Service, Amazon Elastic Container Service, AWS Fargate, and self-managed Kubernetes clusters. It automatically scales as monitoring needs grow and integrates AWS security and compliance capabilities.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-04T17:50:58.485540"}}
{"question": "What are the key features of Amazon Managed Service for Prometheus compared to traditional Prometheus deployments?", "answer": "Amazon Managed Service for Prometheus offers features such as being a fully managed service, automatic scaling based on monitoring needs, highly available multi-Availability Zone deployments, and integration with AWS security and compliance capabilities. In contrast, traditional Prometheus deployments typically require manual management of the infrastructure and scaling.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-04T17:50:58.485974"}}
{"question": "What are the benefits of using Amazon Managed Service for Prometheus?", "answer": "The benefits of using Amazon Managed Service for Prometheus include a fully managed experience across AWS or multiple cloud providers, enhanced security, scalability, and availability. It also manages the operational complexity of scaling the ingestion, storage, alerting, and querying of metrics. Additionally, it eliminates the need to manually deploy, manage, and operate Prometheus components, and seamlessly integrates with Amazon Managed Grafana for data visualization.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-04T17:51:05.655592"}}
{"question": "How does Amazon Managed Service for Prometheus handle high cardinality in monitoring data?", "answer": "Amazon Managed Service for Prometheus is specifically architected to handle high cardinality, which refers to the large number of arbitrary tags in monitoring data generated by container-based applications. This architecture allows it to efficiently manage and organize the numerous time series that can be generated from these applications.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-04T17:51:05.655878"}}
{"question": "What is the relationship between labels in Prometheus and AWS tags?", "answer": "Labels in the Prometheus data model are similar to AWS tags applied on resources. Both labels and tags can be used to differentiate characteristics of the entities being monitored or managed. For example, labels might include key-value pairs like 'region=us-east-1' or 'environment=production', which provide context about the monitored metrics, just like AWS tags help categorize resources.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-04T17:51:05.656033"}}
{"question": "What API calls related to Amazon Managed Service for Prometheus are not recorded by CloudTrail?", "answer": "The following API calls related to Amazon Managed Service for Prometheus are not recorded and delivered by CloudTrail: remote_write, query, query_range, labels, label/{name}/values, series, and metadata.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 444, "generated_at": "2026-02-04T17:51:12.141892"}}
{"question": "What are the primary use cases for Amazon CloudWatch compared to Amazon Managed Service for Prometheus?", "answer": "Amazon CloudWatch is used for comprehensive observability across logs, metrics, and traces for applications running on various AWS services, including EC2 and serverless architectures. It provides features such as custom and automatic dashboards, alarms, and synthetic monitoring. In contrast, Amazon Managed Service for Prometheus is specifically optimized for monitoring container-based workloads and offers Prometheus-compatible APIs for ingesting and querying Prometheus metrics, focusing solely on metrics without collecting logs or traces.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 444, "generated_at": "2026-02-04T17:51:12.142259"}}
{"question": "How does Amazon Managed Service for Prometheus differ from Amazon CloudWatch in terms of data collection?", "answer": "Amazon Managed Service for Prometheus is a metric-only service that does not collect logs or distributed trace data, while Amazon CloudWatch provides a comprehensive solution that includes logs, metrics, and traces for applications. Thus, Amazon Managed Service for Prometheus focuses solely on Prometheus metrics, whereas Amazon CloudWatch encompasses a broader range of observability data.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 444, "generated_at": "2026-02-04T17:51:12.142752"}}
{"question": "What is Amazon Managed Grafana?", "answer": "Amazon Managed Grafana is a fully managed service that is compatible with the open source Grafana project. It simplifies the process for engineering teams to query, visualize, and alert on data sources such as metrics, logs, and traces, regardless of where they are stored.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:51:18.820517"}}
{"question": "How does Amazon Managed Service for Prometheus enhance the capabilities of the open source Prometheus project?", "answer": "Amazon Managed Service for Prometheus is based on the popular Cloud Native Computing Foundation (CNCF) Prometheus project and is powered by Cortex, which adds horizontal scalability to ingest, store, query, and alert on Prometheus metrics. This service is committed to ongoing open source contributions and collaborates with the community to improve the scale and reliability of this and other open source projects.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:51:18.820884"}}
{"question": "What are the similarities between Amazon Managed Grafana and Amazon Managed Service for Prometheus?", "answer": "Both Amazon Managed Grafana and Amazon Managed Service for Prometheus share AWS security services, including fine-grained access control and activity audit trails. Additionally, Amazon Managed Grafana offers alerting capabilities that can be used to alert on Prometheus metrics, which connects the functionalities of both services.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-04T17:51:18.821382"}}
{"question": "What is the primary function of the Amazon Managed Service for Prometheus collector?", "answer": "The primary function of the Amazon Managed Service for Prometheus collector is to serve as an agentless scraper that enables customers to automatically discover and monitor their Amazon EKS applications and infrastructure, eliminating the need to manage Prometheus agents for collecting Prometheus metrics.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:25.725586"}}
{"question": "How does the Amazon Managed Service for Prometheus collector differ from AWS Distro for OpenTelemetry (ADOT) in terms of management requirements?", "answer": "The Amazon Managed Service for Prometheus collector is an agentless scraper that does not require customers to manage any Prometheus scrapers, whereas AWS Distro for OpenTelemetry (ADOT) requires customers to install, right-size, and manage the ADOT agent if they wish to utilize it.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:25.725953"}}
{"question": "What are the steps to get started with the Amazon Managed Service for Prometheus collector?", "answer": "To get started with the Amazon Managed Service for Prometheus collector, you can use either the AWS console or APIs. You need to specify the Amazon EKS cluster to scrape, the Prometheus-compatible scrape configuration, the subnets and security groups for connecting to the cluster, and the destination Amazon Managed Service for Prometheus workspace to send the data to. Additionally, in the EKS console, you can enable the agentless collector directly from the create cluster flow.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:25.726479"}}
{"question": "What is Amazon MSK and what does it manage?", "answer": "Amazon MSK is an AWS streaming data service that manages Apache Kafka infrastructure and operations. It simplifies the process for developers and DevOps managers to run Apache Kafka applications and Kafka Connect connectors on AWS, without the need to become experts in operating Apache Kafka.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-04T17:51:31.072552"}}
{"question": "How does Amazon MSK simplify the use of Apache Kafka for developers?", "answer": "Amazon MSK simplifies the use of Apache Kafka for developers by operating, maintaining, and scaling Apache Kafka clusters automatically. It provides enterprise-grade security features out of the box and has built-in AWS integrations that accelerate the development of streaming data applications.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-04T17:51:31.072745"}}
{"question": "How does Amazon MSK differ from traditional Apache Kafka in terms of management and scaling?", "answer": "Amazon MSK differs from traditional Apache Kafka in that it manages the infrastructure and operations for Apache Kafka, which removes the need for users to become experts in operating Apache Kafka. Additionally, Amazon MSK automatically scales Apache Kafka clusters, while traditional setups require manual management and scaling efforts.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-04T17:51:31.072888"}}
{"question": "What are the components of a record in Apache Kafka?", "answer": "Each record in Apache Kafka consists of a key, a value, a timestamp, and sometimes header metadata.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-04T17:51:35.758810"}}
{"question": "How does Apache Kafka ensure the order of records when processing streaming data?", "answer": "Apache Kafka preserves the order of records by storing events as a continuous series of records and allowing data consumers to process data from topics on a first-in-first-out basis.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-04T17:51:35.759145"}}
{"question": "What is the difference between data producers and data consumers in Apache Kafka?", "answer": "Data producers in Apache Kafka, such as websites and IoT devices, continually publish streaming data to topics, while data consumers, such as machine learning applications and AWS Lambda functions, read from these topics at their own rate.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-04T17:51:35.759341"}}
{"question": "What feature of AWS Glue can Apache Kafka clients use at no additional charge?", "answer": "Apache Kafka clients can use the AWS Glue Schema Registry, which is a serverless feature of AWS Glue, at no additional charge.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-04T17:51:41.729208"}}
{"question": "What advantages does Amazon MSK provide for running Apache Kafka on AWS?", "answer": "Amazon MSK makes it easy to get started and run Apache Kafka on AWS with open high availability and security. It offers integrations with AWS services without the operational overhead of running an Apache Kafka cluster, manages the setup, provisioning, AWS integrations, and ongoing maintenance of Apache Kafka clusters.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-04T17:51:41.729553"}}
{"question": "How do provisioned clusters differ from serverless clusters in Amazon MSK?", "answer": "Provisioned clusters in Amazon MSK contain broker instances and abstracted metadata nodes, whereas serverless clusters are a resource in and of themselves that abstract away all underlying resources.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-04T17:51:41.730053"}}
{"question": "What are the main responsibilities of brokers in an Apache Kafka cluster?", "answer": "Brokers in an Apache Kafka cluster are responsible for storing and replicating the data published to Kafka topics, managing the partitions within those topics, handling client requests for producing and consuming messages, and coordinating with each other to maintain the overall state of the Kafka deployment.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T17:51:50.400862"}}
{"question": "How do Standard brokers differ from Express brokers in terms of storage management?", "answer": "With Standard brokers, you need to provision storage and optionally enable provisioned storage throughput for storage volumes to scale I/O without needing additional brokers. In contrast, with Express brokers, you do not need to provision or manage storage at all.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T17:51:50.401241"}}
{"question": "What type of instances can you choose for provisioned clusters in Amazon MSK?", "answer": "For provisioned clusters in Amazon MSK, you can choose EC2 T3.small instances or instances within the EC2 M7g and M5 instance families.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-04T17:51:50.401738"}}
{"question": "What replication strategy does Amazon MSK use for data replication between brokers?", "answer": "Amazon MSK uses Apache Kafkas leader-follower replication to replicate data between brokers.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:56.906892"}}
{"question": "How do Express brokers ensure higher availability compared to Standard brokers in Amazon MSK?", "answer": "Express brokers guarantee higher availability by always replicating your data across three Availability Zones, while Standard brokers allow for a custom replication strategy by topic that may not necessarily enforce such availability.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:56.907235"}}
{"question": "What is the difference in configuration management between Standard brokers and Express brokers in Amazon MSK?", "answer": "Standard brokers allow for more customizable configurations, including the ability to set a custom replication strategy by topic, while Express brokers protect more configurations from suboptimal values that could affect availability and durability, and they also simplify the experience by fully managing the storage layer.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-04T17:51:56.907833"}}
{"question": "What are the two deployment options offered by Amazon MSK for Apache Kafka clusters?", "answer": "The two deployment options offered by Amazon MSK for Apache Kafka clusters are Amazon MSK Provisioned and Amazon MSK Serverless.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-04T17:52:01.872510"}}
{"question": "How does Amazon MSK Provisioned differ from Amazon MSK Serverless in terms of cluster management?", "answer": "Amazon MSK Provisioned allows users to have varying levels of control over their cluster while still removing most of the operational overhead associated with managing Apache Kafka clusters. In contrast, Amazon MSK Serverless fully abstracts cluster scaling and management, enabling users to run applications without the need to provision, configure, or optimize clusters.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-04T17:52:01.872847"}}
{"question": "What are the key differences between the broker types available in MSK Provisioned?", "answer": "In MSK Provisioned, users can choose from various broker types, including Standard and Express brokers. However, the context does not provide specific differences in features or performance between these broker types.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-04T17:52:01.873368"}}
{"question": "What are the two main broker types offered by MSK Provisioned?", "answer": "The two main broker types offered by MSK Provisioned are Standard and Express brokers.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-04T17:52:07.706701"}}
{"question": "How does MSK Provisioned allow users to customize their Apache Kafka clusters?", "answer": "MSK Provisioned allows users to manually configure and scale their Apache Kafka clusters by choosing the instance types, storage volumes on Standard broker type, and the number of broker nodes. Users can also scale their clusters by adding or removing brokers based on their evolving data processing needs, optimizing the clusters for specific workload requirements.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-04T17:52:07.707043"}}
{"question": "What are the key differences between Standard and Express brokers in terms of management and configuration?", "answer": "Standard brokers are customer managed, allowing for more configuration options, including EBS storage, tiered storage, and provisioned storage throughput. In contrast, Express brokers are fully MSK managed, providing higher resilience and ease-of-use with less configurability.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-04T17:52:07.707549"}}
{"question": "What is CloudWatch used for?", "answer": "CloudWatch is used for monitoring resources and applications in the AWS cloud.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-04T17:52:11.779924"}}
{"question": "What does Open Monitoring in the context of CloudWatch imply?", "answer": "Open Monitoring in the context of CloudWatch implies the ability to monitor various resources and applications, potentially including third-party services or custom metrics.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-04T17:52:11.780267"}}
{"question": "How does CloudWatch relate to Open Monitoring?", "answer": "CloudWatch is a service that encompasses Open Monitoring, allowing it to monitor not only AWS resources but also extend to other applications and services.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-04T17:52:11.780850"}}
{"question": "What instance types does Amazon MSK support for running Apache Kafka workloads?", "answer": "Amazon MSK supports AWS Graviton3-based M7g instances from .large through .16xlarge sizes for running all Apache Kafka workloads.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-04T17:52:18.120619"}}
{"question": "How do Graviton instances compare to M5 instances in terms of cost and throughput?", "answer": "Graviton instances offer up to 24% lower costs compared to corresponding M5 instances and provide up to 29% higher throughput per instance compared to Amazon MSK M5 instances.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-04T17:52:18.120962"}}
{"question": "What are the key differences between Standard brokers and Express brokers in Amazon MSK Provisioned?", "answer": "Standard brokers offer the most flexibility for configuring cluster performance, including a wide range of configurations for availability, durability, throughput, and latency, and require manual provisioning of storage. In contrast, Express brokers simplify management, are more cost-effective at scale, automatically scale storage, and recover 90% quicker while providing up to 3x more throughput per broker and scaling up to 20x faster.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-04T17:52:18.121499"}}
{"question": "What are the benefits of using Express brokers compared to Standard brokers in terms of storage management?", "answer": "Express brokers eliminate the need to provision or manage any storage resources, providing elastic, virtually unlimited, pay-as-you-go, and fully managed storage. This simplifies cluster management and removes the operational overhead associated with storage management.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T17:52:24.095230"}}
{"question": "How do Express brokers enhance the scaling capabilities of a cluster?", "answer": "Express brokers allow for faster scaling of the cluster and moving of partitions compared to Standard brokers. This is crucial for handling load spikes or reducing costs by scaling in the cluster. Users can expand their cluster, remove brokers, reassign partitions, and set up LinkedIns Cruise Control for rebalancing.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T17:52:24.095567"}}
{"question": "How does the throughput of Express brokers compare to Standard brokers?", "answer": "Express brokers offer up to 3x more throughput per broker than Standard brokers. For instance, an m7g.16xlarge sized Express broker can write data at up to 500 MBps, whereas the equivalent Standard broker can only handle 153.8 MBps.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-04T17:52:24.096015"}}
{"question": "What features do Express brokers in Amazon MSK offer regarding data encryption?", "answer": "Express brokers in Amazon MSK integrate with AWS Key Management Service (AWS KMS) to provide transparent server-side encryption for the storage. When creating an MSK cluster with Express brokers, you can specify the AWS KMS key for data encryption at rest. If no key is specified, Amazon MSK creates an AWS managed key to use on your behalf. Additionally, Amazon MSK uses TLS to encrypt data in transit for Express brokers.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-04T17:52:31.924990"}}
{"question": "How do Express brokers differ from Standard brokers in terms of configuration flexibility?", "answer": "Express brokers provide a simplified configuration experience, which increases price performance and reduces operational overhead, making them suitable for various Apache Kafka workloads. However, Standard brokers allow for more granular control of broker configurations, enabling users to customize a wider set of Kafka settings such as replication factor, size of log files, and leader election policies. This gives more flexibility over cluster settings compared to Express brokers.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-04T17:52:31.926750"}}
{"question": "What are the similarities and differences between Standard brokers and Express brokers in Amazon MSK?", "answer": "Both Standard brokers and Express brokers in Amazon MSK support most of the same features and capabilities, such as integration with AWS KMS for encryption and using Apache Kafka APIs. However, they differ in storage management, instance type availability, and supported versions, as well as the level of customization available for broker configurations. Standard brokers offer more options for customizing settings compared to Express brokers.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-04T17:52:31.927021"}}
{"question": "What type of capacity management does MSK Serverless provide for Apache Kafka clusters?", "answer": "MSK Serverless makes it easy to run Apache Kafka clusters without having to manage compute and storage capacity, allowing you to run applications without the need to provision, configure, or optimize clusters.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T17:52:38.068492"}}
{"question": "How does MSK Serverless ensure data security and access control?", "answer": "MSK Serverless encrypts all traffic in transit and all data at rest using service-managed keys issued through AWS KMS. It also offers AWS Identity and Access Management (IAM) access control for managing client authentication and authorization to Apache Kafka resources such as topics.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T17:52:38.068687"}}
{"question": "What are the differences in write and read capacity allocations in MSK Serverless?", "answer": "MSK Serverless provides up to 200 MBps of write capacity and 400 MBps of read capacity per cluster. Additionally, it allocates up to 5 MBps of instant write capacity and 10 MBps of instant read capacity per partition to ensure sufficient throughput availability.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-04T17:52:38.068795"}}
{"question": "What does MSK Serverless do when you create a partition?", "answer": "When you create a partition, MSK Serverless creates two replicas of it and places them in different Availability Zones. Additionally, MSK Serverless automatically detects and recovers failed backend resources to maintain high availability.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-04T17:52:46.285985"}}
{"question": "How does Amazon MSK ensure the security of its resources within a VPC?", "answer": "Amazon MSK always runs within an Amazon VPC managed by the Amazon MSK service. The resources will be available to your own Amazon VPC, subnet, and security group that you select when the cluster is set up. IP addresses from your VPC are attached to Amazon MSK resources through ENIs, and all network traffic stays within the AWS network and is not accessible to the internet by default. The security groups on the ENIs will dictate the source and type of ingress and egress traffic allowed on your brokers.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-04T17:52:46.287465"}}
{"question": "What is the difference between enabling public access and keeping Amazon MSK resources private?", "answer": "Enabling public access allows authorized clients external to a private Amazon VPC to stream encrypted data in and out of specific Amazon MSK clusters running Apache Kafka 2.6.0 or later versions. In contrast, keeping Amazon MSK resources private means that all network traffic stays within the AWS network and is not accessible to the internet by default. Public access can be enabled for MSK clusters after a cluster has been created at no additional cost, but standard AWS data transfer costs for cluster ingress and egress apply.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-04T17:52:46.287738"}}
{"question": "What is the default method for data production and consumption from an Amazon MSK cluster?", "answer": "By default, the only way data can be produced and consumed from an Amazon MSK cluster is over a private connection between your clients in your VPC and the Amazon MSK cluster.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:52:50.752166"}}
{"question": "What are the recommendations for configuring security groups when public access is enabled for an MSK cluster?", "answer": "When public access is enabled for an MSK cluster, it is recommended to configure the cluster's security groups to have inbound TCP rules that allow public access from your trusted IP address and to make these rules as restrictive as possible.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:52:50.752511"}}
{"question": "How does private connectivity differ from public access in terms of connection security for an MSK cluster?", "answer": "Private connectivity allows for a secure connection to the MSK cluster using Amazon MSK managed VPC connections with PrivateLink technology, while public access, although authenticated, authorized, and encrypted, is no longer considered private.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-04T17:52:50.753063"}}
{"question": "What options do you have for authentication and authorization in provisioned clusters?", "answer": "For provisioned clusters, you can use IAM access control for both authentication and authorization, which is recommended. Alternatively, you can use TLS certificate authentication for authentication and access control lists for authorization, or SASL/SCRAM for authentication and access control lists for authorization.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-04T17:52:55.650409"}}
{"question": "Why is IAM access control recommended for Amazon MSK?", "answer": "IAM access control is recommended for Amazon MSK because it is the easiest to use and defaults to least privilege access, making it the most secure option.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-04T17:52:55.650680"}}
{"question": "How does authorization differ between IAM access control and TLS/SASL authentication in Amazon MSK?", "answer": "With IAM access control, Amazon MSK uses the policies you write and its own authorizer to authorize actions. In contrast, if you are using TLS certificate authentication or SASL/SCRAM, Apache Kafka uses access control lists (ACLs) for authorization.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-04T17:52:55.650898"}}
{"question": "What factors influence the cost of monitoring an Apache Kafka cluster using CloudWatch?", "answer": "The cost of monitoring your cluster using CloudWatch is dependent on the monitoring level and the size of your Apache Kafka cluster. CloudWatch charges per metric per month and includes an AWS Free Tier.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T17:53:00.984940"}}
{"question": "How does the default set of Amazon MSK metrics differ from partition-level metrics in terms of cost?", "answer": "Topic-level metrics are included in the default set of Amazon MSK metrics, which are free of charge. In contrast, partition-level metrics are charged according to Amazon CloudWatch pricing.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T17:53:00.985182"}}
{"question": "What logging capabilities does Amazon MSK provide for brokers within a provisioned cluster?", "answer": "Amazon MSK provides INFO-level logs for all brokers within a provisioned cluster. Additionally, you can enable broker log delivery to Amazon CloudWatch Logs, Amazon S3, and Amazon Data Firehose.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-15", "source_tokens": 502, "generated_at": "2026-02-04T17:53:00.985592"}}
{"question": "What protocol does Amazon MSK use for metadata management?", "answer": "Amazon MSK uses Apache ZooKeeper for metadata management.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-04T17:53:06.018180"}}
{"question": "What is the main advantage of using KRaft mode over ZooKeeper mode in Kafka clusters?", "answer": "The main advantage of using KRaft mode over ZooKeeper mode is that it allows metadata to be stored and replicated as topics within Kafka brokers, resulting in faster propagation of metadata.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-04T17:53:06.018520"}}
{"question": "How does the number of partitions per broker compare between KRaft-based clusters and ZooKeeper-based clusters?", "answer": "The number of partitions per broker is the same on KRaft- and ZooKeeper-based clusters. However, KRaft allows you to host more partitions per cluster by provisioning more brokers in a cluster.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-04T17:53:06.019003"}}
{"question": "Which AWS service is used for delivering data to Amazon S3 from Amazon MSK in a no-code manner?", "answer": "Amazon S3 uses Firehose for delivering data to Amazon S3 from Amazon MSK in a no-code manner.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-04T17:53:10.022641"}}
{"question": "What are the primary roles of AWS KMS and IAM in the context of Amazon MSK?", "answer": "AWS KMS is used for storage volume encryption, while IAM is used for authentication and authorization of Apache Kafka and service APIs.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-04T17:53:10.022978"}}
{"question": "How does Amazon MSK Serverless differ from Amazon MSK in terms of AWS service integration?", "answer": "Amazon MSK Serverless integrates with AWS PrivateLink for private connectivity, which is not mentioned for Amazon MSK.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-04T17:53:10.023518"}}
{"question": "What types of MSK clusters does MSK Replicator support for replication?", "answer": "MSK Replicator supports replication across both Provisioned and Serverless types of MSK clusters.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-04T17:53:16.965855"}}
{"question": "How does cross-Region replication enhance the resiliency of streaming applications?", "answer": "Cross-Region replication helps build highly available and fault-tolerant multi-Region streaming applications, which increases resiliency by ensuring that data is replicated across different AWS Regions, enabling lower latency access to consumers in various geographic regions.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-04T17:53:16.966180"}}
{"question": "What is the difference between cross-Region replication and same-Region replication in MSK Replicator?", "answer": "Cross-Region replication is used to replicate data across MSK clusters in different AWS Regions, which enhances availability and provides lower latency for consumers in various regions. In contrast, same-Region replication is used to distribute data from one cluster to many clusters within the same AWS Region for sharing data with partners and teams, or to aggregate data from multiple clusters into one for analytics.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-04T17:53:16.966708"}}
{"question": "What metrics can be viewed in CloudWatch for MSK Replicator?", "answer": "You can view metrics for ReplicationLatency, MessageLag, and ReplicatorThroughput at a topic and aggregate level for each Replicator in CloudWatch. These metrics are visible under ReplicatorName in the AWS/Kafka namespace. Additionally, you can see the ReplicatorFailure, AuthError, and ThrottleTime metrics to check if your Replicator is encountering any issues.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-04T17:53:26.386260"}}
{"question": "What is the difference between active-active and active-passive cluster topologies in MSK Replicator?", "answer": "In an active-active setup, both MSK clusters are actively serving reads and writes, meaning that data can be processed simultaneously by both clusters. In contrast, an active-passive setup allows only one MSK cluster at a time to actively serve streaming data, while the other cluster remains on standby.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-04T17:53:26.387425"}}
{"question": "How does MSK Replicator handle authentication compared to other authentication methods?", "answer": "MSK Replicator uses IAM access control to connect to your source and target clusters, requiring that both clusters be enabled for IAM access control to create a Replicator. However, you can simultaneously use other authentication methods such as SASL/SCRAM and mTLS for your clients, as Amazon MSK supports multiple authentication methods at the same time.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-04T17:53:26.387675"}}
{"question": "What prefix does MSK Replicator add to the topic names in the target cluster?", "answer": "MSK Replicator adds an auto-generated prefix to the topic names in the target cluster, which is based on the sourceKafkaClusterAlias. For instance, if the sourceKafkaClusterAlias is 'exampleCluster', the new topic in the target cluster would be called 'exampleCluster.topic'.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-04T17:53:33.084237"}}
{"question": "How does MSK Replicator affect other consumers on the source cluster?", "answer": "Since MSK Replicator acts as a consumer for your source cluster, it is possible that replication can cause other consumers to be throttled on the source cluster. This effect depends on the read capacity of the source cluster and the throughput of the data being replicated.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-04T17:53:33.084607"}}
{"question": "What options are available for compression codecs when creating an MSK Replicator, and how do they compare?", "answer": "When creating an MSK Replicator, you can choose from the following compression codecs: None, GZIP, Snappy, LZ4, and ZSTD. These options allow you to select a compression method based on your specific needs for data throughput and storage efficiency.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-04T17:53:33.085084"}}
{"question": "How can you scale up storage in a provisioned MSK cluster?", "answer": "You can scale up storage in your provisioned cluster running on Standard brokers using the AWS Management Console or AWS CLI. Additionally, you can create an auto scaling storage policy using the AWS Management Console or by creating an AWS Application Auto Scaling policy using the AWS CLI or APIs.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-04T17:53:40.420169"}}
{"question": "What is the difference between Standard brokers and Express brokers in terms of storage management?", "answer": "With Standard brokers, you can scale up storage and manage it using the AWS Management Console or AWS CLI. They also support tiered storage for virtually unlimited data without adding more brokers. In contrast, with Express brokers, you do not need to provision or manage storage, and you also have access to virtually unlimited storage without the same level of management required.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-04T17:53:40.420536"}}
{"question": "What happens to completed log segments in Apache Kafka when they reach a certain size?", "answer": "When completed log segments in Apache Kafka reach a specified size configured at the cluster or topic level, they are copied to the low-cost storage tier. Data is retained in performance-optimized storage for a specified retention time or size and is then deleted. There is a separate time and size limit setting for the low-cost storage, which is longer than that of the primary storage tier.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-04T17:53:40.421101"}}
{"question": "What are the data transfer charges for provisioned clusters in Amazon MSK?", "answer": "With provisioned clusters, you will pay standard AWS data transfer charges for data transferred in and out of an MSK cluster. However, there are no charges for data transfer within the cluster in a Region, including data transfer between brokers and data transfer between brokers and metadata management nodes.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-04T17:53:48.681933"}}
{"question": "How does the data transfer charging structure differ between provisioned and serverless clusters in Amazon MSK?", "answer": "In provisioned clusters, you are charged for data transferred in and out of the MSK cluster but not for data transferred within the cluster in a Region. In contrast, with serverless clusters, you will pay standard AWS data transfer charges for data transferred to or from another Region and for data transferred out to the public internet.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-04T17:53:48.682279"}}
{"question": "What is the guaranteed Monthly Uptime Percentage for Amazon MSK, and what happens if Multi-AZ deployments fall below this percentage?", "answer": "The Amazon MSK SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Amazon MSK, including MSK Serverless and MSK Connect. If Multi-AZ deployments on Amazon MSK have a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle, you are eligible for an SLA credit for Amazon MSK under the Amazon MSK SLA.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-04T17:53:48.682781"}}
{"question": "What is Amazon Managed Workflows for Apache Airflow (MWAA) used for?", "answer": "Amazon Managed Workflows for Apache Airflow (MWAA) is a managed Apache Airflow service used to extract business insights across an organization by combining, enriching, and transforming data through a series of tasks called a workflow.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T17:53:55.330775"}}
{"question": "Why should teams use Amazon MWAA instead of managing their own Airflow environment?", "answer": "Teams should use Amazon MWAA to spend more engineering and data science time building workflows and less time managing the infrastructure and Airflow environment. It allows for consistent performance from the managed service and eliminates the need for hands-on operations such as configuring, maintaining servers, and monitoring, which are typically required when using Airflow independently.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T17:53:55.331125"}}
{"question": "How does the management of Airflow in Amazon MWAA differ from managing a self-hosted Airflow environment?", "answer": "In Amazon MWAA, the management of Airflow is handled by the service, which includes provisioning infrastructure capacity, installing software, and providing user management through AWS Identity and Access Management (IAM) and Single Sign-On (SSO). In contrast, a self-hosted Airflow environment requires teams to manage the worker fleet, install dependencies, scale the system, and restart the scheduler themselves, leading to more hands-on operations.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-04T17:53:55.331545"}}
{"question": "What is Amazon MWAA and what functionalities does it provide?", "answer": "Amazon MWAA is a workflow environment designed for data engineers and data scientists to build workflows using various AWS, on-premise, and other cloud services. It enables workflows to retrieve input from sources like S3 using Athena queries, perform transformations on EMR clusters, and train machine learning models on SageMaker. Workflows in Amazon MWAA are authored as Directed Acyclic Graphs (DAGs) using Python.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-04T17:54:03.732018"}}
{"question": "What are the advantages of using Amazon MWAA over other workflow solutions?", "answer": "The key advantages of using Amazon MWAA include its open source nature and portability. It has a large and active open source community that regularly contributes new functionality and integrations. Additionally, Amazon MWAA supports existing Airflow workflows and integrations without the need for code changes, making migration easy and the environment familiar for users.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-04T17:54:03.732268"}}
{"question": "How does Amazon MWAA compare to Step Functions in terms of usage scenarios?", "answer": "Amazon MWAA should be used when prioritizing open source and portability, as it allows for easy integration and support for existing workflows. In contrast, Step Functions are recommended when prioritizing cost and performance, especially in scenarios like processing streaming data through multiple steps before storing it in a DynamoDB database or S3, where it offers higher performance at a lower cost.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-04T17:54:03.732656"}}
{"question": "What are the authentication methods supported by the AWS Console Mobile Application?", "answer": "The AWS Console Mobile Application supports several authentication methods, including owner/root credentials, IAM user credentials, and federated login via AWS Single Sign-On, Microsoft Active Directory, and third-party identity providers.", "question_type": "factual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-04T17:54:10.465727"}}
{"question": "Why is it recommended to use IAM user credentials or a federated role to log in to the Console Mobile Application?", "answer": "It is recommended to use IAM user credentials or a federated role to log in to the Console Mobile Application for security reasons. IAM users can be deactivated if a device is lost, preventing unauthorized access, whereas root accounts cannot be deactivated.", "question_type": "conceptual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-04T17:54:10.466086"}}
{"question": "How does the AWS Console Mobile Application support security compared to using a root account?", "answer": "The AWS Console Mobile Application supports security by allowing the use of IAM user credentials, which can be deactivated if a device is lost, whereas root accounts cannot be deactivated, making them less secure in case of device loss.", "question_type": "comparison", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-04T17:54:10.466517"}}
{"question": "What software authenticators are supported by the AWS Console Mobile App?", "answer": "The AWS Console Mobile App supports software authenticators such as Google Authenticator, Microsoft Authenticator, and LastPass Authenticator.", "question_type": "factual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:54:16.672296"}}
{"question": "What is the recommended security practice for using the AWS Console Mobile App?", "answer": "It is recommended to use either a hardware MFA device or a virtual MFA on a separate mobile device for the greatest level of account protection, in addition to using a password or biometric lock on your mobile device.", "question_type": "conceptual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:54:16.672633"}}
{"question": "How does the capability to create resources differ between the AWS CloudShell service and the mobile app's graphical user interface?", "answer": "Currently, the only way to create resources from the mobile app is through the AWS CloudShell service using the AWS Command Line Interface (AWS CLI). In contrast, while the mobile app's graphical user interface allows users to view and sometimes modify resources, it does not support the creation of resources.", "question_type": "comparison", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T17:54:16.673164"}}
{"question": "What type of database service is Amazon MemoryDB?", "answer": "Amazon MemoryDB is a Valkey- and Redis OSS-compatible, durable, in-memory database service that delivers ultra-fast performance.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:54:21.857063"}}
{"question": "How does Amazon MemoryDB ensure data durability and consistency?", "answer": "Amazon MemoryDB ensures data durability and consistency by storing the entire dataset in memory and leveraging a distributed transactional log, which provides in-memory speed while maintaining data durability, consistency, and recoverability.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:54:21.857400"}}
{"question": "How does MemoryDB Multi-Region compare to a single-region setup in terms of availability?", "answer": "MemoryDB Multi-Region offers up to 99.999% availability, which is likely higher than a single-region setup, although the specific availability percentage for a single-region setup is not mentioned in the context.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T17:54:21.857890"}}
{"question": "What types of data does MemoryDB support?", "answer": "MemoryDB supports all Valkey and Redis OSS data types such as strings, lists, sets, hashes, sorted sets, hyperloglogs, bitmaps, and streams.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T17:54:28.687442"}}
{"question": "How does MemoryDB manage redundancy and failover within a cluster?", "answer": "In a MemoryDB cluster, each shard has a primary node that serves read and write requests, and up to 5 optional replica nodes that only serve read requests. If the primary node fails, it can failover to a replica node, promoting that replica to the new primary node for that shard.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T17:54:28.687808"}}
{"question": "What is the main difference between a primary node and a replica node in a MemoryDB cluster?", "answer": "The primary node in a MemoryDB cluster serves both read and write requests, while a replica node only serves read requests. Additionally, the primary node can failover to a replica node if necessary, promoting the replica to become the new primary node.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-04T17:54:28.688306"}}
{"question": "What is Amazon MemoryDB primarily used for?", "answer": "Amazon MemoryDB is primarily used as a durable, in-memory database for workloads that require an ultra-fast, Valkey- or Redis OSS-compatible primary database. It is suitable for applications that need durable databases providing ultra-fast performance with microsecond read and single-digit millisecond write latency.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T17:54:36.308640"}}
{"question": "Why would someone choose to use MemoryDB instead of ElastiCache?", "answer": "Someone would choose to use MemoryDB instead of ElastiCache if their workload requires a durable database that offers ultra-fast performance, as MemoryDB provides durability and performance benefits. Additionally, MemoryDB simplifies application architecture and can lower costs by replacing the need for a cache with a durable database, while ElastiCache is primarily focused on caching data to accelerate access from other databases.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T17:54:36.308989"}}
{"question": "How do the availability and latency features of MemoryDB Multi-Region compare to standard MemoryDB?", "answer": "MemoryDB Multi-Region offers up to 99.999% availability and maintains microsecond read and single-digit millisecond write latency, similar to standard MemoryDB. However, MemoryDB Multi-Region also provides data redundancy across multiple AWS Regions and includes features like active-active replication and automatic conflict resolution, enhancing the availability and resiliency of applications built across multiple Regions.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-04T17:54:36.309511"}}
{"question": "What is the primary purpose of using MemoryDB Multi-Region?", "answer": "The primary purpose of using MemoryDB Multi-Region is to build applications that require the highest levels of availability, increased resiliency, and improved business continuity. It is also suitable for multi-Region applications that need fast response times anywhere in the world.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:54:43.858174"}}
{"question": "How does MemoryDB Multi-Region handle data replication and conflict resolution?", "answer": "MemoryDB Multi-Region replicates data across regional clusters in a configuration called a multi-Region cluster. When data is written to any regional cluster, it is automatically and asynchronously replicated to all other regional clusters, typically within one second, without affecting the application's performance. Additionally, MemoryDB Multi-Region automatically resolves update conflicts and corrects for data divergence issues in the background, ensuring that there is no impact on the application's availability.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:54:43.858525"}}
{"question": "What can you do if you want to add a new regional cluster to a MemoryDB Multi-Region cluster?", "answer": "To add a new regional cluster to a MemoryDB Multi-Region cluster, you can create regional clusters in the respective AWS Regions. However, you cannot add an existing MemoryDB cluster to an existing MemoryDB Multi-Region cluster; you can only create a new regional cluster or remove an existing one from the multi-Region cluster.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T17:54:43.859040"}}
{"question": "What data structure does MemoryDB Multi-Region use to handle conflicting concurrent writes?", "answer": "MemoryDB Multi-Region uses Conflict-free Replicated Data Type (CRDT) to reconcile between conflicting concurrent writes.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-04T17:54:48.789825"}}
{"question": "How does MemoryDB Multi-Region ensure data durability and consistency?", "answer": "MemoryDB ensures data durability and consistency by storing the entire data set in memory and using a distributed Multi-AZ transactional log. This setup allows for fast database recovery and restart, while the in-memory storage provides ultra-fast performance and high throughput.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-04T17:54:48.790213"}}
{"question": "How does the write latency of MemoryDB compare to its read latency?", "answer": "MemoryDB delivers microsecond read latency and single-digit millisecond write latency. This indicates that read operations are significantly faster than write operations, with read latency occurring in microseconds and write latency occurring in single-digit milliseconds.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-04T17:54:48.790468"}}
{"question": "What is the maximum number of replicas that can be created in different availability zones (AZs) for a MemoryDB cluster?", "answer": "You can create a MemoryDB cluster with up to 5 replicas in different AZs.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T17:54:56.466249"}}
{"question": "How does MemoryDB ensure data consistency during a primary node failure?", "answer": "MemoryDB ensures data consistency during a primary node failure by utilizing a distributed transactional log, which keeps the data on replicas up-to-date. When a failure occurs, MemoryDB automatically fails over and promotes one of the replicas to serve as the new primary, directing write traffic to it. Only data that has been successfully persisted in the multi-AZ transaction log is visible, ensuring that data is not lost across failovers.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T17:54:56.466541"}}
{"question": "How does the consistency model of MemoryDB compare to that of Valkey and Redis OSS in terms of data loss during failover?", "answer": "The consistency model of MemoryDB is similar to that of Valkey and Redis OSS; however, in MemoryDB, data is not lost across failovers, allowing clients to read their writes from primaries regardless of node failures. In contrast, Valkey and Redis OSS can experience data loss during a failover, as writes can become lost, violating the consistency model.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-5", "source_tokens": 467, "generated_at": "2026-02-04T17:54:56.466710"}}
{"question": "What improvements does MemoryDB version 7.0 for Redis OSS introduce?", "answer": "MemoryDB version 7.0 for Redis OSS introduces enhanced IO multiplexing, which delivers additional improvements to throughput and latency at scale.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-04T17:55:03.703200"}}
{"question": "Why is enhanced IO multiplexing beneficial for throughput-bound workloads?", "answer": "Enhanced IO multiplexing is ideal for throughput-bound workloads with multiple client connections because its benefits scale with the level of workload concurrency. It allows each dedicated network IO thread to pipeline commands from multiple clients into the MemoryDB engine, thus taking advantage of the engine's ability to efficiently process commands in batches.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-04T17:55:03.703465"}}
{"question": "How does the performance of MemoryDB version 7.2 for Valkey compare to MemoryDB version 6 for Redis OSS?", "answer": "MemoryDB version 7.2 for Valkey, which supports enhanced IO multiplexing, can achieve up to 46% increased throughput and up to 21% decreased P99 latency when compared with MemoryDB version 6 for Redis OSS, especially under conditions with high concurrency.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-04T17:55:03.703856"}}
{"question": "What are the two methods for resizing a MemoryDB cluster?", "answer": "You can resize your MemoryDB cluster both horizontally and vertically. Horizontal resizing involves adding or removing nodes and shards, while vertical resizing involves changing your node type to adjust memory and CPU resources per node.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:55:09.840053"}}
{"question": "What advantages does MemoryDB provide during maintenance and updates of a cluster?", "answer": "MemoryDB makes maintenance and updates easy by automatically patching the cluster during specified maintenance windows for mandatory updates. Additionally, it allows for service updates to be applied at any time or scheduled for future maintenance windows, helping to strengthen security, reliability, and operational performance, all while keeping the cluster online to serve read and write requests.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:55:09.840373"}}
{"question": "How does the process of creating snapshots compare to restoring a MemoryDB cluster?", "answer": "Creating snapshots involves backing up the data and metadata of your MemoryDB cluster either manually or through an automated scheduler, while restoring a MemoryDB cluster can be done from a snapshot or from a Valkey or Redis OSS RDB file when creating a new cluster. Snapshots are stored in Amazon S3 and can be retained for up to 35 days, whereas restoration can utilize either snapshots or RDB files.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-04T17:55:09.840791"}}
{"question": "What is the first step to migrate data from ElastiCache to MemoryDB?", "answer": "The first step to migrate data from ElastiCache to MemoryDB is to create a snapshot of your ElastiCache cluster and export it to your S3 bucket.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-04T17:55:16.235554"}}
{"question": "How does MemoryDB ensure data security during transit and at rest?", "answer": "MemoryDB supports encryption of your data both at-rest and in-transit. For encryption at rest, you can use AWS Key Management Service customer managed keys (CMK) or a MemoryDB provided key. Additionally, with Graviton2 instances for your MemoryDB cluster, your data is encrypted in memory using always-on 256-bit DRAM encryption.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-04T17:55:16.235803"}}
{"question": "What are the differences in how MemoryDB and ElastiCache handle data access control?", "answer": "MemoryDB uses Access Control Lists (ACLs) to control both authentication and authorization for the cluster, allowing different permissions for different users. In contrast, the context does not specify how ElastiCache handles data access control, so a direct comparison cannot be made.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-04T17:55:16.236196"}}
{"question": "What is data tiering used for in MemoryDB clusters?", "answer": "Data tiering is used when you need an easier and more cost-effective way to scale data capacity for your MemoryDB clusters without sacrificing your applications availability. It is ideal for workloads that access up to 20% of their data regularly and for applications that can tolerate additional latency for less-frequently accessed items.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-04T17:55:24.130173"}}
{"question": "How does MemoryDB manage data placement when data tiering is enabled?", "answer": "When data tiering is enabled, MemoryDB manages data placement by transparently moving items between memory and disk using a least-recently used (LRU) policy. When memory is fully consumed, MemoryDB detects which items were least-recently used and moves their values to disk, optimizing cost. When an application needs to retrieve an item from disk, MemoryDB moves its value back to memory before serving the request, with minimal impact to performance.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-04T17:55:24.130462"}}
{"question": "What are the differences in capacity and cost savings between R6gd nodes and R6g nodes in MemoryDB?", "answer": "R6gd nodes have nearly 5x more total capacity (memory + SSD) compared to R6g nodes, which are memory only. Additionally, using R6gd nodes with data tiering can help achieve over 60% storage cost savings when running at maximum utilization, compared to R6g nodes.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-04T17:55:24.130964"}}
{"question": "What types of nodes does MemoryDB offer reserved nodes for?", "answer": "MemoryDB offers reserved nodes for the memory optimized R6g, R7g, and R6gd (with data tiering) nodes.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-04T17:55:31.168707"}}
{"question": "How does size flexibility for MemoryDB reserved nodes benefit AWS users?", "answer": "Size flexibility for MemoryDB reserved nodes benefits AWS users by allowing them to automatically apply the discounted reserved node rate to usage of all sizes within the same node family, reducing the time spent managing reserved nodes and enabling them to maximize their discount even when capacity needs change.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-04T17:55:31.169015"}}
{"question": "How do the pricing factors for MemoryDB reserved nodes differ from the costs associated with data written or Snapshot Storage?", "answer": "The pricing for MemoryDB reserved nodes is based on node type, term duration (one- or three-year), payment option (No Upfront, Partial Upfront, All Upfront), and AWS Region, while reserved node prices do not cover costs related to data written or Snapshot Storage.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-04T17:55:31.169422"}}
{"question": "What is the main advantage of using vector search for MemoryDB in AI/ML applications?", "answer": "The main advantage of using vector search for MemoryDB in AI/ML applications is its ability to deliver the fastest vector search performance at the highest recall rates among popular vector databases on AWS, making it well suited for use cases where peak performance is a critical selection criterion.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-04T17:55:37.702619"}}
{"question": "How does vector search for MemoryDB balance speed and recall rates when configuring AI/ML-driven applications?", "answer": "Vector search for MemoryDB balances speed and recall rates by providing the highest throughput with single-digit millisecond query and update response times while storing the vectors in memory, thus not compromising on recall even when prioritizing speed.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-04T17:55:37.702924"}}
{"question": "How does the indexing process of vector embeddings in MemoryDB compare to traditional data storage solutions?", "answer": "In MemoryDB, vector embeddings are indexed and stored in memory as JSON or hash data types, allowing for efficient search queries, prefiltering, and fast updates within single-digit milliseconds. Traditional data storage solutions may not offer the same level of speed, recall, or capability to handle vector embeddings directly.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-04T17:55:37.703303"}}
{"question": "What is AWS Transform and what does it do?", "answer": "AWS Transform is the first agentic AI service developed to accelerate enterprise migration and modernization of .NET, mainframe, and VMware workloads. It deploys specialized AI agents to automate complex tasks such as assessments, code analysis, refactoring, decomposition, dependency mapping, validation, and transformation planning, significantly reducing project timelines.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:55:44.083417"}}
{"question": "How does AWS Migration Hub assist organizations in their cloud transformation journey?", "answer": "AWS Migration Hub assists organizations by providing access to tools needed to collect and inventory existing IT assets, analyze application components and infrastructure dependencies, and group resources into applications. It allows users to generate migration strategy and EC2 instance recommendations for planning, track the progress of application migrations to AWS, and modernize applications already running on AWS, thereby simplifying and accelerating the migration process.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:55:44.083716"}}
{"question": "What services are integrated with AWS Migration Hub and what do they do?", "answer": "AWS Application Migration Service, AWS Server Migration Service, AWS Database Migration Service, and ATADATA ATAmotion are integrated with AWS Migration Hub. These services automatically report migration status to Migration Hub, facilitating the tracking of the migration process.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-04T17:55:44.084039"}}
{"question": "What is the primary function of AWS Migration Hub?", "answer": "The primary function of AWS Migration Hub is to provide visibility into your migration progress, allowing you to see the status of your migration after using one of the integrated migration tools.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:55:49.336294"}}
{"question": "How does AWS Migration Hub help you understand your IT environment?", "answer": "AWS Migration Hub helps you understand your IT environment by allowing you to explore information collected by AWS discovery tools, which is stored in the AWS Application Discovery Services repository. This enables you to view technical specifications and performance information about discovered resources.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:55:49.336604"}}
{"question": "What is the difference between the costs associated with AWS Migration Hub and AWS Migration Hub Refactor Spaces?", "answer": "AWS Migration Hub is available at no additional charge, with costs incurred only for the migration tools used and any resources consumed on AWS. In contrast, AWS Migration Hub Refactor Spaces incurs charges for usage plus any costs associated with provisioned resources, such as Transit Gateway.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-04T17:55:49.337070"}}
{"question": "What is required before using most features in AWS Migration Hub?", "answer": "Before using most features in AWS Migration Hub, you need to select a Migration Hub home Region from the Migration Hub Settings page or by using the Migration Hub Config API.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T17:55:56.033486"}}
{"question": "How does the Migration Hub home Region function in relation to migration tracking?", "answer": "The Migration Hub home Region functions as a single repository of discovery and migration planning information for your entire portfolio. It provides a single view of migrations into multiple AWS Regions, where migration status from integrated tools is aggregated and visible. Once set, the Migration Hub home Region cannot be changed.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T17:55:56.033736"}}
{"question": "What is the difference between the Migration Hub home Region and the integrated migration tools?", "answer": "The Migration Hub home Region stores the discovery and migration tracking data and provides a view of migration statuses aggregated from multiple destination Regions. In contrast, integrated migration tools, such as AWS Application Migration Service and AWS Database Migration Service, are responsible for sending the migration status to the selected Migration Hub home Region and require authorization on the Tools page of the Migration Hub console to do so.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-04T17:55:56.034083"}}
{"question": "What happens if I start migrating without performing discovery in AWS Migration Hub?", "answer": "If you start migrating without performing discovery, your application servers and database servers will appear as resources in Migration Hub as you migrate them using the integrated migration tools that youve authorized in the Migration Hub console.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T17:56:01.922338"}}
{"question": "What are the two data collection options available for discovery in AWS Migration Hub?", "answer": "The two data collection options available for discovery in AWS Migration Hub are using the AWS Application Discovery Service agentless collector for VMware environments, and installing agents on your servers to collect a wide variety of information, including resource utilization, processes running on the server, and the servers network dependencies.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T17:56:01.922701"}}
{"question": "How do the visibility of applications differ between IAM users within the same AWS account and those outside of it?", "answer": "Applications created by any IAM user within an account are visible to any other IAM users within the same account who are granted access to AWS Migration Hub. In contrast, users do not have visibility into applications or resources from other AWS accounts.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T17:56:01.923135"}}
{"question": "What feature allows you to import server details into AWS Migration Hub?", "answer": "The feature that allows you to import server details into AWS Migration Hub is called Migration Hub import. You can access it from the Migration Hub console or by invoking the Application Discovery Service APIs.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-04T17:56:09.103295"}}
{"question": "What happens if a row in the CSV import template does not have any of the required fields populated?", "answer": "If a row in the CSV import template does not contain a value for the matching key ('ExternalId') or for any of the required fields such as 'IPAddress,' 'HostName,' 'MACAddress,' or a combination of 'VMware.MoRefId' and 'VMware.vCenterId,' that row will not be imported.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-04T17:56:09.103531"}}
{"question": "How does Migration Hub import handle the uniqueness of server records when importing data?", "answer": "Migration Hub import determines the uniqueness of server records by using the values specified for 'ExternalId,' 'IPAddress,' 'HostName,' 'MACAddress,' or a combination of 'VMware.MoRefId' and 'VMware.vCenterId.' If a matching key ('ExternalId') is provided, it will use that to uniquely identify and import the records. If not, it will rely on the other specified fields to determine uniqueness.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-04T17:56:09.103697"}}
{"question": "What data does the EC2 instance recommendations feature analyze to provide recommendations?", "answer": "The EC2 instance recommendations feature analyzes data collected from each on-premises server, including server specification, CPU, and memory utilization, to recommend the least expensive EC2 instance required to run the on-premises workload.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-04T17:56:15.937152"}}
{"question": "How can users fine-tune the EC2 instance recommendations they receive?", "answer": "Users can fine-tune the EC2 instance recommendations by specifying preferences for AWS purchasing option, AWS Region, EC2 instance type exclusions, and CPU/RAM utilization metric, which can be set to average, peak, or percentile.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-04T17:56:15.937499"}}
{"question": "What is the difference between the EC2 instance recommendations for current generation instances and previous generation instances?", "answer": "The EC2 instance recommendations feature only recommends current generation instances and does not provide recommendations for previous generation instances.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-04T17:56:15.937930"}}
{"question": "What feature does Migration Hub provide to help understand projected EC2 costs?", "answer": "Migration Hub offers the EC2 instance recommendation feature to help understand projected EC2 costs.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-04T17:56:23.485470"}}
{"question": "Why is right-sizing compute resources important in the context of AWS?", "answer": "Right-sizing your compute resources is important as it is one dimension of understanding your total cost of ownership (TCO).", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-04T17:56:23.485760"}}
{"question": "How does Migration Hub track the migration status of resources compared to AWS migration tools?", "answer": "Migration Hub tracks the migration status of resources by providing a diagram and a table that show the general and detailed status of each resource, whereas AWS migration tools like AWS Server Migration Service report specific statuses such as 'In progress / replication starting' or 'Completed / AMI created'.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-04T17:56:23.486107"}}
{"question": "What two conditions must be met to view migration progress in AWS Migration Hub?", "answer": "To view migration progress in AWS Migration Hub, the resources that you are migrating must be in the AWS Discovery repository, and you must use supported tools to perform the migration.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-04T17:56:30.504035"}}
{"question": "Why is it important to group resources into applications when tracking migration status in AWS Migration Hub?", "answer": "It is important to group resources into applications when tracking migration status because AWS Migration Hub will show the status of the resource migrations only if the resource is grouped in an application. This allows you to track the migration status in a single grouping as the migration progresses.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-04T17:56:30.504332"}}
{"question": "How does the status reporting differ between supported tools and tools that are not integrated with AWS Migration Hub?", "answer": "Supported tools can report migration status directly to the AWS Migration Hub Management Console, while tools that are not integrated with AWS Migration Hub will not report status in the Migration Hub Management Console. However, you can still see the status of other resources in the application and the application level status, or you can update the status via your own automation using the CLI or APIs.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-04T17:56:30.504745"}}
{"question": "What does AWS Migration Hubs Strategy Recommendations help you achieve?", "answer": "AWS Migration Hubs Strategy Recommendations helps you easily build a migration and modernization strategy for your applications running on premises or in AWS. It provides guidance on the strategy and tools that help you migrate and modernize at scale.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-04T17:56:36.390884"}}
{"question": "How does the application transformation process benefit organizations using AWS?", "answer": "The application transformation process benefits organizations using AWS by refactoring, rearchitecting, and rewriting applications to maximize the availability, scalability, business agility, and cost optimization benefits of running in the cloud.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-04T17:56:36.391176"}}
{"question": "What is the difference between rehost and replatform options supported by Strategy Recommendations?", "answer": "Rehost options involve migrating applications to EC2 without significant changes, while replatform options involve moving applications to managed environments such as RDS and Elastic Beanstalk, and may include OS upgrades or other modifications to improve the applications infrastructure.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-04T17:56:36.391665"}}
{"question": "What types of applications are candidates for using Refactor Spaces?", "answer": "Any application targeted for refactor, rewrite, or rearchitecture is a candidate for using Refactor Spaces, as long as its external interface is an HTTP-based protocol and it is running in AWS, or it can be rehosted with Application Migration Service or replatformed first.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:56:42.364282"}}
{"question": "How does Refactor Spaces help in transforming legacy applications?", "answer": "Refactor Spaces helps in transforming legacy applications by allowing users to combine existing applications and microservices into a single application while accommodating different approaches for architecture, technology, team alignment, and processes. It enables the transformation of legacy applications or the extension of them with microservices that can run on various AWS compute targets, providing significant time savings by creating the necessary infrastructure for application refactoring in minutes.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:56:42.364769"}}
{"question": "What are the key components orchestrated by Refactor Spaces for creating refactoring environments?", "answer": "Refactor Spaces orchestrates Transit Gateway, Resource Access Manager, and API Gateway to create refactoring environments. These components help bridge networking across accounts and simplify communication between existing applications and new microservices.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T17:56:42.365168"}}
{"question": "What does a Refactor Spaces Application provide for existing applications and new microservices?", "answer": "A Refactor Spaces Application provides configurable request routing to your existing application and new microservices. It includes a proxy that simplifies strangler fig refactoring in AWS.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-04T17:56:47.629809"}}
{"question": "How does Refactor Spaces ensure that underlying architecture changes remain transparent to app consumers?", "answer": "Refactor Spaces uses an applications proxy and routing to keep underlying architecture changes transparent to app consumers.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-04T17:56:47.630155"}}
{"question": "What is the difference in traffic routing between a service with a Lambda endpoint and a service with a URL endpoint in Refactor Spaces?", "answer": "For services with a Lambda endpoint, traffic is routed using API Gateways Lambda integration. In contrast, for services with a URL endpoint, traffic is routed using an API Gateway VPC Link and NLB target group.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-04T17:56:47.630532"}}
{"question": "What are the methods to use Refactor Spaces?", "answer": "Refactor Spaces can be used through the AWS Management Console, AWS SDK/CLI, or CloudFormation (CFN).", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-04T17:56:53.232402"}}
{"question": "Why is it recommended to have at least two AWS accounts when using Refactor Spaces?", "answer": "It is recommended to have at least two accountsone for your existing application and one to own the Refactor Spaces environment and manage traffic routing between services.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-04T17:56:53.232634"}}
{"question": "How does traffic routing differ for existing applications and newly created microservices in Refactor Spaces?", "answer": "Initially, all traffic will flow to the existing application, requiring the creation of a default route that sends all traffic to the service representing the existing app. Over time, routes will be added to cut traffic over to business capabilities being served by new microservices.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-04T17:56:53.233027"}}
{"question": "What is the main purpose of AWS Migration Hub Orchestrator?", "answer": "The main purpose of AWS Migration Hub Orchestrator is to automate and simplify the migration of applications to AWS. It helps reduce migration costs and time by eliminating many manual tasks involved in migrating large-scale enterprise applications, managing dependencies between different tools, and providing visibility into migration progress in one place.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-04T17:56:59.909552"}}
{"question": "How does AWS Migration Hub Orchestrator help in accelerating migrations?", "answer": "AWS Migration Hub Orchestrator helps accelerate migrations by using proven predefined workflow templates based on thousands of applications with similar patterns that AWS has migrated. This allows users to leverage existing knowledge and best practices to speed up the migration process.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-04T17:56:59.909850"}}
{"question": "What are the differences between predefined workflow templates and customizable workflow templates in AWS Migration Hub Orchestrator?", "answer": "Predefined workflow templates in AWS Migration Hub Orchestrator are based on proven patterns from thousands of migrated applications, providing a prescribed set of migration tasks and tools. In contrast, customizable workflow templates allow users to build on top of these baseline recommendations, modify the steps and dependencies, and adapt the templates to address the specific needs of their workloads and use cases.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-04T17:56:59.910238"}}
{"question": "What is the primary purpose of Orchestrator in the context of migrating applications to AWS?", "answer": "The primary purpose of Orchestrator is to simplify and accelerate the migration of applications to AWS.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-04T17:57:05.474829"}}
{"question": "How does Orchestrator help in customizing the migration workflow?", "answer": "Orchestrator helps in customizing the migration workflow by allowing users to add their own steps, dependencies, and automations to address the needs of specific use cases.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-04T17:57:05.475169"}}
{"question": "What advantages does Orchestrator provide when orchestrating migration tasks across different migration tools?", "answer": "Orchestrator provides advantages such as the ability to reuse inventory metadata, configuration specification, and environment context, which minimizes the inputs needed for each tool. It also automates manual migration tasks, manages dependencies between different tools, and offers visibility into migration progress in one place, ultimately helping to reduce migration costs and time.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-04T17:57:05.475373"}}
{"question": "What are the available methods to access Orchestrator?", "answer": "You can access Orchestrator from the AWS Migration Hub console or the AWS Command Line Interface (CLI).", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-04T17:57:11.444053"}}
{"question": "What is the purpose of a workflow template in Orchestrator?", "answer": "A workflow template is a playbook that includes a prescribed set of migration tasks, dependencies, suitable migration tools, and recommended automation opportunities, helping to streamline the application migration process.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-04T17:57:11.444361"}}
{"question": "How do the first two predefined workflow templates differ in their migration focus?", "answer": "The first template is designed to migrate SAP NetWeaverbased applications with HANA databases using AWS Launch Wizard and HANA System Replication, while the second template focuses on accelerating the rehosting of any applications using AWS Application Migration Service (MGN).", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-04T17:57:11.444761"}}
{"question": "What are some key features of Amazon Neptune?", "answer": "Amazon Neptune is a fully managed graph database that offers high availability (up to 99.99%), multi-Region capabilities for improved disaster recovery, dynamic scaling with serverless architecture, and native integrations with other AWS services. It can search and query billions of relationships in milliseconds across thousands of concurrent queries, and it automatically scales storage while maintaining consistent performance without overprovisioning.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:57:18.537551"}}
{"question": "How does Amazon Neptune improve the accuracy of AI applications?", "answer": "Amazon Neptune improves the accuracy of AI applications by modeling data as a graph, which captures context that enhances both accuracy and explainability of generative AI applications. This graph-based approach allows for better insights into relationships within the data, ultimately benefiting AI development.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:57:18.537840"}}
{"question": "In what ways does Amazon Neptune ensure high availability compared to traditional databases?", "answer": "Amazon Neptune ensures high availability through features such as automatic failover to one of up to 15 read replicas in case of instance failure, automatic detection and restart of database crashes without the need for crash recovery, and its fault-tolerant and self-healing storage that repairs disk failures in the background without impacting database availability. Traditional databases may require manual intervention for recovery and may not have such extensive automated features.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-04T17:57:18.538281"}}
{"question": "What types of analytics does Neptune Analytics support?", "answer": "Neptune Analytics supports graph analytics, graph algorithms, and vector search of graph data stored in Amazon S3 or the Neptune database.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-04T17:57:26.024827"}}
{"question": "How does Neptune ML enhance the use of graph data for predictions?", "answer": "Neptune ML enhances the use of graph data for predictions by integrating with Amazon SageMaker to train graph neural networks (GNNs), allowing for fast and accurate predictions using graph data. It also supports real-time predictions on nodes, edges, and properties that were added to the graph after the initial ML model training, eliminating the need to retrain the models for new data.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-04T17:57:26.025174"}}
{"question": "How does data loading differ between Neptune Analytics using an existing Neptune database and loading from S3?", "answer": "When using an existing Neptune database as the data source, the data is automatically loaded into Neptune Analytics. In contrast, when loading from S3, users need to provide graph data directly using CSV files in common graph export formats.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-04T17:57:26.025596"}}
{"question": "What query languages does Neptune Database support for the property graph data model?", "answer": "Neptune Database supports two query languages for the property graph data model: the open-source Apache TinkerPop Gremlin graph traversal language and the openCypher query language.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:57:31.367971"}}
{"question": "How does Neptune Analytics empower users to interact with data?", "answer": "Neptune Analytics empowers users to interact with data using familiar tools such as Pandas, Jupyter, and Python, allowing them to discover and pinpoint interactions and patterns of behavior in the data that are indicative of fraud, illegal activities, optimization opportunities, and more.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:57:31.368351"}}
{"question": "How does Neptune ML differ from Neptune Analytics in terms of functionality?", "answer": "Neptune ML is focused on designing, building, optimizing, and predicting relationships and categorizations using state-of-the-art Graph Neural Networks (GNNs), whereas Neptune Analytics is used for interacting with data to derive insights and perform analytics tasks such as running low-latency analytic queries and using built-in graph algorithms.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-04T17:57:31.368758"}}
{"question": "What types of data can a Neptune Database cluster store?", "answer": "A Neptune Database cluster can store both property graph data and RDF data.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T17:57:36.603026"}}
{"question": "How does Neptune support the execution of queries for property graph data?", "answer": "Neptune allows you to execute either a Gremlin or openCypher query over property graph data regardless of the language used to enter that data. This means you can use either query language for the same dataset, although you cannot execute a query for property graph data over RDF data or vice-versa.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T17:57:36.603318"}}
{"question": "What are the differences between the Gremlin and SPARQL endpoints in Neptune?", "answer": "The Gremlin endpoint supports connections using both HTTPS and WebSocket protocols and is designed for property graph data, allowing the execution of Gremlin or openCypher queries. In contrast, the SPARQL endpoint implements the SPARQL 1.1 Protocol and is used for querying RDF data, working with any client that supports SPARQL 1.1.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-04T17:57:36.603728"}}
{"question": "What is the main purpose of the Neptune Database?", "answer": "The main purpose of the Neptune Database is to serve as a purpose-built, high-performance graph database engine designed to support graph applications that require high throughput and low-latency graph queries.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T17:57:43.441998"}}
{"question": "How does Neptune Database optimize its I/O operations compared to traditional database engines?", "answer": "Neptune Database optimizes its I/O operations by removing unnecessary I/O operations to reduce costs, ensuring resources are available for serving read/write traffic. It only consumes write I/O operations when pushing transaction log records to the storage layer for durability. Furthermore, unlike traditional database engines, Neptune never pushes modified database pages to the storage layer, resulting in additional I/O consumption savings.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T17:57:43.442344"}}
{"question": "In what ways does Neptune Database share operational technology with Amazon RDS?", "answer": "Neptune Database shares operational technology with Amazon RDS for certain management features such as instance lifecycle management, encryption at rest with AWS Key Management Service (AWS KMS) keys, and security groups management.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T17:57:43.442952"}}
{"question": "What is the minimum storage requirement for Amazon Neptune?", "answer": "The minimum storage requirement for Amazon Neptune is 10 GiB.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T17:57:48.958936"}}
{"question": "How does Amazon Neptune Serverless handle the scaling of resources for graph workloads?", "answer": "Amazon Neptune Serverless automatically determines and provisions the compute and memory resources needed to run graph workloads. It scales capacity based on the workloads changing requirements to maintain consistent performance, without the need for manual management or optimization of capacity.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T17:57:48.959239"}}
{"question": "What is the difference between modifying the DB instance class and using Neptune Serverless for scaling resources?", "answer": "Modifying the DB instance class in the AWS Management Console requires manual selection of the desired instance and can affect availability for a few minutes during the scaling operation. In contrast, Neptune Serverless automatically scales resources based on workload demands without manual intervention, providing an instant scaling solution that maintains consistent performance without the need for provisioning.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-04T17:57:48.959646"}}
{"question": "What happens to the final user-created database snapshot when a Neptune database instance is deleted?", "answer": "When a Neptune database instance is deleted, the final user-created database snapshot is retained along with all other manually created database snapshots. This allows you to restore the deleted database instance at a later date. However, automated backups created for point-in-time restore are not kept.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T17:57:55.107839"}}
{"question": "What are the benefits of sharing database snapshots between AWS accounts in Neptune?", "answer": "Sharing database snapshots between AWS accounts in Neptune allows users to restore a database containing shared data, which facilitates data sharing between various environments such as production, development, testing, and staging. Furthermore, it enables users to keep backups of their data secure in a separate account, providing an extra layer of security in case the main AWS account is compromised.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T17:57:55.108129"}}
{"question": "How do the sharing capabilities of manual and automatic snapshots differ in Neptune?", "answer": "Manual snapshots in Neptune can be shared with up to 20 AWS account IDs or made public for anyone to access. In contrast, automatic snapshots cannot be shared directly; to share an automatic snapshot, a manual copy must be created first. This highlights that while manual snapshots have flexible sharing options, automatic snapshots do not support sharing without additional steps.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T17:57:55.108608"}}
{"question": "What are the requirements for creating a Neptune Database cluster in terms of Availability Zones?", "answer": "A Neptune Database cluster can only be created in an Amazon VPC that has at least two subnets in at least two Availability Zones. This distribution helps ensure that there are instances available in the database cluster in the event of an Availability Zone failure.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-04T17:58:01.606155"}}
{"question": "How does Neptune handle database crashes differently from other databases?", "answer": "Unlike other databases, after a database crash, Neptune does not need to replay the redo log from the last database checkpoint before making the database available for operations. This design reduces database restart times to less than 60 seconds in most cases, as Neptune moves the buffer cache out of the database process and makes it available immediately at restart time, thus preventing throttling access until the cache is repopulated.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-04T17:58:01.606458"}}
{"question": "What happens to read replicas in the event of a writer instance failure in a Neptune Database cluster?", "answer": "In the event of a writer instance failure, a read replica will be automatically promoted to a writer instance. One Neptune cluster can have one writer instance and up to 15 read replicas, and updates made by the primary are visible to all Amazon Neptune Replicas.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-04T17:58:01.606886"}}
{"question": "What happens if the higher priority replicas on a Neptune cluster are unhealthy?", "answer": "If the higher priority replicas on the cluster are unhealthy or unavailable, Neptune will promote the lower priority replica to become the primary instance.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-04T17:58:07.933797"}}
{"question": "How does Neptune handle failover automatically?", "answer": "Neptune handles failover automatically by flipping the canonical name record (CNAME) for your database primary endpoint to a healthy replica, which is then promoted to become the new primary. This process typically completes within 30 seconds.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-04T17:58:07.934026"}}
{"question": "How does the failover process differ when using a Neptune Replica compared to a single instance?", "answer": "When using a Neptune Replica, the failover process typically completes within 30 seconds as the CNAME is updated to point to a healthy replica. In contrast, if there is no Neptune Replica and only a single instance, the failover process can take under 15 minutes, as Neptune will first try to create a new database instance in the same Availability Zone, and if that fails, it will attempt to create one in a different Availability Zone.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-04T17:58:07.934171"}}
{"question": "What must all Amazon Neptune Database instances be created in?", "answer": "All Amazon Neptune Database instances must be created in a VPC (Virtual Private Cloud).", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-04T17:58:12.346081"}}
{"question": "Why is it necessary to access Neptune databases through the HTTPS port entered during database creation?", "answer": "Accessing Neptune databases through the HTTPS port entered during database creation is necessary to provide an additional layer of security for your data.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-04T17:58:12.346368"}}
{"question": "How does Neptune Analytics differ from traditional analytics engines in terms of graph processing?", "answer": "Neptune Analytics differs from traditional analytics engines by being an in-memory engine that can load large graphs into memory, delivering responses in seconds and supporting thousands of analytic queries per second using popular graph analytics algorithms.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-04T17:58:12.346774"}}
{"question": "Is Neptune Analytics ACID compliant?", "answer": "Yes, Neptune Analytics is ACID compliant with strong consistency.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T17:58:17.386870"}}
{"question": "What capabilities does Neptune Analytics provide for vector search?", "answer": "Neptune Analytics supports a vector search index on embeddings stored in your graph data, with the ability to handle embeddings of up to 65,000 dimensions. It also provides efficient vector search that can be invoked directly from the openCypher query language used for writing graph queries.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T17:58:17.387214"}}
{"question": "How does the availability of Neptune Analytics differ when using Multi-AZ deployments versus without a standby?", "answer": "Neptune Analytics offers Multi-AZ deployments with enhanced availability and durability by provisioning a hot standby in a separate Availability Zone. With a hot standby, the failover time is in seconds, whereas without a standby, the service provisions new underlying compute capacity within minutes.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T17:58:17.387685"}}
{"question": "What types of classifications and predictions does Neptune ML support?", "answer": "Neptune ML supports node classification, multi-class classification, node regression, edge classification, single-class classification, edge regression, and link (edge) prediction.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-04T17:58:22.364243"}}
{"question": "How does Neptune ML enhance the capabilities of AWS Neptune?", "answer": "Neptune ML enhances the capabilities of AWS Neptune by providing advanced machine learning features such as various types of classifications and predictions, which can be applied to both nodes and edges within a graph database.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-04T17:58:22.364591"}}
{"question": "How does the classification support in Neptune ML differ between nodes and edges?", "answer": "Neptune ML provides support for both node classification and edge classification, indicating that it can classify both the entities (nodes) and the relationships (edges) within a graph. This allows users to apply different classification techniques depending on whether they are analyzing the nodes or the edges.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-04T17:58:22.364997"}}
{"question": "What is AWS Network Firewall and what does it help to protect?", "answer": "AWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs). It helps to protect your network traffic by allowing you to define firewall rules, block malicious activity, and manage security policies across your VPCs.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-04T17:58:30.920323"}}
{"question": "How does AWS Network Firewall facilitate the management of security policies?", "answer": "AWS Network Firewall works together with AWS Firewall Manager, allowing users to build policies based on AWS Network Firewall rules. This integration enables the central application of these policies across multiple VPCs and accounts, ensuring consistent enforcement of mandatory security policies.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-04T17:58:30.920617"}}
{"question": "What are the differences between managing your own network security infrastructure and using AWS Network Firewall?", "answer": "When managing your own network security infrastructure, you are responsible for building and maintaining the security systems, which can be complex and resource-intensive. In contrast, AWS Network Firewall is a managed service where AWS handles the infrastructure, allowing you to set up protections with just a few clicks and scale automatically with network traffic, freeing you from the burden of infrastructure management.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-04T17:58:30.921270"}}
{"question": "What features does AWS Network Firewall provide to protect against common network threats?", "answer": "AWS Network Firewall includes features such as a stateful firewall that tracks connections and identifies protocols to enforce policies, an intrusion prevention system (IPS) for active traffic flow inspection, and web filtering to stop traffic to known-bad URLs and monitor fully qualified domain names.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T17:58:42.885557"}}
{"question": "How does AWS Network Firewall enhance the security of VPC-to-VPC traffic?", "answer": "AWS Network Firewall enhances the security of VPC-to-VPC traffic by providing control and visibility, allowing for the logical separation of networks that host sensitive applications or line-of-business resources. It also offers outbound traffic filtering based on URLs, IP addresses, and domains to help meet compliance requirements and prevent data leaks.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T17:58:42.885909"}}
{"question": "In what ways does AWS Network Firewall differ from AWS Shield Advanced regarding DDoS protection?", "answer": "AWS Network Firewall is designed to protect and control access to and from your VPC but does not mitigate volumetric attacks like distributed denial of service (DDoS) attacks. In contrast, AWS Shield Advanced offers managed DDoS protection that is customized to specific application traffic, making it suitable for protecting against DDoS attacks and ensuring application availability.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T17:58:42.886352"}}
{"question": "What is the uptime commitment provided by the AWS Network Firewall's Service Level Agreement?", "answer": "The AWS Network Firewall offers a Service Level Agreement with an uptime commitment of 99.99%.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-04T17:58:48.289221"}}
{"question": "How does AWS Network Firewall manage its firewall capacity based on traffic load?", "answer": "AWS Network Firewall enables you to automatically scale your firewall capacity up or down based on traffic load, which helps maintain steady, predictable performance and minimizes costs.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-04T17:58:48.289578"}}
{"question": "What are the two primary deployment types supported by AWS Network Firewall, and how do they differ?", "answer": "AWS Network Firewall supports two primary deployment types: centralized and distributed. In a distributed deployment, the firewall can be deployed within each of your Amazon VPCs for enforcement closer to the applications. In contrast, a centralized deployment is achieved as a VPC attachment to your AWS Transit Gateway, allowing for filtering of various inbound and outbound traffic while maintaining symmetric routing.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-04T17:58:48.290054"}}
{"question": "What is the minimum size of the subnet required to deploy AWS Network Firewall?", "answer": "The minimum size of the subnet required to deploy AWS Network Firewall is /28.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-04T17:58:53.215368"}}
{"question": "How does AWS Network Firewall handle scaling and software updates?", "answer": "AWS Network Firewall is an AWS managed service, which means that AWS takes care of scaling, availability, resiliency, and software updates.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-04T17:58:53.215611"}}
{"question": "What is the difference between stateless and stateful rules in AWS Network Firewall?", "answer": "Stateless rules consist of network access control lists (ACLs) based on source and destination IP addresses, ports, or protocols, and do not maintain connection states. In contrast, stateful rules, or Layer-4 rules, also consider source and destination IP addresses, ports, and protocols but maintain and secure connections or sessions throughout the life of the connection or session.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-04T17:58:53.215975"}}
{"question": "What are the types of outbound traffic control supported by AWS Network Firewall?", "answer": "AWS Network Firewall supports the following types of outbound traffic control: HTTPS (SNI)/HTTP protocol URL filtering, Access Control Lists (ACLs), DNS query, and protocol detection.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T17:59:01.485197"}}
{"question": "How does AWS Network Firewall pricing work when associating a firewall with multiple VPCs?", "answer": "When you associate a firewall with multiple VPCs, you pay the standard hourly rate per region and Availability Zone (AZ) for the primary firewall endpoint in the inspection VPC. Additionally, you pay a reduced hourly rate per region and AZ for each additional secondary endpoint associated with that firewall. You are also billed for the amount of traffic processed by your firewall, charged by the gigabyte per region and AZ.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T17:59:01.485462"}}
{"question": "How does the bandwidth scaling of AWS Network Firewall work across associated VPC endpoints?", "answer": "AWS Network Firewall automatically scales up to 100 Gbps bandwidth per Availability Zone (AZ). This 100 Gbps bandwidth is shared across all associated VPC endpoints, which means that customers should consider the total anticipated traffic volume when planning their deployment. If a single endpoint is oversubscribed, it may impact performance.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-04T17:59:01.485837"}}
{"question": "What metrics are available for each VPC endpoint in AWS Network Firewall?", "answer": "The available metrics for each VPC endpoint in AWS Network Firewall are received packets, dropped packets, invalid dropped packets, other dropped packets, and passed packets.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T17:59:09.065039"}}
{"question": "How does the active threat defense managed rule groups differ from existing managed rule groups in AWS Network Firewall?", "answer": "Active threat defense managed rule groups differ from existing Domain, IP, and threat signature managed rule groups primarily because they are based on Amazon threat intelligence. This capability focuses on providing rapid protection against active threats identified by Amazon threat intelligence, and when an active threat is detected, AWS Network Firewall automatically applies managed rules to block it. Active threat defense is designed to complement other managed rule groups, offering an additional layer of protection.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T17:59:09.065381"}}
{"question": "What are the steps to configure AWS Network Firewall TLS inspection, and how does this process compare to enabling active threat defense managed rule groups?", "answer": "To configure AWS Network Firewall TLS inspection, you need to follow a 3-step process: 1) provision certificates and keys, 2) create a TLS inspection configuration, and 3) apply the configuration to a firewall policy. In contrast, enabling active threat defense managed rule groups can be done through the AWS Management Console, AWS CLI, or AWS SDKs, and involves selecting the active threat defense rule group within the AWS managed rule groups dropdown when creating or updating a firewall policy. Thus, TLS inspection requires a defined setup process while active threat defense can be enabled directly through a selection in the firewall policy.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-04T17:59:09.065895"}}
{"question": "What logging and monitoring capabilities does AWS Network Firewall provide?", "answer": "AWS Network Firewall integrates with Amazon CloudWatch, providing comprehensive logging and monitoring capabilities that help you track rule matches and performance metrics.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-04T17:59:14.580725"}}
{"question": "How does active threat defense managed rule groups enhance security visibility?", "answer": "Active threat defense managed rule groups provide enhanced visibility into your security posture by offering details on indicator groups, indicator types, and specific threat names being mitigated.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-04T17:59:14.581044"}}
{"question": "What is the fixed rule capacity for active threat defense managed rule groups compared to the default total limit for stateful rules per firewall policy?", "answer": "Active threat defense managed rule groups have a fixed rule capacity of 15,000, while the default total limit for stateful rules per firewall policy is 30,000 stateful rules in a Region.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-04T17:59:14.581448"}}
{"question": "What types of clusters can be created using Amazon OpenSearch Service?", "answer": "Amazon OpenSearch Service domains can be either Elasticsearch clusters (versions 1.5 to 7.10) or OpenSearch clusters. These can be created using the Amazon OpenSearch Service console, CLI, or API.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-04T17:59:19.685250"}}
{"question": "How does Amazon OpenSearch Service support legacy versions of Elasticsearch?", "answer": "Amazon OpenSearch Service supports several legacy open-source Elasticsearch versions, specifically up to version 7.10, in addition to offering the latest versions of OpenSearch.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-04T17:59:19.685597"}}
{"question": "How does the customer base of Amazon OpenSearch Service compare to the number of clusters it manages?", "answer": "Amazon OpenSearch Service currently has tens of thousands of active customers and manages hundreds of thousands of clusters, processing trillions of requests per month.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-04T17:59:19.686022"}}
{"question": "What tasks does Amazon OpenSearch Service automate for users once a domain is running?", "answer": "Once your domain is running, Amazon OpenSearch Service automates common administrative tasks, such as performing backups, monitoring instances, and patching software.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:59:25.100333"}}
{"question": "Why is it recommended to use three AZ deployments for production-grade workloads in Amazon OpenSearch Service?", "answer": "Three AZ deployments are strongly recommended for workloads with higher availability requirements, as they provide better fault tolerance and reliability compared to single or two AZ deployments.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:59:25.100682"}}
{"question": "How do the availability zone options differ for Amazon OpenSearch Service in US West (N. California) compared to other regions?", "answer": "In US West (N. California), Amazon OpenSearch Service supports only two AZs, whereas in all other regions where the service is available, it supports three AZ deployments.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T17:59:25.101202"}}
{"question": "What capabilities does OpenSearch support for search and analytics?", "answer": "OpenSearch supports a number of search and analytics capabilities such as k-nearest neighbors (KNN) search, SQL, Anomaly Detection, Machine Learning Commons, Trace Analytics, and full-text search.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T17:59:32.017712"}}
{"question": "How does Amazon OpenSearch Service simplify the management of OpenSearch clusters for users?", "answer": "Amazon OpenSearch Service simplifies the management of OpenSearch clusters by being a fully managed service that allows users to run and scale clusters without having to manage, monitor, or maintain the underlying infrastructure, nor requiring in-depth expertise in operating OpenSearch clusters.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T17:59:32.018025"}}
{"question": "How do Amazon OpenSearch Service domains differ from the OpenSearch that can be run on premises or other cloud platforms?", "answer": "Amazon OpenSearch Service domains are fully managed and run on AWS, allowing users to create and manage domains easily through the console. In contrast, OpenSearch can also be run on premises or in hybrid and multicloud environments by various partners, which may involve more management and operational complexities.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T17:59:32.018439"}}
{"question": "What options does Amazon OpenSearch Service provide for data ingestion?", "answer": "Amazon OpenSearch Service supports three options for data ingestion: Amazon Kinesis Data Firehose, integration with Logstash, and native Elasticsearch or OpenSearch APIs such as the index and bulk APIs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T17:59:38.395690"}}
{"question": "What are the benefits of using Amazon Kinesis Data Firehose for data ingestion in Amazon OpenSearch Service?", "answer": "Amazon Kinesis Data Firehose is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also transform, batch, and compress the data before loading it into Amazon OpenSearch Service.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T17:59:38.396065"}}
{"question": "How does the data storage option differ between local on-instance storage and EBS volumes in Amazon OpenSearch Service?", "answer": "When using local on-instance storage, the storage is tied directly to the instance, whereas EBS volumes provide more flexibility, allowing users to increase and decrease the size of the storage volume as necessary during domain creation.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T17:59:38.396586"}}
{"question": "What is the maximum storage capacity per node for Amazon OpenSearch Service using R6g.12xlarge instances?", "answer": "The maximum storage per node for Amazon OpenSearch Service using R6g.12xlarge instances with EBS gp3 storage is 24 TB.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:59:45.192520"}}
{"question": "Why is it recommended to deploy data instances across three Availability Zones (AZs) for production workloads in Amazon OpenSearch Service?", "answer": "It is recommended to deploy data instances across three Availability Zones for production workloads because it offers better availability.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:59:45.192865"}}
{"question": "How does the distribution of dedicated master instances differ when deploying data instances across one AZ compared to two or three AZs?", "answer": "If you deploy your data instances in a single AZ, your dedicated master instances are also deployed in the same AZ. However, if you deploy your data instances across two or three AZs, Amazon OpenSearch Service automatically distributes the dedicated master instances across the three AZs.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T17:59:45.193274"}}
{"question": "What happens if one or more instances in an Availability Zone (AZ) are unreachable in Amazon OpenSearch Service?", "answer": "If one or more instances in an AZ are unreachable or not functional, Amazon OpenSearch Service automatically tries to bring up new instances in the same AZ to replace the affected instances. If new instances cannot be brought up in the AZ, Amazon OpenSearch Service will bring up new instances in the other available AZs, provided the domain has been configured to deploy instances across multiple AZs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-04T17:59:54.563560"}}
{"question": "Why is it recommended to use three Availability Zones (AZs) when configuring Amazon OpenSearch Service, even with one replica?", "answer": "It is recommended to use three AZs because if an AZ disruption occurs in a three AZ domain, you only lose one-third of your capacity. In contrast, if the disruption occurs in a two AZ domain, you lose half your capacity, which can be more disruptive. Additionally, in a three AZ domain, if one AZ is disrupted, Amazon OpenSearch Service can fall back to the two remaining AZs and still support cross-AZ replication, while a two AZ domain loses cross-AZ replication if one AZ is disrupted, further reducing availability.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-04T17:59:54.563908"}}
{"question": "What is the relationship between the number of Availability Zones (AZs) and the number of subnets in your VPC domain for Amazon OpenSearch Service?", "answer": "The number of AZs your domain is deployed to corresponds to the number of subnets you have configured for your VPC domain. To enable three AZ deployment, you need to configure at least three subnets in your VPC domain.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-04T17:59:54.564434"}}
{"question": "What operations can be performed to scale an Amazon OpenSearch Service domain?", "answer": "You can scale your Amazon OpenSearch Service domain by adding, removing, or modifying instances or storage volumes depending on your application needs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T18:00:01.818678"}}
{"question": "Why are snapshots important for Amazon OpenSearch Service domains?", "answer": "Snapshots are important because they provide a copy of your Amazon OpenSearch Service domain at a moment in time, which can be useful in case of data loss caused by node failure, hardware failure, or for archiving purposes. They allow you to recover your domain with preloaded data or create a new domain with that data.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T18:00:01.819014"}}
{"question": "How does the automated snapshot retention policy of Amazon OpenSearch Service compare to the manual snapshot creation process?", "answer": "Amazon OpenSearch Service automatically creates hourly snapshots of each domain and retains them for 14 days by default. In contrast, manual snapshots can be created at any time and are not subject to the automatic retention policy, allowing users more control over what data is backed up and retained.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-04T18:00:01.819426"}}
{"question": "Are there any charges for automated hourly snapshots in Amazon OpenSearch Service?", "answer": "There is no additional charge for the automated hourly snapshots in Amazon OpenSearch Service. They are stored for free in an S3 bucket for node recovery purposes.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-04T18:00:07.317252"}}
{"question": "What is the purpose of slow logs in Amazon OpenSearch Service?", "answer": "Slow logs in Amazon OpenSearch Service are log files that help track the performance of various stages in an operation. They provide insights into the indexing process through Index Slow Logs and insights into the performance of queries and fetches through Search Slow Logs, which helps fine-tune the performance of search operations.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-04T18:00:07.317481"}}
{"question": "How do manual snapshots differ from automated snapshots in terms of storage and charges?", "answer": "Automated hourly snapshots in Amazon OpenSearch Service are stored for free in an S3 bucket and incur no additional charges. In contrast, manual snapshots created using the snapshot API are stored in your own S3 bucket and will incur relevant Amazon S3 usage charges.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-04T18:00:07.317904"}}
{"question": "What must be updated in order to start the logging process for slow logs in Amazon OpenSearch Service?", "answer": "To start the logging process for slow logs in Amazon OpenSearch Service, you have to update the settings for one or more indices to enable logging.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-04T18:00:14.513433"}}
{"question": "What happens when slow logs or error logs are enabled in Amazon OpenSearch Service?", "answer": "When slow logs or error logs are enabled, Amazon OpenSearch Service starts publishing the generated logs to CloudWatch Logs. It does not charge for enabling the logs, but standard CloudWatch charges will apply.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-04T18:00:14.513783"}}
{"question": "How does the logging for error logs differ from slow logs in terms of scope in Amazon OpenSearch Service?", "answer": "Error logs are exposed for the entire domain in Amazon OpenSearch Service, meaning that once enabled, log entries from all indices in the domain will be made available. In contrast, slow logs can be enabled for specific indices.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-04T18:00:14.514219"}}
{"question": "What is the recommended approach for enabling slow logs in Amazon OpenSearch Service?", "answer": "The recommended approach is to only enable slow logs for those indexes for which you need additional performance insights. Once the investigation is done, you should turn off logging to avoid incurring any additional costs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-04T18:00:19.997368"}}
{"question": "Why should slow logs be turned off after troubleshooting?", "answer": "Slow logs should be turned off after troubleshooting to avoid incurring any additional costs associated with logging.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-04T18:00:19.997703"}}
{"question": "How does the upgrade process for Amazon OpenSearch Service ensure no downtime?", "answer": "The upgrade process ensures no downtime by deploying a new cluster in the background every time the log status is updated and then replacing the existing cluster with the new one. This process does not cause any downtime; however, the update to the log status will not be instantaneous.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-04T18:00:19.998046"}}
{"question": "What versions of Elasticsearch support in-place version upgrades?", "answer": "In-place version upgrades are available only for domains running Elasticsearch 5.x and above.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T18:00:25.314261"}}
{"question": "What happens if issues are encountered during the upgrade process?", "answer": "If encountered issues are minor and fixable, Amazon OpenSearch Service automatically tries to address them and unblock the upgrade. However, if an issue blocks the upgrade, the service reverts back to the snapshot that was taken before the upgrade and logs the error.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T18:00:25.314562"}}
{"question": "Can you make changes to your domain configuration during the in-place version upgrade?", "answer": "No, once the in-place version upgrade has been triggered, you cannot make changes to your domain configuration until the upgrade completes or fails. However, you can continue reading and writing data while the upgrade is in progress.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-04T18:00:25.314771"}}
{"question": "How long can upgrades take for an OpenSearch cluster?", "answer": "Upgrades can take anywhere from a few minutes to a few hours to complete, depending on the amount of data and the size of the cluster.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-04T18:00:32.239537"}}
{"question": "What is the purpose of the Multi-AZ with Standby deployment option in Amazon OpenSearch Service?", "answer": "The Multi-AZ with Standby deployment option enables high-availability and consistent performance for business-critical workloads, making managed clusters resilient to infrastructure failures such as node drops or a single Availability Zone failure, thus ensuring no impact to performance or availability.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-04T18:00:32.239883"}}
{"question": "What are the requirements for enabling Multi-AZ with Standby compared to a standard deployment?", "answer": "To enable Multi-AZ with Standby, managed clusters need to run OpenSearch version 1.3 or more recent, be deployed in AWS Regions with 3-AZ (the North California region does not support 3-AZ), have the number of data nodes in multiples of three, and the number of data copies (primary + replica) should also be in multiples of three. These requirements differ from standard deployments, which may not have such specific conditions.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-04T18:00:32.240364"}}
{"question": "What events does Amazon OpenSearch Service automatically recover from within a minute when using Multi-AZ with Standby?", "answer": "Amazon OpenSearch Service automatically fails over from active to standby nodes in under a minute when the following events occur: loss of one active AZ or all nodes in an active AZ, loss of connectivity to one active AZ, instance hardware failure in the active AZ, and storage failure on a node in the active AZ.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T18:00:40.731937"}}
{"question": "What is the primary difference between the 'Zone Awareness' option and the Multi-AZ with Standby option in terms of capacity handling?", "answer": "The primary difference between the 'Zone Awareness' option and the Multi-AZ with Standby option is how redundant or additional capacity is handled to maintain availability. Multi-AZ with Standby requires at least one copy of data in each AZ to explicitly reserve capacity in one AZ as standby, which acts as a failover target during AZ disruption or instance failure. In contrast, the existing model requires maintaining optimum levels of resources to serve the workload without a specific standby capacity.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T18:00:40.732287"}}
{"question": "How does the sizing approach for Multi-AZ with Standby differ from the existing model in terms of redundancy?", "answer": "For Multi-AZ with Standby, the sizing approach involves looking at the capacity needed to service the workload and then adding 50% for redundancy. In the existing model, you maintain optimum levels of resources to serve your workload without specifically reserving additional capacity for standby purposes.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-04T18:00:40.732832"}}
{"question": "What is the Monthly Uptime Percentage guaranteed by the Amazon OpenSearch Service SLA?", "answer": "The Amazon OpenSearch Service SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-04T18:00:48.327949"}}
{"question": "What are the responsibilities of a user under the shared responsibility model for Amazon OpenSearch Service?", "answer": "Under the shared responsibility model for Amazon OpenSearch Service, you are responsible for ensuring that your cluster is sized in accordance with your workload. This includes monitoring error and latency metrics, as well as storage, CPU, and RAM utilization for signals that the cluster may be overloaded and needs to be scaled.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-04T18:00:48.328290"}}
{"question": "How does the cost of moving to Multi-AZ with Standby relate to a cluster's current sizing and redundancy?", "answer": "If your cluster already follows the best practices and has at least three copies of data for a 3-AZ cluster, you are unlikely to incur additional costs in moving to Multi-AZ with Standby. However, if the cluster is undersized or lacks enough redundant capacity to serve the workload, you will need to add capacity to move to Multi-AZ with Standby for enhanced availability and performance.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-04T18:00:48.328812"}}
{"question": "Which instance types support cross-cluster search?", "answer": "Cross-cluster search is supported on the following instance types: i2, i3 family; r3, r4, r5 family; m4, m5 family; c4, c5 family; and Graviton family.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-04T18:00:56.109376"}}
{"question": "What are the requirements for domains participating in cross-cluster replication?", "answer": "Domains participating in cross-cluster replication need to meet the following criteria: they must be on Elasticsearch version 7.10, have encryption in transit enabled, have Fine Grained Access Control (FGAC) enabled, and their versions should adhere to the same rules as rolling version upgrades.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-04T18:00:56.109741"}}
{"question": "How does cross-cluster search support differ from cross-cluster replication regarding instance types?", "answer": "Cross-cluster search supports a variety of instance types including i2, i3, r3, r4, r5, m4, m5, c4, c5, and Graviton families, while cross-cluster replication does not support Ultrawarm or Cold Storage.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-04T18:00:56.110256"}}
{"question": "When was the OpenSearch project announced?", "answer": "The OpenSearch project was announced on April 12, 2021.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-04T18:01:02.322266"}}
{"question": "What is the significance of the name change from Amazon Elasticsearch Service to Amazon OpenSearch Service?", "answer": "The name change from Amazon Elasticsearch Service to Amazon OpenSearch Service signifies a commitment to a community-driven, open source project that continues to support users with a secure, high-quality search and analytics suite. It reflects the introduction of OpenSearch, which is derived from Elasticsearch and includes new SDK and configuration APIs that users need to adopt for future functionalities.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-04T18:01:02.322516"}}
{"question": "How does the support for OpenSearch 1.0 compare to the support for legacy Elasticsearch versions in the service?", "answer": "Support for OpenSearch 1.0 was added to the managed service on September 7, 2021, and the service changed its name to Amazon OpenSearch Service. In contrast, support for legacy Elasticsearch versions continues until 7.10, allowing users to maintain their existing operations while transitioning to the new OpenSearch functionalities.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-04T18:01:02.322897"}}
{"question": "Will my existing setup continue to work after upgrading to OpenSearch 1.0?", "answer": "Yes, from a backward compatibility perspective, your existing setup will continue to work with OpenSearch 1.0. However, it is recommended to eventually move to the latest SDK for a cleaner and up-to-date experience.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:01:11.164828"}}
{"question": "What are the benefits of upgrading to OpenSearch 1.x?", "answer": "Upgrading to OpenSearch 1.x ensures that your search infrastructure is built on a growing and dynamic Apache-Licensed open source project. It also provides access to a wealth of innovative improvements and features available in OpenSearch 1.2, including enterprise-grade security, alerting, data-lifecycle management, observability, ML-based anomaly detection, and more, all with no additional licensing fees.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:01:11.165136"}}
{"question": "How does the blue/green deployment process work during an upgrade to OpenSearch?", "answer": "During a blue/green (BG) deployment process, the service adds nodes to the OpenSearch Service cluster in the new configuration and version. It migrates data from the old nodes and drops the old nodes once the data migration is complete. While the BG process is designed not to interfere with query and indexing requests, some changes, particularly those involving security-related settings, may cause dashboards to be unavailable during the change period.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:01:11.165538"}}
{"question": "What version of Elasticsearch is OpenSearch 1.0 a fork of?", "answer": "OpenSearch 1.0 is a fork of open source Elasticsearch 7.10.2.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-04T18:01:18.416789"}}
{"question": "What should users do to ensure compatibility with older clients when migrating to OpenSearch Service?", "answer": "Users should try to bring their older clients up to a minimum standard of support on Elasticsearch 7.10.2 to ensure a smooth transition, especially if the clients perform version checking or leverage functionality targeted to older versions of Elasticsearch.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-04T18:01:18.417174"}}
{"question": "How does the compatibility of OpenSearch 1.0 compare to Elasticsearch 7.10.2 regarding client usage?", "answer": "OpenSearch 1.0 is wire-compatible with Elasticsearch 7.10, meaning that users typically do not need to change their usage. Most existing clients can continue to be used due to the APIs and core search functionality being compatible with Elasticsearch version 7.10.2, but users with older clients or those that perform version checks may need to address compatibility issues.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-04T18:01:18.417546"}}
{"question": "What is OpenSearch 1.0 a fork of?", "answer": "OpenSearch 1.0 is a fork of Elasticsearch 7.10.2.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:01:31.627035"}}
{"question": "What are the benefits of enabling compatibility mode in OpenSearch 1.0?", "answer": "Enabling compatibility mode in OpenSearch 1.0 allows Elasticsearch clients to be compatible with OpenSearch 1.0.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:01:31.627552"}}
{"question": "How does the support policy for OpenSearch Service versions differ between Standard Support and Extended Support?", "answer": "Every engine version launched in OpenSearch Service is covered by Standard Support, which includes regular bug fixes and security updates. When Standard Support ends, an Extended Support period of at least 12 months begins, during which AWS provides critical security fixes and operating system patches. While in Extended Support, users will incur additional charges besides standard instance and storage costs.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:01:31.627769"}}
{"question": "What additional charge applies to domains running Extended Support?", "answer": "Domains that are running Extended Support will be charged an additional flat fee per Normalized Instance Hour (NIH), in addition to the standard instance and storage pricing.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-04T18:01:40.782748"}}
{"question": "How is the Normalized Instance Hour (NIH) calculated for domains under Extended Support?", "answer": "Normalized Instance Hour (NIH) is computed as a factor of the instance size (e.g., medium, large) and the number of instance hours. For example, for an m7g.medium.search instance, the NIH is calculated as $0.0065 multiplied by the number of instance hours and the size normalization factor.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-04T18:01:40.783125"}}
{"question": "How does the cost for running an instance under Extended Support compare to running it under Standard Support?", "answer": "The cost for running an instance under Extended Support includes the standard instance usage cost plus an additional charge for Extended Support. For example, if you run an instance for 24 hours, the standard cost may be $1.632, and with Extended Support, you would pay an additional $0.312, making the total $1.944. In contrast, under Standard Support, you would only pay the standard instance usage cost without the additional Extended Support fee.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-04T18:01:40.783642"}}
{"question": "What happens to domains running a version after the end of Extended Support?", "answer": "Once Extended Support ends for a version, domains running that specific version will not receive bug fixes or security updates. They will be isolated, and data will be preserved for at least 30 days. Isolated domains can no longer be accessed, and you will have to restore data into a new domain running a supported version.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-04T18:01:48.576923"}}
{"question": "Why is it recommended to upgrade to a supported version before the end of Extended Support?", "answer": "It is recommended to upgrade to a supported version before the end of Extended Support because, after this period, domains running unsupported versions will not receive any bug fixes or security updates, which could leave them vulnerable. Additionally, isolated domains cannot be accessed, making data recovery more complex.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-04T18:01:48.577205"}}
{"question": "How does the zero-ETL integration with Amazon DynamoDB differ from traditional data pipeline management?", "answer": "The zero-ETL integration with Amazon DynamoDB abstracts away the operational complexity involved in orchestrating the replication of data from an operational datastore to a search datastore. In contrast, traditional data pipelines can be challenging and costly to build and manage, often suffering from intermittent errors that are difficult to track. The integration provides a fully managed solution that enables near real-time search results from transactional data, which is not typically the case with traditional data pipelines.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-04T18:01:48.577364"}}
{"question": "What is the primary function of the zero-ETL integration between Amazon OpenSearch Service and Amazon DynamoDB?", "answer": "The primary function of the zero-ETL integration is to seamlessly move operational data from Amazon DynamoDB to Amazon OpenSearch Service using Amazon OpenSearch Ingestion.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-04T18:01:55.900501"}}
{"question": "How does Amazon OpenSearch Ingestion enhance the data replication process from Amazon DynamoDB to Amazon OpenSearch Service?", "answer": "Amazon OpenSearch Ingestion enhances the data replication process by understanding the structure of Amazon DynamoDB tables, bootstrapping an Amazon OpenSearch Service managed cluster or serverless collection with existing data, and leveraging native data transformational capabilities to aggregate and filter the data while in motion.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-04T18:01:55.900743"}}
{"question": "What role does the IAM role play in the zero-ETL integration feature between Amazon DynamoDB and Amazon OpenSearch Service?", "answer": "The IAM role created by the zero-ETL integration feature has the necessary permissions to read data from Amazon DynamoDB tables and write to an Amazon OpenSearch domain or collection, and it is assumed by Amazon OpenSearch Ingestion pipelines to maintain the right security posture during data movement.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-04T18:01:55.901209"}}
{"question": "What can customers view related to their zero-ETL integration with Amazon DynamoDB?", "answer": "Customers can view all the metrics related to their zero-ETL integration with Amazon DynamoDB on the dashboards provided by Amazon OpenSearch Ingestion, along with real-time logs in Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-04T18:02:03.416218"}}
{"question": "How does the OpenSearch Service query engine enhance the analysis of operational data stored in cloud object stores?", "answer": "The OpenSearch Service query engine enhances the analysis of operational data stored in cloud object stores, such as Amazon S3 and S3-based data lakes, by supporting this analysis without duplicating data. Additionally, it offers built-in query acceleration capabilities to boost the performance of queries and facilitate the creation of fast-loading dashboards.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-04T18:02:03.416561"}}
{"question": "What are the differences in access requirements when setting up a new Direct Query data source compared to regular querying in OpenSearch Service?", "answer": "When setting up a new Direct Query data source, customers need to provide read/write access to Amazon S3 and AWS Glue Data Catalog to facilitate querying data in Amazon S3 from OpenSearch Service. In contrast, regular querying in OpenSearch Service does not specifically mention the need for such access to Amazon S3 and AWS Glue Data Catalog.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-04T18:02:03.417162"}}
{"question": "What are the units used to measure compute capacity in OpenSearch Service?", "answer": "The compute capacity in OpenSearch Service is measured in OpenSearch Compute Units (OCUs).", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-04T18:02:09.164284"}}
{"question": "How does the query-access integration between Amazon OpenSearch Service and Amazon Security Lake benefit security analysts?", "answer": "The query-access integration allows security analysts to use the OpenSearch Dashboards console to run direct queries on the data in Security Lake and leverage on-demand indexing and pre-built content to get started with security-related queries.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-04T18:02:09.164660"}}
{"question": "What is the difference between query-access integration and data-access integration in Amazon OpenSearch Service and Security Lake?", "answer": "In the query-access integration, security analysts can run direct queries on Security Lake data using the OpenSearch Dashboards console, while in the data-access integration, the OpenSearch ingestion service provides a preconfigured Security Lake blueprint for ingesting Open Cybersecurity Schema Framework (OCSF) parquet files from Security Lake.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-04T18:02:09.165171"}}
{"question": "What do you need to have in place before getting started with integrating Security Lake and Amazon OpenSearch Service?", "answer": "You first need to have an existing Security Lake setup in your AWS environment. This will provide the centralized storage and access to your enterprise security data.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-04T18:02:15.835293"}}
{"question": "What is the purpose of configuring permissions and access controls when integrating Security Lake with Amazon OpenSearch Service?", "answer": "Configuring the necessary permissions and access controls allows Amazon OpenSearch Service to securely access and query the data in your Security Lake.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-04T18:02:15.835641"}}
{"question": "How does using AWS Management Console differ from using AWS CloudFormation templates for enabling integration between Security Lake and Amazon OpenSearch Service?", "answer": "The context does not provide specific differences between using AWS Management Console and AWS CloudFormation templates for enabling integration. Both methods involve configuring the necessary permissions and access controls.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-04T18:02:15.836097"}}
{"question": "What capabilities does AWS Organizations provide for managing AWS accounts?", "answer": "AWS Organizations enables several capabilities including automating AWS account creation and management, maintaining a secure environment with policies and management of AWS security services, governing access to AWS services, resources, and regions, centrally managing policies across multiple AWS accounts, auditing your environment for compliance, viewing and managing costs with consolidated billing, and configuring AWS services across multiple accounts.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T18:02:24.867856"}}
{"question": "How does AWS Control Tower enhance the management of AWS accounts compared to AWS Organizations?", "answer": "AWS Control Tower enhances the management of AWS accounts by providing built-in best practices for creating and managing a multi-account AWS environment. It automatically sets up account structures and implements preventive guardrails using Service Control Policies (SCPs) and Resource Control Policies (RCPs). While AWS Organizations focuses on central governance, AWS Control Tower simplifies multi-account management with automated setup, prescriptive guidance, and flexible controls.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T18:02:24.868113"}}
{"question": "In what ways do AWS Organizations and AWS Control Tower differ in their approach to account management?", "answer": "AWS Organizations focuses on central governance, allowing users to programmatically create new accounts, manage resources, and apply governance policies across accounts. In contrast, AWS Control Tower is built on top of AWS Organizations and provides automated governance with built-in best practices, including the automatic setup of account structures and preventive guardrails. Therefore, while AWS Organizations provides foundational management capabilities, AWS Control Tower adds layers of automation and best practices for enhanced governance.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-04T18:02:24.868216"}}
{"question": "What is the primary function of an AWS account?", "answer": "The primary function of an AWS account is to serve as a container for your AWS resources, allowing you to create and manage these resources while providing administrative capabilities for access and billing.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T18:02:30.111394"}}
{"question": "Why is using multiple AWS accounts considered a best practice?", "answer": "Using multiple AWS accounts is considered a best practice for scaling your environment because it provides a natural billing boundary for costs, isolates resources for security, offers flexibility for individuals and teams, and is adaptable for new business processes.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T18:02:30.111664"}}
{"question": "What distinguishes a management account from a member account in an AWS organization?", "answer": "A management account is the AWS account used to create and manage the organization, having ultimate control over security, infrastructure, and finance policies, while a member account is any AWS account, other than the management account, that is part of the organization and can only belong to one organization at a time.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-04T18:02:30.112153"}}
{"question": "What is an organizational unit (OU) in AWS?", "answer": "An organizational unit (OU) is a group of AWS accounts within an organization. It can also contain other OUs, allowing the creation of a hierarchy. For example, you can group all accounts that belong to the same department into a departmental OU or group all accounts running security services into a security OU.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-04T18:02:37.321661"}}
{"question": "Why are organizational units (OUs) useful in AWS Organizations?", "answer": "OUs are useful when you need to apply the same controls to a subset of accounts in your organization. They enable smaller units of management, allowing for the creation of nested OUs for better organization, such as separating production workloads from pre-production within workload OUs. Policies from parent OUs can also be inherited by nested OUs.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-04T18:02:37.321999"}}
{"question": "How do service control policies (SCPs) and resource control policies (RCPs) differ in their function within AWS Organizations?", "answer": "Service control policies (SCPs) offer central control over the maximum available permissions for IAM users and IAM roles in an organization, while resource control policies (RCPs) offer central control over the maximum available permissions for resources in an organization. Thus, SCPs focus on user and role permissions, whereas RCPs focus on resource permissions.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-04T18:02:37.322488"}}
{"question": "What is the first step to invite an existing AWS account to join your organization?", "answer": "The first step to invite an existing AWS account to join your organization is to sign in as an administrator of the management account and navigate to the AWS Organizations console.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:02:44.796261"}}
{"question": "Why is it important to select the management account carefully?", "answer": "It is important to select the management account carefully because you cannot change which AWS account is the management account once it is set.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:02:44.796592"}}
{"question": "What is the difference between inviting an existing account and creating a new account in your organization?", "answer": "Inviting an existing account involves sending an invitation to an already existing AWS account, which must then be accepted by an administrator of that account, while creating a new account involves directly setting up a new AWS account within your organization using the management account, where you provide a name and email address for the account.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:02:44.797109"}}
{"question": "What does AWS Organizations create when a new account is created?", "answer": "When a new account is created as part of AWS account creation, AWS Organizations creates an IAM role with full administrative permissions in the new account.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T18:02:52.068192"}}
{"question": "What steps must be taken to make an account standalone after it has been created in an organization?", "answer": "To make an account standalone after it has been created in an organization, you must first remove the account from your organization. After making the account standalone, you need to update certain information, such as providing contact information, a valid payment method, and choosing a support plan option.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T18:02:52.068526"}}
{"question": "How does the process of removing a member account differ between signing in as an administrator of the master account and signing in as an administrator of the member account?", "answer": "When removing a member account by signing in to the management account, you navigate to the AWS Organizations console, select the account to remove, and choose 'Remove account.' If the account lacks a valid payment method, you must provide one. In contrast, when removing a member account by signing in as an administrator of the member account, you navigate to the AWS Organizations console and choose 'Leave organization.' If this account also lacks a payment method, you must provide one as well.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-04T18:02:52.068723"}}
{"question": "What are the steps to create an organizational unit (OU) in AWS Organizations?", "answer": "To create an OU, sign in as an administrator of the management account and navigate to the AWS Organizations console. Then, choose the 'Organize accounts' tab, navigate in the hierarchy to where you want to create the OU, and choose 'Create organizational unit.' Provide a unique name for your OU. Note that you can rename the OU later.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-04T18:02:59.849120"}}
{"question": "What is the maximum depth for nesting organizational units (OUs) in AWS Organizations?", "answer": "You can nest your OUs five levels deep. This includes the root and AWS accounts created in the lowest OUs; your hierarchy can be a total of five levels deep.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-04T18:02:59.849462"}}
{"question": "How does the membership of an AWS account in an organizational unit (OU) compare to that of an OU itself?", "answer": "An AWS account can be a member of only one OU at a time, while an OU can also be a member of only one OU at a time. This means that both accounts and OUs have a restriction of single membership within the hierarchy.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-04T18:02:59.849851"}}
{"question": "What are the two ways to attach a policy in AWS Organizations?", "answer": "You can attach a policy in one of two ways: first, by navigating to where you want to assign the policy in the AWS Organizations console (the root, an OU, or an account), and then choosing 'Attach Policy'. Second, by going to the 'Policies' tab in the Organizations console, selecting an existing policy, choosing 'Attach Policy' from the 'Actions' drop-down list, and then selecting the root, OU, or account to which you want to attach the policy.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-04T18:03:08.514665"}}
{"question": "What is the purpose of service control policies (SCPs) in AWS Organizations?", "answer": "Service control policies (SCPs) offer central control over the maximum available permissions for IAM users and IAM roles in an organization. They help manage and restrict permissions across all accounts under an organization.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-04T18:03:08.515127"}}
{"question": "How do resource control policies (RCPs) differ from backup policies in AWS Organizations?", "answer": "Resource control policies (RCPs) offer central control over the maximum available permissions for resources in an organization, while backup policies allow you to centrally manage and apply backup plans to AWS resources across an organization's accounts. In summary, RCPs focus on permissions for resources, whereas backup policies focus on managing backup plans for those resources.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-04T18:03:08.515517"}}
{"question": "What do Service Control Policies (SCPs) allow you to control in an AWS organization?", "answer": "Service Control Policies (SCPs) allow you to control which AWS service actions are accessible to principals, including account root, IAM users, and IAM roles, in the accounts of your organization.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:03:14.901872"}}
{"question": "How do SCPs determine the effective permissions for a principal in an AWS account?", "answer": "The effective permissions on a principal in an account that has an SCP attached are determined by the intersection of what is allowed explicitly in the SCP and what is allowed explicitly in the permissions attached to the principal.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:03:14.902209"}}
{"question": "How do SCPs compare to IAM policies regarding permissions when an empty policy is attached?", "answer": "SCPs behave the same way as IAM policies in that an empty IAM policy is equivalent to a default DENY. Therefore, attaching an empty SCP to an account is equivalent to attaching a policy that explicitly denies all actions.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:03:14.902687"}}
{"question": "Can the IAM policy simulator include the effects of Service Control Policies (SCPs)?", "answer": "Yes, the IAM policy simulator can include the effects of SCPs. It can be used in a member account to understand the effect on individual principals in that account.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-04T18:03:24.748993"}}
{"question": "What is the purpose of a Resource Control Policy (RCP) in AWS Organizations?", "answer": "A Resource Control Policy (RCP) is used to define and enforce preventative controls on AWS resources within your organization. It allows you to centrally set the maximum available permissions for your AWS resources as you scale your workloads, helping to restrict access to resources to only those identities that belong to your organization or to specify conditions for external access.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-04T18:03:24.749329"}}
{"question": "How do declarative policies differ from Resource Control Policies (RCPs) in terms of enforcement?", "answer": "Declarative policies are management policies that enforce durable intent, such as maintaining baseline configurations for AWS services, while Resource Control Policies (RCPs) focus specifically on defining and enforcing preventative controls on AWS resources. Declarative policies prevent non-compliant actions and maintain configurations during changes in APIs or organizational resources, whereas RCPs set maximum permissions and access restrictions.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-04T18:03:24.749969"}}
{"question": "What do service control policies (SCPs) provide for IAM users and roles in an organization?", "answer": "Service control policies (SCPs) offer central control over the maximum available permissions for IAM users and IAM roles in an organization.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-04T18:03:33.561365"}}
{"question": "How do declarative policies simplify the management of service control policies?", "answer": "Declarative policies provide a simpler way to define the configuration and offer end users visibility into why their actions failed through customizable error messages. They eliminate the need to update SCPs with new APIs to protect configuration objectives, as once set, a declarative policy will maintain the configuration.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-04T18:03:33.561700"}}
{"question": "What is the relationship between existing SCPs and declarative policies when they are used together?", "answer": "If you have existing SCPs for a control supported by declarative policies, adding them to a declarative policy will serve as an additional layer of protection to enforce the desired configuration.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-04T18:03:33.562185"}}
{"question": "What types of applications can utilize Outposts racks?", "answer": "Outposts racks can support applications that have low latency or local data processing requirements. These applications may need to generate near real-time responses to end user applications or communicate with on-premises systems or control on-site equipment. Examples include workloads running on factory floors for automated operations in manufacturing, real-time patient diagnosis or medical imaging, and content and media streaming.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-04T18:03:42.329814"}}
{"question": "Why would a company choose to use Outposts racks for data storage and processing?", "answer": "A company would choose to use Outposts racks to securely store and process customer data that needs to remain on-premises or in countries where there is no AWS Region. Additionally, they can run data-intensive workloads on Outposts racks to process data locally, which is beneficial when transmitting data to AWS Regions is expensive and wasteful, providing better control over data analysis, backup, and restore.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-04T18:03:42.330190"}}
{"question": "How do Outposts racks compare to traditional AWS Regions in terms of data processing for certain applications?", "answer": "Outposts racks are specifically designed to support applications that require low latency or local data processing, whereas traditional AWS Regions may not be suitable for applications that need to generate near real-time responses or communicate with on-premises systems. Outposts racks allow for local processing of data-intensive workloads, which can be more efficient when sending data to AWS Regions is costly or inefficient.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-04T18:03:42.330808"}}
{"question": "Which AWS Regions support first-generation Outposts racks?", "answer": "First-generation Outposts racks are currently supported in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Canada (Central), South America (So Paulo), EU (Frankfurt), EU (Stockholm), EU (Ireland), EU (London), EU (Paris), EU (Milan), EU (Spain), Middle East (Bahrain), Middle East (UAE), Israel (Tel Aviv), Africa (Cape Town), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Jakarta), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Osaka), Asia Pacific (Mumbai), AWS GovCloud (US-West), and AWS GovCloud (US-East).", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T18:03:53.609860"}}
{"question": "What is the difference between first-generation and second-generation Outposts racks in terms of supported AWS Regions?", "answer": "First-generation Outposts racks are supported in a broader range of AWS Regions compared to second-generation Outposts racks. While both generations support US East (N. Virginia), US East (Ohio), US West (N. California), and US West (Oregon), first-generation racks can connect to many additional regions including those in Canada, South America, Europe, the Middle East, Africa, and Asia Pacific. In contrast, second-generation Outposts racks are limited to just the four regions mentioned.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T18:03:53.610236"}}
{"question": "Can customers connect their Outposts to the same AWS Regions for both first-generation and second-generation racks?", "answer": "Yes, customers can connect their Outposts to the same AWS Regions for both first-generation and second-generation racks in the following regions: US East (N. Virginia), US East (Ohio), US West (N. California), and US West (Oregon).", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-04T18:03:53.610716"}}
{"question": "What is the AWS Region code for Canada (Central)?", "answer": "The AWS Region code for Canada (Central) is ca-central-1.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-04T18:04:00.294363"}}
{"question": "Why is it recommended to consult with an AWS sales representative or APN partner regarding home Region options?", "answer": "It is recommended to consult with an AWS sales representative or APN partner to evaluate available home Region options in your geography and to seek a custom recommendation about the service link bandwidth and latency requirements for your workloads.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-04T18:04:00.294717"}}
{"question": "How does the AWS Region in Singapore compare to the Regions in Europe in terms of location?", "answer": "The AWS Region in Singapore (ap-southeast-1) is located in Asia Pacific, while the Regions in Europe include EU (London) with the code eu-west-2 and EU (Paris) with the code eu-west-3.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-04T18:04:00.295246"}}
{"question": "In which countries can first-generation Outposts racks be installed?", "answer": "First-generation Outposts racks can be shipped to and installed in the US, Canada, Mexico, all EU countries, the United Kingdom, Switzerland, Norway, Bahrain, the United Arab Emirates, Israel, South Africa, Gibraltar, Morocco, Nigeria, Kenya, Oman, Kazakhstan, Serbia, Qatar, Egypt, Iceland, Turkey, the Kingdom of Saudi Arabia, Senegal, Jordan, and Kuwait in the EMEA region; Australia, New Zealand, Japan, South Korea, Taiwan, Singapore, Indonesia, Malaysia, Thailand, the Philippines, Brunei, India, Vietnam, and Bangladesh in the APAC region; Brazil, Colombia, Argentina, Chile, Peru, Ecuador, Trinidad and Tobago, and Uruguay in the SA region; and Puerto Rico, Costa Rica, Panama, and Guatemala in the CA region.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-04T18:04:13.119876"}}
{"question": "What are the key differences between the countries where first-generation and second-generation Outposts racks can be installed?", "answer": "The key differences between first-generation and second-generation Outposts racks regarding installation countries are that first-generation racks can be installed in more countries, including Mexico, South Africa, Gibraltar, Morocco, Nigeria, Oman, Kazakhstan, Serbia, Qatar, and additional countries in the APAC region like South Korea, Taiwan, and India. In contrast, second-generation racks have a more limited list, excluding Mexico, South Africa, and several others while retaining only a subset of APAC countries.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-04T18:04:13.120273"}}
{"question": "Why is connectivity important for Outposts racks?", "answer": "Connectivity is important for Outposts racks because they rely on a connection to the parent AWS Region. They are not designed for disconnected operations or environments with limited to no connectivity. AWS recommends customers to have highly available networking connections back to their AWS Region to ensure proper functionality.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-04T18:04:13.120749"}}
{"question": "What type of hardware do AWS Outposts racks leverage?", "answer": "AWS Outposts racks leverage AWS designed infrastructure and are only supported on AWS-designed hardware that is optimized for secure, high-performance, and reliable operations.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-04T18:04:23.030413"}}
{"question": "What are the benefits of using AWS Outposts racks?", "answer": "AWS Outposts racks are a fully managed service that provides native access to AWS services, and they come with fully integrated AWS designed configurations including built-in top-of-rack switches and redundant power supply to ensure an ideal AWS experience. They also allow users to order as much compute and storage infrastructure as needed, with options to create custom combinations of Amazon EC2, Amazon EBS, and Amazon S3 capacity.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-04T18:04:23.030771"}}
{"question": "How do AWS Outposts racks differ from traditional AWS services?", "answer": "AWS Outposts racks differ from traditional AWS services in that they provide physical infrastructure designed by AWS that operates on-premises while still offering native access to AWS services. Additionally, Outposts racks come with fully integrated configurations and are a fully managed service that requires no additional effort or configuration on-site, unlike traditional services that may only be accessed remotely without local infrastructure.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-04T18:04:23.031426"}}
{"question": "What are the primary benefits of second-generation Outposts racks?", "answer": "The primary benefits of second-generation Outposts racks include simplified scaling and built-in resiliency, supporting the latest in-Region EC2 instance types, and the introduction of new purpose-built Outposts instance types.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T18:04:29.824845"}}
{"question": "How do the new purpose-built Outposts instance types differ from previous instance types?", "answer": "The new purpose-built Outposts instance types, such as Bmn-sf2e and Bmn-cx2, are specifically designed for ultra-low latency and throughput-intensive workloads, featuring accelerated networking. In contrast, previous instance types did not have this specialized focus on low latency and high throughput.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T18:04:29.825187"}}
{"question": "How do the performance capabilities of the C7i, M7i, and R7i instances compare to C5, M5, and R5 instances on first-generation Outposts racks?", "answer": "C7i, M7i, and R7i instances deliver 2x the vCPU, memory, and network bandwidth and up to 40% better performance compared to C5, M5, and R5 instances on first-generation Outposts racks.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-04T18:04:29.825561"}}
{"question": "What types of EBS volume types can be used to launch EC2 instances on second-generation Outposts racks?", "answer": "You can launch EC2 instances using AMIs backed with EBS gp2 or gp3 volume types on second-generation Outposts racks.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:04:36.927804"}}
{"question": "How do EBS snapshots work on Outposts racks, and what is their storage option?", "answer": "EBS snapshots of EBS Volumes on Outposts racks are stored by default on Amazon S3 in the Region. If the Outpost is provisioned with Amazon S3 on Outposts, you have the option to store your snapshots locally on your Outpost. EBS snapshots are incremental, meaning only the blocks on your Outpost that have changed after your most recent snapshot are saved.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:04:36.928131"}}
{"question": "What is the difference between using S3 on Outposts and traditional S3 for customers with data residency requirements?", "answer": "S3 on Outposts, available on first-generation Outposts racks, is ideal for customers with data residency requirements or those in regulated industries that need to securely store and process customer data on premises or in locations without an AWS region. In contrast, traditional S3 does not offer the same on-premises data residency capabilities.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:04:36.928743"}}
{"question": "What types of databases can you run with Amazon RDS on Outposts?", "answer": "With Amazon RDS on Outposts, you can run managed Microsoft SQL Server, MySQL, and PostgreSQL databases on premises for low latency workloads that need to be run in close proximity to on-premises data and applications.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T18:04:46.175980"}}
{"question": "How does AWS facilitate data residency with Outposts racks?", "answer": "AWS facilitates data residency with Outposts racks by allowing customer data to be configured to remain on Outposts racks using Amazon Elastic Block Store (EBS) and Amazon Simple Storage Service (S3) on Outposts. Customers can control access and specify data residency requirements using AWS Identity and Access Management (IAM) and granular data control rules. S3 on Outposts stores data on the Outpost by default, and customers may choose to replicate some or all of their data to AWS Regions based on their specific residency requirements.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T18:04:46.176213"}}
{"question": "What is the difference between S3 on Outposts and ElastiCache on Outposts regarding data handling?", "answer": "S3 on Outposts is designed to store data on the Outpost by default and allows for the option to replicate some or all data to AWS Regions. In contrast, ElastiCache on Outposts enables secure local processing of customer data on the Outposts rack, providing sub-millisecond responses for ultra low-latency applications without the need for replication to the AWS Region.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-04T18:04:46.176353"}}
{"question": "What is AWS Resource Access Manager (RAM) used for?", "answer": "AWS Resource Access Manager (RAM) is a service that enables you to share your AWS resources with any AWS account or within your AWS Organization. It allows the Outpost owner to create and manage Outpost resources like EC2 instances, EBS volumes, subnets, and local gateways centrally, and share these resources across multiple AWS accounts within the same organization.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:04:53.664192"}}
{"question": "How does Route 53 Resolver improve the performance of on-premises applications on Outposts?", "answer": "Route 53 Resolver improves the performance of on-premises applications on Outposts by resolving Domain Name Server (DNS) queries locally. When enabled on Outposts, it stores DNS responses on Outposts racks, providing continued DNS resolution even during unexpected network disconnects to the parent AWS Region. This local serving of DNS responses also enables low-latency DNS resolution, enhancing the performance of on-premises applications.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:04:53.664562"}}
{"question": "What types of EC2 instances are supported on AWS Outposts racks?", "answer": "AWS Outposts racks support EC2 instances built on the AWS Nitro System, including general purpose, compute optimized, memory optimized, storage optimized, and GPU optimized instances with Intel Xeon Scalable processors. Additionally, Graviton processors based EC2 instances are expected to be available soon.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:04:53.665052"}}
{"question": "What are the power requirements for first-generation Outposts racks deployments?", "answer": "First-generation Outposts racks deployments require 5-15 kVA of power.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:04:59.986820"}}
{"question": "What is the significance of compliance certifications for AWS Outposts racks?", "answer": "Compliance certifications for AWS Outposts racks, such as HIPAA eligibility and PCI compliance, indicate that these racks meet specific regulatory standards, which can be crucial for customers needing to ensure their data handling and storage practices adhere to legal and industry requirements. Customers are also responsible for physical security and access controls under the AWS Shared Responsibility model.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:04:59.987108"}}
{"question": "How do the power and space requirements differ between first-generation and second-generation Outposts racks?", "answer": "First-generation Outposts racks require 5-15 kVA of power and space for a single 42U rack. In contrast, second-generation Outposts racks require more power, with the compute rack needing 10-30 kVA and the network rack needing 8.89 kVA, and they require space for two 42U racks.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:04:59.987699"}}
{"question": "Are AWS Outposts racks GxP compatible?", "answer": "Yes, AWS Outposts racks are GxP compatible.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-04T18:05:07.385049"}}
{"question": "What responsibilities do customers have regarding GxP compliance when using AWS Outposts?", "answer": "GxP-regulated life sciences organizations using AWS services are responsible for designing and verifying their GxP compliance.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-04T18:05:07.385389"}}
{"question": "How do the responsibilities of customers differ between AWS Outposts and Bmn-sf2/Bmn-cx2 instances?", "answer": "For AWS Outposts, customers are responsible for attesting to physical security and access controls, as well as environmental requirements. In contrast, for Bmn-sf2 and Bmn-cx2 instances, customers are responsible for managing the network accelerator cards and associated bare metal network switches, which can be handled by in-house IT, AWS services, or third-party providers.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-04T18:05:07.385811"}}
{"question": "What will AWS automatically execute for an Outpost when it is installed and visible in the AWS Management Console?", "answer": "AWS will automatically execute software upgrades and patches for an Outpost when it is installed and visible in the AWS Management Console.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T18:05:14.676816"}}
{"question": "How does AWS handle API availability during a disconnection of an Outpost?", "answer": "During a disconnection of an Outpost, API availability will be degraded, meaning that run/start/stop/terminate APIs may not work. However, instance metrics and logs will continue to be cached locally for up to 7 days and will be pushed to the AWS Region when connectivity returns.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T18:05:14.677112"}}
{"question": "What can users do with existing S3 buckets during a disconnection period, and what actions are restricted?", "answer": "During a disconnection period, existing users can continue to operate on existing S3 buckets with all object operations for up to 12 hours. They can add and delete objects, but they cannot create or add new buckets, new users, or change bucket policies.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-04T18:05:14.677700"}}
{"question": "What are the two mechanisms available to increase the compute and storage capacity of AWS Outposts racks?", "answer": "The two mechanisms to increase the compute and storage capacity of AWS Outposts racks are: 1) adding additional Outposts racks from the Outposts rack catalog, and 2) increasing the configuration of existing Outposts racks from 'small' to 'medium' or 'large', or from 'medium' to 'large', provided there is available power and positions within the rack.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-04T18:05:22.089149"}}
{"question": "Why might an AWS user choose to increase the configuration of their existing Outposts racks instead of adding new racks?", "answer": "An AWS user might choose to increase the configuration of their existing Outposts racks instead of adding new racks if their current racks have available power and positions. This option allows for a more efficient use of existing resources without the need to purchase and integrate additional hardware.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-04T18:05:22.089483"}}
{"question": "How does the capacity increase differ between adding new Outposts racks and upgrading existing racks?", "answer": "When adding new Outposts racks, you are expanding your capacity by introducing additional hardware from the Outposts rack catalog. In contrast, upgrading existing racks involves changing the configuration of the current racks from smaller to larger configurations (from 'small' to 'medium' or 'large', or from 'medium' to 'large') if there is sufficient power and space. This represents a more flexible use of existing infrastructure compared to simply adding more equipment.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-04T18:05:22.090000"}}
{"question": "What type of service is Amazon Personalize?", "answer": "Amazon Personalize is a fully managed machine learning (ML) service that generates product and content recommendations for users based on the data provided.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-04T18:05:27.321086"}}
{"question": "How does Amazon Personalize enhance customer experience?", "answer": "Amazon Personalize enhances customer experience by using algorithms to analyze customer behavior and recommend products, content, and services that are likely to be of interest to them, which can increase customer engagement, loyalty, and sales.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-04T18:05:27.321524"}}
{"question": "What are the key components of data that users need to provide for Amazon Personalize?", "answer": "Users need to provide data about their end-users, such as age, location, and device type; items in their catalog, including genre and price; and interactions between users and items, like clicks and purchases.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-04T18:05:27.321847"}}
{"question": "What is one way that Amazon Personalize improves user engagement?", "answer": "Amazon Personalize improves user engagement by offering personalized recommendations, which are tailored to users' preferences. As a result, users are more likely to interact with products and services that match their interests.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-04T18:05:33.156633"}}
{"question": "How does personalization with Amazon Personalize contribute to customer satisfaction?", "answer": "Personalization with Amazon Personalize contributes to customer satisfaction by allowing businesses to provide a better customer experience. It surfaces products and services that are more relevant to customers' needs and interests, thereby enhancing their overall experience.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-04T18:05:33.156973"}}
{"question": "What are some advantages of using Amazon Personalize over manual analysis for generating recommendations?", "answer": "The advantages of using Amazon Personalize over manual analysis for generating recommendations include the automation of the recommendation generation process, which allows companies to deploy recommendation models in days instead of months. This efficiency helps organizations save valuable time and resources that would otherwise be consumed by manual analysis and recommendation generation.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-04T18:05:33.157480"}}
{"question": "What are some examples of how Amazon Personalize can be used in different industries?", "answer": "Amazon Personalize can be used in various industries for different purposes. For example, it can provide product recommendations for e-commerce, news articles for publications, hotel recommendations for travel websites, credit card suggestions for banks, and match recommendations for dating sites. Additionally, it can personalize experiences in physical channels, such as customizing weekly meals for users in a meal delivery subscription plan.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-04T18:05:40.465240"}}
{"question": "How does Amazon Personalize enhance user experience in a video streaming app?", "answer": "Amazon Personalize enhances user experience in a video streaming app by adding multiple types of personalized video recommendations. These include features like 'Top picks for you', 'More like X', and 'Most popular' video recommendations, which cater to the individual preferences of users.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-04T18:05:40.465710"}}
{"question": "How do personalized product recommendations in an e-commerce app compare to personalized emails generated for users?", "answer": "Personalized product recommendations in an e-commerce app, such as 'Recommended for you', 'Frequently bought together', and 'Customers who viewed X also viewed', focus on suggesting items based on user behavior and preferences within the app. In contrast, personalized emails generated for users involve creating batch recommendations for an entire email list, which can then be sent using an AWS service or third-party service, thus targeting users through email rather than directly within the app.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-04T18:05:40.466110"}}
{"question": "What are the three steps involved in using Amazon Personalize?", "answer": "The three steps involved in using Amazon Personalize are: first, pointing Amazon Personalize to your user interaction data stored in Amazon S3 and optionally providing an items or users dataset; second, training a custom private recommendation model for your data with just a few clicks or API calls; and third, retrieving personalized recommendations.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-04T18:05:48.374143"}}
{"question": "How does Amazon Personalize handle the selection of algorithms for training models?", "answer": "Amazon Personalize can automatically choose the right algorithm for your dataset using AutoML, or you can manually choose one from several available algorithm options.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-04T18:05:48.374378"}}
{"question": "What options are available for importing data into Amazon Personalize?", "answer": "Data can be imported into Amazon Personalize via Amazon Simple Storage Service (S3) or by using SageMaker Data Wrangler. Additionally, real-time activity stream data can be sent using a JavaScript API and Server-Side SDKs.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-04T18:05:48.374726"}}
{"question": "What types of data must users provide to Amazon Personalize?", "answer": "Users must provide user activity stream or event data, catalog (item) data, and user data to Amazon Personalize. User activity stream data includes a historical log of user interactions such as clicks, purchases, and likes. Catalog data can include items like books or products along with their item ids and metadata. User data includes optional profile information such as demographic data like gender and age.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T18:05:56.495795"}}
{"question": "Why is it important to include certain data types when using Amazon Personalize?", "answer": "Including certain data types, such as event type, event value, contextual metadata, and item and user metadata, is important because it can help improve the relevance of recommendations provided by Amazon Personalize. These data types enhance the model's ability to generate individualized recommendations and create a more personalized experience for end-users.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T18:05:56.496128"}}
{"question": "How does user activity stream data differ from catalog data in the context of Amazon Personalize?", "answer": "User activity stream data consists of a historical log of users' interactions on the website or application, capturing events like clicks and purchases. In contrast, catalog data includes information about items such as books or products, which involves item ids and associated metadata. User activity stream data focuses on user interactions, while catalog data focuses on the items themselves.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-04T18:05:56.496697"}}
{"question": "What tool does Amazon Personalize integrate with for data preparation?", "answer": "Amazon Personalize integrates with Amazon SageMaker Data Wrangler for data preparation.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-04T18:06:02.431303"}}
{"question": "How does Amazon Personalize help in improving the quality of data used for personalization models?", "answer": "Amazon Personalize helps improve the quality of data by analyzing the data provided, identifying potential data deficiencies, and offering suggestions to assist customers with remediation, which ultimately enhances the performance of personalization models.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-04T18:06:02.431646"}}
{"question": "How does the 'new item exploration weight' in Amazon Personalize affect user recommendations compared to user exposure data?", "answer": "The 'new item exploration weight' in Amazon Personalize is used to balance exposing new content to users while still offering the most relevant recommendations, whereas user exposure data considers which items users have seen but chosen not to interact with, influencing the recommendations based on user behavior.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-04T18:06:02.432154"}}
{"question": "What is the purpose of the Amazon Personalize Search Ranking plugin within OpenSearch?", "answer": "The Amazon Personalize Search Ranking plugin within OpenSearch helps users leverage the deep learning capabilities offered by Amazon Personalize to apply personalized re-ranking to OpenSearch search results. This enables the personalization of search results for each user, improving the relevance of items based on their interests, context, and past interactions in real-time.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:06:09.977951"}}
{"question": "How does personalized search differ from traditional keyword matching?", "answer": "Personalized search goes beyond the traditional keyword matching approach by boosting relevant items in a user's search results based on their interests, context, and past interactions rather than solely relying on keyword relevance.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:06:09.978294"}}
{"question": "What are the steps to get started with Amazon OpenSearch and Amazon Personalize Search Ranking plugin?", "answer": "To get started with Amazon OpenSearch and the Amazon Personalize Search Ranking plugin, you need to set up an OpenSearch domain, set up an Amazon Personalize campaign using the AWS-personalized-ranking recipe, associate the Amazon Personalize Search Ranking plugin with your domain, and finally configure the plugin. Additionally, you can use the OpenSearch dashboard to compare your search results.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:06:09.978878"}}
{"question": "What are the purposes of the algorithms referred to as recipes in Amazon Personalize?", "answer": "Recipes in Amazon Personalize are algorithms designed for specific personalization use cases, including product or content recommendations, personalized ranking, and user segmentation. Each recipe provides an algorithm that Amazon Personalize uses for model training and configuration.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-04T18:06:17.286534"}}
{"question": "How does the Amazon Personalize Next Best Action (NBA) help brands increase user engagement?", "answer": "Amazon Personalize Next Best Action (NBA) helps brands recommend the best actions for individual users to take in real-time, which can increase loyalty and conversion. Brands define a list of actions, upload required datasets, train their custom NBA model, and then integrate the recommendations into their applications or marketing technology tools via an API.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-04T18:06:17.286849"}}
{"question": "How do the getRecommendations and getPersonalizedRanking APIs compare in Amazon Personalize?", "answer": "The getRecommendations API returns a list of recommended itemIDs for a user or a list of similar items for an item, while the getPersonalizedRanking API returns a reranked list of items for a user. Both APIs provide itemIDs that can be product identifiers, videoIDs, etc., which are then used to enhance the end-user experience.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-04T18:06:17.287046"}}
{"question": "What method is recommended for measuring the impact of a model on business metrics in Amazon Personalize?", "answer": "The recommended method for measuring the impact of a model on business metrics in Amazon Personalize is online testing, also known as A/B testing. This is the most common method and provides the best measure of impact.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T18:06:23.940310"}}
{"question": "How do offline metrics differ from online metrics in the context of Amazon Personalize?", "answer": "Offline metrics in Amazon Personalize are computed for each solution version and recommender to measure the accuracy of predictions from the model, using historical data split into training and testing sets. In contrast, online metrics are empirical results observed from user interactions with recommendations in a live environment, taking into account real-time data generated by users.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T18:06:23.940645"}}
{"question": "What is the purpose of defining a 'metric attribution' in Amazon Personalize?", "answer": "The purpose of defining a 'metric attribution' in Amazon Personalize is to create a list of interactions (event types) that you want to evaluate and report on, which helps in measuring the business outcome of any recommendation. This allows you to visualize and evaluate the impact of one or multiple recommendations, contributing to a more data-driven personalization strategy.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-04T18:06:23.941274"}}
{"question": "What is the ownership status of the model inputs and outputs in Amazon Personalize?", "answer": "The model inputs and outputs in Amazon Personalize are entirely owned by the customer's AWS account, and they are not shared across other AWS accounts or with any other business units such as Amazon Retail or Amazon Prime.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T18:06:30.280401"}}
{"question": "How does Amazon Personalize ensure the security of customer data?", "answer": "Amazon Personalize ensures the security of customer data by protecting every interaction with encryption. Additionally, any user, items, or interactions data processed can be further encrypted with customer keys through AWS Key Management Service. The data is also encrypted at rest and in transit in the AWS Region where the customer is using the service. Access to Amazon Personalize can be controlled through an AWS Identity and Access Management (IAM) permissions policy to keep sensitive information secure and confidential.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T18:06:30.280746"}}
{"question": "What is the difference between user personalization and personalized ranking in Amazon Personalize?", "answer": "User personalization involves tailoring recommendations to a user's profile, behavior, preferences, and history to boost customer engagement and satisfaction. In contrast, personalized ranking refers to re-ranking items in a category or search response based on user preference or history, which surfaces relevant items or content to a specific user while optimizing for business priorities like revenue or promotions.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-04T18:06:30.281228"}}
{"question": "What is the purpose of user segmentation in Amazon Personalize?", "answer": "User segmentation in Amazon Personalize is designed to intelligently segment end-users based on their preferences and create targeted messages that resonate with specific customer groups.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-04T18:06:36.330218"}}
{"question": "How does Amazon Personalize enhance the recommendation process for new products?", "answer": "Amazon Personalize enhances the recommendation process for new products by creating quality recommendations even when data on user preferences is scarce, allowing businesses to effectively promote new items.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-04T18:06:36.330497"}}
{"question": "What distinguishes real-time recommendations from batch recommendations in Amazon Personalize?", "answer": "Real-time recommendations in Amazon Personalize respond to changing user intent immediately, while batch recommendations are designed to feed mass recommendations to batch-oriented workflows, which do not require instant updates.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-04T18:06:36.330919"}}
{"question": "What are the cost management tips provided for Amazon Personalize?", "answer": "The cost management tips for Amazon Personalize include caching results based on your needs for real-time updates, re-training based on business requirements only, relying heavily on auto-scaling by setting the minimum provisioned TPS low unless it negatively impacts your throughput/latency targets, and considering using batch recommendations when the use case aligns with a downstream batch process such as email marketing. Additionally, batch recommendations run against a solution version and do not require a campaign, and they are only available in custom recommendation datasets.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-04T18:06:43.450419"}}
{"question": "How does Amazon Personalize help in managing costs effectively?", "answer": "Amazon Personalize helps in managing costs effectively by allowing users to only pay for what they use, with no minimum fees or upfront commitments. The tips for cost management include caching results, re-training based on business needs, leveraging auto-scaling, and using batch recommendations when appropriate, all of which contribute to optimizing usage and controlling expenses.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-04T18:06:43.450763"}}
{"question": "How do batch recommendations differ from regular campaign recommendations in Amazon Personalize?", "answer": "Batch recommendations in Amazon Personalize differ from regular campaign recommendations in that they run against a solution version and do not require a campaign. Additionally, batch recommendations are only available in custom recommendation datasets, whereas regular campaign recommendations do not have this restriction.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-04T18:06:43.451261"}}
{"question": "When will AWS end support for Amazon Pinpoint?", "answer": "AWS will end support for Amazon Pinpoint on October 30, 2026.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T18:06:49.335524"}}
{"question": "What are the key features of Amazon Pinpoint Journeys?", "answer": "Amazon Pinpoint Journeys automate multi-step campaigns. Each activity in a journey can be an action, such as sending an email, a time-based wait, splitting the journey segment based on customer action (like opening an email versus not opening it), or enforcing a holdout.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T18:06:49.335851"}}
{"question": "How do the activities in a journey differ from regular campaign activities in Amazon Pinpoint?", "answer": "Activities in a journey specifically include actions like sending an email, time-based waits, and the ability to split segments based on customer actions, which is more dynamic compared to regular campaign activities that may not include such detailed automation and segmentation.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-04T18:06:49.336336"}}
{"question": "What is the maximum duration for which a journey can run in Amazon Pinpoint?", "answer": "A journey in Amazon Pinpoint can run continuously for up to 18 months.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-04T18:06:55.131828"}}
{"question": "What features does Amazon Pinpoint offer to ensure the effectiveness of campaigns?", "answer": "Amazon Pinpoint offers several features to ensure campaign effectiveness, including the ability to define user targets, determine message content, schedule delivery times, and track campaign results. Additionally, it provides analytics to measure messaging effectiveness and understand the impact on user behavior.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-04T18:06:55.132167"}}
{"question": "How do the journey review process and test feature in Amazon Pinpoint compare?", "answer": "The journey review process in Amazon Pinpoint checks for show-stopping errors and provides recommendations and best practices before launching a journey. In contrast, the test feature allows marketers to send a group of test participants through the journey to ensure it behaves as expected. Both features are aimed at improving the quality and reliability of journeys, but they serve different purposes in the journey setup process.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-04T18:06:55.132681"}}
{"question": "What are the core services included in Amazon Pinpoint?", "answer": "Amazon Pinpoint's core services include engagement analytics, communication channels, deliverability metrics, audience management and segmentation, template management, and campaign management.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T18:07:02.449671"}}
{"question": "How do A/B campaigns differ from standard campaigns in Amazon Pinpoint?", "answer": "A/B campaigns differ from standard campaigns in that they involve more than one treatment, where each treatment varies based on the message or the sending schedule. This allows for comparison of response rates to determine which treatment had a bigger impact on customers, while standard campaigns consist of a targeted segment, a message, and a schedule for sending that message.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T18:07:02.450003"}}
{"question": "What options do you have for scheduling campaigns in Amazon Pinpoint?", "answer": "In Amazon Pinpoint, you can schedule campaigns to be sent at a specific time or triggered by an event. Time-based campaigns can be set to run immediately, at a future designated time, or on a recurring schedule (hourly, daily, weekly, or monthly). You can also specify whether to deliver messages based on each recipient's local time zone.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-04T18:07:02.450501"}}
{"question": "What is the maximum duration that a journey can run continuously in Amazon Pinpoint?", "answer": "A journey in Amazon Pinpoint can run continuously for up to 18 months.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-04T18:07:09.194491"}}
{"question": "How does the message limit feature in Amazon Pinpoint campaigns benefit new customers?", "answer": "The message limit feature in Amazon Pinpoint campaigns benefits new customers by allowing you to set a strict limit on the number of messages they can receive at a specific moment in time. For example, if the limit is set to 1 for a campaign targeting new customers, it ensures that they only receive the message once, preventing them from being overwhelmed with multiple messages.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-04T18:07:09.194967"}}
{"question": "How does the review process for journeys in Amazon Pinpoint help before launching?", "answer": "The review process for journeys in Amazon Pinpoint checks for show-stopping errors and provides recommendations and best practices. This ensures that any potential issues are identified and addressed before the journey is launched, enhancing the likelihood of successful execution.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-04T18:07:09.195245"}}
{"question": "What communication channels does Amazon Pinpoint support for engaging users?", "answer": "Amazon Pinpoint supports several communication channels for engaging users, including email, SMS text messaging, push notifications, voice messages, and custom channels.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T18:07:15.268830"}}
{"question": "How do event-based campaigns in Amazon Pinpoint function?", "answer": "Event-based campaigns in Amazon Pinpoint send messages to customers based on specific actions they take within applications, such as making purchases or watching a video. Instead of scheduling a message for a certain time, developers select events, attributes, and metric values that trigger the campaigns, allowing for more personalized and timely communication.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T18:07:15.269169"}}
{"question": "What is the difference between transactional messaging and targeted messaging in Amazon Pinpoint?", "answer": "Transactional messaging in Amazon Pinpoint includes messages like one-time-password and order confirmation messages, which are typically triggered by specific user actions. In contrast, targeted messaging includes marketing promotions that are aimed at specific user segments based on their behavior or attributes. Both messaging types can be implemented through event-based campaigns, but they serve different purposes.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-04T18:07:15.269688"}}
{"question": "What are custom events in Amazon Pinpoint?", "answer": "Custom events are event metrics that you define to track user actions specific to your application or game. They help you monitor how often specific actions occur and can be filtered based on attributes and their associated values.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-04T18:07:22.718823"}}
{"question": "How can custom events be utilized to meet business goals?", "answer": "Custom events can be utilized to meet business goals by naming them according to specific actions, such as 'Item Bought', and by adding context through attributes and metrics. For instance, if the goal is to track purchases, you would use 'Item Bought' as the event, add 'Item XYZ' as an attribute, and use 'Item Price' as the metric to measure the price for purchased items.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-04T18:07:22.719167"}}
{"question": "How do custom event names differ from attribute names in Amazon Pinpoint?", "answer": "Custom event names should be broad, allowing for a general categorization of events, while attribute names should be specific, providing detailed context about the event. For example, a custom event name might be 'Item Bought', which is broad, whereas an attribute name could be 'Item XYZ', which is specific to a particular item.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-04T18:07:22.719785"}}
{"question": "What is the purpose of custom events in an app?", "answer": "Custom events help you understand the actions that users take when using your app. They allow developers to track specific actions, such as how often a level is completed or how much health players have left at the end of a level.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-04T18:07:28.997714"}}
{"question": "How can custom events contribute to improving user retention in a game?", "answer": "By analyzing custom events, developers can discover patterns, such as if a level is too easy because players always finish with maximum health. This insight allows developers to adjust the level's difficulty, which can better challenge and engage players, ultimately improving retention.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-04T18:07:28.998077"}}
{"question": "What is the difference between endpoints and users in Amazon Pinpoint?", "answer": "In Amazon Pinpoint, an endpoint is a destination for sending messages, such as a user's mobile device, email address, or phone number. In contrast, a user is an individual with a unique user ID that can be associated with up to 10 endpoints.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-04T18:07:28.998500"}}
{"question": "What metrics can be tracked for standard campaigns in Amazon Pinpoint?", "answer": "For standard campaigns, you can track messages sent, messages delivered, delivery rate, open rate, and campaign sessions by time of day.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T18:07:37.071740"}}
{"question": "How does Amazon Pinpoint measure daily retention?", "answer": "Daily retention is measured by determining the number of users that first used your app on a specific day, came back and used your app in the next 7 days (7-day retention), fourteen days (14-day retention), and thirty days (30-day retention).", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T18:07:37.072038"}}
{"question": "What is the difference between daily active users (DAU) and monthly active users (MAU) in the context of calculating the sticky factor?", "answer": "Daily active users (DAU) refers to the number of unique users who engage with the app on a specific day, while monthly active users (MAU) refers to the number of unique users who engage with the app over the course of a month. The sticky factor is calculated by dividing DAU by MAU, which indicates the level of user engagement.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-04T18:07:37.072201"}}
{"question": "How long does Amazon Pinpoint automatically store analytics data?", "answer": "Amazon Pinpoint automatically stores your analytics data for 90 days.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-04T18:07:42.166337"}}
{"question": "What are the benefits of using 10DLC phone numbers for sending messages with Amazon Pinpoint?", "answer": "The benefits of using 10DLC phone numbers for sending messages with Amazon Pinpoint include high throughput and high rates of message delivery when sending text messages to customers.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-04T18:07:42.166699"}}
{"question": "How do 10DLC phone numbers compare to unregistered US long codes in terms of SMS messaging?", "answer": "10DLC phone numbers can be used to send SMS messages to recipients in the US after completing the registration process, while unregistered US long codes can only be used with the voice channel and not for sending SMS messages.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-04T18:07:42.167200"}}
{"question": "What happens if I don't delete unregistered long codes from my account?", "answer": "If you dont delete unregistered long codes from your account, they will remain there, and youll continue to pay $1 per month for each unregistered long code. However, you wont be able to use these unregistered US long codes to send text messages.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:07:49.341013"}}
{"question": "What is the significance of completing the 10DLC conversion process before June 1st, 2021?", "answer": "Completing the 10DLC conversion process before June 1st, 2021, is significant because you wont experience any downtime during the conversion. If you begin the process after this date, you may experience several days of downtime.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:07:49.341358"}}
{"question": "How does Amazon Pinpoint determine which number to use for sending messages when multiple numbers are available?", "answer": "When multiple numbers are available in your Amazon Pinpoint account, Amazon Pinpoint determines which number to use for sending messages by looking for the best number. It will first use a short code if available, then look for a 10DLC phone number if no short code exists, and if neither is available, it will look for a toll-free number to send the message.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-04T18:07:49.341805"}}
{"question": "How long does it take to associate a new phone number with a 10DLC campaign?", "answer": "It takes up to 14 business days to associate a new phone number with a 10DLC campaign. When the association process is complete, the status changes to Ready.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-04T18:07:55.309535"}}
{"question": "What are the limitations regarding the association of phone numbers with 10DLC campaigns?", "answer": "You can associate multiple phone numbers with a 10DLC campaign; however, you cant associate a single phone number with more than one 10DLC campaign. Additionally, using multiple phone numbers for the same campaign doesnt provide any added benefit in terms of throughput.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-04T18:07:55.310014"}}
{"question": "What is the difference between using multiple phone numbers and a single phone number for a 10DLC campaign in terms of throughput?", "answer": "Using multiple phone numbers for the same 10DLC campaign does not provide any added benefit in terms of throughput, while a single phone number can only be associated with one 10DLC campaign.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-04T18:07:55.310218"}}
{"question": "What do you need to do if you want to register your 10DLC company and campaign again?", "answer": "You would have to register again through the Amazon Pinpoint console.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-04T18:08:01.981522"}}
{"question": "How does the trust score affect the number of messages accepted by mobile carriers for 10DLC?", "answer": "The trust score is calculated for each sender during the company and campaign registration processes, and it determines how many messages each carrier will accept from you. If you exceed the limits for your campaign for a particular carrier, that carrier will begin rejecting your messages.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-04T18:08:01.981856"}}
{"question": "What is the difference in the registration process for 10DLC companies and campaigns on Amazon Pinpoint and Amazon SNS?", "answer": "The Amazon Pinpoint console allows you to register 10DLC companies and campaigns, while the Amazon SNS console currently doesnt include a way to register them. However, you can still use the 10DLC phone numbers configured in the Amazon Pinpoint console to send messages using Amazon SNS.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-04T18:08:01.982377"}}
{"question": "What features does Amazon Pinpoint offer for message management compared to typical Amazon SNS and Amazon SES use cases?", "answer": "Amazon Pinpoint offers features such as the ability to create message templates, delivery schedules, highly-targeted segments, and full campaigns, which are not part of typical Amazon SNS and Amazon SES use cases where you need to manage each message's audience, content, and delivery schedule manually.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T18:08:09.153742"}}
{"question": "How does Amazon Pinpoint voice enhance customer engagement compared to traditional messaging methods?", "answer": "Amazon Pinpoint voice enhances customer engagement by allowing businesses to deliver transactional voice messages, such as one-time passwords, appointment reminders, and order confirmations, over the phone. This capability enables the conversion of text scripts into lifelike speech, which can be sent as personalized messages. This is a more dynamic method of engagement compared to traditional messaging methods that rely solely on text.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T18:08:09.154088"}}
{"question": "How does Amazon Pinpoint's SMS channel compare to its voice channel in terms of customer engagement?", "answer": "Amazon Pinpoint's SMS channel allows businesses to send text messages to customers who prefer text communication, while the voice channel enables the delivery of voice messages to customers who may not be able to receive SMS messages. Thus, the SMS channel is primarily text-based, whereas the voice channel provides an auditory experience, catering to different customer preferences and needs.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-04T18:08:09.154737"}}
{"question": "What happens to your AWS account after the post-closure period?", "answer": "After the post-closure period, AWS permanently closes your AWS account, and you can no longer reopen it. Any content that you didn't delete is permanently deleted, and any AWS services that you didn't stop are stopped.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T18:08:14.413206"}}
{"question": "How can I provide feedback or feature requests if I don't have an AWS Account Manager?", "answer": "If you don't currently have an AWS Account Manager, you can provide your feedback on the Amazon Pinpoint forum.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T18:08:14.413544"}}
{"question": "How do the AWS carrier fees for A2P SMS relate to mobile carrier fees in the US?", "answer": "The AWS carrier fees cover the charges assessed by mobile carriers in the US each time an A2P SMS is sent over their networks, and these fees are subject to change when mobile carriers change their fees.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-04T18:08:14.414061"}}
{"question": "What does Amazon Polly do?", "answer": "Amazon Polly is a service that turns text into lifelike speech, enabling existing applications to speak as a first-class feature and creating opportunities for new categories of speech-enabled products.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T18:08:25.345240"}}
{"question": "How does Amazon Polly ensure high-quality speech synthesis?", "answer": "Amazon Polly includes dozens of lifelike voices and supports multiple languages, allowing users to select the ideal voice for their applications. It also supports Speech Synthesis Markup Language (SSML) tags like prosody to adjust speech rate, pitch, or volume.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T18:08:25.345471"}}
{"question": "What are the advantages of using Amazon Polly compared to traditional speech synthesis methods?", "answer": "Amazon Polly provides lifelike speech, has very low response times, allows for caching and replaying generated speech at no additional cost, and offers a pay-as-you-go pricing model with low costs per request and no restrictions on storage and reuse of voice output.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-04T18:08:25.345858"}}
{"question": "What aspects of speech can be controlled using SSML?", "answer": "You can control various aspects of speech such as pronunciation, volume, pitch, and speech rate using standardized Speech Synthesis Markup Language (SSML).", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T18:08:30.861825"}}
{"question": "How do Speech Marks enhance the user experience during synthesized speech?", "answer": "Speech Marks enhance the user experience by providing metadata that allows for speech-synchronized animation or karaoke-style highlighting. This synchronization can be achieved by detecting when specific words or sentences are spoken in the audio stream, enabling developers to synchronize graphical highlighting and animations, such as lip movements of an avatar, with the synthesized speech.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T18:08:30.862163"}}
{"question": "What are the differences between the elements included in Speech Marks?", "answer": "Speech Marks include four elements: Sentence, which indicates a sentence element in the input text to be spoken; Word, which indicates a word element in the text; Viseme, which describes the shape of the lips that corresponds to the sound being spoken; and SSML, which describes an SSML element used in the text.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-04T18:08:30.862589"}}
{"question": "What are some applications of Amazon Polly in education?", "answer": "In education, Amazon Polly can be used to build applications that leverage its Text-to-Speech (TTS) capability to help people with reading disabilities. It can also assist the blind and visually impaired in consuming digital content such as eBooks and news.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T18:08:36.650239"}}
{"question": "How does cloud-based text-to-speech with Amazon Polly benefit developers compared to on-device solutions?", "answer": "Cloud-based text-to-speech with Amazon Polly benefits developers by dramatically reducing local resource requirements, including CPU power, RAM, and disk space. This minimizes development costs and power consumption on devices. Additionally, it allows support for all available languages and voices at the highest possible quality, provides instant availability of speech corrections and enhancements, and is platform independent, which helps minimize development time and effort.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T18:08:36.650580"}}
{"question": "How does the integration of Amazon Polly with Amazon Lex enhance application development?", "answer": "The integration of Amazon Polly with Amazon Lex allows developers to create full-blown Voice User Interfaces for their applications. This combination enhances the capability of applications by enabling natural language processing and speech capabilities, resulting in more interactive and user-friendly experiences.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-04T18:08:36.651017"}}
{"question": "Which regions support Amazon Pollys Neural voices?", "answer": "Amazon Pollys Neural voices are supported in the following regions: US East (N. Virginia), US West (Oregon), Canada (Central), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Africa (Cape Town), EU (London), EU (Frankfurt), EU (Ireland), and AWS GovCloud (US-West).", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T18:08:43.817378"}}
{"question": "What programming languages does Amazon Polly support?", "answer": "Amazon Polly supports all the programming languages included in the AWS SDK, which are Java, Node.js, .NET, PHP, Python, Ruby, Go, and C++. Additionally, it supports the AWS Mobile SDK for iOS and Android, as well as an HTTP API for implementing custom access layers.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T18:08:43.817865"}}
{"question": "How does the audio streaming capability of Amazon Polly compare to traditional audio playback methods?", "answer": "Amazon Polly allows you to stream audio to users in near real time, which can provide a more interactive experience compared to traditional audio playback methods that may require the entire audio file to be downloaded before playback can begin.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-04T18:08:43.818142"}}
{"question": "What should I do if I want to build a Brand Voice using Amazon Polly?", "answer": "If you are interested in building a Brand Voice using Amazon Polly, you should reach out to your AWS Account Manager or contact AWS for more information.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-04T18:08:49.351605"}}
{"question": "What are the benefits of using the AWS Free Tier for Amazon Polly?", "answer": "The AWS Free Tier allows new Amazon Polly customers to synthesize millions of characters for free each month for the first 12 months after sign-up. Additionally, starting July 15, 2025, new AWS customers will receive up to $200 in AWS Free Tier credits, which can be applied towards eligible AWS services, including Amazon Polly.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-04T18:08:49.351942"}}
{"question": "What is the difference between the free plan and the paid plan for Amazon Polly?", "answer": "The free plan allows new customers to use Amazon Polly for free for 6 months after account creation, while the paid plan requires payment and allows customers to utilize Amazon Polly beyond the free period. If a customer upgrades to a paid plan, any remaining Free Tier credit balance will automatically apply to their AWS bills.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-04T18:08:49.352455"}}
{"question": "What does Amazon Polly do with the text inputs it processes?", "answer": "Amazon Polly may store and use text inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Polly and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-04T18:08:53.855107"}}
{"question": "Why is the use of content important for Amazon Polly?", "answer": "The use of your content is important for continuous improvement of your Amazon Polly customer experience, including the development and training of related technologies.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-04T18:08:53.855446"}}
{"question": "How does Amazon Polly ensure the security of your content compared to other services?", "answer": "Amazon Polly implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content, prioritizing trust, privacy, and security.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-04T18:08:53.856076"}}
{"question": "What security measures does Amazon Polly implement to protect content?", "answer": "Amazon Polly implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to or disclosure of your content, ensuring compliance with their commitments to users.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T18:08:59.387389"}}
{"question": "How does the use of Amazon Polly relate to the Children's Online Privacy Protection Act (COPPA)?", "answer": "You may use Amazon Polly in connection with websites, programs, or other applications directed or targeted, in whole or in part, to children under age 13, provided that you comply with the Amazon Polly Service Terms, including obtaining any required notices and verifiable parental consent under COPPA.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T18:08:59.387748"}}
{"question": "How does ownership of output from Amazon Polly differ from the ownership of input text that belongs to a third party?", "answer": "As between you and AWS, your Polly output belongs to you. However, if you input text into Polly that belongs to a third party, you are required to have the rights to do so, indicating a distinction between ownership of the generated output and the input text.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-04T18:08:59.387970"}}
{"question": "What is AWS Private Certificate Authority (AWS Private CA)?", "answer": "AWS Private Certificate Authority (AWS Private CA) is a highly available, managed service for creating and maintaining an internal public key infrastructure (PKI) for your organization. It removes the upfront investment and ongoing maintenance costs of operating your own private certificate authority (CA) and simplifies lifecycle management of the certificates in your PKI.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T18:09:04.303490"}}
{"question": "How does AWS Private CA simplify the management of certificates?", "answer": "AWS Private CA simplifies the lifecycle management of certificates by allowing users to easily create and deploy private certificates for AWS resources using the AWS Management Console. It also provides flexibility to create private certificates with custom certificate lifetimes, key algorithms, resource names, and other information.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T18:09:04.303824"}}
{"question": "What are the two main components of a Certificate Authority (CA)?", "answer": "The two main components of a Certificate Authority (CA) are the CA certificate, which is a cryptographic building block that allows other certificates to be issued, and a set of runtime services for maintaining revocation information through the Online Certificate Status Protocol (OCSP) or a certificate revocation list (CRL).", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-04T18:09:04.304026"}}
{"question": "What is the main difference between public CAs and private CAs in terms of operational constraints?", "answer": "Public CAs must follow strict rules, provide operational visibility, and meet security standards imposed by browser and operating system vendors, while private CA administrators can create their own rules for issuing certificates and are free of many constraints placed on public CAs.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-04T18:09:10.028450"}}
{"question": "Why might an organization choose to use private certificates instead of public certificates?", "answer": "An organization might choose to use private certificates because they offer flexibility, allowing the identification of nearly anything within the organization without disclosing the name publicly. Additionally, private certificates can include information that is prohibited in public certificates, which could be necessary for certain enterprise applications that require extra information not allowed in public certificates.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-04T18:09:10.028807"}}
{"question": "How do the trust requirements for private certificates differ from those of public certificates?", "answer": "Private certificates require an administrator to add the private CA that issued them to the list of trusted CAs in browsers and other network applications for them to be trusted, whereas public certificates are typically trusted automatically by browsers and operating systems without additional configuration.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-04T18:09:10.029301"}}
{"question": "What are the main limitations of self-signed certificates?", "answer": "Self-signed certificates cannot verify identity, cannot be revoked, and it can be difficult to track their expiration dates, which may lead to outages caused by certificate expirations.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T18:09:16.007265"}}
{"question": "How does a CA hierarchy benefit an organization in managing certificates?", "answer": "A CA hierarchy benefits an organization by providing strong security and restrictive access controls for the most-trusted root CA at the top of the trust chain, while allowing more permissive access and bulk certificate issuance for subordinate CAs lower in the chain. This structure helps control access and distribute management of the CAs across different teams within the organization.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T18:09:16.007555"}}
{"question": "How do self-signed certificates differ from certificates issued by a CA in terms of trust and infrastructure requirements?", "answer": "Self-signed certificates act as their own root and are easy to generate without the need for expertise or infrastructure, whereas certificates issued by a CA rely on a secure root maintained by the CA and are part of a structured trust model. This means that self-signed certificates do not offer the same level of identity verification and trust as those issued by a CA.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-04T18:09:16.007709"}}
{"question": "What is the main purpose of a subordinate CA in a CA hierarchy?", "answer": "A subordinate CA can be configured to directly issue certificates, act as an intermediate CA that signs other subordinate CAs, issue end-entity certificates, or serve as both an intermediate and issuing CA.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-04T18:09:22.095358"}}
{"question": "Why are root CAs considered to be more trusted than subordinate CAs?", "answer": "Root CAs and other CAs near the top of a CA hierarchy typically have restrictive policies controlling certificate issuance and administrative access, are used infrequently, and are tightly controlled and audited. This results in a lower risk of compromise, making them more trusted.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-04T18:09:22.095708"}}
{"question": "How does the trustworthiness of root CAs compare to that of subordinate CAs in terms of certificate issuance policies?", "answer": "Root CAs have more restrictive policies controlling certificate issuance and administrative access compared to subordinate CAs, leading to a lower risk of compromise and greater trustworthiness. In contrast, subordinate CAs typically have less restrictive policies, reflecting their role in issuing end-entity certificates.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-04T18:09:22.096126"}}
{"question": "What is a use case for short-lived certificates?", "answer": "Short-lived certificates should be used in cases where a temporary certificate is needed, such as for a short-lived ad-hoc AWS workload that requires certificates to enable TLS. These certificates are considered best practice because they expire quickly and do not need to be revoked.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-04T18:09:28.161818"}}
{"question": "How does the security of short-lived certificates work?", "answer": "The security of short-lived certificates is based on their frequent re-issuance to reaffirm their health. This frequent re-issuance requires the subject to demonstrate compliance with the certificate policy regularly. This model is similar to that used by Security Assertion Markup Language (SAML) and OpenID Connect (OIDC) tokens.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-04T18:09:28.162461"}}
{"question": "How do short-lived certificates differ from long-term credentials in AWS IAM Roles Anywhere?", "answer": "Short-lived certificates are used for temporary security credentials in IAM Roles Anywhere, allowing workloads running outside of AWS to access AWS resources without managing long-term credentials. In contrast, long-term credentials require ongoing management and may not provide the same security assurance as the frequent re-issuance of short-lived certificates.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-04T18:09:28.162712"}}
{"question": "What is a trust anchor in IAM Roles Anywhere?", "answer": "A trust anchor in IAM Roles Anywhere is either a reference to AWS Private CA or another CA certificate. It establishes trust between IAM Roles Anywhere and your CA.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-04T18:09:33.982458"}}
{"question": "How does Matter ensure security and interoperability among smart home devices?", "answer": "Matter ensures security and interoperability by enforcing device certification and authenticity checks before allowing smart home devices to join a Matter smart home network (fabric) and communicate with other Matter devices.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-04T18:09:33.982956"}}
{"question": "What are the differences between Device Attestation Certificates (DAC) and Node Operational Certificates (NOC) in Matter?", "answer": "Device Attestation Certificates (DAC) are provisioned by device makers to identify the device vendor and product type, and they are validated by Matter fabric administrator devices during device commissioning. In contrast, Node Operational Certificates (NOC) are issued by Matter administrators during commissioning and are used by devices for communication with other Matter devices on the fabric.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-04T18:09:33.983178"}}
{"question": "What is the purpose of using AWS Private CA in relation to Matter products?", "answer": "AWS Private CA can be used as a Delegated Service Provider to establish and operate a Product Attestation Authority (PAA) and one or more Product Attestation Intermediates to issue Device Attestation Certificates (DACs) for Matter products.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T18:09:41.241741"}}
{"question": "What options do you have for scoping your Product Attestation Authority (PAA) when using AWS Private CA?", "answer": "When using AWS Private CA, you can set up your Product Attestation Authority (PAA) to be either non-VID-scoped or VID-scoped. This choice depends on whether you plan to issue DACs for other companies or only for your own products.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T18:09:41.242090"}}
{"question": "How does AWS Private CA differ from AWS Certificate Manager (ACM) in the context of Matter certificates?", "answer": "AWS Private CA is specifically designed to establish and operate device attestation CA hierarchies to meet the requirements of Matter products, while AWS Certificate Manager (ACM) does not support Matter certificates due to their specific requirements that are often incompatible with other certificate use cases.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-04T18:09:41.242310"}}
{"question": "What is AWS PrivateLink used for?", "answer": "AWS PrivateLink lets users access services and resources hosted on AWS in a highly available and scalable manner while keeping all network traffic within the AWS network.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-04T18:09:45.790289"}}
{"question": "How do users access services and resources using AWS PrivateLink?", "answer": "Users access services and resources from their Amazon Virtual Private Cloud (VPC) or on premises without using public IPs and without requiring traffic to traverse across the internet by creating VPC endpoints powered by PrivateLink.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-04T18:09:45.790651"}}
{"question": "What is the relationship between Network Load Balancers and AWS PrivateLink for service owners?", "answer": "Service owners can register their Network Load Balancers to PrivateLink services to provide their services to other AWS customers, and they need to establish a Network Load Balancer to front their service to onboard it to AWS PrivateLink.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-04T18:09:45.790989"}}
{"question": "What are VPC endpoints and what purpose do they serve?", "answer": "VPC endpoints enable you to privately connect your VPC to services and resources hosted on AWS without requiring an internet gateway, NAT device, VPN, or firewall proxies. They serve the purpose of allowing communication between instances in your VPC and AWS services/resources.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T18:09:50.998269"}}
{"question": "How do interface endpoints differ from gateway endpoints in terms of connectivity?", "answer": "Interface endpoints provide private connectivity to services powered by PrivateLink, which may include AWS services, your own services, or SaaS solutions, and they support connectivity over AWS Direct Connect and VPN. In contrast, gateway endpoints are only available for AWS services like Amazon S3 and Amazon DynamoDB, do not enable PrivateLink, and route traffic to supported services through Amazons private network without additional connectivity options.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T18:09:50.998590"}}
{"question": "What types of endpoints does Amazon VPC offer, and which types are powered by PrivateLink?", "answer": "Amazon VPC offers five different types of VPC endpoints: gateway endpoint, interface endpoint, Gateway Load Balancer endpoint, resource endpoint, and service network endpoint. All VPC endpoint types except the gateway endpoint are powered by PrivateLink.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-04T18:09:50.998807"}}
{"question": "What are some benefits of using VPC endpoints?", "answer": "VPC endpoints provide several benefits, including secure access to a specific service or resource without the need for internet gateways, NAT gateways, VPN connections, or VPC peering connections, which reduces the risk of exposing resources to the internet or other outside networks. Additionally, your traffic remains within Amazon's private network, further minimizing exposure to the internet. Access can also be restricted to specific users, actions, and resources, and you can limit access to resources provided by an Amazon service to traffic originating from a specific VPC or through a specific VPC endpoint.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-04T18:10:02.364574"}}
{"question": "How do resource endpoints and service network endpoints differ in their functionality?", "answer": "Resource endpoints provide private connectivity to VPC resources such as databases, clusters, domain-name targets, and IP addresses that do not require load balancing. In contrast, service network endpoints allow for private connections to services and resources within a VPC Lattice service network and enable access to multiple services and resources through a single VPC endpoint. Both types of endpoints support connectivity over AWS Direct Connect and VPN.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-04T18:10:02.364954"}}
{"question": "What steps must a resource owner take to onboard their resource to PrivateLink?", "answer": "To onboard a resource to PrivateLink, a resource owner needs to create a resource configuration in Amazon VPC Lattice that includes a list of resources. After creating this configuration, the resource owner must share it with their customers' accounts using AWS Resource Access Manager (RAM) to allow customers to establish endpoints within their VPC to connect to the resource(s).", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-04T18:10:02.365344"}}
{"question": "What are the charges associated with creating an interface or Gateway Load Balancer VPC endpoint in a VPC?", "answer": "You are charged for each hour that your VPC endpoint is provisioned in each Availability Zone when you create an interface or Gateway Load Balancer VPC endpoint in your VPC.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T18:10:07.460727"}}
{"question": "How does the billing for resource VPC endpoints differ from that of interface or Gateway Load Balancer VPC endpoints?", "answer": "For resource VPC endpoints, you are charged for each hour regardless of the number of Availability Zones your VPC endpoint is provisioned in, whereas for interface or Gateway Load Balancer VPC endpoints, you are charged for each hour in each Availability Zone where the endpoint is provisioned.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T18:10:07.461048"}}
{"question": "How does the scaling limit of VPC peering compare to that of AWS PrivateLink?", "answer": "VPC peering is limited to 125 VPC connections, while AWS PrivateLink has virtually unlimited scale, allowing you to add as many VPC endpoints as you need based on the number of VPCs, resources, and services you want to connect to.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-04T18:10:07.461264"}}
{"question": "What are the components that connect to a single endpoint service or resource?", "answer": "Gateway, interface, Gateway Load Balancer, and resource VPC endpoints connect to a single endpoint service or resource.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-04T18:10:12.604142"}}
{"question": "How does AWS PrivateLink ensure the security of data between a VPC endpoint and a service?", "answer": "The security of AWS PrivateLink relies on three factors: the path, the policies, and mode of communication. The path between a VPC endpoint and a service stays within AWS and does not traverse the Internet, which helps protect against Internet breaches. Additionally, endpoint policies can be created to restrict access to requests that come to the VPC endpoint.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-04T18:10:12.604489"}}
{"question": "How do VPC endpoint DNS records differ from the IP addresses they return?", "answer": "VPC endpoint's DNS records are publicly resolvable but will return the private IP address within the associated VPC.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-04T18:10:12.605065"}}
{"question": "What is the primary function of AWS Proton for application developers?", "answer": "The primary function of AWS Proton for application developers is to enable them to self-serve from infrastructure templates to provision the infrastructure they need for their application code. It allows developers to use a self-service interface to deploy their applications with minimal configuration and provides the flexibility to customize templates to meet specific application needs.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-04T18:10:19.814370"}}
{"question": "How does AWS Proton enhance the deployment process for application developers?", "answer": "AWS Proton enhances the deployment process for application developers by allowing them to select Service templates that meet their needs and easily trigger deployment through a supported CI/CD pipeline without needing to write Infrastructure as Code templates. This self-service experience streamlines the deployment process, enabling developers to focus on writing code rather than managing infrastructure.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-04T18:10:19.814631"}}
{"question": "What are the key differences between AWS Proton and Service Catalog?", "answer": "The key differences between AWS Proton and Service Catalog are that AWS Proton is a deployment workflow tool specifically designed for managing Infrastructure as Code (IaC) templates, while Service Catalog is a catalog of AWS resources that enables customers to store, share, and govern IaC templates and create individual stacks for specific resources. Additionally, AWS Proton provides a self-service experience for developers to manage deployment, whereas Service Catalog focuses on governance and storage of templates.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-04T18:10:19.814775"}}
{"question": "In which AWS Regions is AWS Proton supported?", "answer": "AWS Proton is supported in the following AWS Regions: US East (Ohio) us-east-2, US East (N. Virginia) us-east-1, US West (Oregon) us-west-2, Canada (Central) ca-central-1, EU (Frankfurt) eu-central-1, EU (Ireland) eu-west-1, EU (London) eu-west-2, Asia Pacific (Sydney) ap-southeast-2, Asia Pacific (Tokyo) ap-northeast-1, Asia Pacific (Seoul) ap-northeast-2, and Asia Pacific (Singapore) ap-southeast-1.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-04T18:10:27.665632"}}
{"question": "What is the role of platform engineers in AWS Proton?", "answer": "Platform engineers are responsible for managing the creation of templates for environments and services in AWS Proton. They also trigger environment deployment and can use the 'bring your own environment' feature to onboard an existing environment to Proton.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-04T18:10:27.665965"}}
{"question": "How does AWS Proton facilitate the management of infrastructure templates for developers compared to traditional methods?", "answer": "AWS Proton allows platform teams to create a 'stack' as a reusable version-controlled template for developers, providing a simple, declarative way to define everything needed to provision, deploy, and manage a service. This makes it easier for platform teams to identify and update out-of-date infrastructure when templates are updated, which is more efficient than traditional methods that may not have such version control and ease of management.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-04T18:10:27.666175"}}
{"question": "What can you do with existing infrastructure as code files in AWS Proton?", "answer": "In AWS Proton, you can take an existing infrastructure as code file and update it to define input parameters that AWS Proton will combine with input values when resources are provisioned.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-04T18:10:32.243652"}}
{"question": "How does AWS Proton facilitate infrastructure provisioning for developers?", "answer": "AWS Proton facilitates infrastructure provisioning for developers by providing a self-service interface that allows them to provision infrastructure and deploy their projects without needing to interact with the underlying resources. It also offers visibility into the general status of applications, including stacks in use and stack health status, along with access to CI/CD pipelines, observability tools, and source control for each project.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-04T18:10:32.243998"}}
{"question": "How does AWS Proton handle templates compared to using existing infrastructure as code files?", "answer": "AWS Proton allows users to start with a collection of open-source templates to define their architecture or take existing infrastructure as code files and update them for use. While templates can be saved and registered in an Amazon S3 bucket to be used and updated within AWS Proton, existing infrastructure as code files require modification to define input parameters before they can be provisioned.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-04T18:10:32.244219"}}
{"question": "What is Amazon Q?", "answer": "Amazon Q is a generative AI assistant designed to transform how work gets done in organizations. It is particularly specialized for software developers, business intelligence analysts, contact center employees, supply chain analysts, and anyone building with AWS. Amazon Q helps employees gain insights on their data and accelerate their tasks.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:10:38.957749"}}
{"question": "How does Amazon Q Business enhance productivity within an organization?", "answer": "Amazon Q Business enhances productivity by making generative AI securely accessible to everyone in an organization. It leverages the company's own content, data, and systems to provide fast, relevant answers to pressing questions, solve problems, generate content, and take actions. Moreover, it connects easily and securely to commonly used systems and tools, allowing it to synthesize information and provide tailored assistance that empowers teams to be more data-driven, creative, and productive.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:10:38.958086"}}
{"question": "What are the key differences between Amazon Q Business and Amazon Q Developer?", "answer": "Amazon Q Business focuses on providing generative AI assistance to all employees within an organization, helping them with tasks such as getting answers to questions, solving problems, and generating content. In contrast, Amazon Q Developer is specifically tailored for software developers and IT professionals, offering advanced capabilities for managing data and AI/ML, and assisting with coding, testing, deploying, troubleshooting, and modernizing applications.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:10:38.958308"}}
{"question": "What functionality does Amazon Q provide within Amazon QuickSight?", "answer": "Amazon Q in QuickSight provides a generative BI assistant that allows business analysts to build BI dashboards, visualizations, and complex calculations quickly using natural language. It empowers employees to create customizable data stories and offers multi-visual Q&A responses and AI-driven executive summaries to discover key insights, trends, and drivers.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-04T18:10:44.864645"}}
{"question": "How does Amazon Q enhance customer service in Amazon Connect?", "answer": "Amazon Q enhances customer service in Amazon Connect by automatically detecting customer issues during conversations and leveraging generative AI to deliver real-time, personalized responses and recommended actions. It utilizes customer information and content from knowledge repositories and external websites to improve service efficiency.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-04T18:10:44.864992"}}
{"question": "In what ways does Amazon Q in AWS Supply Chain differ from its use in Amazon QuickSight?", "answer": "Amazon Q in AWS Supply Chain focuses on analyzing data in the AWS Supply Chain Data Lake to provide operational and financial insights and to answer urgent supply chain questions, thereby operating the supply chain more efficiently. In contrast, Amazon Q in QuickSight is aimed at creating BI dashboards and visualizations using natural language. Both utilize generative AI but serve different business functions.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-04T18:10:44.865465"}}
{"question": "What types of subscription plans does Amazon Q offer?", "answer": "Amazon Q offers various subscription plans including free, lite, and pro options. Prices vary based on user subscription and how and where you want to integrate Amazon Q in your business.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T18:10:49.674367"}}
{"question": "How does Amazon Q enhance productivity in organizations?", "answer": "Amazon Q enhances productivity by allowing employees to easily and securely connect to over 50 commonly used business tools, enabling tailored conversations, problem-solving, content generation, and task streamlining. It also helps employees get answers to questions across business data and is built with security and privacy in mind, making it easier to use generative AI for increased productivity and innovation.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T18:10:49.674752"}}
{"question": "How does Amazon Q differ from traditional virtual assistants in its functionality?", "answer": "Amazon Q differs from traditional virtual assistants by being specifically designed for business functions, allowing users to chat in natural language to get help with digital tasks across various roles, such as creating dashboards or generating code. Additionally, it is built on Amazon Bedrock and utilizes multiple Foundational Models to route tasks to the best fit, which is not something typical virtual assistants do.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-04T18:10:49.674984"}}
{"question": "What security features does Amazon Q offer to enterprise clients?", "answer": "Amazon Q is built to meet enterprise clients' security requirements by inheriting the controls implemented in Amazon Bedrock, which enforce safety, security, and the responsible use of AI.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-04T18:10:54.949655"}}
{"question": "How does access control work within Amazon Q?", "answer": "Access control within Amazon Q is determined by user permissions. If a user is not permitted to access certain information outside of Amazon Q, they cannot access that information from within Amazon Q either.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-04T18:10:54.950011"}}
{"question": "How does Amazon Q's pricing model work in relation to its functionality?", "answer": "Amazon Q has a monthly fee for most of its functionality, although some functionality may be available for free trial for a short time. Users should refer to the pricing page for specific details.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-04T18:10:54.950492"}}
{"question": "What types of data sources can be connected to Amazon QuickSight?", "answer": "Amazon QuickSight can connect to various data sources including CSV and Excel files, SaaS applications like Salesforce, on-premises databases such as SQL Server, MySQL, and PostgreSQL, as well as AWS data sources like Amazon Redshift, Amazon Relational Database Service (Amazon RDS), Amazon Aurora, Amazon Athena, and Amazon Simple Storage Service (Amazon S3).", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-04T18:11:01.227140"}}
{"question": "How does Amazon QuickSight facilitate business analytics for organizations?", "answer": "Amazon QuickSight facilitates business analytics for organizations by providing a unified business intelligence service that allows employees to build visualizations, perform ad hoc analysis, and gain business insights from their data anytime and on any device. It offers modern interactive dashboards, paginated reports, natural language queries, and embedded analytics, enabling users to meet varying analytic needs from the same source of truth.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-04T18:11:01.227374"}}
{"question": "In what ways do Amazon QuickSight's capabilities support fast query performance compared to traditional methods?", "answer": "Amazon QuickSight supports fast and responsive query performance through its robust in-memory engine called SPICE. This allows it to deliver quick insights and analytics capabilities to a large number of users, which is a significant advantage over traditional methods that may not utilize such an efficient in-memory architecture.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-04T18:11:01.227502"}}
{"question": "What are some AWS services that QuickSight can discover data sources from?", "answer": "QuickSight can discover data sources from AWS services such as Amazon Redshift, Amazon RDS, Amazon Athena, and Amazon S3.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T18:11:07.263687"}}
{"question": "How does QuickSight differentiate itself from traditional BI solutions?", "answer": "QuickSight differentiates itself from traditional BI solutions by offering a simple and fast setup process, enabling users to connect to various AWS data sources seamlessly without the need for extensive data modeling or complex infrastructure. It also allows for interactive ad-hoc data exploration and visualization, which traditional BI solutions typically lack.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T18:11:07.264024"}}
{"question": "How does the cost structure of QuickSight compare to traditional BI solutions?", "answer": "The cost structure of QuickSight involves a low monthly fee for each user, eliminating the need for significant up-front investments and long-term licenses typically required by traditional BI solutions. This allows organizations to deliver business analytics functionality without incurring high initial costs.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-1", "source_tokens": 507, "generated_at": "2026-02-04T18:11:07.264242"}}
{"question": "What permissions must the QuickSight account administrator grant for SageMaker API calls?", "answer": "The QuickSight account administrator needs to grant QuickSight IAM permissions to make SageMaker API calls on your behalf.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T18:11:12.115202"}}
{"question": "What are the main differences between Author and Author Pro licenses in QuickSight?", "answer": "The main differences between Author and Author Pro licenses in QuickSight are that Author Pro includes all the capabilities of an Author license and adds Amazon Q Generative BI features. These additional features allow users to build dashboards with natural language, create Q Topics, generate executive dashboard summaries, and build and share generative data stories.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T18:11:12.115538"}}
{"question": "How do Reader and Reader Pro accounts differ in terms of capabilities?", "answer": "Reader Pro accounts include all capabilities of Reader accounts, plus additional Generative BI capabilities in Amazon Q, which allow for executive dashboard summaries and the ability to build and share generative data stories. In contrast, standard Reader accounts do not have these advanced Generative BI features.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-04T18:11:12.115767"}}
{"question": "What capabilities does a QuickSight Admin have?", "answer": "A QuickSight Admin can manage QuickSight users and account-level preferences, purchase SPICE capacity and annual subscriptions for the account, and has all QuickSight authoring capabilities. Additionally, Admins can upgrade Standard Edition accounts to Enterprise Edition if needed.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:11:17.330250"}}
{"question": "What are the differences between QuickSight Admins and QuickSight Authors?", "answer": "QuickSight Admins can manage users, account preferences, purchase resources, and upgrade account editions, while QuickSight Authors and Readers cannot change account permissions or invite more users. Both Admins and Authors are recognized as Authors for billing purposes.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:11:17.330639"}}
{"question": "How can users access QuickSight on mobile devices?", "answer": "Users can access QuickSight through mobile apps available on iOS and Android, which allow for browsing, searching, and interacting with dashboards. They can also use a web browser on any mobile device to access QuickSight.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-04T18:11:17.330817"}}
{"question": "What types of data preparation can QuickSight perform before visualization?", "answer": "QuickSight can format and transform your data by allowing you to alias data fields, change data types, subset your data using built-in filters, perform database join operations through drag and drop, and create calculated fields using mathematical operations and built-in functions such as conditional statements, string, numerical, and date functions.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:11:23.214923"}}
{"question": "How does QuickSight handle data scalability?", "answer": "QuickSight allows you to seamlessly grow your data from a few hundred megabytes to many terabytes without the need to manage any infrastructure, thereby simplifying the process of scaling your data.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:11:23.215255"}}
{"question": "What are the differences in roles and permissions between an ADMIN and a USER in QuickSight?", "answer": "An ADMIN role in QuickSight allows the user to create and delete user accounts, purchase annual subscriptions, and SPICE capacity in addition to using the service. In contrast, a USER role, assigned by the inviter, does not have the administrative privileges to manage accounts or subscriptions.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:11:23.215676"}}
{"question": "What types of files can you upload to QuickSight for analysis?", "answer": "You can upload spreadsheets and CSV files to QuickSight for analysis.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-04T18:11:28.367241"}}
{"question": "How does QuickSight determine the appropriate visualizations for your data?", "answer": "QuickSight uses an innovative technology called AutoGraph, which selects the most appropriate visualizations based on the properties of the data, such as cardinality and data type.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-04T18:11:28.367506"}}
{"question": "What is the difference between a dashboard and a visualization in QuickSight?", "answer": "A dashboard in QuickSight is a collection of visualizations, tables, and other visual displays arranged and visible together, while a visualization is a single representation of data designed to reveal insights. Dashboards can contain multiple visualizations that are composed and published together.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-04T18:11:28.367633"}}
{"question": "What is the purpose of Stories in QuickSight?", "answer": "Stories in QuickSight are guided tours through specific views of an analysis. They are used to convey key points, a thought process, or the evolution of an analysis for collaboration. Users can construct them by capturing and annotating specific states of the analysis, and when readers select an image in the story, they are taken into the analysis at that point to explore on their own.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T18:11:35.549983"}}
{"question": "How does the Cost and Usage Dashboard benefit users of Billing and Cost Management?", "answer": "The Cost and Usage Dashboard offers direct integration with QuickSight, automating the creation of the dashboard that provides insights into AWS spend. It brings the benefits of the open source project Cloud Intelligence Dashboards (CID) to the Billing and Cost Management console as an AWS-supported feature, eliminating the need for maintaining underlying infrastructure like Amazon Athena views or AWS Glue crawlers.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T18:11:35.550253"}}
{"question": "What are the differences between data connection options in QuickSight?", "answer": "In QuickSight, you have several options to get your data into the service: you can upload files, connect to AWS data sources, connect to external data stores over JDBC/ODBC, or use other API-based data store connectors. These options provide flexibility in how users can integrate their data with QuickSight.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-04T18:11:35.550423"}}
{"question": "What is row-level security (RLS) in QuickSight?", "answer": "Row-level security (RLS) in QuickSight enables dataset owners to control access to data at row granularity based on permissions associated with the user interacting with the data. This means QuickSight users only need to manage a single set of data and apply appropriate row-level dataset rules to it, allowing all associated dashboards and analyses to enforce these rules and simplifying dataset management.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T18:11:42.383390"}}
{"question": "Can a Standard Edition account in QuickSight be upgraded to Enterprise Edition?", "answer": "Yes, Standard Edition accounts can be upgraded to Enterprise Edition through the QuickSight management page. Existing authentication details and user data will be seamlessly migrated to Enterprise Edition.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T18:11:42.384039"}}
{"question": "What are some features that differentiate Amazon QuickSight Enterprise Edition from Standard Edition?", "answer": "Amazon QuickSight Enterprise Edition offers enhanced functionalities such as QuickSight Readers, connectivity to data sources in Private VPC, row-level security, hourly refresh of SPICE data, as well as Active Directory (AD) connectivity and group-based management of assets for AD accounts. These features are not available in the Standard Edition.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-04T18:11:42.384289"}}
{"question": "How many topics are covered under the Amazon RDS FAQs?", "answer": "The Amazon RDS FAQs cover a total of 14 topics.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-04T18:11:46.711920"}}
{"question": "What is the purpose of Amazon RDS Blue/Green Deployments?", "answer": "Amazon RDS Blue/Green Deployments are designed to facilitate safe and reliable database updates with minimal downtime by creating a separate environment for testing before deploying changes to the production environment.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-04T18:11:46.712265"}}
{"question": "How does the number of topics related to security compare to those related to database configuration in Amazon RDS FAQs?", "answer": "In the Amazon RDS FAQs, there are 19 topics related to security, which is significantly more than the 3 topics related to database configuration.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-04T18:11:46.714286"}}
{"question": "What types of databases can be accessed through Amazon RDS?", "answer": "Amazon RDS provides access to RDS for PostgreSQL, RDS for MySQL, RDS for MariaDB, RDS for SQL Server, RDS for Oracle, and RDS for Db2 databases.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-04T18:11:52.412246"}}
{"question": "How does Amazon RDS benefit users in terms of database management?", "answer": "Amazon RDS benefits users by managing time-consuming database administration tasks, allowing users to focus on their applications and business. It also offers automatic backups, keeps database software up to date, and provides the flexibility to scale compute resources or storage capacity as needed.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-04T18:11:52.412460"}}
{"question": "What is the difference between using Amazon RDS and managing a relational database using Amazon EC2?", "answer": "The difference between using Amazon RDS and managing a relational database on Amazon EC2 is that Amazon RDS is a fully managed service that offloads database administration, while using Amazon EC2 requires you to manage your own relational database in the cloud.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-04T18:11:52.412602"}}
{"question": "How can I set up a connection between an EC2 compute instance and a new Amazon RDS database?", "answer": "To set up a connection between an EC2 compute instance and a new Amazon RDS database, go to the Amazon RDS console and on the 'Create database' page, select the 'Connect to an EC2 compute resource' option in the Connectivity Section. This will automate the manual networking setup tasks such as creating a VPC, security groups, subnets, and ingress/egress rules.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:11:59.646776"}}
{"question": "What is the benefit of using the connectivity automation feature when connecting to an RDS database?", "answer": "The connectivity automation feature improves productivity for new users and application developers by allowing them to quickly and seamlessly connect an application or client using SQL on an EC2 compute instance to an RDS database within minutes.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:11:59.647116"}}
{"question": "What is the difference between setting up a connection for an existing RDS database and a new Amazon RDS database?", "answer": "To set up a connection for a new Amazon RDS database, you select the 'Connect to an EC2 compute resource' option during the database creation process. In contrast, for an existing RDS database, you need to open the RDS console, select the database from the list, and choose 'Set up EC2 connection' from the 'Action' menu dropdown list.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:11:59.647467"}}
{"question": "What resources can you specify when creating a DB instance in AWS?", "answer": "When creating a DB instance in AWS, you can specify the compute and storage resources for your database environment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-04T18:12:05.493389"}}
{"question": "How can you control access and security for your DB instances in AWS?", "answer": "You can control access and security for your DB instances through the AWS Management Console, Amazon RDS APIs, and the AWS Command Line Interface.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-04T18:12:05.493709"}}
{"question": "What are the differences between launching a DB instance using the AWS Management Console and using the CreateDBInstance API?", "answer": "Launching a DB instance using the AWS Management Console involves clicking on 'RDS' and then the 'Launch DB Instance' button where you can specify various parameters. In contrast, using the CreateDBInstance API allows you to create your DB instance programmatically without the graphical interface.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-04T18:12:05.493930"}}
{"question": "What is the maximum number of Amazon RDS DB instances a customer can have by default?", "answer": "By default, customers are allowed to have up to a total of 40 Amazon RDS DB instances.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-04T18:12:11.288487"}}
{"question": "How does the Bring Your Own License (BYOL) model differ from the License Included model for RDS for Oracle and RDS for SQL Server?", "answer": "Under the License Included model, customers can have up to 10 RDS for Oracle or RDS for SQL Server DB instances. In contrast, under the Bring Your Own License (BYOL) model, all 40 DB instances can be utilized for Amazon Aurora, RDS for PostgreSQL, RDS for MySQL, RDS for MariaDB, and RDS for Oracle.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-04T18:12:11.288799"}}
{"question": "What is the limit on the number of databases that can be created on an RDS for SQL Server instance compared to RDS for Db2?", "answer": "RDS for SQL Server has a limit of up to 100 databases on a single DB instance, while RDS for Db2 has a limit of up to 1 database per instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-04T18:12:11.288995"}}
{"question": "What is the purpose of the Amazon RDS maintenance window?", "answer": "The Amazon RDS maintenance window is your opportunity to control when DB instance modifications, database engine version upgrades, and software patching occurs, in the event they are requested or required. If a maintenance event is scheduled for a given week, it will be initiated during the maintenance window you identify.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-04T18:12:16.545262"}}
{"question": "How does running a DB instance as a Multi-AZ deployment affect maintenance events?", "answer": "Running your DB instance as a Multi-AZ deployment can further reduce the impact of a maintenance event.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-04T18:12:16.545607"}}
{"question": "What happens if no preferred maintenance window is specified for a DB instance?", "answer": "If you do not specify a preferred weekly maintenance window when creating your DB instance, a 30-minute default value is assigned.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-04T18:12:16.545829"}}
{"question": "What does Enhanced Monitoring provide access to for production databases?", "answer": "Enhanced Monitoring provides access to over 50 CPU, memory, file system, and disk I/O metrics for production databases.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-04T18:12:21.083637"}}
{"question": "Why might a user consider scaling their DB instance class?", "answer": "A user might consider scaling their DB instance class if there are high levels of CPU utilization, as this can reduce query performance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-04T18:12:21.083947"}}
{"question": "How does the method of identifying slow queries differ between RDS for MySQL/MariaDB and RDS for Oracle?", "answer": "For RDS for MySQL or MariaDB, slow queries can be identified by accessing the slow query logs and querying the mysql.slow_log table. In contrast, for RDS for Oracle, slow queries are identified using Oracle trace file data.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-04T18:12:21.084153"}}
{"question": "How long does Amazon RDS typically aim to support new database engine versions after their general availability?", "answer": "Amazon RDS typically aims to support new engine versions within 5 months of their general availability.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-04T18:12:25.731012"}}
{"question": "What factors influence the number of new database engine versions supported by Amazon RDS?", "answer": "The number of new versions supported by Amazon RDS will vary based on the frequency and content of releases and patches from the engines vendor or development organization, as well as the outcome of a thorough vetting of these releases and patches by the database engineering team.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-04T18:12:25.731723"}}
{"question": "Are all database engine versions available in every AWS region when creating a new DB instance?", "answer": "No, not every database engine version is available in every AWS region when creating a new DB instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-04T18:12:25.732165"}}
{"question": "What is the purpose of minor version upgrades in Amazon RDS?", "answer": "The purpose of minor version upgrades in Amazon RDS is to provide the latest security and functionality fixes while ensuring that the changes are backward-compatible with previous minor versions of the same major version of the database engine.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-04T18:12:32.096880"}}
{"question": "Why is it recommended to keep your database instance upgraded to the most current minor version?", "answer": "It is recommended to keep your database instance upgraded to the most current minor version because it will contain the latest security and functionality fixes, which are essential for maintaining the performance and security of your database.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-04T18:12:32.097193"}}
{"question": "How do automatic minor version upgrades differ from manual upgrades in Amazon RDS?", "answer": "Automatic minor version upgrades occur when a new engine minor version contains significant bug fixes and are scheduled during customer-specified maintenance windows, while manual upgrades require the user to use the Modify DB Instance command and specify the desired version, which can be applied either during the next maintenance window or immediately by selecting the Apply Immediately option.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-04T18:12:32.097403"}}
{"question": "Who is responsible for initiating major version upgrades of a DB instance?", "answer": "You are responsible for initiating major version upgrades of a DB instance, as they will not occur automatically due to compatibility risks.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-04T18:12:37.447092"}}
{"question": "Why do major version upgrades of DB instances not occur automatically?", "answer": "Major version upgrades of DB instances do not occur automatically because they involve some compatibility risk.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-04T18:12:37.447440"}}
{"question": "What is the difference between major version upgrades and major version deprecation in terms of initiation?", "answer": "Major version upgrades must be initiated by you due to compatibility risks, while major version deprecation may involve automatic processes, as indicated in the context.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-04T18:12:37.447624"}}
{"question": "How can I upgrade my DB instance in Amazon RDS?", "answer": "You can upgrade your DB instance in Amazon RDS by creating a DB snapshot of your existing DB instance, restoring from that snapshot to create a new DB instance, and then initiating a version upgrade for the new DB instance. This allows you to experiment safely on the upgraded copy before deciding to upgrade your original instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:12:43.531624"}}
{"question": "What is the support duration for major and minor version releases in Amazon RDS?", "answer": "Amazon RDS intends to support major version releases for at least 3 years after they are initially supported, and minor versions for at least 1 year after their initial support. However, specific major or minor versions may be deprecated sooner due to security issues or other significant bugs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:12:43.532070"}}
{"question": "What is the difference between the deprecation timelines for major and minor versions in Amazon RDS?", "answer": "When a minor version of a database engine is deprecated, Amazon RDS provides a three-month period after the announcement before beginning automatic upgrades. In contrast, for a deprecated major version, there is a minimum six-month period after the announcement for users to initiate an upgrade to a supported major version before an automatic upgrade is applied during scheduled maintenance windows.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:12:43.532293"}}
{"question": "What happens if a specific major or minor version of Amazon RDS is deprecated?", "answer": "If a specific major or minor version of Amazon RDS is deprecated, Amazon will discontinue the creation of new database instances and clusters with those versions. However, existing customers may still be able to run their databases using the deprecated versions.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-04T18:12:50.724266"}}
{"question": "How is the billing structured for Amazon RDS services?", "answer": "Billing for Amazon RDS services is based on several factors: DB instance hours depending on the class of the DB instance consumed, storage capacity provisioned to the DB instance charged per GB per month, total storage I/O requests for Amazon RDS Magnetic Storage and Amazon Aurora, provisioned IOPS for Provisioned IOPS (SSD) Storage, backup storage related to automated backups and customer-initiated snapshots, and data transfer for internet data in and out of the DB instance. Billing commences as soon as the DB instance is available and continues until the instance is terminated.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-04T18:12:50.724604"}}
{"question": "How does the billing for DB instance hours differ from the billing of storage in Amazon RDS?", "answer": "Billing for DB instance hours is based on the class of the DB instance consumed and is charged in one-second increments with a 10-minute minimum charge after a billable status change. In contrast, storage is billed per GB per month based on the provisioned storage capacity of the DB instance, and if the storage capacity is scaled within the month, the bill will be pro-rated.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-04T18:12:50.724827"}}
{"question": "How are DB instance hours billed?", "answer": "DB instance hours are billed for each hour your DB instance is running in an available state. Partial DB instance hours consumed are billed in one-second increments with a 10 minute minimum charge following a billable status change, such as creating, starting, or modifying the DB instance class.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-04T18:12:55.905254"}}
{"question": "What must you do to avoid being charged for additional DB instance hours?", "answer": "To avoid being charged for additional DB instance hours, you must stop or delete your DB instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-04T18:12:55.905588"}}
{"question": "What charges are incurred while a database instance is stopped compared to when it is running?", "answer": "While your database instance is stopped, you are charged for provisioned storage (including Provisioned IOPS) and backup storage (including manual snapshots and automated backups within your specified retention window), but not for DB instance hours. In contrast, when the database instance is running, you are charged for DB instance hours.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-04T18:12:55.905723"}}
{"question": "What is the maximum amount of free backup storage provided for an AWS account in a region?", "answer": "Free backup storage is provided up to your account's total provisioned database storage across the entire region. For example, if you have a MySQL DB instance with 100 GB of provisioned storage and a PostgreSQL DB instance with 150 GB of provisioned storage, you will receive a total of 250 GB of backup storage at no additional charge.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-04T18:13:02.195992"}}
{"question": "How is the charge for backup storage calculated if you exceed the free backup storage limit?", "answer": "Each day, your account's total provisioned database storage in the region is compared against your total backup storage in the region. You are only charged for the excess backup storage. For example, if you have 10 GB of excess backup storage each day, you will be charged for 10 GB-month of backup storage for the month.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-04T18:13:02.196338"}}
{"question": "What is the difference in data replication between the primary data storage and backup storage in AWS RDS?", "answer": "The primary data storage for your DB instance is located within a single Availability Zone, while the backup data, including transaction logs, is geo-redundantly replicated across multiple Availability Zones. This replication provides greater levels of data durability for the backups compared to the primary data storage.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-04T18:13:02.196534"}}
{"question": "How are Multi-AZ DB instance hours billed?", "answer": "Multi-AZ DB instance hours are billed based on the class of the DB instance consumed, such as db.t2.micro or db.m4.large. Partial DB instance hours are billed in one-second increments with a 10 minutes minimum charge following a billable status change, like creating, starting, or modifying the DB instance class.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-04T18:13:07.916384"}}
{"question": "What is the impact of converting a DB instance deployment between standard and Multi-AZ within a given hour on billing?", "answer": "If you convert your DB instance deployment between standard and Multi-AZ within a given hour, you will be charged both applicable rates for that hour. Additionally, for provisioned storage, you will be charged the higher of the applicable storage rates for that hour.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-04T18:13:07.916706"}}
{"question": "How does the I/O usage differ between Multi-AZ and standard DB instance deployments?", "answer": "Multi-AZ deployments consume a larger volume of I/O requests than standard DB instance deployments, depending on the database write/read ratio. Specifically, write I/O usage associated with database updates will double for Multi-AZ deployments because Amazon RDS synchronously replicates data to the standby DB instance, while read I/O usage will remain the same.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-04T18:13:07.917064"}}
{"question": "What types of database engines are included in the AWS Free Tier for Amazon RDS?", "answer": "The AWS Free Tier for Amazon RDS includes free use of Single-AZ Micro DB instances running MySQL, MariaDB, PostgreSQL, and SQL Server Express Edition.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T18:13:15.372410"}}
{"question": "How does the AWS Free Tier limit the usage of Amazon RDS instances?", "answer": "The AWS Free Tier limits usage to 750 instance hours per month. Any usage beyond this limit across all Amazon RDS Single-AZ Micro DB instances and eligible database engines will be billed at standard Amazon RDS prices.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T18:13:15.372723"}}
{"question": "What is the difference between AWS Free Tier usage and Amazon RDS reserved instances?", "answer": "The AWS Free Tier provides free use of Single-AZ Micro DB instances up to 750 instance hours per month, whereas Amazon RDS reserved instances allow you to reserve a DB instance for a one or three year term in exchange for a significant discount compared to on-demand pricing. Reserved instances have payment options of No Upfront, Partial Upfront, and All Upfront, which are not applicable to the Free Tier.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-04T18:13:15.372935"}}
{"question": "What is the main difference between reserved instances and on-demand DB instances?", "answer": "The main difference between reserved instances and on-demand DB instances is how they are billed. Reserved instances require a one- or three-year reservation purchase, which provides a lower effective hourly usage rate compared to on-demand DB instances, which are billed at on-demand hourly rates.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-04T18:13:25.134454"}}
{"question": "How does purchasing a reserved instance affect the billing of a DB instance?", "answer": "When you purchase a reserved instance, it allows you to launch a DB instance using the same instance class, engine, and region for which the reservation was made. As long as the reservation is active, Amazon RDS will apply the reduced hourly rate to the new DB instance, effectively lowering the billing compared to on-demand rates.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-04T18:13:25.134782"}}
{"question": "In what way do reserved instances differ from capacity reservations in Amazon RDS?", "answer": "Reserved instances are not specific to an Availability Zone and do not provide capacity reservations, meaning that even if capacity is limited in one Availability Zone, reservations can still be purchased for the Region and the discount will apply to matching usage in any Availability Zone within that Region. In contrast, capacity reservations would ensure that specific capacity is reserved in a particular Availability Zone.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-04T18:13:25.135008"}}
{"question": "When are the pricing changes for a reserved instance activated?", "answer": "Pricing changes associated with a reserved instance are activated once your request is received while the payment authorization is processed.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-04T18:13:29.832923"}}
{"question": "How does AWS handle billing for DB instances when a reservation is made?", "answer": "When computing your bill, AWS's system automatically applies your Reservation(s) such that all eligible DB instances are charged at the lower hourly reserved DB instance rate, regardless of whether they are on-demand or reserved instances.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-04T18:13:29.833222"}}
{"question": "What happens to a reserved instance when its reservation term expires compared to an on-demand instance?", "answer": "When a reserved instance's reservation term expires, it will revert to the appropriate On-Demand hourly usage rate for your DB instance class and Region, while on-demand instances continue to be billed at their hourly on-demand rate.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-04T18:13:29.833395"}}
{"question": "What attributes are associated with each reservation for a DB instance?", "answer": "Each reservation is associated with the following set of attributes: DB engine, DB instance class, Multi-AZ deployment option, license model, and Region.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-04T18:13:37.850062"}}
{"question": "How does size-flexibility work for reservations that are eligible, and what is an example of its application?", "answer": "A reservation for a DB engine and license model that is eligible for size-flexibility will automatically apply to a running DB instance of any size within the same instance family for the same database engine and Region. For example, if you purchased a db.m4.2xlarge MySQL reservation and then scaled up the running DB instance to a db.m4.4xlarge, the discounted rate of the reserved instance will cover half of the usage of the larger DB instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-04T18:13:37.850398"}}
{"question": "What is the difference in how a reservation applies to eligible size-flexibility DB engines versus those that are not eligible?", "answer": "For DB engines and license models that are eligible for size-flexibility, a reservation can apply to a running DB instance of any size within the same instance family. In contrast, for DB engines or license models that are not eligible for size-flexibility, each reservation can only be applied to a DB instance with the same attributes for the duration of the term. If any attributes are modified before the end of the reservation term, the hourly usage rates will revert to on-demand rates.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-04T18:13:37.850619"}}
{"question": "Can I cancel my reserved DB instance and get a refund for the one-time payment?", "answer": "No, you cannot cancel your reserved DB instance and the one-time payment (if applicable) is not refundable. You will continue to pay for every hour during your Reserved DB instance term regardless of your usage.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-04T18:13:45.366799"}}
{"question": "What are the payment options available when purchasing a Reserved DB instance?", "answer": "When purchasing a Reserved DB instance (RI), there are three payment options available: All Upfront, No Upfront, and Partial Upfront. With the All Upfront option, you pay for the entire term in one upfront payment. The No Upfront option allows you to pay nothing upfront, with the entire value spread across every hour in the term, billed regardless of usage. The Partial Upfront option is a hybrid where you make a small upfront payment and are billed a low hourly rate for every hour in the term, also regardless of usage.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-04T18:13:45.367135"}}
{"question": "How do the All Upfront and Partial Upfront payment options differ?", "answer": "The All Upfront payment option requires you to pay for the entire term of the Reserved DB instance in one upfront payment, while the Partial Upfront payment option involves making a small upfront payment and then being billed a low hourly rate for every hour in the term. Both options require payment for every hour during the term regardless of usage, but the key difference lies in the initial payment structure.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-04T18:13:45.367355"}}
{"question": "What types of storage does Amazon RDS use for database and log storage?", "answer": "Amazon RDS uses EBS volumes for database and log storage.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-04T18:13:52.714880"}}
{"question": "How does scaling up storage for MySQL and Oracle DB instances affect I/O capacity?", "answer": "Scaling up storage for MySQL and Oracle DB instances may result in some I/O capacity improvement.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-04T18:13:52.715191"}}
{"question": "What is the difference in performance characteristics between Amazon RDS General Purpose (SSD) Storage and Amazon RDS Provisioned IOPS (SSD) Storage?", "answer": "Amazon RDS General Purpose (SSD) Storage is suitable for moderate I/O requirements with a baseline of 3 IOPS/GB and the ability to burst up to 3,000 IOPS, providing predictable performance. In contrast, Amazon RDS Provisioned IOPS (SSD) Storage is designed for fast, predictable, and consistent I/O performance, allowing users to specify an IOPS rate for the DB instance and optimized for I/O-intensive, transactional (OLTP) workloads.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-04T18:13:52.715412"}}
{"question": "What type of workloads is Amazon RDS magnetic storage useful for?", "answer": "Amazon RDS magnetic storage is useful for small database workloads where data is accessed less frequently.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-04T18:13:57.442399"}}
{"question": "Why is magnetic storage not recommended for production database instances?", "answer": "Magnetic storage is not recommended for production database instances because it is designed for small workloads with infrequent data access, which may not meet the performance requirements of production environments.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-04T18:13:57.443093"}}
{"question": "How does Amazon RDS Provisioned IOPS (SSD) Storage differ from Amazon RDS General Purpose (SSD) Storage?", "answer": "Amazon RDS Provisioned IOPS (SSD) Storage is suited for high-performance OLTP workloads, whereas Amazon RDS General Purpose (SSD) Storage is intended for database workloads with moderate I/O requirements.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-04T18:13:57.443301"}}
{"question": "What is the default retention period for automated backups in Amazon RDS?", "answer": "The default retention period for automated backups in Amazon RDS is 7 days, but it can be set to a maximum of 35 days.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T18:14:02.715021"}}
{"question": "How does point-in-time recovery work in Amazon RDS?", "answer": "Point-in-time recovery in Amazon RDS works by applying transaction logs to the most appropriate daily backup when automated backups are enabled. This allows you to restore your DB instance to a specific time within the retention period, up to the Latest Restorable Time.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T18:14:02.715472"}}
{"question": "What is the difference between automated backups and DB Snapshots in Amazon RDS?", "answer": "The main difference between automated backups and DB Snapshots in Amazon RDS is that automated backups are performed automatically by Amazon RDS at a specified time and allow for point-in-time recovery, while DB Snapshots are user-initiated backups that can be created at any time and are retained until explicitly deleted.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-04T18:14:02.715726"}}
{"question": "What happens when you perform a restore operation to a point in time or from a DB Snapshot?", "answer": "When you perform a restore operation to a point in time or from a DB Snapshot, a new DB Instance is created with a new endpoint.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-04T18:14:06.157005"}}
{"question": "Why is a new DB Instance created during a restore operation?", "answer": "A new DB Instance is created during a restore operation to enable you to create multiple DB Instances from a specific DB Snapshot or point in time.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-04T18:14:06.157263"}}
{"question": "What can you do with the old DB Instance after restoring from a DB Snapshot?", "answer": "The old DB Instance can be deleted if so desired after restoring from a DB Snapshot.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-04T18:14:06.157419"}}
{"question": "What is the default retention period for automated backups in Amazon RDS?", "answer": "By default, Amazon RDS enables automated backups of your DB instance with a 7-day retention period.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-04T18:14:10.552359"}}
{"question": "How can you modify the backup retention period for an existing DB instance in Amazon RDS?", "answer": "You can modify the backup retention period for an existing DB instance using the RDS Console or the ModifyDBInstance API.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-04T18:14:10.552714"}}
{"question": "What happens to storage I/O during the backup window for a standard DB instance compared to a Multi-AZ DB deployment?", "answer": "During the backup window for a standard DB instance, storage I/O may be briefly suspended while the backup process initializes, typically under a few seconds. In contrast, there is no I/O suspension for Multi-AZ DB deployments, since the backup is taken from the standby.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-04T18:14:10.552920"}}
{"question": "How many automated DB snapshots are typically retained compared to the retention period?", "answer": "It is normal to have 1 or 2 more automated DB snapshots than the number of days in your retention period. One extra automated snapshot is retained to ensure the ability to perform a point in time restore to any time during the retention period.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-04T18:14:14.832430"}}
{"question": "What is the purpose of having an extra automated snapshot in the DB backup process?", "answer": "An extra automated snapshot is retained to ensure the ability to perform a point in time restore to any time during the retention period.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-04T18:14:14.832784"}}
{"question": "What happens to automated backups when a DB instance is deleted, and how does this differ from manually created DB snapshots?", "answer": "Automated backups are deleted when the DB instance is deleted. In contrast, only manually created DB snapshots are retained after the DB instance is deleted.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-04T18:14:14.832965"}}
{"question": "What is a DB Subnet Group in the context of Amazon RDS?", "answer": "A DB Subnet Group is a collection of subnets that you may want to designate for your Amazon RDS DB Instances in a VPC. Each DB Subnet Group should have at least one subnet for every Availability Zone in a given Region.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-04T18:14:21.237775"}}
{"question": "How does Amazon RDS manage backups and software patching for DB Instances deployed in EC2-Classic and EC2-VPC?", "answer": "The basic functionality of Amazon RDS is the same regardless of whether it is used in an EC2-Classic or EC2-VPC environment. Amazon RDS manages backups, software patching, automatic failure detection, read replicas, and recovery for DB Instances deployed inside or outside a VPC.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-04T18:14:21.238070"}}
{"question": "What are the differences in subnet requirements for Single-AZ and Multi-AZ deployments in Amazon RDS?", "answer": "For Multi-AZ deployments, it is necessary to define a subnet for all Availability Zones in a Region to allow Amazon RDS to create a new standby in another Availability Zone if needed. For Single-AZ deployments, it is also important to define a subnet for all Availability Zones in case there is a desire to convert them to Multi-AZ deployments later.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-04T18:14:21.238374"}}
{"question": "What are the options available for accessing DB Instances deployed within a VPC from the Internet?", "answer": "DB Instances deployed within a VPC can be accessed from the Internet using VPN, bastion hosts that you can launch in your public subnet, or by enabling the Publicly Accessible option when creating the DB Instances.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-04T18:14:27.495727"}}
{"question": "What is the purpose of using a bastion host in relation to accessing DB Instances in a VPC?", "answer": "A bastion host is used to allow access to DB Instances within a VPC from external sources. It acts as an SSH host located in a public subnet, which must have an internet gateway and routing rules configured to forward requests to the private IP address of the Amazon RDS DB instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-04T18:14:27.496013"}}
{"question": "How does the accessibility of DB Instances differ when using the Publicly Accessible option compared to using a VPN or bastion host?", "answer": "When the Publicly Accessible option is set to yes, DB Instances within a VPC are fully accessible from outside the VPC by default, eliminating the need for a VPN or bastion host. In contrast, using a VPN or bastion host requires additional configuration and setup to enable access to the DB Instances.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-04T18:14:27.496203"}}
{"question": "What do you need to modify in your VPC to ensure that your DB instance is reachable from client instances?", "answer": "You need to modify routing tables and networking ACLs in your VPC to ensure that your DB instance is reachable from your client instances.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-04T18:14:31.183814"}}
{"question": "Why is it important to configure networking ACLs for cross-AZ communication in a Multi-AZ deployment?", "answer": "It is important to configure networking ACLs for cross-AZ communication in a Multi-AZ deployment because after a failover, your client EC2 instance and Amazon RDS DB Instance may be in different Availability Zones, and proper configuration ensures that they can communicate with each other.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-04T18:14:31.184027"}}
{"question": "What are the implications of removing subnets from an existing DB Subnet Group?", "answer": "Removing subnets from an existing DB Subnet Group can cause unavailability for instances if they are running in a particular Availability Zone that gets removed from the subnet group.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-04T18:14:31.184181"}}
{"question": "What are the default privileges granted to the primary user in MySQL?", "answer": "The default privileges for the primary user in MySQL include: create, drop, references, event, alter, delete, index, insert, select, update, create temporary tables, lock tables, trigger, create view, show view, alter routine, create routine, execute, trigger, create user, process, show databases, and grant option.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T18:14:35.400758"}}
{"question": "How does the primary user's role in Oracle differ from that in MySQL?", "answer": "In Oracle, the primary user is granted the 'dba' role and inherits most of the privileges associated with that role, whereas in MySQL, the primary user has a specific set of default privileges that do not include a role-based inheritance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T18:14:35.401066"}}
{"question": "What must be configured to allow access to your Amazon RDS database over the internet?", "answer": "To allow access to your Amazon RDS database over the internet, you must intentionally turn on the ability by configuring Security Groups. You can authorize access for specific IPs, IP ranges, or subnets corresponding to servers in your own data center.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-04T18:14:35.401254"}}
{"question": "What services does Amazon RDS use for managing encryption keys?", "answer": "Amazon RDS uses AWS Key Management Service (KMS) for managing encryption keys.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-04T18:14:38.955407"}}
{"question": "How does Amazon RDS handle encryption and decryption of data?", "answer": "Amazon RDS handles encryption and decryption transparently, meaning that users do not need to manage the encryption process manually.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-04T18:14:38.955784"}}
{"question": "What features of Amazon RDS can be referenced in AWS IAM policies for access control?", "answer": "Amazon RDS resources that can be referenced in AWS IAM policies include DB instances, DB snapshots, read replicas, DB security groups, DB option groups, DB parameter groups, event subscriptions, and DB subnet groups.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-04T18:14:38.955986"}}
{"question": "Are all Amazon RDS database engines HIPAA-eligible?", "answer": "Yes, all Amazon RDS database engines are HIPAA-eligible, allowing you to build HIPAA-compliant applications and store healthcare-related information, including protected health information (PHI), under an executed Business Associate Agreement (BAA) with AWS.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-04T18:14:44.791598"}}
{"question": "What is the purpose of a database parameter group in Amazon RDS?", "answer": "A database parameter group (DB Parameter Group) acts as a 'container' for engine configuration values that can be applied to one or more DB Instances. It allows you to specify custom engine configuration values for your DB Instances, as opposed to using the default DB Parameter Group, which contains engine defaults and Amazon RDS system defaults optimized for the DB Instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-04T18:14:44.791853"}}
{"question": "What are the risks associated with changing configuration parameters from recommended values in Amazon RDS?", "answer": "Changing configuration parameters from recommended values can have unintended effects, ranging from degraded performance to system crashes. Therefore, such changes should only be attempted by advanced users who are willing to assume these risks.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-04T18:14:44.792199"}}
{"question": "What does Amazon RDS automatically provision when you create or modify your DB instance to run as a Multi-AZ deployment?", "answer": "Amazon RDS automatically provisions and maintains a synchronous 'standby' replica in a different Availability Zone when you create or modify your DB instance to run as a Multi-AZ deployment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-04T18:14:50.136483"}}
{"question": "How does Multi-AZ deployment enhance the reliability of database operations in Amazon RDS?", "answer": "Multi-AZ deployment enhances reliability by maintaining a synchronous standby replica in a different Availability Zone, allowing for automatic failover to the standby during planned maintenance or in the event of failures. This ensures that database writes and reads can resume quickly without manual intervention, protecting the latest database updates against DB instance failure.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-04T18:14:50.136794"}}
{"question": "What is the difference between the primary DB instance and the standby in a Multi-AZ deployment?", "answer": "In a Multi-AZ deployment, the primary DB instance serves database writes and reads, while the standby is an up-to-date replica that is not directly interacted with and cannot serve read traffic. The standby is promoted to primary only during failover scenarios, at which point it accepts database operations.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-04T18:14:50.136995"}}
{"question": "What are the chief benefits of running a DB instance as a Multi-AZ deployment?", "answer": "The chief benefits of running your DB instance as a Multi-AZ deployment are enhanced database durability and availability. The increased availability and fault tolerance offered by Multi-AZ deployments make them a natural fit for production environments.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-04T18:14:56.167057"}}
{"question": "How does a Multi-AZ deployment improve data durability compared to standard deployments in a single AZ?", "answer": "A Multi-AZ deployment safeguards your data in the event of a DB instance component failure or loss of availability in one Availability Zone. For example, if a storage volume on your primary fails, Amazon RDS automatically initiates a failover to the standby, where all of your database updates are intact. This provides additional data durability relative to standard deployments in a single AZ, where a user-initiated restore operation would be required, and updates that occurred after the latest restorable time (typically within the last five minutes) would not be available.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-04T18:14:56.167408"}}
{"question": "What is the difference in availability impact during maintenance operations between Multi-AZ deployments and single AZ deployments?", "answer": "In Multi-AZ deployments, the availability impact during maintenance operations, such as patching or DB instance class scaling, is limited to the time required for automatic failover to complete, as these operations occur first on the standby before failover. In contrast, single AZ deployments do not provide this level of availability support during maintenance, leading to potentially greater downtime.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-04T18:14:56.167924"}}
{"question": "Can a Multi-AZ standby serve read requests?", "answer": "No, a Multi-AZ standby cannot serve read requests. Multi-AZ deployments are designed for enhanced database availability and durability, not for read scaling benefits.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-04T18:15:00.236950"}}
{"question": "What is the primary purpose of Multi-AZ deployments?", "answer": "The primary purpose of Multi-AZ deployments is to provide enhanced database availability and durability through synchronous replication between the primary and standby instances.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-04T18:15:00.237280"}}
{"question": "What are the steps involved in converting a Single-AZ DB instance to Multi-AZ?", "answer": "To convert a Single-AZ DB instance to Multi-AZ, a snapshot of the primary instance is taken, a new standby instance is created in a different Availability Zone from the snapshot, and synchronous replication is configured between the primary and standby instances. This process incurs no downtime, although there may be increased latency while the standby catches up to the primary.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-04T18:15:00.237484"}}
{"question": "What scenarios trigger Amazon RDS to automatically perform a failover in Multi-AZ deployments?", "answer": "Amazon RDS automatically performs a failover in the event of the following scenarios: loss of availability in the primary Availability Zone, loss of network connectivity to the primary, compute unit failure on the primary, and storage failure on the primary.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T18:15:05.897689"}}
{"question": "How does Amazon RDS ensure enhanced availability during operations like DB instance scaling or system upgrades in Multi-AZ deployments?", "answer": "For enhanced availability during operations such as DB instance scaling or system upgrades, Amazon RDS applies these changes first on the standby instance prior to automatic failover. As a result, the availability impact is limited only to the time required for the automatic failover to complete.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T18:15:05.897990"}}
{"question": "How does the failover process in Amazon RDS differ from the handling of long-running queries or deadlocks?", "answer": "The failover process in Amazon RDS is automatically handled in response to specific failure scenarios, such as loss of availability or network connectivity, while it does not failover automatically in response to database operations like long-running queries, deadlocks, or database corruption errors.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-04T18:15:05.898177"}}
{"question": "What is the process for initiating a failover in Amazon RDS?", "answer": "You can initiate a failover in Amazon RDS when rebooting your instance by using the AWS Management Console or the RebootDBInstance API call.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-04T18:15:09.882112"}}
{"question": "What are the benefits of using Multi-AZ deployments in Amazon RDS?", "answer": "Multi-AZ deployments in Amazon RDS provide automatic failover without user intervention, ensuring high availability and resilience of the database tier. The creation of the standby, synchronous replication, and failover processes are all handled automatically, allowing for seamless operation during failure conditions.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-04T18:15:09.882428"}}
{"question": "How does the location of the standby in a Multi-AZ deployment compare to the primary DB instance?", "answer": "In a Multi-AZ deployment, the standby is automatically provisioned in a different Availability Zone within the same Region as the DB instance primary, ensuring that they are not located in the same zone to enhance resilience.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-04T18:15:09.882603"}}
{"question": "How do automated backups and DB Snapshots differ in their operation for Single-AZ and Multi-AZ deployments?", "answer": "Automated backups and DB Snapshots are handled in the same way for both Single-AZ and Multi-AZ deployments. However, in a Multi-AZ deployment, the backups and snapshots are taken from the standby instance to avoid I/O suspension on the primary instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-04T18:15:19.740781"}}
{"question": "What are the advantages of using read replicas in a database deployment?", "answer": "Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy workloads. They enable you to distribute your application's read traffic among multiple replicas, which can improve performance and reduce the load on the source DB instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-04T18:15:19.741119"}}
{"question": "How does the replication process for read replicas differ from the primary DB instance updates?", "answer": "Updates are applied to read replicas after they occur on the source DB instance, using the supported engine's native, asynchronous replication. This means there may be replication lag, which can vary significantly, indicating that the read replicas may not always reflect the most current state of the source DB instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-04T18:15:19.741347"}}
{"question": "What is one common reason for deploying read replicas in AWS?", "answer": "One common reason for deploying read replicas is to scale beyond the compute or I/O capacity of a single DB instance for read-heavy database workloads. This excess read traffic can be directed to one or more read replicas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-04T18:15:25.959652"}}
{"question": "Why might a business choose to run reporting queries against a read replica instead of the primary DB instance?", "answer": "A business might choose to run reporting queries against a read replica rather than the primary DB instance to avoid impacting the performance of the production DB instance, especially if the reporting queries are read-heavy and could slow down transaction processing.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-04T18:15:25.960113"}}
{"question": "How do the use cases for read replicas differ from the primary DB instance regarding availability during maintenance?", "answer": "Read replicas can serve read traffic while the source DB instance is unavailable, such as during I/O suspension for backups or scheduled maintenance. In contrast, the primary DB instance cannot handle I/O requests during these periods, which means that read traffic would typically be disrupted unless redirected to the read replicas.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-04T18:15:25.960315"}}
{"question": "Which versions of PostgreSQL support the creation of read replicas in Amazon RDS?", "answer": "DB instances with PostgreSQL version 9.3.5 or newer support the creation of read replicas in Amazon RDS. Existing instances prior to version 9.3.5 need to be upgraded to at least version 9.3.5 to utilize this feature.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-04T18:15:32.001828"}}
{"question": "What are the requirements for enabling read replicas in Amazon RDS for MySQL?", "answer": "To enable read replicas in Amazon RDS for MySQL, automatic backups must be and remain enabled on the source DB instance. Additionally, automatic backups on the replica are only supported for Amazon RDS read replicas running MySQL version 5.6 and later, and not for version 5.5.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-04T18:15:32.002215"}}
{"question": "How does the support for read replicas in Amazon RDS for Oracle compare to that for Amazon RDS for PostgreSQL?", "answer": "Amazon RDS for Oracle supports read replicas for Oracle version 12.1.0.2.v12 and higher, including all 12.2 versions, using the Bring Your Own License model with Oracle Database Enterprise Edition and licensed for the Active Data Guard Option. In contrast, Amazon RDS for PostgreSQL requires DB instances to be upgraded to version 9.3.5 or newer to support read replicas, indicating that while both services require specific versions for read replicas, the criteria and licensing models differ.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-04T18:15:32.002502"}}
{"question": "What API is used to create a read replica in Amazon RDS?", "answer": "You can create a read replica using the standard CreateDBInstanceReadReplica API.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T18:15:36.505162"}}
{"question": "What is the role of the SourceDBInstanceIdentifier when creating a read replica?", "answer": "The SourceDBInstanceIdentifier is the DB Instance Identifier of the 'source' DB Instance from which you wish to replicate, allowing you to identify the read replica during its creation.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T18:15:36.505393"}}
{"question": "How many read replicas can be created for a source DB instance in Amazon RDS for MySQL compared to Amazon RDS for Oracle?", "answer": "Amazon RDS for MySQL allows you to create up to 15 read replicas for a given source DB instance, while Amazon RDS for Oracle allows you to create up to 5 read replicas for the same.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-04T18:15:36.505870"}}
{"question": "What types of database engines support read replicas in Amazon RDS?", "answer": "Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server support read replicas, which are implemented using those engines' native asynchronous replication.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-04T18:15:41.270006"}}
{"question": "What is the main advantage of using Multi-AZ deployments over read replicas in Amazon RDS?", "answer": "The main advantage of using Multi-AZ deployments over read replicas is that Multi-AZ deployments utilize synchronous replication, ensuring that all database writes are concurrent on the primary and standby instances. This provides enhanced write availability and protects the latest database updates, which are immediately available on the standby in the event of a failover.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-04T18:15:41.270315"}}
{"question": "How do read replicas and Multi-AZ deployments complement each other in Amazon RDS?", "answer": "Read replicas and Multi-AZ deployments complement each other in Amazon RDS by addressing different needs. Multi-AZ deployments enhance write availability and data durability, while associated read replicas improve read traffic scalability. Using both in conjunction allows for a more robust production deployment.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-04T18:15:41.270528"}}
{"question": "What types of read replicas can be created in Amazon Aurora, Amazon RDS for MySQL, and MariaDB?", "answer": "You can create three tiers of read replicas: a first-tier read replica, a second-tier read replica from an existing first-tier read replica, and a third-tier replica from second-tier read replicas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-04T18:15:46.527065"}}
{"question": "Why might an application benefit from using second-tier and third-tier read replicas?", "answer": "By creating a second-tier and third-tier read replica, you may be able to move some of the replication load from the primary database instance to different tiers of Read Replica based on your application needs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-04T18:15:46.527300"}}
{"question": "How do the support for DDL SQL statements against read replicas differ between Amazon RDS for MySQL and Amazon RDS for PostgreSQL?", "answer": "Amazon RDS for MySQL can be configured to permit DDL SQL statements against a read replica, while Amazon RDS for PostgreSQL does not currently support the execution of DDL SQL statements against a read replica.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-04T18:15:46.527454"}}
{"question": "What happens to updates made to a source DB instance in relation to its read replicas?", "answer": "Updates to a source DB instance will automatically be replicated to any associated read replicas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-04T18:15:51.360011"}}
{"question": "What are some reasons a read replica might fall behind its source DB instance?", "answer": "A read replica can fall behind its source DB instance for various reasons, including: if the write I/O volume to the source DB instance exceeds the rate at which changes can be applied to the read replica, particularly if the compute capacity of the read replica is less than that of the source DB instance; complex or long-running transactions to the source DB instance that hold up replication; and network partitions or latency between the source DB instance and the read replica.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-04T18:15:51.360356"}}
{"question": "How do the strengths and weaknesses of supported engines' native replication affect Read Replicas?", "answer": "Read Replicas are subject to the strengths and weaknesses of supported engines' native replication, which means they may experience lag or inconsistency compared to their source DB instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-04T18:15:51.360787"}}
{"question": "How can I retrieve a list of all the DB Instances deployed in Amazon RDS?", "answer": "You can retrieve a list of all the DB Instances you have deployed in Amazon RDS by using the standard DescribeDBInstances API or by clicking on the 'Instances' tab of the Amazon RDS Console.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-04T18:15:56.575281"}}
{"question": "What is the significance of the 'Replica Lag' metric in Amazon RDS?", "answer": "'Replica Lag' is a significant metric in Amazon RDS as it indicates how far a read replica has fallen behind its source DB instance. This metric is published as an Amazon CloudWatch metric and can be accessed via the AWS Management Console or Amazon CloudWatch APIs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-04T18:15:56.575507"}}
{"question": "What happens to the Replication State of a Read Replica if a replication error occurs, and how does this change if the error is fixed?", "answer": "If a replication error occurs, the Replication State field in the AWS Management Console is updated to 'Error'. If the replication error is fixed, the Replication State changes to 'Replicating'.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-04T18:15:56.575893"}}
{"question": "How can you delete a read replica in AWS?", "answer": "You can delete a read replica by using either the AWS Management Console or by passing its DB Instance identifier to the DeleteDBInstance API.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-04T18:16:03.434823"}}
{"question": "What happens to an Amazon Aurora replica when its corresponding source DB Instance is deleted?", "answer": "When the corresponding source DB Instance of an Amazon Aurora replica is deleted, the replica will remain active and continue to accept read traffic. Additionally, one of the replicas in the cluster will automatically be promoted as the new primary and will start accepting write traffic.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-04T18:16:03.435042"}}
{"question": "How do the behaviors of Amazon RDS for MySQL or MariaDB read replicas compare to those of Amazon RDS for PostgreSQL read replicas when the source DB Instance is deleted?", "answer": "Both Amazon RDS for MySQL or MariaDB read replicas and Amazon RDS for PostgreSQL read replicas will stay active and continue accepting read traffic after their corresponding source DB Instance is deleted. However, in the case of Amazon RDS for PostgreSQL, all read replicas will be promoted to standalone DB Instances that can accept both read and write traffic upon deletion of the source DB Instance, whereas the MySQL or MariaDB read replicas do not automatically promote to standalone instances unless explicitly deleted.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-04T18:16:03.435259"}}
{"question": "What system level metrics does Enhanced Monitoring capture for Amazon RDS instances?", "answer": "Enhanced Monitoring captures system level metrics such as CPU, memory, file system, and disk I/O for Amazon RDS instances.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-04T18:16:08.607804"}}
{"question": "How does Enhanced Monitoring differ from Performance Insights in terms of the level of diagnostics provided?", "answer": "Enhanced Monitoring provides deeper visibility into the health of Amazon RDS instances by collecting vital operating system metrics and process information, while Performance Insights offers an even deeper level of diagnostics and visualization of database load, along with a longer data retention period.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-04T18:16:08.608169"}}
{"question": "What are some key benefits of using CloudWatch Database Insights?", "answer": "Key benefits of CloudWatch Database Insights include effortless telemetry collection, curated insights with pre-built dashboards and alarms, a unified view for monitoring multiple databases, AI/ML capabilities for anomaly detection, application context monitoring to correlate database and application performance, fleet and instance-level views for analysis, and seamless integration with services like Amazon CloudWatch Application Signals and AWS X-Ray.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-04T18:16:08.608378"}}
{"question": "What is the maximum granularity for viewing performance values for metrics in Amazon RDS Enhanced Monitoring?", "answer": "The maximum granularity for viewing performance values for metrics in Amazon RDS Enhanced Monitoring is up to 1 second.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-04T18:16:13.979540"}}
{"question": "Why would someone choose to use CloudWatch instead of the Amazon RDS console dashboard?", "answer": "Someone would choose to use CloudWatch instead of the Amazon RDS console dashboard to view historical data beyond what is available on the RDS console dashboard. CloudWatch allows monitoring of Amazon RDS instances to diagnose the health of the entire AWS stack in a single location.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-04T18:16:13.979894"}}
{"question": "How do the granularity options for Amazon RDS Enhanced Monitoring compare to those for CloudWatch?", "answer": "Amazon RDS Enhanced Monitoring supports a granularity of up to 1 second, while CloudWatch supports granularities of up to 1 minute, with values averaged out for granularities less than that.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-04T18:16:13.980435"}}
{"question": "What is the default retention period configured for Enhanced Monitoring in CloudWatch Logs?", "answer": "The default retention period configured for Enhanced Monitoring in CloudWatch Logs is 30 days.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-04T18:16:20.949094"}}
{"question": "How does the defined granularity for Enhanced Monitoring affect the data ingested into CloudWatch Logs?", "answer": "The amount of information transferred for an Amazon RDS instance is directly proportional to the defined granularity for the Enhanced Monitoring feature. This means that different granularities will result in varying amounts of data being ingested into CloudWatch Logs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-04T18:16:20.949409"}}
{"question": "What are the differences between Amazon RDS Performance Insights and CloudWatch Database Insights?", "answer": "Amazon RDS Performance Insights is focused on database performance tuning and monitoring, allowing customers to assess the load on their database and take action as needed. In contrast, CloudWatch Database Insights inherits all the capabilities of Performance Insights but adds fleet-level monitoring, integration with application performance monitoring, and correlation of database metrics with logs and events.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-04T18:16:20.949589"}}
{"question": "What are the main benefits of using Amazon RDS Proxy?", "answer": "The main benefits of using Amazon RDS Proxy include improving scalability by pooling and sharing database connections, improving availability by reducing database failover times by up to 66% and preserving application connections during failovers, and improving security by optionally enforcing AWS IAM authentication to databases and securely storing credentials in AWS Secrets Manager.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-04T18:16:28.081602"}}
{"question": "How does Amazon RDS Proxy enhance the availability of applications?", "answer": "Amazon RDS Proxy enhances the availability of applications by reducing database failover times by up to 66% and preserving application connections during failovers.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-04T18:16:28.081950"}}
{"question": "In what ways does Amazon RDS Proxy improve security compared to traditional database access methods?", "answer": "Amazon RDS Proxy improves security by optionally enforcing AWS IAM authentication to databases and securely storing credentials in AWS Secrets Manager, which may not be features typically present in traditional database access methods.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-04T18:16:28.082449"}}
{"question": "What is one of the main benefits of using Amazon RDS Proxy for applications with unpredictable workloads?", "answer": "One of the main benefits of using Amazon RDS Proxy for applications with unpredictable workloads is its connection governance feature, which allows applications to efficiently reuse database connections. This helps in gracefully scaling the application by regulating the number of database connections that are opened and preserving overall performance and availability.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-04T18:16:32.830277"}}
{"question": "How does Amazon RDS Proxy enhance the availability of applications during transient failures?", "answer": "Amazon RDS Proxy enhances the availability of applications during transient failures by automatically routing traffic to a new database instance while preserving application connections. It also bypasses Domain Name System (DNS) caches to reduce failover times by up to 66% for Amazon RDS and Aurora Multi-AZ databases, allowing applications to tolerate database failures transparently without complex failure handling code.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-04T18:16:32.830659"}}
{"question": "How does Amazon RDS Proxy differ from traditional database management in handling idle connections?", "answer": "Amazon RDS Proxy differs from traditional database management in that it holds idling connections instead of requiring overprovisioning of databases to support mostly idling connections. This allows it to establish database connections only as required to optimally serve active requests, reducing unnecessary stress on database compute and memory.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-04T18:16:32.830900"}}
{"question": "What is the average network latency added by Amazon RDS Proxy to query or transaction response time?", "answer": "Amazon RDS Proxy can add an average of 5 milliseconds of network latency to query or transaction response time.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-04T18:16:39.992230"}}
{"question": "What are the benefits of using Amazon RDS Proxy for serverless applications?", "answer": "The benefits of using Amazon RDS Proxy for serverless applications include efficient scaling through pooling and reusing database connections, eliminating the need to handle database credentials in Lambda code by using the IAM execution role for authentication, and no requirement to manage new infrastructure or code, as RDS Proxy is fully managed and automatically scales based on application demands.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-04T18:16:39.992518"}}
{"question": "How does the process of enabling Amazon RDS Proxy differ for Amazon RDS databases and Lambda functions?", "answer": "Enabling Amazon RDS Proxy for an Amazon RDS database involves just a few clicks in the Amazon RDS console, where you specify the VPC and subnets for access. Similarly, as a Lambda user, you can enable RDS Proxy for your Amazon RDS database and set up a Lambda function to access it with just a few clicks in the Lambda console, indicating that both processes are user-friendly and require minimal effort.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-04T18:16:39.992679"}}
{"question": "What APIs can be used to create a proxy in Amazon RDS?", "answer": "You can use Amazon RDS Proxy APIs to create a proxy and then define target groups to associate the proxy with specific database instances or clusters.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-04T18:16:47.572897"}}
{"question": "How does Trusted Language Extensions (TLE) for PostgreSQL benefit developers using Amazon Aurora and Amazon RDS?", "answer": "Trusted Language Extensions (TLE) for PostgreSQL enables developers to build high performance PostgreSQL extensions and run them safely on Amazon Aurora and Amazon RDS. This improves time to market and removes the burden on database administrators to certify custom and third-party code for production database workloads, allowing developers to proceed as soon as they decide an extension meets their needs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-04T18:16:47.573239"}}
{"question": "What is the relationship between Trusted Language Extensions (TLE) and database administrators' responsibilities?", "answer": "Trusted Language Extensions (TLE) reduces the burden placed on database administrators to certify custom and third-party code for use in production database workloads, thus allowing developers to implement new PostgreSQL extensions without waiting for administrator approval.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-04T18:16:47.573467"}}
{"question": "What is the purpose of TLE for PostgreSQL?", "answer": "The purpose of TLE for PostgreSQL is to offer multiple layers of protection to mitigate the risk of software defects in PostgreSQL extensions that can crash the database. TLE is designed to limit access to system resources, control who can install specific extensions, and contain the impact of any extension defect to a single database connection.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-04T18:16:53.254350"}}
{"question": "How does TLE for PostgreSQL enhance security for database extensions?", "answer": "TLE for PostgreSQL enhances security for database extensions by providing fine-grained, online control over who can install extensions through the rds_superuser role, allowing DBAs to create a permissions model for running them. It also limits the impact of an extension defect to a single database connection and allows for the allow-listing of 'PostgreSQL hooks' for more sophisticated extensions.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-04T18:16:53.254662"}}
{"question": "How does the role of rds_superuser relate to TLE for PostgreSQL?", "answer": "The rds_superuser role is crucial in the management of TLE for PostgreSQL as it determines who is permitted to install specific extensions. Changes regarding extensions can only be made through the TLE API by users with the rds_superuser role, which also allows them to activate TLE and control the permissions model for running extensions.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-04T18:16:53.254865"}}
{"question": "What types of programming languages does TLE for PostgreSQL currently support?", "answer": "TLE for PostgreSQL currently supports JavaScript, PL/pgSQL, Perl, and SQL.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-04T18:16:57.058935"}}
{"question": "How does AWS manage the security risks associated with PostgreSQL extensions in Aurora and Amazon RDS?", "answer": "AWS manages the security risks for each of the PostgreSQL extensions under the AWS shared responsibility model.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-04T18:16:57.059412"}}
{"question": "What is the difference in deployment methods for TLE extensions compared to user-defined functions in PostgreSQL?", "answer": "TLE extensions are deployed using the SQL CREATE EXTENSION command from any PostgreSQL client, similar to how you would create a user-defined function written in a procedural language, such as PL/pgSQL or PL/Perl.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-04T18:16:57.059611"}}
{"question": "What versions of Amazon Aurora and RDS support Blue/Green Deployments?", "answer": "Amazon RDS Blue/Green Deployments are available for Amazon Aurora MySQL-Compatible Edition versions 5.6 and higher, RDS for MySQL versions 5.7 and higher, and RDS for MariaDB versions 10.2 and higher. They are also supported for Amazon Aurora PostgreSQL-Compatible Edition and Amazon RDS for PostgreSQL for versions 11.21 and higher, 12.16 and higher, 13.12 and higher, 14.9 and higher, and 15.4 and higher.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-04T18:17:03.964483"}}
{"question": "What are the benefits of using Amazon RDS Blue/Green Deployments?", "answer": "Amazon RDS Blue/Green Deployments allow you to make safer, simpler, and faster database changes. They are ideal for use cases such as major or minor version database engine upgrades, operating system updates, schema changes on green environments that do not break logical replication, and database parameter setting changes. Additionally, you can make multiple database updates at the same time using a single switchover, which helps to stay current on security patches, improve database performance, and access newer database features with short, predictable downtime.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-04T18:17:03.964946"}}
{"question": "How do Blue/Green Deployments compare to traditional deployment methods in terms of downtime?", "answer": "Blue/Green Deployments offer short, predictable downtime when making database changes, as they allow for multiple updates using a single switchover. In contrast, traditional deployment methods may not provide the same level of predictability or efficiency in downtime, potentially leading to longer and more uncertain downtime periods during updates.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-04T18:17:03.965244"}}
{"question": "What is the cost of running workloads on blue instances compared to green instances?", "answer": "You will incur the same price for running your workloads on green instances as you do for blue instances. Effectively, you are paying approximately 2x the cost of running workloads on db.instance for the lifespan of the blue-green-deployment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-04T18:17:09.484919"}}
{"question": "What are the benefits of using Amazon RDS Blue/Green Deployments?", "answer": "Amazon RDS Blue/Green Deployments allow you to make safer, simpler, and faster database changes, such as major or minor version upgrades, schema changes, instance scaling, engine parameter changes, and maintenance updates.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-04T18:17:09.485314"}}
{"question": "How does the cost structure for blue instances compare to green instances during a blue-green deployment?", "answer": "The cost structure for blue instances and green instances is the same; you will incur the same price for both. However, during a blue-green deployment, you effectively pay approximately 2x the cost of running the blue instances due to the need to run both environments simultaneously.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-04T18:17:09.485838"}}
{"question": "What happens to write operations during the switchover in Amazon RDS Blue/Green Deployments?", "answer": "During the switchover in Amazon RDS Blue/Green Deployments, write operations are blocked to both the blue and green environments until the switchover is complete. This ensures that the staging environment catches up with the production system and maintains data consistency.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-04T18:17:15.177160"}}
{"question": "Why is it important for the green environment to catch up with the production system during the switchover process?", "answer": "It is important for the green environment to catch up with the production system during the switchover process to ensure that data is consistent between the staging and production environments. This synchronization prevents data loss and ensures a smooth transition to the new production environment.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-04T18:17:15.177492"}}
{"question": "How does the handling of switchover differ for a self-managed logical replica compared to a source for a self-managed logical replica in Amazon RDS Blue/Green Deployments?", "answer": "For a self-managed logical replica that is a subscriber, the switchover is blocked, and it is recommended to stop replication before proceeding with the switchover. In contrast, if the blue environment is a source for a self-managed logical replica, the switchover can continue, but the self-managed replica must be updated to replicate from the green environment after the switchover.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-04T18:17:15.177700"}}
{"question": "What is the primary benefit of using Amazon RDS Optimized Writes for MySQL?", "answer": "The primary benefit of using Amazon RDS Optimized Writes for MySQL is the potential for up to 2x improved write transaction throughput, which is especially helpful for applications with write-heavy workloads such as digital payments, financial trading, and online gaming applications.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-04T18:17:20.356685"}}
{"question": "How does Amazon Aurora MySQL-Compatible Edition differ in data writing compared to traditional MySQL using the doublewrite buffer?", "answer": "Amazon Aurora MySQL-Compatible Edition differs in that it avoids the use of the doublewrite buffer altogether. Instead, it replicates data six ways across three Availability Zones (AZs) and uses a quorum-based approach to durably write data and correctly read it thereafter.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-04T18:17:20.356999"}}
{"question": "What are the differences in storage methods for MySQL and Amazon RDS Optimized Reads when handling temporary objects?", "answer": "MySQL traditionally uses the Amazon Elastic Block Store volume for temporary objects, while Amazon RDS Optimized Reads place temporary objects on the database instance's NVMe-based instance storage. This approach helps to speed up complex query processing by up to 2X.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-04T18:17:20.357270"}}
{"question": "What versions of MySQL and MariaDB support Amazon RDS Optimized Reads?", "answer": "Amazon RDS Optimized Reads are available for RDS for MySQL on MySQL versions 8.0.28 and higher, and on RDS for MariaDB on MariaDB versions 10.4.25, 10.5.16, 10.6.7 and higher.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-04T18:17:27.306146"}}
{"question": "When should customers consider using Amazon RDS Optimized Reads?", "answer": "Customers should use Amazon RDS Optimized Reads when they have workloads that require complex queries, general purpose analytics, intricate groups, sorts, hash aggregations, high-load joins, and Common Table Expressions (CTEs). These use cases often result in the creation of temporary tables, which allows Optimized Reads to speed up the workloads query processing.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-04T18:17:27.306525"}}
{"question": "What are the differences between instance types that support Amazon RDS Optimized Reads and the zero-ETL integration?", "answer": "The instance types that support Amazon RDS Optimized Reads include db.r5d, db.m5d, db.r6gd, db.m6gd, X2idn, and X2iedn. These instances are designed to enhance query processing for complex workloads. On the other hand, the zero-ETL integration is focused on enabling analytics and machine learning on transactional data, allowing for rapid replication to Amazon Redshift or Amazon SageMaker without the need for complex data pipelines.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-04T18:17:27.306744"}}
{"question": "What is the primary benefit of using Amazon RDS zero-ETL integration with Amazon Redshift?", "answer": "The primary benefit of using Amazon RDS zero-ETL integration with Amazon Redshift is that it removes the need to build and manage complex data pipelines, allowing access to analytics and machine learning capabilities on transactional data once it is in the lakehouse in Amazon SageMaker or Amazon Redshift.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-04T18:17:31.848399"}}
{"question": "How does using a Read Replica for zero-ETL integration affect resource consumption?", "answer": "Using an Amazon RDS Read Replica as the source Amazon RDS instance for a zero-ETL integration helps to reduce resource consumption on the primary instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-04T18:17:31.848736"}}
{"question": "What resources and costs should be considered for Amazon Redshift and SageMaker when using zero-ETL integration?", "answer": "For Amazon Redshift, you must consider storage and compute costs for the replicated data. For SageMaker, you need to account for AWS Glue storage for storing replicated data and SageMaker compute on the target.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-04T18:17:31.848963"}}
{"question": "What types of transactions are replicated from Amazon RDS to Amazon Redshift or the lakehouse in SageMaker?", "answer": "Only committed transactions in Amazon RDS are replicated to Amazon Redshift or the lakehouse in SageMaker. Uncommitted or rolled-back transactions are not applied.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-04T18:17:38.800353"}}
{"question": "How does the atomicity of transactions ensure data consistency in Amazon RDS zero-ETL integrations?", "answer": "The atomicity of transactions in Amazon RDS zero-ETL integrations ensures data consistency by using a two-phase commit process. This process atomically applies each transaction to Amazon Redshift or the lakehouse in SageMaker, meaning that either all data changes in the transaction are applied, or if an error occurs, none are applied. This mechanism prevents partial transactions or inconsistent data states between the source and target databases.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-04T18:17:38.800628"}}
{"question": "How do schema changes in Amazon RDS affect the corresponding tables in Amazon Redshift?", "answer": "Schema changes such as DDL statements like CREATE TABLE, ALTER TABLE, and DROP TABLE in Amazon RDS are automatically replicated to Amazon Redshift. The integration performs the necessary checks and adjustments in Amazon Redshift tables for these replicated schema changes, ensuring that, for example, adding a column in RDS for MySQL will also add the column in Amazon Redshift.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-04T18:17:38.800827"}}
{"question": "What is Amazon Redshift primarily used for?", "answer": "Amazon Redshift is primarily used to run SQL analytics in the cloud, processing exabytes of data for business insights.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-04T18:17:43.459880"}}
{"question": "How does Amazon Redshift facilitate near real-time analytics?", "answer": "Amazon Redshift facilitates near real-time analytics by employing Zero-ETL approaches and helping users access data in place, allowing for seamless integration with AWS database, analytics, and machine learning services.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-04T18:17:43.460247"}}
{"question": "How does Amazon Redshift Serverless differ from traditional Amazon Redshift in terms of administration?", "answer": "Amazon Redshift Serverless differs from traditional Amazon Redshift by providing a zero-administration environment, which allows engineers, developers, data scientists, and analysts to get started easily and scale analytics quickly without the need for managing infrastructure.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-04T18:17:43.460668"}}
{"question": "What are some of the key features of Amazon Redshift that make it a popular choice among customers?", "answer": "Amazon Redshift is a powerful analytics system that integrates well with database and machine learning services, is streamlined to use, and can serve as a central service for all analytics needs. It offers leading price performance for various analytics workloads and supports real-time and predictive analytics across different data sources. Additionally, it provides performance innovations at no extra cost and ensures industry-leading security with features like identity management, multi-factor authentication, and role-based access control.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T18:17:48.596277"}}
{"question": "How does Amazon Redshift Serverless enhance the performance for unpredictable workloads?", "answer": "Amazon Redshift Serverless enhances performance for unpredictable workloads by automatically provisioning and scaling data warehouse capacity. This ensures that high performance is delivered even for demanding and varying workloads without requiring manual intervention.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T18:17:48.596786"}}
{"question": "How does Amazon Redshift's performance scale with workload compared to traditional data warehouses?", "answer": "Amazon Redshift delivers performance that scales linearly with the workload, which means that as the workload increases, performance increases proportionally. This is different from traditional data warehouses that may not provide such efficient scaling, potentially leading to higher costs and reduced performance under heavy loads.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-04T18:17:48.597007"}}
{"question": "What tasks does Amazon Redshift manage on behalf of users?", "answer": "Amazon Redshift manages tasks such as hardware provisioning, software patching, setup, configuration, monitoring nodes and drives to recover from failures, and backups, allowing users to focus on building their applications.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:17:53.096720"}}
{"question": "How does Amazon Redshift Serverless differ from the provisioned option?", "answer": "Amazon Redshift Serverless automatically provisions and scales the data warehouse capacity for demanding and unpredictable workloads, whereas the provisioned option is more suitable for predictable workloads.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:17:53.097133"}}
{"question": "In what ways does Amazon Redshift integrate with other AWS services?", "answer": "Amazon Redshift integrates with various AWS services by enabling analytics on data stored in Amazon S3 through Redshift Spectrum, offering features like Amazon Aurora Zero-ETL, federated querying from operational databases like Amazon RDS, and integrating with AWS Data Exchange and Amazon SageMaker for data ingestion and machine learning model training.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-04T18:17:53.097420"}}
{"question": "What are some of the pre-loaded sample datasets available in Amazon Redshift Serverless?", "answer": "The pre-loaded sample datasets available in Amazon Redshift Serverless include benchmark datasets TPC-H, TPC-DS, and other sample queries to kick start analytics immediately.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-04T18:17:57.695409"}}
{"question": "How does Amazon Redshift's price performance compare to other cloud data warehouses for small datasets?", "answer": "Amazon Redshift provides the best price performance out of the box, even for a comparatively small 3 TB dataset, delivering up to 5x better price performance than other cloud data warehouses.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-04T18:17:57.695938"}}
{"question": "What is the difference between Amazon Redshift managed storage and the storage options available with other instance types?", "answer": "Amazon Redshift managed storage is available with serverless and RA3 node types, allowing users to scale and pay for compute and storage independently. In contrast, other instance types like Dense Storage or Dense Compute do not automatically use Redshift-managed storage unless upgraded to RA3 instances or Amazon Redshift Serverless.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-04T18:17:57.696175"}}
{"question": "What is Amazon Redshift Spectrum used for?", "answer": "Amazon Redshift Spectrum is a feature of Amazon Redshift that allows you to run queries against your data lake in Amazon S3 without the need for data loading or ETL.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-04T18:18:02.022294"}}
{"question": "Why might a user choose RA3 node types for their Amazon Redshift cluster?", "answer": "A user might choose RA3 node types if they need the flexibility to scale and pay for compute separate from storage, if they query a fraction of their total data, if their data volume is growing rapidly, or if they want to size the cluster based solely on their performance needs.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-04T18:18:02.022684"}}
{"question": "How do RA3 instances with managed storage differ from previous instances regarding data management?", "answer": "RA3 instances with managed storage allow users to choose the number of nodes based on their performance requirements and pay only for the managed storage they use. This contrasts with previous instances where users might have to scale both compute and storage together, which could increase storage costs unnecessarily.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-04T18:18:02.023084"}}
{"question": "When was native spatial data processing support launched in Amazon Redshift?", "answer": "Native spatial data processing support in Amazon Redshift was launched in November 2019.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-04T18:18:05.193461"}}
{"question": "What are the benefits of integrating spatial and business data in Amazon Redshift?", "answer": "Integrating spatial and business data in Amazon Redshift provides location-based analytics for rich insights into your data, which aids in decision making.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-04T18:18:05.193738"}}
{"question": "How does the support for GEOMETRY and GEOGRAPHY data types in Amazon Redshift spatial differ?", "answer": "Amazon Redshift spatial supports both GEOMETRY and GEOGRAPHY data types, allowing users to work with spatial data in different contexts, but the context does not specify any further differences in their use or functionality.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-04T18:18:05.193895"}}
{"question": "What are the primary use cases for Amazon Redshift Serverless?", "answer": "Amazon Redshift Serverless is primarily used for complex BI and analytics workloads that require the best price performance at any scale. It is a great choice for customers needing a data warehouse that supports high performance analytics through deep integrations and easy data ingestion or access.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:18:11.075906"}}
{"question": "How does Amazon Athena differ from Amazon Redshift Serverless in terms of data handling?", "answer": "Amazon Athena is well suited for interactive analytics and data exploration of data in your data lake or any data source, allowing users to query data without the need for ingesting or processing it. In contrast, Amazon Redshift Serverless is designed for complex BI and analytics workloads, where data is ingested into the warehouse for high performance analytics.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:18:11.076195"}}
{"question": "How do the integration capabilities of Amazon Redshift compare to those of Amazon Athena?", "answer": "Amazon Redshift offers deep integrations to access data in place or easily ingest data from various sources like Amazon S3, operational databases such as Aurora and Amazon RDS, and third-party data warehouses via AWS Data Exchange. On the other hand, Amazon Athena provides an extensible connector framework with over 30 out-of-box connectors for applications and other analytics systems, allowing users to perform analytics directly on data without processing it first.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:18:11.076350"}}
{"question": "Do I need to migrate my data to use SageMaker for SQL analytics?", "answer": "No, you don't need to migrate your data in order to use SageMaker for SQL analytics. You can directly discover and query data from multiple sources, including Amazon S3, Amazon Redshift, and other federated data sources.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-04T18:18:15.950267"}}
{"question": "What are the two ways SageMaker allows you to bring data into the platform for SQL analytics?", "answer": "SageMaker offers two ways to bring your data into the platform for SQL analytics: you can run queries directly on data stored in Amazon S3 using the data lake, or you can upload data into your data warehouse by running COPY commands. Additionally, you can upload local data files directly from your computer.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-04T18:18:15.950556"}}
{"question": "How does the data loading process in SageMaker compare to traditional methods?", "answer": "The data loading process in SageMaker is designed to remove technical barriers compared to traditional methods. It allows users to focus on discovering insights without wrestling with complex data-loading processes, enabling direct querying from sources like Amazon S3 and using zero-ETL for operational data warehouses.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-04T18:18:15.950742"}}
{"question": "What is the primary purpose of SageMaker Projects?", "answer": "The primary purpose of SageMaker Projects is to provide a collaborative digital workspace that helps teams organize and manage their data analytics work, similar to a shared folder where SQL queries, data models, code, and other resources can be stored securely.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-04T18:18:20.757145"}}
{"question": "How does SageMaker ensure collaboration among team members in a Project?", "answer": "SageMaker ensures collaboration among team members in a Project by allowing the establishment of a centralized environment where team members can be invited, given specific access permissions, and seamlessly work together. This includes distributing query books, granting access to data sources, and providing shared computing resources.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-04T18:18:20.757509"}}
{"question": "How do the SLAs for SQL Analytics in SageMaker relate to Amazon Redshift and Athena?", "answer": "The SLAs for SQL Analytics in SageMaker are directly tied to the SLAs of the underlying SQL engines, which are Amazon Redshift and Athena. This means that customers can find detailed service commitment information on the respective service level agreement pages for both Amazon Redshift and Athena.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-04T18:18:20.757723"}}
{"question": "What are some of the preloaded sample datasets available in Amazon Redshift Serverless?", "answer": "The preloaded sample datasets available in Amazon Redshift Serverless include weather data, census data, and benchmark datasets.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-04T18:18:25.256529"}}
{"question": "How does Amazon Redshift Serverless benefit users without data warehouse management experience?", "answer": "Amazon Redshift Serverless allows users without data warehouse management experience to avoid the complexities of setting up, configuring, managing clusters, or tuning the warehouse, enabling them to focus on deriving meaningful insights from their data and delivering on core business outcomes.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-04T18:18:25.256853"}}
{"question": "How does the experience of using Amazon Redshift Serverless compare to provisioning Redshift clusters regarding data warehouse management?", "answer": "Using Amazon Redshift Serverless eliminates the need for users to manage or configure clusters, whereas provisioning Redshift clusters provides users with fine-grained control over their data warehouse. In Redshift Serverless, users can focus on analytics without worrying about management tasks, while provisioning clusters allows for more detailed control.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-04T18:18:25.257092"}}
{"question": "What data sources can you load data into Amazon Redshift from?", "answer": "You can load data into Amazon Redshift from a range of data sources including Amazon S3, Amazon RDS, Amazon DynamoDB, Amazon EMR, AWS Glue, AWS Data Pipeline, and any SSH-enabled host on Amazon EC2 or on-premises.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-04T18:18:30.533849"}}
{"question": "How does the auto-copy feature in Amazon Redshift enhance the data loading process?", "answer": "The auto-copy feature in Amazon Redshift enhances the data loading process by automating copy statements, monitoring specified Amazon S3 paths for new files, re-using copy configurations to reduce the need for creating and running new copy statements, and keeping track of loaded files to avoid data duplication.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-04T18:18:30.534593"}}
{"question": "How does loading data using SQL insert statements compare to loading data from S3 or DynamoDB in Amazon Redshift?", "answer": "Loading data using SQL insert statements is slower than loading data from S3 or DynamoDB because while S3 and DynamoDB methods load data in parallel to each compute node, SQL insert statements load through the single leader node.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-04T18:18:30.534830"}}
{"question": "What services can customers use to run Apache Spark jobs that interact with Amazon Redshift?", "answer": "Customers can use Amazon EMR and AWS Glue to run Apache Spark jobs that access and load data into Amazon Redshift as part of the data ingestion and transformation pipelines.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-04T18:18:36.735853"}}
{"question": "What are the benefits of integrating Apache Spark with Amazon Redshift?", "answer": "The benefits of this integration include ease of use for getting started and running Apache Spark applications on data in Amazon Redshift without having to worry about manual steps involved in setting up and maintaining uncertified versions of Spark, convenience of using Apache Spark from various AWS services such as Amazon EMR, AWS Glue, Amazon Athena, and Amazon SageMaker with minimal configuration, and improved performance while running Apache Spark applications on Amazon Redshift.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-04T18:18:36.736233"}}
{"question": "How does the use of Amazon SageMaker with Apache Spark and Amazon Redshift differ from using Amazon Athena with Apache Spark?", "answer": "Amazon SageMaker is used for performing machine learning with Apache Spark and requires access to data stored in Amazon Redshift for feature engineering and transformation, while Amazon Athena customers use Apache Spark to perform interactive analysis on data in Amazon Redshift. Both utilize Apache Spark but serve different purposes: machine learning in SageMaker versus interactive analysis in Athena.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-04T18:18:36.736509"}}
{"question": "What does Amazon Aurora Zero-ETL to Amazon Redshift enable customers to do with their transactional data?", "answer": "Amazon Aurora Zero-ETL to Amazon Redshift enables customers to run near real-time analytics and machine learning on petabytes of transactional data by offering a fully managed solution that makes transactional data from Amazon Aurora available in Amazon Redshift within seconds of being written.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-04T18:18:42.366119"}}
{"question": "How does Amazon Aurora Zero-ETL to Amazon Redshift improve the data management process for customers?", "answer": "Amazon Aurora Zero-ETL to Amazon Redshift improves the data management process by reducing the need for customers to build and manage complex data pipelines, allowing them to focus on improving their applications instead.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-04T18:18:42.366505"}}
{"question": "What are the differences between how streaming data and traditional database tables operate in Amazon Redshift?", "answer": "Streaming data captures the evolution of a time-varying relation when queried, while traditional database tables capture a point-in-time snapshot of this relation. Additionally, Amazon Redshift customers are typically accustomed to operating on regular tables and perform downstream processing using a traditional batch model, such as ELT, whereas streaming data provides a more dynamic view of the data.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-04T18:18:42.366668"}}
{"question": "What are some key use cases for sharing data in AWS?", "answer": "Key use cases include a central ETL cluster sharing data with many BI/analytics clusters for read workload isolation, a data provider sharing data to external consumers, sharing common datasets across different business groups for broad analytics and data science, decentralizing a data warehouse to simplify management, sharing data between development, test, and production environments, and accessing Redshift data from other AWS analytic services.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-04T18:18:47.330073"}}
{"question": "How do cross-database queries enhance data organization in AWS Redshift?", "answer": "Cross-database queries allow users to seamlessly query and join data from any Redshift database they have access to, regardless of the connected database. This flexibility enables users to organize data into separate databases, which supports multi-tenant configurations.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-04T18:18:47.330418"}}
{"question": "How does AWS Data Exchange differ from traditional methods of data sharing?", "answer": "AWS Data Exchange makes it more efficient for AWS customers to securely exchange and use third-party data by providing a centralized platform, whereas traditional methods often involve a mix of shipped physical media, FTP credentials, and bespoke API calls, which can be inconsistent and cumbersome. Additionally, organizations may find it hard and expensive to build and maintain data delivery systems, which AWS Data Exchange alleviates.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-04T18:18:47.330630"}}
{"question": "What feature does Amazon Redshift Serverless use to support unlimited concurrent users and queries?", "answer": "Amazon Redshift Serverless uses the Concurrency Scaling feature to support unlimited concurrent users and concurrent queries, ensuring consistently fast query performance.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-04T18:18:51.792958"}}
{"question": "What is the difference between Concurrency Scaling and Elastic Resize in terms of cluster availability?", "answer": "When using the Concurrency Scaling feature, the cluster remains fully available for read and write operations during the scaling process. In contrast, with Elastic Resize, the cluster becomes unavailable for four to eight minutes during the resize period.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-04T18:18:51.793239"}}
{"question": "How does Amazon Redshift Spectrum facilitate the use of multiple clusters for different use cases?", "answer": "Amazon Redshift Spectrum allows you to run multiple Redshift clusters that can access the same data stored in Amazon S3. This enables different use cases, such as having one cluster for standard reporting and another for data science queries, allowing teams like marketing and operations to use their own separate clusters.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-04T18:18:51.793546"}}
{"question": "What security features does Amazon Redshift provide out-of-the-box?", "answer": "Amazon Redshift provides built-in identity management and federation for single sign-on (SSO), multi-factor authentication, column-level access control, row-level security, role-based access control, and encryption of data in transit and at rest. All these security features are offered at no additional cost to meet demanding security, privacy, and compliance requirements.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-04T18:18:56.261793"}}
{"question": "How does Amazon Redshift support role-based access control?", "answer": "Amazon Redshift supports role-based access control by allowing you to assign one or more roles to a user, along with system and object permissions based on those roles. You can utilize out-of-the-box system roles such as root user, dba, operator, and security admins, or create custom roles as needed.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-04T18:18:56.262111"}}
{"question": "How does Amazon Redshift's Dynamic Data Masking compare to traditional data access methods?", "answer": "Amazon Redshift's Dynamic Data Masking allows for configurable, consistent, format-preserving, and irreversible masked data values, enabling granular access control tailored to different user groups. In contrast, traditional data access methods may not offer such fine-tuned, dynamic control over sensitive data exposure to users, often relying on more static permissions.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-04T18:18:56.262280"}}
{"question": "What identity providers can be configured for single sign-on with Amazon Redshift?", "answer": "Customers can configure Amazon Redshift to provide single sign-on using corporate identity providers such as Microsoft Azure Active Directory, Active Directory Federation Services, Okta, Ping Federate, or other SAML compliant identity providers.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-04T18:19:02.028057"}}
{"question": "How does Amazon Redshift handle a failed node in a data warehouse cluster?", "answer": "Amazon Redshift automatically detects and replaces a failed node in your data warehouse cluster. For Dense Compute (DC) and Dense Storage (DS2) clusters, data is stored on the compute nodes, and when a node is replaced, the data is refreshed from the mirror copy on the other node. In contrast, RA3 clusters and Redshift serverless store data in Amazon S3, with the local drive used as a data cache, and are not impacted the same way.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-04T18:19:02.028340"}}
{"question": "What is the difference between how single node clusters and multi-node clusters handle data replication during a drive failure?", "answer": "Single node clusters do not support data replication, so in the event of a drive failure, the cluster must be restored from a snapshot on S3. In contrast, multi-node clusters can replace failed nodes and refresh data from a mirror copy on another node, ensuring higher data durability and availability.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-04T18:19:02.028890"}}
{"question": "What is the primary benefit of using a multi-AZ deployment for Amazon Redshift?", "answer": "The primary benefit of using a multi-AZ deployment for Amazon Redshift is that it improves availability by running the data warehouse in multiple AWS Availability Zones simultaneously, allowing it to continue operating during unforeseen failure scenarios. This setup is managed as a single data warehouse with one endpoint, ensuring no application changes are required to maintain business continuity.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:19:09.034928"}}
{"question": "How does the Recovery Point Objective (RPO) for Redshift Multi-AZ deployments compare to standard RPO measures?", "answer": "Redshift Multi-AZ deployments support an RPO of 0, meaning that data is guaranteed to be current and up to date in the event of a failure. This is a significant advantage compared to standard RPO measures, which may allow for some data loss between recovery points, whereas Multi-AZ deployments ensure there is no acceptable loss of data.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:19:09.035269"}}
{"question": "How does Redshift Relocation differ from Redshift Multi-AZ in terms of recovery times and data loss?", "answer": "Redshift Relocation allows a data warehouse to be restarted in another AZ during a large-scale outage without data loss, but it is a best-effort approach subject to resource availability and can result in recovery times between 10 and 60 minutes. In contrast, Redshift Multi-AZ deployments offer a much faster Recovery Time Objective (RTO) measured in tens of seconds and guarantee continued operation without being subject to capacity limitations or other issues related to starting a new cluster.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:19:09.035439"}}
{"question": "What drivers can be used to access Amazon Redshift?", "answer": "Amazon Redshift can be accessed using standard JDBC and ODBC drivers. You can also download Amazon Redshift custom JDBC and ODBC drivers from the Connect Client tab of the Redshift Console.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-04T18:19:12.880642"}}
{"question": "What is the significance of the CREATE EXTERNAL SCHEMA command in Amazon Redshift Spectrum?", "answer": "The CREATE EXTERNAL SCHEMA command in Amazon Redshift Spectrum is significant because it allows users to register external tables, which can then be accessed using the same query syntax and capabilities as local tables in the Redshift cluster. External tables are referenced using the schema name defined in this command.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-04T18:19:12.880920"}}
{"question": "How does querying external tables in Amazon Redshift Spectrum compare to querying local tables?", "answer": "Querying external tables in Amazon Redshift Spectrum is similar to querying local tables in that you use the same query syntax and have the same query capabilities. Additionally, external tables can be referenced using the schema name, just like local tables, allowing for clear differentiation between tables.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-04T18:19:12.881305"}}
{"question": "What machine learning models can users create with Amazon Redshift ML?", "answer": "Users can create, train, and deploy both unsupervised learning models like K-Means and supervised learning models including Autopilot, XGBoost, and MLP algorithms using Amazon Redshift ML.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-04T18:19:16.635754"}}
{"question": "How does the Data API simplify access to Amazon Redshift for applications?", "answer": "The Data API simplifies access to Amazon Redshift by eliminating the need to configure drivers and manage database connections. Users can run SQL commands by calling a secured API endpoint, while the Data API manages database connections and buffers data for them.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-04T18:19:16.636047"}}
{"question": "What are the differences in authentication methods supported by the Data API?", "answer": "The Data API supports authentication through IAM credentials and by using a secret key from AWS Secrets Manager. Additionally, it allows for federating AWS IAM credentials with identity providers like Okta or Azure Active Directory, as well as using database credentials stored in Secrets Manager.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-04T18:19:16.636202"}}
{"question": "What is Zero-ETL and what does it aim to achieve?", "answer": "Zero-ETL is a set of fully managed integrations by AWS that removes or minimizes the need to build extract, transform, and load (ETL) data pipelines. It aims to make data available in the lakehouse in SageMaker and Amazon Redshift from multiple operational sources, transactional sources, and enterprise applications.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-04T18:19:21.725951"}}
{"question": "How does Zero-ETL enhance agility in data management?", "answer": "Zero-ETL enhances agility by simplifying data architecture and reducing data-engineering efforts. It allows for the inclusion of new data sources without the need to reprocess large amounts of data, which supports data-driven decision-making and rapid innovation.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-04T18:19:21.726290"}}
{"question": "How does Zero-ETL compare to traditional ETL processes in terms of time to insights?", "answer": "Zero-ETL provides near real-time data access, which allows for fresher data availability for analytics, AI/ML, and reporting. In contrast, traditional ETL processes often involve periodic batch updates that result in delayed data availability. This leads to faster insights with Zero-ETL compared to traditional ETL methods.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-04T18:19:21.726505"}}
{"question": "What are the four zero-ETL integrations announced at re:Invent 2024?", "answer": "The four zero-ETL integrations announced at re:Invent 2024 are: Amazon SageMaker Lakehouse and Amazon Redshift support for zero-ETL integrations from applications, Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse, Amazon OpenSearch Service zero-ETL integration with Amazon CloudWatch Logs, and Amazon OpenSearch Service zero-ETL integration with Amazon Security Lake.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-04T18:19:27.437550"}}
{"question": "How does the zero-ETL integration handle schema changes between Aurora and Amazon Redshift?", "answer": "The zero-ETL integration automatically replicates DDL statements, such as CREATE TABLE, ALTER TABLE, and DROP TABLE, from Aurora to Amazon Redshift. It makes necessary checks and adjustments in Amazon Redshift tables for any replicated schema changes, ensuring that schema consistency is maintained even as DML changes occur in parallel to DDL changes.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-04T18:19:27.437985"}}
{"question": "What is the relationship between Amazon DynamoDB and Amazon OpenSearch Service in the context of zero-ETL integrations?", "answer": "Amazon DynamoDB has a zero-ETL integration with both Amazon SageMaker Lakehouse and Amazon OpenSearch Service. This means that data can flow seamlessly between DynamoDB and these services without the need for traditional ETL processes, enhancing data accessibility and usability.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-04T18:19:27.438316"}}
{"question": "What are the two ways you can access destination databases in Amazon Redshift?", "answer": "You can access destination databases in Amazon Redshift either by using fully qualified object names with three-part notation (destination-database-name.schema-name.table-name) or by creating an external schema referencing the destination database and schema pair and using two-part notation (external-schema-name.table-name).", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-04T18:19:33.119817"}}
{"question": "How does Amazon Redshift ensure that the latest copy of data is available in RA3 clusters and Serverless compared to DS2 and DC2 clusters?", "answer": "Amazon Redshift RA3 clusters and Amazon Redshift Serverless utilize Redshift Managed Storage, which always has the latest copy of the data available. In contrast, DS2 and DC2 clusters mirror the data on the cluster to ensure that the latest copy is available in the event of a failure.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-04T18:19:33.120158"}}
{"question": "What limitations apply to free backup storage on DS2 or DC2 clusters in Amazon Redshift, and how does this differ from RA3 clusters?", "answer": "On DS2 or DC2 clusters, free backup storage is limited to the total size of storage on the nodes in the data warehouse cluster and only applies to active data warehouse clusters. For example, if a data warehouse has total storage of 8 TB, the free backup storage provided will be at most 8 TB at no additional charge. In contrast, RA3 clusters and Amazon Redshift Serverless do not have this limitation mentioned, as they use Redshift Managed Storage which always has the latest copy of the data available.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-04T18:19:33.120366"}}
{"question": "How can I manage the retention period of automated backups for my data warehouse cluster?", "answer": "You can manage the retention period of automated backups for your data warehouse cluster by using the AWS Management Console or the ModifyCluster API to modify the RetentionPeriod parameter.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:19:36.386889"}}
{"question": "What are the implications of setting the retention period for automated backups to 0?", "answer": "Setting the retention period for automated backups to 0 turns off automated backups altogether, which is not recommended.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:19:36.387167"}}
{"question": "How does AWS Backup facilitate backup management across multiple accounts within an organization?", "answer": "AWS Backup facilitates backup management across multiple accounts within an organization through its integration with AWS Organizations, allowing you to centrally create and manage immutable backups and standardize data protection across all your accounts.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:19:36.387321"}}
{"question": "What metrics are available for monitoring Amazon Redshift data warehouse clusters?", "answer": "Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge through the AWS Management Console or Amazon CloudWatch APIs.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-04T18:19:40.543367"}}
{"question": "How can users diagnose performance issues in Amazon Redshift?", "answer": "Users can diagnose performance issues in Amazon Redshift by viewing query plans and execution statistics, which provide information on which users and queries are consuming the most system resources.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-04T18:19:40.543727"}}
{"question": "What happens to the Amazon Redshift cluster during scheduled maintenance windows compared to normal operations?", "answer": "During scheduled maintenance windows, your Amazon Redshift cluster is not available for normal operations, whereas it is operational and available for queries and data processing outside of these maintenance windows.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-04T18:19:40.543922"}}
{"question": "What does Amazon Rekognition Image detect?", "answer": "Amazon Rekognition Image detects objects, scenes, activities, landmarks, faces, dominant colors, and image quality. It also extracts text, recognizes celebrities, and identifies inappropriate content in images.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-04T18:19:45.476988"}}
{"question": "How does Rekognition Video enhance video analysis compared to Rekognition Image?", "answer": "Rekognition Video enhances video analysis by detecting activities and understanding the movement of people within the frame, which includes tracking persons through the video even when their faces are not visible. It is designed for both stored videos in Amazon S3 and live video streams, enabling motion-based context extraction, while Rekognition Image focuses primarily on still images.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-04T18:19:45.477999"}}
{"question": "What are the primary differences between Rekognition Image and Rekognition Video?", "answer": "The primary differences between Rekognition Image and Rekognition Video are in their focus and functionality. Rekognition Image is an image recognition service that analyzes still images, detecting objects, scenes, and faces, while Rekognition Video is a video recognition service that analyzes motion in videos, detecting activities and tracking people. Additionally, Rekognition Video can process live video streams, which is not a feature of Rekognition Image.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-04T18:19:45.478293"}}
{"question": "What is deep learning and how does it relate to machine learning?", "answer": "Deep learning is a sub-field of Machine Learning and a significant branch of Artificial Intelligence. It aims to infer high-level abstractions from raw data by using a deep graph with multiple processing layers composed of multiple linear and non-linear transformations.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T18:19:50.774608"}}
{"question": "Why is deep learning considered beneficial for tasks like computer vision and speech recognition?", "answer": "Deep learning replaces handcrafted features with ones learned from very large amounts of annotated data. It is capable of producing state-of-the-art results on various tasks by iteratively estimating hundreds of thousands of parameters in a deep graph using efficient algorithms.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T18:19:50.774946"}}
{"question": "How does Amazon Rekognition differ from traditional deep learning approaches in terms of user involvement?", "answer": "Amazon Rekognition is fully managed and comes pre-trained for image and video recognition tasks, which means users do not have to build, maintain, or upgrade deep learning pipelines. In contrast, traditional deep learning approaches often require users to tune systems, train models with large amounts of labeled data, and invest significant time and resources into creating a deep learning pipeline.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-04T18:19:50.775154"}}
{"question": "What image formats does Amazon Rekognition Image currently support?", "answer": "Amazon Rekognition Image currently supports the JPEG and PNG image formats.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-04T18:19:54.252895"}}
{"question": "Why is it important to use the H.264 codec with Amazon Rekognition Video?", "answer": "It is important to use the H.264 codec with Amazon Rekognition Video because the supported video file formats, which are MPEG-4 and MOV, must be encoded using H.264 for the video to function correctly with the service.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-04T18:19:54.253260"}}
{"question": "How do the maximum file sizes for images and videos differ in Amazon Rekognition?", "answer": "In Amazon Rekognition, the maximum file size for images is 15MB when passed as an S3 object and 5MB when submitted as an image byte array. In contrast, Amazon Rekognition Video supports file sizes up to 10 GB when passed through as an S3 file.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-04T18:19:54.253435"}}
{"question": "What is the minimum size in pixels for the smallest object or face in a 1600x900 image to ensure proper recognition?", "answer": "The smallest face or object in a 1600x900 image should be at least 45 pixels in either dimension.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-04T18:19:58.244510"}}
{"question": "How does Amazon A2I enhance the accuracy of predictions made by Amazon Rekognition?", "answer": "Amazon A2I enhances the accuracy of predictions by allowing users to route low confidence predictions from Amazon Rekognition to human reviewers. Users can specify conditions for routing, such as a confidence threshold or a random sampling percentage, which helps in monitoring prediction accuracy and ensuring the quality of results.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-04T18:19:58.244848"}}
{"question": "How does the minimum size requirement for face recognition vary with video resolution?", "answer": "The minimum size requirement for face recognition varies with video resolution; it is approximately 1/7 of the screen's smaller dimension at QVGA resolution and 1/30 at HD 1080p resolution. For VGA resolution, lower performance is expected for faces smaller than 1/10 of the screen's smaller dimension.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-04T18:19:58.245044"}}
{"question": "What does a confidence score indicate in Amazon Rekognition?", "answer": "A confidence score is a number between 0 and 100 that indicates the probability that a given prediction is correct. For example, a confidence score of 99 for the label 'Water' suggests it is very likely that the image contains water, while a score of 35 for 'Palm Tree' suggests it is less likely that the image contains a palm tree.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T18:20:03.879469"}}
{"question": "Why might an application choose to set a minimum confidence threshold higher than the default value?", "answer": "Applications that are very sensitive to detection errors, such as false positives, should discard results associated with confidence scores below a certain threshold. By setting minimum confidence values higher than the default value, these applications can ensure more accurate results and improve user experience.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T18:20:03.879771"}}
{"question": "How does the object and scene detection process differ from simply detecting objects in an image?", "answer": "The object and scene detection process involves analyzing an image or video to assign labels based on its visual content, including thousands of objects, scenes, and concepts. In contrast, simply detecting objects might not encompass the broader context or scene associated with those objects, which is addressed in the object and scene detection.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-04T18:20:03.880270"}}
{"question": "What information does Amazon Rekognition return for each label found?", "answer": "Amazon Rekognition returns the parent, alias, and category for each label found, if they exist. Parents are returned in the 'parents' field, aliases in the 'aliases' field, and categories in the 'categories' field.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-04T18:20:08.743578"}}
{"question": "How does Amazon Rekognition define the hierarchy of parent labels?", "answer": "Amazon Rekognition defines the hierarchy of parent labels by returning them in the 'parents' field in hierarchical order. The first parent label is the immediate parent, while the subsequent labels are parents of parents.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-04T18:20:08.743914"}}
{"question": "What is the difference between an alias and a parent label in Amazon Rekognition?", "answer": "An alias in Amazon Rekognition is a label with the same meaning as the primary label, while a parent label indicates a hierarchical relationship where the parent label is broader than the primary label. For example, 'Cell Phone' is an alias of 'Mobile Phone', and 'Vehicle' is a parent of 'Car'.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-04T18:20:08.744119"}}
{"question": "What categories of labels does Rekognition support?", "answer": "Rekognition supports labels belonging to several common categories including People and Events, Food and Drink, Nature and Outdoors, Animals and Pets, Home and Garden, Sports and Leisure, Plants and Flowers, Art and Entertainment, Transportation and Vehicles, Electronics, and Landmarks.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T18:20:13.396727"}}
{"question": "How does Rekognition Video identify complex activities in videos?", "answer": "Rekognition Video identifies complex activities by relying on motion and time context in the video, which helps in accurately identifying activities such as 'blowing a candle' or 'extinguishing fire'.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T18:20:13.396944"}}
{"question": "In what way does the label detection feature of Rekognition Video differ from the general label support in Rekognition?", "answer": "The label detection feature of Rekognition Video focuses on automatically identifying objects and activities in videos and provides timestamps and confidence scores for each label, while the general label support in Rekognition encompasses a wide range of static labels across different categories, without specific mention of video context.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-04T18:20:13.397129"}}
{"question": "What types of scores does Image Properties measure for image quality?", "answer": "Image Properties measures image quality through three scores: brightness, sharpness, and contrast scores.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-04T18:20:17.497723"}}
{"question": "How does Image Properties determine the dominant colors in an image?", "answer": "Image Properties determines the dominant colors in an image by first identifying the dominant colors by pixel percentage, and then mapping these colors to the 140 CSS color palette, RGB, hex code, and 12 simplified colors.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-04T18:20:17.498035"}}
{"question": "How do the default number of dominant colors returned by Image Properties compare to the maximum it can return?", "answer": "By default, Image Properties returns ten (10) dominant colors, while the maximum number of dominant colors the API can return is 12.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-04T18:20:17.498207"}}
{"question": "What is Custom Labels designed for?", "answer": "Custom Labels is meant for finding objects and scenes in images. It is not designed for analyzing faces or customized text detection, for which other Rekognition APIs should be used.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-04T18:20:22.034151"}}
{"question": "How does the number of images required for training a custom model vary?", "answer": "The number of images required to train a custom model depends on the variability of the custom labels you want the model to predict and the quality of the training data. For instance, a distinct logo can be detected with just 1-2 training images, while a more subtle logo may need tens to hundreds of training examples depending on variations like scale, viewpoint, and deformations.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-04T18:20:22.034465"}}
{"question": "What factors influence the number of inference compute resources needed for a custom model?", "answer": "The number of parallel inference compute resources needed depends on the number of images you need to process at a given time. The throughput of a single resource is influenced by factors including the size of the images, the complexity of the images (such as the number of detected objects), and the complexity of the custom model.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-04T18:20:22.034641"}}
{"question": "What should you do if you expect to process images periodically?", "answer": "If you expect to process images periodically, you should start provisioning your custom model at a scheduled time, process all your images, and then stop provisioning. If you dont stop provisioning, you will be charged even if no images are processed.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-04T18:20:26.351860"}}
{"question": "Why is it important to stop provisioning after processing images?", "answer": "It is important to stop provisioning after processing images because you will be charged for the compute resources even if no images are processed if you do not stop provisioning.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-04T18:20:26.352172"}}
{"question": "What is the difference in charges if your training fails versus if you dont stop provisioning?", "answer": "If your training fails, you will not be charged for the compute resources. In contrast, if you dont stop provisioning after processing images, you will incur charges even if no images are processed.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-04T18:20:26.352526"}}
{"question": "What types of inappropriate, offensive, and unwanted content does Amazon Rekognition detect?", "answer": "Amazon Rekognitions Content Moderation API detects explicit or suggestive adult content, violent content, weapons, visually disturbing content, drugs, alcohol, tobacco, hate symbols, gambling, and rude gestures in images and videos.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T18:20:32.107521"}}
{"question": "How does Amazon Rekognition provide developers with control over content moderation?", "answer": "Amazon Rekognition provides developers with control over content moderation by returning a hierarchical list of labels with confidence scores for detected content. This allows developers to filter and manage large volumes of user-generated content (UGC) more granularly, as they can use high-level labels like 'Explicit Nudity' along with second-level labels such as 'Graphic Male Nudity' to implement complex filtering logic tailored to different geographies and demographics.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T18:20:32.107793"}}
{"question": "How does the content detection of Amazon Rekognition compare with its ability to identify illegal content?", "answer": "Amazon Rekognitions Content Moderation API is designed to detect various types of inappropriate and offensive content, but it does not detect illegal content, such as child sexual abuse material, or unnatural adult content. This distinction emphasizes that while Rekognition can help filter explicit and suggestive content, it is not an authority or exhaustive filter for all inappropriate content.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-04T18:20:32.107953"}}
{"question": "What field can be used to track the version of models in Amazon Rekognition?", "answer": "You can use the 'ModerationModelVersion' field in the API response to track the version of models in Amazon Rekognition.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-04T18:20:36.907147"}}
{"question": "How can I balance the detection of inappropriate content with the accuracy of detection in Amazon Rekognition?", "answer": "You can use the MinConfidence parameter in your API requests to balance detection of content (recall) versus the accuracy of detection (precision). Reducing MinConfidence may help detect most inappropriate content but could also result in false positives, while increasing it ensures that detected content is likely inappropriate but may miss some inappropriate items.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-04T18:20:36.907456"}}
{"question": "What are the implications of adjusting the 'MinConfidence' parameter in Amazon Rekognition?", "answer": "If you reduce the 'MinConfidence', you are likely to detect most inappropriate content but may also include content that is not inappropriate. Conversely, if you increase 'MinConfidence', you are likely to ensure that all detected content is truly inappropriate, but it may result in some inappropriate content going undetected.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-04T18:20:36.908038"}}
{"question": "What attributes does Amazon Rekognition Image return for each detected face?", "answer": "Amazon Rekognition Image returns the bounding box for each detected face along with attributes such as gender, presence of sunglasses, and face landmark points.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-04T18:20:41.038606"}}
{"question": "How can face pose information be utilized in facial analysis?", "answer": "Face pose information can be used to find the orientation of the face bounding polygon, measure deformation, and track faces accurately, among other applications.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-04T18:20:41.038962"}}
{"question": "What is the difference between face quality and face pose in the context of Amazon Rekognition?", "answer": "Face quality describes the quality of the detected face image using sharpness and brightness parameters, while face pose refers to the rotation of a detected face on the pitch, roll, and yaw axes, measured in degrees. Face quality is concerned with the visual clarity of the image, whereas face pose deals with the orientation of the face.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-04T18:20:41.039414"}}
{"question": "What attributes can Rekognition Video analyze regarding detected faces?", "answer": "Rekognition Video can analyze face attributes such as whether the face is smiling, if the eyes are open, and the emotions being shown. It also returns the detected faces with timestamps, their positions, and a bounding box along with landmark points like the left eye, right eye, nose, left corner of the mouth, and right corner of the mouth.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-04T18:20:46.478573"}}
{"question": "How can using multiple face instances with variations improve the performance of face recognition?", "answer": "Using multiple face instances per person with variations such as beard, glasses, and different poses (both profile and frontal) can significantly improve the performance of face recognition. This is because it provides a more comprehensive representation of an individual's face, aiding in more accurate detection and comparison.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-04T18:20:46.478916"}}
{"question": "What is the difference between Face Comparison and Face Search in Amazon Rekognition?", "answer": "Face Comparison is the process of comparing one face to one or more faces to measure similarity, typically using the CompareFaces API, which gives a similarity score and confidence score for each face detected. In contrast, Face Search uses an input face to search for similar matches in a collection of stored faces, allowing for applications like multi-factor authentication and automated entry systems.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-04T18:20:46.479129"}}
{"question": "What is the purpose of the CreateCollection API in AWS Rekognition?", "answer": "The CreateCollection API is used to create a face collection in a supported AWS region and returns an Amazon Resource Name (ARN) for that collection. Each face collection has a unique CollectionId associated with it.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T18:20:51.050998"}}
{"question": "How does the IndexFaces API contribute to managing face collections in AWS Rekognition?", "answer": "The IndexFaces API allows you to add a face to an existing face collection by accepting an image in the form of an S3 object or image byte array. It adds a vector representation of the faces detected to the collection and returns a unique FaceId and face bounding box for each face vector added.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T18:20:51.051337"}}
{"question": "What is the difference between searching for faces using the SearchFaceByImage API and searching for users using the SearchUsersByImage API?", "answer": "The SearchFaceByImage API is used to search for a face within an indexed collection of faces, returning a set of matching faces ordered by similarity score. In contrast, the SearchUsersByImage API searches for users based on an input face, returning a set of users that match, also ordered by similarity score. The key difference lies in the target of the search: faces versus users.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-04T18:20:51.051548"}}
{"question": "What does Amazon Rekognition's Celebrity Recognition feature do?", "answer": "Amazon Rekognitions Celebrity Recognition is a deep learning based easy-to-use API for detection and recognition of individuals who are famous, noteworthy, or prominent in their field. It operates at scale and recognizes celebrities across various categories, including politics, sports, business, entertainment, and media.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T18:20:56.118459"}}
{"question": "How can the performance of face recognition be improved when using Amazon Rekognition?", "answer": "The performance of face recognition can be significantly improved by using multiple face instances per person with variations such as beard, glasses, and different poses (profile and frontal). This helps to ensure better recognition accuracy.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T18:20:56.118819"}}
{"question": "How does the recognition of celebrities in video differ from the recognition in images using Amazon Rekognition?", "answer": "In video, Amazon Rekognition can detect and recognize when and where well-known persons appear, providing a time-coded output that includes the name, unique id of the celebrity, bounding box coordinates, confidence score, and URLs pointing to related content like the celebrity's IMDB link. In contrast, image recognition using the API focuses on identifying celebrities in still images without the time-coded context.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-04T18:20:56.119024"}}
{"question": "What factors can affect the quality of the Rekognition Video APIs?", "answer": "The quality of the Rekognition Video APIs can be affected by very fast moving celebrities, blurred videos, heavy makeup, and camouflage commonly used by actors and actresses.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:21:00.887912"}}
{"question": "How does Amazon Rekognition's DetectText API function when detecting text in images and videos?", "answer": "Amazon Rekognitions DetectText API takes in an image and returns the text label and a bounding box for each detected string of characters, along with a confidence score. It is designed to detect and recognize text within real-world images and videos, such as street names, captions, product names, overlaid graphics, video subtitles, and vehicular license plates.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:21:00.888266"}}
{"question": "What are the differences in text detection capabilities between Amazon Rekognition and document image processing?", "answer": "Amazon Rekognition's text detection is specifically built to work with real-world images and videos rather than document images. It supports text in most Latin scripts and numbers in a variety of layouts, fonts, and styles, and can recognize text rotated by up to -90 to +90 degrees from the horizontal axis, while document image processing typically focuses on structured text layouts.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-04T18:21:00.888476"}}
{"question": "What types of protective equipment can the Amazon Rekognition 'DetectProtectiveEquipment' API detect?", "answer": "The Amazon Rekognition 'DetectProtectiveEquipment' API can detect common types of face covers, hand covers, and head covers. Additionally, it can detect PPE such as high-visibility vests, safety goggles, and other PPE unique to your business using Amazon Rekognition Custom Labels.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-04T18:21:06.239944"}}
{"question": "How does the 'CoversBodyPart' value in the API output help users?", "answer": "The 'CoversBodyPart' value in the API output provides a true/false indication of whether the protective equipment is on the corresponding body part of the person. This helps filter out cases where the PPE is present in the image but not actually worn by the person, although it does not indicate whether the person is adequately protected or if the protective equipment is properly worn.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-04T18:21:06.240260"}}
{"question": "How does Amazon Rekognition PPE detection differ from facial recognition?", "answer": "Amazon Rekognition PPE detection does not perform facial recognition or facial comparison and cannot identify the detected persons. This means it only detects PPE without linking it to the identity of the individuals wearing it.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-04T18:21:06.240462"}}
{"question": "What notifications does Amazon Rekognition send when it detects a desired object?", "answer": "When Amazon Rekognition detects a desired object, it sends a notification that includes the object detected, a bounding box, a zoomed-in image of the object, and the time stamp.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:21:11.287282"}}
{"question": "What are the key capabilities of Amazon Rekognition Streaming Video Events?", "answer": "Amazon Rekognition Streaming Video Events provides several key capabilities, including sending smart alerts to end users, integrating with smart assistants like Echo devices for announcements, and offering smart search capabilities to find video clips where specific objects like packages were detected.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:21:11.287595"}}
{"question": "How does the detection of pets differ from the detection of packages in Amazon Rekognition Streaming Video Events?", "answer": "In Amazon Rekognition Streaming Video Events, pets can be detected specifically as dogs and cats, while packages are detected as medium and large cardboard boxes, as well as smaller boxes, bubble mailer envelopes, and folders, although detection accuracy may vary for the latter items.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-04T18:21:11.287763"}}
{"question": "Will I be charged separately for each label detected in Amazon Rekognition?", "answer": "No, you will not be charged separately for each label. You will be charged for the duration of streaming video processed by Rekognition.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-04T18:21:16.347676"}}
{"question": "How does opting into specific labels work when using Amazon Rekognition?", "answer": "You can either opt into specific labels, such as pet or package, or choose to opt in to all three labels, which include people, pet, and package, while configuring your stream processing settings.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-04T18:21:16.348006"}}
{"question": "What are the differences in video stream requirements between new and existing Kinesis Video Streams for Amazon Rekognition?", "answer": "Amazon Rekognition Streaming Video Events works with both new and existing Kinesis Video Streams. There is no requirement to create new Kinesis Video Streams to use Streaming Video Events; you can simply integrate the relevant KVS streams with Amazon Rekognition Streaming Video Events API.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-04T18:21:16.348183"}}
{"question": "What is the maximum number of concurrent sessions supported by Amazon Rekognition Streaming Video Events per AWS customer?", "answer": "Amazon Rekognition Streaming Video Events can support 600 concurrent sessions per AWS customer.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-04T18:21:19.941104"}}
{"question": "What should I do if I need to process more than 600 concurrent video streams with Amazon Rekognition?", "answer": "If you need to increase the limit of 600 concurrent sessions, you should reach out to your account manager.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-04T18:21:19.941441"}}
{"question": "How does the limit of concurrent sessions for Amazon Rekognition compare to typical video processing limits in other services?", "answer": "The context does not provide information about the concurrent session limits of other video processing services, so a comparison cannot be made.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-04T18:21:19.942105"}}
{"question": "What information does Amazon Rekognition Video return when a label is detected across multiple consecutive frames?", "answer": "When a label is detected across multiple consecutive frames, Amazon Rekognition Video returns a video segment defined by a start timestamp, an end timestamp, and a duration. For example, if 'Dog' is detected in 2 consecutive frames at 2000ms and 4000ms, it returns 1 label entry for 'Dog' with a start timestamp of 2000ms, an end timestamp of 4000ms, and a duration of 2000ms.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T18:21:26.150935"}}
{"question": "How does Amazon Rekognition Video define a video segment?", "answer": "A video segment is defined by a start timestamp, an end timestamp, and a duration. This allows for organization of label results by video segments when a label is detected in consecutive frames.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T18:21:26.151303"}}
{"question": "What are the start and end timestamps for the label 'Dog' when detected in 2 consecutive frames at 2000ms and 4000ms?", "answer": "The start timestamp for the label 'Dog' is 2000ms, and the end timestamp is 4000ms when detected in 2 consecutive frames.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-04T18:21:26.151703"}}
{"question": "What types of segments or entities can Amazon Rekognition Video detect for media analysis?", "answer": "Amazon Rekognition Video can detect black frames, credits, shots, color bars, and slates for media analysis.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:21:30.927193"}}
{"question": "How can the detection of credits by Amazon Rekognition Video enhance viewer experience in VOD applications?", "answer": "The detection of credits allows Amazon Rekognition Video to identify the exact frames where opening and closing credits start and end, which can be used to generate 'binge markers' or interactive viewer prompts such as 'Next Episode' or 'Skip Intro' in VOD applications.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:21:30.927528"}}
{"question": "How does the detection of black frames differ from the detection of shots in Amazon Rekognition Video?", "answer": "Black frames are short durations of empty frames with no audio used for cues like ad insertion, while shots refer to a series of interrelated consecutive pictures taken by a single camera representing continuous action. Amazon Rekognition Video detects black frames to automate ad insertion and segment demarcation, whereas it detects shots to determine their start, end, duration, and count for applications like creating promotional videos or inserting ads without disrupting viewer experience.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:21:30.927720"}}
{"question": "What are slates in the context of video content?", "answer": "Slates are sections, typically at the beginning of a video, that contain text metadata about the episode, studio, video format, audio channels, and more.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:21:35.542870"}}
{"question": "How does Amazon Rekognition Video assist operators in managing video content segments?", "answer": "Amazon Rekognition Video enables operators to detect the start and end of each content segment in the video. This capability allows operators to find the program run time, identify specific segments for particular purposes, and categorize segments based on domain knowledge.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:21:35.543152"}}
{"question": "How do slates and studio logos differ in their purpose within a video?", "answer": "Slates contain text metadata about the episode and other details, while studio logos are sequences that show the logos or emblems of the production studio involved in making the show. Amazon Rekognition can identify both, but they serve different functions: slates provide metadata, whereas studio logos identify the studio.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-04T18:21:35.543349"}}
{"question": "What operations are included in the Amazon Rekognition Video segment detection API?", "answer": "The Amazon Rekognition Video segment detection API includes two operations: StartSegmentDetection to start the analysis, and GetSegmentDetection to get the analysis results.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-04T18:21:43.164971"}}
{"question": "How does the Media Insights application assist users in working with video analysis?", "answer": "The Media Insights application is a serverless framework and demo application that allows users to visualize results of media analysis and try out other Amazon AI services like Amazon Transcribe with their own videos. It enables users to easily generate insights and develop applications for video, audio, text, and image resources, using AWS Machine Learning and Media services.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-04T18:21:43.165261"}}
{"question": "What frame rates does the Amazon Rekognition Video segment detection support, and how does it handle different standards?", "answer": "The Amazon Rekognition Video segment detection supports frame rates between 15 and 60fps, including common frame rates such as 23.976 fps, 25fps, 29.97 fps, and 30fps. It automatically handles integer, fractional, and drop frame standards for these frame rates.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-04T18:21:43.165430"}}
{"question": "What is the minimum confidence score you can specify for segment types in an API request?", "answer": "You can filter out any segment below a 70% confidence score while making the API request.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-04T18:21:47.528054"}}
{"question": "How does Amazon Rekognition handle black frame detection in videos?", "answer": "Amazon Rekognition allows you to control the maximum pixel luminance that you consider to be a black pixel and specifies what percentage of pixels in a frame need to meet this luminance criteria for the frame to be classified as a black frame. For example, you can set a maximum luminance value of 40 and require 99% of pixels to meet this criteria.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-04T18:21:47.528854"}}
{"question": "How does the image processing count differ between the CompareFaces API and other image input APIs in Amazon Rekognition?", "answer": "For the CompareFaces API, only the source image is counted as a unit of images processed, whereas for other image input APIs like DetectLabels and DetectFaces, the actual number of images analyzed is counted as the number of images processed.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-04T18:21:47.529040"}}
{"question": "How much does Amazon Rekognition charge for processing face vectors?", "answer": "Amazon Rekognition charges $0.01 per 1,000 face vectors per month.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-04T18:21:52.190818"}}
{"question": "What is the relationship between Amazon S3 and Amazon Rekognition when analyzing images?", "answer": "You can analyze images stored in Amazon S3 by pointing the Amazon Rekognition API to your S3 bucket, which means you do not need to move your data. However, the S3 bucket must be in the same region as the Amazon Rekognition API endpoint.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-04T18:21:52.191157"}}
{"question": "How does Amazon Rekognition integrate with AWS Lambda compared to its integration with Amazon S3?", "answer": "Amazon Rekognition provides seamless access to AWS Lambda, allowing trigger-based image analysis for AWS data stores, including Amazon S3 and Amazon DynamoDB. While you can analyze images in S3 by pointing the Rekognition API to the S3 bucket, the integration with AWS Lambda allows for more automated and event-driven image analysis.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-04T18:21:52.191600"}}
{"question": "What does Amazon Rekognition do with image and video inputs processed by the service?", "answer": "Amazon Rekognition may store and use image and video inputs processed by the service solely to provide and maintain the service and, unless you opt out, to improve and develop the quality of Amazon Rekognition and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-04T18:21:55.811013"}}
{"question": "Why is the use of customer content important for Amazon Rekognition?", "answer": "The use of customer content is important for continuous improvement of the Amazon Rekognition customer experience, including the development and training of related technologies.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-04T18:21:55.811355"}}
{"question": "How does the access to customer content processed by Amazon Rekognition differ from other services?", "answer": "Only authorized employees will have access to your content that is processed by Amazon Rekognition, which emphasizes that your trust, privacy, and the security of your content are the highest priority for Amazon Rekognition.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-04T18:21:55.811953"}}
{"question": "What is Amazon Rekognition integrated with for access control?", "answer": "Amazon Rekognition is integrated with AWS Identity and Access Management (IAM), which allows AWS IAM policies to be used to ensure that only authorized users have access to Amazon Rekognition APIs.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-04T18:22:00.439922"}}
{"question": "What resources does AWS provide to assist customers in building and using AI systems responsibly?", "answer": "AWS provides Responsible AI guidance and the AWS Responsible AI Policy, which offer resources and tools for responsible AI use. Additionally, AWS has AI Service Cards for certain Amazon Rekognition features, detailing intended use cases, how Rekognition uses machine learning, and key considerations for responsible design and use.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-04T18:22:00.440266"}}
{"question": "How do biometric laws relate to the use of Amazon Rekognition?", "answer": "Biometric laws apply to the collection, processing, or use of biometric data, such as scans of hand or face geometry. These laws may be relevant if your service involves biometric data and often require providing notice and obtaining consent from end users, as well as complying with deletion requests. This is part of the shared responsibility model, and service providers like AWS must also be considered when obtaining consent.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-04T18:22:00.440451"}}
{"question": "What is AWS Resource Access Manager (AWS RAM) used for?", "answer": "AWS Resource Access Manager (AWS RAM) helps you securely share your resources across AWS accounts, within your organization or organizational units (OUs) in AWS Organizations, and with IAM roles and IAM users for supported resource types.", "question_type": "factual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T18:22:05.328310"}}
{"question": "How does AWS RAM facilitate resource sharing among different AWS accounts?", "answer": "AWS RAM facilitates resource sharing by allowing you to create a resource share using the AWS RAM console, AWS RAM APIs, AWS CLI, or AWS SDKs. You can easily share resources by adding them to a resource share, choosing a managed permission to associate with each resource type, and specifying whom you want to give access to the resources.", "question_type": "conceptual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T18:22:05.328531"}}
{"question": "What happens when resources are shared with accounts outside of your organization compared to sharing within your organization using AWS RAM?", "answer": "When resources are shared with accounts outside of your organization, those accounts receive an invitation to join the resource share, and they can start using the shared resources after accepting the invitation. In contrast, if you are part of an organization in AWS Organizations and sharing within your organization is enabled, you can share resources directly with OUs or your entire organization without the need for an invitation.", "question_type": "comparison", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-04T18:22:05.328684"}}
{"question": "What can you do to stop sharing a resource in AWS RAM?", "answer": "You can stop sharing a resource by removing it from the resource share or by deleting the resource share.", "question_type": "factual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T18:22:09.522813"}}
{"question": "What is the difference between AWS managed permissions and customer managed permissions in AWS RAM?", "answer": "AWS managed permissions are created and maintained by AWS, granting permissions for common customer scenarios with default permissions available for every resource type. In contrast, customer managed permissions are authored and maintained by the user, allowing for precise specification of who can do what under which conditions for shared resources. This gives users more control over access compared to the predefined nature of AWS managed permissions.", "question_type": "comparison", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T18:22:09.523234"}}
{"question": "How are changes to resource shares monitored in AWS RAM?", "answer": "All calls to AWS RAM APIs are logged in AWS CloudTrail, and Amazon CloudWatch Events are triggered whenever there are changes to resource shares. This allows for effective logging and monitoring of resource share activities.", "question_type": "conceptual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-04T18:22:09.523729"}}
{"question": "What is the primary function of DNS in the context of networking?", "answer": "The primary function of DNS is to translate human-readable names like www.example.com into numeric IP addresses like 192.0.2.1 that computers use to connect to each other. It manages the mapping between names and numbers, similar to a phone book.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T18:22:14.286446"}}
{"question": "How does DNS function similarly to a phone book?", "answer": "DNS functions similarly to a phone book by managing the mapping between easy-to-remember domain names and their corresponding numeric IP addresses. Just as a phone book helps individuals find the phone number associated with a person's name, DNS helps computers find the IP address associated with a domain name.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T18:22:14.286845"}}
{"question": "What role do DNS servers play in the process of resolving domain names to IP addresses?", "answer": "DNS servers play the role of translating requests for domain names into their corresponding IP addresses. They control which server an end user will reach when they type a domain name into their web browser, handling the queries made for those names.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-04T18:22:14.287135"}}
{"question": "What services does Amazon Route 53 provide?", "answer": "Amazon Route 53 provides highly available and scalable Domain Name System (DNS), domain name registration, and health-checking web services.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-04T18:22:18.788584"}}
{"question": "How does Route 53 help in routing end users to Internet applications?", "answer": "Route 53 helps route end users to Internet applications by translating domain names like example.com into numeric IP addresses, such as 192.0.2.1, which computers use to connect to each other.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-04T18:22:18.788971"}}
{"question": "What is the difference between using Route 53 for DNS management and for health-checking services?", "answer": "Using Route 53 for DNS management involves creating and managing public DNS records and translating domain names into IP addresses, while using it for health-checking services involves monitoring the health and performance of applications and web servers, allowing traffic to be routed to healthy endpoints.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-04T18:22:18.789434"}}
{"question": "What is the first step to using Amazon Route 53?", "answer": "The first step to using Amazon Route 53 is to subscribe to the service by clicking on the sign-up button on the service page.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-04T18:22:22.885123"}}
{"question": "How does Route 53 ensure a high level of availability for DNS records?", "answer": "Route 53 ensures a high level of availability for DNS records by providing four Route 53 name servers across four different Top-Level Domains (TLDs) when a hosted zone is created.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-04T18:22:22.885411"}}
{"question": "What is the difference in handling DNS records for a domain you already own versus a new domain with Route 53?", "answer": "If you already own a domain name, you need to create a hosted zone using the AWS Management Console or the CreateHostedZone API, and you will receive four Route 53 name servers. If you do not have a domain name, you can register a new domain name using the AWS Management Console or the API, and Route 53 will automatically create a hosted zone for you, also providing four Route 53 name servers.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-04T18:22:22.885844"}}
{"question": "What infrastructure is Route 53 built on?", "answer": "Route 53 is built using AWSs highly available and reliable infrastructure.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-04T18:22:26.628868"}}
{"question": "What is the difference between a domain and a hosted zone in Amazon Route 53?", "answer": "A domain is a general DNS concept that refers to easily recognizable names for numerically addressed Internet resources, such as amazon.com. In contrast, a hosted zone is an Amazon Route 53 concept that represents a collection of records that can be managed together and belong to a single parent domain name. All resource record sets within a hosted zone must have the hosted zones domain name as a suffix.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-04T18:22:26.629160"}}
{"question": "How does Route 53 ensure low query latency for end users compared to traditional DNS services?", "answer": "Route 53 ensures low query latency for end users by using a global anycast network of DNS servers that automatically answer queries from the optimal location depending on network conditions, whereas traditional DNS services may not have such globally distributed infrastructure or the capability to circumvent network-related issues.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-04T18:22:26.629435"}}
{"question": "What service allows you to control management access to your Amazon Route 53 hosted zone?", "answer": "You can control management access to your Amazon Route 53 hosted zone by using the AWS Identity and Access Management (IAM) service.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:22:30.448391"}}
{"question": "How does AWS IAM help manage permissions for users in relation to DNS records?", "answer": "AWS IAM allows you to control who in your organization can make changes to your DNS records by creating multiple users and managing the permissions for each of these users within your AWS Account.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:22:30.448729"}}
{"question": "How does the billing for hosted zones work in relation to their creation and deletion?", "answer": "Hosted zones are billed once when they are created and then on the first day of each month. There is a grace period of 12 hours where if you delete a hosted zone within this time, you are not charged. After the grace period, the standard monthly fee is charged. If a hosted zone is created on the last day of the month, the charge for that month might appear on the next month's invoice.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:22:30.449152"}}
{"question": "What is Anycast in the context of Amazon Route 53?", "answer": "Anycast is a networking and routing technology that helps your end users DNS queries get answered from the optimal Route 53 location given network conditions. As a result, your users get high availability and improved performance with Route 53.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-04T18:22:34.721398"}}
{"question": "Why would someone create multiple hosted zones in Amazon Route 53?", "answer": "Creating multiple hosted zones allows you to verify your DNS settings in a 'test' environment and then replicate those settings on a 'production' hosted zone. This ensures that you can test configurations safely before applying them to your production environment.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-04T18:22:34.721736"}}
{"question": "How do the name servers differ between test and production hosted zones in Route 53?", "answer": "In Route 53, hosted zone Z1234 might be your test version of example.com, hosted on name servers ns-1, ns-2, ns-3, and ns-4, while hosted zone Z5678 might be your production version of example.com, hosted on ns-5, ns-6, ns-7, and ns-8. This indicates that each hosted zone has its own virtual set of name servers associated with it, which allows Route 53 to answer DNS queries differently based on the name server queried.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-04T18:22:34.721944"}}
{"question": "What types of DNS records does Amazon Route 53 currently support?", "answer": "Amazon Route 53 currently supports the following DNS record types: A (address record), AAAA (IPv6 address record), CNAME (canonical name record), CAA (certification authority authorization), MX (mail exchange record), NAPTR (name authority pointer record), NS (name server record), PTR (pointer record), SOA (start of authority record), SPF (sender policy framework), SRV (service locator), and TXT (text record).", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-04T18:22:40.349782"}}
{"question": "How does Amazon Route 53 differ from Amazon S3 in terms of functionality?", "answer": "Amazon Route 53 is an authoritative DNS service that does not provide website hosting, while Amazon Simple Storage Service (Amazon S3) can be used to host a static website. For dynamic websites or other web applications, Amazon Elastic Compute Cloud (Amazon EC2) is recommended, which offers more flexibility and control compared to traditional web hosting solutions.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-04T18:22:40.350013"}}
{"question": "How do alias records in Amazon Route 53 function compared to CNAME records?", "answer": "Alias records in Amazon Route 53 are an extension to DNS that allow routing traffic to selected AWS resources. While alias records typically have a type of A or AAAA, they function similarly to CNAME records. They enable you to map your record name (like example.com) to the DNS name of an AWS resource, and resolvers see the A or AAAA record along with the IP address of the AWS resource.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-04T18:22:40.350188"}}
{"question": "What types of DNS records does Amazon Route 53 support wildcard entries for?", "answer": "Amazon Route 53 supports wildcard entries for all record types except NS records.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:22:44.039209"}}
{"question": "What is the purpose of the time to live (TTL) value in DNS records?", "answer": "The time to live (TTL) value associated with every DNS record determines how long a DNS resolver caches a response. Amazon Route 53 does not have a default TTL, so you must specify a TTL for each record to control the caching duration.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:22:44.039483"}}
{"question": "How does the management of changes in Amazon Route 53 ensure consistency compared to typical DNS changes?", "answer": "Amazon Route 53 uses transactional changes to ensure that any change is completed entirely on any individual DNS server, or not at all. This design helps to ensure that DNS queries are always answered consistently, which is particularly important when making changes such as switching between destination servers.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:22:44.039620"}}
{"question": "How long does it typically take for changes to DNS records to propagate in Amazon Route 53?", "answer": "Changes you make to your DNS records in Amazon Route 53 are designed to propagate to its world-wide network of authoritative DNS servers within 60 seconds under normal conditions.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-04T18:22:48.471870"}}
{"question": "What are the recommended uses for AWS CloudTrail logs in relation to Amazon Route 53?", "answer": "AWS CloudTrail logs can be used for security analysis, resource change tracking, and compliance auditing. However, it is not recommended to use CloudTrail logs to roll back changes to your hosted zones due to the potential incompleteness of zone change history.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-04T18:22:48.472213"}}
{"question": "What types of DNS records does Amazon Route 53 support, and how do they relate to IPv6?", "answer": "Amazon Route 53 supports both forward (AAAA) and reverse (PTR) IPv6 records. The service itself is available over IPv6, and recursive DNS resolvers on IPv6 networks can use either IPv4 or IPv6 transport to submit DNS queries to Amazon Route 53. Additionally, Amazon Route 53 health checks also support monitoring endpoints using the IPv6 protocol.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-04T18:22:48.472418"}}
{"question": "What types of load balancers are supported by Amazon Route 53 for Alias records?", "answer": "Amazon Route 53 supports alias records for three types of load balancers: Application Load Balancers, Network Load Balancers, and Classic Load Balancers.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-04T18:22:53.047648"}}
{"question": "What is the purpose of an Alias record in Amazon Route 53?", "answer": "The purpose of an Alias record in Amazon Route 53 is to map your zone apex DNS name to another DNS name, such as that of an ELB load balancer or an Amazon S3 website bucket, allowing for flexibility with changing IP addresses associated with those resources.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-04T18:22:53.064632"}}
{"question": "How does the query handling for Alias records differ between ELB load balancers and Amazon S3 website buckets?", "answer": "For ELB load balancers, Route 53 responds to each request for an Alias record with one or more IP addresses, while for Amazon S3 website buckets, it responds with one IP address. Additionally, there is no charge for queries to Alias records for both ELB load balancers and S3 website buckets, as they are categorized as 'Intra-AWS-DNS-Queries' in the usage report.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-04T18:22:53.065471"}}
{"question": "What is an Alias record in Amazon Route 53?", "answer": "An Alias record in Amazon Route 53 is a special type of record that allows you to map your zone apex (example.com) DNS name to other AWS resources such as an Amazon CloudFront distribution or an AWS Elastic Beanstalk DNS name.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-04T18:22:57.963370"}}
{"question": "Why do IP addresses associated with Amazon CloudFront and AWS Elastic Beanstalk environments change frequently?", "answer": "IP addresses associated with Amazon CloudFront endpoints and AWS Elastic Beanstalk environments can change frequently due to scaling up, scaling down, or software updates. This variability helps direct end users to the nearest edge location in the case of CloudFront and accommodates changes in the Elastic Beanstalk environment.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-04T18:22:57.963769"}}
{"question": "How do the queries to Alias records for CloudFront and Elastic Beanstalk environments compare in terms of cost?", "answer": "Queries to Alias records that are mapped to both Amazon CloudFront distributions and AWS Elastic Beanstalk environments are free. Both types of queries are listed as 'Intra-AWS-DNS-Queries' on the Amazon Route 53 usage report.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-04T18:22:57.963917"}}
{"question": "What is an 'Alias' record in Amazon Route 53?", "answer": "An 'Alias' record in Amazon Route 53 is a special type of record that allows you to map your zone apex DNS name to various AWS resources, such as an Amazon API Gateway DNS name or an Amazon VPC Endpoint DNS name.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-04T18:23:02.572682"}}
{"question": "How does Route 53 handle IP addresses for resources mapped with Alias records?", "answer": "Route 53 responds to each request for an Alias record with one or more IP addresses for the corresponding resource, such as the API Gateway or VPC Endpoint. These IP addresses can change at any time due to scaling up, scaling down, or software updates.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-04T18:23:02.573076"}}
{"question": "What is the difference in the resources that can be mapped using Alias records in Route 53?", "answer": "Alias records in Route 53 can be mapped to different resources such as Amazon API Gateway DNS names and Amazon VPC Endpoint DNS names. Both types of records do not incur additional charges for queries, and the queries are listed as 'Intra-AWS-DNS-Queries' on the Route 53 usage report.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-04T18:23:02.573297"}}
{"question": "What type of DNS record should you create for CloudFront distributions or S3 buckets configured to host static websites?", "answer": "You should create an 'Alias' record that maps to your CloudFront distribution or S3 website bucket.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-04T18:23:07.896717"}}
{"question": "What are the advantages of using Alias records over CNAME records in Amazon Route 53?", "answer": "Alias records have two advantages over CNAME records: first, you can create an Alias record for your zone apex (e.g., example.com, instead of www.example.com), and second, queries to Alias records are free of charge.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-04T18:23:07.897030"}}
{"question": "How does the propagation of updated DNS records work in Amazon Route 53 compared to DNS resolvers on the internet?", "answer": "When resource record sets are changed in Amazon Route 53, the service propagates updates to its world-wide network of authoritative DNS servers. However, DNS resolvers on the internet cache resource record sets according to their time to live (TTL), which means that if you test the record before propagation is complete, you may see an old value, indicating a difference in how updates are handled.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-04T18:23:07.897211"}}
{"question": "What is the purpose of Weighted Round Robin in Amazon Route 53?", "answer": "The purpose of Weighted Round Robin in Amazon Route 53 is to allow you to assign weights to resource record sets to specify the frequency with which different responses are served. This capability can be used for A/B testing, enabling you to send a small portion of traffic to a server with a software change.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-04T18:23:14.143004"}}
{"question": "How does Latency Based Routing (LBR) improve application performance for a global audience?", "answer": "Latency Based Routing (LBR) improves application performance for a global audience by routing end users to the AWS region that provides the lowest latency. It leverages multiple AWS regions and dozens of edge locations worldwide to enhance the user experience by ensuring users connect to the nearest and fastest endpoint.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-04T18:23:14.143343"}}
{"question": "How does the implementation of Weighted Round Robin compare to Latency Based Routing in Amazon Route 53?", "answer": "The implementation of Weighted Round Robin involves assigning weights to resource record sets to control the frequency of responses, whereas Latency Based Routing focuses on directing users to the AWS region with the lowest latency. Both methods require marking the record set appropriately, but they serve different purposes: one for traffic distribution based on weights and the other for optimizing performance based on geographical latency.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-04T18:23:14.143643"}}
{"question": "What geographic granularity levels does Route 53 Geo DNS provide?", "answer": "Route 53 Geo DNS provides three levels of geographic granularity: continent, country, and state.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-04T18:23:18.367445"}}
{"question": "How does Geo DNS enhance the user experience for localized content?", "answer": "Geo DNS enhances the user experience for localized content by allowing the customization of detail pages to be presented in the appropriate language and by restricting content distribution to specific licensed markets, thereby ensuring that users receive relevant content based on their geographic location.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-04T18:23:18.368032"}}
{"question": "What is the relationship between Geo DNS and global records in Route 53?", "answer": "The relationship between Geo DNS and global records in Route 53 is that while Geo DNS directs requests to specific endpoints based on geographic location, the global record serves as a fallback response for DNS queries that come from locations not matched by any specific Geo DNS records. This ensures that Route 53 can provide a response to DNS queries from all possible locations.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-04T18:23:18.368210"}}
{"question": "Can Route 53 handle Geo DNS records for overlapping geographic regions?", "answer": "Yes, Route 53 can have Geo DNS records for overlapping geographic regions, such as a continent and the countries within that continent, or a country and the states within that country.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-04T18:23:24.694931"}}
{"question": "What are the recommended use cases for using Geo DNS and Latency Based Routing in Route 53?", "answer": "Geo DNS is recommended when you have compliance, localization requirements, or other use cases that require stable routing from a specific geography to a specific endpoint. Latency Based Routing is recommended if your goal is to minimize end-user latency.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-04T18:23:24.695288"}}
{"question": "How does the routing decision process differ between Geo DNS and Latency Based Routing in Route 53?", "answer": "Geo DNS bases routing decisions on the geographic location of requests, returning the most specific Geo DNS record for the end user's location. In contrast, Latency Based Routing utilizes latency measurements between viewer networks and AWS datacenters to direct users toward the endpoint that minimizes latency.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-04T18:23:24.695711"}}
{"question": "What is Amazon Route 53 Traffic Flow and how does it benefit application performance?", "answer": "Amazon Route 53 Traffic Flow is a global traffic management service that is easy to use and cost-effective. It benefits application performance by allowing developers to run multiple endpoints around the world and connect users to the best endpoint based on factors such as latency, geography, and endpoint health. This improves the performance and availability of applications for end users.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-04T18:23:41.306704"}}
{"question": "What is a traffic policy in Amazon Route 53 Traffic Flow, and how can it be created?", "answer": "A traffic policy in Amazon Route 53 Traffic Flow is a set of rules defined to route end users requests to one of your applications endpoints. It can be created using the visual policy builder in the Amazon Route 53 Traffic Flow section of the Amazon Route 53 console or as JSON-formatted text files that can be uploaded using the Route 53 API, AWS CLI, or various AWS SDKs.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-04T18:23:41.307024"}}
{"question": "What is the relationship between a traffic policy and a policy record in Amazon Route 53 Traffic Flow?", "answer": "A traffic policy is a set of rules that defines how to route traffic to application endpoints, but by itself, it does not affect routing until it is associated with an applications DNS name. This association is made through a policy record, which links the traffic policy to the appropriate DNS name within an Amazon Route 53 hosted zone. For example, to use a traffic policy named my-first-traffic-policy for www.example.com, a policy record must be created for www.example.com within the hosted zone, choosing my-first-traffic-policy as the traffic policy.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-04T18:23:41.307477"}}
{"question": "What are the two methods to reuse a policy for managing multiple DNS names?", "answer": "The first method is to create additional policy records using the policy, which incurs an additional charge for each policy record created. The second method is to create one policy record using the policy, and for each additional DNS name, create a standard CNAME record pointing to the DNS name of the policy record. However, this second method cannot be used for records at the zone apex.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-04T18:23:46.138676"}}
{"question": "Why is there no charge for creating a traffic policy in AWS Route 53?", "answer": "There is no charge for creating the traffic policy itself because billing is only applied to policy records, which represent the application of a Traffic Flow policy to a specific DNS name. Only policy records incur charges, while traffic policies that are not associated with a DNS name via a policy record are free.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-04T18:23:46.139045"}}
{"question": "How does Traffic Flow differ in billing compared to policy records in AWS Route 53?", "answer": "Traffic Flow does not incur any charges for the traffic policies themselves; only the policy records are billed. A policy record is specifically charged for each DNS name it manages, whereas traffic policies that are not linked to any DNS names via policy records do not incur any cost.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-04T18:23:46.139497"}}
{"question": "What is the purpose of the geoproximity routing feature in AWS Route 53?", "answer": "The geoproximity routing feature in AWS Route 53 routes DNS queries to the nearest endpoint based on geographic location. For example, if a user in Seattle visits a website, geoproximity routing will direct the query to the EC2 instances located in the US West (Oregon) region because it is closer geographically than the US East (Ohio) region.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-04T18:23:52.826189"}}
{"question": "How does changing the geoproximity bias value affect traffic routing in Route 53?", "answer": "Changing the geoproximity bias value on an endpoint can either expand or shrink the area from which Route 53 routes traffic to a resource. However, it is important to note that the geoproximity bias cannot accurately predict the load factor because small shifts in geographic areas might include or exclude major metropolitan areas that generate significant query loads.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-04T18:23:52.826485"}}
{"question": "What is the difference between Private DNS and public DNS in Amazon Route 53?", "answer": "Private DNS is a feature in Amazon Route 53 that allows users to have authoritative DNS within their Virtual Private Clouds (VPCs) without exposing DNS records to the Internet. In contrast, public DNS exposes DNS records to the Internet. With Private DNS, records are only returned when queried from within the associated VPCs, whereas public DNS records can be accessed from anywhere on the Internet.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-04T18:23:52.826914"}}
{"question": "What is required to update the configuration for your Private DNS hosted zone?", "answer": "To update the configuration for your Private DNS hosted zone, you need Internet connectivity to access the Route 53 API endpoint, which is outside of your VPC.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-04T18:23:59.199807"}}
{"question": "How does Route 53 Private DNS manage visibility for private DNS hosted zones?", "answer": "Route 53 Private DNS uses VPC to manage visibility and provide DNS resolution for private DNS hosted zones. To take advantage of Route 53 Private DNS, you must configure a VPC and migrate your resources into it.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-04T18:23:59.200107"}}
{"question": "Can you associate multiple VPCs from different accounts with a single Private DNS hosted zone, and how does this affect DNS answers?", "answer": "Yes, you can associate multiple VPCs with a single hosted zone, and these VPCs can belong to different accounts. DNS answers will be available within every VPC that you associate with the private hosted zone, provided that the VPCs in each region have connectivity with each other for resources in one region to reach resources in another region.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-04T18:23:59.200643"}}
{"question": "What are the two components of DNS Failover?", "answer": "The two components of DNS Failover are health checks and failover.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-04T18:24:03.809237"}}
{"question": "How does Route 53 determine which resources to return answers for in DNS Failover?", "answer": "Route 53 only returns answers for resources that are healthy and reachable from the outside world, ensuring that end users are routed away from a failed or unhealthy part of the application.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-04T18:24:03.809671"}}
{"question": "What is the difference between configuring DNS Failover for Elastic Load Balancers and for other resources?", "answer": "When configuring DNS Failover for Elastic Load Balancers (ELBs), Route 53 automatically creates and manages the health checks for the ELB, and you do not need to create your own health check or associate your resource record set with a health check. This is different from other resources where you may need to set up and manage health checks manually.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-04T18:24:03.810043"}}
{"question": "What does Route 53 do for Elastic Load Balancers and Amazon S3 website buckets regarding health checks?", "answer": "For Elastic Load Balancers and Amazon S3 website buckets, Route 53 automatically creates and manages health checks on your behalf when you create an Alias record pointing to them and enable the 'Evaluate Target Health' parameter.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-04T18:24:08.825483"}}
{"question": "How does Route 53 handle health checks for endpoints located outside of AWS?", "answer": "Route 53 allows you to set up health checks for parts of your application running outside AWS, and you can fail over to any endpoint of your choice, regardless of its location. For example, if you have a legacy application running outside AWS and a backup instance in AWS, you can create health checks for the legacy application, and if it fails, Route 53 can automatically switch to the backup instance in AWS.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-04T18:24:08.825969"}}
{"question": "What is the difference in the way Route 53 handles health checks for AWS endpoints versus other endpoints?", "answer": "For AWS endpoints like Elastic Load Balancers and Amazon S3 website buckets, Route 53 automatically manages health checks when you create an Alias record. In contrast, for other endpoints, you must specify either the DNS name or the IP address when creating a health check for that endpoint.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-04T18:24:08.826313"}}
{"question": "What is the default interval for health check observations in Route 53?", "answer": "By default, health check observations are conducted at an interval of 30 seconds.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-04T18:24:13.534544"}}
{"question": "How do fast interval health checks benefit DNS failover in Route 53?", "answer": "Fast interval health checks enable Route 53 to confirm more quickly that an endpoint has failed, shortening the time required for DNS failover to redirect traffic in response to the endpoints failure.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-04T18:24:13.534895"}}
{"question": "What is the difference in request frequency between standard interval health checks and fast interval health checks?", "answer": "For standard interval health checks, you should expect your endpoint to receive one request every 2-3 seconds on average, while for fast interval health checks, you can expect one or more requests per second.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-04T18:24:13.535400"}}
{"question": "What happens when Route 53 detects three consecutive failed health checks for an application?", "answer": "When Route 53 detects three consecutive failed health checks for an application, it disables the resource records for the failed endpoint and no longer serves these records. This failover step causes traffic to begin being routed to the healthy endpoint(s) instead of the failed endpoint.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-04T18:24:18.964444"}}
{"question": "Why is it recommended to set a TTL of 60 seconds or less when using DNS Failover?", "answer": "It is recommended to set a TTL of 60 seconds or less when using DNS Failover to minimize the amount of time it takes for traffic to stop being routed to the failed endpoint, ensuring a quicker transition to healthy endpoints.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-04T18:24:18.964814"}}
{"question": "How does Route 53 behave when there are no healthy endpoints available in a resource record set?", "answer": "When there are no healthy endpoints remaining in a resource record set, Route 53 behaves as if all health checks are passing, meaning it will not initiate any failover to a backup endpoint.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-04T18:24:18.965246"}}
{"question": "What option must be selected to check for the presence of a designated string in a server response using Route 53 health checks?", "answer": "You must select the 'Enable String Matching' option to check for the presence of a designated string in a server response using Route 53 health checks.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-04T18:24:23.422881"}}
{"question": "How can Amazon Route 53 health checks be used to monitor server health from an operational perspective?", "answer": "Amazon Route 53 health checks can be used to monitor server health from an operational perspective by creating a dedicated status page that can be checked for health, in addition to verifying the HTML served by a web server for an expected string.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-04T18:24:23.423106"}}
{"question": "What is the relationship between Route 53 health checks and Amazon CloudWatch metrics?", "answer": "The results of Route 53 health checks are published as Amazon CloudWatch metrics, which show the endpoint's health and optionally the latency of its response. These metrics can be viewed in the Amazon CloudWatch console and can also trigger alarms for notifications if the health check status changes.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-04T18:24:23.423477"}}
{"question": "How can I configure CloudWatch notifications for Route 53 health checks?", "answer": "To configure CloudWatch notifications for Route 53 health checks, first, go to either the Route 53 or CloudWatch console and set up a CloudWatch alarm on the health check metric. After that, add a notification action and specify the email address or SNS topic where you want the notification to be sent. For full details, you can refer to the Route 53 Developer Guide.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T18:24:29.504158"}}
{"question": "What is the recommended method for setting up DNS Failover with ELB endpoints?", "answer": "The recommended method for setting up DNS Failover with ELB endpoints is to use Alias records with the 'Evaluate Target Health' option. This method does not require you to create your own health checks for ELB endpoints, which means that no specific CloudWatch metrics are generated by Route 53 for these endpoints.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T18:24:29.504512"}}
{"question": "How do CloudWatch metrics for ELB health differ from those for Route 53 health checks?", "answer": "CloudWatch metrics for ELB health are published by Elastic Load Balancing and indicate the health of the load balancer and the number of healthy instances behind it. In contrast, Route 53 health checks generate specific CloudWatch metrics only when you create your own health checks. However, if you use the 'Evaluate Target Health' option with ELB endpoints, no specific CloudWatch metrics are generated by Route 53 for those endpoints.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-04T18:24:29.504981"}}
{"question": "What does Amazon Route 53 do when you enable Evaluate Target Health on an Alias record pointing to an Amazon S3 Website bucket?", "answer": "When you enable Evaluate Target Health on an Alias record pointing to an Amazon S3 Website bucket, Amazon Route 53 takes into account the health of the Amazon S3 service in the AWS region where your bucket is located. It does not check if a specific bucket exists or contains valid website content; it only fails over to another location if the Amazon S3 service itself is unavailable in that AWS region.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-04T18:24:36.255997"}}
{"question": "How do metric based health checks in Amazon Route 53 enhance DNS failover capabilities?", "answer": "Metric based health checks in Amazon Route 53 enhance DNS failover capabilities by allowing you to perform DNS failover based on any metric available within Amazon CloudWatch, including both AWS-provided metrics and custom metrics from your application. This means that the health check can become unhealthy whenever its associated CloudWatch metric enters an alarm state, which is particularly useful for endpoints that cannot be reached by standard health checks, such as instances with private IP addresses in a Virtual Private Cloud (VPC). Additionally, they can be combined with standard health checks for more sophisticated failover scenarios.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-04T18:24:36.256342"}}
{"question": "In what scenarios would you use standard Amazon Route 53 health checks compared to metric based health checks?", "answer": "You would use standard Amazon Route 53 health checks when you need to check the availability of public-facing endpoints, such as web pages, using requests from a global network of checkers. On the other hand, you would opt for metric based health checks when dealing with endpoints that cannot be reached via standard checks, such as those with private IP addresses in a VPC, or when you want to base the health check on specific metrics like CPU load, network activity, or disk reads.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-04T18:24:36.256791"}}
{"question": "What type of address does Amazon Route 53 use when a domain name is specified as the endpoint for a health check?", "answer": "When a domain name is specified as the endpoint for a health check, Amazon Route 53 will look up the IPv4 address of that domain name and will connect to the endpoint using IPv4.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-04T18:24:40.979973"}}
{"question": "Why wouldn't Amazon Route 53 look up the IPv6 address for a health check endpoint specified by a domain name?", "answer": "Amazon Route 53 will not attempt to look up the IPv6 address for an endpoint that is specified by domain name because it is designed to only connect using IPv4 in this scenario.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-04T18:24:40.980337"}}
{"question": "How does the endpoint selection for health checks differ when using a domain name versus an IP address?", "answer": "When using a domain name as the endpoint, Amazon Route 53 connects using the IPv4 address. In contrast, if you select 'IP address' as the endpoint type and enter an IPv6 address, Amazon Route 53 will perform the health check over IPv6 instead of IPv4.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-04T18:24:40.980767"}}
{"question": "What format does AWS use to publish its current IP address ranges?", "answer": "AWS publishes its current IP address ranges in JSON format.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-04T18:24:44.972608"}}
{"question": "How can I programmatically access the AWS IP address ranges file?", "answer": "To access the AWS IP address ranges file programmatically, ensure that the application downloads the file only after successfully verifying the TLS certificate that is returned by the AWS server.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-04T18:24:44.972945"}}
{"question": "What values should I search for in the 'service' field to find IP ranges for Route 53 servers versus Route 53 health checkers?", "answer": "To find IP ranges for Route 53 servers, you should search for 'ROUTE53' in the 'service' field. For Route 53 health checkers, you should search for 'ROUTE53_HEALTHCHECKS'.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-04T18:24:44.973331"}}
{"question": "What is the CIDR notation of the first IPv6 address listed?", "answer": "The CIDR notation of the first IPv6 address listed is 2a05:d018:7ff:f800::/53.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-29", "source_tokens": 469, "generated_at": "2026-02-04T18:24:49.056148"}}
{"question": "What does the '/122' in the IPv6 addresses indicate?", "answer": "The '/122' in the IPv6 addresses indicates the subnet mask, which specifies that the first 122 bits of the address are used for network identification, leaving the remaining bits for host addresses.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-29", "source_tokens": 469, "generated_at": "2026-02-04T18:24:49.056515"}}
{"question": "How do the IPv6 addresses with '/122' differ from the ones with '/53'?", "answer": "The IPv6 addresses with '/122' have a subnet mask that allows for a larger number of available host addresses within each subnet, as they are more specific and thus define smaller subnets compared to the addresses with '/53', which define larger subnets with fewer hosts per network.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-29", "source_tokens": 469, "generated_at": "2026-02-04T18:24:49.056895"}}
{"question": "What services does Route 53 provide for domain name registration?", "answer": "Route 53 allows users to register new domain names and to transfer existing domain names from other registrars for management. The domain name registration services are provided under the Domain Name Registration Agreement.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-04T18:24:53.678389"}}
{"question": "What is the benefit of registering a domain name with Amazon Route 53 regarding renewal?", "answer": "When you register a domain with Amazon Route 53 or transfer a domain registration to it, the domain is configured to renew automatically, ensuring that you do not lose the domain due to expiration.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-04T18:24:53.678729"}}
{"question": "How does the privacy protection feature for individual domain registrations differ from the requirements set by ICANN?", "answer": "ICANN requires that registrars provide and publicly display contact information, including name, address, and phone number, for every domain name registration. However, for domain names registered as an individual, Route 53 offers privacy protection that hides the registrant's personal phone number, email address, and physical address, replacing it with the registrars information and a forwarding email address.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-04T18:24:53.679249"}}
{"question": "What personal information does Route 53's privacy protection hide?", "answer": "Route 53's privacy protection hides your phone number, email address, and physical address. Additionally, your first and last name will be hidden if the TLD registry and registrar allow it.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-04T18:24:57.724522"}}
{"question": "How does using a reusable delegation set benefit customers with many domain names?", "answer": "Using a reusable delegation set benefits customers with many domain names by simplifying the migration to Route 53. It allows them to instruct their domain name registrar to use the same delegation set for all their domains managed by Route 53, thus making management more efficient.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-04T18:24:57.724871"}}
{"question": "What is the difference between a unique delegation set and a reusable delegation set in Route 53?", "answer": "A unique delegation set is automatically assigned by Route 53 for each hosted zone created, while a reusable delegation set can be created using the Route 53 API and applied to multiple hosted zones. This means that a reusable delegation set can be used for several domain names, whereas a unique delegation set is specific to each individual hosted zone.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-04T18:24:57.725294"}}
{"question": "What charges are associated with using Route 53 for domain names?", "answer": "You will be charged for the hosted zone that Route 53 creates for your domain name, as well as for the DNS queries against this hosted zone that Route 53 serves on your behalf.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-04T18:25:02.689457"}}
{"question": "What must you do if you want to delete your Route 53 hosted zone for a domain name under a TLD that requires valid name servers?", "answer": "If you want to delete your Route 53 hosted zone for a domain name under a TLD that requires valid name servers, you will need to procure DNS service from another provider and enter that providers name server addresses before you can safely delete your Route 53 hosted zone for that domain name.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-04T18:25:02.689738"}}
{"question": "How does Amazon's domain registration process compare to Gandi's requirements for verifying contact information?", "answer": "Amazon primarily registers domains through Amazon Registrar, while Gandi acts as the registrar of record and is required by ICANN to contact the registrant to verify their contact information at the time of initial registration. Gandi requires that you verify your contact information within the first 15 days of registration to prevent suspension of the domain name.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-04T18:25:02.689939"}}
{"question": "What steps must be taken before starting the domain transfer process?", "answer": "Before starting the transfer process, you need to ensure that your domain name is unlocked at your current registrar, that you have disabled privacy protection on your domain name if applicable, and that you have obtained the valid Authorization Code, or 'authcode', from your current registrar which you will need to enter as part of the transfer process.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-04T18:25:09.039133"}}
{"question": "Why is it necessary to obtain the DNS record data for your domain before transferring to Route 53?", "answer": "It is necessary to obtain the DNS record data for your domain before transferring to Route 53 because this data, generally available in the form of a 'zone file' from your existing DNS provider, will be used to create a hosted zone in Route 53 that can store the DNS records for your domain name.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-04T18:25:09.039507"}}
{"question": "How does the process of transferring a domain away from Route 53 compare to transferring a domain to Route 53?", "answer": "Transferring a domain away from Route 53 requires initiating a transfer request with your new registrar, who will request the domain name be moved to their management. In contrast, transferring a domain to Route 53 involves unlocking the domain, disabling privacy protection, obtaining an authorization code, and creating a hosted zone to store the DNS records before following the registrar's transfer process.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-04T18:25:09.039902"}}
{"question": "What is Route 53 Resolver and what functionality does it provide?", "answer": "Route 53 Resolver is a regional DNS service that provides recursive DNS lookups for names hosted in EC2 as well as public names on the internet. This functionality is available by default in every Amazon Virtual Private Cloud (VPC).", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-04T18:25:15.551343"}}
{"question": "How does a recursive DNS service like Route 53 Resolver find the final answer to a DNS query?", "answer": "A recursive DNS service like Route 53 Resolver may either be configured to automatically forward the query directly to a specific recursive DNS server, or it may recursively search beginning with the root of the domain and continuing until it finds the final answer. Once an answer is found, the recursive DNS server may cache the answer for a period of time to answer subsequent queries more quickly.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-04T18:25:15.551693"}}
{"question": "What are the differences between an authoritative DNS service and a recursive DNS service as described in the context?", "answer": "An authoritative DNS service contains the final answer to a DNS query, generally an IP address, and clients typically do not talk directly to authoritative DNS services. In contrast, a recursive DNS service, such as Route 53 Resolver, finds the correct authoritative answer for any DNS query by either forwarding the query to a specific server or performing a recursive search.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-04T18:25:15.551907"}}
{"question": "What is the purpose of Route 53 Resolver's integration with AWS Resource Access Manager (RAM)?", "answer": "The purpose of Route 53 Resolver's integration with AWS Resource Access Manager (RAM) is to provide customers with a simple way to share their resources across AWS accounts or within their AWS Organization. This allows rules to be created in one primary account and then shared across multiple accounts using RAM.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-04T18:25:22.647765"}}
{"question": "How does Route 53 Resolver on AWS Outposts improve the performance of on-premises applications?", "answer": "Route 53 Resolver on AWS Outposts improves the performance of on-premises applications by resolving Domain Name Server (DNS) queries locally on Outposts racks, which enhances availability and performance. It automatically stores DNS responses on Outposts racks and continues to provide DNS resolution even during unexpected network disconnects to the parent AWS Region, enabling low-latency DNS resolution.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-04T18:25:22.648145"}}
{"question": "What happens to the shared rules in Route 53 Resolver when they are no longer usable by the accounts they were shared with?", "answer": "When the shared rules in Route 53 Resolver are no longer usable by the accounts they were shared with, those rules will be disassociated from the VPCs in those accounts. This means that if the rules were associated with any VPCs, they will no longer be functional in those accounts.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-04T18:25:22.648365"}}
{"question": "What feature does Amazon Route 53 Resolver DNS Firewall provide for Amazon Virtual Private Clouds (VPCs)?", "answer": "Amazon Route 53 Resolver DNS Firewall provides DNS protections that can be quickly deployed across all of your Amazon VPCs. It allows you to block queries for known malicious domains and to allow queries for trusted domains when using Route 53 Resolver for recursive DNS Resolution.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-04T18:25:27.785774"}}
{"question": "How does the Route 53 Resolver DNS Firewall enhance an organization's security posture?", "answer": "The Route 53 Resolver DNS Firewall enhances an organization's security posture by allowing flexibility in configuration. Organizations can choose to deny all outbound DNS queries for domains not on their approved lists for a strict 'walled-garden' approach, or they can allow all outbound DNS lookups by default and only block requests for known malicious domains using denylists.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-04T18:25:27.786114"}}
{"question": "What is the relationship between Route 53 Resolver DNS Firewall and AWS Firewall Manager?", "answer": "Route 53 Resolver DNS Firewall works together with AWS Firewall Manager by enabling users to build policies based on DNS Firewall rules and then centrally apply those policies across their VPCs and accounts.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-04T18:25:27.786343"}}
{"question": "What is the primary function of Route 53 Resolver DNS Firewall?", "answer": "The primary function of Route 53 Resolver DNS Firewall is to secure Route 53 Resolver DNS network traffic at an organization and account level, providing protection against outbound DNS query threats.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-04T18:25:34.230828"}}
{"question": "How does Route 53 Profiles facilitate DNS configuration management across multiple AWS accounts?", "answer": "Route 53 Profiles facilitate DNS configuration management across multiple AWS accounts by allowing users to create sharable configurations that combine various settings, such as private hosted zone associations, Resolver rules, and DNS Firewall rule groups. These Profiles can then be shared across AWS accounts and associated with Amazon Virtual Private Clouds (VPCs), ensuring consistent DNS configurations without the complexity of managing separate resources.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-04T18:25:34.231244"}}
{"question": "What is the difference between Amazon Route 53 Resolver DNS Firewall and AWS Network Firewall in terms of their deployment models?", "answer": "Amazon Route 53 Resolver DNS Firewall is designed for use with Amazon Route 53 Resolver for DNS resolution, providing granular control to block malicious or compromised domain requests. In contrast, AWS Network Firewall offers similar capabilities but is intended for use with external DNS services to filter or block outbound DNS queries to known malicious domains.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-04T18:25:34.231432"}}
{"question": "How many Profiles can you create per AWS account?", "answer": "You can create one or more Profiles per account.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-04T18:25:37.986533"}}
{"question": "What functionalities do Route 53 Profiles support?", "answer": "Route 53 Profiles support private hosted zones and the settings specified within them, Route 53 Resolver rules (both forwarding and system), and DNS Firewall rule groups. Additionally, some VPC configurations are directly managed within the Profiles, including reverse DNS lookup configuration for Resolver Rules, DNS Firewall failure mode configuration, and DNSSEC validation configuration.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-04T18:25:37.986849"}}
{"question": "What is the difference between associating Profiles with VPCs and sharing Profiles across AWS Regions?", "answer": "You can only associate one Profile per VPC at a time, whereas you cannot share a Profile across AWS Regions.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-04T18:25:37.987023"}}
{"question": "What is Amazon S3?", "answer": "Amazon S3 is an object storage service designed to store and retrieve any amount of data from anywhere. It provides industry-leading durability, availability, performance, security, and virtually unlimited scalability, all at very low costs.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T18:25:41.403027"}}
{"question": "What are the key benefits of using Amazon S3?", "answer": "The key benefits of using Amazon S3 include its industry-leading durability, availability, performance, security, and virtually unlimited scalability, all offered at very low costs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T18:25:41.403448"}}
{"question": "How does Amazon S3 compare to other storage services in terms of durability and scalability?", "answer": "Amazon S3 is noted for its industry-leading durability and virtually unlimited scalability compared to other storage services, although the context does not provide specific comparisons to other services.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-04T18:25:41.403606"}}
{"question": "What is the maximum size of an individual Amazon S3 object that can be uploaded in a single PUT?", "answer": "The maximum size of an individual Amazon S3 object that can be uploaded in a single PUT is 5 GB.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-04T18:25:45.585622"}}
{"question": "How does Amazon S3 support the development of cloud-native applications?", "answer": "Amazon S3 provides a simple web service interface that allows users to store and retrieve any amount of data at any time from anywhere. This highly scalable service enables users to start small and grow their applications without compromising on performance or reliability, making it easier to build cloud-native applications.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-04T18:25:45.586021"}}
{"question": "How does the flexibility of Amazon S3 compare to traditional data storage solutions?", "answer": "Amazon S3 is designed to be highly flexible, allowing users to store any type and amount of data, in any format, and to access it as needed, whether for frequent use or emergency recovery. This flexibility contrasts with traditional data storage solutions, which may have limitations on data types, access frequency, or scalability.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-04T18:25:45.586207"}}
{"question": "What types of objects can be stored in a general purpose bucket in Amazon S3?", "answer": "A general purpose bucket can contain objects stored across all storage classes except S3 Express One Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T18:25:50.150802"}}
{"question": "What are the primary use cases recommended for a directory bucket in Amazon S3?", "answer": "S3 directory buckets are recommended for low-latency use cases due to their support for the S3 Express One Zone storage class, which provides faster data processing within a single Availability Zone.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T18:25:50.151173"}}
{"question": "How does the access method differ between a vector bucket and a general purpose bucket in Amazon S3?", "answer": "In a vector bucket, you do not use the S3 object APIs; instead, you use dedicated vector APIs to write vector data and query it based on semantic meaning and similarity. In contrast, a general purpose bucket allows for the storage and retrieval of objects using standard S3 object APIs.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T18:25:50.151390"}}
{"question": "What types of objects can be stored in a general purpose bucket in Amazon S3?", "answer": "A general purpose bucket in Amazon S3 can contain objects stored across all storage classes except for S3 Express One Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-04T18:25:54.545509"}}
{"question": "When would you recommend using an S3 directory bucket instead of a general purpose bucket?", "answer": "You would recommend using an S3 directory bucket for low-latency use cases, as it only allows objects stored in the S3 Express One Zone storage class, which provides faster data processing within a single Availability Zone.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-04T18:25:54.545856"}}
{"question": "How do S3 table buckets differ from S3 vector buckets in terms of data usage?", "answer": "S3 table buckets are purpose-built for storing tabular data and provide analytics capabilities such as row-level transactions and queryable table snapshots, while S3 vector buckets are designed for storing and querying vectors using dedicated vector APIs based on semantic meaning and similarity.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-04T18:25:54.546090"}}
{"question": "What is the primary function of Amazon S3?", "answer": "The primary function of Amazon S3 is to serve as a simple key-based object store where users can store and retrieve data using unique object keys.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-04T18:25:59.328903"}}
{"question": "How does S3 Object Tagging help users organize their data?", "answer": "S3 Object Tagging helps users organize their data across all of their S3 buckets and/or prefixes by allowing them to assign tags to objects, making it easier to categorize and manage data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-04T18:25:59.329236"}}
{"question": "How does the availability of the S3 Standard storage class compare to the S3 One Zone-IA storage class?", "answer": "The S3 Standard storage class is designed for 99.99% availability, while the S3 One Zone-IA storage class is designed for 99.5% availability, indicating that the S3 Standard class provides a higher level of availability than the One Zone-IA class.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-04T18:25:59.329432"}}
{"question": "What type of consistency does Amazon S3 deliver automatically?", "answer": "Amazon S3 delivers strong read-after-write consistency automatically.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-04T18:26:04.149258"}}
{"question": "Why is strong read-after-write consistency beneficial for high-performance computing workloads?", "answer": "Strong read-after-write consistency is beneficial for high-performance computing workloads because it ensures that when an object is overwritten and then read many times simultaneously, the latest write is read across all reads, providing assurance that users are accessing the most up-to-date data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-04T18:26:04.149608"}}
{"question": "How does the strong consistency of Amazon S3 affect costs compared to other methods of providing consistency?", "answer": "The strong consistency of Amazon S3 reduces costs by removing the need for extra infrastructure to provide strong consistency, which is an advantage over other methods that may require additional resources to ensure consistency.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-04T18:26:04.149934"}}
{"question": "What happens to objects stored in S3 Standard, S3 Standard-IA, S3 Intelligent-Tiering, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive storage classes?", "answer": "Objects in these storage classes are automatically stored across multiple devices spanning a minimum of three Availability Zones (AZs).", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T18:26:09.207710"}}
{"question": "Why should one use S3 storage classes for AWS Dedicated Local Zones?", "answer": "You should use S3 storage classes for AWS Dedicated Local Zones if you have sensitive data and applications that need to run on physically separate infrastructure dedicated to your exclusive use, and placed within a specified regulatory jurisdiction to address security and compliance requirements.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T18:26:09.208177"}}
{"question": "How do objects in directory buckets differ from those in S3 One Zone-IA storage class regarding their storage locations?", "answer": "Objects in directory buckets are stored redundantly within a single Availability Zone or single Local Zone, while objects in the S3 One Zone-IA storage class are also stored redundantly but specifically within a single Availability Zone.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-04T18:26:09.208535"}}
{"question": "What is an AWS Region?", "answer": "An AWS Region is a physical location around the world where AWS clusters data centers. Each AWS Region consists of a minimum of three, isolated, and physically separate Availability Zones (AZs) within a geographic area.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:26:14.670822"}}
{"question": "How do Availability Zones (AZs) enhance the availability and fault tolerance of applications?", "answer": "Availability Zones (AZs) enhance the availability and fault tolerance of applications by allowing customers to operate production applications and databases that are more highly available, fault tolerant, and scalable than would be possible from a single data center. Each AZ has independent power, cooling, and physical security, and they are interconnected with high-bandwidth, low-latency networking, which provides redundancy and reliability.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:26:14.671161"}}
{"question": "What is the difference between the data replication methods of Amazon S3 storage classes and the S3 One Zone-IA storage class?", "answer": "Amazon S3 storage classes such as S3 Standard, S3 Standard-Infrequent Access, S3 Intelligent-Tiering, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive replicate data across a minimum of three Availability Zones to protect against the loss of one entire AZ. In contrast, the S3 One Zone-IA storage class replicates data within a single AZ and is not resilient to the physical loss of that AZ due to disasters.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-04T18:26:14.671368"}}
{"question": "What factors should be considered when choosing an AWS Region for Amazon S3 storage?", "answer": "When choosing an AWS Region for Amazon S3 storage, you should consider factors such as the proximity to your customers or data centers to reduce data access latencies, the need for geographic redundancy and disaster recovery by selecting a remote Region, and the ability to meet specific legal and regulatory requirements. Additionally, you might want to select a Region that helps reduce storage costs by choosing a lower-priced Region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T18:26:21.765149"}}
{"question": "Why is it important to choose the right AWS Region for your Amazon S3 data?", "answer": "Choosing the right AWS Region for your Amazon S3 data is important because it can affect data access latencies, geographic redundancy, disaster recovery capabilities, compliance with legal and regulatory requirements, and overall storage costs. Selecting a Region that aligns with these factors can enhance performance and reliability for your specific application needs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T18:26:21.765496"}}
{"question": "How does data transfer pricing differ between within the same AWS Region and across different Regions for Amazon S3?", "answer": "Data transfer pricing for Amazon S3 differs in that there is no Data Transfer charge for data transferred within the same AWS Region via a COPY request. However, data transferred via a COPY request between different AWS Regions incurs charges as specified on the Amazon S3 pricing page. Additionally, there are no charges for data transferred between Amazon EC2 or any AWS service and Amazon S3 within the same Region, while charges apply for transfers across different Regions.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T18:26:21.767168"}}
{"question": "Are there any setup charges or commitments required to start using Amazon S3?", "answer": "No, there are no setup charges or commitments required to begin using Amazon S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-04T18:26:26.107985"}}
{"question": "What benefits does the AWS Free Usage Tier offer for new AWS customers using Amazon S3?", "answer": "The AWS Free Usage Tier allows new AWS customers to get started with Amazon S3 for free, providing 5 GB of Amazon S3 Standard storage, 20,000 Get Requests, 2,000 Put Requests, and 100 GB of data transfer out each month for one year, except in the AWS GovCloud Regions.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-04T18:26:26.108321"}}
{"question": "How do the charges for Amazon S3 differ between the US East (Northern Virginia) Region and the US West (Northern California) Region?", "answer": "Amazon S3 charges less in the US East (Northern Virginia) Region because the costs are lower there compared to the US West (Northern California) Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-04T18:26:26.108569"}}
{"question": "What is the total Byte-Hour usage calculated for the storage costs in the provided scenario?", "answer": "The total Byte-Hour usage is calculated as follows: [4,294,967,296 bytes x 31 days x (24 hours / day)] + [5,368,709,120 bytes x 16 days x (24 hours / day)] = 5,257,039,970,304 Byte-Hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-04T18:26:31.307919"}}
{"question": "How does object versioning affect the cost of storage in Amazon S3?", "answer": "Object versioning in Amazon S3 affects the cost of storage because each version of an object is stored and incurs charges. In the provided scenario, when a new version of an object is created by performing a PUT operation, the previous version is not deleted but preserved, resulting in additional storage costs for both versions.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-04T18:26:31.308240"}}
{"question": "What is the difference in storage costs between a single object and multiple versions of the same object in Amazon S3?", "answer": "The difference in storage costs between a single object and multiple versions of the same object in Amazon S3 is that a single object incurs a charge for its storage, while multiple versions of the same object incur charges for each version stored. In the example given, both the 4 GB object and the 5 GB object are charged separately since the older version is preserved when a new version is created.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-04T18:26:31.308612"}}
{"question": "What happens when your Amazon S3 storage is accessed by another AWS Account?", "answer": "Normal Amazon S3 pricing applies when your storage is accessed by another AWS Account.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-04T18:26:34.636787"}}
{"question": "What is a Requester Pays bucket in Amazon S3?", "answer": "A Requester Pays bucket is a configuration where the requester will pay the cost of requests and downloads of your Amazon S3 data instead of the bucket owner.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-04T18:26:34.637140"}}
{"question": "How does pricing differ between a normal Amazon S3 bucket and a Requester Pays bucket?", "answer": "In a normal Amazon S3 bucket, the bucket owner pays for the requests and downloads, while in a Requester Pays bucket, the requester is responsible for these costs.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-04T18:26:34.637575"}}
{"question": "What should you do first if you have a dedicated AWS account team?", "answer": "If you have a dedicated AWS account team, you should contact them first and inform them of your plans.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-04T18:26:37.661279"}}
{"question": "Why might it be important to discuss options with your AWS account team?", "answer": "It might be important to discuss options with your AWS account team if you have a negotiated commitment with AWS, as they can provide guidance tailored to your specific situation.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-04T18:26:37.661549"}}
{"question": "What are the steps to take if you want to inform AWS about your plans?", "answer": "The steps to take are: first, contact your dedicated AWS account team if you have one, second, review the criteria and process described on the page, and third, contact AWS Customer Support.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-04T18:26:37.662358"}}
{"question": "What must you indicate when requesting free data transfer to move off AWS?", "answer": "You must indicate that your request is for 'free data transfer to move off AWS.'", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:26:42.564374"}}
{"question": "What happens if AWS Customer Support approves your move off AWS?", "answer": "If AWS Customer Support approves your move, you will receive a temporary credit for the cost of data transfer out based on the volume of all data you have stored across AWS services at the time of AWS' calculation. You will then have 60 days to complete your move off of AWS, and the credit will count against data transfer out usage only.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:26:42.564693"}}
{"question": "How does the eligibility for free data transfer out differ for customers with less than 100 GB of data stored in their AWS account compared to those with more?", "answer": "Customers with less than 100 GB of data stored in their AWS account may move this data off of AWS for free under AWS's existing 100 GB monthly free tier for data transfer out. However, these customers are not eligible for additional credits, while customers with more than 100 GB may be eligible for credits if they meet other requirements.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:26:42.564895"}}
{"question": "What are the four steps to get started with S3 Vectors?", "answer": "To get started with S3 Vectors, you need to follow four steps: First, create a vector bucket in a specific AWS Region using the CreateVectorBucket API or in the S3 Console. Second, create a vector index in the vector bucket using the CreateIndex API or in the S3 Console, specifying the distance metric and the number of dimensions for the vectors. Third, add vector data to the vector index with the PutVectors API, optionally attaching metadata as key value pairs. Fourth, perform a similarity query with the QueryVectors API, specifying the vector to search for and the number of similar results to return.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-04T18:26:49.294093"}}
{"question": "Why is it important to specify a distance metric when creating a vector index?", "answer": "It is important to specify a distance metric when creating a vector index because the choice of distance metric, such as Cosine or Euclidean, can impact the accuracy of the results returned from similarity queries. For the most accurate results, it is recommended to select the distance metric that is advised by your embedding model.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-04T18:26:49.294387"}}
{"question": "How does creating a vector index differ from adding vector data to it?", "answer": "Creating a vector index involves specifying parameters such as the vector bucket, index name, distance metric, dimensions, and optionally a list of metadata fields to exclude from filtering. In contrast, adding vector data to a vector index with the PutVectors API involves inserting the actual vector data and can include attaching metadata as key value pairs for filtering during queries. Essentially, creating an index sets up the framework for organizing and querying the vector data, while adding data populates that framework.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-04T18:26:49.294925"}}
{"question": "What API do you use to add vectors to a vector index?", "answer": "You can add vectors to a vector index using the PutVectors API.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T18:26:53.073435"}}
{"question": "Why is it recommended to insert vectors in large batches when using the PutVectors API?", "answer": "It is recommended to insert vectors in large batches, up to the maximum request size, to maximize write throughput.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T18:26:53.073770"}}
{"question": "How does S3 Vectors compare to traditional storage in terms of durability and availability?", "answer": "S3 Vectors is designed for 11 9s of data durability and delivers 99.99% availability with an availability SLA of 99.9%, making it highly durable and available compared to traditional storage solutions.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-04T18:26:53.073974"}}
{"question": "What is the average recall percentage that S3 Vectors delivers for most datasets?", "answer": "S3 Vectors delivers over 90% average recall for most datasets.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-04T18:26:58.216705"}}
{"question": "How does average recall measure the quality of query results in S3 Vectors?", "answer": "Average recall measures the quality of query results by indicating the percentage of the ground truth closest vectors, stored in the index, that are included in the response to a query vector. An average recall of 90% means that 90% of the closest vectors to the query vector are found in the response.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-04T18:26:58.217066"}}
{"question": "What are the differences between using an existing S3 vector index and letting Bedrock create a new vector index for RAG workflows?", "answer": "When using an existing S3 vector index for RAG workflows, you can save on vector storage costs. In contrast, if you let Bedrock create and manage the vector index for you, you can use the Quick Create workflow in the Bedrock console, which may simplify the setup process but does not offer the same cost-saving on storage.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-04T18:26:58.217447"}}
{"question": "What are the two ways to use S3 Vectors with Amazon OpenSearch Service?", "answer": "The two ways to use S3 Vectors with Amazon OpenSearch Service are: First, S3 customers can export all vectors from an S3 vector index to OpenSearch Serverless as a new serverless collection using either the S3 or OpenSearch console. Second, managed OpenSearch customers can choose S3 Vectors as their engine for vector data that can be queried with sub-second latency, allowing OpenSearch to use S3 Vectors as the underlying engine for vectors while enabling updates and searches through the OpenSearch APIs.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T18:27:05.915467"}}
{"question": "What benefits do users gain by using S3 Vectors with Amazon OpenSearch Service?", "answer": "Users gain several benefits by using S3 Vectors with Amazon OpenSearch Service, including the ability to selectively use OpenSearch Serverless for workloads with real-time query needs, the cost benefits of S3 Vectors, and the capability to update and search vector data using OpenSearch APIs without requiring changes to their applications.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T18:27:05.915842"}}
{"question": "How does IPv6 support for Amazon S3 compare to using IPv4 in terms of application integration and compliance?", "answer": "Using IPv6 support for Amazon S3 allows applications to connect to Amazon S3 without the need for IPv6 to IPv4 translation software, which simplifies integration with existing IPv6-based on-premises applications and helps meet compliance requirements. In contrast, IPv4 may require additional networking equipment to handle address translation, which can incur extra costs.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-04T18:27:05.915996"}}
{"question": "What type of endpoint should you point your application to for accessing Amazon S3 over both IPv4 and IPv6?", "answer": "You should point your application to Amazon S3s 'dual-stack' endpoint, which supports access over both IPv4 and IPv6.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-04T18:27:10.747947"}}
{"question": "How does Amazon S3 Event Notifications enhance the functionality of S3 buckets?", "answer": "Amazon S3 Event Notifications enhance the functionality of S3 buckets by allowing users to receive notifications when certain events occur, such as PUT, POST, COPY, and DELETE events. This feature enables users to run workflows, send alerts, or perform actions in response to changes in their objects stored in S3, such as transcoding media files or synchronizing S3 objects with other data stores.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-04T18:27:10.748283"}}
{"question": "Is there any performance difference between using IPv4 and IPv6 with Amazon S3?", "answer": "No, you will see the same performance when using either IPv4 or IPv6 with Amazon S3.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-04T18:27:10.748784"}}
{"question": "Are there any additional charges for using Amazon S3 for event notifications?", "answer": "No, there are no additional charges for using Amazon S3 for event notifications. You only pay for the use of Amazon SNS or Amazon SQS to deliver event notifications, or for the cost of running an AWS Lambda function.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-04T18:27:16.780334"}}
{"question": "How does Amazon S3 Transfer Acceleration improve file transfers over long distances?", "answer": "Amazon S3 Transfer Acceleration improves file transfers over long distances by leveraging Amazon CloudFronts globally distributed AWS Edge locations. As data arrives at an AWS Edge Location, it is routed to your Amazon S3 bucket over an optimized network path, resulting in faster, easier, and more secure transfers.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-04T18:27:16.780690"}}
{"question": "What are the differences between using the s3-accelerate endpoint and the regular endpoints for data transfer?", "answer": "The s3-accelerate endpoint is specifically designed for faster data transfer, utilizing S3 Transfer Acceleration, while the regular endpoints are used for standard data transfer. To take advantage of faster data transfers, you must enable S3 Transfer Acceleration and use either the .s3-accelerate.amazonaws.com or .s3-accelerate.dualstack.amazonaws.com endpoints. If you choose to use standard data transfer, you can continue using the regular endpoints.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-04T18:27:16.781031"}}
{"question": "What factors primarily influence the amount of acceleration provided by S3 Transfer Acceleration?", "answer": "The amount of acceleration primarily depends on your available bandwidth, the distance between the source and destination, and packet loss rates on the network path.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-04T18:27:22.697710"}}
{"question": "How does S3 Transfer Acceleration optimize data transfer speeds for users uploading data from different locations?", "answer": "S3 Transfer Acceleration is designed to optimize transfer speeds from across the world into S3 buckets. It is particularly beneficial when uploading to a centralized bucket from geographically dispersed locations or when regularly transferring GBs or TBs of data across continents, potentially saving hours or days of data transfer time.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-04T18:27:22.698068"}}
{"question": "In what scenarios might S3 Transfer Acceleration be more beneficial compared to regular Amazon S3 transfers?", "answer": "S3 Transfer Acceleration might be more beneficial when the source is farther from the destination, when there is more available bandwidth, and/or when the object size is bigger. For example, one customer experienced a 50% reduction in the average time to ingest 300 MB files from users across the US, Europe, and parts of Asia to a bucket in the Asia Pacific (Sydney) Region, while another customer saw performance improvements exceeding 500% for users in South East Asia and Australia uploading 250 MB files to an S3 bucket in the US East (N. Virginia) Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-04T18:27:22.698281"}}
{"question": "Does S3 Transfer Acceleration support multipart uploads?", "answer": "Yes, S3 Transfer Acceleration supports all bucket level features including multipart uploads.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-04T18:27:27.793515"}}
{"question": "When should I consider using Amazon CloudFront's PUT/POST commands instead of S3 Transfer Acceleration?", "answer": "You should consider using Amazon CloudFront's PUT/POST commands if you have objects that are smaller than 1 GB or if the data set is less than 1 GB in size for optimal performance.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-04T18:27:27.794639"}}
{"question": "How does S3 Transfer Acceleration compare to AWS Direct Connect for data transfer?", "answer": "S3 Transfer Acceleration is best for submitting data from distributed client locations over the public internet or where variable network conditions make throughput poor, while AWS Direct Connect is a good choice for customers who have a private networking requirement. Some AWS Direct Connect customers also use S3 Transfer Acceleration to help with remote office transfers where they may experience poor internet performance.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-04T18:27:27.794890"}}
{"question": "What is the default access level for Amazon S3 buckets upon creation?", "answer": "Upon creation, only you have access to Amazon S3 buckets that you create, meaning the default access level is secure and private.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-04T18:27:32.718853"}}
{"question": "Why is it important to enable Amazon S3 Block Public Access?", "answer": "Enabling Amazon S3 Block Public Access is important for all accounts and buckets that you do not want publicly accessible, as it helps prevent unintended public access to your data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-04T18:27:32.719181"}}
{"question": "How do bucket policies compare to IAM policies for controlling access to Amazon S3 resources?", "answer": "Both bucket policies and IAM policies are mechanisms for controlling access to Amazon S3 resources, but bucket policies are specifically attached to S3 buckets and define permissions for those buckets, while IAM policies are attached to IAM users, groups, or roles, allowing for broader access control across AWS services.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-04T18:27:32.719357"}}
{"question": "What type of encryption does Amazon S3 apply to all new data uploads as of January 5, 2023?", "answer": "Amazon S3 applies S3-managed server-side encryption (SSE-S3) as the base level of encryption to all object uploads.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-04T18:27:37.449853"}}
{"question": "What are the advantages of using SSE-S3 for encryption in Amazon S3?", "answer": "SSE-S3 provides a fully-managed solution where Amazon handles key management and key protection using multiple layers of security. It is advantageous for users who prefer to have Amazon manage their keys.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-04T18:27:37.450414"}}
{"question": "How does SSE-C differ from SSE-S3 in terms of key management?", "answer": "With SSE-C, you retain control of the encryption keys while Amazon S3 performs encryption and decryption of objects. In contrast, SSE-S3 is fully managed by Amazon, meaning they handle key management and protection.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-04T18:27:37.450599"}}
{"question": "What are some benefits of using AWS KMS to manage encryption keys?", "answer": "Using AWS KMS to manage your keys provides several benefits, including separate permissions for KMS key usage, an audit trail to track who accessed which object and when, visibility into failed access attempts by unauthorized users, and additional security controls to comply with industry requirements such as PCI-DSS, HIPAA/HITECH, and FedRAMP.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-24", "source_tokens": 509, "generated_at": "2026-02-04T18:27:44.117759"}}
{"question": "How does DSSE-KMS enhance encryption for data stored in Amazon S3?", "answer": "DSSE-KMS enhances encryption for data stored in Amazon S3 by simplifying the process of applying two layers of encryption to data, utilizing different implementations of the 256-bit Advanced Encryption Standard with Galois Counter Mode (AES-GCM) algorithm. This dual-layer encryption is suitable for top-secret workloads and is managed through AWS KMS, which generates data keys.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-24", "source_tokens": 509, "generated_at": "2026-02-04T18:27:44.118841"}}
{"question": "How does client-side encryption differ from using AWS KMS for encryption management?", "answer": "Client-side encryption differs from using AWS KMS in that it allows customers to retain full control over their encryption keys and perform the encryption and decryption of objects on the client side using a library of their choice. In contrast, AWS KMS manages the encryption keys and provides additional permissions and auditing features, which may not be available with client-side encryption.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-24", "source_tokens": 509, "generated_at": "2026-02-04T18:27:44.119132"}}
{"question": "What is the purpose of using encryption in data protection?", "answer": "The purpose of using encryption in data protection is to secure sensitive information by converting it into a format that cannot be easily understood by unauthorized users.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-04T18:27:47.862819"}}
{"question": "What type of documentation discusses protecting data using encryption?", "answer": "The documentation that discusses protecting data using encryption is specifically focused on encryption methods and best practices for securing data.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-04T18:27:47.863203"}}
{"question": "How does encryption relate to data security compared to other methods of data protection?", "answer": "Encryption is a specific method of data protection that focuses on transforming data into an unreadable format, whereas other methods might include access controls, physical security measures, or data masking. Each method addresses different aspects of data security.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-04T18:27:47.863428"}}
{"question": "What regions can customers choose to store all their data in Europe?", "answer": "Customers can choose to store all data in Europe by using the Europe (Frankfurt), Europe (Ireland), Europe (Paris), Europe (Stockholm), Europe (Milan), Europe (Spain), Europe (London), or Europe (Zurich) Region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-04T18:27:51.935234"}}
{"question": "What is the responsibility of customers regarding data storage in Europe?", "answer": "It is the customer's responsibility to ensure that they comply with European privacy laws when storing data in Europe.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-04T18:27:51.935516"}}
{"question": "What is the difference between gateway VPC endpoints and interface VPC endpoints for Amazon S3?", "answer": "Gateway VPC endpoints are specified in your route table to access S3 from your VPC over the AWS network, while interface VPC endpoints extend the functionality of gateway endpoints by using private IPs to route requests to S3 from within your VPC, on-premises, or from a different AWS Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-04T18:27:51.935696"}}
{"question": "What condition can be used in S3 bucket policies to restrict access to a specific Amazon VPC Endpoint?", "answer": "The condition that can be used in S3 bucket policies to restrict access to a specific Amazon VPC Endpoint is aws:sourceVpce.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-04T18:27:56.345141"}}
{"question": "Why does AWS recommend using interface VPC endpoints for accessing S3 from on-premises or from a VPC in another AWS Region?", "answer": "AWS recommends using interface VPC endpoints for accessing S3 from on-premises or from a VPC in another AWS Region because they provide private connectivity, eliminating the need to use public IPs, change firewall rules, or configure an internet gateway.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-04T18:27:56.345476"}}
{"question": "How do interface VPC endpoints differ from gateway VPC endpoints in terms of billing when accessing S3 from a VPC in the same AWS Region?", "answer": "Interface VPC endpoints are billed, while gateway VPC endpoints are not billed when accessing S3 from a VPC in the same AWS Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-04T18:27:56.345659"}}
{"question": "What type of data does Amazon Macie help to discover and classify?", "answer": "Amazon Macie helps to discover and classify sensitive data stored in Amazon S3, such as personally identifiable information (PII) and intellectual property.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-04T18:28:01.083128"}}
{"question": "How does Amazon Macie enhance data security within an organization?", "answer": "Amazon Macie enhances data security by automatically discovering, classifying, and protecting sensitive data, continuously monitoring data access activity for anomalies, and delivering alerts for unauthorized access or data leaks, thereby allowing organizations to take swift action.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-04T18:28:01.083472"}}
{"question": "In what ways does Amazon Macie respond to suspicious behavior compared to standard security measures?", "answer": "Amazon Macie responds to suspicious behavior by providing controls via templated Lambda functions to revoke access or trigger password reset policies, which is more automated and low-touch compared to standard security measures that may require manual intervention.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-04T18:28:01.083896"}}
{"question": "What is the purpose of Access Analyzer for S3?", "answer": "The purpose of Access Analyzer for S3 is to help simplify permissions management by allowing you to set, verify, and refine policies for your S3 buckets and access points. It monitors existing access policies to ensure they provide only the required access to S3 resources and helps you discover and make changes to buckets that do not require access.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-04T18:28:05.926782"}}
{"question": "How does Access Analyzer for S3 assist in managing bucket permissions?", "answer": "Access Analyzer for S3 assists in managing bucket permissions by evaluating bucket access policies, alerting you when a bucket allows access to anyone on the internet or is shared with other AWS accounts, and providing findings about the source and level of public or shared access. It also allows you to block public access with a single click and configure granular levels of access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-04T18:28:05.927038"}}
{"question": "What is the difference between Access Analyzer for S3 and S3 Access Grants?", "answer": "Access Analyzer for S3 focuses on monitoring and verifying access policies for S3 buckets, alerting users about potential security issues, and providing findings to refine access. In contrast, S3 Access Grants map identities from directories to datasets in S3, automatically managing data permissions at scale and logging end-user access in AWS CloudTrail for detailed audit history.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-04T18:28:05.927200"}}
{"question": "What are the steps to get started with S3 Access Grants?", "answer": "To get started with S3 Access Grants, you need to follow four steps: First, configure an S3 Access Grants instance and, if using corporate directory users and groups, enable AWS Identity Center and connect it to your S3 Access Grants instance. Second, register a location with S3 Access Grants by providing an IAM role for creating temporary S3 credentials. Third, define permission grants that specify who can access what. Finally, have your application request temporary credentials from S3 Access Grants to access S3 using the Access Grants-vended credentials.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-04T18:28:11.840913"}}
{"question": "What types of identities does S3 Access Grants support?", "answer": "S3 Access Grants supports two types of identities: enterprise user or group identities from AWS Identity Center, and AWS IAM principals which include IAM users and roles. This allows for scalable and auditable access control based on directory group memberships or custom identity federations.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-04T18:28:11.841450"}}
{"question": "How do the access levels of S3 Access Grants compare to each other?", "answer": "S3 Access Grants offers three access levels: READ, WRITE, and READWRITE. The READ level allows users to view and retrieve objects from S3. The WRITE level allows users to write to and delete from S3. The READWRITE level combines both permissions, allowing users to perform both READ and WRITE actions.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-04T18:28:11.841686"}}
{"question": "What is the maximum number of grants and locations you can create per S3 Access Grants instance?", "answer": "You can create up to 100,000 grants and up to 1,000 locations per S3 Access Grants instance.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-04T18:28:16.433767"}}
{"question": "How does the latency for obtaining temporary credentials from S3 Access Grants compare to obtaining temporary credentials from AWS STS?", "answer": "The latency for obtaining temporary credentials from S3 Access Grants is similar to obtaining temporary credentials from AWS STS. Additionally, once you have obtained the credentials from S3 Access Grants, you can reuse unexpired credentials for subsequent requests without any additional latency.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-04T18:28:16.434140"}}
{"question": "How does the initialization of the S3 client differ when using S3 Access Grants compared to using traditional IAM credentials?", "answer": "When using S3 Access Grants, you need to obtain S3 Access Grants credentials specific to the authenticated user in your application before initializing the S3 client. In contrast, traditionally, you would initialize your S3 client with IAM credentials associated with your application, such as IAM role credentials for EC2 or long-term IAM user credentials.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-04T18:28:16.434352"}}
{"question": "What does S3 Access Grants work well with?", "answer": "S3 Access Grants works well with existing IAM-based data protection strategies, including encryption, network, and data-perimeter rules.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-04T18:28:20.967531"}}
{"question": "How do S3 Access Grants and IAM work together for managing permissions?", "answer": "S3 Access Grants is built on IAM primitives and enables you to express finer-grained S3 permissions at scale. Bucket owners must include the necessary KMS permissions in the IAM role they grant to S3 Access Grants, allowing S3 Access Grants to utilize that IAM role to access KMS-encrypted objects in the buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-04T18:28:20.967851"}}
{"question": "What is the difference between S3 Access Grants and AWS Lake Formation in terms of data access management?", "answer": "S3 Access Grants is specifically for managing access to direct S3 permissions for unstructured data such as videos, images, and logs, while AWS Lake Formation is intended for managing access to tabular data, such as Glue tables, where row- and column-level access enforcement may be necessary.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-04T18:28:20.968025"}}
{"question": "What are Amazon S3 Access Points used for?", "answer": "Amazon S3 Access Points are endpoints that simplify managing data access for any application or AWS service that works with S3. They allow you to control and simplify how different applications or users can access data by creating access points with names and permissions tailored to each application or user.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:28:26.954958"}}
{"question": "How do S3 Access Points enhance data access management compared to traditional bucket policies?", "answer": "S3 Access Points enhance data access management by allowing users to create hundreds of access points per bucket, each providing a customized path into a bucket with a unique hostname and access policy. This eliminates the need to manage a single, complex bucket policy with hundreds of different permission rules, simplifying the management and auditing of data access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:28:26.955378"}}
{"question": "How do S3 Access Points relate to FSx for OpenZFS file systems?", "answer": "S3 Access Points work with FSx for OpenZFS by allowing users to access their FSx data using the S3 API, treating the data as if it were in S3. This capability enables the file data in FSx for OpenZFS to be used with various artificial intelligence, machine learning, and analytics services and applications that work with S3, while the actual file data remains on the FSx for OpenZFS file system.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:28:26.955644"}}
{"question": "What is the purpose of S3 Access Points in relation to Amazon FSx for OpenZFS?", "answer": "S3 Access Points allow you to access file data in Amazon FSx for OpenZFS using S3 APIs without moving data to S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-04T18:28:31.074656"}}
{"question": "How do S3 Access Points attached to FSx for OpenZFS file systems function in comparison to those attached to S3 buckets?", "answer": "S3 Access Points attached to FSx for OpenZFS file systems work similarly to those attached to S3 buckets by providing data access via S3 with access controlled by access policies, while the data continues to be stored in either FSx for OpenZFS file systems or S3 buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-04T18:28:31.074942"}}
{"question": "What types of services and applications can benefit from using S3 Access Points with FSx for OpenZFS data?", "answer": "Customers can use S3 Access Points with generative AI, machine learning, and analytics services and applications that work with S3 to access their FSx for OpenZFS data.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-04T18:28:31.075107"}}
{"question": "What is the maximum number of S3 Access Points you can create per Region per account?", "answer": "By default, you can create 10,000 S3 Access Points per Region per account on buckets in your account and cross-account. However, there is no hard limit on the number of S3 Access Points per AWS account.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-04T18:28:36.334318"}}
{"question": "How do S3 Access Points enhance management of access for different users and applications?", "answer": "S3 Access Points enhance management of access by allowing you to create an access point for specific use cases or applications, which can support a single user or application, or groups of users or applications within and across accounts. This allows for separate management of each access point, making it easier to control permissions and access to data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-04T18:28:36.334662"}}
{"question": "What are the differences between the two ways to access data in shared buckets through an access point?", "answer": "The two ways to access data in shared buckets through an access point are: using the access point ARN in place of a bucket name for S3 object operations, and using an access point alias instead when requests require a bucket name in the standard S3 bucket name format. Access point aliases are automatically generated and can be used interchangeably with S3 bucket names for data access.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-04T18:28:36.335134"}}
{"question": "What is the purpose of S3 access point policies?", "answer": "S3 access point policies are used to grant or restrict access to the S3 data requested through the access point. They work similarly to bucket policies and are evaluated alongside other relevant policies to decide whether to authorize a request.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:28:43.163631"}}
{"question": "How can AWS Organizations Service Control Policies (SCPs) be utilized with S3 access points?", "answer": "AWS Organizations Service Control Policies (SCPs) can be utilized to enforce that any access point created in your organization sets the 'network origin control' API parameter value to 'vpc'. This mandates that any new access point automatically restricts data access to VPC-only traffic, ensuring that no additional access policy is required for this restriction.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:28:43.163965"}}
{"question": "How do access points differ from bucket policies in terms of enforcing VPC-only traffic?", "answer": "Access points provide an easier and auditable way to restrict access to VPC-only traffic for all applications in an organization, compared to bucket policies. While bucket policies can limit access to specified VPCs, access points can be mandated to enforce VPC-only access automatically through AWS SCPs, without needing additional access policies.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:28:43.164190"}}
{"question": "What happens to access to an S3 bucket when an access point is removed?", "answer": "When you remove an access point, any access to the associated bucket through other access points, and through the bucket hostname, will not be disrupted.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-04T18:28:47.872857"}}
{"question": "What is the durability percentage of Amazon S3 and how is this achieved?", "answer": "Amazon S3 is designed to provide 99.999999999% (11 nines) data durability. This is achieved through its unique architecture, which stores data redundantly across a minimum of 3 Availability Zones (AZ) by default, providing built-in resilience against widespread disaster.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-04T18:28:47.873201"}}
{"question": "How does storing data in multiple Availability Zones (AZs) compare to storing data in a single AZ in terms of resilience?", "answer": "Storing data in multiple Availability Zones (AZs) provides resilience against the permanent loss of an entire data center, while storing data in a single AZ minimizes storage cost or latency but does not offer the same level of resilience against data loss.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-04T18:28:47.873442"}}
{"question": "What is a potential risk associated with using the One Zone storage class in AWS?", "answer": "The potential risk associated with using the One Zone storage class in AWS is that data may be lost in the unlikely case of loss or damage to all or part of an AWS Availability Zone. Events such as fire and water damage could lead to this data loss.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-04T18:28:53.095960"}}
{"question": "How does Amazon S3 ensure data durability?", "answer": "Amazon S3 ensures data durability through a strong durability culture, where durability best practices are integrated into systems and software from the ground up. S3 is designed to deliver 99.999999999% data durability, and AWS leverages its extensive experience operating high-durability storage to mitigate risks and incorporate safeguards.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-04T18:28:53.096312"}}
{"question": "How do One Zone storage classes compare to Regional storage classes in terms of durability?", "answer": "One Zone storage classes and Regional storage classes are designed using similar engineering designs to protect objects from independent disk, host, and rack-level failures. However, while both types are designed to deliver 99.999999999% data durability, One Zone storage classes are at risk of data loss if there is damage to the Availability Zone, whereas Regional storage classes do not have this specific risk.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-04T18:28:53.096481"}}
{"question": "What mechanisms does Amazon S3 use to verify data integrity?", "answer": "Amazon S3 uses a combination of Content-MD5 checksums, secure hash algorithms (SHAs), and cyclic redundancy checks (CRCs) to verify data integrity. It performs checksums on data at rest and repairs any disparity using redundant data.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-04T18:28:57.293006"}}
{"question": "Why is using checksums for data validation considered a best practice in Amazon S3?", "answer": "Using checksums for data validation is considered a best practice for data durability because these capabilities increase performance and reduce the cost of ensuring data integrity.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-04T18:28:57.293350"}}
{"question": "How does the handling of object versions differ when versioning is enabled in an Amazon S3 bucket?", "answer": "When versioning is enabled in an Amazon S3 bucket, Amazon S3 preserves existing objects anytime a PUT, POST, COPY, or DELETE operation is performed on them. By default, GET requests will retrieve the most recently written version, while older versions can be retrieved by specifying a version in the request.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-04T18:28:57.293758"}}
{"question": "What does Amazon S3 Versioning provide for customers?", "answer": "Amazon S3 Versioning provides customers with an additional level of protection by allowing them to recover from accidental overwrites or deletions of objects. It helps in easily recovering from unintended user actions and application failures, and can also be used for data retention and archiving.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-04T18:29:02.800538"}}
{"question": "How can Lifecycle rules be used in conjunction with S3 Versioning?", "answer": "Lifecycle rules can be used along with S3 Versioning to implement a rollback window for S3 objects. For instance, you can set up a rule that archives all previous versions to the lower-cost S3 Glacier Flexible Retrieval storage class and deletes them after a specified period, such as 100 days, allowing a rollback option while reducing storage costs. Additionally, old (noncurrent) versions can be deleted after five days if there are at least two newer versions.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-04T18:29:02.800883"}}
{"question": "What happens when a DELETE operation is performed on an object in an S3 bucket with Versioning enabled, and how does it compare to a bucket without Versioning?", "answer": "When a DELETE operation is performed on an object in an S3 bucket with Versioning enabled, all versions of that object continue to be preserved and can be retrieved or restored. In contrast, if Versioning is not enabled, subsequent simple requests will no longer retrieve the object after it is deleted. This highlights the primary difference where Versioning allows for recovery of previous versions while non-versioned buckets do not retain deleted objects.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-04T18:29:02.801097"}}
{"question": "What is required to permanently delete a version of an object in an Amazon S3 bucket with MFA Delete enabled?", "answer": "To permanently delete a version of an object in an Amazon S3 bucket with MFA Delete enabled, two forms of authentication are required: your AWS account credentials and a valid six-digit code and serial number from an authentication device in your physical possession.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-04T18:29:09.681936"}}
{"question": "How does enabling Versioning with MFA Delete enhance the security of an Amazon S3 bucket?", "answer": "Enabling Versioning with MFA Delete enhances the security of an Amazon S3 bucket by requiring two forms of authentication to permanently delete an object version, thus providing an additional layer of security beyond just using AWS account credentials.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-04T18:29:09.682277"}}
{"question": "What are the differences between standard Versioning and Versioning with MFA Delete in Amazon S3?", "answer": "The key difference between standard Versioning and Versioning with MFA Delete in Amazon S3 is that while standard Versioning allows for the deletion of object versions using only AWS account credentials, Versioning with MFA Delete requires an additional layer of security by also requiring a valid six-digit code and serial number from an authentication device.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-04T18:29:09.682471"}}
{"question": "What storage costs apply when using versioning in Amazon S3?", "answer": "Normal Amazon S3 rates apply for every version of an object stored or requested.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-04T18:29:14.789366"}}
{"question": "How does versioning in Amazon S3 affect the storage of objects?", "answer": "When versioning is enabled in Amazon S3, the previous version of an object is not deleted when a new version is written. Instead, the previous version is preserved as an older version, and the new version becomes the most recently written version of the object within the bucket.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-04T18:29:14.789720"}}
{"question": "How do the storage costs of the 4 GB and 5 GB objects differ in the given example?", "answer": "In the example, the storage cost for the 4 GB object is calculated for the entire month (31 days), while the storage cost for the 5 GB object is calculated for 16 days. Thus, the 4 GB object contributes to the total Byte-Hour usage for a longer duration than the 5 GB object, despite the 5 GB object being larger.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-04T18:29:14.789962"}}
{"question": "What is the main purpose of Amazon S3 Object Lock?", "answer": "The main purpose of Amazon S3 Object Lock is to prevent an object version from being deleted or overwritten for a fixed amount of time or indefinitely, allowing users to enforce retention policies as an added layer of data protection or for regulatory compliance.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-04T18:29:19.823955"}}
{"question": "In what scenarios should you consider using S3 Object Lock?", "answer": "You should consider using S3 Object Lock if you have regulatory requirements that specify that data must be WORM protected, or if you want to add an additional layer of protection to data in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-04T18:29:19.824206"}}
{"question": "How does S3 Object Lock maintain protection during S3 Lifecycle transitions?", "answer": "S3 Object Lock protection is maintained regardless of which storage class the object version resides in and throughout S3 Lifecycle transitions between storage classes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-04T18:29:19.824401"}}
{"question": "What does Amazon S3 Object Lock do?", "answer": "Amazon S3 Object Lock prevents deletion of an object version for the duration of a specified retention period or indefinitely until a legal hold is removed. It ensures that an object version remains immutable for as long as WORM protection is applied.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-04T18:29:24.434753"}}
{"question": "What is the difference between the Retain Until Date and a Legal Hold in S3 Object Lock?", "answer": "The Retain Until Date defines a specific length of time for which an object version will remain immutable, and once assigned, the object version cannot be modified or deleted until that date has passed. In contrast, a Legal Hold prevents an object version from being modified or deleted indefinitely until it is explicitly removed, regardless of the Retain Until Date.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-04T18:29:24.435149"}}
{"question": "How do Governance Mode and Compliance Mode differ in S3 Object Lock?", "answer": "In Governance Mode, AWS accounts with specific IAM permissions can remove WORM protection from an object version. However, in Compliance Mode, WORM protection cannot be removed by any user, including the root account, providing a stronger level of immutability to comply with regulations.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-04T18:29:24.435376"}}
{"question": "What is required to set up S3 Replication from a bucket with S3 Object Lock enabled?", "answer": "To set up S3 Replication from a bucket with S3 Object Lock enabled, you need to add a replication configuration on your source bucket, specifying a destination bucket in the same or different AWS Region and account. You must choose to replicate either all objects at the bucket level or filter them on a shared prefix or object level using S3 object tags. Additionally, you need to specify an IAM role with the required permissions and ensure that S3 Versioning is enabled for both the source and destination buckets. Lastly, the destination bucket must also have S3 Object Lock enabled.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-45", "source_tokens": 462, "generated_at": "2026-02-04T18:29:32.516939"}}
{"question": "Why is it necessary to grant specific permissions such as s3:GetObjectRetention and s3:GetObjectLegalHold for S3 Replication?", "answer": "It is necessary to grant specific permissions like s3:GetObjectRetention and s3:GetObjectLegalHold for S3 Replication to ensure that the IAM role used to set up the replication can access the required object retention and legal hold information on the source bucket. This is crucial for proper replication of objects that have S3 Object Lock enabled. Alternatively, having the broader permission s3:Get* will also satisfy this requirement.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-45", "source_tokens": 462, "generated_at": "2026-02-04T18:29:32.517242"}}
{"question": "How does S3 Replication for S3 Object Lock buckets compare to general S3 Replication features?", "answer": "S3 Replication for S3 Object Lock buckets supports all features of S3 Replication, including S3 Same-Region Replication (S3 SRR), S3 Cross-Region Replication (S3 CRR), S3 Replication metrics, S3 Replication Time Control (S3 RTC), and S3 Batch Replication. This means that users can utilize the same replication capabilities even when replicating from S3 Object Lock enabled buckets.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-45", "source_tokens": 462, "generated_at": "2026-02-04T18:29:32.517493"}}
{"question": "What factors should I consider when choosing an S3 storage class?", "answer": "When choosing an S3 storage class, you should consider the access patterns and retention time of your data to optimize for the lowest total cost over the lifetime of your data.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-04T18:29:37.033718"}}
{"question": "How do S3 storage classes help in managing costs for different workloads?", "answer": "S3 storage classes are purpose-built to provide the lowest cost storage for different access patterns, which helps in managing costs based on the specific data access, resiliency, and cost requirements of your workloads.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-04T18:29:37.034106"}}
{"question": "In what ways are S3 storage classes suitable for various use cases, and how do they differ in terms of costs?", "answer": "S3 storage classes are suitable for virtually any use case, including those with demanding performance needs, data residency requirements, unknown or changing access patterns, or archival storage. Each S3 storage class charges a fee to store data and also fees to access data, thus differing in terms of costs based on the specific requirements of the workload.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-04T18:29:37.034563"}}
{"question": "What is the recommended default storage class for workloads with changing or unpredictable access patterns?", "answer": "The recommended default storage class for workloads with changing, unpredictable, or unknown access patterns is S3 Intelligent-Tiering, as it automatically saves on storage costs.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-04T18:29:41.263112"}}
{"question": "Why might S3 Glacier Deep Archive be the best choice for long-lived archive storage?", "answer": "S3 Glacier Deep Archive is the best choice for long-lived archive storage because it offers the lowest cost storage in the cloud and is suitable for use cases such as compliance archives and digital media preservation, with data retrieval within 12 hours.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-04T18:29:41.263395"}}
{"question": "How does S3 Glacier Instant Retrieval differ from S3 Glacier Flexible Retrieval in terms of data access speed?", "answer": "S3 Glacier Instant Retrieval provides immediate access to archive data with retrieval in milliseconds, while S3 Glacier Flexible Retrieval does not require immediate access but allows retrieval in minutes or free bulk retrievals in 512 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-04T18:29:41.263583"}}
{"question": "What storage class can be selected for data with a lower resiliency requirement?", "answer": "For data that has a lower resiliency requirement, you can select the S3 One Zone-Infrequent Access storage class.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-04T18:29:45.014160"}}
{"question": "How can costs be reduced when dealing with data that has lower resiliency requirements?", "answer": "Costs can be reduced by selecting a single-AZ storage class, such as S3 One Zone-Infrequent Access, for data that has a lower resiliency requirement.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-04T18:29:45.014477"}}
{"question": "What options are available for storing data that has residency or isolation requirements that cannot be met by an existing AWS Region?", "answer": "For data with residency or isolation requirements that can't be met by an existing AWS Region, you can use S3 storage classes for AWS Dedicated Local Zones or S3 on Outposts racks to store your data in a specific perimeter.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-04T18:29:45.014652"}}
{"question": "What is S3 Intelligent-Tiering and how does it help reduce storage costs?", "answer": "S3 Intelligent-Tiering is a cloud storage service that automatically reduces storage costs on a granular object level by moving data to the most cost-effective access tier based on access frequency. It does this without performance impact, retrieval fees, or operational overhead.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-04T18:29:48.835764"}}
{"question": "How does S3 Intelligent-Tiering determine when to move objects between tiers?", "answer": "S3 Intelligent-Tiering monitors access patterns and automatically moves objects from one tier to another based on the frequency of access. This process is facilitated for a small monthly object monitoring and automation charge.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-04T18:29:48.836087"}}
{"question": "How does S3 Intelligent-Tiering compare to other storage classes in terms of retrieval fees?", "answer": "Unlike other storage classes that may have retrieval fees, S3 Intelligent-Tiering does not impose any retrieval charges. This means that users will not experience unexpected increases in storage bills when access patterns change.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-04T18:29:48.836280"}}
{"question": "What is the main purpose of the Amazon S3 Intelligent-Tiering storage class?", "answer": "The main purpose of the Amazon S3 Intelligent-Tiering storage class is to optimize storage costs by automatically moving data to the most cost-effective access tier when access patterns change.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-04T18:29:52.347760"}}
{"question": "How does S3 Intelligent-Tiering determine when to move objects to the Infrequent Access tier?", "answer": "S3 Intelligent-Tiering determines when to move objects to the Infrequent Access tier by monitoring access patterns and automatically moving objects that have not been accessed for 30 consecutive days.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-04T18:29:52.348148"}}
{"question": "What are the differences in cost savings between the Archive Instant Access tier and the Deep Archive Access tier?", "answer": "The Archive Instant Access tier saves up to 68% on storage costs after 90 days of no access, whereas the Deep Archive Access tier saves up to 95% on storage costs after 180 days of no access.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-04T18:29:52.348328"}}
{"question": "What is the minimum object size requirement for S3 Intelligent-Tiering?", "answer": "There is no minimum object size for S3 Intelligent-Tiering, but objects smaller than 128KB are not eligible for auto-tiering.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-04T18:29:56.950941"}}
{"question": "How does S3 Intelligent-Tiering ensure data availability and durability?", "answer": "S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, providing the same low latency and high throughput performance as S3 Standard.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-04T18:29:56.951190"}}
{"question": "How do the charges for objects smaller than 128KB in S3 Intelligent-Tiering compare to larger objects?", "answer": "Objects smaller than 128KB stored in S3 Intelligent-Tiering are always charged at the Frequent Access tier rates and are not charged the monitoring and automation charge, while larger objects can be eligible for auto-tiering.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-04T18:29:56.951367"}}
{"question": "What is S3 Intelligent-Tiering primarily recommended for?", "answer": "S3 Intelligent-Tiering is primarily recommended for workloads with unknown or changing access patterns, including data lakes, data analytics, machine learning, new applications, and user-generated content.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-04T18:30:02.285057"}}
{"question": "How does S3 Intelligent-Tiering optimize storage costs for users?", "answer": "S3 Intelligent-Tiering optimizes storage costs by automatically moving data to the most cost-effective access tier based on access frequency, without impacting performance, incurring retrieval fees, or creating operational overhead.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-04T18:30:02.285344"}}
{"question": "How do the Archive Access and Deep Archive Access tiers compare in terms of performance and retrieval requirements?", "answer": "The Archive Access tier has the same performance as S3 Glacier Flexible Retrieval, while the Deep Archive Access tier has the same performance as the S3 Glacier Deep Archive storage class. Both tiers require that before retrieving an object, it must first be restored, and objects in the Archive Access tier can be moved to the Frequent Access tier in 35 hours, while those in the Deep Archive Access tier can take up to 12 hours to be moved.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-04T18:30:02.285848"}}
{"question": "What is the durability percentage of S3 Intelligent-Tiering?", "answer": "S3 Intelligent-Tiering is designed for 99.999999999% durability.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-04T18:30:08.679349"}}
{"question": "What are the methods available for getting data into S3 Intelligent-Tiering?", "answer": "There are two ways to get data into S3 Intelligent-Tiering: you can directly PUT into S3 Intelligent-Tiering by specifying INTELLIGENT_TIERING in the x-amz-storage-class header, or you can set lifecycle policies to transition objects from S3 Standard or S3 Standard-IA to S3 INTELLIGENT_TIERING.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-04T18:30:08.679688"}}
{"question": "How does the availability of S3 Intelligent-Tiering compare to S3 Standard storage class?", "answer": "S3 Intelligent-Tiering is designed for 99.9% availability, whereas the context does not specify the availability percentage for S3 Standard storage class, but it is known to be highly available as well.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-04T18:30:08.680192"}}
{"question": "What are the access tiers included in the S3 Intelligent-Tiering storage class?", "answer": "The S3 Intelligent-Tiering storage class automatically stores objects in three access tiers: a Frequent Access tier, an Infrequent Access tier, and an Archive Instant Access tier. The Frequent Access tier is priced at S3 Standard storage rates, the Infrequent Access tier is priced at S3 Standard-Infrequent Access storage rates, and the Archive Instant Access tier is priced at S3 Glacier Instant Retrieval storage rates.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-04T18:30:15.304469"}}
{"question": "How does S3 Intelligent-Tiering help reduce storage costs for infrequently accessed data?", "answer": "S3 Intelligent-Tiering helps reduce storage costs for infrequently accessed data by automatically monitoring access patterns and moving objects through low latency and high throughput access tiers, as well as to two optional asynchronous archive access tiers. This allows customers to benefit from the lowest storage costs in the cloud for data that can be accessed asynchronously.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-04T18:30:15.304866"}}
{"question": "What is the difference in billing for small objects in S3 Intelligent-Tiering compared to larger objects?", "answer": "Small objects in S3 Intelligent-Tiering, specifically those smaller than 128KB, are not eligible for auto-tiering and will not be monitored. As a result, they will always be charged at the Frequent Access tier rates without any monitoring and automation charge. In contrast, larger objects can be monitored and automatically moved between different access tiers based on their access patterns.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-04T18:30:15.305119"}}
{"question": "How long does it take for objects from the Archive Access Tier to move to the Frequent Access tier?", "answer": "Objects in the Archive Access Tier are moved to the Frequent Access tier in 3-5 hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-04T18:30:20.442889"}}
{"question": "What is the purpose of Amazon S3 Inventory in relation to the S3 Intelligent-Tiering storage class?", "answer": "Amazon S3 Inventory is used to report the access tier of objects stored in the S3 Intelligent-Tiering storage class. It provides CSV, ORC, or Parquet output files that list your objects and their corresponding metadata on a daily or weekly basis for an S3 bucket or a shared prefix.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-04T18:30:20.443248"}}
{"question": "How does the lifecycle management of S3 Intelligent-Tiering compare with that of S3 Glacier Deep Archive?", "answer": "You can lifecycle objects from S3 Intelligent-Tiering Frequent Access, Infrequent, and Archive Instant Access tiers to S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive. Additionally, objects from the S3 Intelligent-Tiering optional archive access tiers can be lifecycled to S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive. However, you can lifecycle objects from the S3 Intelligent-Tiering Deep Archive Access tier specifically to S3 Glacier Deep Archive.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-04T18:30:20.443445"}}
{"question": "What is the minimum billable object size for the S3 Intelligent-Tiering storage class?", "answer": "The S3 Intelligent-Tiering storage class has no minimum billable object size; however, objects smaller than 128KB are not eligible for auto-tiering.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-04T18:30:25.995423"}}
{"question": "Why is S3 Standard suitable for performance-sensitive use cases?", "answer": "S3 Standard is suitable for performance-sensitive use cases because it delivers durable storage with millisecond access latency and high throughput performance for frequently accessed data, typically more than once per month. It is designed for applications such as data lakes, cloud-native applications, dynamic websites, content distribution, mobile and gaming applications, analytics, and machine learning models.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-04T18:30:25.995684"}}
{"question": "How does the S3 Intelligent-Tiering storage class differ from S3 Standard in terms of object size eligibility for auto-tiering?", "answer": "The S3 Intelligent-Tiering storage class does not have a minimum billable object size, but objects smaller than 128KB are not eligible for auto-tiering and will be charged at the Frequent Access tier rates. In contrast, S3 Standard is designed for frequently accessed data, requiring access in milliseconds, and is ideal for data that is read or written very often without retrieval charges.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-04T18:30:25.995853"}}
{"question": "What is the primary purpose of Amazon S3 Express One Zone?", "answer": "The primary purpose of Amazon S3 Express One Zone is to deliver consistent single-digit millisecond data access for customers most latency-sensitive applications. It is designed to provide the fastest data access speed and highest performance for such applications.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-04T18:30:30.033490"}}
{"question": "How does S3 Express One Zone compare to Amazon S3 Standard in terms of latency and request costs?", "answer": "S3 Express One Zone offers data access speed that is up to 10x faster and request costs that are up to 80% lower than Amazon S3 Standard.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-04T18:30:30.033925"}}
{"question": "What features make S3 Express One Zone ideal for request-intensive operations?", "answer": "S3 Express One Zone is ideal for request-intensive operations such as machine learning training and inference, interactive analytics, and media content creation due to its low latency and high performance in data access speed.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-04T18:30:30.034100"}}
{"question": "What is the maximum number of reads and writes supported per S3 directory bucket in S3 Express One Zone?", "answer": "Each S3 directory bucket in S3 Express One Zone can support up to 2 million reads and up to 200,000 writes per second, independent of the number of directories within the bucket.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-04T18:30:35.530391"}}
{"question": "How does S3 Express One Zone optimize for performance compared to other S3 storage classes?", "answer": "S3 Express One Zone optimizes for performance by using high-performance hardware, enhancing its object protocol to streamline authentication and metadata overheads, and storing data in a new bucket type called an Amazon S3 directory bucket. This architecture results in consistent single-digit millisecond first-byte read and write latency, making it up to 10x faster than existing S3 storage classes.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-04T18:30:35.530677"}}
{"question": "How does the storage architecture of S3 Express One Zone differ from standard S3 storage classes in terms of latency and performance?", "answer": "S3 Express One Zone is designed to provide consistent single-digit millisecond first-byte read and write latency, which is significantly fasterup to 10xthan existing S3 storage classes. Additionally, it allows customers to store data in a single AWS Availability Zone to minimize latency, while standard S3 storage classes may not offer the same level of performance elasticity or request latency.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-04T18:30:35.530874"}}
{"question": "What happens to S3 directory buckets that have no request activity for at least 3 months?", "answer": "S3 directory buckets that have no request activity for a period of at least 3 months will transition to an inactive state. While in this inactive state, the bucket becomes temporarily inaccessible for reads and writes, but retains all storage, object metadata, and bucket metadata. Existing storage charges will still apply to these inactive buckets.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-04T18:30:41.792561"}}
{"question": "How does the S3 Express One Zone storage class ensure high performance for machine learning applications?", "answer": "S3 Express One Zone is designed to allow individual customers to burst throughput to very high aggregate levels, making it suitable for machine learning model training applications. Users can achieve the highest performance by spreading requests over separate connections to maximize the accessible bandwidth, enabling them to train against millions of objects and petabytes of data effectively.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-04T18:30:41.792903"}}
{"question": "How does the availability of S3 Express One Zone compare to standard S3 storage classes?", "answer": "S3 Express One Zone is designed to deliver 99.95% availability within a single Availability Zone, with an availability SLA of 99.9%. In comparison, standard S3 storage classes typically offer higher availability across multiple Availability Zones, which can be greater than 99.99%. This means that while S3 Express One Zone offers high availability, it is limited to a single AZ, unlike standard S3 classes that provide cross-AZ redundancy.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-04T18:30:41.793104"}}
{"question": "What are the charges associated with using S3 Express One Zone?", "answer": "S3 Express One Zone charges you for storage and requests. There are no setup charges or commitments to begin using the service. The storage charges are based on total storage used per hour, measured in gigabyte per month (GB-Month). Additionally, you will incur a per request fee for access based on the request type, such as PUTs and GETs, as well as additional per-GB fees for data upload and retrieval.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-04T18:30:48.090378"}}
{"question": "How is the total storage cost calculated in S3 Express One Zone?", "answer": "The total storage cost in S3 Express One Zone is calculated by multiplying the total Byte-Hour usage, measured in GB-Month, by the cost per GB-Month. For example, if you have a total storage usage of 10 GB-Month, the cost would be 10 GB-Month multiplied by $0.11, resulting in a total storage cost of $1.10.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-04T18:30:48.090733"}}
{"question": "How do the request charges for PUT and GET requests compare in S3 Express One Zone?", "answer": "In S3 Express One Zone, the request charges for PUT and GET requests are different. For PUT requests, the charge is $0.00113 per 1,000 requests, while for GET requests, the charge is $0.00003 per 1,000 requests. Therefore, PUT requests are significantly more expensive than GET requests.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-04T18:30:48.090936"}}
{"question": "What is the total storage cost for storing 10 TB of data for a month?", "answer": "The total storage cost for storing 10 TB of data for a month is $363.41.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-04T18:30:53.717754"}}
{"question": "How are the request charges calculated for PUT and GET requests?", "answer": "The request charges for PUT requests are calculated as follows: 5,242,880 requests per day multiplied by 30 days, then multiplied by $0.00113 per 1,000 requests, resulting in $177.73. For GET requests, the calculation is 10,485,760 requests per day multiplied by 30 days, then multiplied by $0.00003 per 1,000 requests, which totals $9.44.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-04T18:30:53.718051"}}
{"question": "What is the difference in costs between data upload and data retrieval charges?", "answer": "The data upload charge is $983.04, while the data retrieval charge is $368.64. Therefore, the difference in costs is $983.04 - $368.64 = $614.40, with the data upload charge being significantly higher than the data retrieval charge.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-04T18:30:53.718225"}}
{"question": "What is the total amount of charges calculated in the context?", "answer": "The total amount of charges calculated is $1,902.26.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-04T18:30:57.822451"}}
{"question": "How is the total charges amount derived in this context?", "answer": "The total charges amount is derived by summing the individual charges: $363.41, $177.73, $9.44, $983.04, and $368.64.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-04T18:30:57.822827"}}
{"question": "What are the individual charges that make up the total charges?", "answer": "The individual charges that make up the total charges are $363.41, $177.73, $9.44, $983.04, and $368.64.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-04T18:30:57.823228"}}
{"question": "What are the costs associated with accessing data in S3 Express One Zone?", "answer": "The request charges to access data in S3 Express One Zone include costs to transfer data within the AWS network in a Region, and there is no additional Data Transfer charge for data transferred between Amazon EC2 (or any AWS service) and S3 Express One Zone within the same Region. Additionally, the request charges also include costs to use Gateway VPC endpoints, but there is no additional charge for using Gateway endpoints with S3 Express One Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T18:31:05.372421"}}
{"question": "What makes S3 Standard-Infrequent Access (S3 Standard-IA) suitable for long-term storage and backups?", "answer": "S3 Standard-IA is suitable for long-term storage and backups because it is designed for data that is accessed less frequently but requires rapid access when needed. It offers high durability, throughput, and low latency similar to the S3 Standard storage class, along with a low per-GB storage price and per-GB retrieval charge. This combination of low cost and high performance makes it ideal for long-term file storage, older sync and share storage, and aging data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T18:31:05.372953"}}
{"question": "How does S3 Standard-IA compare to S3 Standard in terms of latency and performance?", "answer": "S3 Standard-IA provides the same milliseconds latency and high throughput performance as the S3 Standard storage class. This means that while S3 Standard-IA is designed for less frequent access, it does not compromise on access speed and performance when data is needed.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-04T18:31:05.373167"}}
{"question": "What is the purpose of S3 Standard-IA?", "answer": "S3 Standard-IA is designed for long-lived, infrequently accessed data that is retained for months or years.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-04T18:31:10.729811"}}
{"question": "How does the minimum object storage charge work in S3 Standard-IA?", "answer": "S3 Standard-IA has a minimum object storage charge of 128KB. This means that objects smaller than 128KB will incur storage charges as if the object were 128KB. For instance, a 6KB object will be charged for 6KB plus an additional charge equivalent to 122KB.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-04T18:31:10.730129"}}
{"question": "What are the options for migrating objects from S3 Standard-IA using Lifecycle policies?", "answer": "Using Lifecycle policies, you can migrate objects from S3 Standard to S3 Standard-IA, and you can also tier objects from S3 Standard-IA to S3 One Zone-IA, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and the S3 Glacier Deep Archive storage class.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-04T18:31:10.730329"}}
{"question": "What is the main advantage of using S3 One Zone-IA over S3 Standard-IA?", "answer": "The main advantage of using S3 One Zone-IA over S3 Standard-IA is that it offers storage at 20% less cost while still providing redundant data storage within a single Availability Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-04T18:31:16.435170"}}
{"question": "What type of data is S3 One Zone-IA storage class best suited for?", "answer": "S3 One Zone-IA storage class is best suited for infrequently-accessed storage, such as backup copies, disaster recovery copies, or other easily re-creatable data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-04T18:31:16.435521"}}
{"question": "How does the durability of S3 One Zone-IA compare to that of S3 Standard and other storage classes designed for availability?", "answer": "S3 One Zone-IA is designed for 99.999999999% durability within an Availability Zone, but unlike S3 Standard, S3 Intelligent-Tiering, S3 Standard-Infrequent Access, and S3 Glacier, it is not resilient to the loss of availability or the physical loss of an entire Availability Zone.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-04T18:31:16.435724"}}
{"question": "What is the purpose of the S3 One Zone-IA storage class?", "answer": "The S3 One Zone-IA storage class uses an individual AWS Availability Zone within the Region and offers protection against equipment failure within that Availability Zone. However, the data stored in S3 One Zone-IA is not resilient to the physical loss of the Availability Zone resulting from disasters such as earthquakes and floods.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-04T18:31:23.794048"}}
{"question": "How does S3 Glacier Instant Retrieval differ from S3 Standard-IA in terms of data access frequency and costs?", "answer": "S3 Glacier Instant Retrieval is designed for data that is rarely accessed, typically once a quarter, and offers milliseconds retrieval times. It provides the same low latency and high throughput performance as S3 Standard-IA but is intended for less frequently accessed data, resulting in a lower storage price but slightly higher data access costs compared to S3 Standard-IA.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-04T18:31:23.794393"}}
{"question": "What are the differences in data durability and availability between S3 Standard and S3 Glacier Instant Retrieval?", "answer": "S3 Standard and S3 Standard-IA storage classes offer protection against disasters by storing data redundantly in multiple Availability Zones, whereas S3 Glacier Instant Retrieval is designed for 99.999999999% (11 9s) of data durability and 99.9% availability by redundantly storing data across at least three physically separated AWS Availability Zones. Therefore, S3 Glacier Instant Retrieval provides extremely high durability and availability compared to S3 Standard and S3 Standard-IA, which focus on redundancy within multiple Availability Zones.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-04T18:31:23.794605"}}
{"question": "What is the durability percentage of S3 Glacier Instant Retrieval?", "answer": "S3 Glacier Instant Retrieval is designed for 99.999999999% (11 9s) of durability.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-04T18:31:30.129217"}}
{"question": "How does S3 Glacier Instant Retrieval differ from S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive in terms of access?", "answer": "S3 Glacier Instant Retrieval allows immediate access to objects without needing to issue a Restore request, whereas S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive are designed for asynchronous access and require a Restore request before accessing objects.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-04T18:31:30.129540"}}
{"question": "What are the similarities and differences in availability between S3 Glacier Instant Retrieval and S3 Standard-IA?", "answer": "Both S3 Glacier Instant Retrieval and S3 Standard-IA have the same availability rate of 99.9%. Additionally, both provide a service level agreement that offers service credits if availability falls below 99% in any billing cycle.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-04T18:31:30.129745"}}
{"question": "What is the minimum object storage charge for S3 Glacier Instant Retrieval?", "answer": "The minimum object storage charge for S3 Glacier Instant Retrieval is 128KB.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-04T18:31:35.946010"}}
{"question": "How does S3 Glacier Instant Retrieval charge for objects smaller than 128KB?", "answer": "Objects smaller than 128KB in size will incur storage charges as if the object were 128KB. For example, a 6KB object will incur storage charges for 6KB and an additional minimum object size charge equivalent to 122KB.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-04T18:31:35.946343"}}
{"question": "How are storage charges calculated for S3 Glacier Instant Retrieval compared to other request types?", "answer": "S3 Glacier Instant Retrieval charges are based on three components: monthly storage, requests based on the request type, and data retrievals. The volume of storage billed in a month is based on average storage used throughout the month, measured in gigabyte per month (GB-Month). Requests such as PUTs, COPYs, and GETs incur additional charges, and there is a per GB fee for every gigabyte of data retrieved.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-04T18:31:35.946553"}}
{"question": "What are the main use cases for the S3 Glacier Flexible Retrieval storage class?", "answer": "The main use cases for the S3 Glacier Flexible Retrieval storage class include backup, disaster recovery, and offsite data storage needs. It is especially suited for archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-04T18:31:40.955805"}}
{"question": "How does S3 Glacier Flexible Retrieval balance cost and access times for data retrieval?", "answer": "S3 Glacier Flexible Retrieval balances cost and access times by offering flexible retrieval options that allow access times ranging from minutes to hours, while also providing free bulk retrievals. This makes it an ideal solution for situations where some data may need to be retrieved quickly without incurring additional costs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-04T18:31:40.956179"}}
{"question": "How does the durability and availability of S3 Glacier Flexible Retrieval compare to other storage classes?", "answer": "S3 Glacier Flexible Retrieval is designed for 99.999999999% (11 9s) of data durability and 99.99% availability by redundantly storing data across multiple physically separated AWS Availability Zones in a given year. The context does not provide a direct comparison to other storage classes, but it indicates that S3 Glacier Flexible Retrieval offers high durability and availability.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-04T18:31:40.956485"}}
{"question": "What are the two ways to get data into S3 Glacier Flexible Retrieval?", "answer": "The two ways to get data into S3 Glacier Flexible Retrieval are by directly using PUT with the GLACIER storage class specified in the x-amz-storage-class header and by using S3 Lifecycle rules to transition objects from other S3 storage classes based on object age.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-04T18:31:46.976178"}}
{"question": "Why is it recommended to use S3 APIs and the S3 Management Console for accessing S3 Glacier features?", "answer": "It is recommended to use S3 APIs and the S3 Management Console for accessing S3 Glacier features because they provide an enhanced experience that includes access to the full S3 feature set, such as lifecycle management, S3 Replication, S3 Storage Lens, and more.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-04T18:31:46.976584"}}
{"question": "How does transitioning objects to S3 Glacier Flexible Retrieval differ from directly putting data into it?", "answer": "Transitioning objects to S3 Glacier Flexible Retrieval involves using S3 Lifecycle rules to move objects from other active S3 storage classes based on their age, while directly putting data into S3 Glacier Flexible Retrieval is done by specifying the GLACIER storage class in the PUT request.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-04T18:31:46.977110"}}
{"question": "How do you retrieve data stored in S3 Glacier Flexible Retrieval?", "answer": "To retrieve data stored in S3 Glacier Flexible Retrieval, you need to initiate a retrieval request using the Amazon S3 APIs or the Amazon S3 console. This request creates a temporary copy of your data in the S3 Standard storage class while keeping the archived data intact in S3 Glacier Flexible Retrieval.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-04T18:31:51.511827"}}
{"question": "What happens to the archived data in S3 Glacier Flexible Retrieval when a retrieval request is made?", "answer": "When a retrieval request is made, a temporary copy of the archived data is created in the S3 Standard storage class, but the archived data itself remains intact in S3 Glacier Flexible Retrieval.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-04T18:31:51.512120"}}
{"question": "How does billing work for temporarily available data in regions where Reduced Redundancy Storage is cheaper than S3 Standard?", "answer": "In AWS Regions where Reduced Redundancy Storage is a lower price than S3 Standard, the temporarily available data is billed as Reduced Redundancy Storage. However, it's important to note that the Reduced Redundancy billing storage class does not reflect how the data is stored.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-04T18:31:51.512325"}}
{"question": "What are the three retrieval options available for S3 Glacier Flexible Retrieval?", "answer": "The three retrieval options available for S3 Glacier Flexible Retrieval are Expedited, Standard, and Bulk retrievals.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-04T18:31:56.030109"}}
{"question": "Why might someone choose to purchase provisioned retrieval capacity for S3 Glacier?", "answer": "Someone might choose to purchase provisioned retrieval capacity for S3 Glacier to ensure highly reliable and predictable access to a subset of their data in minutes, especially if they require access to expedited retrievals under any circumstance, as expedited retrievals might not be accepted during periods of high demand without provisioned capacity.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-04T18:31:56.030417"}}
{"question": "How does the retrieval time for Expedited retrievals compare to Standard and Bulk retrievals?", "answer": "Expedited retrievals typically make data available within 1-5 minutes for all but the largest objects (250MB+), whereas Standard retrievals typically complete between 3-5 hours and Bulk retrievals typically complete within 5-12 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-04T18:31:56.030907"}}
{"question": "How is the volume of storage billed in Amazon S3?", "answer": "The volume of storage billed in a month is based on the average storage used throughout the month, measured in gigabyte-months (GB-Months).", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-04T18:32:01.311471"}}
{"question": "What additional data is required by S3 Glacier Flexible Retrieval for each object?", "answer": "S3 Glacier Flexible Retrieval requires an additional 32 KB of data per object for S3 Glaciers index and metadata, plus an additional 8 KB to store and maintain the user-defined name and metadata for objects archived to S3 Glacier Flexible Retrieval.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-04T18:32:01.311737"}}
{"question": "How does the storage calculation differ between S3 Glacier and S3 Standard storage classes?", "answer": "For S3 Glacier, each object incurs an additional charge of 32 KB for index and metadata, while for S3 Standard storage, each object incurs an additional charge of 8 KB to store and maintain the user-defined name and metadata. Therefore, S3 Glacier has a higher overhead per object compared to S3 Standard storage.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-04T18:32:01.312141"}}
{"question": "What is the minimum storage duration for objects archived to S3 Glacier Flexible Retrieval?", "answer": "Objects archived to S3 Glacier Flexible Retrieval have a minimum of 90 days of storage.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-04T18:32:05.245589"}}
{"question": "What additional charges apply if an object is deleted or transitioned before the minimum storage duration in S3 Glacier Flexible Retrieval?", "answer": "If an object is deleted, overwritten, or transitioned before the minimum 90 days of storage, a pro-rated charge equal to the storage charge for the remaining days will be incurred.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-04T18:32:05.245966"}}
{"question": "How do the retrieval methods of S3 Glacier Flexible Retrieval differ in terms of charges?", "answer": "Expedited and Standard retrievals from S3 Glacier Flexible Retrieval have a per-GB retrieval fee and a per-request fee, while Bulk Retrievals are free.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-04T18:32:05.246381"}}
{"question": "What is the retrieval time for the S3 Glacier Instant Retrieval storage class?", "answer": "The S3 Glacier Instant Retrieval storage class delivers data retrieval in milliseconds.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-04T18:32:09.407250"}}
{"question": "What are the advantages of using the S3 Glacier storage classes for data archiving?", "answer": "The advantages of using the S3 Glacier storage classes for data archiving include the highest performance, most retrieval flexibility, and the lowest cost archive storage in the cloud.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-04T18:32:09.407503"}}
{"question": "How does S3 Glacier Deep Archive compare to S3 Glacier Flexible Retrieval in terms of retrieval time and cost?", "answer": "S3 Glacier Deep Archive provides data retrieval within 12 hours and offers the lowest cost storage at $0.00099 per GB-month, while S3 Glacier Flexible Retrieval allows for retrieval in minutes or free bulk retrievals in 512 hours but does not specify a cost comparable to Deep Archive.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-04T18:32:09.407660"}}
{"question": "What types of data are commonly stored in S3 Glacier Deep Archive?", "answer": "Common types of data stored in S3 Glacier Deep Archive include core intellectual property, financial and medical records, research results, legal documents, seismic exploration studies, and long-term backups. This storage class is particularly beneficial for highly regulated industries such as Financial Services, Healthcare, Oil & Gas, and Public Sectors.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-04T18:32:15.156261"}}
{"question": "What are the main advantages of using S3 Glacier Deep Archive for data storage?", "answer": "The main advantages of using S3 Glacier Deep Archive include providing offline protection for important data assets, fulfilling long-term data retention requirements for corporate policy, contractual, or regulatory compliance, and potentially reducing or discontinuing the use of on-premises magnetic tape libraries and off-premises tape archival services.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-04T18:32:15.156558"}}
{"question": "How does S3 Glacier Deep Archive compare to S3 Glacier Flexible Retrieval in terms of cost and retrieval time?", "answer": "S3 Glacier Deep Archive is up to 75% less expensive than S3 Glacier Flexible Retrieval. In terms of retrieval time, S3 Glacier Deep Archive provides retrieval within 12 hours using the Standard retrieval tier, while S3 Glacier Flexible Retrieval offers retrieval in minutes or free bulk retrievals in 5-12 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-04T18:32:15.156759"}}
{"question": "What is the easiest way to store data in S3 Glacier Deep Archive?", "answer": "The easiest way to store data in S3 Glacier Deep Archive is to use the S3 API to upload data directly and specify 'S3 Glacier Deep Archive' as the storage class.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-04T18:32:20.484560"}}
{"question": "How can S3 Lifecycle policies help in using S3 Glacier Deep Archive?", "answer": "S3 Lifecycle policies can be created to migrate data to S3 Glacier Deep Archive based on the age of the object, allowing users to define the lifecycle of their objects and reduce storage costs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-04T18:32:20.484899"}}
{"question": "What is the difference between S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive in terms of archival storage target?", "answer": "When creating a new virtual tape using AWS Storage Gateway, you can set the archival storage target to either S3 Glacier Flexible Retrieval or S3 Glacier Deep Archive, where S3 Glacier Deep Archive provides the lowest cost storage for long-term backups and archives.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-04T18:32:20.485330"}}
{"question": "What is the role of AWS Tape Gateway in migrating data to S3 Glacier Deep Archive?", "answer": "AWS Tape Gateway integrates with existing backup applications using a virtual tape library (VTL) interface, which presents virtual tapes to the backup application. These virtual tapes can be immediately used to store data in Amazon S3, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-04T18:32:26.088014"}}
{"question": "What are the advantages of using AWS Snowball for data migration?", "answer": "AWS Snowball accelerates moving terabytes to petabytes of data into and out of AWS using physical storage devices designed for secure transport. It helps eliminate challenges associated with large-scale data transfers, including high network costs, long transfer times, and security concerns.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-04T18:32:26.088301"}}
{"question": "How does the retrieval of data from S3 Glacier Deep Archive differ when using Standard versus Bulk retrieval tiers?", "answer": "The Standard retrieval tier allows access to archived objects within 12 hours, with retrievals typically starting within 9 hours when using S3 Batch Operations. In contrast, the Bulk retrieval tier is designed for retrieving large amounts of data, even petabytes, at a lower cost, and typically completes within 48 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-04T18:32:26.088471"}}
{"question": "What factors determine the pricing of S3 Glacier Deep Archive storage?", "answer": "The pricing of S3 Glacier Deep Archive storage is determined by the amount of data stored in GBs, the number of PUT/lifecycle transition requests, retrievals in GBs, and the number of restore requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-04T18:32:31.737091"}}
{"question": "How does S3 Glacier Deep Archive storage differ in billing from standard Amazon S3 usage?", "answer": "S3 Glacier Deep Archive usage and cost show up as an independent service line item on your monthly AWS bill, separate from your Amazon S3 usage and costs. However, if using the AWS Cost Management tool, S3 Glacier Deep Archive usage and cost are included under the Amazon S3 usage and cost in detailed monthly spend reports, without being broken out as a separate service line item.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-04T18:32:31.737788"}}
{"question": "What is the minimum storage duration for objects archived in S3 Glacier Deep Archive, and what happens if they are deleted before this period?", "answer": "Objects archived to S3 Glacier Deep Archive have a minimum storage duration of 180 days. If an object is deleted, overwritten, or transitioned before the 180 days are up, a pro-rated charge equal to the storage charge for the remaining days will be incurred.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-04T18:32:31.738013"}}
{"question": "What features are integrated with S3 Glacier Deep Archive?", "answer": "S3 Glacier Deep Archive is integrated with Amazon S3 features, including S3 Object Tagging, S3 Lifecycle policies, S3 Object Lock, and S3 Replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-04T18:32:37.021246"}}
{"question": "How do Amazon S3 Lifecycle policies benefit data management in S3 Glacier Deep Archive?", "answer": "Amazon S3 Lifecycle policies allow customers to automatically migrate data to lower-cost storage classes as the data ages, enabling better cost management and efficiency in storing different types of data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-04T18:32:37.021533"}}
{"question": "What is the relationship between Tape Gateway and S3 Glacier Deep Archive?", "answer": "Tape Gateway integrates with S3 Glacier Deep Archive by allowing users to store virtual tapes in this lowest-cost Amazon S3 storage class, which reduces monthly storage costs by 75% and supports archiving new virtual tapes directly to S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-04T18:32:37.021959"}}
{"question": "What is Amazon S3 on Outposts used for?", "answer": "Amazon S3 on Outposts delivers object storage in your on-premises environment, allowing you to process and store customer data generated on-premises, access data locally for applications that run on-premises, or store data for companies with data residency requirements or in regulated industries.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-04T18:32:42.462113"}}
{"question": "How do S3 object tags enhance the management of S3 objects?", "answer": "S3 object tags are key-value pairs that allow you to create AWS Identity and Access Management (IAM) policies, set up Amazon S3 Lifecycle policies, and customize storage metrics. They can help manage transitions between storage classes and expire objects in the background, improving the overall management of S3 objects.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-04T18:32:42.462472"}}
{"question": "How does Amazon S3 on Outposts compare to standard S3 in terms of data storage location?", "answer": "Amazon S3 on Outposts provides object storage in your on-premises environment, whereas standard Amazon S3 stores data in AWS Regions. This allows S3 on Outposts to serve companies with specific data residency requirements or those in regulated industries by keeping data on-premises.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-04T18:32:42.462693"}}
{"question": "What are the main functions of object tags in S3 storage management?", "answer": "Object tags in S3 storage management allow you to create, update, and delete tags at any time during the lifetime of your object. They enable simple management of storage, control access to objects with specific key-value pairs for security, label objects for projects or business units, and can be used in conjunction with S3 Lifecycle policies and S3 Replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-04T18:32:48.096364"}}
{"question": "How can object tags enhance the security and organization of data in S3?", "answer": "Object tags enhance security by allowing access control to objects based on specific key-value pairs, thereby securing confidential data for select users or groups. They also aid in organizing data by labeling objects related to specific projects or business units, making it easier to manage and transition data using S3 Lifecycle policies.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-04T18:32:48.096717"}}
{"question": "How do the methods for changing object tags differ when using the AWS Management Console compared to other methods?", "answer": "When using the AWS Management Console, you can directly change object tags without needing to resend the entire set of tags. However, when changing object tags through other methods such as the REST API, AWS CLI, or AWS SDKs, you must include the entire existing tag set in your request, as all changes are made to the full tag set.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-04T18:32:48.096890"}}
{"question": "What is the primary purpose of using Amazon S3 Metadata?", "answer": "The primary purpose of using Amazon S3 Metadata is to query information about S3 objects using SQL, which allows users to quickly identify specific datasets for generative AI, analytics, and other use cases.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-04T18:32:52.977183"}}
{"question": "How does S3 Metadata ensure that the metadata is kept up to date?", "answer": "S3 Metadata keeps metadata up to date in near real time, automatically generating and maintaining system-level metadata, custom metadata, and event metadata as data in the bucket changes.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-04T18:32:52.977532"}}
{"question": "How do S3 Metadata tables compare to regular S3 buckets in terms of permissions?", "answer": "S3 Metadata tables are read-only, meaning that only S3 has permission to write, update, or delete metadata, while regular S3 buckets allow for more general permissions for users to manage their objects.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-04T18:32:52.977977"}}
{"question": "What types of tables does S3 Metadata use to store metadata?", "answer": "S3 Metadata stores metadata in two managed tables in your account: journal tables and live inventory tables.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-04T18:32:57.270436"}}
{"question": "How can journal tables be beneficial for application behavior analysis?", "answer": "Journal tables are useful for understanding the behavior of your applications and for identifying any change made to your datasets. You can write SQL queries for journal tables to find S3 objects that match filters, such as objects added in the last 30 days, objects added by active requesters, or objects with metadata changes across the last week.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-04T18:32:57.271189"}}
{"question": "What is the difference in the update frequency between the journal tables and live inventory tables?", "answer": "The journal tables reflect changes made within your bucket in near real time, while the live inventory tables are updated hourly.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-04T18:32:57.271472"}}
{"question": "What file output formats can S3 Inventory provide?", "answer": "S3 Inventory can provide output files in CSV, ORC, or Parquet formats.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-04T18:33:02.459540"}}
{"question": "How does S3 Inventory simplify business workflows and big data jobs?", "answer": "S3 Inventory simplifies and speeds up business workflows and big data jobs by providing a scheduled alternative to Amazon S3s synchronous List API, thus allowing for efficient retrieval of object metadata on a regular basis.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-04T18:33:02.459867"}}
{"question": "What are the differences between configuring S3 Inventory via the AWS Management Console and the PUT Bucket Inventory Configuration API?", "answer": "The AWS Management Console provides a user-friendly interface for configuring S3 Inventory, while the PUT Bucket Inventory Configuration API allows for programmatic configuration. Both methods enable you to set a daily or weekly inventory report, specify a destination S3 bucket, choose the output file format, and select specific object metadata.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-04T18:33:02.460101"}}
{"question": "What are Amazon S3 Tables optimized for?", "answer": "Amazon S3 Tables are specifically optimized for analytics workloads, improving query performance while also reducing costs.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-04T18:33:06.891515"}}
{"question": "How do Amazon S3 Tables enhance the management and querying of tabular data?", "answer": "Amazon S3 Tables enhance the management and querying of tabular data by allowing users to organize structured data into tables, query that data using standard SQL statements with virtually no setup, and providing analytics capabilities such as row-level transactions and queryable table snapshots, all managed by Amazon S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-04T18:33:06.891885"}}
{"question": "How do Amazon S3 Tables compare to standard S3 storage in terms of performance and cost optimization?", "answer": "Amazon S3 Tables deliver the same durability, availability, scalability, and performance characteristics as standard S3 storage, but they also automatically optimize your storage to maximize query performance and minimize cost specifically for analytics workloads.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-04T18:33:06.892048"}}
{"question": "What formats are supported for storing structured data in S3 Tables?", "answer": "S3 Tables support storing structured data in the Apache Parquet, Avro, and ORC formats.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-04T18:33:12.874982"}}
{"question": "How does S3 optimize the underlying data over time?", "answer": "S3 automatically optimizes the underlying Parquet, Avro, or ORC data by rewriting, or 'compacting' your objects, which improves query performance.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-04T18:33:12.875375"}}
{"question": "What are the methods available for creating and deleting tables in S3 Tables?", "answer": "You can create a table in your table bucket using the CreateTable API in S3 or by using your query engine. To delete a table, you can use the DeleteTable API in S3 or your query engine. When you delete a table, it will no longer be accessible by your query engine.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-04T18:33:12.875616"}}
{"question": "What query engines can be used to query S3 Tables that support the Apache Iceberg standard?", "answer": "You can use Amazon Athena, Amazon Redshift, and Apache Spark to query Iceberg tables in your table buckets using standard SQL.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-04T18:33:17.223943"}}
{"question": "Why do table buckets offer improved query performance compared to general purpose Amazon S3 buckets?", "answer": "Table buckets provide up to 3x faster query performance and up to 10x higher transactions per second (TPS) because they automatically compact the underlying Parquet, Avro, or ORC data for your tables, optimizing query performance, and the purpose-built storage supports up to 10x the TPS by default.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-04T18:33:17.224296"}}
{"question": "How do table buckets and general purpose Amazon S3 buckets differ in terms of manual object management?", "answer": "Table buckets do not allow manual object overwrites or deletes to prevent compromising the integrity of the tables or breaking downstream applications, while general purpose Amazon S3 buckets typically allow such operations.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-04T18:33:17.224726"}}
{"question": "Does S3 Tables support AWS CloudTrail?", "answer": "Yes, S3 Tables support AWS CloudTrail. You can set up CloudTrail data and management events for your table buckets, similar to how you would with a general purpose S3 bucket.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-04T18:33:23.744487"}}
{"question": "How does AWS Key Management Service (AWS KMS) enhance the security of data in S3 Tables?", "answer": "AWS Key Management Service (AWS KMS) enhances the security of data in S3 Tables by allowing you to encrypt your data using your own encryption keys. These keys are created and managed within your AWS account, and KMS provides separate permissions for the use of these keys, adding an extra layer of control and protection against unauthorized access. Additionally, KMS generates a detailed audit trail, enabling you to track who accessed which table and when, as well as offering additional security controls to support compliance with industry requirements such as PCI-DSS, HIPAA/HITECH, and FedRAMP.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-04T18:33:23.744884"}}
{"question": "What are the differences between the default target file size for compaction in S3 Tables and the minimum target file size that can be set?", "answer": "The default target file size for compaction in S3 Tables is 512MB, while the minimum target file size that can be set is 64MB. Users have the option to change the target file size from 64MB to 512MB using the PutTableMaintenanceConfiguration API.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-04T18:33:23.745105"}}
{"question": "What determines the number of active snapshots for your tables in snapshot management?", "answer": "The number of active snapshots for your tables in snapshot management is determined by the MinimumSnapshots, which defaults to 1, and the MaximumSnapshotAge, which defaults to 120 hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-04T18:33:28.857736"}}
{"question": "How does snapshot management handle expired snapshots?", "answer": "When a snapshot expires, Amazon S3 creates delete markers for the data and metadata files uniquely referenced by that snapshot and marks these files as noncurrent. The noncurrent files are then deleted after the number of days specified by the NoncurrentDays property in your unreferenced file removal policy.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-04T18:33:28.858166"}}
{"question": "What happens to snapshot management when a branch or tag-based retention policy is configured?", "answer": "Snapshot management for S3 Tables is disabled when you configure a branch or tag-based retention policy, or when you configure a retention policy on the metadata.json file that is longer than the values configured through the PutTableMaintenanceConfiguration API.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-04T18:33:28.858404"}}
{"question": "What is S3 Batch Operations used for?", "answer": "S3 Batch Operations is a feature that automates the execution of a single operation across many objects, such as copying an object or executing an AWS Lambda function. It allows you to make changes to billions of objects with a few clicks in the S3 console or a single API request, without the need for custom application code or compute clusters.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-04T18:33:33.157621"}}
{"question": "How does S3 Batch Operations handle retries and notifications?", "answer": "S3 Batch Operations manages retries for storage operations, displays progress, delivers notifications, provides a completion report, and sends events to AWS CloudTrail for all operations performed on the target objects.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-04T18:33:33.157930"}}
{"question": "How does using S3 Batch Operations compare to writing custom application code for storage management?", "answer": "Using S3 Batch Operations allows users to automate the execution of storage operations across many objects without the need for writing custom application code or running compute clusters. In contrast, writing custom application code typically requires more effort and resources to manage storage operations.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-04T18:33:33.158104"}}
{"question": "What are the steps to create your first S3 Batch Operations job?", "answer": "To create your first S3 Batch Operations job, you need to go into the Amazon S3 console or use the AWS CLI or SDK. Start by selecting an S3 Inventory report or providing a custom list of objects for S3 Batch Operations to act upon. Then, choose from a set of supported S3 operations, customize job parameters, and finally confirm the job details before S3 Batch Operations begins executing the specified operation.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-04T18:33:38.819274"}}
{"question": "What customization options are available when creating an S3 Batch Operations job?", "answer": "When creating an S3 Batch Operations job, you can customize it with specific parameters such as tag values, ACL grantees, and restoration duration. Additionally, you can write your own Lambda function to further customize your storage actions and invoke that code through S3 Batch Operations.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-04T18:33:38.820305"}}
{"question": "How does S3 Object Lock support customers in the financial services industry compared to S3 Batch Operations?", "answer": "S3 Object Lock provides added support for customers in the financial services industry by allowing broker-dealers to retain records in a non-erasable and non-rewritable format to comply with regulatory requirements. In contrast, S3 Batch Operations focuses on processing and managing lists of objects for various operations, such as changing permissions or restoring data, but does not specifically address regulatory compliance like S3 Object Lock does.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-04T18:33:38.820478"}}
{"question": "What is required to be notified to the Designated Examining Authority when using Amazon S3 for electronic storage?", "answer": "You are required to provide notification to your regulator or Designated Examining Authority (DEA) of your choice to use Amazon S3 for electronic storage along with a copy of the Cohasset Assessment.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-04T18:33:44.022946"}}
{"question": "What is the benefit of using S3 Lifecycle management in Amazon S3?", "answer": "The benefit of using S3 Lifecycle management is that it allows you to define the lifecycle of your objects with a predefined policy, which can help reduce your cost of storage by automatically migrating objects to cheaper storage classes based on the age of the data or by automatically removing objects based on their age.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-04T18:33:44.023219"}}
{"question": "How do CloudWatch request metrics differ from CloudWatch storage metrics in terms of reporting frequency?", "answer": "CloudWatch request metrics are available in CloudWatch within 15 minutes after they are enabled and are priced as custom metrics, while CloudWatch storage metrics are enabled by default for all buckets and are reported once per day.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-04T18:33:44.023552"}}
{"question": "What tools can I use to set up and manage Lifecycle policies in AWS?", "answer": "You can set up and manage Lifecycle policies using the AWS Management Console, S3 REST API, AWS SDKs, or AWS Command Line Interface (CLI).", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-04T18:33:47.643023"}}
{"question": "At what levels can Lifecycle policies be specified in AWS?", "answer": "Lifecycle policies can be specified at the prefix level or at the bucket level in AWS.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-04T18:33:47.643602"}}
{"question": "How do the AWS Management Console and AWS CLI differ in terms of managing Lifecycle policies?", "answer": "Both the AWS Management Console and AWS CLI allow you to manage Lifecycle policies, but the Console provides a graphical user interface while the CLI allows for command-line management.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-04T18:33:47.643764"}}
{"question": "What storage classes can objects be migrated to using Amazon S3 Lifecycle policies?", "answer": "With Amazon S3 Lifecycle policies, objects can be migrated from the S3 Standard storage class to S3 Standard-IA or S3 One Zone-IA, and/or archived to S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, or S3 Glacier Deep Archive storage classes.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-04T18:33:53.117250"}}
{"question": "How do S3 Lifecycle policies help in managing storage costs?", "answer": "S3 Lifecycle policies help manage storage costs by allowing you to configure object migrations and deletions automatically, which reduces storage costs and saves time without the need for manual data review and migration.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-04T18:33:53.117502"}}
{"question": "What is the difference between using a prefix to apply an S3 Lifecycle policy to a set of objects versus specifying a key name for an individual object?", "answer": "Using a prefix to apply an S3 Lifecycle policy affects a set of objects that share the common prefix (e.g., 'logs/'), while specifying a key name applies the rule to an individual object. This allows for more granular control over which objects are subject to the lifecycle actions.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-04T18:33:53.117946"}}
{"question": "What is the cost associated with setting up and applying Lifecycle policies in Amazon S3?", "answer": "There is no additional cost to set up and apply Lifecycle policies in Amazon S3. However, a transition request is charged per object when an object becomes eligible for transition according to the Lifecycle rule.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-04T18:33:57.724869"}}
{"question": "How does the S3 Lifecycle policy that expires incomplete multipart uploads help with costs?", "answer": "The S3 Lifecycle policy that expires incomplete multipart uploads helps save on costs by limiting the time that non-completed multipart uploads are stored. This policy automatically removes incomplete multipart uploads and the associated storage after a predefined number of days, thus lowering your S3 storage bill.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-04T18:33:57.725210"}}
{"question": "What are the differences between S3 Storage Lens and S3 Inventory in terms of functionality?", "answer": "S3 Storage Lens delivers organization-wide visibility into object storage usage and activity trends, providing actionable recommendations to optimize costs and apply data protection best practices. In contrast, S3 Inventory provides a report of your objects and their corresponding metadata on a daily or weekly basis for an S3 bucket or prefix, which can help meet business, compliance, and regulatory needs by verifying the encryption and replication status of objects.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-04T18:33:57.725407"}}
{"question": "What does Amazon S3 Storage Lens provide for object storage usage?", "answer": "Amazon S3 Storage Lens provides organization-wide visibility into object storage usage and activity trends, as well as actionable recommendations to optimize costs and apply data protection best practices.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-04T18:34:01.844988"}}
{"question": "How does S3 Storage Lens help in optimizing storage costs?", "answer": "S3 Storage Lens delivers contextual recommendations to find ways to reduce storage costs and apply best practices on data protection across tens or hundreds of accounts and buckets, which can be accessed through the interactive dashboard.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-04T18:34:01.845285"}}
{"question": "What are the differences between default metrics and advanced metrics in S3 Storage Lens?", "answer": "Default metrics in S3 Storage Lens are enabled by default for all Amazon S3 users and provide a basic level of insight. In contrast, advanced metrics, which can be activated for an additional cost, offer 35 additional metrics and prefix-level aggregations for more detailed analysis.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-04T18:34:01.845674"}}
{"question": "What types of questions can the S3 Storage Lens dashboard help answer with the Summary filter?", "answer": "The S3 Storage Lens dashboard can help answer top-level questions related to overall storage usage and activity trends with the Summary filter. For example, questions like 'How rapidly is my overall byte count and request count increasing over time?' can be explored.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-04T18:34:07.932453"}}
{"question": "How does the Cost Optimization filter in S3 Storage Lens assist users?", "answer": "The Cost Optimization filter in S3 Storage Lens assists users by allowing them to explore questions related to storage cost reduction, such as 'Is it possible for me to save money by retaining fewer non-current versions?'", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-04T18:34:07.932746"}}
{"question": "What is the difference between free metrics and advanced metrics in S3 Storage Lens?", "answer": "Free metrics in S3 Storage Lens include metrics to analyze usage based on a daily snapshot of objects, organized into categories like cost optimization, data protection, access management, performance, and events. Advanced metrics, available for an additional cost, provide metrics related to activity, deeper cost optimization, additional data protection, and detailed status codes. For example, advanced metrics include request counts and S3 Lifecycle rule counts, while free metrics do not.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-04T18:34:07.932914"}}
{"question": "What is the historical data retention period for S3 Storage Lens free metrics?", "answer": "S3 Storage Lens free metrics retains 14 days of historical data.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-04T18:34:12.932193"}}
{"question": "What are the benefits of using S3 Storage Lens advanced metrics compared to the free metrics?", "answer": "S3 Storage Lens advanced metrics provide 35 additional metrics, prefix-level aggregation, CloudWatch metrics support, custom object metadata filtering with S3 Storage Lens groups, and they retain 15 months of historical data in the dashboard, compared to the 28 metrics and 14 days of historical data offered by the free metrics.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-04T18:34:12.932562"}}
{"question": "How do S3 Inventory and S3 Storage Lens differ in their functionality?", "answer": "S3 Inventory provides a list of objects and their corresponding metadata for an S3 bucket or a shared prefix, allowing for object-level analysis of storage. In contrast, S3 Storage Lens provides aggregated metrics by organization, account, region, storage class, bucket, prefix, and S3 Storage Lens group levels, which enhances organization-wide visibility of storage.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-04T18:34:12.932759"}}
{"question": "What does S3 Storage Class Analysis provide regarding storage class recommendations?", "answer": "S3 Storage Class Analysis provides recommendations for an optimal storage class by creating object age groups based on object-level access patterns within an individual bucket, prefix, or tag for the previous 30-90 days.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-04T18:34:18.463328"}}
{"question": "How does S3 Storage Lens help in improving cost efficiency?", "answer": "S3 Storage Lens provides daily organization level recommendations on ways to improve cost efficiency and apply data protection best practices. It offers additional granular recommendations by account, region, storage class, bucket, S3 Storage Lens group, or prefix, especially when using S3 Storage Lens advanced metrics.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-04T18:34:18.463632"}}
{"question": "What is the difference between S3 Storage Class Analysis and S3 Storage Lens in terms of their recommendations?", "answer": "S3 Storage Class Analysis focuses on creating object age groups based on access patterns to provide recommendations for optimal storage classes, particularly identifying infrequent access patterns for potential transitions to S3 Standard-IA. In contrast, S3 Storage Lens provides daily recommendations at the organization level for improving cost efficiency and data protection practices, with additional detailed insights based on various metrics and filters.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-04T18:34:18.463798"}}
{"question": "What is Amazon Athena and how does it work with data in S3?", "answer": "Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL queries. It is serverless, meaning there is no infrastructure to set up or manage, allowing you to start analyzing data immediately. Athena works directly with data stored in any S3 storage class without requiring you to load your data into it. To get started, you simply log into the Athena Management Console, define your schema, and begin querying.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-04T18:34:24.818826"}}
{"question": "When should I use S3 Object Lambda for querying data in S3?", "answer": "You should use S3 Object Lambda if you want to add transformations while filtering data as it is returned to an application. This feature allows you to add your own code to S3 GET requests to filter the data according to your specific needs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-04T18:34:24.819586"}}
{"question": "How does Amazon Athena compare to client-side filtering for querying data in S3?", "answer": "Amazon Athena allows you to process multiple S3 objects in a single query, supports complex operations like joins and window functions, and operates directly on data stored in S3 without requiring data uploads. In contrast, client-side filtering involves downloading an S3 object to an AWS compute instance and filtering the contents using data analysis libraries on the client application, such as using the Pandas library in a Python application. Client-side filtering may be more appropriate for specific data analysis needs, while Athena is better for interactive, ad-hoc querying of larger datasets.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-04T18:34:24.819833"}}
{"question": "What feature of Amazon Redshift allows for querying unstructured data in Amazon S3 without loading or ETL?", "answer": "Amazon Redshift Spectrum is the feature of Amazon Redshift that lets you run queries against exabytes of unstructured data in Amazon S3 with no loading or ETL required.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-04T18:34:34.531413"}}
{"question": "How does Amazon Redshift Spectrum improve query performance when accessing data in Amazon S3?", "answer": "Amazon Redshift Spectrum improves query performance by determining what data is local and what is in Amazon S3, generating a plan to minimize the amount of Amazon S3 data that needs to be read, and requesting Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3. It also scales out to thousands of instances if needed, allowing queries to run quickly regardless of data size.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-04T18:34:34.882718"}}
{"question": "How does Amazon S3 Replication differ from Amazon Redshift Spectrum regarding data handling?", "answer": "Amazon S3 Replication enables automatic, asynchronous copying of objects across Amazon S3 buckets, allowing for the replication of new objects and existing bucket contents between different or the same AWS Regions. In contrast, Amazon Redshift Spectrum allows querying unstructured data in Amazon S3 without loading it into Amazon Redshift and separates storage and compute to scale each independently.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-04T18:34:34.883212"}}
{"question": "What is the purpose of CRR in Amazon S3?", "answer": "CRR, or Cross-Region Replication, is an Amazon S3 feature that automatically replicates data between buckets across different AWS Regions. It provides lower-latency data access in different geographic regions and helps meet compliance requirements by storing copies of data hundreds of miles apart.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-04T18:34:40.484030"}}
{"question": "How does SRR differ from CRR in terms of data replication?", "answer": "SRR, or Same-Region Replication, replicates data between buckets within the same AWS Region, while CRR replicates data across different AWS Regions. SRR is used to address data sovereignty and compliance requirements by keeping a copy of data in a separate AWS account within the same region, whereas CRR is focused on enabling lower-latency access and compliance through geographic separation.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-04T18:34:40.484290"}}
{"question": "What can you use Amazon S3 Batch Replication for?", "answer": "Amazon S3 Batch Replication can be used to replicate existing objects between buckets, backfill a newly created bucket with existing objects, retry objects that were previously unable to replicate, migrate data across accounts, or add new buckets to your data lake.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-04T18:34:40.484657"}}
{"question": "What must be enabled for both the source and destination buckets to enable S3 Replication?", "answer": "Versioning must be enabled for both the source and destination buckets to enable S3 Replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-04T18:34:45.240203"}}
{"question": "What is the purpose of establishing replication rules in S3 Replication?", "answer": "The purpose of establishing replication rules in S3 Replication is to make copies of your objects into another storage class, in the same or a different region.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-04T18:34:45.240584"}}
{"question": "How do lifecycle actions differ between the source and destination buckets in S3 Replication?", "answer": "Lifecycle actions are not replicated in S3 Replication, meaning if you want the same lifecycle configuration applied to both the source and destination buckets, you must enable the same lifecycle configuration on both.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-04T18:34:45.241042"}}
{"question": "What are the options available when setting up S3 Replication for new destination buckets?", "answer": "When setting up S3 Replication for new destination buckets, you have the flexibility to choose the storage class of the destination bucket, the encryption type, replication metrics and notifications, Replication Time Control (RTC), and other properties.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-04T18:34:51.690821"}}
{"question": "What is required to replicate object tags across AWS Regions using Cross-Region Replication?", "answer": "For customers with Cross-Region Replication already enabled, new permissions are required in order for tags to replicate.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-04T18:34:51.691190"}}
{"question": "How does delete marker replication behave in S3 Replication, and what conditions must be met for it to work?", "answer": "When you replicate delete markers, Amazon S3 will behave as if the object was deleted in both buckets. You must have delete marker replication enabled in your replication configuration, and it can be applied to the entire bucket or to Amazon S3 objects that have a specific prefix. However, it is important to note that delete marker replication is not supported for object tag based replication rules.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-04T18:34:51.691719"}}
{"question": "What feature does S3 Batch Replication provide for objects that initially fail to replicate?", "answer": "S3 Batch Replication allows you to re-replicate objects that fail to replicate initially.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-04T18:34:55.438829"}}
{"question": "What are the two types of encryption that S3 offers for data?", "answer": "S3 offers both server-side encryption and client-side encryption. Server-side encryption involves S3 encrypting the objects for you, while client-side encryption requires you to encrypt data on the client-side before uploading it to S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-04T18:34:55.439124"}}
{"question": "How does server-side encryption differ from client-side encryption in S3?", "answer": "Server-side encryption is when S3 encrypts the objects for you, while client-side encryption is when you encrypt the data on your end before uploading it to S3.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-04T18:34:55.439614"}}
{"question": "What are the charges associated with S3 Replication for cross account replication?", "answer": "For cross account replication, customers pay for replication PUT requests and inter-region Data Transfer OUT from S3 to the destination region. Additionally, if S3 Replication Time Control (S3 RTC) is enabled, there are specific Data Transfer OUT and replication PUT request charges associated with S3 RTC. The source account pays for all data transfer, while the destination account pays for the replication PUT requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-04T18:35:02.171441"}}
{"question": "How does S3 Replication Time Control (S3 RTC) enhance replication performance?", "answer": "S3 Replication Time Control provides predictable replication performance by ensuring that most objects are replicated in seconds and 99.99% of objects within 15 minutes. It is designed to meet compliance or business requirements and is backed by a Service Level Agreement (SLA) that guarantees 99.9% of objects will be replicated in 15 minutes for each replication region pair during any billing month.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-04T18:35:02.171794"}}
{"question": "What is the difference in data transfer charges between S3 Cross Region Replication (S3 CRR) and S3 Same Region Replication (S3 SRR)?", "answer": "Data transfer charges apply only for S3 Cross Region Replication (S3 CRR) and S3 Replication Time Control (S3 RTC). There are no data transfer charges for S3 Same Region Replication (S3 SRR).", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-04T18:35:02.172218"}}
{"question": "What metrics does Amazon S3 Replication provide for monitoring the replication process?", "answer": "Amazon S3 Replication provides four detailed metrics: operations pending, bytes pending, replication latency, and operations failed replication. These metrics help monitor the total number of operations and size of objects pending replication, the replication latency between source and destination buckets, and the count of operations that did not replicate successfully for each replication rule.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-04T18:35:12.027299"}}
{"question": "How can Amazon S3 Replication Time Control improve the management of replication errors?", "answer": "Amazon S3 Replication Time Control (S3 RTC) improves the management of replication errors by sending an S3 Event Notification if an object takes more than 15 minutes to replicate and another notification when that object successfully replicates to the destination. This helps users quickly identify and address replication delays.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-04T18:35:12.028276"}}
{"question": "How does the configuration of Amazon S3 Replication metrics differ for S3 Replication Time Control enabled rules compared to other replication rules?", "answer": "For S3 Replication Time Control enabled rules, S3 Replication metrics and events are enabled by default. In contrast, for other replication rules, users need to enable these metrics manually for each new or existing replication rule.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-04T18:35:12.028602"}}
{"question": "What metrics should not be used to track S3 Batch Replication progress?", "answer": "You should not use metrics like bytes pending, operations pending, and replication latency to track S3 Batch Replication progress.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-04T18:35:16.532892"}}
{"question": "How does Amazon S3 Replication Time Control ensure the timely replication of objects?", "answer": "Amazon S3 Replication Time Control is designed to replicate 99.99% of your objects within 15 minutes, and it is backed by a service level agreement.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-04T18:35:16.533222"}}
{"question": "What happens if fewer than 99.9% of objects are replicated in 15 minutes under the S3 RTC SLA?", "answer": "If fewer than 99.9% of your objects are replicated in 15 minutes for each replication region pair during a monthly billing cycle, the S3 RTC SLA provides a service credit on any object that takes longer than 15 minutes to replicate.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-04T18:35:16.533649"}}
{"question": "What charges do you incur when using S3 Replication for both Cross-Region Replication and Same Region Replication?", "answer": "When using S3 Replication for both Cross-Region Replication (CRR) and Same Region Replication, you incur charges for storage in the selected destination S3 storage classes, storage charges for the primary copy, replication PUT requests, and applicable infrequent access storage retrieval charges. For CRR specifically, you also pay for inter-region Data Transfer OUT from S3 to your destination region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-04T18:35:24.930091"}}
{"question": "How does S3 Multi-Region Access Points improve performance for data access across multiple regions?", "answer": "S3 Multi-Region Access Points improve performance by up to 60% when accessing data sets that are replicated across multiple AWS Regions. They utilize AWS Global Accelerator to consider factors like network congestion and the location of the requesting application, allowing for dynamic routing of requests over the AWS network to the lowest latency copy of the data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-04T18:35:24.930441"}}
{"question": "What are the differences in charges when using S3 Replication between the same region and across different regions?", "answer": "When using S3 Replication within the same region, you incur charges for storage and replication PUT requests, but there are no inter-region data transfer charges. In contrast, for Cross-Region Replication (CRR), you incur additional charges for inter-region Data Transfer OUT from S3 to the destination region, which would be $2.00 for a 100 GB object transferred, along with the standard replication and storage charges.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-04T18:35:24.930919"}}
{"question": "What is the primary benefit of using S3 Multi-Region Access Points?", "answer": "The primary benefit of using S3 Multi-Region Access Points is that they accelerate and simplify storage for multi-region applications by dynamically routing S3 requests to a replicated data set, which reduces request latency and allows applications to run up to 60% faster.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-04T18:35:31.204195"}}
{"question": "How do S3 Multi-Region Access Points contribute to application resilience?", "answer": "S3 Multi-Region Access Points contribute to application resilience by helping build multi-region and multi-account applications that are more protected against accidental or unauthorized data deletion.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-04T18:35:31.204567"}}
{"question": "How do S3 Multi-Region Access Points differ from traditional S3 setups in terms of architecture?", "answer": "S3 Multi-Region Access Points differ from traditional S3 setups by allowing users to maintain a simple region-agnostic architecture for their applications while taking advantage of AWS's global infrastructure, whereas traditional setups may require more complex management of region-specific resources.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-04T18:35:31.205095"}}
{"question": "What is the maximum number of AWS Regions that you can configure a Multi-Region Access Point to route across?", "answer": "You can configure your Multi-Region Access Point to route across one bucket per AWS Region, in up to 17 AWS Regions.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-04T18:35:36.946485"}}
{"question": "How do S3 Multi-Region Access Points improve performance for applications accessing S3 over the internet?", "answer": "S3 Multi-Region Access Points improve performance by onboarding internet-based requests to the AWS global network to avoid congested network segments on the internet, which reduces network latency and jitter while improving performance. Applications can see performance improvements of up to 60% based on AWS Global Accelerator.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-04T18:35:36.946824"}}
{"question": "What is the difference between active-active and active-passive configurations for S3 Multi-Region Access Points?", "answer": "In an active-active configuration, S3 Multi-Region Access Points dynamically route requests based on factors like network congestion and the location of the requesting application to the closest copy of the data. In contrast, an active-passive configuration allows you to initiate a failover to shift S3 data access request traffic to the chosen alternate AWS Region and account within minutes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-04T18:35:36.947343"}}
{"question": "What charges apply when using an S3 Multi-Region Access Point to route requests within AWS?", "answer": "When using an S3 Multi-Region Access Point to route requests within AWS, you pay a low per-GB data routing charge for each GB processed, along with standard charges for S3 requests, storage, data transfer, and replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-04T18:35:42.157266"}}
{"question": "How do S3 Multi-Region Access Points enhance performance for applications running outside of AWS?", "answer": "S3 Multi-Region Access Points enhance performance for applications running outside of AWS by automatically routing requests through an AWS edge location over the global private AWS network to the closest copy of the data based on access latency.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-04T18:35:42.157498"}}
{"question": "What is the difference in charges when accessing S3 Multi-Region Access Points over the internet compared to within AWS?", "answer": "When accessing S3 Multi-Region Access Points over the internet, you incur a data routing charge and an internet acceleration charge, in addition to standard S3 data transfer pricing. In contrast, when routing requests within AWS, you only pay the low per-GB data routing charge and standard charges for S3 requests, storage, data transfer, and replication.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-04T18:35:42.157647"}}
{"question": "What is S3 Transfer Acceleration used for?", "answer": "S3 Transfer Acceleration is used to speed up content transfers to and from Amazon S3 using the AWS global network. It helps accelerate long-distance transfers of larger objects to and from a single Amazon S3 bucket.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-04T18:35:47.876230"}}
{"question": "How does S3 Multi-Region Access Points enhance data transfer performance?", "answer": "S3 Multi-Region Access Points enhance data transfer performance by allowing accelerated transfers across many S3 buckets in multiple AWS Regions using the AWS global network. It also enables dynamic routing of requests to the lowest latency copy of data when combined with S3 Cross Replication.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-04T18:35:47.877103"}}
{"question": "What is the difference in the scope of data transfer between S3 Transfer Acceleration and S3 Multi-Region Access Points?", "answer": "S3 Transfer Acceleration is designed for speeding up transfers to and from a single Amazon S3 bucket, while S3 Multi-Region Access Points can perform accelerated transfers across multiple S3 buckets in various AWS Regions. This means that S3 Multi-Region Access Points can handle internet-based, VPC-based, and on-premises requests across a broader range of data sources compared to S3 Transfer Acceleration.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-04T18:35:47.877338"}}
{"question": "What types of requests can S3 Object Lambda modify?", "answer": "S3 Object Lambda can modify and process data for S3 GET, LIST, and HEAD requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-04T18:35:52.070189"}}
{"question": "How does S3 Object Lambda facilitate meeting unique data format requirements for applications?", "answer": "S3 Object Lambda helps meet unique data format requirements by allowing you to add custom code to modify the data returned without having to build and operate additional infrastructure, such as a proxy layer, or maintain multiple derivative copies of the data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-04T18:35:52.070551"}}
{"question": "How does the use of AWS Lambda functions relate to S3 Object Lambda's functionality?", "answer": "S3 Object Lambda uses AWS Lambda functions to automatically process the output of S3 GET, LIST, or HEAD requests, allowing for the transformation of data returned to applications through the S3 Object Lambda endpoint.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-04T18:35:52.071051"}}
{"question": "What actions can you perform with S3 Object Lambda?", "answer": "You can use S3 Object Lambda to process data inline with S3 GET, LIST, or HEAD requests. This includes masking sensitive data for compliance, restructuring raw data for machine learning compatibility, filtering data to restrict access to specific content, and enriching object lists by querying an external index.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-04T18:35:56.370959"}}
{"question": "Why would someone use S3 Object Lambda instead of building custom processing infrastructure?", "answer": "Using S3 Object Lambda allows you to share a single copy of your data across many applications, which avoids the need to build and operate custom processing infrastructure or to store derivative copies of your data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-04T18:35:56.371301"}}
{"question": "How does S3 Object Lambda process requests compared to standard S3 requests?", "answer": "S3 Object Lambda processes requests by using Lambda functions specified by the user, which are attached to an S3 Object Lambda Access Point. In contrast, standard S3 requests do not invoke Lambda functions and do not allow for inline data processing.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-04T18:35:56.371812"}}
{"question": "What types of requests are supported by S3 Object Lambda?", "answer": "S3 Object Lambda supports GET, LIST, and HEAD requests. Any other S3 API calls made to an S3 Object Lambda Access Point will return the standard S3 API response.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-04T18:36:01.883051"}}
{"question": "How can AWS users automate the configuration of S3 Object Lambda?", "answer": "Users can automate the configuration of S3 Object Lambda by using AWS CloudFormation. When using the AWS CloudFormation template, the deployed Lambda function in the user's account will pass S3 objects back to the requesting client or application without any changes, and users can add custom code to modify and process data as it is returned.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-04T18:36:01.883401"}}
{"question": "What is the relationship between S3 Object Lambda Access Point aliases and S3 bucket names?", "answer": "Aliases for S3 Object Lambda Access Points are automatically generated and are interchangeable with S3 bucket names for data accessed through S3 Object Lambda. This means that existing S3 Object Lambda Access Points have aliases that are automatically assigned and ready for use, allowing for a seamless integration with S3 bucket naming conventions.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-04T18:36:01.883917"}}
{"question": "What happens when a S3 Object Lambda function fails?", "answer": "When a S3 Object Lambda function fails, you will receive a request response detailing the failure.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-04T18:36:07.461593"}}
{"question": "How does AWS assist in monitoring S3 Object Lambda functions?", "answer": "AWS automatically monitors S3 Object Lambda functions on your behalf, reporting metrics through Amazon CloudWatch. Additionally, Lambda logs all requests processed by your function and automatically stores logs generated by your code with Amazon CloudWatch Logs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-04T18:36:07.553017"}}
{"question": "How do the charges for S3 Object Lambda differ from general AWS Lambda usage?", "answer": "When using S3 Object Lambda, you incur a per GB charge for every gigabyte of data returned, in addition to being charged for requests based on the request type (GET, LIST, and HEAD) and AWS Lambda compute charges for the time your specified function is running to process the requested data. This differs from general AWS Lambda usage, where charges are typically based solely on the compute time and number of requests without the additional per GB data charge.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-04T18:36:07.554349"}}
{"question": "What is Mountpoint for Amazon S3 and how does it work?", "answer": "Mountpoint for Amazon S3 is an open source file client that allows you to mount an S3 bucket on your compute instance, enabling access to it as a local file system. It translates local file system operations into REST API calls on objects stored in Amazon S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-04T18:36:13.675230"}}
{"question": "In what scenarios is Mountpoint for Amazon S3 considered ideal?", "answer": "Mountpoint for Amazon S3 is ideal for read-heavy data lake workloads that process petabytes of data using random and sequential read operations on existing files, and sequential write operations for creating new files. Common use cases include petabyte-scale autonomous vehicle simulation, machine learning training, genomics analysis, and image rendering.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-04T18:36:13.675611"}}
{"question": "How does Mountpoint for Amazon S3 differ from Amazon FSx for Lustre in terms of application suitability?", "answer": "Mountpoint for Amazon S3 is suitable for applications that require high throughput for reading and writing data without modifying existing files or deleting existing directories. In contrast, Amazon FSx for Lustre is better for data lake applications that require POSIX semantics and shared file system features like appending to existing files and file locking.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-04T18:36:13.676088"}}
{"question": "What operations does Mountpoint for Amazon S3 support on existing S3 objects?", "answer": "Mountpoint for Amazon S3 supports sequential and random read operations on existing Amazon S3 objects, and it supports sequential writes for new objects.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-04T18:36:18.465889"}}
{"question": "How does Mountpoint for Amazon S3 translate file system operations?", "answer": "Mountpoint for Amazon S3 translates file system operations like read and write into object API requests made to your S3 bucket. After this translation, Amazon S3 evaluates all the relevant access policies to decide whether to authorize the request.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-04T18:36:18.466167"}}
{"question": "How does the performance of Mountpoint for Amazon S3 compare to AWS SDKs?", "answer": "Mountpoint for Amazon S3 delivers the same performance as the AWS SDKs, meaning that data lake applications achieve high single-instance transfer rates and efficiently utilize the available network bandwidth on their Amazon EC2 instance.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-04T18:36:18.466330"}}
{"question": "What type of metadata does Mountpoint for Amazon S3 not support?", "answer": "Mountpoint for Amazon S3 does not support reading or writing POSIX-style metadata, such as user ID, group ID, and permission fields.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-04T18:36:22.749380"}}
{"question": "What is the recommended method for accessing Amazon S3 from on-premises applications?", "answer": "The recommended method for accessing Amazon S3 from on-premises applications is to use AWS PrivateLink-based interface VPC endpoints.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-04T18:36:22.749747"}}
{"question": "How does accessing S3 via interface VPC endpoints differ from accessing it via gateway VPC endpoints?", "answer": "Accessing S3 via interface VPC endpoints is recommended for on-premises access or from a VPC in another AWS Region, while gateway VPC endpoints are recommended for resources that access S3 from a VPC in the same AWS Region as the S3 bucket, as they are not billed.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-04T18:36:22.750387"}}
{"question": "What is the purpose of Storage Browser for Amazon S3?", "answer": "The purpose of Storage Browser for Amazon S3 is to provide end users, such as customers, partners, and employees, with a simple interface for data stored in S3. It allows authorized users to easily browse, download, upload, copy, and delete data in S3 directly from web applications.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-04T18:36:28.727609"}}
{"question": "Why might a developer choose to use Storage Browser instead of writing custom code for S3 interactions?", "answer": "A developer might choose to use Storage Browser instead of writing custom code because it provides a simple user interface specifically designed for browsing, downloading, and uploading S3 data. This saves time and effort as it eliminates the need to write custom code to support this user experience, allowing developers to focus on other aspects of their applications.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-04T18:36:28.727893"}}
{"question": "How does the process of adding Storage Browser to an application compare to setting up authorization for it?", "answer": "The process of adding Storage Browser to an application involves three key steps: first, adding a reference to call Storage Browser when a specific page is loaded by importing the NPM package and adding code from the S3 User Guide. In contrast, setting up authorization requires configuring Storage Browser to work with IAM Identity Center, Amazon Cognito, or a custom authorization service. While the first step focuses on integrating the component into the application, the authorization setup is about ensuring that only authorized users can access the S3 data.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-04T18:36:28.728326"}}
{"question": "What is the first step to use AWS managed authorization with Storage Browser?", "answer": "The first step to use AWS managed authorization with Storage Browser is to configure an IAM Identity Center and set up permission grants for your users and groups in S3 Access Grants as defined in the S3 User Guide for setting up Storage Browser.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-04T18:36:34.298088"}}
{"question": "How does using Amazon Cognito differ from using IAM Identity Center for accessing Storage Browser?", "answer": "Using Amazon Cognito involves setting up an identity store in Cognito, associating it with an auth resource in Amplify, deploying the resource in Amplify, and connecting your application code to your auth resource. In contrast, using IAM Identity Center requires configuring the Identity Center and exchanging an identity token from an external Identity Provider with one from Identity Center, before providing the Identity Center token to Storage Browser.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-04T18:36:34.298749"}}
{"question": "What capabilities does Storage Browser provide for end users accessing S3 data?", "answer": "Storage Browser allows end users to browse buckets and prefixes, sort by object metadata, search for prefixes and objects by name, and perform actions such as uploading, downloading, copying, and deleting objects in S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-04T18:36:34.299179"}}
{"question": "What aspects of the Storage Browser interface can be customized?", "answer": "You can customize the primary colors, padding, alignment, language, and other aspects of the Storage Browser interface to match your applications design and branding.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-04T18:36:39.401329"}}
{"question": "Why would someone choose to use the Storage Browser for Amazon S3 in their application?", "answer": "Someone would choose to use the Storage Browser for Amazon S3 if they want to add a simple user interface specifically designed for browsing, downloading, and uploading S3 data to their applications without having to write their own code to support this user experience.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-04T18:36:39.402402"}}
{"question": "How does the Storage Browser simplify the process of accessing S3 data compared to writing custom code?", "answer": "The Storage Browser simplifies the process of accessing S3 data by making API calls to S3 on your behalf, allowing you to provide a user interface for end users to browse, download, upload, copy, and delete data in S3 without the need for custom coding.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-04T18:36:39.402639"}}
{"question": "What is the first step to use AWS managed authorization with Storage Browser?", "answer": "The first step to use AWS managed authorization with Storage Browser is to configure an IAM Identity Center and set up permission grants for your users and groups in S3 Access Grants as defined in the S3 User Guide for setting up Storage Browser.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-04T18:36:47.076453"}}
{"question": "How does using Amazon Cognito for authorization differ from using IAM Identity Center?", "answer": "Using Amazon Cognito for authorization involves setting up an identity store in Cognito, associating it with an auth resource in Amplify, deploying the resource in Amplify, and connecting your application code to your auth resource. In contrast, using IAM Identity Center requires configuring the Identity Center, setting up permission grants, and exchanging identity tokens. Both methods ultimately allow access to Storage Browser, but they utilize different services and configuration steps.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-04T18:36:47.076709"}}
{"question": "What functionalities do end users have when using Storage Browser with S3?", "answer": "End users can browse buckets and prefixes, sort by object metadata, search for prefixes and objects by name, and perform actions such as uploading, downloading, copying, and deleting objects in S3 when using Storage Browser.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-04T18:36:47.077249"}}
{"question": "What elements can you customize in the Storage Browser interface?", "answer": "You can customize a custom logo, primary colors, padding, alignment, language, and other aspects of the Storage Browser interface.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-04T18:36:50.618418"}}
{"question": "Why would you want to customize the Storage Browser interface?", "answer": "You may want to customize the Storage Browser interface to match your applications design and branding.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-04T18:36:50.618786"}}
{"question": "How does customizing the Storage Browser interface relate to application branding?", "answer": "Customizing the Storage Browser interface allows you to align its visual elements, such as the logo and colors, with your application's overall design and branding, ensuring a cohesive user experience.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-04T18:36:50.619280"}}
{"question": "What is Amazon SageMaker AI used for?", "answer": "Amazon SageMaker AI is used as a fully managed machine learning (ML) service that allows data scientists and developers to quickly and confidently build, train, and deploy ML models into a production-ready hosted environment.", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-04T18:36:55.788744"}}
{"question": "How does Amazon SageMaker AI benefit organizations in terms of data management?", "answer": "Amazon SageMaker AI benefits organizations by allowing them to store and share data without the need to build and manage their own servers, which gives them more time to collaboratively build and develop their ML workflows, enabling faster progress.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-04T18:36:55.789023"}}
{"question": "What is the relationship between Amazon SageMaker and Amazon SageMaker AI?", "answer": "Amazon SageMaker was renamed to Amazon SageMaker AI on December 03, 2024, but this name change does not affect any of the existing Amazon SageMaker features. The API namespaces remain unchanged for backward compatibility purposes.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-04T18:36:55.789206"}}
{"question": "What is Amazon SageMaker described as in the context?", "answer": "Amazon SageMaker is described as a unified platform for data, analytics, and AI. It brings together AWS machine learning and analytics capabilities, delivering an integrated experience for analytics and AI with unified access to all your data.", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-04T18:37:01.620940"}}
{"question": "What capabilities does Amazon SageMaker include?", "answer": "Amazon SageMaker includes several capabilities such as Amazon SageMaker AI for building, training, and deploying ML and foundation models; Amazon SageMaker Lakehouse for unifying data access; Amazon SageMaker Data and AI Governance for data and AI collaboration; SQL Analytics for gaining insights; Amazon SageMaker Data Processing for data analysis and preparation; Amazon SageMaker Unified Studio for a consolidated development environment; and Amazon Bedrock for building and scaling generative AI applications.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-04T18:37:01.621285"}}
{"question": "How does Amazon SageMaker Lakehouse relate to data sources?", "answer": "Amazon SageMaker Lakehouse unifies data access across various data sources including Amazon S3 data lakes and Amazon Redshift.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-04T18:37:01.621686"}}
{"question": "What is the primary function of Amazon SageMaker AI?", "answer": "The primary function of Amazon SageMaker AI is to build, train, and deploy ML and foundation models, with fully managed infrastructure, tools, and workflows.", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-04T18:37:05.901503"}}
{"question": "How does Amazon SageMaker Lakehouse enhance data access?", "answer": "Amazon SageMaker Lakehouse enhances data access by unifying it across Amazon S3 data lakes, Amazon Redshift, and other data sources.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-04T18:37:05.901841"}}
{"question": "How does Amazon SageMaker Data Processing compare to SQL Analytics in terms of their focus?", "answer": "Amazon SageMaker Data Processing focuses on analyzing, preparing, and integrating data for analytics and AI using open-source frameworks, while SQL Analytics, specifically with Amazon Redshift, is designed to gain insights with a price-performant SQL engine.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-04T18:37:05.902078"}}
{"question": "What is AWS Secrets Manager used for?", "answer": "AWS Secrets Manager is a secrets management service that helps you protect access to your applications, services, and IT resources. It enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-04T18:37:10.200350"}}
{"question": "How does AWS Secrets Manager support developers in managing application secrets?", "answer": "AWS Secrets Manager supports developers by allowing them to replace hardcoded secrets in their applications with code that retrieves those secrets programmatically using the Secrets Manager APIs. This enhances security by eliminating the need to store sensitive information directly in the application code.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-04T18:37:10.200700"}}
{"question": "How does AWS Secrets Manager's secret rotation feature differ for database types hosted on AWS compared to others?", "answer": "AWS Secrets Manager allows for the rotation of passwords for supported database types hosted on AWS on a schedule or on demand, without risking impact on applications. In contrast, for other secrets such as passwords for Oracle databases hosted on Amazon EC2 or OAuth refresh tokens, users can extend the rotation functionality by modifying sample Lambda functions.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-04T18:37:10.201202"}}
{"question": "What types of secrets can you manage with AWS Secrets Manager?", "answer": "You can manage secrets such as database credentials, on-premises resource credentials, SaaS application credentials, third-party API keys, and Secure Shell (SSH) keys using AWS Secrets Manager.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T18:37:15.717387"}}
{"question": "How does AWS Secrets Manager facilitate the rotation of credentials?", "answer": "AWS Secrets Manager natively allows you to rotate credentials for Amazon Relational Database Service (RDS), Amazon DocumentDB, and Amazon Redshift. You can also extend its functionality to rotate other secrets, such as credentials for Oracle databases hosted on EC2 or OAuth refresh tokens, by modifying sample AWS Lambda functions provided in the Secrets Manager documentation.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T18:37:15.717726"}}
{"question": "How do the methods for uploading secrets differ when using the Secrets Manager console compared to using AWS SDK or AWS CLI?", "answer": "When using the Secrets Manager console, you can upload a secret through the graphical interface. In contrast, with the AWS SDK or AWS CLI, you can upload a secret programmatically, but you can only upload each secret once using these methods. Additionally, you can write a script to upload multiple secrets using the AWS SDK or AWS CLI, while the console is more suited for single secret uploads.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-04T18:37:15.718221"}}
{"question": "What does AWS Secrets Manager do to enable database credential rotation?", "answer": "AWS Secrets Manager enables you to configure database credential rotation on a schedule, allowing you to follow security best practices and rotate your database credentials safely. When a rotation is initiated, it uses super database credentials to create a clone user with the same privileges but a different password.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-04T18:37:20.903059"}}
{"question": "Why is it important to rotate database credentials using AWS Secrets Manager?", "answer": "Rotating database credentials using AWS Secrets Manager is important because it helps you follow security best practices by ensuring that database credentials are regularly updated, which can reduce the risk of unauthorized access to your databases.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-04T18:37:20.903406"}}
{"question": "How does the authentication process differ when AWS Secrets Manager rotates a database credential compared to establishing a connection?", "answer": "When AWS Secrets Manager rotates a database credential, the open database connection is not re-authenticated. This means that while the credentials are updated, the existing connections do not require re-authentication until they are re-established.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-04T18:37:20.903921"}}
{"question": "What encryption algorithm does AWS Secrets Manager use to encrypt secrets?", "answer": "AWS Secrets Manager uses the AES-256 encryption algorithm to encrypt your secrets.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-04T18:37:27.460021"}}
{"question": "How does AWS Secrets Manager handle the storage and retrieval of secrets?", "answer": "When a secret is stored, AWS Secrets Manager requests a plaintext and an encrypted data key from AWS Key Management Service (KMS). It uses the plaintext data key to encrypt the secret in memory and stores the encrypted secret and encrypted data key. Upon retrieval, Secrets Manager decrypts the data key using the AWS KMS default keys and then uses the plaintext data key to decrypt the secret. The data key is stored encrypted and is never written to disk in plaintext, and Secrets Manager does not write or cache the plaintext secret to persistent storage.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-04T18:37:27.460366"}}
{"question": "What are the payment terms for using AWS Secrets Manager compared to other AWS services?", "answer": "With AWS Secrets Manager, you pay only for what you use, with no minimum fee, no set-up fees, or commitments required to begin using the service. This is different from some other AWS services that may require a commitment or have minimum fees. At the end of the month, your credit card is automatically charged for that months usage, which includes charges for the number of secrets stored and for API requests made to the service.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-04T18:37:27.460582"}}
{"question": "What is the duration of the AWS Secrets Manager free trial?", "answer": "The AWS Secrets Manager free trial lasts for 30 days, starting when you store your first secret.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-04T18:37:33.083602"}}
{"question": "What benefits does the AWS Free Tier provide to new customers starting July 15, 2025?", "answer": "New AWS customers will receive up to $200 in AWS Free Tier credits, which can be applied towards eligible AWS services, including Secrets Manager. Additionally, customers can choose between a free plan and a paid plan at account sign-up, with the free plan available for 6 months after account creation.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-04T18:37:33.083945"}}
{"question": "How do the free trial and Free Tier credits differ for AWS Secrets Manager?", "answer": "The free trial for AWS Secrets Manager is a 30-day period that allows users to rotate, manage, and retrieve secrets at no additional charge, starting when they store their first secret. In contrast, the Free Tier credits, which are available to new customers starting July 15, 2025, provide up to $200 that can be applied towards eligible AWS services, including Secrets Manager, and must be used within 12 months of account creation.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-04T18:37:33.084462"}}
{"question": "What is AWS Security Hub?", "answer": "AWS Security Hub is a unified cloud security solution that prioritizes critical security issues and helps users respond at scale. It detects critical issues by automatically correlating and enriching security signals from multiple sources, allowing security teams to surface and prioritize active risks in their cloud environment through automated analysis and contextual insights.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-04T18:37:38.627730"}}
{"question": "How does AWS Security Hub help improve security decision-making?", "answer": "AWS Security Hub improves security decision-making by transforming complex security signals into actionable insights through intuitive visualizations. This enables users to make more informed security decisions quickly.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-04T18:37:38.628074"}}
{"question": "What distinguishes AWS Security Hub from AWS Security Hub CSPM?", "answer": "AWS Security Hub is a comprehensive cloud security solution that correlates and analyzes security signals from various sources, while AWS Security Hub CSPM (Cloud Security Posture Management) is a specific capability within Security Hub that focuses on providing automated security best practice checks to understand overall security posture across AWS accounts.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-04T18:37:38.628604"}}
{"question": "What are the core capabilities included in AWS Security Hub?", "answer": "AWS Security Hub includes core security capabilities such as posture management through Security Hub CSPM and vulnerability management through Amazon Inspector. Additionally, it integrates with Amazon GuardDuty for threat detection and Amazon Macie for sensitive data discovery.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T18:37:43.282790"}}
{"question": "How does the enhanced Security Hub improve the identification of security risks?", "answer": "The enhanced Security Hub improves the identification of security risks by automatically correlating security signals across multiple capabilities, such as vulnerability management, threat detection, posture management, and sensitive data discovery. This correlation helps identify critical security risks that might be missed when findings are viewed in isolation.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T18:37:43.283158"}}
{"question": "How does the new version of Security Hub compare to the previous version in terms of security findings aggregation?", "answer": "The new version of Security Hub retains the features of security findings aggregation and posture management from the previous version but enhances them with additional capabilities for automated correlation, analysis, and automated response. This evolution enables users to gain broader visibility and actionable insights compared to the previous version.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-04T18:37:43.283377"}}
{"question": "What is the primary use case of AWS Security Hub CSPM?", "answer": "The primary use case of AWS Security Hub CSPM is to provide a unified cloud security solution that prioritizes and helps you respond to critical security issues, including security posture management through automated best practice checks.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-04T18:37:47.923071"}}
{"question": "How does AWS Security Hub enhance security signal analysis?", "answer": "AWS Security Hub enhances security signal analysis through automated correlation across multiple security signals with enriched context, allowing for individual checks against best practices and compliance standards.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-04T18:37:47.923431"}}
{"question": "What are the differences between AWS Security Hub and Security Hub CSPM?", "answer": "AWS Security Hub is a unified cloud security solution that includes core capabilities such as Security Hub CSPM and Amazon Inspector, while Security Hub CSPM specifically focuses on security posture management and automated best practice checks. Security Hub can integrate additional capabilities like Amazon GuardDuty and Amazon Macie, whereas Security Hub CSPM is primarily concerned with compliance and security checks.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-04T18:37:47.925576"}}
{"question": "What are the core capabilities of the recommended unified security solution in AWS Security Hub?", "answer": "The core capabilities of the recommended unified security solution in AWS Security Hub include Security Hub CSPM for posture management and Amazon Inspector for vulnerability management, which encompasses Amazon EC2 scanning, Amazon ECR container scanning, and AWS Lambda standard scanning.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T18:37:53.108824"}}
{"question": "Why is the unified security solution recommended over the individual approach?", "answer": "The unified security solution is recommended because it provides automated correlation and response capabilities across all enabled security capabilities. This approach offers enhanced context across security signals, helping users prioritize and respond to security risks at scale. In contrast, the individual approach requires manual correlation of findings, which can be less efficient.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T18:37:53.109120"}}
{"question": "How does the management of security findings differ between the unified and individual approaches?", "answer": "In the unified approach, security findings are managed through a single delegated administrator console, allowing for automated correlation and management across multiple AWS Regions and accounts. In contrast, the individual approach requires users to manage security findings separately, necessitating manual correlation to identify and prioritize critical security risks.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-04T18:37:53.109286"}}
{"question": "What core capabilities are automatically enabled when Security Hub reaches General Availability?", "answer": "When Security Hub reaches General Availability, it will automatically enable its core capabilities, which include Security Hub CSPM for posture management and Amazon Inspector capabilities for vulnerability management. The Amazon Inspector capabilities specifically include Amazon EC2 scanning, Amazon ECR scanning, and AWS Lambda standard scanning.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T18:37:58.824506"}}
{"question": "Why is it important to enable AWS Config when using Security Hub CSPM?", "answer": "It is important to enable AWS Config when using Security Hub CSPM because Security Hub CSPM requires AWS Config to be enabled in your account and configured to record resource configuration changes. AWS Config needs to track these configuration changes in order to identify potential misconfigurations in your resources.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T18:37:58.824876"}}
{"question": "How do the optional capabilities of Amazon GuardDuty and Amazon Macie compare to the core capabilities of Security Hub?", "answer": "The optional capabilities of Amazon GuardDuty and Amazon Macie differ from the core capabilities of Security Hub in that the core capabilities, which include Security Hub CSPM and Amazon Inspector scanning, are essential for using the enhanced Security Hub features like exposure findings and automated correlation analysis. In contrast, while Amazon GuardDuty and Amazon Macie provide additional security functionalities, they are not required to use Security Hub and are recommended for comprehensive security coverage.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-04T18:37:58.825397"}}
{"question": "What does Security Hub provide in terms of security management?", "answer": "Security Hub provides a unified view and advanced correlation capabilities for security management. It complements other AWS security services by correlating and enriching findings from services like Amazon GuardDuty, Amazon Inspector, and Amazon Macie, while also offering enhanced analytics and automated response capabilities across the entire cloud environment.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-04T18:38:04.240413"}}
{"question": "How does Security Hub help prioritize security findings?", "answer": "Security Hub helps prioritize security findings through two mechanisms: insights and security standards. Insights are grouped or correlated findings that identify higher-priority issues faster, such as potential malware infections on EC2 instances. Security standards are sets of controls based on regulatory requirements or best practices, with AWS defining specific security checks aligned to these controls.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-04T18:38:04.240761"}}
{"question": "How does Security Hub's correlation of findings compare to viewing findings in isolation?", "answer": "Security Hub's correlation of findings allows for a more comprehensive analysis of security issues by considering resource relationships and signals from various capabilities, leading to the generation of exposure findings. This approach helps users visually understand potential attack paths and complex security scenarios, which may be missed when viewing findings in isolation. In contrast, viewing findings in isolation may not provide the same level of insight into critical security issues.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-04T18:38:04.241274"}}
{"question": "How does Security Hub determine the severity of exposure findings?", "answer": "Security Hub determines the severity of exposure findings by analyzing and correlating multiple security traits across AWS services. It assigns a severity rating based on how these factors are correlated rather than evaluating them in isolation. For example, a resource with an identified vulnerability may receive a higher severity rating if it is exploitable from the internet or has access to sensitive data.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-04T18:38:09.163782"}}
{"question": "What factors does Security Hub consider when calculating the likelihood of exploit for a risk?", "answer": "Security Hub considers both external signals, such as the Exploit Protection Scoring System (EPSS), and internal threat intelligence to determine the probability that the risk will be exploited. This comprehensive approach assesses the likelihood of exploit for exposure findings related to Amazon Elastic Compute Cloud (EC2) instances and AWS Lambda functions.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-04T18:38:09.164127"}}
{"question": "What is the relationship between Security Hub's automated correlation of security signals and the identification of potential attack paths?", "answer": "The automated correlation of security signals by Security Hub helps to identify potential attack paths by visualizing how vulnerabilities and misconfigurations might be chained together to affect critical resources. This insight allows users to understand which critical resources could be impacted and the scope of potential exposure, enabling them to prioritize remediation efforts to protect these resources before risks can be exploited.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-04T18:38:09.164629"}}
{"question": "What are the sources of findings for Security Hub during the preview period?", "answer": "During the preview period, Security Hub receives findings from Security Hub CSPM, Amazon GuardDuty, Amazon Inspector, and Amazon Macie.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T18:38:13.382201"}}
{"question": "How does the enhanced Security Hub differ from Security Hub CSPM in terms of the types of findings generated?", "answer": "The enhanced Security Hub generates exposure findings by correlating security signals from AWS Security Hub CSPM, Amazon Inspector, and Amazon Macie to identify critical security risks, while Security Hub CSPM does not generate these exposure findings.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T18:38:13.382528"}}
{"question": "What is the difference between the formats of findings used by Security Hub and Security Hub CSPM?", "answer": "The enhanced Security Hub uses the OCSF (Open Cybersecurity Schema Framework) format for findings, while Security Hub CSPM uses the ASFF (AWS Security Finding Format). This difference reflects their distinct approaches to security finding management and analysis.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-04T18:38:13.382997"}}
{"question": "What resource types can be evaluated by AWS Security Hub?", "answer": "AWS Security Hub can evaluate resource types that are supported by its security capabilities, which include Security Hub CSPM, Amazon Inspector, GuardDuty, and Macie. All individual resources within these resource types are included in the resource list.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:38:19.654992"}}
{"question": "How does AWS Security Hub facilitate the integration of findings with other tools?", "answer": "AWS Security Hub supports workflow options by enabling the export of findings via EventBridge. This allows users to set up integrations with chat systems such as Slack, create automated remediation pipelines using AWS Lambda, or use partner security orchestration tools, SIEMs, and ticketing systems like ServiceNow.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:38:19.655350"}}
{"question": "What is the recommended approach for managing Delegated Administrators across AWS Security Hub and its associated services?", "answer": "The recommended approach is to use the same Delegated Administrator for all security capabilities, including Security Hub, Security Hub CSPM, GuardDuty, Amazon Inspector, and Macie. This helps maintain consistent governance and least-privileged access control.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:38:19.655735"}}
{"question": "What are automation rules in Security Hub and Security Hub CSPM used for?", "answer": "Automation rules in Security Hub can make updates to findings and automatically create tickets in Jira or ServiceNow, but these rules apply only to findings within Security Hub. In contrast, automation rules in Security Hub CSPM can also make updates to findings, but these rules apply only to findings within Security Hub CSPM. Each solution's automation rules operate independently.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T18:38:27.605467"}}
{"question": "How do insights in Security Hub CSPM help AWS users?", "answer": "Insights in Security Hub CSPM help AWS users by providing a collection of related findings. They offer managed insights using filters that can be tailored for unique environments, aiding in the identification of security issues such as Amazon EC2 instances missing security patches or Amazon S3 buckets with public read or write permissions.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T18:38:27.605815"}}
{"question": "What is the difference between the automation rules in Security Hub and Security Hub CSPM?", "answer": "The automation rules in Security Hub apply only to findings within Security Hub, while the automation rules in Security Hub CSPM apply only to findings within Security Hub CSPM. Additionally, each set of automation rules operates independently, meaning they must be configured individually based on where the user wants to manage their findings.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-04T18:38:27.606318"}}
{"question": "What is the purpose of the AWS Foundational Security Best Practices standard?", "answer": "The purpose of the AWS Foundational Security Best Practices standard is to provide a set of controls that detect when AWS accounts and resources deviate from security best practices. It allows continuous evaluation of AWS accounts and workloads to quickly identify areas of deviation from best practices and provides actionable and prescriptive guidance on how to improve and maintain an organizations security posture.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T18:38:34.088816"}}
{"question": "How do Security Hub CSPM and AWS Config conformance packs differ in their approach to compliance management?", "answer": "Security Hub CSPM is a core capability that provides security and compliance posture management as a service, primarily using AWS Config and AWS Config rules to evaluate the configuration of AWS resources. In contrast, AWS Config conformance packs are templates that package a group of AWS Config rules and associated remediation actions into a single entity, simplifying the management and deployment of rules across an organization. While Security Hub CSPM is geared towards operationalizing existing compliance standards, AWS Config conformance packs allow users to assemble their own compliance or security standards.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T18:38:34.089161"}}
{"question": "What mechanisms do Security Hub CSPM and AWS Config use to evaluate compliance?", "answer": "Security Hub CSPM uses AWS Config and AWS Config rules as its primary mechanism to evaluate the configuration of AWS resources. AWS Config rules can be invoked periodically or upon detecting changes to resource configurations, allowing for continuous auditing and assessment of compliance with organizational policies and guidelines.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-04T18:38:34.089740"}}
{"question": "What is the primary purpose of Audit Manager?", "answer": "The primary purpose of Audit Manager is to be used by audit and compliance professionals to continuously assess compliance with regulations and industry standards.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-04T18:38:39.242831"}}
{"question": "How do Audit Manager and Security Hub CSPM complement each other in managing compliance and security?", "answer": "Audit Manager and Security Hub CSPM complement each other because Audit Manager collects findings from Security Hub CSPMs automated security checks and combines them with other forms of evidence, like AWS CloudTrail logs, to generate comprehensive assessment reports. Security Hub CSPM focuses on continuous monitoring and improving the security posture by conducting automated security checks aligned with industry frameworks, while Audit Manager provides the framework for assessing compliance through a combination of automated and manual evidence.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-04T18:38:39.243171"}}
{"question": "In what way do the evidence collection capabilities of Audit Manager differ from those of Security Hub CSPM?", "answer": "Audit Manager covers a full set of controls in each supported framework, including those that require manual evidence upload, such as an incident response plan. In contrast, Security Hub CSPM focuses on generating only automated evidence via its security checks for a subset of controls and does not cover controls that require evidence from other AWS services or manual evidence uploads.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-04T18:38:39.243566"}}
{"question": "What is the purpose of AWS Systems Manager OpsCenter?", "answer": "AWS Systems Manager OpsCenter helps IT operators and DevOps engineers diagnose and resolve operational issues related to AWS resources in a central location.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-04T18:38:43.184688"}}
{"question": "Why do most customers separate their security issues from operational issues when using AWS?", "answer": "Most customers separate their security issues and operational issues because security issues are sensitive and typically have different access requirements.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-04T18:38:43.185048"}}
{"question": "How do Security Hub and Systems Manager differ in their approach to managing issues?", "answer": "Security Hub is used by customers to understand, manage, and remediate security issues, while Systems Manager is used to understand, manage, and remediate operational issues. Security Hub focuses on security posture, whereas Systems Manager focuses on operational efficiency.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-04T18:38:43.185568"}}
{"question": "What is the primary purpose of AWS Security Hub CSPM?", "answer": "The primary purpose of AWS Security Hub CSPM is to be used by security teams, compliance professionals, and DevOps engineers to continuously monitor and improve the security posture of their AWS accounts and resources.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-04T18:38:50.353153"}}
{"question": "How do AWS Control Tower and Security Hub CSPM work together to enhance security?", "answer": "AWS Control Tower and Security Hub CSPM work together to enhance security by providing complementary services. Customers should use AWS Control Tower's preventative guardrails in combination with the security best practice controls in Security Hub CSPM, as they are mutually reinforcing and help ensure that accounts and resources are in a secure state. AWS Control Tower applies high-level rules to enforce policies and detect violations, while Security Hub CSPM performs security best practice checks and aggregates security findings.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-04T18:38:50.353496"}}
{"question": "What are the key functionalities of AWS Control Tower compared to Security Hub CSPM?", "answer": "AWS Control Tower focuses on setting up and governing a secure, multi-account AWS environment based on AWS best practices, applying mandatory high-level rules called guardrails, and ensuring account configurations align with Security Hub CSPM best practices. In contrast, Security Hub CSPM continuously monitors and improves security posture, aggregates security findings, and performs checks against AWS Foundational Security Best Practices and other standards. While AWS Control Tower manages governance and policy enforcement, Security Hub CSPM emphasizes ongoing security monitoring and compliance.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-04T18:38:50.354024"}}
{"question": "What capabilities need to be enabled separately during the preview period of the enhanced Security Hub?", "answer": "During the preview period, you need to enable each capability separately: Security Hub CSPM, Amazon Inspector, Amazon GuardDuty, and Amazon Macie.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T18:38:55.479835"}}
{"question": "How does the enhanced Security Hub improve security management compared to the standard Security Hub CSPM?", "answer": "The enhanced Security Hub improves security management by automatically correlating and enriching security signals across multiple capabilities, transforming them into actionable insights, and providing automated response workflows. This helps reduce security risks, improve team productivity, and minimize operational disruptions while maintaining comprehensive visibility into the security posture.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T18:38:55.480189"}}
{"question": "How do the security checks of Security Hub CSPM differ from the requirements of security standards?", "answer": "Security Hub CSPM focuses on automated security checks, while most security standards have various controls that cannot be checked in an automated fashion. Therefore, those controls are out of scope for Security Hub CSPM. Although Security Hub CSPM security checks can help prepare for an audit, they do not guarantee passing an audit associated with the security standard.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-04T18:38:55.480681"}}
{"question": "What versions of the CIS AWS Foundations Benchmark does Security Hub CSPM support?", "answer": "Security Hub CSPM supports CIS AWS Foundations Benchmark v1.2.0 and v1.4.0.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-04T18:38:59.078145"}}
{"question": "How does Security Hub CSPM relate to the NIST SP 800-53 Rev. 5 framework?", "answer": "Security Hub CSPM provides controls that support select NIST SP 800-53 requirements, and these controls are evaluated through automated security checks.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-04T18:38:59.078504"}}
{"question": "What is the difference between the PCI DSS versions supported by Security Hub CSPM?", "answer": "Security Hub CSPM supports both PCI DSS version 3.2.1 and version 4.0.1, but the context does not provide specific differences between these two versions.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-04T18:38:59.079004"}}
{"question": "What is AWS SAM?", "answer": "AWS SAM, or the AWS Serverless Application Model, is an open source framework for building serverless applications. It provides shorthand syntax to express functions, APIs, databases, and event source mappings, allowing users to define the application they want with just a few lines per resource using YAML.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-04T18:39:03.793711"}}
{"question": "How does AWS SAM facilitate the deployment of serverless applications?", "answer": "AWS SAM facilitates the deployment of serverless applications by transforming and expanding the SAM syntax into AWS CloudFormation syntax during deployment. This allows CloudFormation to provision resources with reliable deployment capabilities.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-04T18:39:03.794052"}}
{"question": "How does the cost structure of using AWS SAM compare to manually creating AWS resources?", "answer": "There is no additional charge to use AWS SAM itself. Users pay for the AWS resources created using SAM in the same manner as if they created them manually. This means that users only pay for what they use, as they use it, with no minimum fees or required upfront commitments.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-04T18:39:03.794534"}}
{"question": "What is a SAM template file?", "answer": "A SAM template file is a YAML configuration that represents the architecture of a serverless application. It is used to declare all of the AWS resources that comprise your serverless application in one place.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-04T18:39:08.561292"}}
{"question": "How do AWS SAM templates relate to AWS CloudFormation templates?", "answer": "AWS SAM templates are an extension of AWS CloudFormation templates. This means that any resource that can be declared in an AWS CloudFormation template can also be declared in an AWS SAM template.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-04T18:39:08.561643"}}
{"question": "What are the primary functions of the AWS SAM CLI commands 'sam package' and 'sam deploy'?", "answer": "The 'sam package' command lets you bundle your application code and dependencies into a deployment package, while the 'sam deploy' command allows you to deploy your serverless application to the AWS Cloud.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-04T18:39:08.562176"}}
{"question": "What services can be used to build and run serverless applications?", "answer": "You can use fully managed AWS services such as AWS Lambda for compute, Amazon API Gateway for APIs, and Amazon DynamoDB for databases to build and run serverless applications.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T18:39:13.529273"}}
{"question": "What are the benefits of using serverless applications according to the context?", "answer": "Serverless applications eliminate the need to provision, deploy, or manage servers or other infrastructure. They come with built-in high availability and scale continuously and automatically.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T18:39:13.529621"}}
{"question": "How does the AWS Serverless Application Repository facilitate the deployment of applications compared to traditional application deployment?", "answer": "The AWS Serverless Application Repository makes it easy to deploy applications for common use cases like web and mobile back-ends, stream processing, and machine learning, allowing users to quickly get started with the AWS Serverless platform without the overhead of managing infrastructure, which is typically required in traditional application deployment.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-04T18:39:13.530136"}}
{"question": "What license do applications provided by AWS fall under?", "answer": "Applications provided by AWS are available under the MIT open source license.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-04T18:39:19.028655"}}
{"question": "What steps do you need to follow to publish a serverless application using the AWS Serverless Application Model (SAM)?", "answer": "To publish a serverless application, you need to describe the application using the AWS Serverless Application Model (SAM) format, package it using the AWS CLI, and then publish it using the AWS Management Console, AWS CLI, or AWS SDKs. Additionally, you must have a valid AWS account and provide a name, description, source code link, and a LICENSE.txt for your application.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-04T18:39:19.029000"}}
{"question": "How do the validation processes differ for applications published by AWS and those published by third parties?", "answer": "All applications published by AWS are vetted for license adherence and code quality. In contrast, applications published by third parties are validated specifically for correct use of permissions to ensure consumers are aware of which resources can be modified or accessed by the application.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-04T18:39:19.029508"}}
{"question": "What is the maximum number of nested applications that can be included in a single top-level application template?", "answer": "The maximum number of nested applications that can be included in a single top-level application template is 199.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T18:39:23.632935"}}
{"question": "What is a nested serverless application and how does it relate to AWS CloudFormation?", "answer": "A nested serverless application is a component that is deployed as part of another serverless application. These nested applications are deployed as AWS CloudFormation nested stacks, allowing common patterns to be defined in multiple application templates and reused across different applications.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T18:39:23.633279"}}
{"question": "How do AWS Lambda and Amazon API Gateway work together in the context of charging fees for serverless applications?", "answer": "AWS Lambda can be integrated behind Amazon API Gateway to charge a fee for the use of a serverless application. This integration allows you to sell the API as a SaaS product through the AWS Marketplace.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-04T18:39:23.633814"}}
{"question": "What command can be used to ensure that nested applications are available before deployment?", "answer": "You can use the existing SAM CLI command 'sam package' to ensure that nested applications are still available to you before you deploy the application in your account.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T18:39:29.012515"}}
{"question": "How can access to serverless applications in the Serverless Application Repository be controlled?", "answer": "Access to serverless applications in the Serverless Application Repository can be controlled using AWS IAM resource-based policies. These policies can be used to keep applications private, grant cross-account access, grant organization access, or make them publicly available.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T18:39:29.012859"}}
{"question": "What is the difference in sharing applications with individual accounts versus an AWS Organization?", "answer": "You can share an application only with accounts that belong to the same AWS Organization as your account, whereas sharing with individual accounts can be done through resource-based policies. Additionally, when sharing with an AWS Organization, you can grant access to all accounts within that organization.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T18:39:29.013293"}}
{"question": "Is it possible to share applications within an organizational unit?", "answer": "No, sharing of applications within an organizational unit isnt supported.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-04T18:39:33.247001"}}
{"question": "How can I provide access to my application for certain accounts in an organization?", "answer": "To provide access to your application for certain accounts in an organization, you need to update the resource-based policy to include the AWS accounts along with the AWS organization ID with whom you would like to share the application.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-04T18:39:33.247379"}}
{"question": "What are the differences between keeping an app private and granting cross-account access?", "answer": "Keeping an app private means that it is only accessible by the owner, while granting cross-account access allows specific AWS accounts outside of the owner's account to access the application. Both options provide different levels of access control depending on the needs of the user.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-04T18:39:33.247892"}}
{"question": "What types of forms can AWS Serverless Applications be made available in within the Repository?", "answer": "AWS Serverless Applications can be made available in either binary or source code form within the Repository. This applies to applications made available privately, across specified AWS accounts, or to all AWS customers.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T18:39:42.844622"}}
{"question": "What responsibilities does a publisher have when submitting their AWS Serverless Application to the Repository?", "answer": "A publisher is responsible for ensuring they have all licenses and necessary permissions to submit their AWS Serverless Applications to the Repository. They must also submit the terms of the application's license(s), review, evaluate, and test the application before submission, and ensure it does not contain malware or harmful content.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T18:39:42.844999"}}
{"question": "How does the responsibility of AWS customers differ from that of publishers regarding AWS Serverless Applications?", "answer": "Publishers are responsible for submitting their AWS Serverless Applications with the necessary licenses, permissions, and ensuring the applications meet quality standards. In contrast, AWS customers are responsible for complying with the license(s) and any attribution or requirements when they download these applications, as well as determining if they have the appropriate rights if they create derivative works.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-04T18:39:42.845544"}}
{"question": "Who is responsible for the licensing agreements between Publishers and AWS customers?", "answer": "The licensing agreements are solely between the Publisher and AWS customers. Neither AWS nor any of its affiliates are a party to that license or agreement, and they will have no liability or obligations under that agreement.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-04T18:39:46.791448"}}
{"question": "What does the term 'Repository Content' refer to in the context of AWS Serverless Applications?", "answer": "In this context, 'Repository Content' refers to AWS Serverless Applications and any other third-party materials available in the Repository.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-04T18:39:46.791791"}}
{"question": "How does the liability of AWS regarding Repository Content compare to that of Publishers and copyright holders?", "answer": "AWS, Publishers, and copyright holders all state that they will not be liable for any claims, damages, or other liabilities arising from the Repository Content or its use. Therefore, their liabilities are similarly limited regarding the Repository Content.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-04T18:39:46.791954"}}
{"question": "What is the purpose of letting the team know about content quality?", "answer": "The purpose of letting the team know is to improve the quality of the content on their pages.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-04T18:39:50.412759"}}
{"question": "Why is it important to improve the quality of content on pages?", "answer": "Improving the quality of content on pages is important because it enhances the user experience, ensures accurate information is presented, and can lead to greater engagement from visitors.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-04T18:39:50.413101"}}
{"question": "What action should be taken if someone wants to contribute to content quality improvement?", "answer": "If someone wants to contribute to content quality improvement, they should let the team know.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-04T18:39:50.413623"}}
{"question": "What is the primary purpose of AWS Service Catalog?", "answer": "The primary purpose of AWS Service Catalog is to allow IT administrators to create, manage, and distribute catalogs of approved products to end users, enabling them to access the products they need in a personalized portal while enforcing compliance with organizational business policies.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:39:55.357399"}}
{"question": "How does AWS Service Catalog benefit organizations in terms of agility and cost management?", "answer": "AWS Service Catalog benefits organizations by increasing agility and reducing costs as it allows end users to find and launch only the products they need from a catalog that is controlled by administrators, ensuring compliance with policies while streamlining resource deployment.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:39:55.357743"}}
{"question": "How does AWS Service Catalog support both large organizations and small teams?", "answer": "AWS Service Catalog supports large organizations by providing a standard method of provisioning cloud resources for thousands of users through centralized policy management. It also caters to small teams by allowing front-line development managers to provide and maintain a standard development and testing environment.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:39:55.358258"}}
{"question": "What is a portfolio in the context of AWS Service Catalog?", "answer": "A portfolio is a collection of products, with configuration information that determines who can use those products and how they can use them. Administrators can create a customized portfolio for each type of user in an organization and selectively grant access to the appropriate portfolio.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-04T18:39:59.939948"}}
{"question": "How do portfolios help administrators manage product access in an organization?", "answer": "By using portfolios, permissions, sharing, and constraints, administrators can ensure that users are launching products that are configured properly for the organizations needs. This allows for tailored access to products based on user type and specific organizational requirements.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-04T18:39:59.940235"}}
{"question": "What is the difference between portfolios and products in AWS Service Catalog?", "answer": "Portfolios are collections of products that include configuration information about who can use them and how, while products are the individual offerings that can be included in multiple portfolios. Portfolios manage access and organization of products, whereas products are the actual services or tools provided.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-04T18:39:59.940729"}}
{"question": "What information do you specify when creating a portfolio in the AWS Service Catalog console?", "answer": "When creating a portfolio in the AWS Service Catalog console, you specify the name, a description, and the owner of the portfolio.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-04T18:40:05.331437"}}
{"question": "How can tags be utilized in AWS Identity and Access Management (IAM) policies?", "answer": "Tags can be used in AWS Identity and Access Management (IAM) policies to allow or deny access to IAM users, groups, and roles, or to restrict operations that can be performed by IAM users, groups, and roles.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-04T18:40:05.331714"}}
{"question": "How does a portfolio created for a development team differ from one created for a sales and marketing team?", "answer": "A portfolio created for a development team will likely contain different products than a portfolio targeted at the sales and marketing team, as each portfolio is customized with different products and access permissions specific to the needs of the respective end users.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-04T18:40:05.332162"}}
{"question": "What is the process for sharing a portfolio with other AWS accounts?", "answer": "To share your portfolio with other AWS accounts, you specify the account ID you want to share with and then send the Amazon Resource Number (ARN) of the portfolio to that account. The owner of that account can create a link to the shared portfolio and assign IAM users from that account to the portfolio.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-04T18:40:12.579560"}}
{"question": "What control do you have over a shared portfolio in AWS?", "answer": "When you share your portfolio with other AWS accounts, you retain ownership and control of the portfolio. Only you can make changes, such as adding new products or updating products, and you can also 'unshare' your portfolio at any time.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-04T18:40:12.579908"}}
{"question": "How does creating a new product version differ from creating a new product in AWS Service Catalog?", "answer": "Creating a new product version in AWS Service Catalog is done in the same way as creating new products. However, when a new version of a product is published to a portfolio, end users can choose to launch the new version or update their running stacks, while AWS Service Catalog does not automatically update products that are in use when an update becomes available.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-04T18:40:12.580415"}}
{"question": "What are template constraints in AWS Service Catalog?", "answer": "Template constraints are rules that limit the parameter values a user can enter when launching a product. They constrain how the AWS CloudFormation template for the product is deployed and are created using a simple editor, applied to individual products.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-04T18:40:17.078087"}}
{"question": "How does AWS Service Catalog determine which template constraint to apply when provisioning a product?", "answer": "AWS Service Catalog applies the most restrictive constraint among all constraints applied to the portfolio and the product when provisioning a new product or updating an existing one.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-04T18:40:17.078433"}}
{"question": "What is the difference between using a users IAM access permissions and a pre-defined IAM role in AWS Service Catalog?", "answer": "A users IAM access permissions allow users to provision AWS resources based on their individual permissions, while a pre-defined IAM role gives full control over the AWS resources by specifying a specific role at the product level for resource provisioning.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-04T18:40:17.078883"}}
{"question": "What does the AWS Service Management Connector for ServiceNow and Jira Service Desk provide?", "answer": "The AWS Service Management Connector for ServiceNow and Jira Service Desk provides integration features that simplify cloud provisioning and resource management for administrators. It allows ServiceNow users to request AWS products, which can be any IT service that administrators want to make available for deployment on AWS.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-04T18:40:24.050184"}}
{"question": "How does the AWS Service Management Connector enhance the experience for ServiceNow and Jira Service Desk users?", "answer": "The AWS Service Management Connector enhances the experience for ServiceNow and Jira Service Desk users by allowing them to browse and request AWS products approved by administrators. It also enables users to view configuration item details on provisioned products and execute AWS Systems Manager automation documents, simplifying AWS product request actions.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-04T18:40:24.050528"}}
{"question": "What are the differences in availability for the AWS Service Management Connector for ServiceNow and Jira Service Desk?", "answer": "The AWS Service Management Connector for ServiceNow is available at no charge in the ServiceNow Store, while the connector for Jira Service Desk is available at no charge in the Atlassian Marketplace. Both connectors are generally available in all AWS Regions where AWS Service Catalog is available.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-04T18:40:24.051020"}}
{"question": "What happens after you choose Launch for a product in the AWS Service Catalog portal?", "answer": "After you choose Launch for a product in the AWS Service Catalog portal, you will be guided through a series of questions about how you plan to use the product. These questions may pertain to your business needs or your infrastructure requirements, such as the EC2 instance type. Once you provide the required information, you will see the product in the AWS Service Catalog console. During the provisioning process, the status will show as 'in progress,' and after completion, it will display 'complete' along with information like endpoints or Amazon Resource Names (ARNs) for accessing the product.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:40:32.462291"}}
{"question": "How does AWS Service Catalog facilitate self-service provisioning with governance for Terraform users?", "answer": "AWS Service Catalog enables customers using Terraform open source and Terraform Cloud to provide self-service provisioning with governance to their end users in AWS. Central IT can utilize a single tool to organize, govern, and distribute their Terraform configurations within AWS at scale. Key features include cataloging standardized and pre-approved templates, access control, least privileges during provisioning, versioning, sharing to numerous AWS accounts, and tagging. End-users can simply view the list of products and versions they have access to and deploy them with a single action.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:40:32.462630"}}
{"question": "What is the difference between using an updated version of a product and the current version in AWS Service Catalog?", "answer": "When a new version of a product is published in AWS Service Catalog, you can use the Update Stack command to adopt that version. If you are currently using a product that has an update available, it will continue to run until you decide to close it. At that point, you have the option to switch to the new version. This means that the current version remains operational until you actively choose to upgrade to the newer version.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-04T18:40:32.463152"}}
{"question": "What is required to use AWS Service Catalog with Terraform open source?", "answer": "To use AWS Service Catalog with Terraform open source, you need to set up a Terraform open source engine in one of your accounts. This involves creating the engine by using the AWS provided Terraform Reference Engine, which will install and configure the code and infrastructure required for your Terraform open source engine to work with AWS Service Catalog.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-04T18:40:38.497679"}}
{"question": "How does AWS Service Catalog facilitate the use of different IaC tools like Terraform and CloudFormation?", "answer": "AWS Service Catalog facilitates the use of different IaC tools like Terraform and CloudFormation by serving as a single tool to catalog and share both types of configurations. It provides an easy-to-use, common interface for end users to view and provision resources, regardless of the underlying IaC technology being used.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-04T18:40:38.498042"}}
{"question": "What is the relationship between the central account and spoke accounts in the AWS Service Catalog 'hub and spoke' model for Terraform?", "answer": "In the AWS Service Catalog 'hub and spoke' model for Terraform, a product is defined in a single central account (the Hub), where you can install your Terraform open source or Terraform Cloud engine and create Terraform products. These products can then be shared with multiple spoke accounts, enabling access to IAM roles, users, and groups in those accounts.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-04T18:40:38.498487"}}
{"question": "What file format is required for template files synced with AWS Service Catalog?", "answer": "The template file format required for syncing products with AWS Service Catalog is a single file archived in Tar and compressed in Gzip.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-04T18:40:43.402952"}}
{"question": "What is the purpose of AWS Service Catalog AppRegistry?", "answer": "The purpose of AWS Service Catalog AppRegistry is to allow organizations to understand the application context of their AWS resources by providing a repository for information that describes the applications and associated resources used within the enterprise.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-04T18:40:43.403316"}}
{"question": "How does AWS Service Catalog AppRegistry relate to CloudFormation stacks?", "answer": "AWS Service Catalog AppRegistry enables you to define your application, including associated CloudFormation stacks that represent all the resources required for the application. These stacks can be either existing or new, and new stacks can be associated to the application upon provisioning by including an association in the stack's CloudFormation template.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-04T18:40:43.403819"}}
{"question": "What type of metadata do attribute groups contain?", "answer": "Attribute groups contain application metadata that is important to your enterprise. This includes metadata such as application security classification, organizational ownership, application type, cost center, and support information.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-04T18:40:47.196865"}}
{"question": "How do updates to attribute groups affect associated applications?", "answer": "When attribute groups are updated, these updates are automatically reflected in all applications associated with the attribute group.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-04T18:40:47.197202"}}
{"question": "What flexibility do attribute groups provide in terms of metadata capture compared to traditional methods?", "answer": "Attribute groups include an open JSON schema, which provides the flexibility to capture complex enterprise metadata, unlike traditional methods that may not accommodate such complexity.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-04T18:40:47.197704"}}
{"question": "What types of events does AWS Shield Standard protect against?", "answer": "AWS Shield Standard provides protection for all AWS customers against common and most frequently occurring infrastructure events, specifically layer 3 and 4 events like SYN/UDP floods, reflection events, and others to support high availability of applications on AWS.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-04T18:40:53.849839"}}
{"question": "How does AWS Shield Advanced enhance DDoS protection compared to AWS Shield Standard?", "answer": "AWS Shield Advanced offers always-on automatic mitigation of sophisticated DDoS events, which minimizes application downtime and latency. Additionally, it allows for customizing DDoS protection strategies using application-specific security controls and provides expert guidance from the Shield Response Team during active DDoS incidents, which is not available with AWS Shield Standard.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-04T18:40:53.850183"}}
{"question": "What is the purpose of the AWS Shield network security director?", "answer": "The AWS Shield network security director serves to visualize network resources and address configuration issues from known threats like SQL injections and DDoS events. It analyzes your network resources, connections, and configurations against AWS best practices and threat intelligence to build a complete network topology, providing visibility into your network and aggregating security findings into a comprehensive dashboard for quick response.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-04T18:40:53.850695"}}
{"question": "What does AWS Shield Advanced provide for applications running on Amazon EC2 and other resources?", "answer": "AWS Shield Advanced provides enhanced protections against sophisticated and larger attacks for applications running on protected Amazon EC2, Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator, and Route 53 resources.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T18:41:00.839692"}}
{"question": "How does AWS Shield Advanced help in mitigating DDoS attacks?", "answer": "AWS Shield Advanced helps in mitigating DDoS attacks by employing advanced attack mitigation and routing techniques, providing always-on, flow-based monitoring of network traffic, and offering near real-time notifications of suspected DDoS incidents. Additionally, it allows customers with Business or Enterprise support to engage the Shield Response Team (SRT) for 24/7 management and mitigation of application layer DDoS events.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T18:41:00.840065"}}
{"question": "What features differentiate AWS Shield Advanced from the AWS Shield network security director?", "answer": "AWS Shield Advanced provides detection and mitigation against large and sophisticated DDoS events, near real-time visibility into events, integration with AWS WAF, and 24/7 access to the Shield Response Team (SRT). In contrast, the AWS Shield network security director, currently in preview, represents an expansion of capabilities to enhance network and application protection beyond DDoS defense, focusing on comprehensive security solutions.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-04T18:41:00.840581"}}
{"question": "How do I start a network security analysis using Amazon Q Developer?", "answer": "To start a network security analysis, launch Amazon Q Developer from anywhere in the AWS Management Console and enter a network securityrelated prompt, such as 'What are my most critical network security configuration issues?' This will direct you to the AWS Shield network security director console to initiate the analysis.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-04T18:41:06.783754"}}
{"question": "What types of network security issues does AWS Shield help analyze?", "answer": "AWS Shield helps analyze common network security issues such as controlling human access to resources and protecting applications against threats like DDoS. It also allows users to check if any resources are vulnerable to common web threats, and it can determine if EC2 instances allow unrestricted access to all ports.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-04T18:41:06.784111"}}
{"question": "What resources does AWS Shield currently support for analysis in its preview capability?", "answer": "Currently in preview, AWS Shield supports analysis of AWS WAF, VPC security groups, and VPC network access control lists (network ACLs). It also discovers Amazon CloudFront distributions, Amazon Application Load Balancers, Amazon API Gateways, Amazon Virtual Private Clouds (VPCs), VPC Elastic Network Interfaces, VPC subnets, and Amazon EC2 instances in a single account.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-04T18:41:06.784635"}}
{"question": "What does Amazon Q Developer assist with in relation to network security?", "answer": "Amazon Q Developer helps identify network security configuration issues in your AWS account by understanding natural language queries and working with AWS Shield to provide relevant responses.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:41:12.447535"}}
{"question": "How does AWS Shield supplement its references for network security controls?", "answer": "AWS Shield supplements its references for network security controls by recommending when and how certain network security services should be enabled based on a resource's network context, such as whether it is internet-facing or has other connected resources.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:41:12.447874"}}
{"question": "What are the differences between AWS Shield and AWS Shield Advanced in terms of DDoS protection?", "answer": "AWS Shield provides basic DDoS protection, while AWS Shield Advanced includes DDoS cost protection, which safeguards against scaling charges caused by DDoS attacks that lead to usage spikes on protected resources. Additionally, Shield Advanced allows you to request credits via the regular AWS Support channel if resources scale up due to a DDoS attack.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:41:12.448362"}}
{"question": "In which AWS Regions is AWS Shield network security director available at no additional cost during the preview period?", "answer": "During the preview period, AWS Shield network security director is available at no additional cost in the US East (N. Virginia) and Europe (Stockholm) AWS Regions.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-04T18:41:18.483528"}}
{"question": "What types of attacks does AWS Shield Standard automatically protect against?", "answer": "AWS Shield Standard automatically provides protection for web applications running on AWS against the most common, frequently occurring Infrastructure layer attacks, such as UDP floods and State exhaustion attacks like TCP SYN floods.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-04T18:41:18.483867"}}
{"question": "How does AWS Shield Advanced differ from AWS Shield Standard in terms of regional availability and protection capabilities?", "answer": "AWS Shield Advanced is available globally on all Amazon CloudFront, AWS Global Accelerator, and Amazon Route 53 edge locations worldwide, and it can be enabled directly on Elastic Load Balancing or Amazon EC2 in specific AWS Regions. In contrast, AWS Shield Standard is available on all AWS services in every AWS Region and edge location worldwide but does not offer the advanced protections provided by Shield Advanced.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-04T18:41:18.484359"}}
{"question": "What is the maximum number of AWS resources that can be enabled for AWS Shield Advanced protection?", "answer": "You can enable up to 1000 AWS resources of each supported resource type for AWS Shield Advanced protection.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-04T18:41:22.987025"}}
{"question": "How does AWS Shield Advanced protect against application layer DDoS events?", "answer": "AWS Shield Advanced provides application layer (L7) DDoS protection through AWS Managed Rule group, which automatically detects and mitigates DDoS events within seconds.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-04T18:41:22.987363"}}
{"question": "How does AWS Shield Standard differ from AWS Shield Advanced in terms of DDoS protection?", "answer": "AWS Shield Standard automatically protects web applications running on AWS against the most common DDoS events, while AWS Shield Advanced offers enhanced application layer DDoS protection and includes additional features such as automatic detection and mitigation of DDoS events.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-04T18:41:22.987954"}}
{"question": "What features are included in AWS Shield Advanced for DDoS protection?", "answer": "AWS Shield Advanced includes always-on automatic mitigation of sophisticated DDoS events for layers 3, 4, and 7, 24/7 support from the Shield Response Team (SRT), cost protection against event spikes, and application layer (L7) DDoS protection for up to 50 billion AWS WAF requests per month at no additional cost. If the inclusion is exceeded, additional charges will apply.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-04T18:41:31.329673"}}
{"question": "How does the AWS Shield network security director help users strengthen their security posture?", "answer": "The AWS Shield network security director helps users strengthen their security posture by identifying and analyzing AWS resources, configurations, and connections in their account. It discovers resources that need protection, aggregates findings in a single network topology view, and prioritizes these findings by severity level, allowing users to respond to critical issues first. It also provides instructions on implementing the correct services and rule sets to address issues quickly.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-04T18:41:31.330026"}}
{"question": "What is the difference between engaging the AWS Shield Response Team through AWS support versus having a Business or Enterprise support plan?", "answer": "Engaging the AWS Shield Response Team (SRT) through regular AWS support is possible, but to escalate to or engage the SRT, you must have a Business or Enterprise support plan. Response times for the SRT also depend on the AWS Support plan you are subscribed to, indicating that the level of support received may vary based on the chosen plan.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-04T18:41:31.330519"}}
{"question": "How long does it take for AWS Shield Advanced to notify customers of an event after detection?", "answer": "Typically, AWS Shield Advanced provides notification of an event within a few minutes of event detection.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-04T18:41:37.264887"}}
{"question": "What features does AWS Shield Advanced provide to help customers understand DDoS events?", "answer": "AWS Shield Advanced provides access to the Global threat environment dashboard, which gives an anonymized and sampled view of all DDoS events seen on AWS within the last 2 weeks, and it allows customers to see the history of all incidents in the trailing 13 months.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-04T18:41:37.265218"}}
{"question": "How does the DDoS protection provided by AWS WAF compare to the features of AWS Shield Advanced?", "answer": "AWS WAF includes application layer (L7) DDoS protection through a managed rule group that automatically detects and mitigates DDoS events, while AWS Shield Advanced customers benefit from notifications of events, access to a global threat dashboard, and historical incident data. Additionally, AWS Shield Advanced customers can enable certain features without additional costs up to 50 billion AWS WAF requests per month, whereas AWS WAF provides real-time metrics and logs related to web requests.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-04T18:41:37.265765"}}
{"question": "What does AWS Shield Advanced do in response to DDoS events?", "answer": "AWS Shield Advanced responds to DDoS events by creating, evaluating, and deploying custom AWS WAF rules for your protected resources.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T18:41:42.081052"}}
{"question": "How does AWS WAF application layer (L7) DDoS protection enhance application security?", "answer": "AWS WAF application layer (L7) DDoS protection can be used in addition to custom AWS WAF rules for application protection, providing an additional layer of security by challenging suspicious traffic to verify its legitimacy.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T18:41:42.081358"}}
{"question": "What is the difference in cost for AWS Shield Standard and AWS Shield Advanced?", "answer": "AWS Shield Standard is built into the AWS services with no additional costs, while AWS Shield Advanced requires a monthly fee of $3,000 per organization, in addition to AWS Shield Advanced Data Transfer usage fees for enabled resources.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-04T18:41:42.081852"}}
{"question": "What does AWS Shield Advanced allow you to choose?", "answer": "AWS Shield Advanced allows you the flexibility to choose the resources that you'd like to protect.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-04T18:41:47.613376"}}
{"question": "How does billing work for AWS Shield Advanced if multiple accounts are involved?", "answer": "If your organization has multiple AWS accounts, you can subscribe multiple AWS Accounts to AWS Shield Advanced by individually enabling it on each account. You will pay the monthly fee once as long as the AWS accounts are all under a single consolidated billing, and you own all the AWS accounts and resources in those accounts.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-04T18:41:47.613709"}}
{"question": "Is there a difference in the billing structure for AWS Shield Advanced when using multiple accounts versus a single account?", "answer": "Yes, when using multiple accounts under a single consolidated billing, you will only pay the monthly fee once for AWS Shield Advanced, compared to paying for each account individually if they are not consolidated.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-04T18:41:47.614242"}}
{"question": "What are the two types of AWS Snowball devices available for selection?", "answer": "The two types of AWS Snowball devices available for selection are AWS Snowball Edge Compute Optimized and AWS Snowball Edge Storage Optimized.", "question_type": "factual", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T18:41:52.908821"}}
{"question": "How does AWS Snowball enhance application performance in edge environments?", "answer": "AWS Snowball enhances application performance in disconnected, austere edge environments by allowing users to run compute workloads with little or no connectivity.", "question_type": "conceptual", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T18:41:52.909149"}}
{"question": "How does the data transfer process differ between using AWS Snowball and traditional cloud data migration methods?", "answer": "The data transfer process using AWS Snowball differs from traditional cloud data migration methods in that it allows for the migration of petabytes of data offline or under limited network conditions, utilizing physical devices to transport data securely rather than relying solely on internet connectivity.", "question_type": "comparison", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-04T18:41:52.909346"}}
{"question": "What is Amazon Simple Notification Service (Amazon SNS)?", "answer": "Amazon Simple Notification Service (Amazon SNS) is a web service that makes it easy to set up, operate, and send notifications from the cloud. It provides developers with a highly scalable, flexible, and cost-effective capability to publish messages from an application and immediately deliver them to subscribers or other applications.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-04T18:41:59.521469"}}
{"question": "How does Amazon SNS deliver notifications to clients?", "answer": "Amazon SNS follows the 'publish-subscribe' (pub-sub) messaging paradigm, with notifications being delivered to clients using a 'push' mechanism. This mechanism eliminates the need for clients to periodically check or 'poll' for new information and updates.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-04T18:41:59.521817"}}
{"question": "What are the advantages of using Amazon SNS compared to traditional polling methods for notifications?", "answer": "The advantages of using Amazon SNS compared to traditional polling methods include the use of a 'push' mechanism for delivering notifications, which eliminates the need for clients to poll for updates. Additionally, SNS offers simple APIs that require minimal up-front development effort, no maintenance or management overhead, and pay-as-you-go pricing, making it easier for developers to incorporate a powerful notification system into their applications.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-04T18:41:59.522325"}}
{"question": "What are some benefits of using Amazon SNS for building distributed applications?", "answer": "Some benefits of using Amazon SNS for building distributed applications include instantaneous, push-based delivery with no polling, simple APIs for easy integration with applications, flexible message delivery over multiple transport protocols, an inexpensive pay-as-you-go model with no up-front costs, and a web-based AWS Management Console that offers a point-and-click interface.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-04T18:42:06.693928"}}
{"question": "How does Amazon SNS support event notifications in workflow systems?", "answer": "Amazon SNS supports event notifications in workflow systems by relaying events among distributed computer applications, moving data between data stores, or updating records in business systems. It can immediately deliver event updates and notifications concerning validation, approval, inventory changes, and shipment status to relevant system components and end-users.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-04T18:42:06.694275"}}
{"question": "In what ways does Amazon SNS differ from Amazon SQS in terms of message delivery?", "answer": "Amazon SNS provides instantaneous, push-based delivery of messages to subscribers, allowing for real-time notifications, while Amazon SQS is typically used for reliably sending messages to one or many system components asynchronously. SNS is focused on delivering messages as they are published, whereas SQS is designed for queueing messages for later processing.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-04T18:42:06.694846"}}
{"question": "What is the primary function of Amazon SNS?", "answer": "The primary function of Amazon SNS is to allow applications to send time-critical messages to multiple subscribers through a 'push' mechanism, which eliminates the need for applications to periodically check or 'poll' for updates.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T18:42:13.357959"}}
{"question": "How do Amazon SQS and Amazon SNS complement each other in application architecture?", "answer": "Amazon SQS and Amazon SNS complement each other by allowing SNS to publish messages to SQS queues, which reliably sends messages to one or many system components asynchronously. This pattern helps to decouple the sending and receiving components of applications, enhancing their flexibility and reliability.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T18:42:13.358308"}}
{"question": "How does Amazon MQ differ from Amazon SQS and Amazon SNS in terms of application migration?", "answer": "Amazon MQ differs from Amazon SQS and Amazon SNS in that it supports industry-standard APIs and protocols, allowing users to switch from any standards-based message broker to Amazon MQ without rewriting the messaging code in their applications. In contrast, Amazon SQS and SNS are recommended for building brand new applications in the cloud.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-04T18:42:13.358756"}}
{"question": "What functionalities does the AWS Management Console provide for Amazon SNS?", "answer": "The AWS Management Console provides a point-and-click, web-based interface to access and manage Amazon SNS. Using the console, you can create topics, add subscribers, send notifications, publish messages to various endpoints (such as HTTP, SQS, Lambda, mobile push, email, or SMS), and edit topic policies to control publisher and subscriber access.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-04T18:42:21.916565"}}
{"question": "How does AWS CloudTrail enhance the auditing capabilities for Amazon SNS?", "answer": "AWS CloudTrail enhances the auditing capabilities for Amazon SNS by recording AWS API calls for your account and delivering log files that include details such as the identity of the API caller, the time of the API call, the source IP address, the request parameters, and the response elements returned by SNS. This allows users to obtain a history of API calls made on their account.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-04T18:42:21.916882"}}
{"question": "What is the difference between authenticated and unauthenticated calls in the context of CloudTrail auditing for Amazon SNS?", "answer": "The difference is that CloudTrail currently supports auditing only for authenticated calls made to Amazon SNS. This means that while you can obtain audit logs for authenticated API calls, there are no available logs for unauthenticated ConfirmSubscription and Unsubscribe calls.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-04T18:42:21.917491"}}
{"question": "What are the charges for using Amazon SNS requests?", "answer": "Users pay $0.50 per 1 million Amazon SNS requests, $0.06 per 100,000 notification deliveries over HTTP, and $2.00 per 100,000 notification deliveries over email. For SMS messaging, charges vary by destination country.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-04T18:42:27.865748"}}
{"question": "How does the Free Tier for Amazon SNS help new users get started?", "answer": "The Free Tier allows users to get started with Amazon SNS for free by incurring no charges for the first 1 million Amazon SNS requests, no charges for the first 100,000 notifications over HTTP, and no charges for the first 1,000 notifications over email each month.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-04T18:42:27.866126"}}
{"question": "How do the charges for notification deliveries over HTTP compare to email notifications in Amazon SNS?", "answer": "For notification deliveries over HTTP, the charge is $0.06 per 100,000 notifications, while for email notifications, the charge is $2.00 per 100,000 notifications. This indicates that email notifications are significantly more expensive than HTTP notifications.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-04T18:42:27.866655"}}
{"question": "What characters are allowed in AWS topic names?", "answer": "AWS topic names can include alphanumeric characters, hyphens (-), and underscores (_).", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-04T18:42:33.385482"}}
{"question": "What should users do if they want to reference a topic in Amazon SNS?", "answer": "Users should reference the unique topic ARN, which is assigned by Amazon SNS when the topic is created. They should always use the ARN returned from the API call to create the topic instead of attempting to build it from its separate components.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-04T18:42:33.385820"}}
{"question": "How does the operation of creating a topic differ from deleting a topic in Amazon SNS?", "answer": "Creating a topic involves using the CreateTopic operation, which assigns a unique ARN to the new topic. In contrast, deleting a topic uses the DeleteTopic operation, after which the topic name can be reused, but the ARN associated with the topic is no longer valid.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-04T18:42:33.386302"}}
{"question": "What is the function of the ListSubscriptionsByTopic API?", "answer": "The ListSubscriptionsByTopic API allows a topic owner to see the list of all subscribers actively registered to a topic.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-04T18:42:38.958650"}}
{"question": "How do the ListSubscriptions and ListSubscriptionsByTopic APIs differ in terms of their functionality?", "answer": "The ListSubscriptions API allows a user to get a list of all their active subscriptions to one or more topics, while the ListSubscriptionsByTopic API specifically allows a topic owner to view all subscribers registered to a particular topic.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-04T18:42:38.958865"}}
{"question": "What types of transport can subscribers use to receive notifications from an Amazon SNS topic?", "answer": "Subscribers can receive notifications through various transports, including SQS (standard or FIFO queue), HTTP, HTTPS, Email, Email-JSON, and SMS. A topic can support subscriptions and notification deliveries over multiple transports.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-04T18:42:38.959206"}}
{"question": "What feature does Amazon SNS offer to allow subscribers to receive only specific messages?", "answer": "Amazon SNS offers message filtering, which enables topic subscribers to selectively receive only a subset of the messages they are interested in, rather than receiving all messages published to a topic.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-04T18:42:46.933017"}}
{"question": "How does Amazon SNS integrate with other AWS services in an order processing workflow?", "answer": "In an order processing workflow, Amazon SNS integrates with services like Amazon EC2, Amazon SQS, and Amazon SimpleDB. For instance, when a customer places an order, the transaction is recorded in Amazon SimpleDB, an application on EC2 forwards the order request to a payment processor, and upon approval, an order confirmation message is published to an SNS topic. This allows notifications to be sent to various subscribers, updating them about the payment processing status and orchestrating real-time processing in related systems like inventory or shipping.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-04T18:42:46.933384"}}
{"question": "What is the difference between using Amazon SNS and Amazon SQS in the context of message delivery?", "answer": "Amazon SNS is used for sending notifications to multiple subscribers simultaneously, allowing instant updates to various stakeholders, while Amazon SQS is used to persist notifications in a queue for later processing by applications, such as an auditing application. In the context of an order processing system, SNS can trigger real-time actions in related components, whereas SQS ensures that all notifications are stored and can be processed at a future time.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-04T18:42:46.933895"}}
{"question": "How long should you typically wait before reusing a topic name after it has been deleted?", "answer": "Topic names should typically be available for reuse approximately 30-60 seconds after the previous topic with the same name has been deleted. The exact time will depend on the number of subscriptions that were active on the topic.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:42:53.069950"}}
{"question": "What are the benefits of using SNS FIFO topics for message delivery?", "answer": "SNS FIFO topics allow users to publish messages to a topic for delivery to a series of subscribing endpoints while ensuring that the messages are delivered in order (first-in-first-out) and once only. They simplify the messaging architecture and reduce the effort required to process high throughput, consistently ordered transactions. Additionally, they can deliver ordered messages to Amazon SQS FIFO queues for consistent end-to-end message ordering in distributed applications.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:42:53.080055"}}
{"question": "How do SNS FIFO topics compare to Kinesis Streams in terms of subscriber limits for ordered fan-out?", "answer": "SNS FIFO topics can support ordered fan-out of up to 100 subscribers, whereas Kinesis Streams only supports ordered fan-out up to 5 subscribers. This makes SNS FIFO topics more suitable for applications requiring a larger number of subscribers while maintaining message order.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-04T18:42:53.080501"}}
{"question": "What protocols can a subscriber specify to receive email notifications from Amazon SNS?", "answer": "A subscriber can specify either 'Email' or 'Email-JSON' as the protocol to receive email notifications from Amazon SNS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-04T18:42:58.372317"}}
{"question": "What is the difference between the 'Email' and 'Email-JSON' transports in Amazon SNS?", "answer": "'Email-JSON' sends notifications as a JSON object and is intended for applications that programmatically process emails, while 'Email' sends regular, text-based messages that are easily readable and meant for end-users or consumers.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-04T18:42:58.372688"}}
{"question": "How does the subscription confirmation process differ for users receiving notifications via 'Email' compared to 'Email-JSON'?", "answer": "The subscription confirmation process is the same for both 'Email' and 'Email-JSON' transports. In both cases, Amazon SNS sends an email with a confirmation link that the user must click to opt-in for receiving notifications. The difference lies in the format of the notifications received after confirmation, with 'Email' providing readable text messages and 'Email-JSON' providing notifications in JSON format.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-04T18:42:58.373200"}}
{"question": "What is required for an SQS queue to receive notifications from Amazon SNS?", "answer": "The SQS queue owner must subscribe the SQS queue to the Amazon SNS topic for Amazon SNS to successfully deliver messages to the queue.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-04T18:43:03.251939"}}
{"question": "What happens when a user owns both the Amazon SNS topic and the SQS queue?", "answer": "If the user owns both the Amazon SNS topic being subscribed to and the SQS queue receiving the notifications, nothing further is required. Any message published to the topic will automatically be delivered to the specified SQS queue.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-04T18:43:03.252281"}}
{"question": "How does the behavior differ when the SQS queue owner is not the owner of the SNS topic?", "answer": "If the user owning the SQS queue is not the owner of the SNS topic, Amazon SNS will require an explicit confirmation to the subscription request before messages can be delivered to the SQS queue.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-04T18:43:03.252795"}}
{"question": "What information is included in the notification message sent by Amazon SNS over HTTP, HTTPS, Email-JSON, and SQS transport protocols?", "answer": "The notification message consists of a simple JSON object that includes the following information: MessageId, Timestamp, TopicArn, Type, UnsubscribeURL, Message, Subject, Signature, and SignatureVersion.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-04T18:43:09.739861"}}
{"question": "Why is it important to secure data over the wire when making API calls to Amazon SNS?", "answer": "It is important to secure data over the wire by connecting to secure SSL end-points to protect the user's data from being intercepted during transmission.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-04T18:43:09.740213"}}
{"question": "How does the permissions model work for publishing to a topic in Amazon SNS?", "answer": "By default, only the topic owners have permissions to publish to a topic. However, a topic owner can set explicit permissions to allow other users with valid AWS IDs to publish to the topic. Permissions can be managed using the AddPermission and RemovePermission APIs or through access control policies for more advanced use cases.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-04T18:43:09.740782"}}
{"question": "How can users with AWS IDs subscribe to topics in Amazon SNS?", "answer": "Users with AWS IDs can subscribe to any topic directly, provided that the topic owner has granted them the necessary permissions. Their AWS IDs will be validated during the subscription registration process.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-04T18:43:15.520863"}}
{"question": "What is the role of topic owners in managing subscriptions in Amazon SNS?", "answer": "The role of topic owners in managing subscriptions in Amazon SNS includes granting or restricting access to subscribers by setting appropriate permissions for the topic using Access Control policies. They can also subscribe and register endpoints on behalf of users without AWS IDs.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-04T18:43:15.521211"}}
{"question": "How do the subscription processes differ for users with AWS IDs versus those without AWS IDs?", "answer": "Users with AWS IDs can subscribe directly to any topic as long as they have the necessary permissions from the topic owner, while users without AWS IDs cannot subscribe directly. Instead, topic owners must subscribe and register endpoints on their behalf.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-04T18:43:15.521713"}}
{"question": "What is the purpose of the explicit opt-in process in Amazon SNS subscription registration?", "answer": "The purpose of the explicit opt-in process in Amazon SNS subscription registration is to prevent spam and ensure that a subscriber end-point is genuinely interested in receiving notifications from a particular topic. This is achieved through a 2-part handshake that requires confirmation from the subscriber.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-04T18:43:22.885513"}}
{"question": "How does the confirmation process differ for HTTP/HTTPS notifications compared to Email notifications in Amazon SNS?", "answer": "For HTTP/HTTPS notifications, Amazon SNS sends a confirmation message containing a token via a POST request to the specified URL, and the application must call the ConfirmSubscription API with the token. In contrast, for Email and Email-JSON notifications, Amazon SNS sends an email with an embedded link that the user must click to confirm the subscription request.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-04T18:43:22.885852"}}
{"question": "What is the difference in the subscription confirmation process for Amazon SQS notifications compared to Email notifications?", "answer": "For Amazon SQS notifications, the confirmation process involves enqueuing a challenge message containing a token to the specified queue, and the application must call the ConfirmSubscription API with that token. In contrast, for Email notifications, the process requires the user to click on an embedded link in an email to confirm the subscription request. Thus, SQS uses a token-based confirmation through a queue, while Email relies on user interaction through a link.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-04T18:43:22.886355"}}
{"question": "How does Amazon SNS ensure the authenticity of notifications?", "answer": "Amazon SNS ensures the authenticity of notifications by signing all notification deliveries using a cryptographically secure, asymmetric mechanism involving a private-public key pair based on certificates. It publishes its certificate to a well-known location and signs messages with the private key of that certificate. Developers and applications can then obtain the certificate and validate the signature of the notifications using the public key.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T18:43:31.041872"}}
{"question": "What is the significance of the AuthenticateOnUnsubscribe flag in Amazon SNS subscription management?", "answer": "The AuthenticateOnUnsubscribe flag is significant because it determines who can unsubscribe from a subscription. If the flag is set to True when the subscription is confirmed via the ConfirmSubscription API call, only the topic owner or the subscription owner can unsubscribe. Conversely, if the subscription was confirmed anonymously without this flag set to True, it can be unsubscribed by anyone anonymously.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T18:43:31.042250"}}
{"question": "What are the differences between the SSL connection for publishers and subscribers in Amazon SNS?", "answer": "Publishers in Amazon SNS can connect over HTTPS and publish messages over an SSL channel, securing the messages sent to Amazon SNS. Subscribers, on the other hand, must register an SSL-enabled end-point during the subscription registration process, ensuring that notifications are delivered securely over an SSL channel to that end-point. Thus, while both publishers and subscribers can use SSL for security, their roles in this process differ, with publishers sending messages and subscribers receiving them.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-04T18:43:31.042775"}}
{"question": "Is Amazon SNS considered a HIPAA eligible service?", "answer": "Yes, Amazon SNS is included in the AWS HIPAA compliance program as a HIPAA eligible service, provided that there is an executed Business Associate Agreement (BAA) with AWS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-04T18:43:38.716994"}}
{"question": "What should developers keep in mind regarding message delivery and duplicates when using Amazon SNS?", "answer": "Developers should be aware that although most of the time each message will be delivered to their application exactly once, the distributed nature of Amazon SNS and transient network conditions could result in occasional duplicate messages at the subscriber end. Therefore, applications should be designed to handle the possibility of processing a message more than once without creating errors or inconsistencies.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-04T18:43:38.717355"}}
{"question": "How does the durability of messages in Amazon SNS compare to its message delivery order?", "answer": "Amazon SNS provides durable storage of all messages by storing multiple copies across multiple Availability Zones, ensuring that message durability continues without disruption even in the event of a failure in one zone. However, while SNS attempts to deliver messages in the order they were published, network issues may result in out-of-order messages at the subscriber end. Thus, message durability and delivery order are managed separately.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-04T18:43:38.717835"}}
{"question": "What happens when Amazon SNS can't access a subscribed endpoint?", "answer": "When Amazon SNS can't access a subscribed endpoint, message delivery fails due to either a client-side or a server-side error. A client-side error occurs if the subscribed endpoint has been deleted by its owner or if its access permissions have changed, preventing delivery. A server-side error happens when the service powering the subscribed endpoint, like Amazon SQS or AWS Lambda, is unavailable.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-04T18:43:45.488356"}}
{"question": "What is the purpose of a dead-letter queue in Amazon SNS?", "answer": "A dead-letter queue (DLQ) in Amazon SNS serves the purpose of storing messages that could not be successfully delivered after exhausting the retry policy. If a message results in a client-side error or continues to receive a server-side error beyond the specified number of retries, the message is discarded unless a DLQ is attached to the subscription, allowing for later analysis or reprocessing.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-04T18:43:45.488729"}}
{"question": "How does the message delivery retry process in Amazon SNS differ between client-side and server-side errors?", "answer": "The message delivery retry process in Amazon SNS operates the same for both client-side and server-side errors in terms of the retry policy applied, which includes four phases: retries with no delay, retries with minimum delay, retries according to a back-off model, and retries with maximum delay. However, the cause of failure differs: client-side errors are due to issues like deletion or permission changes of the endpoint, while server-side errors are due to the unavailability of the service powering the endpoint.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-04T18:43:45.489259"}}
{"question": "What are the types of Origination IDs supported by AWS for sending SMS messages?", "answer": "AWS supports various types of Origination IDs including short codes, long codes, 10DLC, and Sender IDs.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T18:43:50.949358"}}
{"question": "Why is it important to comply with laws and regulations when sending SMS messages through AWS?", "answer": "It is important to comply with laws, regulations, and carrier requirements based on all the destination countries you plan to send SMS messages to, to ensure that your messaging practices are legal and adhere to local guidelines.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T18:43:50.949704"}}
{"question": "How does the spend quota for SMS messages affect message delivery in Amazon SNS?", "answer": "The spend quota for SMS messages affects message delivery in Amazon SNS by determining the total cost incurred for SMS traffic. If the account-level spend quota is exceeded, Amazon SNS stops delivering messages until the quota is increased or a new calendar month begins. Additionally, if an individual message's spend quota is specified and exceeded, that message will not be sent.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-04T18:43:50.950224"}}
{"question": "What capabilities does Amazon SNS support for SMS messaging?", "answer": "Amazon SNS supports two-way SMS capabilities through AWS End User Messaging.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-04T18:43:55.293127"}}
{"question": "Why is it beneficial to reserve dedicated short codes or long codes when using Amazon SNS for messaging?", "answer": "Reserving dedicated short codes or dedicated long codes makes it easier for your audience to recognize that your organization is the source of your messages, enhancing brand recognition and trust.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-04T18:43:55.293470"}}
{"question": "How does Amazon SNS prioritize the use of numbers when sending SMS notifications?", "answer": "Amazon SNS prioritizes using a dedicated short code first, followed by dedicated long codes. If dedicated numbers are not available, it falls back to a shared set of numbers to send SMS notifications, attempting to use the same number for messages to a specific destination phone number, which is referred to as 'Sticky Sender ID'.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-04T18:43:55.293985"}}
{"question": "What number formatting does AWS encourage for phone numbers in Amazon SNS?", "answer": "AWS strongly encourages E.164 number formatting for all phone numbers both in the 'to' and 'from' fields.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-04T18:44:01.248057"}}
{"question": "What happens when a recipient opts out of receiving SMS messages from Amazon SNS?", "answer": "When a recipient opts out by replying with specific commands, they will no longer receive SMS messages delivered from your AWS account unless you opt in the phone number again. The recipient must reply to the same long code or short code that Amazon SNS used to deliver the message.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-04T18:44:01.248395"}}
{"question": "How does the Delivery Status feature in Amazon SNS differ from the opt-out process?", "answer": "The Delivery Status feature in Amazon SNS provides information on the final disposition of SMS messages based on delivery receipts from the destination carrier, while the opt-out process allows recipients to stop receiving messages from your AWS account without unsubscribing them from an SNS topic. Opt-outs disable the subscription but do not require re-subscribing if the number is opted in again.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-04T18:44:01.248909"}}
{"question": "What is the cost associated with sending SMS messages via the Amazon SNS API?", "answer": "When you send SMS messages via the Amazon SNS API, there is a charge of $0.5 per million requests made to SNS. Additionally, there is a charge for delivering SMS messages that varies based on the recipient's country, the type of route used, the recipient's mobile carrier, and other factors.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-04T18:44:06.728041"}}
{"question": "How does Amazon SNS handle SMS messages that exceed the maximum byte limit?", "answer": "If a message contains more than 140 bytes, Amazon SNS automatically splits it into multiple messages. You will be charged for each individual message created from the split.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-04T18:44:06.728376"}}
{"question": "What are the maximum character limits for SMS messages based on different encodings in Amazon SNS?", "answer": "In Amazon SNS, a message that includes characters encoded using GSM-7 can include up to 160 characters. A message using ASCII encoding can contain up to 140 characters, while a message using UCS-2 encoding can contain up to 70 characters.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-04T18:44:06.728894"}}
{"question": "What is the maximum size for Amazon SNS messages excluding SMS?", "answer": "Amazon SNS messages can contain up to 256 KB of text data, including XML, JSON, and unformatted text, with the exception of SMS messages.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-04T18:44:12.914792"}}
{"question": "What happens if a published message exceeds the size limit for SMS messages?", "answer": "If you publish a message that exceeds the size limit for SMS messages, Amazon SNS sends it as multiple messages, each fitting within the size limit. Messages are not cut off in the middle of a word but on whole-word boundaries.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-04T18:44:12.915027"}}
{"question": "How does the message delivery format differ between the default setting and when 'RawMessageDelivery' is enabled?", "answer": "By default, messages are delivered encoded in JSON format, which provides metadata about the message and topic. However, if 'RawMessageDelivery' is enabled, messages are delivered in raw form, exactly as they were published, without any encoding.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-04T18:44:12.915193"}}
{"question": "What types of endpoints support raw message delivery in AWS?", "answer": "Raw message delivery is supported with SQS and HTTP(S) endpoints. Deliveries to Lambda, email, and SMS endpoints behave the same independent of the 'RawMessageDelivery' property.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:44:18.722285"}}
{"question": "How do push notifications sent through SNS Mobile Push differ from traditional SMS notifications?", "answer": "Push notifications sent through SNS Mobile Push allow an installed mobile application to notify its users immediately about events without the application being open, unlike traditional SMS notifications. The notifications appear on the user's device, and when acknowledged, the app launches to provide more information. Additionally, push notifications offer enhanced functionality at a fraction of the cost compared to SMS.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:44:18.722639"}}
{"question": "What is the difference between the push notification opt-in requirements for SNS Mobile Push and traditional SMS?", "answer": "SNS Mobile Push does not require explicit opt-in for sending push notifications, but the iOS, Android, and Kindle Fire operating systems do require users to opt-in. In contrast, traditional SMS generally requires explicit consent from users to receive messages.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:44:18.723230"}}
{"question": "Do end-users need to modify their client app to receive push notifications using SNS?", "answer": "No, end-users do not need to modify their client app to receive push notifications when using SNS. They opt-in to receive push notifications when they first run the app, regardless of whether SNS delivers the notifications.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-04T18:44:23.636950"}}
{"question": "What is the advantage of using direct addressing in SNS for push notifications?", "answer": "The advantage of using direct addressing in SNS for push notifications is that it allows you to deliver notifications directly to a single endpoint. This is useful for delivering precisely targeted messages to each recipient, rather than sending identical messages to all subscribers of a topic.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-04T18:44:23.637320"}}
{"question": "How does SNS differ from Baidu Cloud Push in terms of client app modification requirements?", "answer": "SNS does not require you to modify your client app to work properly, whereas Baidu Cloud Push requires Baidu-specific components to be added to your client code for it to function correctly.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-04T18:44:23.637829"}}
{"question": "Which messaging services require the use of topics for email messaging in Amazon SNS?", "answer": "Email messaging requires the use of topics in Amazon SNS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-04T18:44:29.414631"}}
{"question": "What happens in Amazon SNS when a token is reported as expired or invalid by APNS or FCM?", "answer": "When a token is reported as expired or invalid by APNS or FCM, SNS automatically disables the application endpoint associated with that token and notifies you of this change via an event.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-04T18:44:29.414977"}}
{"question": "How do GCM device tokens compare to FCM device tokens in terms of usage for notifications?", "answer": "GCM device tokens are completely interchangeable with the newer Firebase Cloud Messaging (FCM) device tokens. This means that existing GCM tokens can still be used to send notifications, and this is also true for GCM tokens that are generated in the future.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-04T18:44:29.415548"}}
{"question": "What must you do to send raw notifications via SNS?", "answer": "You must encode the notification payload as text to send raw notifications via SNS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-04T18:44:33.858848"}}
{"question": "How do message attributes enhance the functionality of SNS messages?", "answer": "Message attributes allow you to provide structured metadata items about the message, such as timestamps, geospatial data, signatures, and identifiers. This information is optional and sent along with the message body, enabling the receiver to determine how to handle the message without processing the message body first.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-04T18:44:33.859190"}}
{"question": "How do message attributes differ between SQS and mobile push endpoints in SNS?", "answer": "For SQS endpoints, you can specify up to 10 name-type-value triples per message, with supported types including String, Binary, and Number. In contrast, mobile push endpoints support specific message attributes relevant to each mobile platform, such as notification type, which are different from the attributes used for SQS.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-04T18:44:33.859726"}}
{"question": "What is the default Time to Live (TTL) for SNS mobile platforms?", "answer": "The default Time to Live (TTL) for SNS mobile platforms is 4 weeks.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-04T18:44:38.437997"}}
{"question": "How does SNS handle the TTL specified within the message payload compared to a message attribute?", "answer": "If you specify a TTL within the message payload and also within a message attribute, SNS will follow the message attribute.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-04T18:44:38.438341"}}
{"question": "Which mobile push endpoints support TTL, and which endpoint does not support it?", "answer": "The mobile push endpoints that support TTL include APNS, APNS_Sandbox, FCM, ADM, Baidu, and WNS. Microsoft MPNS does not currently support TTL.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-04T18:44:38.438828"}}
{"question": "Is there an additional charge for using the Delivery Status feature in Amazon SNS?", "answer": "There is currently no additional Amazon SNS charge for using the Delivery Status feature. However, you may incur charges for using CloudWatch, as this feature creates Amazon CloudWatch log groups.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-04T18:44:43.341858"}}
{"question": "What is the purpose of defining a Log Metrics Filter in Amazon CloudWatch Logs after activating the Delivery Status feature?", "answer": "The purpose of defining a Log Metrics Filter in Amazon CloudWatch Logs after activating the Delivery Status feature is to extract specific information that you are interested in, such as failure rate and dwell time. This metrics filter allows you to monitor and analyze delivery attempts effectively.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-04T18:44:43.342230"}}
{"question": "How does Amazon SNS manage the invocation of multiple AWS Lambda functions when a message is published?", "answer": "Amazon SNS supports message fan-out, which means that publishing a single message can invoke different AWS Lambda functions that are subscribed to the SNS topic. Additionally, it can also deliver notifications to supported Amazon SNS destinations such as mobile push, HTTP endpoints, SQS, email, and SMS.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-04T18:44:43.342551"}}
{"question": "What is the cost of publishing a message with Amazon SNS?", "answer": "Publishing a message with Amazon SNS costs $0.50 per million requests. Additionally, there are no extra fees for delivering a message to an AWS Lambda function aside from the charges incurred in using AWS services.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-04T18:44:48.940276"}}
{"question": "How does subscribing AWS Lambda functions to Amazon SNS topics enhance message handling?", "answer": "Subscribing AWS Lambda functions to Amazon SNS topics allows for custom message handling. It enables the invocation of a Lambda function to modify messages, such as localizing language, and then filter and route those messages to other topics and endpoints. This integration allows existing applications and services that send SNS notifications to utilize AWS Lambda without the need to provision or manage infrastructure for custom message handling.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-04T18:44:48.940502"}}
{"question": "How do the AWS Lambda Free Tier limits compare to the Amazon SNS Free Tier limits?", "answer": "The AWS Lambda Free Tier includes 1 million requests per month and 400,000 GB-seconds of compute time per month. In comparison, the Amazon SNS Free Tier offers 1 million requests per month. Both services provide a Free Tier, but AWS Lambda includes additional compute time limits.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-04T18:44:48.940881"}}
{"question": "Can an AWS account owner subscribe an AWS Lambda function from another account to their Amazon SNS topic?", "answer": "No, an AWS account owner cannot subscribe an AWS Lambda function that belongs to another account to their Amazon SNS topic. However, they can subscribe their own AWS Lambda functions to their own Amazon SNS topics or subscribe their AWS Lambda functions to an Amazon SNS topic created by another account if the topic policy allows it.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-04T18:44:56.033505"}}
{"question": "What is the relationship between Amazon SNS and AWS Lambda in terms of message delivery and event structure?", "answer": "Amazon SNS treats AWS Lambda functions like any other destination for message delivery. When an AWS Lambda function is invoked by an Amazon SNS message, it receives an SNS Event that includes data such as the Message ID, the topic ARN, the message payload, and message attributes. This integration allows for flexible communication between SNS and Lambda functions.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-04T18:44:56.033847"}}
{"question": "How does the concurrency limitation of AWS Lambda affect message deliveries from Amazon SNS?", "answer": "AWS Lambda supports 1000 concurrent executions per AWS account per region. If the message deliveries from Amazon SNS to AWS Lambda contribute to exceeding these concurrency quotas, the deliveries will be throttled. In such cases, if AWS Lambda throttles an SNS message, Amazon SNS will retry the delivery attempts.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-04T18:44:56.034347"}}
{"question": "What is required to register an iOS application for VoIP push notifications?", "answer": "To register an iOS application for VoIP push notifications, you need to obtain the VoIP push notification certificate from Apple in addition to the regular push notification certificate and create a new Platform Application in Amazon SNS, choosing Apple VoIP Push as the platform type.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-04T18:45:01.408432"}}
{"question": "How do VoIP remote notifications differ from regular push notifications in iOS?", "answer": "VoIP remote notifications allow voice-over-IP (VoIP) apps to register such that iOS can launch or wake the app when an incoming VoIP call arrives, whereas regular push notifications are used for general app notifications and do not specifically trigger app launches for incoming calls.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-04T18:45:01.408785"}}
{"question": "How does the registration process for VoIP notifications compare to that of regular push notifications on iOS?", "answer": "The procedure to register for VoIP notifications is similar to registering for regular push notifications on iOS, but it requires additional steps such as obtaining a specific VoIP push notification certificate and configuring a new Platform Application in Amazon SNS for VoIP.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-04T18:45:01.409269"}}
{"question": "What are some advantages of using Amazon SQS over building your own message queue system?", "answer": "Amazon SQS provides several advantages over building your own software for managing message queues, including no administrative overhead, little configuration required, and the ability to process billions of messages per day at scale. Additionally, it eliminates the need for ongoing hardware maintenance and system administration resources, which are typically required for alternative solutions.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:45:08.117633"}}
{"question": "How does Amazon SQS ensure message durability compared to traditional message queuing systems?", "answer": "Amazon SQS provides extremely high message durability, which adds confidence for users and stakeholders that messages will not be lost. In contrast, traditional message queuing systems often require redundant storage and complex configurations to ensure messages are not lost in case of hardware failure.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:45:08.117976"}}
{"question": "What is the difference between Amazon SNS and Amazon SQS in terms of message delivery mechanism?", "answer": "Amazon SNS uses a 'push' mechanism to send time-critical messages to multiple subscribers, eliminating the need for applications to periodically check or 'poll' for updates. In contrast, Amazon SQS operates on a polling model for message exchange, which allows distributed applications to decouple sending and receiving components.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-04T18:45:08.118485"}}
{"question": "What is Amazon MQ used for?", "answer": "Amazon MQ is used for moving messaging to the cloud quickly and easily, and it supports industry-standard APIs and protocols, allowing users to switch from any standards-based message broker to Amazon MQ without rewriting the messaging code in their applications.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T18:45:13.904700"}}
{"question": "How do FIFO queues differ from standard queues in terms of message delivery?", "answer": "FIFO queues provide exactly-once processing, ensuring that each message is delivered once and remains available until a consumer processes it and deletes it. In contrast, standard queues provide at-least-once delivery, meaning each message is delivered at least once but does not guarantee delivery in the exact order they are sent.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T18:45:13.905045"}}
{"question": "What are the main differences between FIFO queues and standard queues regarding message order and delivery?", "answer": "FIFO queues preserve the exact order of messages sent and received, while standard queues provide a loose-FIFO capability that attempts to preserve order but does not guarantee it due to their highly distributed architecture. Additionally, FIFO queues ensure exactly-once processing of messages, whereas standard queues guarantee at-least-once delivery.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-1", "source_tokens": 332, "generated_at": "2026-02-04T18:45:13.905553"}}
{"question": "What is Amazon SQS used for?", "answer": "Amazon SQS is used for storing messages as they travel between applications or microservices, moving data between distributed application components, and helping to decouple these components. It also provides middleware constructs such as dead-letter queues and poison-pill management.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T18:45:20.824978"}}
{"question": "How does Amazon SQS support message handling in applications?", "answer": "Amazon SQS supports message handling by offering a reliable and highly-scalable hosted queue for storing messages. It provides common middleware constructs like dead-letter queues, poison-pill management, and can be accessed through a generic web services API by any programming language supported by the AWS SDK.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T18:45:20.825325"}}
{"question": "How does Amazon SQS pricing compare to the Free Tier usage?", "answer": "Amazon SQS pricing is based on the number of requests and includes data transfer charges for data transferred out of Amazon SQS, except when data is sent to EC2 instances or AWS Lambda functions in the same region. The Free Tier offers 1 million requests per month at no charge, allowing many small-scale applications to operate within this limit. However, once the Free Tier limit is exceeded, all additional requests are chargeable at the same rate.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-04T18:45:20.825535"}}
{"question": "What are the batch operations available in Amazon SQS and how do they affect costs?", "answer": "The batch operations available in Amazon SQS are SendMessageBatch, DeleteMessageBatch, and ChangeMessageVisibilityBatch. These operations cost the same as other Amazon SQS requests, and by grouping messages into batches, you can reduce your Amazon SQS costs.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T18:45:26.301383"}}
{"question": "How can cost allocation tags help in managing Amazon SQS costs?", "answer": "Cost allocation tags can help in managing Amazon SQS costs by allowing you to tag and track your queues based on metadata labels comprised of key-value pairs. For example, you can tag your queues by cost center, which enables you to categorize and monitor your costs according to these cost centers.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T18:45:26.301708"}}
{"question": "How does the use of Amazon SQS with compute services like Amazon EC2 compare to its use with storage services like Amazon S3?", "answer": "The context does not provide a direct comparison of the use of Amazon SQS with compute services like Amazon EC2 versus its use with storage services like Amazon S3. However, it does state that Amazon SQS can be used with both types of services to make applications more flexible and scalable.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-04T18:45:26.302167"}}
{"question": "Who can perform operations on an Amazon SQS message queue?", "answer": "Only an AWS account owner or an AWS account that the account owner has delegated rights to can perform operations on an Amazon SQS message queue.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:45:32.804707"}}
{"question": "What is the purpose of a dead letter queue in Amazon SQS?", "answer": "A dead letter queue in Amazon SQS is used to receive messages from other source queues after a maximum number of processing attempts cannot be completed. It allows you to isolate messages that can't be processed for later analysis.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:45:32.805049"}}
{"question": "How does the visibility timeout affect message processing in Amazon SQS compared to dead letter queues?", "answer": "The visibility timeout in Amazon SQS is a period during which it prevents other consuming components from receiving and processing a message. In contrast, dead letter queues are used specifically for messages that cannot be processed after a certain number of attempts, allowing for later analysis. While visibility timeout temporarily hides messages from other consumers, dead letter queues store messages that failed processing.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-04T18:45:32.805494"}}
{"question": "How many metadata attributes can an Amazon SQS message contain?", "answer": "An Amazon SQS message can contain up to 10 metadata attributes.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-04T18:45:37.302345"}}
{"question": "What are the advantages of using message attributes in Amazon SQS?", "answer": "Using message attributes in Amazon SQS helps separate the body of a message from the metadata that describes it, which allows for faster and more efficient processing and storage of information. This is because applications do not have to inspect the entire message before understanding how to process it.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-04T18:45:37.302683"}}
{"question": "How does long polling differ from short polling in Amazon SQS?", "answer": "Long polling differs from short polling in that it does not return a response until a message arrives in the message queue or the long poll times out, while short polling returns immediately even if the message queue is empty. Long polling can help reduce costs by minimizing the number of empty receives.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-04T18:45:37.302878"}}
{"question": "What is the primary advantage of using Amazon SQS long polling over short polling?", "answer": "The primary advantage of using Amazon SQS long polling over short polling is that long-polling requests allow queue consumers to receive messages as soon as they arrive in the queue while also reducing the number of empty ReceiveMessageResponse instances returned.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-04T18:45:42.809329"}}
{"question": "Why might an application using a single thread to poll multiple queues not benefit from long polling?", "answer": "An application using a single thread to poll multiple queues might not benefit from long polling because the single thread will wait for the long-poll timeout on any empty queues. This waiting can delay the processing of other queues that might contain messages, limiting the advantages of long polling.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-04T18:45:42.809699"}}
{"question": "How does the maximum long-poll timeout of 20 seconds relate to the number of empty ReceiveMessageResponse instances returned?", "answer": "The maximum long-poll timeout of 20 seconds is beneficial because higher long-poll timeout values reduce the number of empty ReceiveMessageResponse instances returned. Therefore, setting the long-poll timeout as high as possible can improve performance by minimizing these empty responses.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-04T18:45:42.810228"}}
{"question": "What features does the AmazonSQSBufferedAsyncClient for Java provide?", "answer": "The AmazonSQSBufferedAsyncClient for Java provides automatic batching of multiple SendMessage, DeleteMessage, or ChangeMessageVisibility requests, and prefetching of messages into a local buffer. These features allow applications to immediately process messages from Amazon SQS without waiting for retrieval.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T18:45:49.226586"}}
{"question": "How do automatic batching and prefetching contribute to the performance of an application using Amazon SQS?", "answer": "Automatic batching and prefetching work together to increase the throughput and reduce the latency of an application while also reducing costs by making fewer Amazon SQS requests.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T18:45:49.226929"}}
{"question": "What is the difference between using the AmazonSQSBufferedAsyncClient and the AmazonSQSAsyncClient?", "answer": "The AmazonSQSBufferedAsyncClient is implemented as a drop-in replacement for the AmazonSQSAsyncClient. By updating the application to use the AmazonSQSBufferedAsyncClient instead of the AmazonSQSAsyncClient, the application gains the benefits of automatic batching and prefetching without requiring any changes to the application's code.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-04T18:45:49.227509"}}
{"question": "In which AWS regions are FIFO queues available?", "answer": "FIFO queues are available in all AWS regions where Amazon SQS is available.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-04T18:45:52.766279"}}
{"question": "What is the primary purpose of FIFO queues in Amazon SQS?", "answer": "The primary purpose of FIFO queues in Amazon SQS is to never introduce duplicate messages. They are designed to prevent message duplication, even if the message producer sends the same message multiple times due to not receiving a response.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-04T18:45:52.766613"}}
{"question": "How do standard queues differ from FIFO queues in terms of message delivery?", "answer": "Standard queues provide at-least-once delivery, which means you might occasionally receive duplicate copies of a message. In contrast, FIFO queues are designed to never introduce duplicate messages. Therefore, while standard queues require applications to be idempotent to handle potential duplicates, FIFO queues do not have this concern.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-04T18:45:52.767103"}}
{"question": "What services are currently not compatible with FIFO queues in Amazon SQS?", "answer": "The services that are currently not compatible with FIFO queues in Amazon SQS include Auto Scaling Lifecycle Hooks, AWS IoT Rule Actions, and AWS Lambda Dead Letter Queues.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-04T18:45:58.047451"}}
{"question": "How do message group IDs affect message ordering in FIFO queues?", "answer": "In FIFO queues, messages are grouped into distinct, ordered 'bundles' based on their message group IDs. All messages with the same message group ID are sent and received in strict order. However, messages with different message group ID values might be sent and received out of order. Therefore, to preserve the order of messages, you must associate a message group ID with each message, and if a message group ID is not provided, the action fails.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-04T18:45:58.047790"}}
{"question": "What is the difference in metric accuracy between FIFO queues and standard queues in Amazon SQS?", "answer": "FIFO queues support all metrics that standard queues support, but for FIFO queues, all approximate metrics return accurate counts. In contrast, standard queues may not guarantee accurate counts for their approximate metrics.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-04T18:45:58.048281"}}
{"question": "What suffix must the name of a FIFO queue end with?", "answer": "The name of a FIFO queue must end with the .fifo suffix.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T18:46:03.565153"}}
{"question": "How does the order of messages in a FIFO queue get determined when multiple producers send messages in parallel?", "answer": "When multiple producers send messages in parallel without waiting for the success response from SendMessage or SendMessageBatch actions, the order between producers might not be preserved. The final ordering sequence that FIFO queues use to place messages in the queue is contained in the response of SendMessage or SendMessageBatch actions, which allows the multiple-parallel-producer code to determine the final order of messages in the queue.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T18:46:03.565451"}}
{"question": "How do FIFO queues differ from standard queues in terms of serving messages from the same message group?", "answer": "By design, Amazon SQS FIFO queues do not serve messages from the same message group to more than one consumer at a time, whereas standard queues do not have this restriction and can serve messages from the same message group to multiple consumers.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-04T18:46:03.565931"}}
{"question": "What is the primary purpose of using fair queues in Amazon SQS?", "answer": "The primary purpose of using fair queues in Amazon SQS is to ensure consistent, low message dwell time for all tenants in a multi-tenant queue, especially in scenarios where some tenants may generate large message backlogs or require varying processing times that could impact others.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-04T18:46:09.761777"}}
{"question": "How do fair queues maintain consistent dwell time for different tenants?", "answer": "Fair queues maintain consistent dwell time for different tenants by reordering messages when a single tenant causes the queue to build a backlog. The queue prioritizes delivering messages from other tenants, while still allowing messages from the tenant causing the backlog to be delivered, although their dwell time may increase based on consumer capacity.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-04T18:46:09.762018"}}
{"question": "What is the difference between FIFO queues and fair queues in terms of throughput and message processing?", "answer": "FIFO queues maintain strict ordering and limit the number of in-flight messages from each tenant, which prevents noisy neighbors but limits throughput for each tenant. In contrast, fair queues do not impose throughput limitations; they allow multiple consumers to process messages from the same tenant concurrently while prioritizing messages from tenants that are not causing backlogs, thus maintaining high throughput and fair resource allocation.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-04T18:46:09.762378"}}
{"question": "What specific metrics are available for fair queues in Amazon CloudWatch?", "answer": "The specific metrics available for fair queues in Amazon CloudWatch include the number of noisy neighbors detected (tenants causing queue backlogs), message count for quiet tenants (those not causing backlogs), and dwell time statistics. These metrics help you monitor how effectively the queue maintains consistent message dwell times across your tenants.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-04T18:46:16.052733"}}
{"question": "How do fair queues differ from standard queues in terms of message group IDs?", "answer": "Fair queues allow for the selective application of message group IDs, which means that messages without a message group ID are treated as belonging to unique tenants. This feature helps mitigate the impact of noisy neighbors while optimizing costs, whereas standard queues do not have this mechanism.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-04T18:46:16.053104"}}
{"question": "What are the security measures provided by Amazon SQS for message queues?", "answer": "Amazon SQS employs authentication mechanisms to secure messages against unauthorized access. Users can control who can send messages to a message queue and who can receive messages from it. Additionally, users can enhance security by encrypting messages before they are placed in a message queue. Amazon SQS also has its own resource-based permissions system that uses policies similar to AWS Identity and Access Management (IAM) policies.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-04T18:46:16.053602"}}
{"question": "What happens if you do not delete a message from an Amazon SQS queue after processing it?", "answer": "If you do not delete the message, Amazon SQS will deliver it again when it receives another receive request.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-04T18:46:20.514605"}}
{"question": "What is the purpose of server-side encryption (SSE) in Amazon SQS?", "answer": "The purpose of server-side encryption (SSE) in Amazon SQS is to protect the contents of messages in queues using keys managed in the AWS Key Management Service (AWS KMS). SSE encrypts messages as soon as Amazon SQS receives them, ensuring that the messages are stored in encrypted form and decrypted only when sent to an authorized consumer.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-04T18:46:20.514998"}}
{"question": "How do FIFO queues differ from standard queues in terms of message duplication?", "answer": "FIFO queues never introduce duplicate messages, while standard queues may under rare circumstances deliver a previously-deleted message a second time.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-04T18:46:20.515482"}}
{"question": "What must be specified to enable server-side encryption (SSE) for a queue in Amazon SQS?", "answer": "To enable SSE for a new or existing queue using the Amazon SQS API, you must specify the customer master key (CMK) ID: this can be the alias, alias ARN, key ID, or key ARN of either an AWS-managed CMK or a custom CMK by setting the KmsMasterKeyId attribute of the CreateQueue or SetQueueAttributes action.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-04T18:46:27.274331"}}
{"question": "Why is it important to configure AWS KMS key policies before using SSE with Amazon SQS?", "answer": "It is important to configure AWS KMS key policies to allow encryption of queues and to enable encryption and decryption of messages before using SSE. This ensures that the necessary permissions are in place for both the producer and consumer of the messages.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-04T18:46:27.274671"}}
{"question": "How do the permissions required for sending messages to an encrypted queue differ from those required for receiving messages?", "answer": "To send messages to an encrypted queue, the producer must have the kms:GenerateDataKey and kms:Decrypt permissions for the CMK. In contrast, to receive messages from an encrypted queue, the consumer must have the kms:Decrypt permission for any CMK that is used to encrypt the messages in the specified queue. Additionally, if the queue acts as a dead letter queue, the consumer must also have the kms:Decrypt permission for any CMK that is used to encrypt the messages in the source queue.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-04T18:46:27.275080"}}
{"question": "What components does SSE not encrypt in an Amazon SQS queue?", "answer": "SSE does not encrypt the following components: queue metadata (queue name and attributes), message metadata (message ID, timestamp, and attributes), and per-queue metrics.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-04T18:46:32.743511"}}
{"question": "How does Amazon SQS ensure the security of messages using SSE?", "answer": "Amazon SQS ensures the security of messages using SSE by encrypting the body of a message with the AES-GCM 256 algorithm. It also generates data keys based on either the AWS-managed customer master key (CMK) for Amazon SQS or a custom CMK to provide envelope encryption and decryption of messages for a configurable time period, which can range from 1 minute to 24 hours.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-04T18:46:32.743742"}}
{"question": "What factors limit the number of SSE queues that can be created in Amazon SQS?", "answer": "The number of SSE queues that can be created in Amazon SQS is limited by several factors: the data key reuse period (which can be set between 1 minute to 24 hours), the AWS KMS per-account quota (default is 100 TPS), the number of IAM users or accounts that access the queues, and the existence of a large backlog, as a larger backlog requires more AWS KMS calls.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-04T18:46:32.744146"}}
{"question": "What is the formula used to calculate the number of API requests per queue in Amazon SQS?", "answer": "The formula to calculate the number of API requests per queue (R) in Amazon SQS is R = B / D * (2 * P + C), where B is the billing period in seconds, D is the data key reuse period in seconds, P is the number of producing principals, and C is the number of consuming principals.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-04T18:46:36.778028"}}
{"question": "Why might actual costs for Amazon SQS be higher than the predicted costs using the provided formula?", "answer": "Actual costs for Amazon SQS might be higher than the predicted costs using the provided formula because of the distributed nature of Amazon SQS.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-04T18:46:36.778368"}}
{"question": "How do the costs incurred by producing principals compare to those incurred by consuming principals in Amazon SQS?", "answer": "Producing principals generally incur double the cost of consuming principals in Amazon SQS.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-04T18:46:36.778892"}}
{"question": "What is required to use Amazon SQS for building HIPAA-compliant applications?", "answer": "To use Amazon SQS for building HIPAA-compliant applications, you need to have an executed Business Associate Agreement (BAA) with AWS.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-04T18:46:42.336119"}}
{"question": "How does the Amazon SQS message retention period affect message handling?", "answer": "The Amazon SQS message retention period affects message handling by providing greater flexibility, allowing for longer intervals between message production and consumption. You can configure the retention period from 1 minute to 14 days, with a default of 4 days, which means messages can be retained for varying lengths of time before they are automatically deleted once the quota is reached.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-04T18:46:42.336462"}}
{"question": "What are the differences between sending messages directly through Amazon SQS and using Amazon S3 with the Amazon SQS Extended Client Library for Java?", "answer": "The main difference is that when sending messages directly through Amazon SQS, you can transfer protected health information (PHI) if you have a BAA in place. Alternatively, if you prefer not to transfer PHI through Amazon SQS or if your messages are larger than 1 MiB, you can send message payloads through Amazon S3 using the Amazon SQS Extended Client Library for Java.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-04T18:46:42.336891"}}
{"question": "What is the maximum message size that can be configured for an Amazon SQS message?", "answer": "The maximum message size that can be configured for an Amazon SQS message is between 1,024 bytes (1 KiB) and 1,048,576 bytes (1 MiB).", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-04T18:46:53.548487"}}
{"question": "How can I send messages larger than 1 MiB using Amazon SQS?", "answer": "To send messages larger than 1 MiB, you can use the Amazon SQS Extended Client Library for Java or Python, which allows you to send an Amazon SQS message that contains a reference to a message payload in Amazon S3 that can be as large as 2 GiB.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-04T18:46:53.548862"}}
{"question": "What is the difference in the quota for inflight messages between standard queues and FIFO queues in Amazon SQS?", "answer": "Both standard queues and FIFO queues in Amazon SQS have a quota of 120,000 inflight messages. Inflight messages are those that have been received from the queue by a consuming component but have not yet been deleted from the queue.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-04T18:46:53.549306"}}
{"question": "What APIs does Amazon SQS provide for managing access policy statements?", "answer": "Amazon SQS provides the following APIs for managing access policy statements: AddPermission, RemovePermission, SetQueueAttributes, and GetQueueAttributes.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-04T18:46:57.895329"}}
{"question": "Can you configure an access policy for anonymous user access to a message queue in Amazon SQS?", "answer": "Yes, you can configure an access policy that allows anonymous users to access a message queue in Amazon SQS.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-04T18:46:57.895671"}}
{"question": "How does Amazon SQS pricing differ for message queues in China (Beijing) compared to other regions?", "answer": "Amazon SQS pricing is the same for all regions except China (Beijing), indicating that there may be different pricing structures or rates applied specifically for that region.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-04T18:46:57.896190"}}
{"question": "What is the purpose of a dead-letter queue in Amazon SQS?", "answer": "A dead-letter queue is an Amazon SQS queue used to send messages that a source queue's consumer application cannot consume successfully. It helps manage message consumption failures and the life cycle of unconsumed messages.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-04T18:47:03.250596"}}
{"question": "How does the redrive policy work in relation to dead-letter queues?", "answer": "The redrive policy is a configuration that links a source queue to a dead-letter queue and sets a maxReceiveCount, which defines how many times a message can be received by the consumer before being moved to the dead-letter queue. If the ReceiveCount for a message exceeds this maxReceiveCount, Amazon SQS moves the message to the dead-letter queue.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-04T18:47:03.250940"}}
{"question": "Can you use a FIFO dead-letter queue with a standard source queue?", "answer": "No, you cannot use a FIFO dead-letter queue with a standard source queue. You must use a FIFO dead-letter queue only with a FIFO queue and a standard dead-letter queue only with a standard queue.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-04T18:47:03.251456"}}
{"question": "What is AWS Step Functions?", "answer": "AWS Step Functions is a fully managed service that makes it easier to coordinate the components of distributed applications and microservices using visual workflows.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-04T18:47:07.752628"}}
{"question": "How does AWS Step Functions enhance application reliability and debugging?", "answer": "AWS Step Functions enhances application reliability by automatically triggering and tracking each step, and retrying when there are errors, ensuring that the application executes in order. It also logs the state of each step, allowing for quicker diagnosis and debugging when issues arise.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-04T18:47:07.752970"}}
{"question": "In what way does breaking an application into service components benefit system updates compared to a monolithic architecture?", "answer": "Breaking an application into service components ensures that the failure of one component does not bring the whole system down, allowing each component to scale independently. This means that a component can be updated without requiring the entire system to be redeployed after each change, unlike a monolithic architecture where updates often necessitate redeploying the entire application.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-04T18:47:07.753501"}}
{"question": "What kind of applications can be built using AWS Step Functions?", "answer": "AWS Step Functions can be used for building serverless generative AI applications, automating mission-critical business processes in e-commerce, implementing robust user registration processes and sign-on authentication in web applications, and creating tools for continuous integration and continuous deployment in DevOps and IT automation.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T18:47:13.868403"}}
{"question": "How do state machines function within AWS Step Functions?", "answer": "In AWS Step Functions, state machines define your workflow as a series of steps, their relationships, and their inputs and outputs. Each state represents a step in the workflow diagram and can perform tasks such as executing work, making choices, passing parameters, initiating parallel execution, managing timeouts, or terminating the workflow with a success or failure.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T18:47:13.868747"}}
{"question": "How do the visual console features of Step Functions assist in workflow design compared to traditional methods?", "answer": "The visual console of Step Functions automatically graphs each state in the order of execution, making it easier to design multi-step applications. It highlights the real-time status of each step and provides a detailed history of every execution, which enhances usability and monitoring compared to traditional methods that may not offer such visualizations and real-time updates.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-04T18:47:13.869262"}}
{"question": "What are service integrations in AWS Step Functions?", "answer": "Service integrations in AWS Step Functions help you construct calls to AWS services and include the response in your workflow. They enable you to invoke one of over 9,000 AWS API actions from more than 200 services directly from your workflow.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-04T18:47:18.759086"}}
{"question": "How do Activity Tasks differ from service integrations in AWS Step Functions?", "answer": "Activity Tasks allow you to incorporate integration with activity workers that can run in various locations, including Amazon EC2, Amazon ECS, on mobile devices, or on on-premises servers. In contrast, service integrations focus on invoking AWS services and incorporating their responses into the workflow.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-04T18:47:18.759319"}}
{"question": "What resources are available for getting started with AWS Step Functions?", "answer": "To get started with AWS Step Functions, you can explore sample projects in the Step Functions console, read through the Step Functions Developer Guide, or try the 10-minute tutorials provided.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-04T18:47:18.759695"}}
{"question": "What language is used to define AWS Step Functions state machines?", "answer": "AWS Step Functions state machines are defined in JSON using the declarative Amazon States Language.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-04T18:47:23.662051"}}
{"question": "What are the advantages of composing Express Workflows as a child workflow of Standard Workflows?", "answer": "By running Express Workflows as a child workflow of Standard Workflows, the Express Workflow is invoked from a Task state in the parent orchestration workflow and succeeds or fails as a whole from the parent's perspective. It is also subject to the parent's retry policy for that Task.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-04T18:47:23.662394"}}
{"question": "How do the workflow types of Express Workflows and Standard Workflows interact?", "answer": "Express Workflows can be run as a child workflow of Standard Workflows, allowing them to be invoked from a Task state in the parent orchestration workflow, where they succeed or fail as a whole from the parent's perspective. Additionally, Express Workflows can call other Express Workflows as long as the total duration does not exceed the limit of the parent workflow.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-04T18:47:23.662838"}}
{"question": "What are the two operating modes of the Map state in Step Functions?", "answer": "The two operating modes of the Map state in Step Functions are Inline and Distributed.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-04T18:47:27.914789"}}
{"question": "How does the Distributed mode of the Map state optimize execution for Amazon S3?", "answer": "The Distributed mode of the Map state is optimized for Amazon S3 by allowing you to more easily iterate over objects in an S3 bucket. It splits iterations into parallel executions to help overcome payload and execution history limits.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-04T18:47:27.915117"}}
{"question": "What is the difference in concurrency between Inline mode and Distributed mode in the Map state?", "answer": "Inline mode supports a concurrency of 40 parallel branches, while Distributed mode allows for a concurrency of up to 10,000 parallel branches.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-04T18:47:27.915612"}}
{"question": "What must be declared to use JSONata as the query language in a workflow?", "answer": "To use JSONata as the query language in a workflow, you must declare 'QueryLanguage':'JSONata' on individual states or for the entire workflow.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:47:32.927892"}}
{"question": "How does using JSONata simplify data transformation in workflows compared to JSONPath?", "answer": "Using JSONata simplifies data transformation in workflows by replacing the five primary fields used in JSONPath (InputPath, Parameters, ResultSelector, ResultPath, and OutputPath) with two new fields: Arguments and Output. This new structure provides additional capabilities for data manipulation and eliminates the complexity of reasoning about multiple fields.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:47:32.928233"}}
{"question": "What are the key differences between JSONPath and JSONata regarding the expression format?", "answer": "The key differences between JSONPath and JSONata regarding the expression format are that JSONPath uses the '.$' convention for field names, while JSONata does not. Instead, JSONata expressions are enclosed in {% %}. Additionally, JSONata allows for writing Choice state conditions on a single line using the new Condition field, which can accept either a boolean value or a string value based on the QueryLanguage setting.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:47:32.928749"}}
{"question": "What is the primary use case for AWS Step Functions?", "answer": "AWS Step Functions should be used when you need to coordinate service components in the development of highly scalable and auditable applications.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-04T18:47:37.493342"}}
{"question": "How does AWS Step Functions facilitate application development compared to Amazon SQS?", "answer": "Step Functions offers several features that facilitate application development, such as passing data between tasks and flexibility in distributing tasks, whereas SQS requires you to implement application-level functionality.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-04T18:47:37.493730"}}
{"question": "What are the differences in functionality between AWS Step Functions and Amazon Simple Queue Service (SQS)?", "answer": "AWS Step Functions has out-of-the-box capabilities to build workflows that coordinate distributed applications and provides an application-centric view for tracking tasks and events. In contrast, Amazon SQS allows you to build basic workflows but has limited functionality and requires you to implement your own application-level tracking.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-04T18:47:37.494123"}}
{"question": "What is the primary function of Amazon EventBridge?", "answer": "The primary function of Amazon EventBridge is to connect application components together using events, making it easier for developers to build scalable event-driven applications.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-04T18:47:43.234024"}}
{"question": "How do Amazon EventBridge and AWS Step Functions differ in their focus?", "answer": "Amazon EventBridge focuses on routing events, whereas AWS Step Functions focuses on the orchestration of workflows and management of state.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-04T18:47:43.234418"}}
{"question": "In what ways can Amazon EventBridge API Destinations and AWS Step Functions' HTTPS endpoints integration work together?", "answer": "Amazon EventBridge API Destinations and AWS Step Functions' HTTPS endpoints integration can support a connection for authentication, allowing you to reuse authentication credentials across services, and both can be used together to build highly scalable and robust distributed applications.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-04T18:47:43.234833"}}
{"question": "What is the purpose of the TestState API in AWS Step Functions?", "answer": "The TestState API is used to test a single step of your workflow, enabling faster feedback cycles to accelerate development. It allows you to call services and endpoints directly, modify the input to mimic different scenarios, and review the response.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-04T18:47:51.041129"}}
{"question": "How does the Distributed Map state in AWS Step Functions facilitate large-scale data processing?", "answer": "The Distributed Map state allows Step Functions to iterate through items and start parallel workflow executions instantly, enabling on-demand data processing at scale. It is optimized to work with S3, allowing you to specify an S3 bucket with filter criteria, a manifest file, or a JSON/CSV file stored in S3 as inputs for your workflow.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-04T18:47:51.041479"}}
{"question": "What is the relationship between AWS Step Functions and Amazon API Gateway?", "answer": "AWS Step Functions can be associated with Amazon API Gateway to invoke state machines when an HTTPS request is sent to a defined API method. This integration allows for starting Step Functions state machines that coordinate components of a distributed backend application and includes human activity tasks within the application's steps.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-04T18:47:51.041952"}}
{"question": "What is the primary function of AWS Step Functions?", "answer": "AWS Step Functions is a serverless orchestration service that allows you to easily coordinate multiple Lambda functions into flexible workflows, which are easy to debug and change.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T18:47:56.867967"}}
{"question": "How does orchestration differ from choreography in distributed service communication?", "answer": "Orchestration involves tightly controlled communication where a service like Step Functions coordinates the interaction and order of service invocation, while choreography allows for communication without centralized control, as seen with Amazon EventBridge, where events flow between services independently.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T18:47:56.868317"}}
{"question": "What are the benefits of using Step Functions in conjunction with Amazon EventBridge?", "answer": "Using Step Functions with Amazon EventBridge allows you to trigger workflows in Step Functions through events, such as sending an event or creating a schedule with EventBridge Scheduler, and then emitting events at different steps of the workflow, providing a flexible integration between the two services.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-04T18:47:56.868867"}}
{"question": "What metrics does AWS Step Functions send to Amazon CloudWatch?", "answer": "AWS Step Functions sends metrics to Amazon CloudWatch for application monitoring, which includes collecting and tracking metrics, setting alarms, and automatically reacting to changes in AWS Step Functions.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T18:48:03.110485"}}
{"question": "How does Step Functions enhance data processing with Amazon Bedrock?", "answer": "Step Functions enhances data processing with Amazon Bedrock by allowing users to invoke Bedrocks Foundation Models directly from workflows using natural language, enabling capabilities such as text summarization, image generation, and personalization. It also allows for retrieving current information from databases to improve response accuracy and generating embeddings through a multi-step process.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T18:48:03.110840"}}
{"question": "How do the logging options differ for Express Workflows in AWS Step Functions?", "answer": "By default, Express Workflows report all outcomes to CloudWatch Logs, including workflow input, output, and completed steps. However, users have the option to select different levels of logging to only log errors, and they can also choose not to log input and output.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-04T18:48:03.111254"}}
{"question": "What compliance standards does Step Functions conform to?", "answer": "Step Functions conforms to HIPAA, FedRAMP, SOC, GDPR, and other common compliance standards.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-04T18:48:07.928168"}}
{"question": "How does Step Functions utilize AWS PrivateLink and VPC Endpoints?", "answer": "Step Functions utilizes AWS PrivateLink and VPC Endpoints (VPCE) to allow access from VPC-enabled AWS Lambda functions and other AWS services without traversing the public internet.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-04T18:48:07.928510"}}
{"question": "What is the relationship between Step Functions and VPC Endpoints?", "answer": "Step Functions can be accessed through VPC Endpoints using AWS PrivateLink, enabling VPC-enabled AWS Lambda functions and other AWS services to connect without using the public internet.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-04T18:48:07.929016"}}
{"question": "What is AWS Storage Gateway?", "answer": "AWS Storage Gateway is a hybrid cloud storage service that provides on-premises access to virtually unlimited cloud storage. It allows users to utilize AWS storage without rewriting existing applications by supporting standard storage protocols such as iSCSI, SMB, and NFS.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T18:48:13.774356"}}
{"question": "How does AWS Storage Gateway optimize data transfer to AWS?", "answer": "AWS Storage Gateway optimizes data transfer to AWS by sending only changed data and compressing data, which helps reduce the amount of data that needs to be transferred and speeds up the process.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T18:48:13.774693"}}
{"question": "What are the key hybrid cloud use cases supported by AWS Storage Gateway?", "answer": "AWS Storage Gateway supports four key hybrid cloud use cases: (1) moving backups and archives to the cloud, (2) reducing on-premises storage with cloud-backed file shares, (3) providing on-premises applications with low-latency access to data stored in AWS, and (4) enabling data lake access for pre and post-processing workflows.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-04T18:48:13.775202"}}
{"question": "What types of storage interfaces does Storage Gateway provide for on-premises applications?", "answer": "Storage Gateway provides three types of storage interfaces for on-premises applications: file, volume, and tape.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-04T18:48:19.511486"}}
{"question": "How does the Amazon S3 File Gateway allow access to stored objects?", "answer": "The Amazon S3 File Gateway enables you to store and retrieve objects in Amazon Simple Storage Service (S3) using file protocols such as Network File System (NFS) and Server Message Block (SMB). Objects written through S3 File Gateway can be directly accessed in S3.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-04T18:48:19.511794"}}
{"question": "What is the difference between the Volume Gateway and the Tape Gateway in terms of data storage?", "answer": "The Volume Gateway provides block storage to on-premises applications using iSCSI connectivity, with data stored in Amazon S3 and the ability to take point-in-time copies as Amazon EBS snapshots. In contrast, the Tape Gateway provides an iSCSI virtual tape library interface for backup applications, where virtual tapes are stored in Amazon S3 and can be archived to Amazon S3 Glacier or Amazon S3 Glacier Deep Archive.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-04T18:48:19.512178"}}
{"question": "What are the two touchpoints you can use to access the AWS Storage Gateway service?", "answer": "The two touchpoints to use the AWS Storage Gateway service are the AWS Management Console and the gateway appliance.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-04T18:48:25.039411"}}
{"question": "How does the AWS Storage Gateway facilitate the connection between applications and AWS storage?", "answer": "The AWS Storage Gateway facilitates the connection by providing standard storage interfaces, transparent caching, efficient data transfer, and integration with AWS monitoring and security services.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-04T18:48:25.039742"}}
{"question": "What is the difference between configuring file shares for the Amazon S3 File Gateway and the Amazon FSx File Gateway?", "answer": "For the Amazon S3 File Gateway, you configure file shares that are mapped to selected S3 buckets or S3 prefixes using IAM roles. In contrast, for the Amazon FSx File Gateway, you configure file shares by attaching an existing Amazon FSx file system that contains one or more file shares, using a service account.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-04T18:48:25.040246"}}
{"question": "What protocols does Amazon S3 File Gateway support for accessing S3 objects?", "answer": "Amazon S3 File Gateway supports standard file storage protocols, specifically Network File System (NFS) and Server Message Block (SMB), for accessing and managing S3 objects.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-04T18:48:31.482465"}}
{"question": "How does Amazon S3 File Gateway enhance the use of existing file-based applications?", "answer": "Amazon S3 File Gateway enhances the use of existing file-based applications by allowing them to access secure and durable cloud storage without requiring modifications. It presents S3 buckets as network file shares, translating file operations into object requests on S3, which enables applications to read and write files over standard protocols.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-04T18:48:31.482729"}}
{"question": "In what ways do Amazon S3 File Gateway and Amazon FSx File Gateway differ in terms of the services they optimize for file access?", "answer": "Amazon S3 File Gateway optimizes access to Amazon S3 and presents it as a network file share using NFS and SMB, while Amazon FSx File Gateway optimizes on-premises access to Windows file shares on Amazon FSx. S3 File Gateway is geared toward storing and retrieving S3 objects, whereas FSx File Gateway focuses on providing low-latency access to FSx for Windows File Server data.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-04T18:48:31.483122"}}
{"question": "What is the purpose of Tape Gateway in AWS?", "answer": "Tape Gateway is a cloud-based Virtual Tape Library (VTL) that presents a VTL interface to backup applications, allowing them to create, read from, and write data to virtual tapes. It stores virtual tapes in Amazon S3 and allows for immediate access and archiving to Amazon S3 Glacier or Amazon S3 Glacier Deep Archive.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-04T18:48:38.044531"}}
{"question": "How does the cached mode of Volume Gateway differ from the stored mode?", "answer": "In cached mode, the primary data is written to Amazon S3 while frequently accessed data is retained locally for low-latency access. In contrast, stored mode keeps the primary data stored locally, providing low-latency access to the entire dataset, while asynchronously backing up the data to AWS.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-04T18:48:38.044865"}}
{"question": "What are the differences between the storage options available for Tape Gateway and Volume Gateway?", "answer": "Tape Gateway stores virtual tapes in Amazon S3 and supports archiving to Amazon S3 Glacier or Amazon S3 Glacier Deep Archive. In contrast, Volume Gateway provides block storage volumes that can be mounted as iSCSI devices, with data either stored locally in cached mode or both locally and in Amazon S3 in stored mode.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-04T18:48:38.045329"}}
{"question": "What protocols does AWS Storage Gateway support for integrating with existing applications?", "answer": "AWS Storage Gateway supports standard protocols such as iSCSI, SMB, and NFS, allowing you to use your existing applications without any changes.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-04T18:48:43.323840"}}
{"question": "How does the local cache feature of AWS Storage Gateway enhance data access?", "answer": "The local cache feature of AWS Storage Gateway provides low-latency access to recently used data, optimizing data transfer to AWS storage through intelligent buffering, upload management to address network variations, and bandwidth management.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-04T18:48:43.324203"}}
{"question": "What are the differences between AWS Storage Gateway and Amazon S3 File Gateway in terms of functionality?", "answer": "AWS Storage Gateway offers a range of features to integrate AWS storage with existing applications, utilizing protocols like iSCSI, SMB, and NFS. In contrast, Amazon S3 File Gateway specifically provides a file interface to store files as objects in Amazon S3 and is tailored for use cases like migrating on-premises file data to S3, backing up file data as objects, and enabling hybrid cloud workflows. While both serve to integrate on-premises applications with AWS storage, Amazon S3 File Gateway focuses on file storage as objects in S3.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-04T18:48:43.324723"}}
{"question": "What storage classes does Amazon S3 File Gateway support?", "answer": "Amazon S3 File Gateway supports Amazon S3 Standard, S3 Intelligent-Tiering, S3 Standard - Infrequent Access (S3 Standard-IA), and S3 One Zone-IA.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-04T18:48:49.950314"}}
{"question": "How does Amazon S3 File Gateway provide low-latency access to cached data for on-premises applications?", "answer": "Amazon S3 File Gateway securely and durably stores both file contents and metadata as objects, allowing on-premises applications to access cached data with low latency.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-04T18:48:49.950658"}}
{"question": "What are the differences in access control configurations between NFS and SMB file shares in Amazon S3 File Gateway?", "answer": "For NFS file shares, you can limit access to specific NFS clients or networks and configure them as read-only or read-write, as well as enable user permission squashing. In contrast, SMB file shares can be accessed by Active Directory users only or provide authenticated guest access, with further limitations on access as read-only or read-write, or to specific AD users and groups.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-04T18:48:49.951298"}}
{"question": "What type of Active Directory does Amazon S3 File Gateway integrate with?", "answer": "Amazon S3 File Gateway integrates with Microsoft Active Directory on-premises as well as with in-cloud Active Directory solutions such as Managed Microsoft AD.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-04T18:48:56.514008"}}
{"question": "How does Amazon S3 File Gateway utilize IAM roles for accessing S3 buckets?", "answer": "Amazon S3 File Gateway uses an AWS Identity and Access Management (IAM) role to access your S3 bucket. You can set up an IAM role yourself or have it automatically set up by the AWS Storage Gateway Management Console. For automatic setup, AWS Storage Gateway will create a new IAM role in your account and associate it with an IAM Access Policy to access your S3 bucket. The IAM role and IAM access policy are created in your account and you can fully manage them yourself.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-04T18:48:56.514349"}}
{"question": "What is the difference between mapping a file share to the root of an S3 bucket versus mapping it to an S3 prefix?", "answer": "If you map a file share to the root of the S3 bucket, the file share is tied to the entire bucket. However, if you specify an S3 prefix when creating a file share, you are tying the file share to that specific S3 prefix within the bucket.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-04T18:48:56.514900"}}
{"question": "What is the relationship between files and objects in Amazon S3 when using File Gateway?", "answer": "There is a one-to-one relationship between files and objects in Amazon S3 when using File Gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T18:49:01.124924"}}
{"question": "How does the renaming of files and directories work in Amazon S3 File Gateway?", "answer": "When you rename a file or directory in Amazon S3 File Gateway, the gateway performs copy-put requests to create a copy of the objects in S3 under the new keys and then deletes the original objects. This approach makes the rename operation appear atomic to clients, but it does not support renaming of objects directly. As a result, renaming directories containing a large number of files is not instantaneous, will create two copies of the data in S3, and will block operations in the directories until the rename operation is complete.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T18:49:01.125268"}}
{"question": "What happens when a client creates a sparse file in Amazon S3 File Gateway compared to a regular file?", "answer": "Creating sparse files in Amazon S3 File Gateway will result in a non-sparse zero-filled object in S3, whereas creating a regular file will store the file as an object with its actual contents.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-04T18:49:01.125718"}}
{"question": "What metadata is durably stored in S3 for files managed by File Gateway?", "answer": "The metadata that is durably stored in S3 includes POSIX-style metadata such as ownership, permissions, and timestamps, which are associated with the file in the user metadata of the object.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T18:49:05.498875"}}
{"question": "How does enabling MIME type guessing benefit the use of File Gateway with Amazon S3?", "answer": "Enabling MIME type guessing benefits the use of File Gateway with Amazon S3 by allowing the File Gateway to use the filename extension to determine the MIME type for the file and set the S3 object's Content-Type accordingly. This is particularly useful when accessing files directly via URL or distributing them through Amazon CloudFront.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T18:49:05.499222"}}
{"question": "What happens when an object that was managed by File Gateway is directly overwritten in S3?", "answer": "When an object that was managed by Amazon S3 File Gateway is directly overwritten or updated in S3, it results in undefined behavior when the object is accessed through the file share. Therefore, such objects should only be managed by the gateway.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-04T18:49:05.499744"}}
{"question": "What happens to the metadata of objects uploaded directly to an S3 bucket?", "answer": "The metadata such as ownership and permissions will be inherited from the objects parent folder. Permissions at the root of the share are fixed, and objects created directly under the root folder will inherit these fixed permissions.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-10", "source_tokens": 476, "generated_at": "2026-02-04T18:49:10.483323"}}
{"question": "Why is it not recommended to have multiple writers to a single S3 bucket?", "answer": "It is not recommended to have multiple writers to a single S3 bucket because it can lead to unpredictable results. Concurrent modifications of the same object can result in undefined behavior when the object is accessed through the file share.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-10", "source_tokens": 476, "generated_at": "2026-02-04T18:49:10.483675"}}
{"question": "What is the difference in configuration for multiple readers versus multiple writers in an Amazon S3 File Gateway?", "answer": "You can have multiple readers on a bucket managed through an Amazon S3 File Gateway, and you can configure a file share as read-only to allow multiple gateways to read objects from the same bucket. However, for multiple writers, it is recommended to maintain a single writer to avoid unpredictable results, as concurrent modifications can lead to undefined behavior.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-10", "source_tokens": 476, "generated_at": "2026-02-04T18:49:10.484194"}}
{"question": "What happens when you write files to your file share with Amazon S3 File Gateway?", "answer": "When you write files to your file share with Amazon S3 File Gateway, the data is stored locally first and then asynchronously uploaded to your S3 bucket.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-04T18:49:15.199569"}}
{"question": "How can notifications be utilized after a file upload completes with Amazon S3 File Gateway?", "answer": "Notifications can be requested through AWS CloudWatch Events when the upload of an individual file completes. These notifications can trigger additional workflows, such as invoking an AWS Lambda function or Amazon EC2 Systems Manager Automation, which depend on the data now available in S3.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-04T18:49:15.199814"}}
{"question": "How do file upload notifications differ from S3 event notifications in terms of completion status?", "answer": "File upload notifications provide a notification for each individual file that is uploaded to Amazon S3 through S3 File Gateway and indicate that the upload has completed. In contrast, S3 event notifications include partial file uploads, meaning there is no way to tell from the S3 event notification that the file upload has completed.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-04T18:49:15.199947"}}
{"question": "What is the maximum number of file shares that can be created for a single S3 bucket in a single gateway?", "answer": "You can create up to 50 shares for an S3 bucket in a single gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-04T18:49:19.143279"}}
{"question": "What are the recommended practices regarding writers to an S3 bucket when using AWS Storage Gateway?", "answer": "It is recommended to have a single writer to the bucket, either an Amazon S3 File Gateway or a client accessing S3 directly.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-04T18:49:19.143631"}}
{"question": "How do the total storage limits of Amazon S3 compare to the total capacity returned by the gateway?", "answer": "The gateway returns a total capacity of 8 EB, while Amazon S3 does not limit total storage. This indicates that S3 can store vast amounts of data without a specified limit, while the gateway presents a large but fixed capacity.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-04T18:49:19.144127"}}
{"question": "What versions of SMB and NFS does Amazon S3 File Gateway support?", "answer": "Amazon S3 File Gateway supports SMB versions 2 and 3, as well as NFS versions 3, 4.0, and 4.1.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T18:49:23.610558"}}
{"question": "Why is local disk storage important for Amazon S3 File Gateway?", "answer": "Local disk storage on the gateway is important because it temporarily holds changed data that needs to be transferred to AWS and locally caches data for low-latency read access. This allows the gateway to manage the cache and maintain the most recently accessed data, improving performance for both read and write operations.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T18:49:23.610896"}}
{"question": "How does the write-back mechanism of Amazon S3 File Gateway compare to directly uploading data to S3?", "answer": "The write-back mechanism of Amazon S3 File Gateway first persists data to disk and then asynchronously uploads it to S3, which helps maximize write performance. In contrast, directly uploading data to S3 would not utilize this mechanism and might not provide the same level of optimization for write operations.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-04T18:49:23.611378"}}
{"question": "What happens to data written to the cache when more recently accessed data needs to be stored?", "answer": "Data written to the cache from your applications or through retrieval from Amazon S3 is evicted from the cache only when space is needed to store more recently accessed data.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-04T18:49:29.245823"}}
{"question": "How does Amazon S3 File Gateway optimize data uploads to S3?", "answer": "Amazon S3 File Gateway uses multipart uploads and copy put, which means that only changed data is uploaded to S3. This approach can help reduce data transfer because it avoids uploading full objects or all the data that exists in your bucket.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-04T18:49:29.246168"}}
{"question": "How does the performance of Amazon FSx File Gateway compare to that of standard file access methods?", "answer": "Amazon FSx File Gateway optimizes on-premises access to Windows file shares on Amazon FSx, allowing users to access FSx for Windows File Server data with low latency and conserving shared bandwidth. In contrast to standard methods, FSx File Gateway provides a local cache of frequently used data for faster performance, while synchronizing changed data to FSx for Windows File Server in the background.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-04T18:49:29.246668"}}
{"question": "What does Amazon FSx File Gateway provide for clients to connect to?", "answer": "Amazon FSx File Gateway provides an SMB file protocol server for clients to connect to.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-04T18:49:35.535982"}}
{"question": "How does Amazon FSx File Gateway improve performance for latency-sensitive applications?", "answer": "Amazon FSx File Gateway improves performance for latency-sensitive applications by providing an on-premises cache of frequently used data that clients can access with low latency, similar to what they would experience inside AWS. File system operations are performed against the local cache, while synchronization of changed data to Amazon FSx for Windows File Server occurs in the background.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-04T18:49:35.536330"}}
{"question": "How does the data access method differ between on-premises applications and using Amazon FSx File Gateway?", "answer": "On-premises applications may experience delays and slow performance when directly accessing files in AWS from remote locations. In contrast, Amazon FSx File Gateway allows users to access an on-premises cache of frequently used data with low latency, which minimizes data transfer and optimizes network bandwidth usage to AWS.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-04T18:49:35.536859"}}
{"question": "What are the prerequisites for using Amazon FSx File Gateway?", "answer": "To use Amazon FSx File Gateway, you need to have at least one running Amazon FSx file system and ensure that you have on-premises access to Amazon FSx for Windows File Server either through a VPN or through an AWS Direct Connect connection.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T18:49:41.467343"}}
{"question": "How does Amazon FSx File Gateway facilitate access to Windows file systems?", "answer": "Amazon FSx File Gateway facilitates access to Windows file systems by mapping local file shares and their contents to file shares stored remotely in Amazon FSx for Windows File Server, allowing users to browse and connect to these file shares on Amazon FSx File Gateway corresponding to the selected Amazon FSx file systems.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T18:49:41.467678"}}
{"question": "How do file share access methods differ between Amazon FSx File Gateway and Amazon FSx in AWS?", "answer": "File shares can be accessed from both Amazon FSx File Gateway and directly from Amazon FSx in AWS. However, it is important to ensure that files can only be written from a single location at a time, as Amazon FSx File Gateway does not prevent simultaneous writes from multiple locations that could create conflicts.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-04T18:49:41.468246"}}
{"question": "How many file systems can a gateway be attached to in Amazon FSx for Windows File Server?", "answer": "You can attach a gateway to shares on up to 5 file systems as long as they are all members of the same Active Directory domain.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-04T18:49:47.623016"}}
{"question": "What security features does Amazon FSx File Gateway utilize when it becomes a member of an Active Directory domain?", "answer": "Once Amazon FSx File Gateway becomes a member of the Active Directory domain, it has access to all users and policies that are set in that domain for the purposes of enforcing security. It behaves identically to any Windows Server and enforces all applicable file access policies based on what is configured in Active Directory.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-04T18:49:47.623397"}}
{"question": "How does Amazon FSx File Gateway's access control compare to that of Windows Server hosts?", "answer": "Amazon FSx File Gateway uses native Windows Access Controls and is compatible with any existing static access lists that work with Microsoft Windows. The maximum size of an ACL is 64KB or approximately 1820 Access Control Entries, which is identical to Windows Server hosts. Access controls are set and stored on FSx Windows File Server, so they only need to be created once and will be reflected in all attached File Gateways.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-04T18:49:47.623882"}}
{"question": "What is the maximum downtime users and applications may experience during a restart of the Amazon FSx File Gateway?", "answer": "Users and applications may experience up to 60 seconds of downtime during a restart of the Amazon FSx File Gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-04T18:49:53.655408"}}
{"question": "How does Amazon FSx File Gateway handle failures in terms of high availability?", "answer": "Amazon FSx File Gateway achieves high availability by running continuous health checks against the gateway's operation and connecting to the VMware monitoring service. In the event of a hardware, software, or network failure, VMware triggers a gateway restart, either on a new host or the existing host if operational. This process ensures that connections to the gateway are automatically re-established without manual intervention.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-04T18:49:53.655835"}}
{"question": "How does the Amazon FSx File Gateway compare to the Amazon S3 File Gateway in terms of high availability features?", "answer": "Both Amazon FSx File Gateway and Amazon S3 File Gateway achieve high availability by running continuous health checks. However, Amazon FSx File Gateway specifically connects to the VMware monitoring service and has the capability to recover from various types of failures, including hardware, hypervisor, network, and software issues. The text does not provide details on the specific high availability features of Amazon S3 File Gateway, so a direct comparison cannot be made.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-04T18:49:53.656343"}}
{"question": "What is the maximum size of a virtual tape that can be created on a Tape Gateway?", "answer": "The maximum size of a virtual tape that can be created on a Tape Gateway is 15 TiB.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-04T18:49:58.197260"}}
{"question": "How does Tape Gateway ensure data integrity when storing virtual tapes in S3 Glacier Deep Archive?", "answer": "Tape Gateway ensures data integrity by performing regular fixity checks to confirm that the data can be read without errors and that no errors have been introduced.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-04T18:49:58.197596"}}
{"question": "What are the differences in data reliability between storing tapes offsite and using Tape Gateway with S3 Glacier Deep Archive?", "answer": "When storing tapes offsite, there is a risk of receiving an incorrect or broken tape during restore, whereas with Tape Gateway, you always receive the correct data. Additionally, tapes stored in S3 Glacier Deep Archive are protected by 11 9s of durability and undergo regular fixity checks, which is not guaranteed with offsite warehousing.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-04T18:49:58.198111"}}
{"question": "What is the typical retrieval time for a virtual tape archived in S3 Glacier?", "answer": "The typical retrieval time for a virtual tape archived in S3 Glacier is within 3-5 hours.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-04T18:50:03.652762"}}
{"question": "What must happen before a virtual tape can be accessed?", "answer": "Before a virtual tape can be accessed, it must be stored in a virtual tape library.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-04T18:50:03.653110"}}
{"question": "How does the retrieval time of a virtual tape archived in S3 Glacier compare to that of a tape archived in S3 Glacier Deep Archive?", "answer": "The retrieval time for a virtual tape archived in S3 Glacier is typically within 3-5 hours, while the retrieval time for a tape archived in S3 Glacier Deep Archive is typically within 12 hours. This means that retrieving a tape from S3 Glacier is faster than retrieving one from S3 Glacier Deep Archive.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-04T18:50:03.653599"}}
{"question": "Can you move a tape from S3 Glacier to S3 Glacier Deep Archive using the AWS Storage Gateway Console?", "answer": "Yes, you can move a tape from S3 Glacier to S3 Glacier Deep Archive using the AWS Storage Gateway Console or API. Tape Gateway will then move the virtual tape to the Deep Archive Pool associated with the S3 Glacier Deep Archive storage class.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-04T18:50:08.800008"}}
{"question": "What happens when you move a tape from S3 Glacier to S3 Glacier Deep Archive before 90 days?", "answer": "You will incur a tape move charge for moving a tape from S3 Glacier to S3 Glacier Deep Archive, and if applicable, you will also face an early deletion fee for S3 Glacier if you move the tape before 90 days.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-04T18:50:08.800358"}}
{"question": "What are the differences in moving tapes between S3 Glacier and S3 Glacier Deep Archive?", "answer": "You can move a tape from S3 Glacier to S3 Glacier Deep Archive, but you cannot move a tape from S3 Glacier Deep Archive to S3 Glacier. Additionally, when moving to Deep Archive, there may be a tape move charge and an early deletion fee if moved before 90 days, which does not apply when moving in the opposite direction since that action is not allowed.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-04T18:50:08.800829"}}
{"question": "What is the maximum data capacity per Volume Gateway in cached mode?", "answer": "In cached mode, each Volume Gateway can support a maximum of 1 PB of data, as each of the 32 volumes can be up to 32 TB in size.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:50:14.443595"}}
{"question": "How does data compression affect costs when using Volume Gateway?", "answer": "Volume Gateways compress data before it is transferred to AWS and while it is stored in AWS. This compression can reduce both data transfer and storage charges.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:50:14.443944"}}
{"question": "What is the difference in maximum volume size between cached mode and stored mode in Volume Gateway?", "answer": "In cached mode, each volume can be up to 32 TB, allowing for a maximum of 1 PB of data per gateway. In stored mode, each volume can be up to 16 TB, allowing for a maximum of 512 TB of data per gateway.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-04T18:50:14.444171"}}
{"question": "Can I create an encrypted volume from a KMS-encrypted EBS snapshot using the API?", "answer": "Yes, you can create an encrypted volume from a KMS-encrypted EBS snapshot using the API. The encrypted volume can use the same key that was used to encrypt the EBS snapshot, or you can specify a different encryption key for encrypting the volume.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-04T18:50:22.035578"}}
{"question": "What are the advantages of using snapshots for Volume Gateway volumes?", "answer": "Using snapshots for Volume Gateway volumes allows you to take point-in-time snapshots in the form of Amazon EBS snapshots. This enables you to easily supply data from your on-premises applications to your applications running on Amazon EC2, which is beneficial for on-demand compute capacity for data processing or for disaster recovery purposes. Additionally, snapshots can preserve versions of your data, allowing you to revert to a prior version or repurpose a point-in-time version as a new volume.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-04T18:50:22.035919"}}
{"question": "How do the snapshot functionalities differ between cached volumes and stored volumes?", "answer": "For cached volumes, the volume data is already stored in Amazon S3, and snapshots can be used to preserve versions of that data, allowing for reversion to earlier versions or repurposing as new volumes. In contrast, for stored volumes, where the volume data is kept on-premises, snapshots provide durable, off-site backups in Amazon S3 and can be used to create a new volume for backup recovery.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-04T18:50:22.036532"}}
{"question": "What happens to the status of a snapshot after all data has been uploaded from the gateway to EBS?", "answer": "Once all data written to the volume prior to the snapshot request has been uploaded from the gateway and into EBS, the status of the snapshot changes from PENDING to AVAILABLE. At this point, you can use the snapshot as the base for a new gateway or EBS volume.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-04T18:50:29.131861"}}
{"question": "How does the primary data storage differ between cached volumes and stored volumes when creating a new volume from a snapshot?", "answer": "Cached volumes store primary data in Amazon S3, so when creating a new volume from a snapshot, the snapshot data remains in Amazon S3 and becomes the primary data for the new volume. In contrast, stored volumes keep primary data locally, which means that when a new volume is created from a snapshot, the gateway downloads the data contained within the snapshot to local hardware, where it becomes the primary data for the new volume.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-04T18:50:29.132214"}}
{"question": "Can you take snapshots without impacting application performance, and what condition must be met regarding data capture?", "answer": "Yes, taking snapshots does not require you to un-mount your volumes and does not impact your applications performance. However, it is important to note that snapshots only capture data that has been written to your AWS Storage Gateway volume, potentially excluding any data that has been locally buffered by your application or operating system.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-04T18:50:29.132733"}}
{"question": "What factors influence the time it takes to complete a snapshot in AWS?", "answer": "The time it takes to complete a snapshot is largely dependent upon the size of your volume and the speed of your Internet connection to AWS. Additionally, the AWS Storage Gateway compresses all data prior to upload, which reduces the time to take a snapshot.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-04T18:50:35.801065"}}
{"question": "How does using AWS Backup benefit the management of Volume Gateway backups?", "answer": "Using AWS Backup to back up Volume Gateway volumes simplifies and centralizes backup management, thus reducing operational burden and making it easier to meet compliance requirements across all your AWS resources. It allows you to set customizable scheduled backup policies, manage backup retention and expiration rules, and monitor backups across multiple Volume Gateways and other AWS resources from a central view.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-04T18:50:35.801413"}}
{"question": "What happens to existing Volume Gateway snapshot functionality when AWS Backup is used?", "answer": "All existing Volume Gateway snapshot functionality and your existing Amazon EBS Snapshots remain available and unchanged. You can continue to use the Storage Gateway console to create volumes from your EBS Snapshots and use the Amazon EBS console to view or delete your snapshots.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-04T18:50:35.801613"}}
{"question": "Can AWS Backup back up KMS-encrypted volumes on Volume Gateway?", "answer": "Yes, AWS Backup will back up KMS-encrypted volumes on Volume Gateway with the same key as the one used for volume encryption.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-04T18:50:39.797404"}}
{"question": "What is the benefit of using the hardware appliance for AWS Storage Gateway?", "answer": "The hardware appliance simplifies deployment and management of AWS Storage Gateway on-premises for IT environments such as remote offices and departments that lack existing virtual server infrastructure, adequate disk and memory resources, or staff with hypervisor management skills. It avoids the need to procure additional infrastructure necessary for a virtual environment in order to operate the local Storage Gateway VM appliance.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-04T18:50:39.797724"}}
{"question": "How does the backup schedule of AWS Backup differ from Volume Gateway's scheduled snapshots?", "answer": "AWS Backups backup schedule operates independently from the Volume Gateway scheduled snapshots, providing an additional way to centrally manage all backup and retention policies.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-04T18:50:39.797895"}}
{"question": "How do you activate a hardware appliance in AWS Storage Gateway?", "answer": "You activate a hardware appliance in AWS Storage Gateway by configuring an IP address through the local hardware appliance console and using that IP address in the AWS Storage Gateway console to associate your hardware appliance with your AWS account.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-04T18:50:45.818303"}}
{"question": "What happens if you want to change the gateway type after it has been installed on a hardware appliance?", "answer": "If you want to change the gateway type after it has been installed on a hardware appliance, you need to choose 'Remove Gateway' from the Storage Gateway console. This action deletes the existing gateway and all associated resources, allowing you to launch a new gateway on the hardware appliance.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-04T18:50:45.818673"}}
{"question": "How does the storage failure tolerance differ between the 5 TB and 12 TB models of the hardware appliance?", "answer": "The 5 TB model of the hardware appliance tolerates the failure of 1 SSD, while the 12 TB model tolerates the failure of up to 2 SSDs.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-04T18:50:45.819206"}}
{"question": "How does Storage Gateway achieve high availability during a failure?", "answer": "Storage Gateway achieves high availability by running continuous health-checks against the operation of the gateway that connect to the VMware monitoring service. During a hardware, software, or network failure, VMware will trigger a gateway restart on a new host or on its existing host if the host is still operational.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-04T18:50:51.029046"}}
{"question": "What is the maximum downtime users and applications experience during a Storage Gateway restart?", "answer": "Users and applications will experience up to 60 seconds of downtime during a restart of the Storage Gateway.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-04T18:50:51.029396"}}
{"question": "How do NFS clients and SMB clients behave differently during a Storage Gateway restart?", "answer": "NFS clients connecting to File Gateways may hang for up to 60 seconds on a read or write operation while the gateway restarts and will then retry if the recommended mount settings are used. In contrast, SMB clients may reject a file read or write during a restart depending on their client settings.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-04T18:50:51.029925"}}
{"question": "What health checks does the Storage Gateway provide?", "answer": "The Storage Gateway provides a range of health checks such as file system availability, SMB endpoint availability, and NFS endpoint availability that monitor all of the critical operations of the gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-04T18:50:55.264336"}}
{"question": "How does VMware HA ensure continuous availability for users and applications?", "answer": "VMware HA monitors the underlying infrastructure, such as storage and networking, and works with Storage Gateway to ensure that the whole service is continuously available to users and applications, not just the infrastructure itself.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-04T18:50:55.264678"}}
{"question": "What is the relationship between VMware HA and AWS Storage Gateway in terms of high availability?", "answer": "VMware HA is enabled by default on VMware Cloud on AWS, allowing for High Availability of Storage Gateway without additional requirements. This integration ensures that both the underlying infrastructure and the gateway service itself are continuously monitored and available.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-04T18:50:55.265182"}}
{"question": "Is AWS Storage Gateway HIPAA eligible?", "answer": "Yes, AWS Storage Gateway is HIPAA eligible. If you have an executed Business Associate Agreement (BAA) with AWS, you can use Storage Gateway to store, back up, and archive protected health information (PHI) on scalable, cost-effective, and secure AWS storage services, which are also HIPAA eligible.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-04T18:51:00.049559"}}
{"question": "What compliance standards does AWS Storage Gateway meet?", "answer": "AWS Storage Gateway is compliant with HIPAA, PCI DSS, and FedRAMP. It is HIPAA eligible when a BAA is executed with AWS, compliant with PCI DSS based on recent assessments, and FedRAMP compliant with High authorization level in the AWS GovCloud (US) Regions and Moderate authorization level in the AWS US Commercial Regions.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-04T18:51:00.049931"}}
{"question": "How do the compliance levels of AWS Storage Gateway differ between FedRAMP authorization levels in different regions?", "answer": "AWS Storage Gateway has a High authorization level for FedRAMP compliance in the AWS GovCloud (US) Regions and a Moderate authorization level in the AWS US Commercial Regions.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-04T18:51:00.050445"}}
{"question": "Is the AWS Storage Gateway Hardware Appliance FIPS 140-2 compliant?", "answer": "No, AWS Storage Gateway Hardware Appliance is not FIPS 140-2 compliant.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-04T18:51:05.644469"}}
{"question": "What features do File Gateway audit logs provide for monitoring SMB shares?", "answer": "File Gateway audit logs can be used to monitor client operations for folders and files within SMB file shares. They support monitoring user operations at the share level for each SMB share and log details about operations such as open, delete, read, write, rename, change of permissions, and file operation success. Additionally, user information including timestamp, Active Directory domain, user name, and client IP address is also logged.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-04T18:51:05.644714"}}
{"question": "What is the difference between WORM tape types and regular virtual tapes in AWS Tape Gateway?", "answer": "WORM tape types are designed so that data cannot be erased intentionally or accidentally from the backup application, whereas regular virtual tapes do not have this restriction. Additionally, Tape Gateways Tape Retention Lock capability prevents archived WORM virtual tapes from being deleted for a fixed amount of time or indefinitely, which is not mentioned for regular virtual tapes.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-04T18:51:05.645102"}}
{"question": "Can I deploy a Storage Gateway on a private, non-routable network?", "answer": "Yes, you can deploy a Storage Gateway on a private, non-routable network if that network is connected to your Amazon VPC via Direct Connect (DX) or VPN.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-04T18:51:12.041688"}}
{"question": "What is the purpose of AWS PrivateLink in relation to Storage Gateway?", "answer": "AWS PrivateLink enables private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs, allowing Storage Gateway traffic to be routed via VPC endpoints.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-04T18:51:12.041987"}}
{"question": "How do Volume and Tape Gateways differ in their connectivity compared to File Gateway when using PrivateLink?", "answer": "Volume and Tape Gateways connect directly to AWS services through the Storage Gateway VPC endpoint without the need for a proxy to S3, while File Gateway requires an Amazon EC2 based proxy server to access Amazon S3 buckets over a private network.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-04T18:51:12.042169"}}
{"question": "What factors influence the performance of AWS Storage Gateway?", "answer": "The performance of AWS Storage Gateway depends on the host platform you are using to run the Storage Gateway software, which can be a hardware appliance, virtual machine, or Amazon EC2 instance. Other influencing factors include the network bandwidth between your iSCSI initiator or NFS client and gateway, the speed and configuration of your underlying local disks, the configuration of your VM, the amount of local storage allocated to your gateway, and the bandwidth between your gateway and Amazon storage.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:51:19.740066"}}
{"question": "How does AWS Storage Gateway optimize data transfer and storage costs?", "answer": "AWS Storage Gateway optimizes data transfer and storage costs by performing compression of data both in-transit and at-rest through Volume and Tape Gateways, which can reduce data transfer and storage charges. Additionally, the Storage Gateway only uploads data that has changed, minimizing the amount of data sent over the Internet.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:51:19.740435"}}
{"question": "What are the differences in monitoring capabilities between AWS Storage Gateway and Amazon CloudWatch?", "answer": "AWS Storage Gateway provides metrics and alarms that can be monitored directly from Amazon CloudWatch. Users can access performance metrics such as storage, bandwidth, throughput, and latency for their gateway via CloudWatch. Specific metrics available include CachePercentDirty, CacheHitPercent, CacheFree, CachePercentUsed, CloudBytesUploaded, and CloudBytesDownloaded, which can be viewed by following the monitoring link on the gateway details tab in the AWS Storage Gateway Console.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-04T18:51:19.740964"}}
{"question": "How can I create recommended Amazon CloudWatch alarms for my gateway?", "answer": "You can create recommended Amazon CloudWatch alarms when creating a new gateway or after creating a new gateway from the AWS Storage Gateway console. Additionally, you can create alarms for your gateway in the Amazon CloudWatch console.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-04T18:51:26.152910"}}
{"question": "What are the options for applying updates to my AWS Storage Gateway?", "answer": "You can configure a weekly maintenance schedule to control when updates will be applied to your gateway, or you can apply updates manually when they are available through the AWS Storage Gateway Console or API. Updates should take only a few minutes to complete.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-04T18:51:26.153277"}}
{"question": "How does billing for File Gateways compare to billing for volume and virtual tape data in AWS Storage Gateway?", "answer": "For File Gateways, you are billed by Amazon S3 for the objects stored and requests made. In contrast, for volume and virtual tape data, you are billed for the amount of storage used, which is prorated daily, and prices vary by region. You are only charged for the portion of capacity used, not the provisioned size, whereas File Gateways charge based on S3 storage and requests.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-04T18:51:26.153789"}}
{"question": "What is the cost per GB for data written to AWS by the gateway?", "answer": "The cost for data written to AWS by the gateway is a flat rate of $0.01 per GB, with a monthly maximum charge of no more than $125 per gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-04T18:51:30.357687"}}
{"question": "How does caching and compression by the gateway affect costs?", "answer": "The gateway performs caching, bandwidth optimization, and compression for Volume and Tape Gateways, which means that the amount of data written to AWS may be less than the amount of data your application writes to the gateway. This can help reduce your costs.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-04T18:51:30.357978"}}
{"question": "How do the early deletion fees differ for virtual tapes archived in S3 Glacier and S3 Glacier Deep Archive?", "answer": "The early deletion fee for virtual tapes archived in S3 Glacier is $0.012 per GB if deleted within three months, whereas for S3 Glacier Deep Archive, the text does not specify an early deletion fee, suggesting that there are no charges for deletion if the tape has been stored for six months or longer.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-04T18:51:30.358349"}}
{"question": "How is the cost for virtual tapes stored in the Deep Archive Pool reflected on the AWS bill?", "answer": "The usage and cost for virtual tapes you store in the Deep Archive Pool will show up as an independent service line item on your monthly AWS bill under AWS Storage Gateway Deep Archive, separate from your AWS Storage Gateway and costs.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:51:36.874610"}}
{"question": "What happens to the usage and cost data of virtual tapes when using the AWS Cost Management tool?", "answer": "If you are using the AWS Cost Management tool, the usage and cost for virtual tapes you store in the Deep Archive Pool will be included under AWS Storage Gateway in your detailed monthly spend reports, and it will not be broken out as a separate service line item.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:51:36.875014"}}
{"question": "How does the cost of moving a virtual tape from S3 Glacier to S3 Glacier Deep Archive compare to the early deletion fee for tapes archived for less than 90 days?", "answer": "When moving a virtual tape from S3 Glacier to S3 Glacier Deep Archive, you are charged $0.032 per GB of data stored on the tape. Additionally, if you move a tape that has been archived for less than 90 days in S3 Glacier to S3 Glacier Deep Archive, you will incur an early deletion fee for tape storage in S3 Glacier. The cost for moving the tape is a straightforward charge based on the size, whereas the early deletion fee is an additional charge that applies due to the tape's age in Glacier.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-04T18:51:36.875590"}}
{"question": "What does AWS Premium Support cover regarding the AWS Storage Gateway?", "answer": "AWS Premium Support covers issues related to your use of the AWS Storage Gateway. For further information and pricing, you can refer to the AWS Premium Support detail page.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-04T18:51:41.117036"}}
{"question": "Why is it recommended to purchase AWS Premium Support for AWS Storage Gateway users?", "answer": "It is recommended to purchase AWS Premium Support for AWS Storage Gateway users because it provides assistance for issues related to the service, ensuring that customers have access to support when needed.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-04T18:51:41.117320"}}
{"question": "How does AWS Support assist with hardware-related cases for AWS Storage Gateway?", "answer": "AWS Support coordinates all hardware-related cases with the hardware manufacturer's support team and provides AWS Storage Gateway software and service support.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-04T18:51:41.117488"}}
{"question": "What tools does AWS Systems Manager provide for managing nodes?", "answer": "AWS Systems Manager provides various tools to help complete common node tasks, including Patch Manager for applying patches, Session Manager for secure node management, and Run Command for remotely managing the configuration of managed nodes.", "question_type": "factual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T18:51:45.969817"}}
{"question": "How does AWS Systems Manager improve operational efficiency for managing nodes?", "answer": "AWS Systems Manager improves operational efficiency by simplifying node management, making it easier to manage nodes running anywhere, allowing users to easily install software, apply patches, remediate issues, and gain full visibility across their entire fleet.", "question_type": "conceptual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T18:51:45.970187"}}
{"question": "What is the relationship between managed nodes and the SSM Agent in AWS Systems Manager?", "answer": "A managed node in AWS Systems Manager is any Amazon EC2 instance or non-EC2 machine that has the SSM Agent installed. The SSM Agent enables communication with the Systems Manager service, allowing users to leverage the full suite of Systems Manager tools for management.", "question_type": "comparison", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-04T18:51:45.970687"}}
{"question": "What types of nodes can AWS Systems Manager manage?", "answer": "AWS Systems Manager can manage various nodes including EC2 instances and hybrid servers.", "question_type": "factual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-04T18:51:49.742099"}}
{"question": "What is the purpose of using a delegated administrator account in AWS Systems Manager?", "answer": "The delegated administrator account is used to manage your nodes within AWS Systems Manager, allowing for centralized management across your organization.", "question_type": "conceptual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-04T18:51:49.742450"}}
{"question": "What is required to set up AWS Systems Manager for an AWS Organizations?", "answer": "To set up AWS Systems Manager for an AWS Organizations, you must have access to the management account for your organization and another account in your organization to use as a delegated administrator.", "question_type": "comparison", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-04T18:51:49.742970"}}
{"question": "What types of data can Amazon Textract detect and extract from documents?", "answer": "Amazon Textract can detect and extract printed text, handwriting, structured data (such as fields of interest and their values), and tables from images and scans of documents.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-04T18:51:56.087375"}}
{"question": "How does Amazon Textract ensure the reliability of extracted information?", "answer": "Amazon Textract returns a confidence score for each element it identifies when information is extracted from documents. This allows users to make informed decisions about how to use the results. For example, users can set custom rules to flag any extracted information with a confidence score lower than 95%.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-04T18:51:56.087720"}}
{"question": "How does the capability of Amazon Textract in extracting data from invoices compare to its ability to extract data from identity documents?", "answer": "Amazon Textract can extract explicitly labeled data, implied data, and line items from invoices and receipts in English without any templates or configuration. Similarly, it can extract specific or implied data such as names and addresses from identity documents like U.S. passports and drivers licenses, also without the need for templates or configuration. Both capabilities allow for extraction without worrying about the structure or variations of the data in the documents.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-04T18:51:56.088221"}}
{"question": "What file formats does Amazon Textract currently support?", "answer": "Amazon Textract currently supports PNG, JPEG, TIFF, and PDF formats.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-04T18:51:59.615444"}}
{"question": "What are the submission methods for synchronous and asynchronous APIs in Amazon Textract?", "answer": "For synchronous APIs, you can submit images either as an S3 object or as a byte array. For asynchronous APIs, you can submit S3 objects.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-04T18:51:59.615793"}}
{"question": "How does the method of submitting documents differ between synchronous and asynchronous APIs in Amazon Textract?", "answer": "The main difference in submission methods is that synchronous APIs allow for both S3 objects and byte arrays, while asynchronous APIs only allow for S3 objects.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-04T18:51:59.616284"}}
{"question": "What is the primary function of the Analyze Document API in Amazon Textract?", "answer": "The primary function of the Analyze Document API in Amazon Textract is to detect printed text, handwriting, fields, values, their relationships, tables, and other entities within a document, along with their associated confidence scores. It allows developers to automatically capture structured data from a wide variety of documents.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-04T18:52:04.693791"}}
{"question": "How does the Analyze Document API improve data extraction from documents?", "answer": "The Analyze Document API improves data extraction from documents by allowing developers to specify the data they need to extract using Custom Queries. This feature provides flexibility in extracting structured data without worrying about the structure or variations of the data across different document formats and versions, which enhances extraction accuracy in business-specific documents.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-04T18:52:04.694128"}}
{"question": "How does the Analyze Expense API differ from the Analyze Document API in terms of data extraction?", "answer": "The Analyze Expense API differs from the Analyze Document API in that it is specifically designed to find vendor names, item quantities, and prices on receipts, even when these elements are not labeled with explicit headers. In contrast, the Analyze Document API focuses on a broader range of entities and relationships within various documents, including printed text and tables, and does not specifically target receipts or invoices.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-04T18:52:04.694617"}}
{"question": "What features are available in the Analyze Document API?", "answer": "The Analyze Document API includes the following features: Forms, Tables, Queries, Custom Queries, Signatures, and Layout.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-04T18:52:08.569182"}}
{"question": "How can Queries be customized for business-specific documents?", "answer": "Queries can be customized for business-specific documents using the Custom Queries feature, which allows users to tailor the Queries capabilities to better suit their specific document needs.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-04T18:52:08.569527"}}
{"question": "What is the difference in the maximum number of Queries supported for synchronous versus asynchronous operations?", "answer": "For synchronous operations, the Analyze Document API supports a maximum of 15 Queries per page, while for asynchronous operations, it supports a maximum of 30 Queries per page.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-04T18:52:08.570050"}}
{"question": "What types of documents can Amazon Textract read and extract information from?", "answer": "Amazon Textract can read and extract printed text, handwriting, and structured information from virtually any type of document.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T18:52:13.122862"}}
{"question": "Why is it important to provide a high-quality image for documents when using Amazon Textract?", "answer": "Providing a high-quality image is important because it helps ensure better accuracy in the extraction process. Ideally, the image should be at least 150 DPI to enhance the likelihood of successful data extraction.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T18:52:13.123198"}}
{"question": "How does Amazon Textract's table feature perform in relation to the layout of tables in documents?", "answer": "Amazon Textract's table feature works best when the tables in the document are visually separated from surrounding elements on the page and when the text within the tables is upright. This means tables should not be overlaid on images or complex patterns.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-04T18:52:13.123792"}}
{"question": "In which AWS regions is Amazon Textract currently available?", "answer": "Amazon Textract is currently available in the following regions: US East (Northern Virginia), US East (Ohio), US West (Oregon), US West (N. California), AWS GovCloud (US-West), AWS GovCloud (US-East), Canada (Central), EU (Ireland), EU (London), EU (Frankfurt), EU (Paris), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Seoul), and Asia Pacific (Mumbai).", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:52:25.126786"}}
{"question": "What strategies does AWS recommend to mitigate throttling when using Amazon Textract?", "answer": "AWS recommends several strategies to mitigate throttling when using Amazon Textract: 1. Implement retry logic by following the Error handling guidelines to configure retries for throttling errors. 2. Configure exponential backoff and jitter to improve achievable throughput. 3. Smoothen traffic flow to avoid spiky traffic, potentially using a queueing serverless architecture. 4. Start with samples that apply best practices, such as using IDP CDK Samples with CDK Constructs. 5. Use the Textract Service Quota calculator to estimate quota requirements and submit a quota increase request from the AWS Service Quotas console.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:52:25.127097"}}
{"question": "How does the use of exponential backoff and jitter relate to improving throughput in Amazon Textract?", "answer": "The use of exponential backoff and jitter is related to improving throughput in Amazon Textract by allowing retries to be more spaced out and less likely to occur in bursts. This helps in managing the workload in a way that avoids overwhelming the service during periods of high demand or throttling. By implementing these techniques, users can achieve better overall throughput for their transactions per second (TPS).", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-04T18:52:25.127508"}}
{"question": "What types of image formats are counted as a single page in Amazon Textract?", "answer": "An image counts as a single page if it is in PNG, TIFF, or JPEG format.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-04T18:52:28.959728"}}
{"question": "How does Amazon Textract determine the number of pages processed for PDFs?", "answer": "For PDFs, each page in the document is counted as a page processed.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-04T18:52:28.959944"}}
{"question": "What is the difference in the number of pages analyzed per month between the Analyze Document API using Signatures only and using Forms, Tables, and Layout features under the Free Tier?", "answer": "The Analyze Document API allows for 1,000 pages per month when using Signatures only, while it allows for 100 pages per month when using Forms, Tables, and Layout features.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-04T18:52:28.960281"}}
{"question": "What does Amazon Textract do with the document and image inputs processed by the service?", "answer": "Amazon Textract may store and use document and image inputs solely to provide and maintain the service and to improve and develop the quality of Amazon Textract and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-04T18:52:33.989501"}}
{"question": "Why is the use of content necessary for Amazon Textract?", "answer": "The use of content is necessary for the continuous improvement of the Amazon Textract customer experience, including the development and training of related technologies.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-04T18:52:33.989715"}}
{"question": "How does Amazon Textract ensure the privacy and security of user content compared to its use for improvement purposes?", "answer": "Amazon Textract ensures the privacy and security of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access or disclosure of content. In contrast, it uses the content solely for improving the service and not to target products or services to users.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-04T18:52:33.990099"}}
{"question": "Is Amazon Textract designed to keep my content secure?", "answer": "Yes, Amazon Textract implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content. Your trust, privacy, and the security of your content are the highest priority.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:52:39.247909"}}
{"question": "What happens to my content if I do not opt out of having it used for improvement of Amazon Textract?", "answer": "If you do not opt out, some portion of content processed by Amazon Textract may be stored in another AWS region solely for the continuous improvement and development of your Amazon Textract customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:52:39.248258"}}
{"question": "How does the content storage policy of Amazon Textract differ during the training of adapters compared to regular content processing?", "answer": "During the training of adapters, the content used is processed internally within Amazon Textract and is deleted once training completes. In regular content processing, the content may be stored in another AWS region for improvement purposes unless you opt out, while it is encrypted at rest and in transit in both cases.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-04T18:52:39.248684"}}
{"question": "Is Amazon Textract HIPAA eligible?", "answer": "Yes, Amazon Textract is HIPAA eligible.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-04T18:52:42.460838"}}
{"question": "What compliance standards does Textract meet?", "answer": "Textract is compliant with PCI, ISO, and SOC.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-04T18:52:42.461178"}}
{"question": "How does using AWS PrivateLink with Textract enhance security?", "answer": "Using AWS PrivateLink with Textract allows customers to securely initiate API calls to Amazon Textract from within their Amazon Virtual Private Cloud (Amazon VPC), thereby avoiding the use of the public internet.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-04T18:52:42.461699"}}
{"question": "What technology does Amazon Transcribe use to convert speech to text?", "answer": "Amazon Transcribe uses Automatic Speech Recognition (ASR) technology to convert speech to text.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-04T18:52:48.933605"}}
{"question": "How can Amazon Transcribe be integrated with other AWS services for enhanced functionality?", "answer": "Amazon Transcribe can be integrated with Amazon Comprehend for sentiment analysis and entity extraction from the converted text. It can also work with Amazon Translate and Amazon Polly to translate voice input into another language and generate voice output, enabling multilingual conversations. Additionally, it can be integrated with Amazon Kendra or Amazon OpenSearch for indexing and performing text-based searches across an audio/video library.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-04T18:52:48.933926"}}
{"question": "How does the audio quality affect the performance of Amazon Transcribe compared to its intended functionality?", "answer": "The quality and content of the audio signal can significantly affect the accuracy of Amazon Transcribe's output. Factors such as background noise, overlapping speakers, accented speech, or language switches within a single audio file may hinder the service's performance. Despite these challenges, Amazon Transcribe is designed to handle a wide range of speech and acoustic characteristics and is continually updated to improve its ability to accommodate additional variations.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-04T18:52:48.934353"}}
{"question": "What are the recommended audio formats for Amazon Transcribe?", "answer": "For both batch transcriptions and streaming transcriptions, lossless formats are recommended. However, specific supported media types differ between the two transcription methods.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-04T18:52:53.233676"}}
{"question": "How does Amazon Transcribe handle audio quality from different devices?", "answer": "Amazon Transcribe API can detect the quality of the audio stream being input from a device, distinguishing between 8kHz and 16kHz audio. It then selects the appropriate acoustic models for converting speech to text based on the detected quality.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-04T18:52:53.234014"}}
{"question": "What is the difference between Amazon Transcribe's batch service and streaming service regarding connection duration?", "answer": "The Amazon Transcribe batch service has a limit of four hours (or 2 GB) per API call, while the streaming service can accommodate open connections for up to four hours long.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-04T18:52:53.234513"}}
{"question": "What is one reason why a term included in the custom vocabulary may not be correctly recognized?", "answer": "One of the most frequent reasons for incorrect recognition is that the words are pronounced significantly different than they are written.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T18:52:58.068193"}}
{"question": "How can you improve speech recognition accuracy for words with variable pronunciation?", "answer": "To improve speech recognition accuracy for words with variable pronunciation, it is recommended to create multiple phrase entries in the custom vocabulary file for the same word to cover the possible variations in pronunciation. You can use the DisplayAs column for the desired output for these phrase entries.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T18:52:58.068547"}}
{"question": "What are the implications of having a large custom vocabulary in Amazon Transcribe?", "answer": "Having a large custom vocabulary may lead to over-generation of custom words, especially when it contains words that are pronounced in a similar way. It is preferable to reduce the vocabulary to rare words and words that are actually expected to occur in the audio files. If there is a large vocabulary covering multiple use cases, it is recommended to split it into separate lists for different use cases.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-04T18:52:58.069041"}}
{"question": "Does the Amazon Transcribe Call Analytics feature remove sensitive personal information from the source audio?", "answer": "Yes, Amazon Transcribe Call Analytics removes sensitive personal information from both the transcripts and the source audio.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-04T18:53:03.060728"}}
{"question": "What is the purpose of automatic content redaction in Amazon Transcribe?", "answer": "Automatic content redaction is designed to identify and remove personally identifiable information (PII) from audio input. However, it may not identify and remove all instances of PII in a transcript, so users should review the output to ensure it meets their needs.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-04T18:53:03.061070"}}
{"question": "How do the capabilities of the streaming API differ from the batch API regarding automatic content redaction?", "answer": "The streaming API supports two additional capabilities not available in the batch API: it allows users to identify PII without redacting it, and it enables users to identify or redact specific types of PII, such as redacting only social security numbers and credit card information while keeping other PII like names and email addresses.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-04T18:53:03.061521"}}
{"question": "What happens if no languages are specified when processing an audio file with Amazon Transcribe?", "answer": "If no languages are specified, the system will process the audio file against all the languages supported by Amazon Transcribe and select the most probable one.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-04T18:53:07.426504"}}
{"question": "Why is the accuracy of language identification better when a select list of languages is provided?", "answer": "The accuracy of language identification is better when a select list of languages is provided because it narrows down the options for the system, allowing it to choose from a specific set of languages rather than evaluating all supported languages.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-04T18:53:07.426851"}}
{"question": "How does Amazon Transcribe's handling of voice inputs differ from its use of personally identifiable information?", "answer": "Amazon Transcribe may store and use voice inputs processed by the service to provide and maintain the service and to improve its quality, but it does not use any personally identifiable information contained in the content to target products, services, or marketing to users.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-04T18:53:07.427334"}}
{"question": "Who will have access to the content processed by Amazon Transcribe?", "answer": "Only authorized employees will have access to your content that is processed by Amazon Transcribe.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-04T18:53:11.716953"}}
{"question": "What happens to the original training data after it is used to produce a custom language model?", "answer": "Once the training data is used to produce a custom language model, the original training set you uploaded is expunged from our systems, and you retain ownership of both the original text data and the generated custom model.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-04T18:53:11.717305"}}
{"question": "How does the retention of training data affect technical support for users of Amazon Transcribe?", "answer": "Since training data is not stored, if you require technical support, the support team may need to ask for additional information from you because they do not have convenient access to the original training data or related intermediate artifacts.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-04T18:53:11.717752"}}
{"question": "What encryption methods are used to protect content processed by Amazon Transcribe?", "answer": "Amazon Transcribe implements encryption at rest and in transit to protect content processed by the service. These measures are designed to prevent unauthorized access to or disclosure of the content.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:53:16.973310"}}
{"question": "How does Amazon Transcribe ensure the security and privacy of user content?", "answer": "Amazon Transcribe ensures the security and privacy of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit. Additionally, they prioritize user trust and privacy, and comply with their commitments to users regarding content usage.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:53:16.973693"}}
{"question": "What is the difference between Amazon Transcribe and Amazon Transcribe Call Analytics?", "answer": "Amazon Transcribe is a service that processes speech into text, while Amazon Transcribe Call Analytics is an AI-powered API that provides call transcripts and actionable conversation insights specifically designed for call applications. Call Analytics uses advanced speech-to-text and custom natural language processing models focused on customer care and sales calls, making it distinct from the general transcription service.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-04T18:53:16.974168"}}
{"question": "What types of analytics can Amazon Transcribe Call Analytics perform?", "answer": "Amazon Transcribe Call Analytics can perform both real-time and post-call analytics.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:53:20.753709"}}
{"question": "How can developers utilize Amazon Transcribe Call Analytics in their applications?", "answer": "Developers can utilize Amazon Transcribe Call Analytics by adding valuable intelligence such as customer and agent sentiment scores, call drivers, call categories, and call summarization as an API output to any inbound or outbound call application.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:53:20.754050"}}
{"question": "What is the difference in availability of generative call summarization between real-time and post-call analytics in Amazon Transcribe Call Analytics?", "answer": "Generative call summarization is currently only available with the Transcribe Call Analytics API for post-call analytics, whereas real-time call analytics does not support generative call summarization.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-04T18:53:20.754583"}}
{"question": "What are some use cases for the text transcripts generated by Amazon Transcribe Medical?", "answer": "The text transcripts generated by Amazon Transcribe Medical can be used to support a variety of use cases, including clinical documentation workflow, drug safety monitoring (pharmacovigilance), subtitling for telemedicine, and contact center analytics in the healthcare and life sciences domains.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-04T18:53:25.858290"}}
{"question": "How does Amazon Transcribe Medical ensure that users do not need expertise in ASR or machine learning?", "answer": "Amazon Transcribe Medical ensures that users do not need expertise in ASR or machine learning by allowing them to simply call the Transcribe Medical API. The service handles all necessary machine learning processes in the backend to transcribe medical speech to text.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-04T18:53:25.858630"}}
{"question": "How is the data processed by Amazon Transcribe Medical different from data used to train other Amazon machine learning technologies?", "answer": "The data processed by Amazon Transcribe Medical is not used for any reason other than to provide and maintain the service. Unlike other Amazon machine learning technologies, content processed by Amazon Transcribe Medical is not used to develop or improve the service or any other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-04T18:53:25.859119"}}
{"question": "What are the language models supported by Amazon Transcribe Medical for batch transcriptions?", "answer": "Amazon Transcribe Medical supports custom language models (CLM) for batch transcriptions in Australian English, British English, Hindi, US English, and US Spanish.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-04T18:53:30.655190"}}
{"question": "Why is it important for users to review the output provided by Amazon Transcribe Medical?", "answer": "It is important for users to review the output provided by Amazon Transcribe Medical because the service may not accurately identify protected health information in all circumstances and does not meet HIPAA requirements for de-identification. Users are responsible for ensuring that the information's correctness, completeness, timeliness, and suitability meet their needs.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-04T18:53:30.655460"}}
{"question": "How does using a custom language model (CLM) differ from using the standard transcription service in terms of language support?", "answer": "Using a custom language model (CLM) allows for batch transcriptions in multiple languages such as Australian English, British English, Hindi, US English, and US Spanish, while the standard transcription service only supports US English for streaming transcriptions.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-04T18:53:30.655896"}}
{"question": "What factors influence the change in transcription performance when using custom models?", "answer": "The change in performance will depend on how closely the text data matches the audio and on the amount of data provided. More data is generally better, but it is most important that the data covers words and word sequences that are expected to occur in the audio files you intend to transcribe.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-04T18:53:35.816424"}}
{"question": "Why is the quality of training data important for transcription accuracy?", "answer": "The quality of the training data is important because improvements to transcription accuracy will depend on it, as well as the specific use case. High-quality training data that closely aligns with the expected audio will lead to better performance.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-04T18:53:35.816719"}}
{"question": "How does the maximum number of custom models you can train concurrently compare to the maximum number of models you can store in an AWS account?", "answer": "You can concurrently train up to 5 different models at any given time per AWS account, whereas you can store a maximum of 10 models by default in your account.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-04T18:53:35.817319"}}
{"question": "What topics are covered under the AWS Transit Gateway FAQs?", "answer": "The topics covered under the AWS Transit Gateway FAQs include General information, Performance and limits, Security and compliance, and Feature interoperability.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-04T18:53:40.558327"}}
{"question": "Why is it important to understand the performance and limits of AWS Transit Gateway?", "answer": "Understanding the performance and limits of AWS Transit Gateway is important because it helps users optimize their network architecture and ensure that the gateway can handle their specific workloads and traffic patterns effectively.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-04T18:53:40.558694"}}
{"question": "How does the 'Security and compliance' section differ from the 'Performance and limits' section in the AWS Transit Gateway FAQs?", "answer": "The 'Security and compliance' section focuses on the security measures and compliance standards associated with AWS Transit Gateway, while the 'Performance and limits' section deals with the capabilities and restrictions regarding the performance of the gateway.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-04T18:53:40.559210"}}
{"question": "In which AWS Regions is the AWS Transit Gateway available?", "answer": "AWS Transit Gateway is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (Northern California), AWS GovCloud (US-East), AWS GovCloud (US-West), Canada (Central), South America (So Paulo), Africa (Cape Town), EU (Ireland), EU (Stockholm), EU (London), EU (Frankfurt), EU (Paris), EU (Milan), Middle East (Bahrain), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Seoul), Asia Pacific (Sydney), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Jakarta), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), and Canada West (Calgary).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-04T18:53:54.645859"}}
{"question": "What is the purpose of AWS Transit Gateway Peering support?", "answer": "AWS Transit Gateway Peering support allows for the connection of multiple Transit Gateways across different AWS Regions, enabling efficient routing and management of network traffic between VPCs in separate regions.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-04T18:53:54.646241"}}
{"question": "How does the availability of AWS Transit Gateway compare to Transit Gateway Peering support in terms of AWS Regions?", "answer": "AWS Transit Gateway is available in 27 AWS Regions, while Transit Gateway Peering support is available in 26 AWS Regions. The only region where Transit Gateway is available but does not support Peering is South America (So Paulo).", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-04T18:53:54.646759"}}
{"question": "In which AWS Regions is Transit Gateway Multicast support available?", "answer": "Transit Gateway Multicast support is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), AWS GovCloud (US-East), AWS GovCloud (US-West), Canada (Central), EU (Ireland), EU (London), EU (Frankfurt), EU (Stockholm), EU (Paris), EU (Milano), South America (Sao Paulo), South Africa (Cape Town), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Middle East (Bahrain), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Jakarta), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), and Israel (Tel Aviv).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-04T18:54:08.089827"}}
{"question": "What is the role of IGMP in Transit Gateway Multicast support?", "answer": "IGMP (Internet Group Management Protocol) is essential for managing multicast group memberships for Transit Gateway Multicast. It enables instances to signal their interest in receiving multicast traffic, helping to optimize the delivery of data across the network.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-04T18:54:08.090085"}}
{"question": "How does the availability of IGMP support compare to that of Transit Gateway Multicast support across AWS Regions?", "answer": "IGMP support for Transit Gateway Multicast is available in fewer AWS Regions compared to Transit Gateway Multicast support. While Transit Gateway Multicast is available in a wider range of regions, IGMP support is available in regions like US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (London), Europe (Paris), Europe (Frankfurt), Europe (Stockholm), Europe (Milan), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Osaka), Asia Pacific (Jakarta), Canada (Central), South America (So Paulo), Africa (Cape Town), Middle East (Bahrain), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), GovCloud (US-East), and GovCloud (US-West).", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-04T18:54:08.090480"}}
{"question": "In which AWS Regions is Transit Gateway Connect available?", "answer": "Transit Gateway Connect is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (London), Europe (Paris), Europe (Frankfurt), Europe (Stockholm), Europe (Milan), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Osaka), Asia Pacific (Jakarta), Canada (Central), South America (So Paulo), Africa (Cape Town), Middle East (Bahrain), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), GovCloud (US-East), and GovCloud (US-West).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-04T18:54:16.085555"}}
{"question": "What is the significance of Transit Gateway Connect being available in multiple AWS Regions?", "answer": "The availability of Transit Gateway Connect in multiple AWS Regions allows users to establish and manage connections across different geographical locations, enhancing network flexibility and reliability. This widespread availability enables organizations to optimize their network architecture and improve performance for global applications.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-04T18:54:16.085907"}}
{"question": "How does the availability of Transit Gateway Connect in GovCloud compare to its availability in other regions?", "answer": "Transit Gateway Connect is available in GovCloud (US-East) and GovCloud (US-West), which are specifically designed for government customers requiring compliance with certain regulations. In contrast, it is also available in a broader range of commercial AWS Regions, including various locations in North America, Europe, Asia Pacific, South America, Africa, and the Middle East, catering to a wider audience beyond government users.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-04T18:54:16.086416"}}
{"question": "What is the purpose of creating multiple route tables in an AWS Transit Gateway?", "answer": "The purpose of creating multiple route tables in an AWS Transit Gateway is to segment your network and create isolated networks, similar to virtual routing and forwarding (VRFs) in traditional networks.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-04T18:54:21.484498"}}
{"question": "How does the AWS Transit Gateway manage routing between attached Amazon VPCs and VPNs?", "answer": "The AWS Transit Gateway supports both dynamic and static routing between attached Amazon VPCs and VPNs. By default, Amazon VPCs, VPNs, Direct Connect gateways, Transit Gateway Connect, and peered Transit Gateways are associated with the default route table, but you can create additional route tables and associate other resources with them.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-04T18:54:21.484775"}}
{"question": "What are the differences between the default route table and additional route tables in an AWS Transit Gateway?", "answer": "The default route table in an AWS Transit Gateway automatically associates Amazon VPCs, VPNs, Direct Connect gateways, Transit Gateway Connect, and peered Transit Gateways. In contrast, additional route tables can be created and allow for the association of specific Amazon VPCs, Direct Connect gateways, VPNs, Transit Gateway Connect, and peered Transit Gateways, providing more flexibility in network segmentation.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-04T18:54:21.485272"}}
{"question": "What protocol is used for route propagation between AWS Transit Gateway and on-premises networks?", "answer": "The protocol used for route propagation between the AWS Transit Gateway and on-premises networks is Border Gateway Protocol (BGP).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T18:54:26.949180"}}
{"question": "How does route propagation differ between on-premises networks and Amazon VPCs when using AWS Transit Gateway?", "answer": "Route propagation to/from on-premises networks uses Border Gateway Protocol (BGP), while route propagation to/from Amazon VPCs uses internal APIs instead of BGP. Additionally, when attaching a VPC, its Classless Inter-Domain Routing (CIDR) propagates into the AWS Transit Gateway route table, but routes from the AWS Transit Gateway are not propagated back to the Amazon VPC's route table.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T18:54:26.949520"}}
{"question": "What happens if you attach a new Amazon VPC with an identical CIDR to an already attached Amazon VPC in AWS Transit Gateway?", "answer": "If you attach a new Amazon VPC that has a CIDR identical to an already attached Amazon VPC, AWS Transit Gateway will not propagate the new Amazon VPC route into the AWS Transit Gateway route table.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-04T18:54:26.950042"}}
{"question": "What is the minimum routing requirement for AWS Transit Gateway Connect?", "answer": "AWS Transit Gateway Connect does not support static routes. BGP is a minimum requirement.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:54:31.605760"}}
{"question": "How does AWS Transit Gateway Connect establish BGP sessions?", "answer": "The BGP sessions are established over the GRE tunnel.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:54:31.606101"}}
{"question": "Can you use the same ASN for both the Transit Gateway and the Direct Connect gateway?", "answer": "No, you cannot use the same ASN for the Transit Gateway and the Direct Connect gateway.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-04T18:54:31.606476"}}
{"question": "Does AWS Transit Gateway Connect support IPv6 addresses?", "answer": "Yes, AWS Transit Gateway Connect supports IPv6. You can configure both the GRE tunnel and the Border Gateway Protocol (BGP) addresses with IPv6 addresses.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-04T18:54:36.149365"}}
{"question": "What capabilities does AWS Transit Gateway Network Manager provide for managing networking resources?", "answer": "AWS Transit Gateway Network Manager centralizes management and monitoring of networking resources and connections to remote branch locations. It allows users to create a global network, register AWS Transit Gateways, add on-premises and cloud resources, and monitor the global network through visualizations, events, and metrics.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-04T18:54:36.149706"}}
{"question": "How does the configuration of GRE tunnel addresses compare to BGP addresses in AWS Transit Gateway?", "answer": "You can configure the GRE tunnel and the BGP addresses to be the same or different address family. For example, the GRE tunnel can use an IPv4 address range while the BGP addresses can use an IPv6 address range, and vice versa.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-04T18:54:36.150125"}}
{"question": "What is a Global Network in the context of AWS Transit Gateway Network Manager?", "answer": "A Global Network is an object in the AWS Transit Gateway Network Manager service that represents your private global network in AWS. It includes your AWS Transit Gateway hubs, their attachments, AWS partner SD-WAN network virtual appliances, and on-premises devices, sites, links, and connections.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-04T18:54:42.198707"}}
{"question": "How does the AWS Transit Gateway Network Manager help in monitoring network performance?", "answer": "The AWS Transit Gateway Network Manager helps in monitoring network performance by providing real-time network events and metrics through AWS CloudWatch. The dashboard shows events and metrics such as bytes in/out, packets in/out, packets dropped, and connection status, which helps users monitor their network and take necessary actions.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-04T18:54:42.199057"}}
{"question": "How do the integration capabilities of SD-WAN providers with AWS Transit Gateway Network Manager enhance network management?", "answer": "The integration capabilities of SD-WAN providers with AWS Transit Gateway Network Manager enhance network management by enabling automation of branch-cloud connectivity and providing end-to-end monitoring of the global network from a single dashboard. This integration allows the SD-WAN solution to use AWS APIs to automatically register branch devices, create VPN connections, and apply VPN configurations, thereby simplifying the connection process.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-04T18:54:42.199580"}}
{"question": "What is the primary function of Route Analyzer in AWS Transit Gateway Network Manager?", "answer": "The primary function of Route Analyzer is to verify routing configurations of Transit Gateways across your global network.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-04T18:54:46.291876"}}
{"question": "Can Route Analyzer analyze VPC route tables or customer gateway devices?", "answer": "No, Route Analyzer only verifies Transit Gateway route tables and does not analyze VPC route tables or customer gateway devices.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-04T18:54:46.292215"}}
{"question": "How does the requirement for Transit Gateways to be registered to the Global Network differ for multiple gateways on the path to a destination?", "answer": "If you have multiple Transit Gateways on the path to the destination, all of them need to be registered to the Global Network to use Route Analyzer. In contrast, if there is only one Transit Gateway, it must simply be registered to the Global Network.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-04T18:54:46.292821"}}
{"question": "What is Amazon Translate and how does it work?", "answer": "Amazon Translate is a Neural Machine Translation (MT) service that translates text between supported languages. It is powered by deep learning methods and offers high-quality, affordable, and customizable language translation. The service enables developers to translate company and user-authored content or build applications that require support across multiple languages. It can be accessed via an API for real-time or batch translation of text from the source language to the target language.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-04T18:54:51.895808"}}
{"question": "What are the benefits of using Amazon Translate for developers?", "answer": "The benefits of using Amazon Translate for developers include high-quality translation, affordability, and customization options. Additionally, it allows for the translation of both company and user-authored content, and it supports the development of applications that require multi-language support, all accessible through an API for convenient translation options.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-04T18:54:51.896101"}}
{"question": "How does Amazon Translate's translation capabilities compare to traditional translation methods?", "answer": "The context does not provide specific information comparing Amazon Translate's capabilities to traditional translation methods. Therefore, a direct comparison cannot be made based on the given text.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-04T18:54:51.896627"}}
{"question": "What are the cost savings of using Amazon Translate compared to human translation?", "answer": "Amazon Translate costs a fraction of the cost of human translation, specifically 0.05% at $15 per 1 million characters, whereas human translation averages around $30,000.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-04T18:54:57.492157"}}
{"question": "Why is Amazon Translate beneficial for Language Service Providers (LSPs)?", "answer": "Amazon Translate is beneficial for Language Service Providers (LSPs) because it supports business growth and expansion by increasing productivity by as much as 50%, allowing LSPs to produce larger volumes of translation. This enables professional translators to focus on high-end creative content while Amazon Translate handles the bulk translation tasks.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-04T18:54:57.492525"}}
{"question": "How does Amazon Translate's output quality compare when used with light versus extensive human post-editing?", "answer": "With light human post-editing, Amazon Translate can be used for enabling customer service agents to support users and translating company-authored information like specifications and FAQs. However, with more extensive post-editing, it can be applied to translate high-value, branded content such as advertising and marketing materials, and contracts, indicating that the output quality improves with more thorough post-editing.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-04T18:54:57.492932"}}
{"question": "What are the main ways to use the Amazon Translate API?", "answer": "There are three main ways to use the Amazon Translate API: first, you can integrate the API into your application to localize highly dynamic application components such as multi-participant chat. Second, you can string it with other services to enable language-independent processing, for example, by calling Database services like Amazon RDS through AWS Lambda blueprints to enable website localization of moderately-dynamic content such as user generated reviews and forum posts. Finally, you can translate batches of documents, which can be used by financial services companies to translate and monitor news articles, legal teams for eDiscovery, and patent attorneys to search patent repositories in IP cases.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-04T18:55:03.428827"}}
{"question": "How does Amazon Translate handle an unknown source language?", "answer": "If the source language is unknown, Amazon Translate will identify the source language using Amazon Comprehend behind the scenes and report that language back along with the translation to the target language.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-04T18:55:03.429172"}}
{"question": "In what scenarios can Amazon Translate be integrated with other AWS services?", "answer": "Amazon Translate can be integrated with other AWS services to enable language-independent processing. For example, it can be used with Amazon RDS through AWS Lambda blueprints to localize moderately-dynamic content like user generated reviews and forum posts.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-04T18:55:03.429727"}}
{"question": "What is the maximum size of text that can be translated in a single API call using Amazon Translate's real-time service?", "answer": "The maximum size of text that can be translated in a single API call using Amazon Translate's real-time service is 5,000 bytes.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-04T18:55:10.376604"}}
{"question": "How does the batch translation limit in Amazon Translate differ from the real-time translation limit?", "answer": "The batch translation limit in Amazon Translate allows for a batch of up to 5 GB in size per API call, with each document not exceeding 20 MB and a maximum of 1,000,000 characters. In contrast, the real-time translation limit is restricted to 5,000 bytes per API call, which means that batch translation can handle significantly larger content compared to real-time translation.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-04T18:55:10.376946"}}
{"question": "Is it necessary to attribute translations made by Amazon Translate, and what is the suggested attribution?", "answer": "It is not required to attribute translations made by Amazon Translate; however, it is suggested to attribute the translation to Machine Translation in order to inform your own customers.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-04T18:55:10.377458"}}
{"question": "What does Amazon Translate do with the text inputs processed by the service?", "answer": "Amazon Translate may store and use text inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Translate and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-04T18:55:16.392071"}}
{"question": "Why is the use of customer content important for Amazon Translate?", "answer": "The use of customer content is important for continuous improvement of the Amazon Translate customer experience, including the development and training of related technologies.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-04T18:55:16.392437"}}
{"question": "How does Amazon Translate ensure the security of user content compared to unauthorized access?", "answer": "Amazon Translate implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, user content and ensure that their use complies with commitments to users.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-04T18:55:16.392943"}}
{"question": "What security measures does Amazon Translate implement to protect processed content?", "answer": "Amazon Translate implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to or disclosure of your content. The trust, privacy, and security of your content are their highest priority.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-04T18:55:21.817933"}}
{"question": "Why might some content processed by Amazon Translate be stored in another AWS region?", "answer": "Some portion of content processed by Amazon Translate may be stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Translate customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-04T18:55:21.818197"}}
{"question": "How does the use of Amazon Translate for applications directed at children under age 13 relate to compliance with COPPA?", "answer": "To use Amazon Translate in connection with websites, programs, or other applications directed at children under age 13, you must comply with the AWS Service Terms, including providing any required notices and obtaining any required verifiable parental consent under COPPA.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-04T18:55:21.818617"}}
{"question": "What is Amazon VPC?", "answer": "Amazon VPC (Virtual Private Cloud) lets you provision a logically isolated section of the Amazon Web Services (AWS) cloud where you can launch AWS resources in a virtual network that you define.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:55:27.056955"}}
{"question": "What control do users have over their virtual networking environment in Amazon VPC?", "answer": "Users have complete control over their virtual networking environment in Amazon VPC, including the selection of their own IP address ranges, creation of subnets, and configuration of route tables and network gateways.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:55:27.057294"}}
{"question": "How does the setup of public-facing and private-facing subnets differ in Amazon VPC?", "answer": "In Amazon VPC, a public-facing subnet is created for web servers that have access to the Internet, while backend systems such as databases or application servers are placed in a private-facing subnet with no Internet access.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-04T18:55:27.057796"}}
{"question": "What is a Virtual Private Cloud (VPC) in AWS?", "answer": "A Virtual Private Cloud (VPC) is a logically isolated virtual network in the AWS cloud where you define the VPCs IP address space from ranges you select.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-04T18:55:31.809302"}}
{"question": "How does Amazon VPC enhance security for resources in a virtual network?", "answer": "Amazon VPC enhances security by providing more granular access controls to and from the Amazon EC2 instances in your virtual network, allowing you to define how your network is exposed to the Internet.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-04T18:55:31.809522"}}
{"question": "What is the difference between an Internet Gateway and a NAT Gateway in Amazon VPC?", "answer": "An Internet Gateway is the Amazon VPC side of a connection to the public Internet, allowing resources to access the Internet, whereas a NAT Gateway is a managed service that allows resources in a private subnet to access the Internet without exposing them to incoming traffic from the Internet.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-04T18:55:31.809663"}}
{"question": "What are the four basic options for network architectures when creating a VPC?", "answer": "The four basic options for network architectures when creating a VPC are: 1) Amazon VPC with a single public subnet only, 2) Amazon VPC with public and private subnets, 3) Amazon VPC with public and private subnets and AWS Site-to-Site VPN access, and 4) Amazon VPC with a private subnet only and AWS Site-to-Site VPN access.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-04T18:55:39.228019"}}
{"question": "What is the purpose of VPC endpoints in AWS?", "answer": "VPC endpoints enable you to privately connect your VPC to services hosted on AWS without requiring an Internet gateway, a NAT device, VPN, or firewall proxies. They are designed to allow communication between instances in your VPC and AWS services in a secure manner.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-04T18:55:39.228358"}}
{"question": "How do gateway type endpoints differ from interface type endpoints in Amazon VPC?", "answer": "Gateway type endpoints are available only for specific AWS services such as S3 and DynamoDB, and they add an entry to your route table to route traffic through Amazons private network. In contrast, interface type endpoints provide private connectivity to a wider range of services powered by PrivateLink, including AWS services, your own services, or SaaS solutions, and support connectivity over Direct Connect.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-04T18:55:39.228866"}}
{"question": "Are there any additional charges for creating and using a VPC?", "answer": "No, there are no additional charges for creating and using the VPC itself. However, usage charges for other Amazon Web Services, including Amazon EC2, still apply at published rates for those resources, including data transfer charges.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:55:44.947899"}}
{"question": "What is the purpose of an Internet gateway in Amazon VPC?", "answer": "An Internet gateway enables Amazon EC2 instances in the VPC to directly access the Internet. It allows instances to communicate outbound to the internet and receive unsolicited inbound traffic from the internet, such as web servers.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:55:44.948268"}}
{"question": "How does the data transfer charge differ when accessing AWS resources via a VPC's Internet gateway versus a VPN connection?", "answer": "Data transfer charges are not incurred when accessing Amazon Web Services, such as Amazon S3, via your VPCs Internet gateway. However, if you access AWS resources via your VPN connection, you will incur Internet data transfer charges.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-04T18:55:44.948662"}}
{"question": "What types of IP addresses are considered public IP addresses in a VPC?", "answer": "Public IP addresses in a VPC include public IPv4 addresses, Elastic IP addresses (EIPs), and IPv6 Global Unicast Addresses (GUA). These addresses can be accessed over the internet.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T18:55:51.176126"}}
{"question": "How do instances without public IP addresses access the Internet?", "answer": "Instances without public IP addresses can access the Internet by routing their traffic through a NAT gateway or a NAT instance. They use the public IP address of the NAT device to traverse the Internet, allowing outbound communication but preventing machines on the Internet from initiating connections to these privately addressed instances.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T18:55:51.176474"}}
{"question": "What is the difference between accessing the Internet via a NAT gateway and using an AWS Site-to-Site VPN connection?", "answer": "Accessing the Internet via a NAT gateway allows instances without public IP addresses to send outbound traffic while preventing incoming connections from the Internet. In contrast, an AWS Site-to-Site VPN connection connects a VPC to a datacenter and enables encrypted data transfer between the VPC and the datacenter, without needing an internet gateway.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-04T18:55:51.176981"}}
{"question": "What is the maximum number of secondary CIDR blocks that can be added to a VPC after its creation?", "answer": "You can add up to four (4) secondary CIDR blocks to a VPC after its creation.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T18:55:58.585488"}}
{"question": "Why is it recommended to use non-overlapping IP address ranges when creating multiple VPCs?", "answer": "It is recommended to use non-overlapping IP address ranges when creating multiple VPCs because overlapping IP address ranges prohibit connecting these VPCs to a common home network via the hardware VPN connection.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T18:55:58.585825"}}
{"question": "What are the differences in how publicly routable IP blocks and private IPv4 addresses can be accessed in AWS VPC?", "answer": "Publicly routable IP blocks can only be reached via the Virtual Private Gateway and cannot be accessed over the Internet through the Internet gateway. In contrast, private IPv4 addresses, such as those in the RFC 1918 range, do not have these restrictions and can be used for internal communication within the VPC.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-04T18:55:58.586359"}}
{"question": "How many secondary IPv4 IP ranges can be added to an existing Amazon VPC?", "answer": "You can add four (4) secondary IPv4 IP ranges to your existing Amazon VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-04T18:56:04.012687"}}
{"question": "What are the implications of overlapping IP address ranges when creating a VPC?", "answer": "The IP address ranges of your VPC should not overlap with the IP address ranges of your existing network, as this could lead to conflicts and connectivity issues.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-04T18:56:04.013050"}}
{"question": "How does the size of subnets differ between IPv4 and IPv6 in an Amazon VPC?", "answer": "For IPv4, the minimum size of a subnet is /28 (which provides 14 IP addresses), and subnets cannot be larger than the VPC they are created in. In contrast, for IPv6, the subnet size is fixed to /64, and only one IPv6 CIDR block can be allocated to a subnet.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-04T18:56:04.013570"}}
{"question": "What happens if you do not specify the primary private IPv4 address when launching an Amazon EC2 instance?", "answer": "If you do not specify the primary private IPv4 address when launching an Amazon EC2 instance, AWS automatically addresses it from the IPv4 address range you assign to that subnet.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-04T18:56:10.257255"}}
{"question": "What is the difference between assigning primary and secondary private IPv4 addresses to an EC2 instance?", "answer": "The primary private IPv4 address is retained for the instance's or interface's lifetime, while secondary private IPv4 addresses can be assigned, unassigned, or moved between interfaces or instances at any time.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-04T18:56:10.257605"}}
{"question": "How is the allocation of IPv4 addresses different from that of IPv6 addresses for running instances?", "answer": "An IPv4 address assigned to a running instance can only be reused by another instance once the original instance is in a 'terminated' state. In contrast, the IPv6 GUA assigned to a running instance can be reused by another instance after it is removed from the first instance.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-04T18:56:10.258079"}}
{"question": "What is the maximum number of secondary private IP addresses that can be assigned to an EC2 instance in Amazon VPC based on instance type?", "answer": "The number of secondary private IP addresses that can be assigned to an EC2 instance in Amazon VPC depends on the instance type. For more specific information, you should refer to the EC2 User Guide.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-04T18:56:18.651221"}}
{"question": "What are the limitations of using Elastic IP (EIP) addresses in relation to VPN connections and subnets?", "answer": "EIP addresses will only be reachable from the Internet and not over the VPN connection. Additionally, each EIP address must be associated with a unique private IP address on the instance, and EIPs should only be used on instances in subnets that are configured to route their traffic directly to the Internet gateway. They cannot be used on instances in subnets configured to use a NAT gateway or a NAT instance to access the Internet.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-04T18:56:18.651566"}}
{"question": "How does Bring Your Own IP (BYOIP) differ from using Amazon-supplied IPs?", "answer": "Bring Your Own IP (BYOIP) enables customers to move their existing publicly routable IPv4 or IPv6 address space to AWS, allowing them to continue owning the IP range. In contrast, Amazon-supplied IPs are provided by AWS for use with resources. Customers using BYOIP can create Elastic IPs from their own IPv4 space and associate up to 5 CIDRs from their IPv6 space, while still having access to Amazon-supplied IPs and the option to use both BYOIP Elastic IPs and Amazon-supplied IPs.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-04T18:56:18.652031"}}
{"question": "What is one reason why customers might want to bring their own IP addresses to AWS?", "answer": "One reason customers might want to bring their own IP addresses to AWS is due to IP reputation. Customers consider the reputation of their IP addresses to be a strategic asset, and by using their existing high reputation IPs on AWS, they can maintain their sending success rate for services such as outbound e-mail MTA.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-04T18:56:25.621965"}}
{"question": "How does BYOIP facilitate the migration of workloads that rely on IP address whitelisting to AWS?", "answer": "BYOIP facilitates the migration of workloads that rely on IP address whitelisting to AWS by allowing customers to use their existing IP addresses, which means they do not need to re-establish the whitelists with new IP addresses. This simplifies the process of moving their services to AWS.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-04T18:56:25.622336"}}
{"question": "What is the difference between the maximum IPv4 and IPv6 prefix sizes that can be brought to AWS via BYOIP?", "answer": "The maximum IPv4 prefix that can be brought to AWS via BYOIP is a /24 prefix, while the maximum IPv6 prefix is a /56 prefix. However, if the IPv6 prefix is intended to be advertised to the internet, the most specific prefix that can be brought is a /48.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-04T18:56:25.622859"}}
{"question": "What is Amazon VPC IP Address Manager (IPAM)?", "answer": "Amazon VPC IP Address Manager (IPAM) is a managed service that facilitates the planning, tracking, and monitoring of IP addresses for AWS workloads. It allows users to organize IP addresses based on routing and security needs, set business rules for IP address assignments, and automate the assignment process to VPCs.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:56:34.841554"}}
{"question": "How does IPAM enhance the efficiency of IP address management compared to traditional methods?", "answer": "IPAM enhances efficiency by eliminating the need for spreadsheet-based or homegrown IP address planning applications, which are often hard to maintain and time-consuming. It automates IP address assignments, allowing developers to roll out applications faster without having to wait for central IP address administration teams. Additionally, IPAM can detect overlapping IP addresses and set alarms for address pool exhaustion, which reduces manual work and minimizes errors.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:56:34.841899"}}
{"question": "In what ways does IPAM monitor IP usage compared to traditional methods?", "answer": "IPAM monitors IP usage by providing alerts when it detects potential issues, such as depleting IP addresses that could stall network growth or overlapping IP addresses that might lead to erroneous routing. In contrast, traditional methods that rely on spreadsheets typically lack automated monitoring and alerting capabilities, making it more difficult to proactively manage IP address issues.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-04T18:56:34.842408"}}
{"question": "What are the two default scopes included in IPAM?", "answer": "The two default scopes included in IPAM are the private scope, which is intended for all private space, and the public scope, which is intended for all public space.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-04T18:56:39.933018"}}
{"question": "How do scopes in IPAM help with IP address management?", "answer": "Scopes in IPAM enable you to reuse IP addresses across multiple unconnected networks without causing IP address overlap or conflict. This organization allows for efficient management of IP spaces.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-04T18:56:39.933365"}}
{"question": "What is the difference between an IPAM pool and a scope in IPAM?", "answer": "An IPAM pool is a collection of contiguous IP address ranges (or CIDRs) that are organized according to routing and security needs, while a scope is the highest-level container within IPAM that represents the IP space for a single network. A scope can contain multiple IPAM pools.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-04T18:56:39.933857"}}
{"question": "What increments do the allocation of contiguous IPv6 CIDR blocks start from in Amazon?", "answer": "The allocation of contiguous IPv6 CIDR blocks from Amazon starts in /52 increments, and larger blocks are available upon request.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-04T18:56:45.303157"}}
{"question": "How do security groups and network ACLs differ in their operation within an Amazon VPC?", "answer": "Security groups in a VPC specify which traffic is allowed to or from an Amazon EC2 instance and perform stateful filtering, meaning they remember the state of connections. In contrast, network ACLs operate at the subnet level, evaluate traffic entering and exiting a subnet, and perform stateless filtering, which means they do not remember connection states. Additionally, network ACLs can set both Allow and Deny rules, but they do not filter traffic between instances in the same subnet.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-04T18:56:45.303503"}}
{"question": "Can IPAM pools be shared with accounts outside of your primary AWS Organization, and if so, how?", "answer": "Yes, IPAM pools can be shared with accounts outside of your primary AWS Organization using AWS Resource Access Manager (RAM). This can include accounts that represent another line of business in your company or a managed service hosted by a partner on your behalf, in another AWS Organization.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-04T18:56:45.303701"}}
{"question": "What does stateful filtering do with reply traffic from requests?", "answer": "Stateful filtering tracks the origin of a request and can automatically allow the reply to the request to be returned to the originating computer. For example, it allows the return traffic, usually on a high numbered port, to pass through the stateful filter between the client and the webserver.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-04T18:56:54.060269"}}
{"question": "How does stateful filtering differ from stateless filtering in terms of traffic management?", "answer": "Stateful filtering maintains a state table that tracks the origin and destination port numbers and IP addresses, requiring only one rule to allow traffic inbound to a web server on TCP port 80. In contrast, stateless filtering only examines the source or destination IP address and the destination port, requiring two rules: one for inbound traffic to the web server on TCP port 80 and another for outbound traffic from the webserver.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-04T18:56:54.060613"}}
{"question": "What are the implications of having an Internet gateway configured for Amazon VPC traffic?", "answer": "If an Internet gateway is configured, Amazon VPC traffic bound for Amazon EC2 instances not within a VPC traverses the Internet gateway and enters the public AWS network to reach the EC2 instance. However, if an Internet gateway is not configured, or if the instance is in a subnet that routes through the virtual private gateway, the traffic will traverse the VPN connection, egress from your datacenter, and then re-enter the public AWS network.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-04T18:56:54.061129"}}
{"question": "What are the options available for resources within a VPC to communicate with Amazon S3?", "answer": "There are multiple options for resources within a VPC to communicate with Amazon S3. You can use a VPC Endpoint for S3, which ensures all traffic remains within Amazon's network and allows for additional access policies. Alternatively, you can use an Internet gateway to enable Internet access from your VPC, allowing instances in the VPC to communicate with Amazon S3. Another option is to make all traffic to Amazon S3 traverse the Direct Connect or VPN connection, egress from your datacenter, and then re-enter the public AWS network.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-04T18:57:01.743647"}}
{"question": "What is the purpose of VPC flow logs in Amazon VPC?", "answer": "VPC flow logs is a feature that allows you to capture information about the IP traffic going to and from network interfaces in your VPC. It provides operational visibility about network dependencies and traffic patterns, helps detect anomalies and prevent data leakage, and assists in troubleshooting network connectivity and configuration issues. Additionally, the enriched metadata in flow logs offers insights about who initiated TCP connections and the packet-level source and destination for traffic flowing through intermediate layers such as the NAT Gateway.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-04T18:57:01.743932"}}
{"question": "How does the use of a VPC Endpoint for S3 compare to using an Internet gateway for Amazon S3 communication?", "answer": "Using a VPC Endpoint for S3 ensures that all traffic remains within Amazon's network and allows the application of additional access policies to your Amazon S3 traffic. In contrast, using an Internet gateway enables Internet access from your VPC, allowing instances within the VPC to communicate with Amazon S3 over the public Internet. Therefore, the key difference is that a VPC Endpoint maintains traffic within Amazon's network while an Internet gateway allows communication over the public Internet.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-04T18:57:01.744345"}}
{"question": "What options do you have when creating a flow log for a subnet or VPC?", "answer": "When creating a flow log for a subnet or VPC, you can choose the metadata fields to capture, the maximum aggregation interval, and your preferred log destination. Additionally, you can select whether to capture all traffic or only accepted or rejected traffic.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-04T18:57:08.136643"}}
{"question": "How does the collection of flow log data impact network performance?", "answer": "Flow log data is collected outside of the path of your network traffic, which means it does not affect network throughput or latency. You can create or delete flow logs without any risk of impacting network performance.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-04T18:57:08.136992"}}
{"question": "What is the difference between Amazon VPC flow logs and VPC traffic mirroring?", "answer": "Amazon VPC flow logs are used to monitor and log network traffic for VPCs, subnets, or network interfaces, allowing users to analyze the data through tools like CloudWatch and Amazon S3. In contrast, VPC traffic mirroring enables customers to replicate network traffic to and from an Amazon EC2 instance for security and monitoring purposes, allowing for use-cases such as content inspection and threat monitoring.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-04T18:57:08.137502"}}
{"question": "What does Traffic Mirroring support for EC2 instances?", "answer": "Traffic mirroring supports network packet captures at the Elastic Network Interface (ENI) level for EC2 instances.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-04T18:57:17.395138"}}
{"question": "How does Amazon VPC traffic mirroring differ from Amazon VPC flow logs in terms of the information they capture?", "answer": "Amazon VPC traffic mirroring provides deeper insight into network traffic by allowing the analysis of actual traffic content, including payloads, whereas Amazon VPC flow logs capture information about allowed and denied traffic, source and destination IP addresses, ports, protocol number, packet and byte counts, and actions (accept or reject).", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-04T18:57:17.395500"}}
{"question": "What are some use cases for employing Amazon VPC traffic mirroring?", "answer": "Use cases for employing Amazon VPC traffic mirroring include analyzing actual packets to determine the root cause of performance issues, reverse-engineering a sophisticated network attack, and detecting and stopping insider abuse or compromised workloads.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-04T18:57:17.395977"}}
{"question": "What does the DescribeInstances() function return?", "answer": "The DescribeInstances() function returns all running Amazon EC2 instances.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:57:21.540319"}}
{"question": "How can you differentiate between EC2-Classic and EC2-VPC instances?", "answer": "You can differentiate EC2-Classic instances from EC2-VPC instances by an entry in the subnet field. If there is a subnet ID listed, the instance is within a VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:57:21.540649"}}
{"question": "What is the difference in IP address assignment for instances launched in a VPC versus those launched outside a VPC?", "answer": "An instance launched in a VPC using an Amazon EBS-backed AMI maintains the same IP address when stopped and restarted, while similar instances launched outside a VPC get a new IP address when stopped and restarted.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-04T18:57:21.541070"}}
{"question": "Can the hostname of an instance be changed, and if so, how?", "answer": "Yes, you can change the hostname of an instance from IP based to Resource based or vice versa by stopping the instance and then changing the resource based naming options.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-04T18:57:28.111124"}}
{"question": "What are the benefits of launching resources in a default VPC?", "answer": "When you launch resources in a default VPC, you can benefit from the advanced networking functionalities of Amazon VPC with the ease of use of Amazon EC2. Features include changing security group membership on the fly, security group egress filtering, multiple IP addresses, and multiple network interfaces without having to explicitly create a VPC and launch instances in it.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-04T18:57:28.111461"}}
{"question": "What is the difference between the resolution of IP based names and Resource based names for instances in an IPv4-only subnet?", "answer": "In an IPv4-only subnet, the IP based name always resolves to the Private IPv4 address on the primary network interface of the instance, and this cannot be turned off. In contrast, the Resource based name can be configured to resolve to either the Private IPv4 address on the primary network interface, the first IPv6 GUA on the primary network interface, or both.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-04T18:57:28.112053"}}
{"question": "What tools can you use to launch and manage EC2 instances in a default VPC?", "answer": "You can use the AWS Management Console, AWS EC2 CLI, or the Amazon EC2 API to launch and manage EC2 instances and other AWS resources in a default VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-04T18:57:33.316586"}}
{"question": "What happens to instances launched in default subnets of a default VPC regarding public IP addresses?", "answer": "Instances launched in default subnets in the default VPC automatically receive public IP addresses, and the default VPC is connected to an Internet gateway.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-04T18:57:33.316928"}}
{"question": "How does the process of launching an instance differ between a default VPC and a nondefault VPC?", "answer": "To launch an instance into a default VPC, you do not need to specify a subnet-ID, whereas to launch into nondefault VPCs, you must specify a subnet-ID during the instance launch.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-04T18:57:33.317463"}}
{"question": "What must be done to enable an existing account for a default VPC?", "answer": "To enable an existing account for a default VPC, you must ensure that there are no EC2-Classic resources in that account for the region. Additionally, you need to terminate all non-VPC provisioned Elastic Load Balancers, Amazon RDS, Amazon ElastiCache, and Amazon Redshift resources in that region.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-04T18:57:39.652340"}}
{"question": "What is the main difference between EC2-Classic and Amazon VPC?", "answer": "The main difference between EC2-Classic and Amazon VPC is that EC2-Classic is a flat network where instances run in a single, shared environment with other customers, while Amazon VPC allows you to run instances in a virtual private cloud that is logically isolated to your AWS account.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-04T18:57:39.652694"}}
{"question": "How does the presence of a default VPC affect IAM accounts associated with an AWS account?", "answer": "If your AWS account has a default VPC, any IAM accounts associated with that AWS account will use the same default VPC as the AWS account itself.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-04T18:57:39.653207"}}
{"question": "How can I check if I have EC2-Classic enabled on my AWS account?", "answer": "You can check if you have EC2-Classic enabled on your account by using the AWS console or the describe-account-attributes command for any AWS region. For more details, please refer to the relevant document.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-04T18:57:47.665878"}}
{"question": "What should I do if I have active AWS resources running on EC2-Classic?", "answer": "If you have active AWS resources running on EC2-Classic, you should plan their migration to Amazon VPC as soon as possible. You will not be able to launch any instances or AWS services on the EC2-Classic platform beyond August 15, 2022.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-04T18:57:47.666213"}}
{"question": "What is the difference in the actions required if I do or do not have active AWS resources running on EC2-Classic?", "answer": "If you do not have any active AWS resources running on EC2-Classic, you are requested to turn off EC2-Classic from your account for that region, allowing you to launch Default VPC there. Conversely, if you have active AWS resources on EC2-Classic, you need to plan for their migration to Amazon VPC since you will not be able to launch any instances or services on EC2-Classic after August 15, 2022.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-04T18:57:47.666621"}}
{"question": "What is the main advantage of using Amazon VPC over the EC2-Classic environment?", "answer": "The main advantage of using Amazon VPC over the EC2-Classic environment is that it provides complete control over your virtual network environment, which is logically isolated to your AWS account. This includes features such as the ability to select your own IP address space, configure public and private subnets, and manage route tables and network gateways.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-04T18:57:55.095758"}}
{"question": "How does Amazon VPC enhance the management of network resources compared to EC2-Classic?", "answer": "Amazon VPC enhances the management of network resources compared to EC2-Classic by allowing users to configure public and private subnets, manage route tables, and control network gateways, thereby providing greater flexibility and control over the network environment.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-04T18:57:55.096129"}}
{"question": "In what ways does Amazon VPC provide more options than EC2-Classic?", "answer": "Amazon VPC provides more options than EC2-Classic by allowing users to select their own IP address space, configure public and private subnets, and manage route tables and network gateways. Additionally, Amazon VPC offers a much wider and latest generation of instances compared to EC2-Classic.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-04T18:57:55.096339"}}
{"question": "What script can be used to identify resources provisioned in EC2-Classic across all regions in an account?", "answer": "The script mentioned in the context can be used to identify all resources provisioned in EC2-Classic across all regions in an account.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-04T18:58:01.261528"}}
{"question": "What is the purpose of the AWS Application Migration Service (AWS MGN)?", "answer": "The AWS Application Migration Service (AWS MGN) simplifies, expedites, and reduces the cost of migrating applications from EC2-Classic to VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-04T18:58:01.261872"}}
{"question": "How does the 'AWSSupport-MigrateEC2 ClassicToVPC' runbook differ from using AWS MGN for migrating EC2 instances?", "answer": "The 'AWSSupport-MigrateEC2 ClassicToVPC' runbook automates the migration of a single EC2 instance from EC2-Classic to VPC by creating an AMI of the instance, creating a new instance in VPC, and optionally terminating the EC2-Classic instance, while AWS MGN provides a highly automated lift-and-shift solution for migrating applications more broadly.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-04T18:58:01.262390"}}
{"question": "What will happen to 3-year and 1-year reserved instances for the EC2-Classic environment on October 30, 2021?", "answer": "On October 30, 2021, we will stop issuing 3-year reserved instances (RI) and 1-year RI for the EC2-Classic environment. However, RIs already in place on the EC2-Classic environment will not be affected at this time.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-04T18:58:08.015619"}}
{"question": "What is the process for modifying reserved instances that are set to expire after August 15, 2022?", "answer": "Reserved instances that are set to expire after August 15, 2022, will need to be modified to use the Amazon VPC environment for the remaining period of the lease. For information on how to modify your RIs, please visit the provided document.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-04T18:58:08.015965"}}
{"question": "How does the traffic isolation in peered VPCs compare to traffic isolation in the same VPC?", "answer": "Traffic between instances in peered VPCs remains private and isolated, similar to how traffic between two instances in the same VPC is private and isolated.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-04T18:58:08.016396"}}
{"question": "Can either side of the peering connection terminate it at any time?", "answer": "Yes, either side of the peering connection can terminate the peering connection at any time, which means that traffic wont flow between the two VPCs.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T18:58:15.317079"}}
{"question": "What are the benefits of using Inter-Region VPC Peering in terms of bandwidth and redundancy?", "answer": "Inter-Region VPC Peering operates on a horizontally scaled, redundant, and highly available technology. The bandwidth between instances in peered VPCs is equivalent to that in the same VPC, and traffic goes over the AWS backbone which has in-built redundancy and dynamic bandwidth allocation, ensuring there is no single point of failure for communication.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T18:58:15.317431"}}
{"question": "How does the bandwidth between instances in peered VPCs compare to the bandwidth in the same VPC?", "answer": "The bandwidth between instances in peered VPCs is no different than the bandwidth between instances in the same VPC.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-04T18:58:15.317948"}}
{"question": "What is required to use ClassicLink in an Amazon VPC?", "answer": "To use ClassicLink, you must enable at least one VPC in your account for ClassicLink and associate a Security Group from that VPC with the desired EC2-Classic instance.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-04T18:58:22.295049"}}
{"question": "How does ClassicLink affect communication between EC2-Classic instances and VPC instances?", "answer": "ClassicLink allows EC2 instances in the EC2-Classic platform to communicate with instances in a VPC using private IP addresses. When an EC2-Classic instance is linked to a VPC via ClassicLink, it becomes a member of the associated VPC Security Group, and all the rules of that Security Group apply to communications between the EC2-Classic instance and instances within the VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-04T18:58:22.295394"}}
{"question": "What are the restrictions on enabling ClassicLink for a VPC with a certain CIDR range?", "answer": "ClassicLink cannot be enabled for a VPC that has a CIDR within the 10.0.0.0/8 range, with the exceptions of 10.0.0.0/16 and 10.1.0.0/16. Additionally, ClassicLink cannot be enabled for any VPC that has a route table entry pointing to the 10.0.0.0/8 CIDR space to a target other than 'local'.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-04T18:58:22.295920"}}
{"question": "What happens to traffic from an EC2-Classic instance when using ClassicLink?", "answer": "Traffic from an EC2-Classic instance can only be routed to private IP addresses within the VPC. It will not be routed to any destinations outside the VPC, including Internet gateway, virtual private gateway, or peered VPC destinations.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-04T18:58:29.321163"}}
{"question": "How does AWS PrivateLink enhance security for service users accessing AWS services?", "answer": "AWS PrivateLink enhances security for service users by allowing them to access services hosted on AWS in a highly available and scalable manner while keeping all the network traffic within the AWS network. This means service users can privately access services from their Amazon VPC or on-premises without using public IPs and without requiring the traffic to traverse across the Internet.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-04T18:58:29.321498"}}
{"question": "What is the difference between ClassicLink and AWS PrivateLink regarding traffic routing?", "answer": "ClassicLink allows traffic from EC2-Classic instances to be routed only to private IP addresses within the VPC and does not permit routing to any external destinations. In contrast, AWS PrivateLink enables customers to access services while keeping the network traffic within the AWS network and allows for private access to services using interface type VPC endpoints, which route traffic privately to the corresponding AWS services.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-04T18:58:29.321991"}}
{"question": "Which AWS services support AWS PrivateLink?", "answer": "The AWS services that support AWS PrivateLink include Amazon Elastic Compute Cloud (EC2), Elastic Load Balancing (ELB), Kinesis Streams, Service Catalog, EC2 Systems Manager, Amazon SNS, and AWS DataSync. Additionally, many SaaS solutions also support this feature.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-04T18:58:34.647716"}}
{"question": "How can an on-premises application connect to service endpoints in Amazon VPC?", "answer": "An on-premises application can connect to the service endpoints in Amazon VPC over AWS Direct Connect. The service endpoints will automatically direct the traffic to AWS services powered by AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-04T18:58:34.648052"}}
{"question": "What are the management options available for Amazon VPC compared to ElasticFox?", "answer": "Amazon VPC can be managed via the AWS APIs, command line tools, and the AWS Management Console. Additionally, a simple wizard is available for creating a VPC. In contrast, ElasticFox is no longer officially supported for managing Amazon VPC.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-04T18:58:34.648510"}}
{"question": "What two services are included in AWS VPN?", "answer": "AWS VPN is comprised of two services: AWS Site-to-Site VPN and AWS Client VPN.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-04T18:58:40.515528"}}
{"question": "What is the purpose of the AWS Client VPN endpoint?", "answer": "The Client VPN endpoint is a regional construct that you configure to use the service, and it is where the VPN sessions of the end users terminate. You also specify the authentication details, server certificate information, client IP address allocation, logging, and VPN options as part of configuring the Client VPN endpoint.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-04T18:58:40.515888"}}
{"question": "How does AWS Site-to-Site VPN differ from AWS Client VPN regarding network connectivity?", "answer": "AWS Site-to-Site VPN enables you to securely connect your on-premises network or branch office site to your Amazon Virtual Private Cloud (Amazon VPC), while AWS Client VPN enables users to securely connect to AWS or on-premises networks. Therefore, Site-to-Site VPN focuses on connecting entire networks, whereas Client VPN focuses on connecting individual users.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-04T18:58:40.516471"}}
{"question": "What happens if I no longer wish to use my VPN connection?", "answer": "If you no longer wish to use your VPN connection, you simply terminate the VPN connection to avoid being billed for additional VPN connection-hours.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T18:58:45.687926"}}
{"question": "How do instances without public IP addresses access the Internet?", "answer": "Instances without public IP addresses can access the Internet by routing their traffic through a network address translation (NAT) gateway or a NAT instance. These instances use the public IP address of the NAT gateway or NAT instance to traverse the internet, allowing outbound communication but not enabling machines on the internet to initiate a connection to the privately addressed instances.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T18:58:45.688266"}}
{"question": "What is the difference between a NAT gateway and a hardware VPN connection in terms of Internet access for instances without public IP addresses?", "answer": "A NAT gateway allows instances without public IP addresses to access the Internet by routing traffic through it, using the NAT's public IP address for outbound communications. In contrast, a hardware VPN connection allows instances to route their Internet traffic down the virtual private gateway to an existing datacenter, where they can access the Internet via existing egress points and network security/monitoring devices.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-1", "source_tokens": 499, "generated_at": "2026-02-04T18:58:45.688799"}}
{"question": "What are the two types of AWS Site-to-Site VPN connections?", "answer": "The two types of AWS Site-to-Site VPN connections are statically routed VPN connections and dynamically-routed VPN connections.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T18:58:52.327953"}}
{"question": "What additional capabilities do devices supporting dynamically-routed Site-to-Site VPN connections need to have compared to those supporting statically-routed connections?", "answer": "Devices supporting dynamically-routed Site-to-Site VPN connections must be able to establish Border Gateway Protocol (BGP) peering, bind tunnels to logical interfaces (route-based VPN), and utilize IPsec Dead Peer Detection. These capabilities are in addition to the requirements for statically-routed connections.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T18:58:52.328179"}}
{"question": "How do the default encryption and hashing proposals for the VPN endpoint on AWS differ from the requirements for statically and dynamically routed connections?", "answer": "By default, the VPN endpoint on the AWS side will propose AES-128 for encryption, SHA-1 for hashing, and DH group 2 for Diffie-Hellman. However, the requirements for statically routed connections include support for various encryption functions such as AES 128-bit, 256-bit, and others, as well as hashing functions like SHA-1 and SHA-2. The dynamically routed connections require additional functionalities like BGP peering and Dead Peer Detection, which are not specified in the default proposals.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-04T18:58:52.328560"}}
{"question": "What is the maximum throughput supported by each tunnel in an AWS Site-to-Site VPN connection?", "answer": "Each tunnel in an AWS Site-to-Site VPN connection supports a maximum throughput of up to 1.25 Gbps.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T18:58:58.072550"}}
{"question": "How does the aggregate throughput limit apply to multiple VPN connections to the same Virtual Private Gateway?", "answer": "Multiple VPN connections to the same Virtual Private Gateway are bound by an aggregate throughput limit from AWS to on-premises of up to 1.25 Gbps.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T18:58:58.072886"}}
{"question": "What is the difference in throughput limits between AWS Site-to-Site VPN connections and AWS Direct Connect connections on a Virtual Private Gateway?", "answer": "AWS Site-to-Site VPN connections are bound by an aggregate throughput limit of up to 1.25 Gbps per connection type, while AWS Direct Connect connections on a Virtual Private Gateway are bound by the Direct Connect physical port itself, which may have different throughput characteristics.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-04T18:58:58.073381"}}
{"question": "What is the maximum number of routes that can be advertised to a Site-to-Site VPN connection on an AWS Transit Gateway?", "answer": "The maximum number of routes that can be advertised to a Site-to-Site VPN connection on an AWS Transit Gateway is 1,000 routes.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-04T18:59:02.780223"}}
{"question": "How does the route-based configuration of AWS VPN service handle Security Association (SA) limitations compared to a policy-based solution?", "answer": "The route-based configuration of the AWS VPN service does not run into Security Association (SA) limitations, whereas a policy-based solution is limited to a single SA.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-04T18:59:02.780570"}}
{"question": "What is the difference in the maximum number of advertised routes from a customer gateway device to a Site-to-Site VPN connection on a virtual private gateway versus an AWS Transit Gateway?", "answer": "The maximum number of advertised routes from a customer gateway device to a Site-to-Site VPN connection on a virtual private gateway is 100 routes, while on an AWS Transit Gateway, it is 1,000 routes.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-04T18:59:02.780940"}}
{"question": "What feature allows the deployment of VPN connections to an AWS Transit Gateway using private IP addresses?", "answer": "The Private IP Site-to-Site VPN feature allows you to deploy VPN connections to an AWS Transit Gateway using private IP addresses.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-04T18:59:06.980742"}}
{"question": "What are the advantages of using BGP for private IP VPN connections?", "answer": "Using BGP for private IP VPN connections offers robust liveness detection checks that can assist in failover to the second VPN tunnel if the first tunnel goes down. It is recommended to use BGP capable devices when available.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-04T18:59:06.981084"}}
{"question": "How does the route-table association and propagation behavior for a private IP VPN attachment compare to other Transit Gateway attachments?", "answer": "The route-table association and propagation behavior for a private IP VPN attachment is the same as any other Transit Gateway attachment. You can associate a Transit Gateway route-table to the private IP VPN attachment and propagate routes from the Private IP VPN attachment to any of the Transit Gateway route-tables.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-04T18:59:06.981652"}}
{"question": "What is the maximum bandwidth supported by each private IP VPN connection?", "answer": "Each private IP VPN connection supports 1.25Gbps of bandwidth.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T18:59:11.394456"}}
{"question": "Why might a user choose to enable acceleration for their Site-to-Site VPN connection?", "answer": "A user might choose to enable acceleration for their Site-to-Site VPN connection to achieve a more consistent user experience, as accelerated Site-to-Site VPN uses the highly available and congestion-free AWS global network, reducing the risks of availability and performance issues that can occur when traffic traverses multiple congested public networks.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T18:59:11.394799"}}
{"question": "What is the difference between private IP VPN connections and public IP VPN connections regarding ECMP?", "answer": "ECMP can be used across multiple private IP VPN connections to increase effective bandwidth, but it cannot be used across private and public IP VPN connections. ECMP for private IP VPN will only work with VPN connections that have private IP addresses.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-04T18:59:11.395326"}}
{"question": "What is required for Accelerated Site-to-Site VPN connections?", "answer": "NAT-T is required and is enabled by default for Accelerated Site-to-Site VPN connections.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-04T18:59:15.839180"}}
{"question": "What are the similarities between Accelerated and non-Accelerated VPN tunnels?", "answer": "Accelerated and non-Accelerated VPN tunnels support the same IP security (IPSec) and internet key exchange (IKE) protocols, and also offer the same bandwidth, tunnel options, routing options, and authentication types.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-04T18:59:15.839520"}}
{"question": "How do the tunnel endpoints for Accelerated Site-to-Site VPN connections differ from standard VPN connections?", "answer": "For Accelerated Site-to-Site VPN connections, we select AWS Global Accelerator global internet protocol addresses (IPs) from independent network zones for the two tunnel endpoints, while standard VPN connections do not specify this.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-04T18:59:15.840012"}}
{"question": "Can you enable Site-to-Site VPN logs for both Transit Gateway and Virtual Gateway based VPN connections?", "answer": "Yes, you can enable Site-to-Site VPN logs for both Transit Gateway and Virtual Gateway based VPN connections.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T18:59:20.113545"}}
{"question": "What steps must an IT administrator take to set up a Client VPN endpoint for end users?", "answer": "The IT administrator must create a Client VPN endpoint, associate a target network to that endpoint, and set up the access policies to allow end user connectivity. After that, the administrator distributes the client VPN configuration file to the end users.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T18:59:20.113886"}}
{"question": "What is the difference in impact when enabling logging on one tunnel of a VPN connection versus the other tunnel?", "answer": "When you enable logging on one tunnel of a VPN connection, only the modified tunnel will be impacted, and your connectivity over that tunnel is interrupted for up to several minutes. The other tunnel remains unaffected, as each VPN connection offers two tunnels for high availability.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-04T18:59:20.114362"}}
{"question": "Can I modify an existing endpoint to enable split tunnel after it has been created with it disabled?", "answer": "Yes, if you've previously created an endpoint with split tunnel disabled, you may choose to modify it to enable split tunnel.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-04T18:59:25.231295"}}
{"question": "What happens to traffic when split tunnel is enabled versus when it is disabled in AWS Client VPN?", "answer": "If split tunnel is enabled, traffic destined for routes configured on the endpoint will be routed via the VPN tunnel, while all other traffic will be routed via your local network interface. Conversely, if split tunnel is disabled, all the traffic from the device will traverse through the VPN tunnel.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-04T18:59:25.231637"}}
{"question": "How does AWS Client VPN handle authentication differently when using Active Directory compared to using certificate-based authentication?", "answer": "AWS Client VPN supports authentication with Active Directory using AWS Directory Services, which allows integration with on-premises Active Directory. In contrast, certificate-based authentication requires the user to upload the client certificate and the root certificate used to issue it. Each method serves different authentication needs depending on whether integration with Active Directory is utilized or not.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-04T18:59:25.232061"}}
{"question": "How often are connection logs exported to CloudWatch logs from the Client VPN?", "answer": "Connection logs are exported to CloudWatch logs periodically at 15 minute intervals.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-04T18:59:29.429457"}}
{"question": "What are the requirements for installing the AWS Client VPN software client on Windows and Mac?", "answer": "You need admin access to install the app on both Windows and Mac. After the installation, admin access is not required.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-04T18:59:29.429794"}}
{"question": "How does the software client for AWS Client VPN support existing configurations compared to the AWS Client VPN service?", "answer": "The software client for AWS Client VPN is compatible with existing AWS Client VPN configurations and supports adding profiles using the OpenVPN configuration file generated by the AWS Client VPN service. The client connects to your endpoint based on your settings.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-04T18:59:29.430271"}}
{"question": "What authentication mechanisms are supported by the AWS Client VPN software client?", "answer": "The AWS Client VPN software client supports authentication with Active Directory using AWS Directory Services, Certificate-based authentication, and Federated Authentication using SAML-2.0.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-04T18:59:33.937098"}}
{"question": "Why is it not recommended to run multiple VPN clients on a device?", "answer": "It is not recommended to run multiple VPN clients on a device because this can cause conflicts or interfere with each other, potentially leading to unsuccessful connections.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-04T18:59:33.937455"}}
{"question": "How does the configurable Private Autonomous System Number (ASN) differ from the legacy public ASN for virtual gateways?", "answer": "The configurable Private Autonomous System Number (ASN) allows customers to set the ASN on the Amazon side of the BGP session for VPNs and AWS Direct Connect private VIFs, while the legacy public ASN of the region can only be assigned until June 30th, 2018, and after that date, Amazon will provide a specific ASN of 64512 for use.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-04T18:59:33.937914"}}
{"question": "What range of private ASNs can be chosen for Amazon's virtual gateway?", "answer": "You can choose any private ASN within the range of 16-bit private ASNs, which includes 64512 to 65534. Additionally, you can provide 32-bit ASNs between 4200000000 and 4294967294.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-04T18:59:39.063161"}}
{"question": "Why is Amazon limiting the ASNs to private ASNs for the virtual gateway?", "answer": "Amazon is limiting the ASN to private ASNs to protect customers from BGP spoofing, as they are not validating ownership of the ASNs.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-04T18:59:39.063501"}}
{"question": "What happens to the ASN provided by Amazon for the virtual gateway after June 30th, 2018, compared to before that date?", "answer": "Before June 30th, 2018, Amazon continues to provide the 'legacy public ASN' of the region. After June 30th, 2018, Amazon will provide an ASN of 64512 for the virtual gateway instead.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-04T18:59:39.064019"}}
{"question": "What ASN will Amazon assign to the Amazon side for the new VIF/VPN connection?", "answer": "Amazon will assign 7224 to the Amazon side ASN for the new VIF/VPN connection.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:59:43.474458"}}
{"question": "How does the Amazon side ASN for a new private VIF/VPN connection get determined?", "answer": "The Amazon side ASN for the new private VIF/VPN connection is inherited from your existing virtual gateway and defaults to that ASN.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:59:43.474786"}}
{"question": "What is the relationship between the Amazon side ASN for a virtual gateway and the Amazon side ASN for VIFs and VPN connections?", "answer": "The Amazon side ASN for VIFs and VPN connections is inherited from the Amazon side ASN of the attached virtual gateway. You can assign/configure separate Amazon side ASNs for each virtual gateway, but not for each VIF or VPN connection.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-04T18:59:43.475270"}}
{"question": "What is the valid ASN range that can be used for Customer Gateway configuration in AWS?", "answer": "The valid ASN range that can be used for Customer Gateway configuration in AWS is from 1 to 2147483647, with noted exceptions.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-04T18:59:49.509400"}}
{"question": "Why is the private ASN range of 4200000000 to 4294967294 not supported for Customer Gateway configuration?", "answer": "The context states that private ASN in the range of 4200000000 to 4294967294 is NOT currently supported for Customer Gateway configuration, but it does not provide a specific reason for this limitation.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-04T18:59:49.509754"}}
{"question": "How does the support for private ASN in AWS VPN Customer Gateway differ from the general ASN range?", "answer": "While the general ASN range that can be used is from 1 to 2147483647, private ASN in the range of 4200000000 to 4294967294 is specifically noted as NOT being supported for Customer Gateway configuration.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-04T18:59:49.510241"}}
{"question": "What is AWS WAF and what does it protect against?", "answer": "AWS WAF is a web application firewall that helps protect web applications from attacks by allowing you to configure rules that allow, block, or monitor web requests based on conditions that you define. These conditions include IP addresses, HTTP headers, HTTP body, URI strings, SQL injection, and cross-site scripting.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T18:59:56.075823"}}
{"question": "How does AWS WAF determine whether to block or allow a request?", "answer": "AWS WAF inspects requests against the rules that you have configured. Once a request meets a condition defined in your rules, AWS WAF instructs the underlying service to either block or allow the request based on the action you define.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T18:59:56.076168"}}
{"question": "How does the integration of AWS WAF with Amazon CloudFront differ from its integration with regional services like Application Load Balancer?", "answer": "When AWS WAF is used with Amazon CloudFront, the rules run in all AWS Edge Locations around the world, which means security is enforced without sacrificing performance, as blocked requests are stopped before reaching the web servers. In contrast, when AWS WAF is used with regional services like Application Load Balancer, Amazon API Gateway, and AWS AppSync, the rules run in the region and can be used to protect both internet-facing and internal resources.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-04T18:59:56.076613"}}
{"question": "What types of attacks does AWS WAF help protect against?", "answer": "AWS WAF helps protect your website from common attack techniques like SQL injection and Cross-Site Scripting (XSS).", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-04T19:00:01.655063"}}
{"question": "How does AWS WAF Bot Control enhance application security?", "answer": "AWS WAF Bot Control enhances application security by providing visibility and control over common and pervasive bot traffic. It allows you to monitor, block, or rate-limit bots such as scrapers, scanners, and crawlers, while permitting common bots like status monitors and search engines.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-04T19:00:01.655410"}}
{"question": "What is the relationship between AWS WAF and the Application Load Balancer?", "answer": "AWS WAF can be deployed on the Application Load Balancer (ALB) to protect the origin web servers running behind the ALBs. This integration allows AWS WAF to secure the traffic coming to the web servers managed by the ALB.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-04T19:00:01.655919"}}
{"question": "What is the cost associated with a Rate-based Rule in AWS WAF?", "answer": "A Rate-based Rule costs the same as a regular AWS WAF Rule, which is $1 per rule per WebACL per month.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-04T19:00:06.809484"}}
{"question": "What advantages does a Rate-based Rule offer compared to a regular Rule in AWS WAF?", "answer": "A Rate-based Rule offers the ability to configure a rate-based threshold, allowing you to specify the number of web requests that are allowed by a client IP in a trailing 5 minute period. If an IP address exceeds this limit, new requests will be blocked until the request rate falls below the configured threshold. This feature is not available in regular Rules.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-04T19:00:06.809817"}}
{"question": "How do Rate-based Rules differ from regular Rules in AWS WAF?", "answer": "Rate-based Rules differ from regular Rules in that they include the ability to configure a rate-based threshold, which allows for the blocking of IPs that exceed a specified number of requests in a 5 minute interval. Regular Rules do not have this capability and do not monitor request rates.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-04T19:00:06.810316"}}
{"question": "What is the purpose of Rate-based rules in AWS WAF?", "answer": "Rate-based rules in AWS WAF are designed to block or count an IP address when it exceeds a configured threshold rate, protect against web-layer DDoS attacks, brute force login attempts, and bad bots, and to manage IP addresses that are violating these thresholds.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-04T19:00:11.632349"}}
{"question": "How can Rate-based rules be refined to limit mitigations to specific traffic?", "answer": "Rate-based rules can be refined by using existing AWS WAF match conditions to limit rate-based mitigations to specific URLs, traffic from specific referrers or user agents, or by adding other custom match criteria.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-04T19:00:11.632693"}}
{"question": "How do Rate-based rules compare to regular AWS WAF Rules in terms of visibility features?", "answer": "Rate-based rules support all the visibility features currently available on regular AWS WAF Rules, and additionally, they provide visibility into the IP addresses that are blocked as a result of the Rate-based Rule.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-04T19:00:11.633211"}}
{"question": "What is the main benefit of the AWS WAF setup wizard?", "answer": "The main benefit of the AWS WAF setup wizard is that it simplifies protection deployment for all skill levels, reducing implementation time from hours to just 20 minutes while allowing users to activate preconfigured security defaults tailored to their workload type.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T19:00:16.920783"}}
{"question": "How do Managed Rules differ between AWS and third-party providers?", "answer": "AWS Managed Rules for AWS WAF are managed by AWS, whereas Managed Rules from AWS Marketplace are managed by third-party security sellers, providing users with options for rule management depending on their needs.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T19:00:16.921125"}}
{"question": "What happens to Managed Rules when they are disassociated from a web ACL?", "answer": "When a Managed Rule is disassociated from any web ACLs, it becomes disabled, meaning it will no longer provide protection until it is added back to a web ACL.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-04T19:00:16.921655"}}
{"question": "What does the 'count' action in AWS WAF allow you to do?", "answer": "The 'count' action in AWS WAF allows you to count the number of web requests that are matched by the rules inside the Managed Rule. This helps you estimate how many of your web requests would be blocked if you enable the Managed Rule.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-04T19:00:24.211813"}}
{"question": "How do protection packs differ from individual rules in AWS WAF?", "answer": "Protection packs are a combination of managed rules and custom rules designed to provide protection based on the application type and source of traffic. In contrast, individual rules are standalone rules that can be selected independently of protection packs.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-04T19:00:24.212179"}}
{"question": "What options do you have for viewing how your website is being protected by AWS WAF?", "answer": "You have two options for viewing how your website is being protected by AWS WAF: one-minute metrics available in CloudWatch, and Sampled Web Requests available through the AWS WAF API or management console. These options allow you to see which requests were blocked, allowed, or counted and the corresponding rule that was matched on each request.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-04T19:00:24.212687"}}
{"question": "What action can be configured for rules in AWS WAF to monitor web requests?", "answer": "In AWS WAF, you can configure a 'count' action for rules, which counts the number of web requests that meet your rule conditions.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-04T19:00:32.118707"}}
{"question": "What is the purpose of the Account Takeover Prevention (ATP) managed rule group in AWS WAF?", "answer": "The Account Takeover Prevention (ATP) managed rule group in AWS WAF monitors traffic to your applications login page to detect unauthorized access to user accounts using compromised credentials. It helps prevent credential stuffing attacks, brute force login attempts, and other anomalous login activities by checking in real-time whether the user names and passwords submitted have been compromised elsewhere on the web.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-04T19:00:32.119045"}}
{"question": "How does AWS WAF handle user credentials once they reach its system compared to how traffic is secured between user devices and the application?", "answer": "Once user credentials reach AWS WAF, it inspects the credential, immediately hashes and discards it, ensuring that the credential never leaves the AWS network. In contrast, traffic between user devices and the application is secured by the SSL/TLS protocol configured for the AWS service used to front the application, such as Amazon CloudFront or Application Load Balancer.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-04T19:00:32.119553"}}
{"question": "What is the purpose of Bot Control in AWS?", "answer": "Bot Control gives you visibility and control over common and pervasive bot traffic that can consume resources, skew metrics, cause downtime, and perform other undesired activities. It checks various header fields and request properties against known bot signatures to detect and categorize automated bots, such as scrapers, scanners, and crawlers.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-04T19:00:37.059771"}}
{"question": "How does Account Takeover Prevention (ATP) help protect applications?", "answer": "Account Takeover Prevention (ATP) helps protect applications by providing visibility and control over anomalous login attempts from bad actors using compromised credentials. This helps prevent unauthorized access that may lead to fraudulent activity, particularly by protecting the applications login page.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-04T19:00:37.060115"}}
{"question": "How do Bot Control and Account Takeover Prevention (ATP) work together?", "answer": "Bot Control and Account Takeover Prevention (ATP) can be used independently of each other or together. Both can utilize AWS WAF managed rule groups, and ATP can block matching requests using its default rule action, or customize its behavior with AWS WAF mitigation functionality.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-04T19:00:37.060544"}}
{"question": "What does the Account Creation Fraud prevention (ACFP) rule group do?", "answer": "The Account Creation Fraud prevention (ACFP) is a paid managed rule group that helps detect and mitigate fake account creation attacks against your sign-up or registration page. It prevents promotional or sign-up abuse, loyalty or rewards abuse, and phishing by verifying the credentials submitted, email domains used, and other information like phone numbers and address fields in real-time, blocking sign-up attempts if any information is considered stolen or has a bad reputation.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T19:00:45.517850"}}
{"question": "How does ACFP differ from Account Takeover Prevention (ATP)?", "answer": "ACFP and ATP target different aspects of account security; ACFP focuses on preventing automated fraud related to account creation, such as promotional or sign-up abuse and phishing, while ATP is aimed at preventing unauthorized access to existing accounts through account takeover attacks. ATP targets the sign-in page and is concerned with credential stuffing and brute force attacks, whereas ACFP targets the sign-up page.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T19:00:45.518137"}}
{"question": "Can ACFP and ATP be used together, and if so, how?", "answer": "Yes, ACFP and ATP can be used independently of each other or together. This means that you can implement both rule groups in your application to enhance security measures against different types of fraud and attacks, with ACFP focusing on account creation fraud and ATP addressing account takeover attempts.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-04T19:00:45.518700"}}
{"question": "What additional information does SDK integration provide for ACP rules?", "answer": "SDK integration provides additional information such as browser versions, plugins, and canvas data that increases the efficacy of ACP rules.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-04T19:00:51.254984"}}
{"question": "Why is SDK integration mandatory for Single Page Applications (SPA) and Native Mobile apps?", "answer": "SDK integration is mandatory for Single Page Applications (SPA) and Native Mobile apps because the Challenge action does not work well with these types of applications.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-04T19:00:51.255323"}}
{"question": "How does the logging of ACFP requests differ between the Fraud Dashboard and WAF Logging?", "answer": "The Fraud Dashboard provides a centralized view for monitoring requests analyzed by ACFP, while WAF Logging records all requests analyzed by ACFP in WAF logs, allowing users to query and analyze logs for the ACFP managed rule. Additionally, WAF logs include details such as rule actions, label information, and risk scoring, which can be used to track the efficacy of ACFP.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-04T19:00:51.255902"}}
{"question": "What is the primary function of AWS WAF application layer (L7) DDoS protection?", "answer": "The primary function of AWS WAF application layer (L7) DDoS protection is to automatically defend applications against distributed denial of service (DDoS) events within seconds. It monitors traffic data to establish a baseline and applies rules to block malicious requests when traffic exceeds the established baseline.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T19:00:58.137089"}}
{"question": "How does AWS WAF application layer (L7) DDoS protection establish a baseline for normal traffic?", "answer": "AWS WAF application layer (L7) DDoS protection establishes a baseline by monitoring traffic data within minutes of activation. It uses machine learning models to detect anomalies from the normal traffic patterns.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T19:00:58.137427"}}
{"question": "What are the differences between AWS WAF application layer (L7) DDoS protection and manual rule configuration?", "answer": "AWS WAF application layer (L7) DDoS protection provides automatic defense against DDoS events without the complexity of manually configuring and managing rules. In contrast, manual rule configuration requires users to set up and manage their own rules, which can be time-consuming and complex.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-04T19:00:58.137928"}}
{"question": "What happens once you enable the AWS Managed Rule group with your web ACL?", "answer": "Once you enable the AWS Managed Rule group with your web ACL, the anti-DDoS section will appear in the AWS WAF security dashboard, providing a comprehensive view into event detection and mitigation.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-04T19:01:06.368042"}}
{"question": "How does AWS WAF application layer (L7) DDoS protection customize its rules to meet application needs?", "answer": "AWS WAF application layer (L7) DDoS protection is customizable by configuring inspection for specific application URI paths or adjusting rule sensitivity settings. Sensitivity levels can be set to low, medium, or high, allowing users to adjust the default actions for each rule within a rule group to minimize traffic interference or heighten protection as needed.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-04T19:01:06.368395"}}
{"question": "How does AWS Shield Advanced interact with AWS WAF application layer (L7) DDoS protection?", "answer": "AWS Shield Advanced responds to DDoS events by creating, evaluating, and deploying custom AWS WAF rules for protected resources. With the AWS WAF application layer (L7) DDoS protection enabled, it works in conjunction with all AWS WAF rules to enhance protection against DDoS events.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-04T19:01:06.368909"}}
{"question": "What is the monthly limit for AWS Shield Advanced customers regarding AWS WAF requests?", "answer": "AWS Shield Advanced customers are limited to 50 billion AWS Shield protected AWS WAF requests in a calendar month.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-04T19:01:11.835164"}}
{"question": "How does AWS WAF application layer DDoS protection pricing differ from AWS Shield Advanced pricing?", "answer": "There are no upfront charges or minimum usage commitments for AWS WAF application layer (L7) DDoS protection, and it can be purchased standalone without requiring an AWS Shield Advanced subscription. In contrast, AWS Shield Advanced subscribers are required to pay fees and commit to a 12-month period.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-04T19:01:11.835526"}}
{"question": "What happens to AWS Shield Advanced customers if they exceed the 50 billion requests limit for AWS WAF in a month?", "answer": "If AWS Shield Advanced customers exceed the 50 billion AWS WAF requests limit in a calendar month, they will incur charges for each million requests above that limit.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-04T19:01:11.836029"}}
{"question": "What is the primary purpose of AWS Wavelength?", "answer": "The primary purpose of AWS Wavelength is to bring on-demand computing and storage services to communication service providers networks, enabling customers to build and deploy applications that meet their data residency, low-latency, and resiliency requirements.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-04T19:01:17.877459"}}
{"question": "How does AWS Wavelength enhance the performance of applications requiring low latency?", "answer": "AWS Wavelength enhances the performance of applications requiring low latency by embedding AWS compute and storage services within telco partners data centers, allowing customers to utilize local AWS infrastructure for quicker data processing and reducing the need to move large amounts of data to centralized locations.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-04T19:01:17.877781"}}
{"question": "In what ways can AWS Wavelength be combined with other AWS services, and what is the benefit of this combination?", "answer": "AWS Wavelength can be combined with other AWS hybrid and edge infrastructure services, such as AWS Outposts and AWS Local Zones. The benefit of this combination is to improve resiliency and availability posture, enabling customers to deliver low latency solutions and effectively manage edge data processing needs.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-04T19:01:17.877984"}}
{"question": "What technology does Wavelength Zones use to restrict access to customer data?", "answer": "Wavelength Zones use the AWS Nitro system to restrict access to customer data.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-04T19:01:23.548609"}}
{"question": "How does the AWS Nitro system enhance security for customer workloads on Amazon EC2?", "answer": "The AWS Nitro system provides a strong physical and logical security boundary and is designed to enforce restrictions so that nobody, including anyone in AWS, can access customer workloads on Amazon EC2.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-04T19:01:23.548953"}}
{"question": "In what ways do customers control their data's location with AWS compared to using Wavelength Zones?", "answer": "Customers have always controlled the location of their data with AWS, and with Wavelength Zones, they can now choose to store and process their data locally in these zones, enhancing their sovereignty over data location.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-04T19:01:23.549470"}}
{"question": "What are AWS Local Zones designed for?", "answer": "AWS Local Zones are designed to run workloads requiring low-latency in more locations, such as video rendering and graphics intensive, virtual desktop applications.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-04T19:01:28.665961"}}
{"question": "How do AWS Wavelength and AWS Outposts differ in terms of deployment location?", "answer": "AWS Wavelength embeds storage and compute inside telco providers networks for low-latency applications, while AWS Outposts is designed for workloads that must remain on-premises but want to connect seamlessly to AWS services.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-04T19:01:28.666299"}}
{"question": "What types of applications can benefit from using AWS Wavelength?", "answer": "Applications that can benefit from using AWS Wavelength include IoT devices, game streaming, autonomous vehicles, and live media production, all of which require low-latency processing.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-04T19:01:28.666881"}}
{"question": "What are Wavelength Zones in AWS?", "answer": "Wavelength Zones are extensions of an AWS Region that allow you to use the same AWS tools and capabilities while minimizing the need to re-architect your application to reduce latency.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T19:01:35.616159"}}
{"question": "How do Wavelength Zones benefit existing applications?", "answer": "Wavelength Zones benefit existing applications by allowing users to continue using their current AWS tools and capabilities without significant re-architecting to reduce latency.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T19:01:35.616499"}}
{"question": "What services can be used in Wavelength Zones compared to those available in the main AWS Region?", "answer": "In Wavelength Zones, you can create Amazon EC2 instances, Amazon EBS volumes, and Amazon VPC subnets, and use services that work with these such as Amazon EC2 Auto Scaling and Amazon EKS clusters. However, certain services available in the main AWS Region may not be available in Wavelength Zones, and there are third-party products that can replace some of these services, such as alternatives to Amazon S3 and Amazon RDS.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-04T19:01:35.616934"}}
{"question": "What instance types does Wavelength support for edge workloads?", "answer": "Wavelength supports the following instance types for edge workloads: t3.medium, t3.xlarge, and r5.2xlarge for cost-effective general purpose compute, and g4dn.2xlarge for applications requiring GPUs, such as game streaming and ML inference at the edge.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-04T19:01:40.303989"}}
{"question": "How can customers enhance the resiliency of their workloads when using AWS Wavelength?", "answer": "Customers can enhance the resiliency of their workloads by combining AWS Wavelength with other AWS infrastructure like AWS Outposts, AWS Local Zones, or non-AWS on-premises deployments.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-04T19:01:40.304300"}}
{"question": "How does the availability of Reserved Instances differ between Wavelength Zones and standard EC2 regions?", "answer": "In Wavelength Zones, EC2 Instances are only offered On-Demand; you cannot buy Reserved Instances, whereas standard EC2 regions allow for the purchase of both On-Demand and Reserved Instances.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-04T19:01:40.304788"}}
{"question": "What are the six pillars of the AWS Well-Architected Framework?", "answer": "The six pillars of the AWS Well-Architected Framework are operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability.", "question_type": "factual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T19:01:45.056647"}}
{"question": "How does the AWS Well-Architected Tool assist users in reviewing their workloads?", "answer": "The AWS Well-Architected Tool lets users review their workloads against current AWS best practices and obtain advice on how to architect their workloads for the cloud. It delivers a list of potential issues found in workloads and provides step-by-step guidance to make improvements.", "question_type": "conceptual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T19:01:45.057057"}}
{"question": "What is the difference between AWS-provided lenses and custom lenses in the AWS Well-Architected Tool?", "answer": "AWS-provided lenses are predefined frameworks that users can review their workloads against, while custom lenses allow users to review their workloads using customized questions, which can include specific pillars, questions, answer choices, helpful resources, and improvement plans tailored to their needs.", "question_type": "comparison", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-04T19:01:45.057457"}}
{"question": "How can I access the AWS Well-Architected Tool?", "answer": "You can access the AWS Well-Architected Tool by signing in to the AWS Management Console with your AWS account.", "question_type": "factual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-04T19:01:49.905825"}}
{"question": "What is the purpose of the AWS Well-Architected Tool?", "answer": "The purpose of the AWS Well-Architected Tool is to allow you to define the workload for which you want to perform a Well-Architected review, answer questions across each of the architectural pillars, and then receive an improvement plan with a prioritized list of issues for the workload based on your responses.", "question_type": "conceptual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-04T19:01:49.906189"}}
{"question": "What are the costs associated with using the AWS Well-Architected Tool compared to using AWS resources?", "answer": "There is no additional charge for the AWS Well-Architected Tool; you only pay for your underlying AWS resources.", "question_type": "comparison", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-04T19:01:49.906698"}}
{"question": "What is AWS X-Ray primarily used for?", "answer": "AWS X-Ray is primarily used to help developers analyze and debug production, distributed applications, such as those built using a microservices architecture. It allows developers to understand how their application and its underlying services are performing, identify and troubleshoot the root cause of performance issues and errors.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T19:01:57.112910"}}
{"question": "How does AWS X-Ray differ from a service-centric or resource-centric model?", "answer": "AWS X-Ray provides a user-centric model for collecting data related to requests made to your application, unlike the service-centric or resource-centric models. This user-centric approach enables developers to create a picture of requests as they travel across services and resources, facilitating a better understanding of the user's experience.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T19:01:57.113189"}}
{"question": "What challenges do developers face when tracking requests in distributed applications, and how does AWS X-Ray address these challenges?", "answer": "Developers face challenges when tracking requests across various components of distributed applications due to the reliance on a per-service or per-resource process, as well as the varying log formats and storage mediums. This complexity makes it difficult to correlate data and create an end-to-end picture of requests. AWS X-Ray addresses these challenges by providing a user-centric model that correlates and aggregates data, allowing developers to focus on improving the end-user experience.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-04T19:01:57.113362"}}
{"question": "What does X-Ray do to help create a service map?", "answer": "X-Ray tracks requests made to your applications to create a map of services used by your application. This provides a view of connections among services, enables the creation of a dependency tree, detects latency or errors across AWS Availability Zones or Regions, and helps identify services that are not operating as expected.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-04T19:02:04.597261"}}
{"question": "How does X-Ray assist in identifying errors and bugs in application code?", "answer": "X-Ray automatically highlights bugs or errors in application code by analyzing the response code for each request made to the application. This feature allows for easy debugging of application code without the need to reproduce the bug or error.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-04T19:02:04.597601"}}
{"question": "How does an X-Ray trace differ from an X-Ray segment?", "answer": "An X-Ray trace is a set of data points that share the same trace ID and is created when a client makes a request to the application. In contrast, an X-Ray segment encapsulates all the data points for a single component of the distributed application and includes system-defined and user-defined data, such as annotations. A trace consists of a collection of segments that relay information about the request as it travels through the services.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-04T19:02:04.598125"}}
{"question": "What is an X-Ray annotation?", "answer": "An X-Ray annotation is system-defined or user-defined data associated with a segment. A segment can contain multiple annotations, where system-defined annotations include data added by AWS services, and user-defined annotations are metadata added by a developer.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T19:02:10.556509"}}
{"question": "Why should X-Ray not be used as an audit or compliance tool?", "answer": "X-Ray should not be used as an audit or compliance tool because it does not guarantee data completeness, as it collects data for a statistically significant number of requests rather than for every request sent to an application.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T19:02:10.556854"}}
{"question": "How does the data collection method of X-Ray differ from traditional logging systems?", "answer": "Unlike traditional logging systems that may record every request, X-Ray collects data for a statistically significant number of requests, which makes it more performant and cost-effective, but means it does not guarantee complete data capture.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-2", "source_tokens": 469, "generated_at": "2026-02-04T19:02:10.557410"}}
{"question": "What do you need to include in your application code when using Elastic Beanstalk with X-Ray?", "answer": "When using Elastic Beanstalk with X-Ray, you need to include the language-specific X-Ray libraries in your application code.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-04T19:02:17.641692"}}
{"question": "How does X-Ray support applications running across multiple AWS regions?", "answer": "X-Ray supports applications running across multiple AWS regions by allowing you to track requests flowing through applications or services in different regions. While X-Ray data is stored locally to the processed region, it includes enough information for client applications to combine the data and provide a global view of traces. Region annotations for AWS services are added automatically, but customers must instrument custom services to add regional annotations for cross-region support.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-04T19:02:17.642034"}}
{"question": "What is the difference in logging API calls and trace calls in X-Ray?", "answer": "X-Ray logs all API calls as management events and logs calls on traces as data events. However, data events, which include calls on PutTraceSegments and GetTimeSeriesServiceStatistics, are not logged by default. To log data events, you must configure your CloudTrail trail or event data store to collect them.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-04T19:02:17.642542"}}
