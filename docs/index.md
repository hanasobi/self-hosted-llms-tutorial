

> **Das erste deutschsprachige Tutorial, das zeigt wie Self-Hosted LLMs WIRKLICH funktionieren: Von der ersten Installation Ã¼ber Fine-tuning bis zur vollstÃ¤ndigen DatensouverÃ¤nitÃ¤t â€” mit allen Debugging-Stories und Trade-offs.**

<div style="background: #f6f8fa; padding: 20px; border-radius: 6px; margin: 20px 0;">
  <strong>ğŸ“– Status:</strong> Tutorial-Serie in aktiver Entwicklung<br>
  <strong>ğŸ¯ Zielgruppe:</strong> ML Engineers, Data Scientists, Tech Leads im DACH-Raum<br>
  <strong>â­ GitHub:</strong> <a href="https://github.com/hanasobi/self-hosted-llms-tutorial">self-hosted-llms-tutorial</a>
</div>

---

## Warum diese Tutorial-Serie?

Unternehmen im DACH-Raum stehen vor einem Dilemma: Sie wollen generative KI nutzen, aber sensible Daten dÃ¼rfen nicht an externe APIs flieÃŸen â€” sei es aus DSGVO-GrÃ¼nden, Branchenregulierung oder zum Schutz von Betriebsgeheimnissen.

Diese Tutorial-Serie zeigt den vollstÃ¤ndigen Weg von der ersten LLM-Installation bis zur **kompletten DatensouverÃ¤nitÃ¤t** â€” ohne externe AbhÃ¤ngigkeiten. Jeder Post hat ein klares, erreichbares Ziel, und wir dokumentieren echte Probleme und Debugging-Journeys statt nur den "Happy Path".

<table>
  <tr>
    <th>Andere Tutorials</th>
    <th>Diese Serie</th>
  </tr>
  <tr>
    <td>âŒ "Deploy this YAML, done"</td>
    <td>âœ… Schrittweiser Aufbau mit ErklÃ¤rungen</td>
  </tr>
  <tr>
    <td>âŒ Copy-Paste ohne Kontext</td>
    <td>âœ… Design-Entscheidungen & Trade-offs</td>
  </tr>
  <tr>
    <td>âŒ Nur der Happy Path</td>
    <td>âœ… Echte Debugging-Stories (20h EOS Token Journey)</td>
  </tr>
  <tr>
    <td>âŒ Cloud/API-abhÃ¤ngig</td>
    <td>âœ… VollstÃ¤ndige DatensouverÃ¤nitÃ¤t als Ziel</td>
  </tr>
</table>

---

## Der Weg zur DatensouverÃ¤nitÃ¤t

Die Serie folgt einem klaren didaktischen Bogen â€” vom ersten funktionierenden LLM bis zur vollstÃ¤ndigen UnabhÃ¤ngigkeit von externen Anbietern.

### Phase 1: Self-Hosting Basics

> *"Kann ich ein LLM Ã¼berhaupt selbst betreiben?"*

**Post 1: [Warum Self-Hosting? Der Business Case fÃ¼r DatensouverÃ¤nitÃ¤t](posts/01-warum-self-hosting.html)**
Das Problem, die LÃ¶sung und wann Self-Hosting sinnvoll ist. Entscheidungsmatrix: Cloud-API vs. Self-Hosted.

**Post 2: [vLLM auf Kubernetes â€” Dein erstes selbst gehostetes LLM](posts/02-vllm-kubernetes-basics.html)**
Mistral-7B auf Kubernetes deployen mit vLLM. Nach diesem Post lÃ¤uft ein LLM auf deiner Infrastruktur.

### Phase 2: Anpassung durch Fine-tuning

> *"Wie mache ich es besser fÃ¼r meinen Use Case?"*

**Post 3: Warum Fine-tuning? Wenn RAG und Prompting nicht reichen**
Prompting vs. RAG vs. Fine-tuning â€” wann welcher Ansatz passt und warum wir Fine-tuning brauchen.

**Post 4: Dataset Engineering â€” Von Dokumenten zu Trainingsdaten**
Die Pipeline von Rohdokumenten zu QA-Paaren: Chunking, Synthetic Data Generation, Quality Control. *80% der eigentlichen Arbeit.*

**Post 5: LoRA Training â€” 7B Model auf 16GB GPU**
QLoRA macht groÃŸe Modelle auf Consumer-Hardware trainierbar. Mit MLflow Experiment Tracking.

**Post 5.5: Training Infrastructure â€” HuggingFace Trainer + MLflow**
Von manuellen Training-Loops zu Production-ready Infrastructure mit Custom Callbacks.

**Post 6: Der pad_token Bug â€” Eine Debugging-Geschichte â­**
20 Stunden Debugging dokumentiert: Warum `pad_token = eos_token` alles kaputt macht und wie systematisches Debugging funktioniert.

### Phase 3: Production & SouverÃ¤nitÃ¤t

> *"Wie bringe ich es in Produktion â€” ohne externe AbhÃ¤ngigkeiten?"*

**Post 7: LoRA Serving â€” Fine-tuned Models in Produktion**
LoRA-Adapter auf dem Base Model laden, Multi-LoRA Serving und Performance-Vergleiche.

**Post 8: Evaluation ohne externe APIs â€” LLM-as-Judge Self-Hosted**
QualitÃ¤t messen ohne OpenAI oder Anthropic. Self-hosted LLM-as-Judge mit Rubrics und Consistency Checks.

**Post 9: Dataset-Generierung ohne OpenAI**
Die letzte externe AbhÃ¤ngigkeit eliminieren. Nach diesem Post ist die gesamte Pipeline self-hosted: Dokumente â†’ QA-Paare â†’ Training â†’ Serving â†’ Evaluation.

### Phase 4: Skalierung & Automation

> *"Wie skaliere ich das Ganze?"*

**Post 10: Multi-LoRA in der Praxis â€” Ein Server, viele Use Cases**
Architektur fÃ¼r Multi-Tenant-Setups, Request Routing und Kostenoptimierung.

**Post 11+: Production Pipelines**
Argo Workflows, CI/CD fÃ¼r Model Updates, kontinuierliches Fine-tuning.

---

## DatensouverÃ¤nitÃ¤t als roter Faden

<div style="background: #e8f5e9; padding: 20px; border-left: 4px solid #4caf50; margin: 20px 0;">

<strong>ğŸ”’ Von pragmatisch zu souverÃ¤n</strong><br><br>

Die Serie geht ehrlich mit externen AbhÃ¤ngigkeiten um. In <strong>Post 4</strong> nutzen wir GPT-4o-mini fÃ¼r die Dataset-Generierung â€” ein bewusster Kompromiss, der transparent gemacht wird. In <strong>Post 9</strong> zeigen wir dann die self-hosted Alternative.<br><br>

<strong>Nach Post 9 ist die gesamte Pipeline datensouverÃ¤n:</strong> Kein API-Call verlÃ¤sst deine Infrastruktur â€” weder fÃ¼r Training, Serving, Evaluation noch fÃ¼r Dataset-Generierung.

</div>

---

## FÃ¼r wen ist diese Serie?

Diese Tutorial-Serie richtet sich an technische FachkrÃ¤fte und Entscheider, die Self-Hosted LLMs evaluieren oder implementieren wollen:

- **ML Engineers & Data Scientists**, die den Schritt von Notebooks zu Production-Deployments machen wollen
- **Tech Leads & Architekten**, die einen Self-Hosted AI-Stack evaluieren und Trade-offs verstehen mÃ¼ssen
- **Technische Entscheider (CTO, Head of Data)**, die Machbarkeit und Aufwand fÃ¼r DatensouverÃ¤nitÃ¤t einschÃ¤tzen wollen
- **Implementierungspartner (Freelancer, Agenturen)**, die eine Referenzimplementierung fÃ¼r Kundenprojekte suchen

---

## Projekt-Struktur

```
self-hosted-llms-tutorial/
â”œâ”€â”€ docs/                  Blog Posts (Deutsch)
â”‚   â”œâ”€â”€ index.md           Serien-Ãœbersicht (diese Seite)
â”‚   â””â”€â”€ posts/             Einzelne Blog Posts
â”œâ”€â”€ serving/               vLLM Deployment (Posts 2, 7)
â”œâ”€â”€ data/                  Dataset Engineering (Post 4)
â”œâ”€â”€ training/              LoRA Training (Posts 5, 6)
â”œâ”€â”€ evaluation/            Evaluation Framework (Post 8)
â””â”€â”€ monitoring/            Prometheus + Grafana
```

**Sprache:** Blog Posts auf Deutsch, Code und technische Dokumentation auf Englisch.

---

## Mitmachen & Folgen

- **GitHub Repository:** [self-hosted-llms-tutorial](https://github.com/hanasobi/self-hosted-llms-tutorial)
- **Autor:** [@hanasobi](https://github.com/hanasobi)
- **Gestartet:** Januar 2026

<div style="background: #fffbdd; padding: 15px; border-left: 4px solid #f9c513; margin: 20px 0;">
  <strong>âš ï¸ Hinweis:</strong> Dieses Projekt ist in aktiver Entwicklung. Posts und Code werden regelmÃ¤ÃŸig ergÃ¤nzt. Star das Repo, um auf dem Laufenden zu bleiben!
</div>

---

## Lizenz

- **Code:** MIT License â€” frei nutzbar, modifizierbar und verteilbar
- **Blog Content:** CC BY 4.0 â€” mit Namensnennung