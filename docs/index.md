

> **Ein deutschsprachiges Tutorial, das Schritt fÃ¼r Schritt zeigt, wie Unternehmen mit Self-Hosted LLMs ihre DatensouverÃ¤nitÃ¤t bewahren: Von der Installation Ã¼ber 
Fine-tuning bis zur vollstÃ¤ndigen UnabhÃ¤ngigkeit â€“ inklusive echter Debugging-Stories und transparenten Trade-offs.**

<div style="background: #f6f8fa; padding: 20px; border-radius: 6px; margin: 20px 0;">
  <strong>ğŸ“– Status:</strong> Tutorial-Serie in aktiver Entwicklung<br>
  <strong>ğŸ¯ Zielgruppe:</strong> ML Engineers, Data Scientists, Tech Leads im DACH-Raum<br>
  <strong>â­ GitHub:</strong> <a href="https://github.com/hanasobi/self-hosted-llms-tutorial">self-hosted-llms-tutorial</a>
</div>

---

## Warum diese Tutorial-Serie?

Unternehmen im DACH-Raum stehen vor einem Dilemma: Sie wollen generative KI nutzen, aber sensible Daten dÃ¼rfen nicht an externe APIs flieÃŸen â€” sei es aus DSGVO-GrÃ¼nden, Branchenregulierung oder zum Schutz von Betriebsgeheimnissen.

Diese Tutorial-Serie zeigt den vollstÃ¤ndigen Weg von der ersten LLM-Installation bis zur **kompletten DatensouverÃ¤nitÃ¤t** â€” ohne externe AbhÃ¤ngigkeiten. Jeder Post hat ein klares, erreichbares Ziel, und wir dokumentieren echte Probleme und Debugging-Journeys statt nur den "Happy Path".

## Was diese Serie auszeichnet

**Schrittweiser Aufbau statt FertiglÃ¶sungen**  
Jeder Schritt wird erklÃ¤rt und begrÃ¼ndet. Statt YAML-Dateien zum Copy-Paste erhÃ¤ltst du das VerstÃ¤ndnis, um eigene Entscheidungen zu treffen.

**Design-Entscheidungen transparent gemacht**  
Wir zeigen nicht nur *wie*, sondern auch *warum*. Jede Architektur-Entscheidung wird mit ihren Trade-offs erklÃ¤rt.

**Debugging-Journeys inklusive**  
Echte Probleme und ihre LÃ¶sungen â€“ wie die 20-stÃ¼ndige EOS-Token-Debugging-Story. Hier lernst du, was Tutorials normalerweise auslassen.

**VollstÃ¤ndige DatensouverÃ¤nitÃ¤t als Ziel**  
Der komplette Weg zur UnabhÃ¤ngigkeit von externen APIs â€“ von der ersten Installation bis zur selbst gehosteten Dataset-Generierung.

---

## Der Weg zur DatensouverÃ¤nitÃ¤t

Die Serie folgt einem klaren didaktischen Bogen â€” vom ersten funktionierenden LLM bis zur vollstÃ¤ndigen UnabhÃ¤ngigkeit von externen Anbietern.

### Phase 1: Self-Hosting Basics

> *"Kann ich ein LLM Ã¼berhaupt selbst betreiben?"*

**Post 1: [Warum Self-Hosting? Der Business Case fÃ¼r DatensouverÃ¤nitÃ¤t](posts/01-warum-self-hosting.html)**
Das Problem, die LÃ¶sung und wann Self-Hosting sinnvoll ist. Entscheidungsmatrix: Cloud-API vs. Self-Hosted.

**Post 2: [vLLM auf Kubernetes â€” Dein erstes selbst gehostetes LLM](posts/02-vllm-kubernetes-basics.html)**
Mistral-7B auf Kubernetes deployen mit vLLM. Nach diesem Post lÃ¤uft ein LLM auf deiner Infrastruktur.

### Phase 2: Anpassung durch Fine-tuning

> *"Wie mache ich es besser fÃ¼r meinen Use Case?"*

**Post 3: [Warum Fine-tuning? Wenn RAG und Prompting nicht reichen](posts/03-warum-finetuning.html)**
Prompting vs. RAG vs. Fine-tuning â€” wann welcher Ansatz passt und warum wir Fine-tuning brauchen.

**Post 4: [Dataset Engineering â€” Von Dokumenten zu Trainingsdaten](posts/04-dataset-engineering.html)**
Die Pipeline von Rohdokumenten zu QA-Paaren: Chunking, Synthetic Data Generation, Quality Control. *80% der eigentlichen Arbeit.*

**Post 5: [LoRA Training â€” 7B Model auf 24GB GPU](posts/05-lora-training.html)**
QLoRA macht groÃŸe Modelle auf Consumer-Hardware trainierbar. Mit MLflow Experiment Tracking.

**Post 5.1: [Experiment Tracking mit MLflow (Optional)](posts/05.1-mlflow-tracking.html)**
Self-hosted MLflow fÃ¼r DatensouverÃ¤nitÃ¤t. Custom Callbacks fÃ¼r HuggingFace Trainer. Parameters & Metrics loggen â€“ ohne externe Cloud-Dienste.

**Post 5.2: [Model Evaluation (Optional)](posts/05.2-model-evaluation.html)**
Qualitative Evaluation durch Manual Inspection & stratifiziertes Sampling. Baseline Comparison mit Mistral-Instruct. Multi-modale Bewertung.

**Post 5.3: Der pad_token Bug â€“ Eine Debugging-Geschichte (Optional)**
20 Stunden Debugging dokumentiert: Warum `pad_token = eos_token` alles kaputt macht und wie systematisches Debugging funktioniert.

### Phase 3: Production & SouverÃ¤nitÃ¤t

> *"Wie bringe ich es in Produktion â€” ohne externe AbhÃ¤ngigkeiten?"*

**Post 6: vLLM Deployment mit LoRA â€“ Fine-tuned Models in Produktion**
LoRA-Adapter auf dem Base Model laden mit vLLM. Multi-Adapter Serving. Performance-Vergleiche.

**Post 7: Evaluation ohne externe APIs â€” LLM-as-Judge Self-Hosted**
QualitÃ¤t messen ohne OpenAI oder Anthropic. Self-hosted LLM-as-Judge mit Rubrics und Consistency Checks.

**Post 8: Dataset-Generierung ohne OpenAI**
Die letzte externe AbhÃ¤ngigkeit eliminieren. Nach diesem Post ist die gesamte Pipeline self-hosted: Dokumente â†’ QA-Paare â†’ Training â†’ Serving â†’ Evaluation.

### Phase 4: Skalierung & Automation

> *"Wie skaliere ich das Ganze?"*

**Post 9: Multi-LoRA in der Praxis â€” Ein Server, viele Use Cases**
Architektur fÃ¼r Multi-Tenant-Setups, Request Routing und Kostenoptimierung.

**Post 10+: Production Pipelines**
Argo Workflows, CI/CD fÃ¼r Model Updates, kontinuierliches Fine-tuning.

---

## DatensouverÃ¤nitÃ¤t als roter Faden

<div style="background: #e8f5e9; padding: 20px; border-left: 4px solid #4caf50; margin: 20px 0;">

<strong>ğŸ”’ Von pragmatisch zu souverÃ¤n</strong><br><br>

Die Serie geht ehrlich mit externen AbhÃ¤ngigkeiten um. In <strong>Post 4</strong> nutzen wir GPT-4o-mini fÃ¼r die Dataset-Generierung â€” ein bewusster Kompromiss, der transparent gemacht wird. In <strong>Post 9</strong> zeigen wir dann die self-hosted Alternative.<br><br>

<strong>Nach Post 8 ist die gesamte Pipeline datensouverÃ¤n:</strong> Kein API-Call verlÃ¤sst deine Infrastruktur â€” weder fÃ¼r Training, Serving, Evaluation noch fÃ¼r Dataset-Generierung.

</div>

---

## FÃ¼r wen ist diese Serie?

Diese Tutorial-Serie richtet sich an technische FachkrÃ¤fte und Entscheider, die Self-Hosted LLMs evaluieren oder implementieren wollen:

- **ML Engineers & Data Scientists**, die den Schritt von Notebooks zu Production-Deployments machen wollen
- **Tech Leads & Architekten**, die einen Self-Hosted AI-Stack evaluieren und Trade-offs verstehen mÃ¼ssen
- **Technische Entscheider (CTO, Head of Data)**, die Machbarkeit und Aufwand fÃ¼r DatensouverÃ¤nitÃ¤t einschÃ¤tzen wollen
- **Implementierungspartner (Freelancer, Agenturen)**, die eine Referenzimplementierung fÃ¼r Kundenprojekte suchen

---

## Projekt-Struktur

```
self-hosted-llms-tutorial/
â”œâ”€â”€ docs/                  Blog Posts (Deutsch)
â”‚   â”œâ”€â”€ index.md           Serien-Ãœbersicht (diese Seite)
â”‚   â””â”€â”€ posts/             Einzelne Blog Posts
â”œâ”€â”€ serving/               vLLM Deployment (Posts 2, 6)
â”œâ”€â”€ data/                  Dataset Engineering (Post 4)
â”œâ”€â”€ 05-lora-training/      LoRA Training & Evaluation (Posts 5, 5.1, 5.2, 5.3)
â”œâ”€â”€ 05.1-mlflow-tracking/  LoRA Training & Evaluation (Posts 5, 5.1, 5.2, 5.3)
â”œâ”€â”€ 05.2-model-evaluation/ LoRA Training & Evaluation (Posts 5, 5.1, 5.2, 5.3)
â”œâ”€â”€ 05.3-debugging-story/  LoRA Training & Evaluation (Posts 5, 5.1, 5.2, 5.3)
â””â”€â”€ .../                   Weitere Posts
```

**Sprache:** Blog Posts auf Deutsch, Code und technische Dokumentation auf Englisch.

---

## Mitmachen & Folgen

- **GitHub Repository:** [self-hosted-llms-tutorial](https://github.com/hanasobi/self-hosted-llms-tutorial)
- **Autor:** [@hanasobi](https://github.com/hanasobi)
- **Gestartet:** Januar 2026

<div style="background: #fffbdd; padding: 15px; border-left: 4px solid #f9c513; margin: 20px 0;">
  <strong>âš ï¸ Hinweis:</strong> Dieses Projekt ist in aktiver Entwicklung. Posts und Code werden regelmÃ¤ÃŸig ergÃ¤nzt. Star das Repo, um auf dem Laufenden zu bleiben!
</div>

---

## Lizenz

- **Code:** MIT License â€” frei nutzbar, modifizierbar und verteilbar
- **Blog Content:** CC BY 4.0 â€” mit Namensnennung