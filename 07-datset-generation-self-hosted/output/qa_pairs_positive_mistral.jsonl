{"question": "What standards does Amazon MQ support for creating a new message broker?", "answer": "Amazon MQ supports creating a new message broker using industry standard APIs and protocols for messaging, including JMS, NMS, AMQP 0.9.1, AMQP 1.0, STOMP, MQTTv3, and WebSocket.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T14:14:36.833341"}}
{"question": "How does Amazon MQ simplify managing message brokers in the cloud?", "answer": "Amazon MQ simplifies managing message brokers in the cloud by handling the process of setting up a message broker and provisioning infrastructure, as well as managing ongoing software upgrades, security updates, fault detection, and recovery.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T14:14:36.833664"}}
{"question": "What are the main differences between Amazon MQ's support for Apache ActiveMQ and RabbitMQ?", "answer": "Amazon MQ supports both Apache ActiveMQ and RabbitMQ, allowing users to directly access the consoles, industry standard APIs and protocols, and migrate existing message brokers without rewriting messaging code.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T14:14:36.833819"}}
{"question": "What are the administration tasks that Amazon MQ takes care of?", "answer": "Amazon MQ handles tasks such as broker provisioning, security patching, setup, configuration, broker version upgrades, and recovery.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:14:41.429911"}}
{"question": "Why should you consider using Amazon MQ instead of self-managed message brokers?", "answer": "Amazon MQ is an easier and cost-effective option when you want to offload operational overhead and associated costs. It doesn't charge for inter-node data transfer for RabbitMQ brokers, and it makes it simple to set up and operate message brokers in the cloud.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:14:41.430255"}}
{"question": "Which messaging APIs and protocols does Amazon MQ support?", "answer": "Amazon MQ supports various messaging APIs, such as Java Message Service (JMS) and .NET Message Service (NMS), and protocols, including AMQP, STOMP, MQTT, and WebSocket.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:14:41.430440"}}
{"question": "What version of ActiveMQ is used when creating a new broker in the AWS Management Console by default?", "answer": "Amazon MQ provides the latest version available by default when creating a new broker via the AWS Management Console.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T14:14:45.597368"}}
{"question": "Why would you choose to use durability optimized brokers in Amazon MQ?", "answer": "You would choose to use durability optimized brokers in Amazon MQ if you want to take advantage of high durability and replication across multiple Availability Zones.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T14:14:45.597700"}}
{"question": "How does the version support and upgrade process work for Amazon MQ brokers using throughput optimized storage?", "answer": "Amazon MQ will upgrade throughput optimized brokers to the next supported version when the current version reaches end of support. The upgrade process is not automatic and requires manual action by the user.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T14:14:45.597888"}}
{"question": "What version of RabbitMQ does Amazon MQ support by default?", "answer": "Amazon MQ supports RabbitMQ version 3.13 by default.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T14:14:50.915152"}}
{"question": "How does Amazon MQ's network of brokers ensure high availability?", "answer": "Amazon MQ's network of brokers ensures high availability by allowing messages to be stored by a single broker at any given time and having brokers share information about clients and destinations to route messages through the network. In case of broker failure, active-standby brokers have a standby node that can take over, and each broker maintains its own unique message store replicated across multiple availability zones.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T14:14:50.915535"}}
{"question": "How does the support for RabbitMQ versions differ between Amazon MQ and RabbitMQ?", "answer": "Amazon MQ continually adds support for new RabbitMQ versions, but the number of new versions supported will vary based on the frequency and content of releases by the open-source maintainers. RabbitMQ, on the other hand, is an open source message broker that users can manage themselves, allowing them to choose which version to use.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T14:14:50.915998"}}
{"question": "Which RabbitMQ versions are supported by Amazon MQ and when do they reach end of support?", "answer": "Amazon MQ supports RabbitMQ versions up to the end of support date indicated in the RabbitMQ version support calendar. Amazon MQ provides at least 90 days of notice before a version reaches end of support.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T14:14:57.226079"}}
{"question": "How does Amazon MQ handle upgrading RabbitMQ brokers to the next supported version?", "answer": "When a RabbitMQ broker version reaches end of support, Amazon MQ will upgrade all brokers on that version to the next supported version. Users can also manually upgrade their broker at any time to the next major or minor version. From RabbitMQ version 3.13 onwards, Amazon MQ manages the patch version for users and ensures all brokers are on the latest patch version of the minor version.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T14:14:57.226581"}}
{"question": "What are the differences between using Amazon MQ with AWS Lambda versus Amazon EC2?", "answer": "Both AWS Lambda and Amazon EC2 can use Amazon MQ. The main difference is that with Amazon EC2, you have full control over the infrastructure, while with AWS Lambda, you don't manage the underlying infrastructure. However, in both cases, Amazon MQ is integrated with the same AWS services, such as Amazon CloudWatch, AWS CloudFormation, and AWS Identity and Access Management (IAM).", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T14:14:57.226987"}}
{"question": "What are the different types of Amazon MQ cluster deployments for RabbitMQ?", "answer": "Amazon MQ offers three-node cluster deployments for RabbitMQ.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T14:15:01.434408"}}
{"question": "How does custom configuration work in Amazon MQ?", "answer": "Amazon MQ allows users to create and apply custom configurations to new and existing clusters.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T14:15:01.434711"}}
{"question": "How does encryption of data at rest in Amazon MQ differ between the provided and user-managed AWS KMS keys?", "answer": "When creating a broker, users can choose to use a KMS key in the Amazon MQ service account, a KMS key that Amazon MQ creates and manages, or a KMS key in the user's account. This choice affects who manages the encryption key for the encrypted data at rest in Amazon MQ.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T14:15:01.434870"}}
{"question": "What are the charges for Amazon MQ besides the broker instance and storage usage?", "answer": "Standard data transfer fees also apply to Amazon MQ.", "question_type": "factual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-11T14:15:04.836335"}}
{"question": "How does the AWS Free Tier program apply to Amazon MQ?", "answer": "New AWS customers can receive up to $200 in Free Tier credits that can be applied towards Amazon MQ, which is available for 6 months after account creation.", "question_type": "conceptual", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-11T14:15:04.836598"}}
{"question": "How does the pricing of Amazon MQ for inter-node data transfer compare to other AWS services?", "answer": "Inter-node data transfer is included with the service at no additional charge.", "question_type": "comparison", "metadata": {"service": "AMAZON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amazon-faq-6", "source_tokens": 345, "generated_at": "2026-02-11T14:15:04.836762"}}
{"question": "What are the tools and features included in AWS Amplify?", "answer": "AWS Amplify includes a set of tools (open source framework, visual development environment, console) and services (web app and static website hosting) to accelerate the development of mobile and web applications on AWS. The framework comes with an opinionated set of libraries, UI components, and a command line interface (CLI) for building an app backend and integrating it with iOS, Android, Web, and React Native apps.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:15:11.289310"}}
{"question": "How does Amplify Studio simplify the development process with Amplify?", "answer": "Amplify Studio simplifies the configuration of backends and frontend UIs with a visual point-and-click experience that works seamlessly with the Amplify CLI. It also includes functionality for managing app content and users.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:15:11.289628"}}
{"question": "What are the differences between using Amplify's open source framework and Amplify Studio?", "answer": "Both Amplify's open source framework and Amplify Studio are tools for developing applications using AWS Amplify. The open source framework includes an opinionated set of libraries, UI components, and a command line interface (CLI) for building an app backend and integrating it with iOS, Android, Web, and React Native apps. Amplify Studio, on the other hand, provides a visual point-and-click experience for configuring backends and frontend UIs and managing app content and users.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:15:11.290074"}}
{"question": "What is the AWS Amplify web hosting service and how does it integrate with the console?", "answer": "The AWS Amplify web hosting service is a fully managed offering that can be used to deploy and host Single Page App (SPA) frontends and static websites, whether or not they use Amplify libraries. Users can access and manage this service via the AWS console.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-11T14:15:16.999786"}}
{"question": "What are the benefits of using AWS Amplify's static web hosting service in conjunction with the CLI?", "answer": "The AWS Amplify static web hosting service offers additional functionality when used in conjunction with the CLI. On each check-in, AWS Amplify provisions or updates backend resources prior to deploying the front end. Users can choose between isolated backend deployments per branch or shared backend deployments across branches.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-11T14:15:17.000117"}}
{"question": "How does the AWS Amplify static web hosting service compare to using the CLI for backend resource management without the hosting service?", "answer": "When using the AWS Amplify static web hosting service in conjunction with the CLI for backend resource management, the service provisions or updates the backend resources prior to deploying the front end. Without the hosting service, users would need to manage these backend resources separately.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-1", "source_tokens": 392, "generated_at": "2026-02-11T14:15:17.000564"}}
{"question": "Which AWS services are provisioned when you configure specific features using the Amplify CLI or Amplify Studio?", "answer": "The necessary AWS cloud services are provisioned for you when you configure features using the Amplify CLI or Amplify Studio.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:15:22.119351"}}
{"question": "How does Amplify Studio help non-developers engage with AWS tools for managing app content and users?", "answer": "Amplify Studio provides easy access for non-developers (QA testers, PMs) to manage the app content and users without requiring developers to figure out the right IAM roles and policies.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:15:22.119654"}}
{"question": "What is the difference between using Amplify CLI and Amplify Studio to configure AWS services for an app?", "answer": "The Amplify CLI is used to configure AWS services programmatically, while Amplify Studio is a visual interface for configuring and maintaining app backends and creating frontend UIs. With Amplify Studio, non-developers can also manage app content and users without requiring developers to set up IAM roles and policies.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:15:22.119826"}}
{"question": "What services does the Amplify console provide for AWS Amplify apps?", "answer": "The Amplify console is where you can access AWS Amplify's fully managed web hosting service, set up web hosting, manage CI/CD, add a custom domain, and navigate to underlying AWS service consoles for your apps.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:15:28.191480"}}
{"question": "How does Amplify Studio differ from the Amplify console in terms of usage?", "answer": "The Amplify console is used for managing the hosting and deployment of your app, while Amplify Studio is used for configuring and maintaining the app backend, adding features such as auth, data, and functions. After launching your app, the Amplify Studio also provides a way for non-developers to manage app content and users.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:15:28.191807"}}
{"question": "What are the main advantages of AWS Amplify's static web hosting service compared to other hosting solutions?", "answer": "AWS Amplify's static web hosting service provides a complete workflow for building, deploying, and hosting single page web apps or static sites with serverless backends. It offers continuous deployment, which allows developers to deploy updates on every code commit to their Git repository. When the build succeeds, the app is deployed and hosted on an amplifyapp.com subdomain, and developers can connect their custom domain to start receiving production traffic.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:15:28.192240"}}
{"question": "What does AWS Amplify do when it detects backend functionality?", "answer": "AWS Amplify deploys the necessary AWS resources in the same deployment as the front end.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T14:15:32.632621"}}
{"question": "How does AWS Amplify handle environment variables?", "answer": "Environment variables are configurations required by apps at runtime. You can add environment variables when creating an app or by going to the app settings. All environment variables are encrypted to prevent rogue access.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T14:15:32.632941"}}
{"question": "What's the difference between connecting a public and private repository to AWS Amplify?", "answer": "You can connect private and public repositories from GitHub, BitBucket, GitLab, and AWS CodeCommit. AWS Amplify does not store access tokens from repositories, but fetches them directly from your source provider and discards them after configuring continuous deployment. AWS Amplify currently does not support private Git servers.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T14:15:32.633366"}}
{"question": "What resources does AWS Amplify create during the build process and what are their specifications?", "answer": "AWS Amplify creates a temporary compute container (4 vCPU, 7GB RAM) during the build process. It also leverages Amazon CloudFront Global Edge Network for hosting and distributing the web app globally.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-11T14:15:38.200508"}}
{"question": "How does AWS Amplify utilize Git's branching model for deployment?", "answer": "AWS Amplify uses Gitâ€™s branching model to create new environments every time a developer pushes code to a new branch. New frontend and backend environments are created linked to each connected branch, allowing developers to work in sandbox environments and use Git as a mechanism to merge code and resolve conflicts. Changes are automatically pushed to production once they are merged into the master branch.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-11T14:15:38.201000"}}
{"question": "What's the difference between hosting a web app using AWS Amplify and using a traditional web server?", "answer": "AWS Amplify does not require web servers for hosting modern web apps and leverages the Amazon CloudFront Global Edge Network to distribute static content (HTML, CSS, and JavaScript files) globally. Traditional web servers, on the other hand, require more manual setup and maintenance.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-5", "source_tokens": 448, "generated_at": "2026-02-11T14:15:38.201315"}}
{"question": "What does AWS Amplify provide for connecting custom domains purchased from third-party registrars?", "answer": "AWS Amplify provides instructions on how to update DNS records for third-party registrars to point to their deployed apps.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T14:15:42.355923"}}
{"question": "How does AWS Amplify handle SSL certificates for web hosting?", "answer": "AWS Amplify uses Amazon Certificate Manager to generate and manage public SSL/TLS certificates for AWS based websites and applications, with wildcard domain support.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T14:15:42.356239"}}
{"question": "What's the difference between a redirect and a rewrite in AWS Amplify web hosting?", "answer": "A redirect is a client-side request to update the web browser to a new URL, while a rewrite is a server-side rewrite of the URL that doesn't change what the user sees.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T14:15:42.356715"}}
{"question": "What is the pricing consistency across different AWS regions?", "answer": "The text passage states that prices are the same across all AWS regions.", "question_type": "factual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-11T14:15:45.324939"}}
{"question": "Why does AWS maintain the same pricing structure across different regions?", "answer": "The text passage does not provide information on the reason for pricing consistency across regions.", "question_type": "conceptual", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-11T14:15:45.325267"}}
{"question": "How does AWS pricing consistency compare to pricing variations in other cloud providers?", "answer": "The text passage does not provide any information to make a comparison between AWS and other cloud providers regarding pricing consistency.", "question_type": "comparison", "metadata": {"service": "AMPLIFY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "amplify-faq-7", "source_tokens": 11, "generated_at": "2026-02-11T14:15:45.325683"}}
{"question": "What does Amazon API Gateway charge for with no minimum fees or startup costs?", "answer": "Amazon API Gateway charges for HTTP APIs, REST APIs, and WebSocket APIs based on the number of API calls and the amount of data transferred out for HTTP APIs and REST APIs, and for messages sent and received and the time a user/device is connected for WebSocket APIs.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T14:15:50.955871"}}
{"question": "Why would you use Amazon API Gateway to manage and secure APIs?", "answer": "Amazon API Gateway allows developers to create an API that acts as a front door for applications to access data, business logic, or functionality from back-end services. It handles all tasks involved in accepting and processing concurrent API calls, including traffic management, authorization and access control, monitoring, and API version management.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T14:15:50.956128"}}
{"question": "How does Amazon API Gateway for HTTP APIs and REST APIs pricing compare to WebSocket APIs pricing?", "answer": "For HTTP APIs and REST APIs, you pay based on the number of API calls and the amount of data transferred out. For WebSocket APIs, you pay based on messages sent and received and the time a user/device is connected.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T14:15:50.956529"}}
{"question": "What functionality does API Gateway provide for reducing development effort and time-to-market?", "answer": "API Gateway allows developers to quickly create APIs and assign static content for their responses, enabling teams to begin development while the backend processes are being built.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-11T14:16:02.373680"}}
{"question": "How does API Gateway support real-time two-way communication applications?", "answer": "API Gateway maintains a persistent connection between connected users and enables message transfer between them, allowing for the development of real-time two-way communication applications such as chat apps, streaming dashboards, and notifications.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-11T14:16:02.373995"}}
{"question": "What's the difference between API Gateway's role in reducing development effort and its support for real-time communication?", "answer": "API Gateway reduces development effort by allowing developers to quickly create APIs and assign static content for responses, enabling teams to begin development while the backend processes are being built. It supports real-time communication by maintaining a persistent connection between connected users and enabling message transfer between them.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-2", "source_tokens": 129, "generated_at": "2026-02-11T14:16:02.374476"}}
{"question": "What are the two options Amazon API Gateway offers for creating RESTful APIs?", "answer": "Amazon API Gateway offers two options for creating RESTful APIs: HTTP APIs and REST APIs.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-11T14:16:07.058010"}}
{"question": "How does Amazon API Gateway's REST APIs differ from HTTP APIs in terms of functionality?", "answer": "Amazon API Gateway's REST APIs offer API management features in addition to API proxy functionality, while HTTP APIs are optimized for building APIs that proxy to AWS Lambda functions or HTTP backends.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-11T14:16:07.058326"}}
{"question": "What are the advantages of using Amazon API Gateway's WebSocket APIs over the other two options?", "answer": "Amazon API Gateway's WebSocket APIs offer the advantage of maintaining a persistent connection between connected clients, enabling real-time message communication. They can be integrated with AWS Lambda functions, Amazon Kinesis, or any HTTP endpoint.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-3", "source_tokens": 307, "generated_at": "2026-02-11T14:16:07.058898"}}
{"question": "What are the ideal use cases for HTTP APIs in Amazon API Gateway?", "answer": "HTTP APIs in Amazon API Gateway are ideal for building proxy APIs for AWS Lambda or any HTTP endpoint, building modern APIs that are equipped with OIDC and OAuth 2 authorization, workloads that are likely to grow very large, and APIs for latency sensitive workloads.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-11T14:16:13.454237"}}
{"question": "How do the features and capabilities of HTTP APIs and REST APIs in Amazon API Gateway differ?", "answer": "HTTP APIs are optimized for building APIs that proxy to AWS Lambda functions or HTTP backends, making them ideal for serverless workloads. They come standard with CORS support, OIDC and OAuth2 support for authentication and authorization, and automatic deployments on stages. However, they do not currently support API management functionality. REST APIs, on the other hand, are intended for APIs that require API proxy functionality and API management features in a single solution.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-11T14:16:13.454504"}}
{"question": "Which API type, HTTP or REST, is more suitable for customers looking for a single price point for an all-inclusive set of features needed to build, manage, and publish their APIs?", "answer": "REST APIs are more suitable for customers looking for a single price point for an all-inclusive set of features needed to build, manage, and publish their APIs.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-4", "source_tokens": 452, "generated_at": "2026-02-11T14:16:13.454901"}}
{"question": "What information does the AWS CLI provide about your API through the info and warning fields?", "answer": "The AWS CLI returns information about your API within the info and warning fields.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:16:17.314808"}}
{"question": "Why would you use AWS API Gateway to create a WebSocket API and what can be set for WebSocket routing?", "answer": "You can create a WebSocket API using AWS API Gateway and then set WebSocket routing to indicate the backend services such as AWS Lambda, Amazon Kinesis, or your HTTP endpoint to be invoked based on the message content.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:16:17.315139"}}
{"question": "How does Amazon API Gateway handle HTTPS endpoints for its APIs compared to unencrypted endpoints?", "answer": "Amazon API Gateway exposes HTTPS endpoints only for its APIs and does not support unencrypted (HTTP) endpoints.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:16:17.315543"}}
{"question": "What programming languages does API Gateway support for generating client SDKs?", "answer": "API Gateway supports generating client SDKs for Android and iOS (Swift and Objective-C), web app development with JavaScript, Ruby, and Java.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-11T14:16:22.525477"}}
{"question": "How can you define and manage resources in API Gateway?", "answer": "You can define resources in API Gateway through the console or APIs. Each resource is a typed object that can have associated data models, relationships to other resources, and can respond to different methods. Resources can support one or more standard HTTP methods, and you define which verbs are supported and their implementation.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-11T14:16:22.525684"}}
{"question": "What is the difference between usage plans in API Gateway and how do they compare to defining API keys?", "answer": "Usage plans help manage access to APIs, define throttling and request quota limits, and extract utilization data on a per-API key basis. They can restrict access to certain APIs and generate billing documents. API keys, on the other hand, are used to authenticate and authorize requests.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-6", "source_tokens": 485, "generated_at": "2026-02-11T14:16:22.525860"}}
{"question": "What is the role of stages in Amazon API Gateway and how many stages can an API have?", "answer": "Stages in Amazon API Gateway help manage the development lifecycle of an API. Each REST API can have multiple stages, allowing you to deploy the same API to different environments, such as development and production, with unique configurations and endpoints.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:16:27.752909"}}
{"question": "What are the benefits of using custom domain names with stages in Amazon API Gateway?", "answer": "Using custom domain names with stages in Amazon API Gateway allows you to access your resources directly through the domain name without the need for an additional path parameter. This can make your API more user-friendly and simplify the URL structure.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:16:27.753180"}}
{"question": "How does using stage variables in Amazon API Gateway compare to hardcoding endpoints in API configurations?", "answer": "Using stage variables in Amazon API Gateway instead of hardcoding endpoints in API configurations allows you to use different endpoints for each stage (e.g. dev, beta, prod) with the same API configuration. This improves flexibility and simplifies management.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:16:27.753342"}}
{"question": "What can you use the Swagger importer tool for in Amazon API Gateway?", "answer": "You can use the Swagger importer tool in Amazon API Gateway to import Swagger API definitions into API Gateway, create and deploy new APIs, and update existing ones.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-11T14:16:32.654308"}}
{"question": "How does API Gateway simplify the process of defining API documentation?", "answer": "API Gateway simplifies the process of defining API documentation through documentation inheritance. This feature allows you to define a documentation string once and then use it in multiple places, reducing the effort required to create and maintain API documentation.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-11T14:16:32.654721"}}
{"question": "Can you restrict access to an API in Amazon API Gateway using a Resource Policy, and if so, what are the available options?", "answer": "Yes, you can restrict access to an API in Amazon API Gateway using a Resource Policy. You can allow access to a specific Amazon VPC or VPC endpoint, or grant access to a VPC or VPC endpoint from a different account.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-8", "source_tokens": 442, "generated_at": "2026-02-11T14:16:32.655061"}}
{"question": "What service does AWS provide for signing API requests and managing authorization?", "answer": "Amazon API Gateway is the service provided by AWS for signing API requests and managing authorization.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-11T14:16:37.795407"}}
{"question": "How does AWS implement custom request authorization using Lambda functions?", "answer": "AWS Lambda functions are used as custom request authorizers in Amazon API Gateway. When an API is called, API Gateway checks if a Lambda authorizer is configured. If so, it calls the Lambda function with the incoming authorization token. The Lambda function then returns IAM policies, which are used to authorize the request.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-11T14:16:37.795630"}}
{"question": "What are the differences between using API keys for authorization and using signed API calls or OAuth?", "answer": "API keys should be used for monitoring usage by third-party developers and can be replaced after a security incident. However, they should not be used for authorization due to security concerns. Signed API calls and OAuth are stronger authorization mechanisms that return IAM policies for API Gateway to use.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-9", "source_tokens": 469, "generated_at": "2026-02-11T14:16:37.796014"}}
{"question": "What information about API calls is logged to CloudTrail in Amazon API Gateway?", "answer": "All API calls made to the Amazon API Gateway APis to create, modify, delete, or deploy REST APIs are logged to CloudTrail in your AWS account.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:16:42.966717"}}
{"question": "How can you restrict access to a Private API in Amazon API Gateway?", "answer": "You can apply a Resource Policy to an API to restrict access to a specific Amazon VPC or VPC endpoint. You can also give an Amazon VPC or VPC endpoint from a different account access to the Private API using a Resource Policy.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:16:42.966928"}}
{"question": "What's the difference between logging API calls to CloudWatch and CloudTrail in Amazon API Gateway?", "answer": "CloudTrail logs are focused on changes to resources (API calls to create, modify, delete, or deploy REST APIs) and are stored in your AWS account. CloudWatch logs, on the other hand, provide metrics and monitoring information for your APIs, such as API calls, latency, and error rates.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:16:42.967306"}}
{"question": "What logging options are available in Amazon API Gateway for each method in a REST API?", "answer": "For each method in a REST API, you can set the verbosity of the logging and determine if full request and response data should be logged.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-11T14:16:47.352931"}}
{"question": "How does Amazon API Gateway's throttling help maintain performance and availability of backend services?", "answer": "Throttling in Amazon API Gateway helps maintain performance and availability of backend services by controlling API traffic and ensuring that the number of requests does not exceed the capacity of the backend services.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-11T14:16:47.353338"}}
{"question": "What is the difference between the throttling limits set at the method level and those set in usage plans?", "answer": "Throttling limits set at the method level apply to a specific method in an API, while throttling limits set in usage plans apply to individual API keys.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-11", "source_tokens": 411, "generated_at": "2026-02-11T14:16:47.353803"}}
{"question": "What size can you provision for an API Gateway cache in gigabytes?", "answer": "You can provision an API Gateway cache with a specific size in gigabytes.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-11T14:16:51.458954"}}
{"question": "How does enabling caching in API Gateway impact the performance of your APIs?", "answer": "Enabling caching in API Gateway improves performance by returning cached responses for duplicate requests, reducing traffic to the back-end service.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-11T14:16:51.459197"}}
{"question": "How does caching in API Gateway compare to no caching in terms of handling requests?", "answer": "With no caching, all requests go to the backend service until throttling limits are reached. With caching, duplicate requests are served from the cache if under throttling limits, reducing the load on the backend.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-12", "source_tokens": 502, "generated_at": "2026-02-11T14:16:51.459603"}}
{"question": "What billing units does Amazon API Gateway use for WebSocket APIs?", "answer": "Amazon API Gateway charges for WebSocket APIs based on Connection minutes and messages.", "question_type": "factual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-11T14:16:56.739354"}}
{"question": "How does routing work in Amazon API Gateway's WebSocket APIs?", "answer": "You specify a routing key and an integration backend when defining your WebSocket API. The routing key is an attribute in the message body, and a default integration can be set for non-matching routing keys.", "question_type": "conceptual", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-11T14:16:56.739618"}}
{"question": "How does handling disconnected clients differ between using IAM roles and policies and using AWS Lambda Authorizers in Amazon API Gateway's WebSocket APIs?", "answer": "When a client is disconnected, messages are sent from the Amazon API Gateway service to your backend AWS Lambda function or HTTP endpoint using the $disconnect route. With IAM roles and policies, you need to write the logic for adding or removing clients from the list of connected users. With AWS Lambda Authorizers, the logic is handled within the Lambda function.", "question_type": "comparison", "metadata": {"service": "API", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "api-faq-13", "source_tokens": 461, "generated_at": "2026-02-11T14:16:56.739901"}}
{"question": "What type of applications can Amazon AppFlow integrate with?", "answer": "Amazon AppFlow can integrate with Software-as-a-Service (SaaS) applications like Salesforce, Marketo, Slack, and ServiceNow.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-11T14:17:00.506170"}}
{"question": "How does Amazon AppFlow enhance data security?", "answer": "Amazon AppFlow automatically encrypts data in motion and allows users to restrict data from flowing over the public Internet for SaaS applications that are integrated with AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-11T14:17:00.506527"}}
{"question": "What's the difference between AppFlow's integration capability for SaaS applications and AWS services?", "answer": "AppFlow allows users to securely transfer data between SaaS applications and AWS services.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-0", "source_tokens": 224, "generated_at": "2026-02-11T14:17:00.507004"}}
{"question": "What are the benefits of using Amazon AppFlow for data integration in terms of speed and agility?", "answer": "Amazon AppFlow enables you to integrate applications in a few minutes without the need for coding or management. It includes features like data pagination, error logging, and network connection retries by default. With AppFlow, data flow quality is built in, and you can enrich the flow of data through masking, mapping, merging, filtering, and validation as part of the flow itself.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-11T14:17:05.855769"}}
{"question": "How does Amazon AppFlow provide privacy and security for data during transfer?", "answer": "Amazon AppFlow encrypts data at rest and in motion. You can encrypt data with AWS managed keys or bring your own custom keys. It also allows users to restrict data from flowing over the public Internet using Amazon VPC endpoints enabled by AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-11T14:17:05.856134"}}
{"question": "How does the scalability of Amazon AppFlow compare to traditional data transfer methods?", "answer": "Amazon AppFlow easily scales up without the need to plan or provision resources, allowing you to move large volumes of data without breaking it down into multiple batches.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-1", "source_tokens": 354, "generated_at": "2026-02-11T14:17:05.856307"}}
{"question": "What are the three ways to run data flows in AppFlow?", "answer": "You can run data flows on demand, based on business events, or on a schedule.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T14:17:14.618374"}}
{"question": "How can AppFlow help developers who want to integrate different SaaS applications?", "answer": "AppFlow helps developers save time by allowing them to implement common integration tasks without writing code or learning API documentation for each SaaS application.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T14:17:14.620030"}}
{"question": "What are the differences between running data flows on demand and event-based?", "answer": "Running data flows on demand allows you to run them immediately, while event-based running triggers the flow in response to specific business events.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T14:17:14.620426"}}
{"question": "What encryption method does AppFlow use by default for data at rest and in transit?", "answer": "AppFlow uses the AWS managed customer master key (CMK) for encryption by default.", "question_type": "factual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:17:19.984841"}}
{"question": "How does AppFlow compare to AWS Glue in terms of data processing and integration?", "answer": "AWS Glue is a managed ETL service for preparing and loading data from databases for analytics, while AppFlow is a service for exchanging data between SaaS applications and AWS services. AppFlow is designed for operational data flows and can be initiated by humans, events, or schedules, whereas AWS Glue focuses on data catalog creation and metadata availability for querying.", "question_type": "comparison", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:17:19.985168"}}
{"question": "What is the primary function of AWS DataSync and in what scenarios is it ideal?", "answer": "AWS DataSync is a service for moving large amounts of data between on-premises data sources and the AWS Cloud for bulk data migration, processing, and backup or disaster recovery. It is ideal for transfers of tens or hundreds of terabytes, where making effective use of network bandwidth and achieving high throughput is necessary.", "question_type": "conceptual", "metadata": {"service": "APPFLOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appflow-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:17:19.985732"}}
{"question": "What services can AWS Application Migration Service be used to migrate from?", "answer": "AWS Application Migration Service can be used to migrate applications from physical servers, VMware vSphere, Microsoft Hyper-V, and other cloud providers.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-11T14:17:28.426810"}}
{"question": "How does AWS Application Migration Service simplify the migration process?", "answer": "AWS Application Migration Service simplifies the migration process by automatically converting source servers to run natively on AWS, allowing the same automated process for a wide range of applications, and providing non-disruptive testing and quick cutover migration.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-11T14:17:28.427110"}}
{"question": "What are the benefits of using AWS Application Migration Service over other AWS services for migrations?", "answer": "AWS Application Migration Service offers benefits such as simplification of the migration process, cost reduction, and application modernization automation.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-0", "source_tokens": 485, "generated_at": "2026-02-11T14:17:28.427499"}}
{"question": "What is the full name of the AWS service that helps migrate servers to AWS?", "answer": "AWS Application Migration Service", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T14:17:32.152904"}}
{"question": "How does one perform agentless replication from VMware to AWS with AWS Application Migration Service?", "answer": "By installing the AWS MGN vCenter Client in the vCenter environment and using it for agentless snapshot replication.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T14:17:32.153147"}}
{"question": "What is the difference between using agentless and agent-based replication with AWS Application Migration Service?", "answer": "Agentless replication is performed without installing agents in the source environment, while agent-based replication provides continuous data replication and shorter cutover windows.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T14:17:32.153577"}}
{"question": "What is the free period for using AWS Application Migration Service for one source server?", "answer": "The free period for using AWS Application Migration Service for one source server is 2,160 hours.", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:17:37.291124"}}
{"question": "What are the benefits of using AWS Application Migration Service over CloudEndure Migration?", "answer": "AWS Application Migration Service offers features and operational benefits that are not available with CloudEndure Migration, such as encryption in transit and at rest, private connectivity options, and the ability to control the data replication path.", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:17:37.291489"}}
{"question": "How does the pricing for AWS Application Migration Service compare to CloudEndure Migration?", "answer": "During the free period, there are no charges for AWS Application Migration Service for a source server. After the free period, you will be charged per hour for continuing to replicate the server. You will also incur charges for any AWS infrastructure that is provisioned by AWS Application Migration Service, as well as for resources that are provisioned when you launch test or cutover instances.", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:17:37.291910"}}
{"question": "What is the source for obtaining the most current information about AWS regional services?", "answer": "The AWS Regional Services List", "question_type": "factual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-11T14:17:40.263226"}}
{"question": "How would you obtain the latest information about which AWS services are available in which regions?", "answer": "You would refer to the AWS Regional Services List for this information", "question_type": "conceptual", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-11T14:17:40.263546"}}
{"question": "How does the availability of AWS services vary between regions, and where can you find this information?", "answer": "The availability of AWS services is detailed in the AWS Regional Services List", "question_type": "comparison", "metadata": {"service": "APPLICATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "application-faq-3", "source_tokens": 23, "generated_at": "2026-02-11T14:17:40.263881"}}
{"question": "What data sources can AWS AppSync connect to using a GraphQL schema?", "answer": "AWS AppSync can connect to AWS resources like tables, functions, and domains from Amazon DynamoDB, AWS Lambda and Amazon OpenSearch Service, as well as any data sources and services that provide an HTTP API.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-11T14:17:45.160003"}}
{"question": "How does AWS AppSync handle GraphQL requests and responses?", "answer": "AWS AppSync converts GraphQL queries and mutations into unique formats for different AWS Services, allowing you to define how incoming requests should interact with your data sources and how responses are mapped back into a GraphQL response.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-11T14:17:45.160232"}}
{"question": "What's the difference between writing resolvers in JavaScript vs. using AWS AppSync's console for testing?", "answer": "Writing resolvers in JavaScript allows you to define the custom logic for handling incoming requests and transforming responses, whereas using the console for testing allows you to evaluate your resolvers with mock data without interacting with your data sources.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-0", "source_tokens": 448, "generated_at": "2026-02-11T14:17:45.160616"}}
{"question": "What AWS services can you interact with directly using JavaScript resolvers in AWS AppSync?", "answer": "You can interact with Amazon DynamoDB, Amazon Aurora Serverless, Amazon OpenSearch Service, HTTP APIs, and other AWS services directly using JavaScript resolvers in AWS AppSync.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-11T14:17:50.267750"}}
{"question": "Why would you use a Lambda data source in AWS AppSync instead of directly accessing the target data source?", "answer": "You would use a Lambda data source in AWS AppSync as a proxy to interact with your target data source when you need to implement complex business logic that is not supported by the JavaScript resolvers.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-11T14:17:50.268035"}}
{"question": "How does AWS AppSync allow multiple teams to collaborate on a single API while maintaining independence?", "answer": "AWS AppSync allows multiple teams to collaborate on a single API by using Merged APIs, which is a single GraphQL API composed from multiple source GraphQL APIs. Each team can independently evolve their sub-schema, while the organization provides a single API schema to data consumers.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-1", "source_tokens": 464, "generated_at": "2026-02-11T14:17:50.268212"}}
{"question": "Which data sources are supported by AWS AppSync for subscriptions?", "answer": "AWS AppSync supports subscriptions with any of the data sources, including Amazon DynamoDB, Amazon OpenSearch Service, and AWS Lambda.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T14:17:55.211801"}}
{"question": "How can indexing and conditional checks be used in AWS AppSync with DynamoDB?", "answer": "AWS AppSync allows you to take full advantage of indexing and conditional checks capabilities provided by Amazon DynamoDB when using GraphQL. It returns comprehensive results from DynamoDB.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T14:17:55.212005"}}
{"question": "What is the difference between using the Amplify DataStore category client and the Amplify API (GraphQL) category client for DynamoDB data sources?", "answer": "The Amplify DataStore category client provides the best developer experience and built-in conflict detection and resolution for DynamoDB data sources, while the Amplify API (GraphQL) category client is suitable for non-DynamoDB data sources with no offline requirements.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T14:17:55.212347"}}
{"question": "What domain name is required to create a custom endpoint in AWS AppSync?", "answer": "You need to provide a domain name you own and indicate a valid AWS Certificate Manager (ACM) certificate that covers your domain.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T14:17:58.816158"}}
{"question": "How does AWS AppSync handle requests on a custom domain endpoint?", "answer": "AWS AppSync receives a request on the custom domain endpoint and routes it to the associated API for handling.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T14:17:58.816489"}}
{"question": "What's the difference between a channel and a namespace in AWS AppSync?", "answer": "A channel is a logical destination of an event, it allows publishers and subscribers to define routes for events. A namespace is a logical construct used to define capabilities shared by channels, allowing you to define different authorization modes for your Event API.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T14:17:58.816931"}}
{"question": "What type of events trigger the execution of Event Handlers in an AWS API?", "answer": "Event Handlers are triggered by system events in an AWS API.", "question_type": "factual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-11T14:18:03.488366"}}
{"question": "Can you explain the functionality of the onSubscribe Event Handler in an AWS API?", "answer": "The onSubscribe Event Handler is called any time a client subscribes to a channel in the namespace. You can authorize the subscription and apply filters in this handler.", "question_type": "conceptual", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-11T14:18:03.488692"}}
{"question": "How does the functionality of the onPublish Event Handler compare to the onSubscribe Event Handler in an AWS API?", "answer": "The onPublish Event Handler is called for events published to your channels in the namespace. In contrast, the onSubscribe Event Handler is called when a client subscribes to a channel. Both handlers allow you to transform the event before it is forwarded to subscribed clients, but the onPublish handler also allows you to drop messages by returning null.", "question_type": "comparison", "metadata": {"service": "APPSYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "appsync-faq-4", "source_tokens": 130, "generated_at": "2026-02-11T14:18:03.489151"}}
{"question": "What type of documents can be downloaded through AWS Artifact Reports?", "answer": "AWS Artifact Reports allow you to download AWS security and compliance documents, such as AWS ISO certifications, Payment Card Industry (PCI), and System and Organization Control (SOC) reports.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-11T14:18:07.879208"}}
{"question": "How can I grant non-admin IAM users access to AWS Artifact?", "answer": "To grant IAM users with non-admin permissions access to AWS Artifact, you will need to grant them access using IAM permissions.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-11T14:18:07.879445"}}
{"question": "What are the two states of an AWS Agreement and what do they represent?", "answer": "An Agreement can have two states: Inactive, meaning the Agreement has not been accepted by the user or a previously accepted Agreement has been terminated by the user; and Active, meaning the Agreement has been accepted by the user.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-0", "source_tokens": 483, "generated_at": "2026-02-11T14:18:07.879572"}}
{"question": "What are audit artifacts in AWS Artifact?", "answer": "Audit artifacts are pieces of evidence that demonstrate an organization's adherence to documented processes or specific requirements. AWS Artifact provides customers with reports and agreements that can be used as audit artifacts.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-11T14:18:11.974342"}}
{"question": "How can I provide my auditors with access to AWS compliance reports?", "answer": "You can create IAM user credentials specific to each auditor and configure the credentials to allow them to access only the relevant reports for their audit.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-11T14:18:11.974647"}}
{"question": "What's the difference between an audit artifact and an IAM policy in AWS Artifact?", "answer": "Audit artifacts are pieces of evidence demonstrating adherence to processes or requirements, while IAM policies are used to delegate permissions to users.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-1", "source_tokens": 349, "generated_at": "2026-02-11T14:18:11.975002"}}
{"question": "What types of AWS customers should use AWS Artifact Reports for demonstrating or ensuring compliance?", "answer": "AWS Artifact Reports should be used by AWS customers who are obligated or interested in demonstrating the compliance of their cloud architectures during system design, development, and audit life cycles. This includes those who need to provide evidence in the form of audit artifacts for historical and current compliance of their AWS infrastructure, as well as those who are interested in continuously monitoring or auditing their suppliers.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T14:18:17.535822"}}
{"question": "How can AWS Artifact Reports be used to design cloud architectures that support specific use cases?", "answer": "AWS Artifact Reports provide responsibility guidance that can be used to design cloud architectures and determine the additional security controls necessary to support specific use cases.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T14:18:17.536235"}}
{"question": "What's the difference between sharing AWS compliance reports with auditors or regulators and allowing customers to access them directly?", "answer": "Sharing AWS compliance reports with auditors or regulators is done as evidence of AWS security controls, while customers can access reports using their own AWS Account. The ability to share reports depends on the terms and conditions applicable to the specific AWS compliance report.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T14:18:17.536394"}}
{"question": "What type of reports can AWS customers access through AWS Marketplace Vendor Insights?", "answer": "AWS customers can access third-party compliance reports shared by ISVs through AWS Marketplace Vendor Insights.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:18:21.751610"}}
{"question": "Why should customers using AWS Marketplace Vendor Insights download third-party compliance reports?", "answer": "Customers using AWS Marketplace Vendor Insights should download and use third-party compliance reports as part of their third-party risk assessment.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:18:21.751966"}}
{"question": "What's the difference between managing agreements on AWS Artifact Agreements and using AWS Artifact for downloading reports?", "answer": "AWS Artifact Agreements allows you to manage and accept agreements with AWS for individual and organizational accounts, while AWS Artifact is used to download and access reports.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:18:21.752439"}}
{"question": "What permissions does an administrator have to manage agreements in an AWS account?", "answer": "An administrator of an AWS account has permissions to download, accept, and terminate agreements for that account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-11T14:18:25.641149"}}
{"question": "Why should you have your legal, privacy and/or compliance teams review AWS Artifact Account Agreements?", "answer": "You should review any agreement terms with your legal, privacy and/or compliance teams before accepting to ensure compliance with your organization's policies.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-11T14:18:25.641469"}}
{"question": "How does accepting an AWS Artifact Organization Agreement impact member accounts?", "answer": "When an authorized user of a management account accepts an organization agreement, all existing and future member accounts will be covered under the terms of the agreement automatically.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-4", "source_tokens": 402, "generated_at": "2026-02-11T14:18:25.641896"}}
{"question": "What permissions does the IAM user need to accept an organization agreement in AWS Artifact?", "answer": "The IAM user signed into the AWS console must have 'organizations:DescribeOrganization' permission for AWS Artifact to retrieve information about the accountâ€™s organization agreements.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-11T14:18:29.770863"}}
{"question": "How does accepting an organization agreement in AWS Artifact benefit a management account?", "answer": "Accepting an organization agreement in AWS Artifact allows a management account to manage agreements on behalf of all member accounts in the organization.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-11T14:18:29.771094"}}
{"question": "What's the difference between a management account and a member account in AWS Organizations regarding agreement acceptance?", "answer": "Only management accounts can accept or terminate agreements on behalf of all accounts in an organization using AWS Artifact Organization Agreements.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-5", "source_tokens": 503, "generated_at": "2026-02-11T14:18:29.771427"}}
{"question": "What type of AWS account is a member account?", "answer": "A member account is an AWS account that is part of an organization in AWS Organizations, other than the management account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-11T14:18:34.782452"}}
{"question": "How does a manager account in AWS Organizations manage member accounts' agreements?", "answer": "A manager account in AWS Organizations can create member accounts and invite existing accounts to join the organization. Member accounts can use AWS Artifact Account Agreements to accept or terminate agreements on behalf of themselves, and they can use AWS Artifact Organization Agreements to view the agreements accepted on their behalf by the management account.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-11T14:18:34.782687"}}
{"question": "What is the difference between managing agreements for a whole organization versus individual member accounts in AWS Artifact?", "answer": "In AWS Artifact Organization Agreements, you can only accept agreements on behalf of all accounts within the organization. If you would like to accept an agreement for only some member accounts, you must sign in to each account individually and accept the relevant agreement(s) through AWS Artifact Account Agreements.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-6", "source_tokens": 397, "generated_at": "2026-02-11T14:18:34.782821"}}
{"question": "What happens if a management account and a member account have the same type of AWS Artifact Account Agreement and Organization Agreement in place at the same time?", "answer": "The Organization Agreement will apply instead of the Account Agreement.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T14:18:38.428739"}}
{"question": "Why does an organization agreement take precedence over an account agreement when both are active?", "answer": "According to the terms of the organization agreement, it applies instead of the account agreement when both are active.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T14:18:38.429044"}}
{"question": "What occurs to the member account agreements when a member account is removed from an organization?", "answer": "Any organization agreements accepted on behalf of the member account will no longer apply to that account.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T14:18:38.429523"}}
{"question": "What tab in AWS Artifact Agreements should I use to accept the BAA for a single AWS account?", "answer": "You should use the Account agreements tab to accept the Business Associate Agreement (BAA) for a single AWS account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T14:18:43.203560"}}
{"question": "How does accepting the BAA in AWS Artifact Agreements impact my AWS account(s)?", "answer": "Upon accepting the BAA in AWS Artifact Agreements, you will instantly designate your AWS account(s) for use in connection with protected health information (PHI).", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T14:18:43.203832"}}
{"question": "What is the difference between accepting the BAA in the Account agreements tab and the Organization agreements tab in AWS Artifact Agreements?", "answer": "Accepting the BAA in the Account agreements tab applies only to the individual account you used to accept the account BAA, while accepting the BAA in the Organization agreements tab applies to all accounts linked to your management account through AWS Organizations.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T14:18:43.203990"}}
{"question": "What happens if I terminate an online BAA for my AWS account under the Organization agreements tab?", "answer": "Terminating an online BAA for your AWS account under the Organization agreements tab immediately ceases your account's status as a HIPAA Account and removes it from coverage by a BAA with AWS, unless it is also covered by an individual account BAA.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-11T14:18:48.423637"}}
{"question": "Why should I terminate an organization BAA in AWS Artifact if I no longer need to use any accounts in my organization for handling PHI?", "answer": "Terminating an organization BAA in AWS Artifact removes all accounts within your organization as HIPAA Accounts and removes their coverage by a BAA with AWS, unless they are covered by individual account BAAs.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-11T14:18:48.423871"}}
{"question": "What's the difference between terminating an online BAA for a single AWS account and an organization BAA in AWS Artifact?", "answer": "Terminating an online BAA for a single AWS account only affects that specific account, whereas terminating an organization BAA affects all accounts within the organization.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-9", "source_tokens": 471, "generated_at": "2026-02-11T14:18:48.424003"}}
{"question": "What happens to organization agreements when a member account leaves an AWS organization?", "answer": "When a member account leaves an AWS organization, any accepted organization agreements no longer apply to that account. If the member account wants the agreements to continue applying, they should accept the relevant account agreements under the Account agreements tab in AWS Artifact before leaving.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-11T14:18:53.504125"}}
{"question": "Why should you accept HIPAA Account agreements in AWS Artifact before using HIPAA Eligible Services with PHI?", "answer": "You should accept HIPAA Account agreements in AWS Artifact before using HIPAA Eligible Services with PHI to ensure that the agreements apply to your accounts. This helps maintain compliance with HIPAA regulations.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-11T14:18:53.504453"}}
{"question": "How does managing organization agreements under AWS Artifact compare to managing them offline?", "answer": "Managing organization agreements under AWS Artifact allows all existing and future member accounts in your organization to be covered under the agreement. You cannot download a copy of offline BAA agreements in AWS Artifact, but you can request a copy from your AWS Account Manager.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-10", "source_tokens": 385, "generated_at": "2026-02-11T14:18:53.504863"}}
{"question": "What type of AWS accounts are subject to the AWS BAA according to the text?", "answer": "AWS accounts that store or transmit Protected Health Information (PHI) and use only HIPAA Eligible Services for that purpose are referred to as HIPAA Accounts in the text and are subject to the AWS BAA.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-11T14:18:59.009046"}}
{"question": "How can you modify the number of HIPAA Accounts under an offline BAA?", "answer": "You can add or remove HIPAA Accounts by following the process outlined in your offline BAA, which may include sending an email to aws-hipaa@amazon.com. Changes to the Artifact Agreements interface will reflect the new designation.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-11T14:18:59.009441"}}
{"question": "What's the difference between removing an account as a HIPAA Account under an offline BAA and terminating the offline BAA itself?", "answer": "Removing an account as a HIPAA Account under an offline BAA does not terminate the offline BAA, whereas providing written notice to AWS according to the terms of the offline BAA is required to terminate the offline BAA.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-11", "source_tokens": 417, "generated_at": "2026-02-11T14:18:59.009820"}}
{"question": "What tab should I use in AWS Artifact Agreements to accept an ANDB Addendum for my individual AWS account?", "answer": "You should use the 'Account agreements' tab to accept an ANDB Addendum for your individual AWS account.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-11T14:19:04.025735"}}
{"question": "How does accepting an ANDB Addendum in the 'Organization agreements' tab of AWS Artifact Agreements differ from accepting it in the 'Account agreements' tab?", "answer": "Accepting an ANDB Addendum in the 'Organization agreements' tab applies to all existing and future AWS accounts linked to your management account through AWS Organizations, while accepting it in the 'Account agreements' tab only applies to the individual AWS account you used to accept the ANDB Addendum.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-11T14:19:04.026141"}}
{"question": "If both an account ANDB Addendum and an organizations ANDB Addendum have been accepted, which one takes precedence?", "answer": "The organizations ANDB Addendum will apply instead of the account ANDB Addendum.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-12", "source_tokens": 484, "generated_at": "2026-02-11T14:19:04.026551"}}
{"question": "What happens if I terminate an individual account ANDB Addendum in AWS Artifact?", "answer": "Terminating an individual account ANDB Addendum in AWS Artifact results in the AWS account no longer being covered by an ANDB Addendum with AWS, unless it is also covered by an organizations ANDB Addendum. You should only terminate an account ANDB Addendum when you have removed all personal information from the AWS account and will no longer use it in connection with personal information or when you join that AWS account as a member account in an AWS organization that has an organizations ANDB Addendum.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T14:19:12.360849"}}
{"question": "What is the consequence of terminating an organizations ANDB Addendum in AWS Artifact?", "answer": "Terminating an organizations ANDB Addendum in AWS Artifact causes all AWS accounts in that AWS organization to no longer be covered by an ANDB Addendum with AWS, unless they are covered by an account ANDB Addendum. You should only terminate an organizations ANDB Addendum when all personal information has been removed from the AWS accounts in the organization and those AWS accounts will no longer be used in connection with personal information or when you have agreed account ANDB Addendums for those AWS accounts that are used in connection with personal information.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T14:19:12.361199"}}
{"question": "What's the difference between terminating an individual account ANDB Addendum and an organizations ANDB Addendum in AWS Artifact?", "answer": "Terminating an individual account ANDB Addendum causes the specific AWS account to no longer be covered by an ANDB Addendum with AWS, unless it is also covered by an organizations ANDB Addendum. Terminating an organizations ANDB Addendum causes all AWS accounts in that AWS organization to no longer be covered by an ANDB Addendum with AWS, unless they are covered by an account ANDB Addendum. The key difference lies in the scope of the termination.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T14:19:12.361615"}}
{"question": "What type of AWS accounts are subject to the ANDB Addendum according to the text?", "answer": "ANDB Accounts are defined as AWS accounts where the entity responsible for that account is subject to the Australian Privacy Act and includes personal information in AWSâ€™ possession or control.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:19:17.718205"}}
{"question": "How does accepting an NZNDB Addendum through the AWS Artifact Agreements console differ for individual AWS accounts versus an AWS organization?", "answer": "Accepting an NZNDB Addendum for an individual AWS account is done through the Account agreements tab and applies only to that account. Accepting an NZNDB Addendum for an AWS organization through the Organization agreements tab applies to all existing and future AWS accounts linked to the management account.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:19:17.718555"}}
{"question": "Why would a user accept an NZNDB Addendum on behalf of all existing and future AWS accounts in their organization?", "answer": "Accepting an NZNDB Addendum on behalf of all existing and future AWS accounts in an organization through the Organization agreements tab allows the management account to comply with data protection regulations for all accounts in the organization.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:19:17.718749"}}
{"question": "What button should I click to terminate an account NZNDB Addendum in AWS Artifact?", "answer": "Click on the â€˜Terminate the AWS New Zealand Notifiable Data Breach Addendum for this Accountâ€™ button under the Account agreements tab.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-11T14:19:25.710783"}}
{"question": "Why can't I terminate an account NZNDB Addendum without also terminating an organizations NZNDB Addendum?", "answer": "If you terminate an account NZNDB Addendum under the Account agreements tab, the AWS account you used to sign into AWS Artifact will not be covered by an NZNDB Addendum with AWS unless it is also covered by an organizations NZNDB Addendum. You should only terminate an account NZNDB Addendum when you are sure that you have removed all personal information from the AWS account and will no longer use the AWS account in connection with personal information, or when you join that AWS account as a member account in an AWS organization that has an organizations NZNDB Addendum.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-11T14:19:25.711154"}}
{"question": "How does terminating an organizations NZNDB Addendum impact the coverage for accounts within that organization?", "answer": "If a user of a management account terminates an organizations NZNDB Addendum within the Organization agreements tab, the AWS accounts in that AWS organization will not be covered by an NZNDB Addendum with AWS unless they are covered by an account NZNDB Addendum. You should only terminate an organizations NZNDB Addendum when you are sure that all personal information has been removed from the AWS accounts in that AWS organization and those AWS accounts will no longer be used in connection with personal information, or when you have agreed account NZNDB Addendums for those AWS accounts that are used in connection with personal information.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-15", "source_tokens": 433, "generated_at": "2026-02-11T14:19:25.711579"}}
{"question": "What happens if an account has both an account NZNDB Addendum and an organizations NZNDB Addendum at the same time?", "answer": "The terms of the organizations NZNDB Addendum will apply instead of the terms of the account NZNDB Addendum.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-11T14:19:30.605569"}}
{"question": "Why does the organizations NZNDB Addendum apply instead of the account NZNDB Addendum when both are present?", "answer": "It's not explicitly stated in the context why the organizations NZNDB Addendum takes precedence over the account NZNDB Addendum, but it can be inferred from the information provided.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-11T14:19:30.605911"}}
{"question": "How does having both an account NZNDB Addendum and an organizations NZNDB Addendum impact the application of the agreements?", "answer": "The organizations NZNDB Addendum applies instead of the account NZNDB Addendum when both are present.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-16", "source_tokens": 390, "generated_at": "2026-02-11T14:19:30.606458"}}
{"question": "What error message would I see if I don't have the permissions to download a report in AWS Artifact?", "answer": "You don't have the permissions to download this report", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-11T14:19:35.950186"}}
{"question": "Why do I need specific permissions to manage agreements in AWS Artifact for my organization?", "answer": "You need permissions to manage agreements for your organization in AWS Artifact because it requires access to organization information in AWS Organizations. The necessary permissions are: organizations:EnableAWSServiceAccess and organizations:ListAWSServiceAccessForOrganization.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-11T14:19:35.950390"}}
{"question": "What are the differences in permissions required to manage agreements for an individual user compared to managing agreements for an organization in AWS Artifact?", "answer": "For an individual user, the required permissions include artifact:AcceptAgreement, artifact:TerminateAgreement, and artifact:DownloadAgreement. For managing agreements for an organization, the required permissions are organizations:EnableAWSServiceAccess, organizations:ListAWSServiceAccessForOrganization, iam:CreateRole, iam:AttachRolePolicy, and iam:ListRoles.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-17", "source_tokens": 501, "generated_at": "2026-02-11T14:19:35.950521"}}
{"question": "Which permissions are required to list the configurations in AWS User Notifications?", "answer": "The following permissions are needed: 'notifications:ListChannels', 'notifications:ListEventRules', 'notifications:ListNotificationConfigurations', 'notifications:ListNotificationHubs'.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-11T14:19:41.740026"}}
{"question": "Why can't I create a configuration in AWS User Notifications without certain permissions?", "answer": "You need permissions like 'artifact:GetAccountSettings', 'artifact:PutAccountSettings', 'notifications:AssociateChannel', 'notifications:CreateEventRule', 'notifications:TagResource', 'notifications:CreateNotificationConfiguration', 'notifications-contacts:CreateEmailContact', 'notifications-contacts:SendActivationCode', 'notifications:ListNotificationHubs', and 'notifications:ListEventRules' to create a configuration in AWS User Notifications.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-11T14:19:41.740298"}}
{"question": "What permissions are necessary for creating and managing configurations in AWS User Notifications, compared to listing them?", "answer": "For creating and managing configurations in AWS User Notifications, you need additional permissions such as 'artifact:GetAccountSettings' and 'artifact:PutAccountSettings'. These permissions are not required for just listing the configurations.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-18", "source_tokens": 507, "generated_at": "2026-02-11T14:19:41.740469"}}
{"question": "What permissions are required to list email contacts in AWS notifications?", "answer": "The following permissions are required to list email contacts in AWS notifications: notifications-contacts:ListEmailContacts.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-11T14:19:45.683455"}}
{"question": "Why would you need permissions to list email contacts in AWS notifications?", "answer": "You would need permissions to list email contacts in AWS notifications to manage the contacts associated with your notification configurations.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-11T14:19:45.683694"}}
{"question": "What's the difference between being able to list email contacts and register notification hubs in AWS notifications?", "answer": "Listing email contacts allows you to manage the contacts associated with your notification configurations, while registering notification hubs enables you to create and manage hubs to send messages to multiple targets.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-19", "source_tokens": 444, "generated_at": "2026-02-11T14:19:45.683829"}}
{"question": "What service does AWS Artifact use to send notifications?", "answer": "AWS Artifact uses the AWS User Notification service to send notifications.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-11T14:19:49.747587"}}
{"question": "Why would I use AWS Artifact notifications?", "answer": "You would use AWS Artifact notifications to proactively learn about new reports or agreements that become available on AWS Artifact, saving time and effort needed to manually check for availability of new content.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-11T14:19:49.747837"}}
{"question": "Can you compare the notification setup processes for reports and agreements on AWS Artifact?", "answer": "For reports, you can filter notifications by choosing specific categories and series of reports. For agreements, currently there are no granular filters. Both require subscribing to notifications and creating configurations to start receiving notifications.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-20", "source_tokens": 485, "generated_at": "2026-02-11T14:19:49.748000"}}
{"question": "What email addresses will receive notifications according to the text passage?", "answer": "Notifications will be delivered to the email addresses provided by the user while creating the notification configuration.", "question_type": "factual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-11T14:19:53.473640"}}
{"question": "How does AWS Artifact utilize AWS User Notifications for sending emails?", "answer": "AWS Artifact notifications leverage AWS User Notifications service in order to configure notifications and to send emails.", "question_type": "conceptual", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-11T14:19:53.473870"}}
{"question": "How does the number of email addresses in AWS Artifact notifications compare to the service quota of AWS User Notifications?", "answer": "On AWS Artifact notifications feature, you can provide up to 20 email addresses per notification configuration. Service quotas of AWS User Notification service also apply.", "question_type": "comparison", "metadata": {"service": "ARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "artifact-faq-21", "source_tokens": 156, "generated_at": "2026-02-11T14:19:53.474289"}}
{"question": "What data formats does Amazon Athena for SQL support?", "answer": "Amazon Athena for SQL supports CSV, JSON, Apache ORC, Apache Parquet, and Apache Avro data formats.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-11T14:19:58.614023"}}
{"question": "Why would you use Amazon Athena for SQL instead of other big data services?", "answer": "You would use Amazon Athena for SQL because it is an interactive analytics service that allows you to analyze data directly from Amazon S3 using SQL, and it is serverless, so there is no infrastructure to set up or manage.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-11T14:19:58.614296"}}
{"question": "How does Amazon Athena for SQL compare to Amazon Athena for Apache Spark in terms of data formats?", "answer": "Amazon Athena for SQL uses Trino and Presto with full standard SQL support and works with various standard data formats, including CSV, JSON, Apache ORC, Apache Parquet, and Apache Avro. Amazon Athena for Apache Spark also supports SQL and allows you to use Apache Spark, but it does not explicitly mention the specific data formats it supports.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-0", "source_tokens": 362, "generated_at": "2026-02-11T14:19:58.614682"}}
{"question": "What data sources can Athena analyze?", "answer": "Athena can analyze data stored in S3 and 30 different data sources, including on-premises data sources and other cloud systems.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-11T14:20:03.080165"}}
{"question": "How does Athena process different data formats?", "answer": "Athena can process unstructured, semi-structured, and structured datasets. Examples include CSV, JSON, Avro, Parquet, and ORC.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-11T14:20:03.080427"}}
{"question": "What's the difference between using the Athena console vs. ODBC or JDBC driver for querying data?", "answer": "Using the Athena console allows you to create a schema by writing Data Definition Language (DDL) statements or using a create table wizard. With ODBC or JDBC driver, you can programmatically run queries, add tables, or partitions.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-1", "source_tokens": 314, "generated_at": "2026-02-11T14:20:03.080560"}}
{"question": "What data formats does Athena support for SQL queries?", "answer": "Athena supports various standard data formats including CSV, JSON, ORC, Avro, and Parquet.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-11T14:20:08.946054"}}
{"question": "How does Athena manage the information and schemas about databases and tables?", "answer": "Athena uses a managed AWS Glue Data Catalog to store information and schemas about the databases and tables. You can modify the catalog using DDL statements or through the AWS Management Console. Athena uses schema-on-read technology, which means that your table definitions are applied to your data in S3 when queries are being applied.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-11T14:20:08.946353"}}
{"question": "How does Athena's use of Trino and AWS Glue Data Catalog compare to its previous version using Presto and internal catalog?", "answer": "Athena's new approach in version 3 is to use Trino with the AWS Glue Data Catalog instead of the internal catalog used in version 2 and Presto. This approach allows for full standard SQL support, increased performance, and new features. Additionally, Athena's development team contributes bug fixes and enhancements back to the open-source Trino and PrestoDB projects, allowing anyone using these tools to benefit from Athena's contributions.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-2", "source_tokens": 399, "generated_at": "2026-02-11T14:20:08.946728"}}
{"question": "What are the three main components of AWS Glue?", "answer": "AWS Glue has three main components: 1) a crawler that automatically scans your data sources, identifies data formats, and infers schemas, 2) a fully managed ETL service that allows you to transform and move data to various destinations, and 3) a Data Catalog that stores metadata information about databases and tables.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-11T14:20:16.097814"}}
{"question": "How does upgrading to the AWS Glue Data Catalog benefit data management?", "answer": "Upgrading to the AWS Glue Data Catalog provides a unified metadata repository, allowing integration across various AWS services, and supports data stored in Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for PostgreSQL, Amazon Redshift, S3, MySQL and PostgreSQL databases in your Amazon VPC running on Amazon EC2. It also offers automatic schema and partition recognition, which can help automate table creation and partition loading.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-11T14:20:16.098121"}}
{"question": "What's the difference between the Athena Data Catalog and the AWS Glue Data Catalog?", "answer": "The Athena Data Catalog is an internal data catalog used by Athena, while the AWS Glue Data Catalog is a fully managed metadata repository that supports various data stores including Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for PostgreSQL, Amazon Redshift, S3, MySQL and PostgreSQL databases in your Amazon VPC running on Amazon EC2. AWS Glue also offers automatic schema and partition recognition, while Athena does not.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-3", "source_tokens": 438, "generated_at": "2026-02-11T14:20:16.098502"}}
{"question": "What data formats does Athena support for table creation?", "answer": "Athena supports various data formats like CSV, TSV, JSON, or Textfiles and also open-source columnar formats, such as ORC and Parquet. It also supports compressed data in Snappy, Zlib, LZO, and GZIP formats.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-11T14:20:21.806503"}}
{"question": "How does Athena handle table schemas?", "answer": "Athena uses an approach known as schema-on-read, which allows you to project your schema onto your data when you run a query. This means that the schema is stored in the Data Catalog and used when running queries, but it does not modify your data in S3.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-11T14:20:21.806838"}}
{"question": "What are the differences between Athena's methods for defining table schemas and running queries?", "answer": "Athena uses Apache Hive DDL to define tables and uses the Data Catalog to store the schema. When you run SQL queries, it uses Trino and Presto. Hive is used for DDL and creation/modification and deletion of tables or partitions, while Trino and Presto are used when running SQL queries on S3.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-4", "source_tokens": 502, "generated_at": "2026-02-11T14:20:21.807234"}}
{"question": "Which SerDe is used for interpreting CSV data in Athena?", "answer": "The SerDe used for interpreting CSV data in Athena is 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-11T14:20:26.956544"}}
{"question": "What's the difference between the SerDes used for parsing JSON data in Athena?", "answer": "Athena supports two SerDes for parsing JSON data: 'org.apache.hive.hcatalog.data.JsonSerDe' and 'org.openx.data.jsonserde.JsonSerDe'. Though both are used for JSON parsing, they might have slight differences in their functionality or performance.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-11T14:20:26.956814"}}
{"question": "Why do we need to add partitions to data in Athena?", "answer": "Adding partitions to data in Athena enhances performance by making it easier for Athena to locate specific pieces of data within the S3 bucket. Partitions allow data to be organized and queried more efficiently.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-5", "source_tokens": 459, "generated_at": "2026-02-11T14:20:26.957281"}}
{"question": "What column can you partition your data on using Athena?", "answer": "You can partition your data on any column with Athena.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T14:20:31.887169"}}
{"question": "How does partition indexes in AWS Glue Data Catalog optimize query planning in Athena?", "answer": "Partition indexes in AWS Glue Data Catalog reduce the time required to retrieve and filter partition metadata for tables with large numbers of partitions, optimizing query planning and reducing query runtime in Athena.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T14:20:31.887432"}}
{"question": "What's the difference between running a metadata query in Athena after new data becomes available and adding the new data to an existing prefix?", "answer": "When your data is partitioned, you need to run a metadata query (ALTER TABLE ADD PARTITION) to add the partition to Athena after new data becomes available on S3. If your data is not partitioned, adding the new data (or files) to the existing prefix automatically adds the data to Athena.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T14:20:31.887570"}}
{"question": "What data formats does Athena support for improved query performance and lower cost?", "answer": "Athena supports open-source columnar data formats, such as Parquet and ORC.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-11T14:20:36.130835"}}
{"question": "How can writing UDFs in Athena enhance query performance and functionality?", "answer": "Writing UDFs in Athena allows for custom processing, such as compressing and decompressing data, redacting sensitive data, or applying customized decryption. UDFs can be invoked in SELECT and FILTER clauses of a SQL query.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-11T14:20:36.131177"}}
{"question": "What is the difference between using Athena to query data directly from other cloud storage services versus moving and transforming the data to S3?", "answer": "Using Athena to query data in place allows for analysis without moving or transforming the data, while building pipelines to extract and store data on S3 allows for more comprehensive and unified data analysis.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-7", "source_tokens": 484, "generated_at": "2026-02-11T14:20:36.131498"}}
{"question": "Which SQL queries can I run on data sources using Athena?", "answer": "You can run SQL queries on data sources using Athena to extract and transform data, or perform quick analysis.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-11T14:20:40.591406"}}
{"question": "How does Athena simplify the process of performing analytics on diverse data sources?", "answer": "Athena simplifies the process of performing analytics on diverse data sources by allowing you to run SQL queries on the data where it is, eliminating the need to learn new programming languages or database constructs and build complex pipelines.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-11T14:20:40.591731"}}
{"question": "How does Athena compare to other tools for querying data from multiple sources?", "answer": "Athena allows you to query data across multiple data sources using SQL and built-in connectors, whereas other tools may require learning new languages or constructs and building complex pipelines to extract, transform, and duplicate data.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-8", "source_tokens": 340, "generated_at": "2026-02-11T14:20:40.592247"}}
{"question": "What data sources can you extract insights from using Athena and SQL?", "answer": "With Athena, you can extract insights from various data sources by performing on-demand analysis on data spread across multiple data stores using SQL.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:20:45.290937"}}
{"question": "How does Athena allow users to perform complex tasks with ML models?", "answer": "Athena allows users to invoke their SageMaker AI models in SQL queries to run inference, making complex tasks such as anomaly detection, customer cohort analysis, and sales predictions as simple as writing a SQL query.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:20:45.291210"}}
{"question": "What's the difference between federated queries and creating tables in Athena?", "answer": "Federated queries allow you to run SQL queries on data in external data sources without having to copy the data into Athena first. Creating tables in Athena, on the other hand, stores query results in S3 for future use.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:20:45.291689"}}
{"question": "What industry do financial risk data analysts belong to and what tasks can they perform using Athena and SageMaker?", "answer": "Financial risk data analysts belong to the financial industry and they can use Athena and SageMaker for what-if analysis, Monte Carlo simulations, and running linear regression or forecasting models to predict future values. They can invoke any ML model that is deployed on SageMaker for these tasks.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T14:20:51.740993"}}
{"question": "In what scenarios would you recommend training your own ML model in SageMaker versus using a pretrained model?", "answer": "You would recommend training your own ML model in SageMaker when you want to make domain-specific or industry-specific predictions and categorize new records into the same categories that you used for previous records. Alternatively, for undifferentiated ML needs or when the training data is publicly available, you could use a pretrained model that is deployed on SageMaker.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T14:20:51.741257"}}
{"question": "How does invoking an ML model for query in Athena differ from training and deploying an ML model on SageMaker?", "answer": "Invoking an ML model for query in Athena means using a pre-existing model that is deployed on SageMaker for inference, while training and deploying an ML model on SageMaker involves creating your own model using your proprietary data and deploying it for use.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T14:20:51.741412"}}
{"question": "What phase can you run ML inference in Athena?", "answer": "You can run ML inference in Athena in the Select phase or in the Filter phase.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-11T14:20:55.521721"}}
{"question": "How does SageMaker AI handle machine learning predictions for industry-specific data?", "answer": "SageMaker AI typically handles machine learning predictions for industry-specific data by allowing users to train their own models on their own data.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-11T14:20:55.521956"}}
{"question": "What type of machine learning predictions is more likely to use external models in SageMaker AI?", "answer": "Machine learning predictions for undifferentiated needs, such as machine translation, are more likely to use external models in SageMaker AI.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-11", "source_tokens": 248, "generated_at": "2026-02-11T14:20:55.522306"}}
{"question": "What file formats does Amazon Athena support for fine-grained access control with the Amazon SageMaker data lakehouse?", "answer": "Amazon Athena supports fine-grained access control for data stored in any supported file format using table formats such as Apache Iceberg, Apache Hudi, Apache Hive, and federated data sources that are registered with the lakehouse in Amazon SageMaker.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-11T14:21:01.992196"}}
{"question": "How does the Amazon SageMaker data lakehouse help with fine-grained access control in Amazon Athena?", "answer": "The Amazon SageMaker data lakehouse lets you centrally manage permissions and access control for data catalog resources. With this, you can enforce fine-grained access control policies in Athena queries. Regardless of table format or federated query data source type, you can use the same feature set in the lakehouse to govern your data.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-11T14:21:01.992462"}}
{"question": "What are the differences in access control between using IAM policies and S3 bucket policies in Amazon Athena with the Amazon SageMaker data lakehouse?", "answer": "IAM policies allow you to grant IAM users fine-grained control to your S3 buckets. By controlling access to data on S3, you can restrict users from querying it using Athena. S3 bucket policies, on the other hand, are used to control access to objects in the bucket.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-12", "source_tokens": 337, "generated_at": "2026-02-11T14:21:01.992960"}}
{"question": "What file formats does Amazon Athena support for fine-grained access control with AWS Lake Formation?", "answer": "Amazon Athena supports table formats such as Apache Iceberg, Apache Hudi, and Apache Hive for fine-grained access control with AWS Lake Formation.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-11T14:21:07.115120"}}
{"question": "How can you use AWS Lake Formation to control access to data in Amazon Athena?", "answer": "You can use AWS Lake Formation to enforce fine-grained access control policies in Athena queries for data stored in any supported file format. This allows you to restrict users from querying data using Athena based on access control policies set in Lake Formation.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-11T14:21:07.115354"}}
{"question": "What are the differences between server-side encryption, client-side encryption, and AWS KMS encryption for Athena queries?", "answer": "Server-side encryption is provided by S3-managed encryption keys, client-side encryption uses keys managed by AWS KMS, and Athena also integrates with AWS KMS to encrypt your result sets.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-13", "source_tokens": 505, "generated_at": "2026-02-11T14:21:07.115540"}}
{"question": "What is the pricing model for per query billing in Athena and how does it differ from compute-based billing?", "answer": "With per query billing, Athena charges based on the amount of data scanned per query, while with compute-based billing, you pay an hourly price for query processing capacity. Per query billing is based on the amount of data scanned, in terabytes (TB), while compute-based billing does not depend on data scanned.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-11T14:21:13.357552"}}
{"question": "How does compressing, partitioning, and converting data to columnar formats affect the cost and performance of Athena queries with per query billing?", "answer": "These operations allow Athena to scan and process less data, leading to cost savings and improved performance. Compressing data can save up to 30% to 90% per query, while converting data to columnar formats can further reduce the amount of data scanned and execution time. These operations are recommended when using both per query billing and compute-based billing.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-11T14:21:13.357884"}}
{"question": "What happens if you cancel a query with per query billing and how are you charged?", "answer": "If you cancel a query with per query billing, you are charged for the amount of data scanned up to the point at which you canceled the query.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-14", "source_tokens": 504, "generated_at": "2026-02-11T14:21:13.358316"}}
{"question": "What is Athena's separate charge for using Data Catalog?", "answer": "You are charged separately for using Data Catalog in Athena. For more information about Data Catalog pricing, review the AWS Glue pricing page.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-11T14:21:19.556050"}}
{"question": "How does using Athena for Apache Spark enhance the analytics experience compared to traditional Spark setup?", "answer": "Using Athena for Apache Spark offers a simplified and purpose-built Spark experience with automatic performance tuning, machine configurations, and software patching, allowing for faster application runs and reduced work required for version upgrades. It also offers a tight integration with other AWS services, specifically Data Catalog, allowing for creating Spark applications on data in S3 data lakes by referencing tables from your Data Catalog.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-11T14:21:19.556381"}}
{"question": "What are the benefits of using Athena for Apache Spark over traditional Spark setup in terms of integration and performance?", "answer": "Using Athena for Apache Spark offers a simplified and purpose-built Spark experience with automatic performance tuning, machine configurations, and software patching, resulting in faster application runs and reduced work required for version upgrades. It also provides tight integration with other AWS services, specifically Data Catalog, allowing for creating Spark applications on data in S3 data lakes by referencing tables from your Data Catalog.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-15", "source_tokens": 424, "generated_at": "2026-02-11T14:21:19.556587"}}
{"question": "What is the hourly rate for using a single DPU for an Apache Spark application in Athena?", "answer": "The hourly rate for using a single DPU for an Apache Spark application in Athena is not explicitly stated in the context, but you are charged based on the number of Data Processing Units (DPUs) used and a single DPU provides 4 vCPU and 16 GB of memory.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T14:21:24.810018"}}
{"question": "How does Athena for Apache Spark handle Spark version updates?", "answer": "Athena for Apache Spark is based on the stable Spark 3.2 release and will provide a custom build of Spark. It will handle most Spark version updates automatically in a backward-compatible way without requiring your involvement.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T14:21:24.810259"}}
{"question": "What is the difference between the charges for notebook nodes and Spark driver and worker nodes in Athena?", "answer": "Athena does not charge for the notebook nodes used during the Spark session. However, it will charge you for driver and worker nodes during the duration of the session.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T14:21:24.810446"}}
{"question": "What tool provides the fastest query performance for enterprise reporting and business intelligence workloads?", "answer": "Amazon Redshift", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-11T14:21:29.196518"}}
{"question": "How does Amazon EMR simplify the process of running distributed processing frameworks compared to on-premises deployments?", "answer": "Amazon EMR makes it cost-effective to run highly distributed processing frameworks, such as Apache Hadoop, Spark, and Presto, compared to on-premises deployments.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-11T14:21:29.196784"}}
{"question": "How does the query performance of Amazon Redshift compare to Amazon Athena for running interactive queries for data in S3?", "answer": "Amazon Redshift provides faster query performance for enterprise reporting and business intelligence workloads with complex SQL and multiple joins and subqueries, while Amazon Athena offers a simplified way to run interactive queries for data in S3 without the need to manage servers.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-17", "source_tokens": 184, "generated_at": "2026-02-11T14:21:29.196920"}}
{"question": "What kind of workloads is Amazon Redshift optimized for?", "answer": "Amazon Redshift is optimized for complex BI and analytics workloads, particularly those involving extremely complex SQL with multiple joins and subqueries.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-11T14:21:33.530824"}}
{"question": "How does Amazon Athena differ from Amazon Redshift in terms of workload suitability?", "answer": "Amazon Athena is well suited for interactive analytics and data exploration, while Amazon Redshift is optimized for complex BI and analytics workloads with large and structured datasets.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-11T14:21:33.531146"}}
{"question": "How does the architecture of Amazon Redshift enable better price performance?", "answer": "Amazon Redshift's Massively Parallel Processing (MPP) architecture separates storage and compute, and its machine learning-led automatic optimization capabilities enable the best price performance at any scale.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-18", "source_tokens": 502, "generated_at": "2026-02-11T14:21:33.531656"}}
{"question": "What type of data processing tasks can be performed using Amazon EMR?", "answer": "Amazon EMR can be used for various scale-out data processing tasks such as machine learning, graph analytics, data transformation, streaming data, and running custom code with the latest big data processing frameworks like Apache HBase, Spark, Hadoop, or Presto.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-11T14:21:39.015344"}}
{"question": "How does Amazon EMR differ from Amazon Athena in terms of data processing?", "answer": "Amazon EMR allows you to run custom code and use the latest big data processing frameworks to process and analyze large datasets with full control over infrastructure and clusters. On the other hand, Amazon Athena is designed for running interactive SQL queries against data on S3 without requiring any infrastructure or cluster management.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-11T14:21:39.015949"}}
{"question": "What are the use cases for Amazon EMR in data processing?", "answer": "Amazon EMR can be used for a wide range of data processing tasks beyond just running SQL queries. These include machine learning, graph analytics, data transformation, streaming data, and running custom code with big data processing frameworks. It's ideal for handling large datasets and providing full control over the configuration of clusters and software installed on them.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-19", "source_tokens": 145, "generated_at": "2026-02-11T14:21:39.016168"}}
{"question": "What are the benefits of using EMR Serverless for running Spark and Hive applications?", "answer": "EMR Serverless allows users to eliminate operational overhead, only pay for used resources, and get 2x+ faster performance. It is also 100% API compatible with standard open source and does not require deep Spark expertise.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-11T14:21:43.682018"}}
{"question": "How does EMR Serverless compare to EMR clusters in terms of management and control?", "answer": "EMR Serverless is suitable for customers who want to avoid managing and operating clusters, while EMR clusters offer maximum control and flexibility over how to run applications.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-11T14:21:43.682381"}}
{"question": "Which AWS service is best for customers who want an instant on, interactive experience for Apache Spark applications?", "answer": "Amazon Athena for Apache Spark is best for customers who want an interactive experience similar to Amazon Athena and require short runtimes and sub-second startup time.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-20", "source_tokens": 453, "generated_at": "2026-02-11T14:21:43.682783"}}
{"question": "Which data formats does Athena support that Amazon EMR also does?", "answer": "Athena supports many of the same data formats as Amazon EMR.", "question_type": "factual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-11T14:21:48.747825"}}
{"question": "How can Athena's federated query feature benefit users with existing Hive metastores?", "answer": "Athena's federated query feature allows users to run SQL queries across various data sources unifiedly. If they already have a Hive metastore, they can run DDL statements on Athena and start querying their data without impacting Amazon EMR jobs.", "question_type": "conceptual", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-11T14:21:48.748191"}}
{"question": "How does the functionality of Athena's federated query compare to Amazon EMR when it comes to handling Hive metastores?", "answer": "Athena's federated query allows users to run SQL queries across various data sources unifiedly when they have existing Hive metastores. In contrast, Amazon EMR processes data using distributed computing and doesn't directly support the functionality of querying data with Hive metastores using federated queries.", "question_type": "comparison", "metadata": {"service": "ATHENA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "athena-faq-21", "source_tokens": 161, "generated_at": "2026-02-11T14:21:48.748616"}}
{"question": "What industry standards and regulations can AWS Audit Manager help map my AWS usage to?", "answer": "AWS Audit Manager can help map your AWS usage to industry standards and regulations such as HIPAA, GDPR, PCI DSS, and CIS AWS Foundations Benchmark.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T14:21:53.616190"}}
{"question": "How does AWS Audit Manager simplify the audit process for organizations?", "answer": "AWS Audit Manager simplifies the audit process for organizations by automating evidence collection, organizing it for assessment, and enabling collaboration between teams, making it easier to assess if policies, procedures, and activities are operating effectively.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T14:21:53.616527"}}
{"question": "What is the difference between using a prebuilt framework and making an editable copy in AWS Audit Manager?", "answer": "Using a prebuilt framework in AWS Audit Manager provides mappings of AWS resources to control requirements for well-known industry standards and regulations. Making an editable copy allows you to modify the framework and its controls to meet unique business requirements.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T14:21:53.616879"}}
{"question": "What pricing model does AWS Audit Manager follow?", "answer": "AWS Audit Manager is priced based on the number of resource assessments executed per account per region.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-11T14:21:57.595934"}}
{"question": "What role does AWS Security Hub play in relation to AWS Audit Manager?", "answer": "AWS Security Hub is used to continuously monitor and improve the security posture of AWS accounts and resources, and its automated security checks are used by AWS Audit Manager to collect evidence for assessment reports. They complement each other as Security Hub focuses on generating automated evidence and Audit Manager covers a full set of controls in each supported framework.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-11T14:21:57.596196"}}
{"question": "How does the pricing of AWS Audit Manager differ from AWS Security Hub?", "answer": "AWS Audit Manager pricing is based on the number of resource assessments executed per account per region, while the pricing for AWS Security Hub is not mentioned in the context.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-1", "source_tokens": 479, "generated_at": "2026-02-11T14:21:57.596627"}}
{"question": "Which regions does AWS Audit Manager provide service in?", "answer": "AWS Audit Manager is a regional service, with availability listed on the AWS Regional Services List.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T14:22:01.547162"}}
{"question": "How does AWS Audit Manager help with regulatory compliance?", "answer": "AWS Audit Manager provides prebuilt standard frameworks based on AWS best practices for various regulations and industry standards, such as PCI DSS, HIPAA, GDPR, and more.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T14:22:01.547451"}}
{"question": "What is the difference between AWS Audit Manager's evidence storage and S3?", "answer": "AWS Audit Manager stores evidence in its own managed storage repository with read-only permissions to end-users, while assessment reports (summaries and evidence folders) can be generated and stored in S3.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T14:22:01.547631"}}
{"question": "What is a control in the context of AWS Audit Manager?", "answer": "A control is a prescriptive description that explains how to implement a procedure to conform to a given rule or compliance requirement.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-11T14:22:06.492260"}}
{"question": "How does AWS Audit Manager help you manage controls for compliance?", "answer": "AWS Audit Manager enables you to define your own controls to collect evidence from specific data sources, helping you meet unique compliance requirements. It automatically assesses resources and services based on the controls defined in the framework, collects evidence, and converts it into an auditor-friendly format.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-11T14:22:06.492634"}}
{"question": "What is the difference between a common control and a resource assessment?", "answer": "A common control is a set of one or more core controls that collect evidence from a predefined group of AWS managed data sources and can support a range of overlapping compliance obligations. A resource assessment is a process that collects, stores, and manages evidence for individual resources, such as Amazon EC2 instances or Amazon RDS instances.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-3", "source_tokens": 456, "generated_at": "2026-02-11T14:22:06.492824"}}
{"question": "What can you do after selecting the AWS accounts when launching an assessment in AWS Audit Manager?", "answer": "After selecting the AWS accounts when launching an assessment in AWS Audit Manager, you can focus on reviewing the relevant evidence to ensure your controls are working as intended.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-11T14:22:11.222416"}}
{"question": "What features does AWS Audit Manager offer to help manage stakeholder reviews of controls?", "answer": "AWS Audit Manager offers the delegation feature that enables you to assign controls in your assessment to a subject matter expert to review. After reviewing and selecting the relevant evidence, you are ready to build an audit-ready report.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-11T14:22:11.222770"}}
{"question": "How does the evidence collection and organization process in AWS Audit Manager compare to the traditional manual process?", "answer": "AWS Audit Manager saves you time by automatically collecting and organizing evidence as defined by each control requirement, while in traditional manual processes, you would need to manually collect and organize the evidence yourself.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-4", "source_tokens": 496, "generated_at": "2026-02-11T14:22:11.222919"}}
{"question": "What is the role of the framework library in AWS Audit Manager?", "answer": "The framework library is the central place from which you can access and manage frameworks in AWS Audit Manager. It contains a catalog of standard frameworks pre-built by Audit Manager and custom frameworks you define.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-11T14:22:16.242370"}}
{"question": "How can you create a custom framework in AWS Audit Manager?", "answer": "You can create a custom framework in AWS Audit Manager by making an editable copy of an existing framework or creating a new framework from scratch. When creating a custom framework, you can add controls from the Audit Manager control library and organize them into control sets.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-11T14:22:16.242622"}}
{"question": "What are the differences between creating a custom framework and a custom control in AWS Audit Manager?", "answer": "Both custom frameworks and custom controls can be created in AWS Audit Manager. A custom framework is a collection of controls that you organize to meet your unique requirements, while a custom control is an individual control that you define with its name, description, testing information, and evidence sources.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-5", "source_tokens": 267, "generated_at": "2026-02-11T14:22:16.242797"}}
{"question": "What types of data sources can AWS Audit Manager automatically collect evidence from?", "answer": "AWS Audit Manager can automatically collect evidence from four types of data sources: AWS CloudTrail, AWS Security Hub, AWS Config, and AWS API calls.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T14:22:20.175780"}}
{"question": "How does using AWS managed sources in AWS Audit Manager benefit a user?", "answer": "Using AWS managed sources in AWS Audit Manager allows for automatic updates to all custom controls that use these sources, as they are predefined groupings of data sources that represent a common or core control.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T14:22:20.176040"}}
{"question": "How frequently is daily configuration data evidence captured compared to weekly and monthly evidence?", "answer": "Daily configuration data evidence is captured more frequently than weekly and monthly evidence.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T14:22:20.176427"}}
{"question": "What services does AWS Audit Manager automatically analyze findings from?", "answer": "AWS Audit Manager automatically analyzes findings from AWS Security Hub, AWS CloudTrail, AWS Config, and AWS Control Tower.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-11T14:22:24.759496"}}
{"question": "How does AWS Audit Manager enhance the capabilities of the mentioned AWS services?", "answer": "AWS Audit Manager adds annotations to the collected data from the mentioned AWS services (Security Hub, CloudTrail, Config, and Control Tower) to generate evidence automatically for the respective services and their monitored resources.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-11T14:22:24.759713"}}
{"question": "How does AWS Audit Manager compare the analysis of AWS Security Hub and AWS CloudTrail?", "answer": "The context does not provide enough information to compare the analysis of AWS Security Hub and AWS CloudTrail. Both services have different focuses: Security Hub monitors environments based on best practices and industry standards, while CloudTrail logs and monitors account activity.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-7", "source_tokens": 440, "generated_at": "2026-02-11T14:22:24.759894"}}
{"question": "What service does AWS offer for making foundation models available through an API and enabling private tuning with organizational data?", "answer": "AWS provides a fully managed service called AWS AI/ML (Amazon SageMaker) for making foundation models from various AI companies available through an API and enabling private tuning with organizational data.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-11T14:22:29.978271"}}
{"question": "How can you use AWS AI/ML with AWS Audit Manager for collecting evidence of compliance with intended policies?", "answer": "You can deploy the best practices framework provided by AWS Audit Manager in the accounts where you are running your generative AI models and applications in AWS AI/ML. This will help monitor compliance with intended policies by collecting evidence.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-11T14:22:29.978631"}}
{"question": "What's the difference between AWS AI/ML and AWS Audit Manager in terms of functionality?", "answer": "AWS AI/ML is a fully managed service that makes foundation models available through an API and enables private tuning with organizational data. AWS Audit Manager, on the other hand, provides a generative AI best practices framework for monitoring compliance with intended policies in the accounts where you are running your generative AI models and applications.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-8", "source_tokens": 103, "generated_at": "2026-02-11T14:22:29.979099"}}
{"question": "What can you do with the integration of AWS Audit Manager and MetricStream?", "answer": "You can import evidence of your AWS usage and configurations directly from Audit Manager into MetricStream CyberGRC.", "question_type": "factual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-11T14:22:33.087007"}}
{"question": "How does the integration of AWS Audit Manager and MetricStream benefit you conceptually?", "answer": "It allows you to manage your AWS auditing and GRC needs in one place, streamlining the process.", "question_type": "conceptual", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-11T14:22:33.087334"}}
{"question": "How does the integration of AWS Audit Manager with MetricStream compare to manually importing data?", "answer": "It provides a more efficient and integrated solution, eliminating the need to manually import data between the two systems.", "question_type": "comparison", "metadata": {"service": "AUDIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "audit-faq-9", "source_tokens": 76, "generated_at": "2026-02-11T14:22:33.087729"}}
{"question": "What is Amazon Augmented AI (A2I) and how does it make machine learning development easier?", "answer": "Amazon Augmented AI (A2I) is a service that simplifies the process of building human review workflows for machine learning applications. It provides built-in workflows for common use cases like content moderation and text extraction, allowing predictions from services like Amazon Rekognition and Amazon Textract to be reviewed easily. Developers can also create custom workflows for ML models built on Amazon SageMaker or other tools. Amazon A2I handles complex processes, custom software management, and large reviewer groups, making it easier for developers to focus on their ML projects.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-11T14:22:41.570475"}}
{"question": "What are the benefits of using third-party human review service providers instead of building in-house human review systems?", "answer": "Using third-party human review service providers through Amazon A2I offers several benefits. It saves time and resources as Amazon A2I handles the implementation of complex processes, writing custom software to manage review tasks and results, and managing large reviewer groups. It also allows predictions from various machine learning models to be reviewed easily, providing the flexibility to choose the most appropriate workflow for specific use cases.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-11T14:22:41.570848"}}
{"question": "How does Amazon Augmented AI (A2I) compare to building in-house human review systems?", "answer": "Amazon Augmented AI (A2I) differs from building in-house human review systems by providing a managed service that simplifies the process of building and managing workflows for human review of machine learning predictions. Amazon A2I offers pre-built human review workflows for common machine learning use cases, such as content moderation and text extraction, making it easier to set up and manage review processes for predictions from services like Amazon Rekognition and Amazon Textract. Additionally, Amazon A2I handles the complexity of managing large reviewer groups and software development, allowing developers to focus on their ML projects.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-0", "source_tokens": 363, "generated_at": "2026-02-11T14:22:41.571358"}}
{"question": "What is the first step to create a human review workflow in Amazon A2I?", "answer": "The first step is to provide a pointer to the S3 bucket where the review results should be stored.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T14:22:45.478348"}}
{"question": "How can I define conditions for triggering human reviews in Amazon A2I?", "answer": "You can define conditions based on machine learning prediction confidence, business rules, or form key detection confidence.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T14:22:45.478612"}}
{"question": "What are the three workforce options available in Amazon A2I for human review tasks?", "answer": "The options are: (1) Amazon Mechanical Turk, (2) Third party data labeling service providers available through the AWS Marketplace, and (3) Your own employees.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T14:22:45.479051"}}
{"question": "What security controls does a human review service provider need to maintain to secure customer data according to the text?", "answer": "A human review service provider is required to maintain various security controls to secure customer data. These include SOC 2 compliance and certification, Technology Controls such as blocking attempts to download or copy files and preventing unauthorized access to systems, Network Security Controls like prohibiting remote access to customer data and blocking peer-to-peer file sharing software, Employee Controls including having Non-Disclosure Agreements with employees and preventing employees from storing or copying customer task-related data outside of secure environments, and Physical Access Controls ensuring physical access control measures to prevent unauthorized access to their production site.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-11T14:22:53.200002"}}
{"question": "What are the differences in security controls between human review service providers and service providers not undergoing remote work during the COVID-19 pandemic according to the text?", "answer": "According to the text, human review service providers are required to maintain specific security controls including SOC 2 compliance and various other technical, network, employee, and physical access controls to secure customer data. During the COVID-19 pandemic, some service providers have implemented a remote work policy and have updated their AWS Marketplace listings to reflect that they cannot process customer data from remote work environments without explicit customer consent. These service providers may not be able to maintain the same level of security controls as human review service providers who are not undergoing remote work.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-11T14:22:53.200359"}}
{"question": "What specific security control does the text mention for preventing unauthorized access to a service provider's system?", "answer": "The text mentions that service providers are required to utilize the appropriate software to block any attempts to download or copy files/data from their system and prevent unauthorized access to their systems.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-2", "source_tokens": 511, "generated_at": "2026-02-11T14:22:53.200557"}}
{"question": "What information does AWS require service providers to provide for SOC 2 certification before being listed in the marketplace?", "answer": "AWS requires service providers to provide their SOC 2 certification reports, including information on the authenticity of the auditor, report period, and production site verification.", "question_type": "factual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-11T14:22:58.155051"}}
{"question": "Why is SOC 2 certification important for service providers in the AWS Marketplace?", "answer": "SOC 2 certification is important for service providers in the AWS Marketplace because it helps ensure they meet mandatory security standards and maintain the security of customer information.", "question_type": "conceptual", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-11T14:22:58.155312"}}
{"question": "How does the process for handling security incidents by service providers in the AWS Marketplace differ from the process for removing listings?", "answer": "When a security incident occurs, the service provider must inform AWS and affected customers within 24 hours and provide written details of the internal investigation. In contrast, if a service provider fails to meet security standards, their listing will be removed from the AWS Marketplace within 24 hours and all affected customers will be notified by email.", "question_type": "comparison", "metadata": {"service": "AUGMENTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "augmented-faq-3", "source_tokens": 241, "generated_at": "2026-02-11T14:22:58.155499"}}
{"question": "What are the key features of AWS Auto Scaling for managing infrastructure costs and performance?", "answer": "AWS Auto Scaling is a service that optimizes the performance of applications while lowering infrastructure costs. It allows users to scale collections of related resources with just a few clicks, configure consistent scaling policies across the infrastructure stack, and automate resource scaling based on selected strategies for availability, costs, or a balance of both.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-11T14:23:03.458489"}}
{"question": "How does AWS Auto Scaling help in maintaining performance?", "answer": "AWS Auto Scaling maintains performance by continually monitoring resources underlying an application and automatically increasing capacity when demand spikes to prevent high quality of service issues.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-11T14:23:03.458743"}}
{"question": "In what ways does AWS Auto Scaling differ from other scaling solutions, such as manual scaling or other AWS services?", "answer": "AWS Auto Scaling provides a unified scaling experience for all scalable resources, allows users to automate scaling decisions based on selected strategies, and continually monitors resources to maintain performance, whereas manual scaling requires constant monitoring and other AWS services like Elastic Load Balancing and Amazon RDS require additional setup and configuration.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-0", "source_tokens": 454, "generated_at": "2026-02-11T14:23:03.459112"}}
{"question": "What resource types can AWS Auto Scaling scale based on the given text?", "answer": "AWS Auto Scaling can scale one or more EC2 Auto Scaling groups and DynamoDB tables.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T14:23:08.050497"}}
{"question": "How does AWS Auto Scaling work to scale resources based on the text?", "answer": "AWS Auto Scaling creates a scaling plan for your application, defining how each resource should be scaled. For each resource, it creates a target tracking scaling policy with the most popular metric for that resource type and keeps it at a target value based on the selected scaling strategy.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T14:23:08.050768"}}
{"question": "How does the scaling of EC2 Auto Scaling groups compare to DynamoDB tables in AWS Auto Scaling?", "answer": "Both EC2 Auto Scaling groups and DynamoDB tables can be scaled using AWS Auto Scaling. However, the scaling strategies and metrics used may differ between the two resource types.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T14:23:08.051166"}}
{"question": "What service helps ensure the correct number of Amazon EC2 instances for handling application load?", "answer": "Amazon EC2 Auto Scaling", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-11T14:23:11.730422"}}
{"question": "How does Application Auto Scaling help in managing different AWS resources?", "answer": "Application Auto Scaling allows you to define scaling policies and schedule scaling actions for various AWS resources such as Amazon ECS services, Amazon EC2 Spot fleets, Amazon EMR clusters, and Amazon DynamoDB tables.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-11T14:23:11.730693"}}
{"question": "What are the key benefits of using Application Auto Scaling for scaling resources other than EC2?", "answer": "Application Auto Scaling provides better fault tolerance, availability, and cost management for scaling resources other than EC2.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-2", "source_tokens": 255, "generated_at": "2026-02-11T14:23:11.731186"}}
{"question": "What is the benefit of using AWS Auto Scaling over EC2 Auto Scaling for managing scaling for multiple resources?", "answer": "AWS Auto Scaling allows for unified scaling for multiple resources, includes predefined guidance for easier and faster setup, and offers predictive scaling for EC2 resources.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:23:16.754077"}}
{"question": "What is Predictive Scaling in AWS Auto Scaling and how does it work?", "answer": "Predictive Scaling is a feature of AWS Auto Scaling that uses machine learning models to forecast daily and weekly traffic patterns and schedules changes in the number of EC2 instances accordingly.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:23:16.754426"}}
{"question": "How does AWS Auto Scaling with Predictive Scaling compare to EC2 Auto Scaling in terms of capacity provisioning?", "answer": "AWS Auto Scaling with Predictive Scaling delivers faster, simpler, and more accurate capacity provisioning by provisioning EC2 instances in advance of changing traffic, while EC2 Auto Scaling requires manual setup of step scaling policies or scheduled scaling.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T14:23:16.754864"}}
{"question": "What resources can be included in a scaling plan?", "answer": "A scaling plan can include multiple AWS resources, specifically EC2 resources in this context.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-11T14:23:21.117768"}}
{"question": "How does Predictive Scaling work in relation to target tracking?", "answer": "Predictive Scaling sets the minimum capacity for your application based on forecasted traffic, while target tracking changes the actual capacity based on the current traffic. They work together to generate a scaling plan.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-11T14:23:21.118027"}}
{"question": "What's the difference between Predictive Scaling and Dynamic Scaling in terms of configuration in a scaling plan?", "answer": "Predictive Scaling and Dynamic Scaling can be configured separately in a scaling plan, with Predictive Scaling relying on historical data for traffic forecasts and Dynamic Scaling adjusting capacity based on current resource utilization.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-4", "source_tokens": 494, "generated_at": "2026-02-11T14:23:21.118426"}}
{"question": "What resources can be scaled using AWS Auto Scaling?", "answer": "AWS Auto Scaling can be used to setup scaling for Amazon EC2, Auto Scaling groups, Amazon Elastic Container Service (ECS) services, Amazon EC2 Spot Fleets, and Amazon DynamoDB throughput capacity.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T14:23:25.391958"}}
{"question": "Which AWS Auto Scaling options support Predictive Scaling?", "answer": "Predictive Scaling is available for AWS Auto Scaling for EC2 only.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T14:23:25.392260"}}
{"question": "How does the scalability method differ between AWS Auto Scaling and Amazon EC2 Auto Scaling?", "answer": "AWS Auto Scaling allows you to scale multiple resources across multiple services with a unified interface, while Amazon EC2 Auto Scaling can only scale one Auto Scaling group at a time.", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T14:23:25.392775"}}
{"question": "What metrics and thresholds does AWS Auto Scaling base its recommendations on?", "answer": "AWS Auto Scaling bases its scaling recommendations on the most popular scaling metrics and thresholds used for Auto Scaling.", "question_type": "factual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-11T14:23:30.462534"}}
{"question": "How can you discover resources to be scaled by AWS Auto Scaling?", "answer": "You can either select an AWS CloudFormation stack or select resources based on common resource tag(s) for AWS Auto Scaling to discover.", "question_type": "conceptual", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-11T14:23:30.462781"}}
{"question": "Which regions provide AWS Auto Scaling?", "answer": "AWS Auto Scaling is available in Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Sydney), Canada (Central), US West (Northern California), Europe (London), Europe (Frankfurt), EU (Paris), EU (Milan), US East (Virginia), US East (Ohio), US West (Oregon), EU (Ireland), and Asia Pacific (Singapore).", "question_type": "comparison", "metadata": {"service": "AUTOSCALING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "autoscaling-faq-6", "source_tokens": 318, "generated_at": "2026-02-11T14:23:30.463178"}}
{"question": "What is the full name of SFTP?", "answer": "Secure Shell (SSH) File Transfer Protocol", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:23:34.255047"}}
{"question": "How does AWS Transfer Family support file transfers?", "answer": "AWS Transfer Family offers fully managed support for file transfers over SFTP, AS2, FTPS, FTP, and web browsers directly into and out of Amazon S3 or Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:23:34.255414"}}
{"question": "What is the difference between FTP and FTPS?", "answer": "FTP is a network protocol used for file transfer without encryption, while FTPS is an extension to FTP that uses Transport Layer Security (TLS) to encrypt traffic.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:23:34.255828"}}
{"question": "What protocol does AS2 represent in the context of file transfers?", "answer": "AS2 stands for Applicability Statement 2, a network protocol used for secure and reliable transfer of business-to-business data over the public internet.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T14:23:39.519101"}}
{"question": "How does AWS Transfer Family help in managing B2B file transfers?", "answer": "AWS Transfer Family provides fully managed and secure connectivity options over SFTP, AS2, FTPS, FTP, and web browsers for B2B file transfers, eliminating the need for managing file transfer related infrastructure.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T14:23:39.519332"}}
{"question": "What are the differences between AS2 and FTPS in terms of file transfer protocols supported by AWS Transfer Family?", "answer": "Both AS2 and FTPS are secure file transfer protocols supported by AWS Transfer Family. AS2 is a network protocol used for the secure and reliable transfer of business-to-business data over the public internet, while FTPS (FTP Secure) is a secure variant of the File Transfer Protocol (FTP) that provides secure communication between clients and servers.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T14:23:39.519472"}}
{"question": "What protocols can I enable for my AWS Transfer Family server endpoint?", "answer": "You can enable SFTP, FTPS, and FTP protocols for your AWS Transfer Family server endpoint.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T14:23:44.642832"}}
{"question": "How does AWS Transfer Family simplify file transfer process?", "answer": "AWS Transfer Family simplifies file transfer process by providing a fully managed, highly available file transfer service with auto-scaling capabilities, eliminating the need for managing file transfer related infrastructure. Data is stored in Amazon S3 or Amazon EFS, allowing easy integration with other AWS services and meeting compliance requirements.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T14:23:44.643063"}}
{"question": "What's the difference between setting up AS2 and SFTP connectors for AWS Transfer Family?", "answer": "To set up AS2, you import certificates and private keys, create profiles, and pair up profile information using an agreement for receiving data and a connector for sending data. For SFTP connectors, you create a secret for storing credentials, create a connector, and use it to copy files between remote servers and Amazon S3.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T14:23:44.643416"}}
{"question": "What are the different clients and technologies used for FTPS and SFTP for secure file transfers?", "answer": "FTPS and SFTP are different protocols for secure file transfers. FTPS uses different clients for securing the transmission of commands and data, while SFTP uses a single channel for both commands and data, requiring fewer port openings. Examples of commonly used SFTP/FTPS clients include WinSCP, FileZilla, CyberDuck, lftp, and OpenSSH clients.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-11T14:23:51.295006"}}
{"question": "How does AS2 ensure secure transmission and delivery of messages compared to FTPS/SFTP?", "answer": "AS2 is a secure file transfer protocol that provides options to ensure identity of the sender and receiver, integrity of the message, and confirm whether the message was successfully delivered and decrypted by the receiver. This is different from FTPS and SFTP, which do not have built-in mechanisms for message disposition notification.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-11T14:23:51.295275"}}
{"question": "What are the benefits of using AS2 for secure file transfers in retail, e-commerce, and supply chain workflows?", "answer": "AS2 is a secure file transfer protocol that is prevalent in workflows operating in retail, e-commerce, payments, and supply chain for interacting with business partners. It provides proof to the sender that their message was delivered without being tampered in transit through its built-in mechanism for Message Disposition Notification (MDN).", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-3", "source_tokens": 471, "generated_at": "2026-02-11T14:23:51.295425"}}
{"question": "What protocol does Transfer Family support for SCP commands?", "answer": "Transfer Family supports SCP commands through the SFTP protocol.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T14:23:54.590649"}}
{"question": "How can you customize the user experience in Transfer Family?", "answer": "You can configure Transfer Family to display customized banners and Message of The Day (MOTD) to your users.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T14:23:54.590913"}}
{"question": "How does Transfer Family handle FTP and VPC hosting?", "answer": "Transfer Family only supports VPC hosting for FTP endpoints due to security concerns, as FTP transmits data in clear text. For internet-facing endpoints, you can use Amazon Route 53 or any DNS service to route traffic.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T14:23:54.591044"}}
{"question": "What documentation should I refer to in order to automate the creation of VPC resources to host an FTP server?", "answer": "Refer to the CloudFormation templates documentation for automating creation of VPC resources to host the endpoint during server creation.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-11T14:23:59.552112"}}
{"question": "How can I enable fixed IPs for my server endpoint?", "answer": "You can enable fixed IPs for your server endpoint by selecting the VPC hosted endpoint for your server and choosing the internet-facing option. This will allow you to attach Elastic IPs directly to the endpoint, which is assigned as the endpointâ€™s IP address.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-11T14:23:59.552338"}}
{"question": "What are the three options to restrict incoming traffic by usersâ€™ source IP address for a VPC hosted server endpoint?", "answer": "If you are hosting your server endpoint within VPC, you can use Security Groups or AWS Network Firewall. If you are a public EndpointType Transfer server and API Gateway to integrate your identity management system, you can also use AWS WAF.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-5", "source_tokens": 489, "generated_at": "2026-02-11T14:23:59.552719"}}
{"question": "What type of IP addresses are not supported for firewall whitelisting on the PUBLIC Endpoint?", "answer": "Fixed IP addresses are not supported for firewall whitelisting on the PUBLIC Endpoint.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-11T14:24:03.978878"}}
{"question": "Why should you use VPC hosted endpoints to assign static IP addresses instead of the PUBLIC endpoint type for firewall whitelisting?", "answer": "You should use VPC hosted endpoints to assign static IP addresses to enable firewall whitelisting because static IP addresses are not supported on the PUBLIC Endpoint type.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-11T14:24:03.979169"}}
{"question": "How does the support of different host key types for SFTP servers impact identifying the server?", "answer": "By supporting RSA, ED25519, and ECDSA host keys, up to three separate host keys can be used to identify your SFTP server.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-6", "source_tokens": 463, "generated_at": "2026-02-11T14:24:03.979330"}}
{"question": "What is the default firewall and router support for file transfers in AWS?", "answer": "File transfers traversing a firewall or a router are supported by default using extended passive connection mode (EPSV).", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-11T14:24:08.540178"}}
{"question": "How does the AWS Transfer Family web apps work for end-users to transfer data to and from Amazon S3?", "answer": "End-users can browse, upload, and download data stored in Amazon S3 using Transfer Family web apps, which are created independently of servers. Users are assigned to the web app and given permissions in S3 Access Grants.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-11T14:24:08.540566"}}
{"question": "What are the identity providers supported by AWS IAM Identity Center for connecting to Transfer Family web apps?", "answer": "IAM Identity Center supports connecting to Microsoft Active Directory, Okta Universal Directory, and Microsoft Entra ID (formerly Azure AD) as identity sources for Transfer Family web apps.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-7", "source_tokens": 416, "generated_at": "2026-02-11T14:24:08.541063"}}
{"question": "Which standard is used for automatic user and group information synchronization with IAM Identity Center?", "answer": "The System for Cross-domain Identity Management (SCIM) standard is used for automatic user and group information synchronization with IAM Identity Center.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T14:24:13.310574"}}
{"question": "How does the web app in S3 Access Grants use IAM credentials to securely access data in S3?", "answer": "The web app in S3 Access Grants uses temporary IAM credentials issued by S3 Access Grants to securely access data in S3.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T14:24:13.310801"}}
{"question": "What is the difference between the READWRITE, WRITE, and READ access levels in S3 Access Grants?", "answer": "The READ access level permits viewing and retrieving objects from S3, the WRITE access level permits writing to and deleting from S3, and the READWRITE access level permits both viewing and retrieving objects, and writing to and deleting from S3.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T14:24:13.311174"}}
{"question": "What is the Storage Browser for S3 used for?", "answer": "The Storage Browser for S3 is an open-source component that provides a simple interface for end users to access data stored in Amazon S3.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-11T14:24:17.842295"}}
{"question": "Why can you only have one directory or SAML 2.0 identity provider connected to IAM Identity Center at a time?", "answer": "You can only have one directory or one SAML 2.0 identity provider connected to IAM Identity Center at a time because IAM Identity Center only supports one identity source for a given account.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-11T14:24:17.842609"}}
{"question": "How does the SFTP connector validate the identity of a remote server?", "answer": "The SFTP connector validates the identity of a remote server by using the public portion of the server's host key to compare it to the host key uploaded to the connectorâ€™s configuration.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-9", "source_tokens": 453, "generated_at": "2026-02-11T14:24:17.842891"}}
{"question": "Which API commands can be used to list files on a remote SFTP server and retrieve files from the server?", "answer": "The StartDirectoryListing API command can be used to list files on a remote SFTP server. Once the file list is obtained, the StartFileTransfer API command can be used to retrieve specific files from the server.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-11T14:24:23.109875"}}
{"question": "What are some actions that can be performed using SFTP connectors?", "answer": "SFTP connectors can be used to list files stored in a directory on remote SFTP servers, retrieve files from remote SFTP servers and transfer files from Amazon S3 to a remote SFTP server. They can also be used to delete, rename or move files stored in the remote SFTP server.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-11T14:24:23.110221"}}
{"question": "How does the TestConnection API command help when using SFTP connectors?", "answer": "The TestConnection API command or console action can be used to test connectivity to the remote server when creating a new SFTP connector. This helps ensure that the connector is configured correctly and can establish a connection to the remote server.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-10", "source_tokens": 488, "generated_at": "2026-02-11T14:24:23.110683"}}
{"question": "What API does Amazon EventBridge Scheduler allow you to specify for scheduling file transfers?", "answer": "You can specify AWS Transfer Family's StartFileTransfer API or StartDirectoryListing API as the universal target for your schedule.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-11T14:24:27.753696"}}
{"question": "How can you invoke SFTP connector's StartFileTransfer action from your state machine?", "answer": "You can leverage Step Functionsâ€™ AWS SDK integrations to call the StartFileTransfer API and invoke SFTP connector's StartFileTransfer action directly from your state machine.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-11T14:24:27.754017"}}
{"question": "What is the difference between using Amazon EventBridge Scheduler and AWS Step Functions for file transfers?", "answer": "Amazon EventBridge Scheduler allows you to schedule file transfers using a specified API, while AWS Step Functions enables you to invoke the StartFileTransfer API directly from your state machine and orchestrate event-driven processing of transferred files.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-11", "source_tokens": 446, "generated_at": "2026-02-11T14:24:27.754538"}}
{"question": "What method can be used to retrieve the remote SFTP server's public host key using AWS Transfer Family connectors?", "answer": "You can create a connector without the host key information and then use the TestConnection API command or console action to scan the remote server's public host key. The returned host key can then be added to the connector's configuration.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T14:24:33.566514"}}
{"question": "What is the maximum number of concurrent connections that can be created by the connector for an SFTP server?", "answer": "The connector can create up to 5 concurrent connections to the remote SFTP server if the server supports concurrent sessions from the same user.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T14:24:33.566754"}}
{"question": "How does retrieving the remote server's host key information using AWS Transfer Family connectors compare to scanning the server before creating the connector using the ssh-keyscan utility?", "answer": "Both methods allow you to obtain the remote server's host key information, but the AWS Transfer Family connectors method involves creating a connector without the host key information initially and then using the TestConnection API command or console action to scan the remote server for the host key. In contrast, the ssh-keyscan utility method involves scanning the remote server before creating the connector.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T14:24:33.567196"}}
{"question": "What identity provider options does the service support for SFTP and FTPS authentication?", "answer": "The service supports three identity provider options: Service Managed, Microsoft Active Directory, and Custom Identity Providers.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-11T14:24:37.268339"}}
{"question": "Why should separate credentials be used for FTP and SFTP or FTPS?", "answer": "FTP transmits credentials in cleartext, while SFTP and FTPS encryption protect the credentials. To ensure security, it is recommended to isolate FTP credentials from SFTP or FTPS.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-11T14:24:37.268577"}}
{"question": "How does the service allow for the use of the same endpoint for multiple protocols while maintaining separate credentials?", "answer": "By using a single identity provider for authenticating clients connecting over either protocol, you can allow for the same endpoint to be used while maintaining separate credentials.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-13", "source_tokens": 391, "generated_at": "2026-02-11T14:24:37.268935"}}
{"question": "What identity provider can be used to authenticate users for SFTP, FTPS, and FTP?", "answer": "AWS Managed Microsoft AD, your on-premises environment, or self-managed AD in Amazon EC2 can be used as identity providers to authenticate users for SFTP, FTPS, and FTP.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-11T14:24:42.671159"}}
{"question": "How does the scope down policy work in the context of AD groups?", "answer": "The scope down policy is evaluated in runtime based on each user's information, such as their username. It can be used to provide access to unique prefixes in your bucket for each user based on their username. Additionally, a username can also be used to evaluate logical directory mappings.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-11T14:24:42.671462"}}
{"question": "How does custom mode (BYO) authentication compare to using an AWS Managed identity provider?", "answer": "Custom mode (BYO) authentication enables the use of an existing identity provider to manage end users for all protocol types (SFTP, FTPS, and FTP). It allows credentials to be stored in your corporate directory or an in-house identity datastore, making it a good choice for seamless migration of users. In contrast, using an AWS Managed identity provider requires you to manage your end users within AWS.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-14", "source_tokens": 439, "generated_at": "2026-02-11T14:24:42.671656"}}
{"question": "Which methods does AWS Transfer Family support for identity provider integration?", "answer": "AWS Transfer Family supports integration with an identity provider using AWS Lambda function or Amazon API Gateway.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-11T14:24:47.301335"}}
{"question": "Why should I use Amazon API Gateway instead of AWS Lambda for identity provider integration with AWS Transfer Family?", "answer": "You may consider using Amazon API Gateway for identity provider integration with AWS Transfer Family when you need a RESTful API to connect to an identity provider or when you want to leverage AWS WAF for its geo-blocking and rate limiting capabilities.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-11T14:24:47.301555"}}
{"question": "What authentication methods can be used together with AWS Transfer Family when using a custom identity provider?", "answer": "AWS Transfer Family supports multiple methods of authentication when using a custom identity provider. You can configure your SFTP server to require both password and SSH key, password or SSH key, just password, or just SSH key.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-15", "source_tokens": 502, "generated_at": "2026-02-11T14:24:47.301941"}}
{"question": "What certification has AWS Transfer Family for AS2 received?", "answer": "AWS Transfer Family for AS2 has received the official Drummond Group AS2 Cloud Certification Seal.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-11T14:24:51.003942"}}
{"question": "How does AS2 ensure non-repudiation?", "answer": "AS2 ensures non-repudiation using Message Disposition Notifications (MDNs). When an MDN is requested in a transaction, it validates that messages were successfully exchanged between two parties.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-11T14:24:51.004169"}}
{"question": "What are the sender's options for encrypting, signing, and requesting MDNs in AS2?", "answer": "The sender can choose to either only encrypt, only sign the data, or both when transmitting messages in AS2. They can also choose to request a signed or unsigned MDN.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-16", "source_tokens": 502, "generated_at": "2026-02-11T14:24:51.004505"}}
{"question": "What options does the sender have when requesting an MDN?", "answer": "The sender can choose to request an MDN, choose to request a signed or unsigned MDN, and select the signing algorithms to be used.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-11T14:24:54.628036"}}
{"question": "Why would you use asynchronous MDNs instead of synchronous ones?", "answer": "Asynchronous MDNs are preferred when you need more time to process the message before sending an MDN.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-11T14:24:54.628264"}}
{"question": "How does AWS Transfer Family handle and validate MDNs?", "answer": "AWS Transfer Family validates the MDN using your certificate and stores the message in your Amazon S3 bucket.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-17", "source_tokens": 491, "generated_at": "2026-02-11T14:24:54.628637"}}
{"question": "What directory should be specified for AS2 agreements in AWS B2B Data Interchange to transform X12 EDI files into JSON or XML?", "answer": "The AS2 payload directory should be specified for AS2 agreements in AWS B2B Data Interchange to transform X12 EDI files into JSON or XML.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-11T14:25:05.623904"}}
{"question": "How can automate sending of AS2 messages be achieved using AWS services?", "answer": "AS2 messages can be automated by scheduling them with the Amazon EventBridge Scheduler or by triggering them using Amazon EventBridge rules.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-11T14:25:05.624316"}}
{"question": "What events are published to Amazon EventBridge for AS2 messages and MDNs sent and received by AWS Transfer Family?", "answer": "Every successful or failed AS2 message and MDN sent and received by AWS Transfer Family publishes an event to the default event-bus in Amazon EventBridge.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-19", "source_tokens": 480, "generated_at": "2026-02-11T14:25:05.624495"}}
{"question": "What event notifications does AWS Transfer Family publish in Amazon EventBridge?", "answer": "AWS Transfer Family publishes event notifications in Amazon EventBridge for successful and failed completion of each file transfer operation over SFTP, AS2, FTPS, and FTP.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-11T14:25:11.050651"}}
{"question": "How can I use AWS Transfer Family managed workflows to process files?", "answer": "You can use AWS Transfer Family managed workflows to process files uploaded over SFTP, FTPS, and FTP server endpoints by associating a managed workflow with your server endpoint. This will automatically execute pre-built file processing steps on all files uploaded over that endpoint.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-11T14:25:11.050992"}}
{"question": "What are the differences between using AWS Transfer Family event notifications and managed workflows?", "answer": "Using AWS Transfer Family event notifications allows you to trigger processing of your files using any service that can integrate with EventBridge events. On the other hand, using Transfer Family managed workflows provides a pre-built framework for executing common file-processing tasks such as copying, tagging, and decrypting of files, saving time and enabling compliance.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-20", "source_tokens": 370, "generated_at": "2026-02-11T14:25:11.051417"}}
{"question": "What are managed workflows used for in the context of file processing?", "answer": "Managed workflows are used to simplify file processing by removing the complexities of managing multiple tasks. They provide a standardized solution for file processing with built-in exception handling and file traceability for each step.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T14:25:16.121242"}}
{"question": "How does setting up a managed workflow help in meeting business and legal requirements?", "answer": "Setting up a managed workflow helps meet business and legal requirements by providing built-in exception handling, file traceability, and the ability to replicate and standardize common post-upload file processing tasks across different business units.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T14:25:16.121530"}}
{"question": "What are the differences between managed workflows triggered on fully uploaded files and partially uploaded files?", "answer": "Managed workflows can be associated with a server endpoint to be triggered only on fully uploaded files. Separate managed workflows can be associated to process incomplete uploads. This allows granular control in managing file processing tasks.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T14:25:16.121665"}}
{"question": "What information is automatically published in Amazon EventBridge when a file transfer operation completes using AWS Transfer Family?", "answer": "Amazon EventBridge receives event notifications along with operational information such as file location, username of the sender, server-id or connector-id, and transfer status.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-11T14:25:20.864219"}}
{"question": "Why might you use event-driven architectures with AWS Transfer Family instead of managed workflows?", "answer": "Event-driven architectures allow for granular control in defining file processing, such as using conditional logic based on the source of the file, or integrating with other AWS services, third-party applications, and your own applications.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-11T14:25:20.864449"}}
{"question": "How does managing a workflow for multiple servers differ from managing it for a single server with AWS Transfer Family?", "answer": "Managing a workflow for multiple servers allows for easier maintenance and standardization of configurations, as the same workflow can be associated with each server.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-22", "source_tokens": 346, "generated_at": "2026-02-11T14:25:20.864836"}}
{"question": "What actions are available once a transfer server has received a file from the client?", "answer": "Once a transfer server has received a file from the client, common actions include decrypting the file using PGP keys, moving or copying data to where it needs to be consumed, deleting the original file post archiving or copying to a new location, tagging the file based on its contents, and any custom file processing logic by supplying your own Lambda function.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-11T14:25:27.267791"}}
{"question": "Why can you configure a workflow step to process either the originally uploaded file or the output file from the previous workflow step?", "answer": "This allows you to easily automate moving and renaming of your files after they are uploaded to Amazon S3. For example, to move a file to a different location for file archival or retention, you can configure two steps in your workflow: the first step is to copy a file to a different Amazon S3 location, and the second step is to delete the originally uploaded file.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-11T14:25:27.268145"}}
{"question": "How does using managed workflows enable you to create multiple copies of the original file while preserving the original file for records retention?", "answer": "Using managed workflows, you can create multiple copies of the original file while preserving the original file for records retention. This is useful for maintaining backup copies or for creating different versions of the file for various purposes.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-23", "source_tokens": 494, "generated_at": "2026-02-11T14:25:27.268520"}}
{"question": "What are three ways managed workflows in AWS Step Functions differentiate from other solutions?", "answer": "Managed workflows in AWS Step Functions can be differentiated from other solutions in three ways: 1) the ability to granularly define workflows to be executed only on full file uploads, as well as workflows to be executed only on partial file uploads, 2) the ability to be triggered automatically for files uploaded on S3 as well as EFS, and 3) the provision of no-code and pre-built options for common file processing like PGP decryption. ", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T14:25:34.581398"}}
{"question": "Can managed workflows be triggered for files uploaded via FTP, AS2 or SFTP connectors?", "answer": "Currently, managed workflows in AWS Step Functions can only be triggered for files uploaded over SFTP, FTPS and FTP server endpoints. They are not supported for messages exchanged over AS2, for file downloads over server endpoints, or for files transferred using SFTP connectors.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T14:25:34.581657"}}
{"question": "How does managing workflows for file processing using AWS Step Functions compare to using Amazon S3 Event Notifications?", "answer": "Managing file processing workflows using AWS Step Functions and Amazon S3 Event Notifications serve similar purposes but differ in a few aspects. With AWS Step Functions, you can define more complex workflows and employ conditional logic based on which user uploaded the file. However, AWS Step Functions can only process one file per execution, whereas Amazon S3 Event Notifications can trigger multiple Lambda functions for each file uploaded.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T14:25:34.583043"}}
{"question": "What network does AWS Transfer Family use for data transfer to Amazon S3?", "answer": "AWS Transfer Family uses internal AWS networks for data transfer to Amazon S3, not the public internet.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T14:25:38.785110"}}
{"question": "Why doesn't AWS Transfer Family need AWS PrivateLink for data transfer to Amazon S3?", "answer": "AWS Transfer Family and Amazon S3 can be in the same region and data is transferred over internal AWS networks, eliminating the need for AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T14:25:38.785435"}}
{"question": "How does the use of AWS IAM impact a user's access to files and directories in Amazon S3?", "answer": "AWS IAM determines the level of access for users, enabling or disabling operations on their client and granting access to specific Amazon S3 buckets and directories.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T14:25:38.785869"}}
{"question": "What determines the bucket(s) that an AWS IAM user can access?", "answer": "The bucket(s) an AWS IAM user can access is determined by the IAM Role assigned to their username and any optional scope-down policies.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-11T14:25:43.526521"}}
{"question": "How does the use of S3 Access Point aliases with AWS Transfer Family impact access control?", "answer": "S3 Access Point aliases combined with AWS Transfer Family logical directories enable fine-grained access control for different applications, teams, and departments, while reducing the overhead of managing bucket policies.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-11T14:25:43.526852"}}
{"question": "What's the difference between using the CLI/API and the Console to set up cross account access for AWS Transfer Family?", "answer": "The CLI and API enable setting up cross account access between your server and buckets, while the Console only lists buckets within your own account. Additionally, the role assigned to the user must belong to the account where the buckets are located.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-26", "source_tokens": 422, "generated_at": "2026-02-11T14:25:43.527024"}}
{"question": "What information is available in the event notifications from AWS Transfer Family, that is not present in Amazon S3 event notifications?", "answer": "AWS Transfer Family event notifications contain operational information such as username of the sender, server-id, transfer status, etc., and allows you to define file processing granularly, based on conditional logic over these attributes.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-11T14:25:48.404927"}}
{"question": "How can you use the end-user information in AWS Transfer Family event notifications for post upload processing of your files?", "answer": "You can use the end-user information available in the AWS Transfer Family event notifications to orchestrate granular post upload processing of your files based on the user.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-11T14:25:48.405220"}}
{"question": "What is the difference between the default S3 directory listing performance and the optimized S3 directory listing performance?", "answer": "The optimized S3 directory listing performance allows your end users to enjoy accelerated listing of their directory â€“ from minutes to seconds, compared to the default S3 directory listing performance.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-27", "source_tokens": 427, "generated_at": "2026-02-11T14:25:48.405569"}}
{"question": "What role do logical directory mappings play in controlling user access to files in AWS Transfer Family?", "answer": "Logical directory mappings allow users to access only their designated logical paths and subdirectories, and forbid relative paths that traverse the logical roots. They are validated using relative notation and actively block these paths from resolving before passing them to S3, preventing users from moving beyond their logical mappings.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-11T14:25:54.485861"}}
{"question": "Why is it important to set up ownership of files and folders in AWS Transfer Family before configuring it to work with Amazon EFS?", "answer": "It's essential to set up ownership of files and folders in AWS Transfer Family using the same POSIX identities as the intended AWS Transfer Family users, and configure resource policies for cross-account access if necessary, before configuring AWS Transfer Family to work with Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-11T14:25:54.486321"}}
{"question": "What is the difference in data transfer methods between AWS Transfer Family and Amazon EFS when using AWS PrivateLink?", "answer": "The data transfer between AWS Transfer Family servers and Amazon EFS happens over internal AWS networks and doesn't traverse the public internet. Therefore, you do not need to use AWS PrivateLink for data transfer between Transfer Family servers and Amazon EFS, as Transfer Family does not require AWS PrivateLink endpoints to communicate with storage services in the same region.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-28", "source_tokens": 341, "generated_at": "2026-02-11T14:25:54.486538"}}
{"question": "What are POSIX IDs used for in Amazon EFS?", "answer": "POSIX IDs, which consist of an operating system user id, group id, and secondary group id, are used to control access to a file system in Amazon EFS.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-11T14:26:00.379770"}}
{"question": "How does setting up a user in AWS Transfer Family for Amazon EFS impact their access?", "answer": "When setting up a user in AWS Transfer Family for Amazon EFS, you will need to specify the username, userâ€™s POSIX configuration, and an IAM role. The user will be placed directly within the specified home directory or root of the specified EFS file system upon successful authentication, and their operating system POSIX id will be applied to all requests made through their file transfer clients.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-11T14:26:00.380067"}}
{"question": "How does accessing Amazon EFS through AWS Transfer Family compare to accessing it via a standard file system interface?", "answer": "Files transferred over the enabled protocols in AWS Transfer Family are directly stored in your Amazon EFS file systems. The difference lies in the fact that when accessing EFS through AWS Transfer Family, the file system interface is not a standard one, but rather an interface provided by AWS Transfer Family. Additionally, Transfer Family does not support access points if you are using Amazon EFS for storage.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-29", "source_tokens": 292, "generated_at": "2026-02-11T14:26:00.380491"}}
{"question": "What commands are supported for file manipulation in Amazon S3 and Amazon EFS?", "answer": "The supported commands for file manipulation in Amazon S3 and Amazon EFS include 'cd', 'ls/dir', 'pwd', 'put', 'get', 'rename', 'chown', 'chmod', 'chgrp', 'ln-s/symlink', 'mkdir', 'rm/delete', 'rmdir', and 'chmtime'. However, note that some differences exist, such as the support for directory renames and the change of file ownership and permissions.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-11T14:26:07.957621"}}
{"question": "How does the IAM policy and file system administration impact a user's ability to change file ownership and permissions in Amazon EFS?", "answer": "The IAM policy for an AWS Transfer Family user determines their access level to your file system â€“ read-only, read-write, or root access. As a file system administrator, you can manage ownership and permissions using the file's user id and group id for both service-managed and BYO Auth users.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-11T14:26:07.957883"}}
{"question": "How does the support for file system access and logical directory mappings compare between Amazon S3 and Amazon EFS?", "answer": "Amazon S3 and Amazon EFS have some differences in their support for file system access and logical directory mappings. In Amazon S3, you cannot change directory names, and only root (uid=0) or the file's owner can change file ownership and permissions. Amazon EFS, on the other hand, allows for different file systems and directories for each user, enforces a directory on successful authentication, and supports logical directory mappings with the ability to 'chroot' users to their designated home directory.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-30", "source_tokens": 495, "generated_at": "2026-02-11T14:26:07.958022"}}
{"question": "What will happen if a user tries to access symbolic links in directories when using AWS Transfer Family?", "answer": "The symbolic links will be resolved to their target.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-11T14:26:12.290562"}}
{"question": "Why can't we use symbolic links with logical directory mappings in AWS Transfer Family?", "answer": "Symbolic links are not supported when using logical directory mappings to set up user access in AWS Transfer Family.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-11T14:26:12.290907"}}
{"question": "How can we grant access to multiple file systems for an AWS Transfer Family user and which method is suitable for a linear sequence of common file processing steps?", "answer": "To grant access to multiple file systems for an AWS Transfer Family user, you can specify one or more file systems in the IAM policy you supply as part of user setup. For a linear sequence of common file processing steps, managed workflows can be used.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-31", "source_tokens": 445, "generated_at": "2026-02-11T14:26:12.291054"}}
{"question": "Which AWS regions are FISMA compliant?", "answer": "AWS East/West and GovCloud (US) Regions are FISMA compliant.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-11T14:26:20.135646"}}
{"question": "How can AWS Transfer Family be made FISMA compliant?", "answer": "AWS Transfer Family becomes FISMA compliant when it is authorized for FedRAMP within the respective regions.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-11T14:26:20.135958"}}
{"question": "How does managing workflows in AWS Transfer Family compare to using event notifications for encryption and decryption?", "answer": "Managed workflows in AWS Transfer Family allow for automatic decryption of files using PGP keys when uploaded, while event notifications enable users to orchestrate granular and event-driven processing of transferred files using their own encryption/decryption logic.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-33", "source_tokens": 472, "generated_at": "2026-02-11T14:26:20.136346"}}
{"question": "What AWS service is used to monitor the total number of workflow executions, successful and failed executions?", "answer": "AWS CloudWatch", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-11T14:26:25.264322"}}
{"question": "How can you receive notifications for files uploaded over SFTP, FTPS and FTP server endpoints using Transfer Family?", "answer": "You can use the Transfer Familyâ€™s managed workflows to receive notifications for files uploaded over SFTP, FTPS and FTP server endpoints or subscribe to AWS Transfer Family events in Amazon EventBridge to receive notifications using Amazon Simple Notification Service (SNS)", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-11T14:26:25.264586"}}
{"question": "What is the billing difference between using a single SFTP endpoint for multiple protocols and using separate endpoints for each protocol in Transfer Family?", "answer": "You are billed on an hourly basis for each of the protocols you have enabled and for the amount of data transferred through each of the protocols, regardless of whether the same endpoint is enabled for multiple protocols or you are using different endpoints for each of the protocols.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-34", "source_tokens": 450, "generated_at": "2026-02-11T14:26:25.265054"}}
{"question": "What is the billing impact of stopping an AWS server?", "answer": "Stopping an AWS server does not impact billing.", "question_type": "factual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-11T14:26:28.521320"}}
{"question": "How is billing calculated for Decrypt workflow step in AWS?", "answer": "Billing for Decrypt workflow step is based on the amount of data decrypted using PGP keys.", "question_type": "conceptual", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-11T14:26:28.521656"}}
{"question": "How does billing for SFTP connectors compare to billing for other AWS services?", "answer": "Unlike server endpoints, there is no hourly billing for SFTP connectors.", "question_type": "comparison", "metadata": {"service": "AWS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "aws-faq-35", "source_tokens": 222, "generated_at": "2026-02-11T14:26:28.522170"}}
{"question": "What is AWS Backup and which AWS services does it support?", "answer": "AWS Backup is a fully managed service that centralizes and automates data protection across AWS services like Amazon S3, Amazon FSx, Amazon EC2, Amazon RDS, and hybrid workloads like VMware on premises, VMware Cloud on AWS, and VMware Cloud on AWS Outposts.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:26:34.310304"}}
{"question": "How does AWS Backup help with data protection and compliance?", "answer": "AWS Backup automates the creation of backups, stores those backups in an encrypted backup vault, and offers a centralized console to manage, monitor, and restore from backups. It also helps define access controls and automate backup access management across all your accounts within your AWS Organizations, and generates reports on compliance metrics.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:26:34.310563"}}
{"question": "How does AWS Backup for Amazon S3 compare to AWS Backup support for VMWare in terms of supported services?", "answer": "AWS Backup for Amazon S3 is a service within AWS Backup that specifically deals with protecting data in Amazon S3. AWS Backup support for VMWare, on the other hand, is another feature within AWS Backup that focuses on protecting VMware workloads.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:26:34.310951"}}
{"question": "What AWS services can AWS Backup be used to back up?", "answer": "AWS Backup can be used to back up Amazon Elastic Block Store (EBS) volumes, Amazon EC2 instances, AWS CloudFormation stacks, Windows Volume Shadow Copy Service (VSS) supported applications on EC2, Amazon RDS databases, Amazon DynamoDB tables, Amazon Elastic File System (EFS) file systems, Amazon Aurora databases, Amazon FSx for NetApp ONTAP, Amazon FSx for OpenZFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon Neptune databases, Amazon DocumentDB (with MongoDB compatibility) databases, AWS Storage Gateway volumes, Amazon S3, VMware CloudTM on AWS and on-premises VMware virtual machines, Amazon Redshift manual snapshots, and SAP HANA on EC2. It can also back up Amazon Timestream databases.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-11T14:26:42.878215"}}
{"question": "How does AWS Backup simplify managing backups across multiple AWS services?", "answer": "AWS Backup simplifies managing backups across multiple AWS services by providing a centralized console, automated backup scheduling, backup retention management, backup monitoring and alerting, and advanced features such as lifecycle policies, backup storage and encryption independent from source data, audit and compliance reporting capabilities, delete protection, and immutable backup copies.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-11T14:26:42.878559"}}
{"question": "How does AWS Backup for on-premises Storage Gateway volumes and VMware virtual machines compare to backing up these resources manually?", "answer": "AWS Backup for on-premises Storage Gateway volumes and VMware virtual machines allows you to manage the backups of your application data both on premises and on AWS in a common way. This comparison is based on the fact that AWS Backup provides a fully managed, policy-based data protection solution, while manual backups require custom solutions or manual processes.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-1", "source_tokens": 503, "generated_at": "2026-02-11T14:26:42.879065"}}
{"question": "Which AWS services offer backup features?", "answer": "Amazon S3 Replication, Amazon EBS Snapshots, Amazon RDS snapshots, Amazon FSx backups, Amazon DynamoDB backups, and AWS Storage Gateway snapshots are some AWS services that offer backup features.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-11T14:26:47.688492"}}
{"question": "How does AWS Backup help manage backups across services?", "answer": "AWS Backup is a centralized service that allows managing backups across various AWS services both on AWS and on-premises. It offers backup scheduling, retention management, and backup monitoring capabilities.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-11T14:26:47.688843"}}
{"question": "What are the differences between using Amazon Data Lifecycle Manager and AWS Backup for managing EBS snapshots?", "answer": "Amazon Data Lifecycle Manager automates the creation, retention, and deletion of EBS snapshots, while AWS Backup manages and monitors backups across multiple AWS services from a single place.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-2", "source_tokens": 374, "generated_at": "2026-02-11T14:26:47.689340"}}
{"question": "What type of metrics can you view in the Amazon CloudWatch dashboard for AWS Backup in regions where the native dashboard is not supported?", "answer": "You can view metrics on completed or failed backup, copy, and restore jobs in the Amazon CloudWatch dashboard for AWS Backup.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-11T14:26:52.270968"}}
{"question": "How does AWS Backup's dashboard help you monitor backup health across multiple environments?", "answer": "AWS Backup's native dashboard provides a scalable mechanism to monitor backup health across multiple environments through cross account and cross region support.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-11T14:26:52.271240"}}
{"question": "In what ways does AWS Backup's native dashboard and Amazon CloudWatch dashboard differ in terms of monitoring backup activity?", "answer": "AWS Backup's native dashboard provides real-time insights into backup health with built-in metrics for failure jobs, while Amazon CloudWatch dashboard for AWS Backup allows you to view job status by time period.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-3", "source_tokens": 292, "generated_at": "2026-02-11T14:26:52.271631"}}
{"question": "What is a backup plan in AWS Backup and what does it consist of?", "answer": "A backup plan in AWS Backup is a policy expression that defines when and how resources are backed up. It consists of one or more backup rules.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-11T14:26:57.309384"}}
{"question": "How does a backup plan with multiple rules work in AWS Backup?", "answer": "A backup plan in AWS Backup with multiple rules has each rule defined with a unique backup schedule, lifecycle rule, backup vault, and tags. AWS Backup automatically applies these rules to the assigned resources according to their respective frequencies and retention periods.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-11T14:26:57.309730"}}
{"question": "What's the difference between the warm and cold storage tiers for backup storage in AWS Backup?", "answer": "The warm storage tier is designed for faster access to recovery points at a higher cost. The cold storage tier is optimized for lower-cost, long-term retention of backups for infrequently accessed recovery points. The AWS Backup lifecycle feature automatically transitions your recovery points from the warm to the cold storage tier.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-4", "source_tokens": 403, "generated_at": "2026-02-11T14:26:57.310101"}}
{"question": "What encryption method is used for EBS snapshots when using AWS Backup?", "answer": "EBS snapshots are encrypted using the encryption key of the volume the snapshot was created from.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:27:01.496275"}}
{"question": "Why is encryption important for AWS Backup?", "answer": "Encryption adds an additional layer of protection for backups in transit and at rest, independent from the source services.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:27:01.496519"}}
{"question": "Which services support AWS Backup advanced features and which ones don't?", "answer": "Services like S3, EFS, Timestream, SAP HANA on EC2, Aurora DSQL, and DynamoDB support advanced features. AWS Backup for S3 supports backup access policies and encryption of backups with a different key, but does not support cold storage tier.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-5", "source_tokens": 488, "generated_at": "2026-02-11T14:27:01.496856"}}
{"question": "What is the purpose of AWS Backup Audit Manager in the context of AWS Backup?", "answer": "AWS Backup Audit Manager simplifies implementing, tracking, and demonstrating adherence to backup governance and compliance policies for workloads on AWS. It automatically detects violations of defined data protection policies and prompts users to take corrective actions.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-11T14:27:06.491623"}}
{"question": "What is the difference between an AWS Backup Audit Manager control and a framework?", "answer": "An AWS Backup Audit Manager control is a procedure designed to audit the compliance of a backup requirement, such as backup frequency or retention period. A framework is a collection of controls that can be deployed and managed as a single entity.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-11T14:27:06.491894"}}
{"question": "How can you check the compliance status of an AWS Backup Audit Manager framework and its controls?", "answer": "Navigate to the AWS Backup console, go to the AWS Backup Audit Manager Frameworks section, and select the framework name to view the compliance status of your framework and controls.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-6", "source_tokens": 424, "generated_at": "2026-02-11T14:27:06.492081"}}
{"question": "What does AWS Backup Audit Manager do with the integration with AWS Config?", "answer": "AWS Backup Audit Manager integrates with AWS Config to track backup activity and transcribe data protection policies into backup controls. It evaluates backup activity against these controls and records backup compliance status.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-11T14:27:11.109292"}}
{"question": "How does AWS Backup Audit Manager help in meeting compliance and governance requirements?", "answer": "AWS Backup Audit Manager helps in meeting compliance and governance requirements by allowing users to show the successful completion of restore test scenarios and the completion times for the restore job.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-11T14:27:11.110639"}}
{"question": "How does AWS Backup compare to other services in terms of compliance certifications?", "answer": "AWS Backup is PCI-DSS compliant and HIPAA eligible, making it simplified for users to verify its security and meet their own obligations. It also complies with several other global and industry security standards.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-7", "source_tokens": 486, "generated_at": "2026-02-11T14:27:11.111025"}}
{"question": "What is AWS Backup Vault Lock and how does it help prevent unauthorized changes to backups?", "answer": "AWS Backup Vault Lock is a feature that helps prevent changes to backup lifecycle and prevents manual deletion of backups. It implements safeguards that verify backups are stored using a Write-Once-Read-Many (WORM) model, ensuring no user, including administrators, can delete your backups or change their lifecycle settings. AWS Backup keeps backups according to your scheduled retention periods, helping meet business continuity goals.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-11T14:27:17.965949"}}
{"question": "What's the difference between AWS Backup Vault Lock and S3 Glacier Vault Lock?", "answer": "AWS Backup Vault Lock applies to data residing in your AWS Backup backup vault and prevents manual deletion of backups and changes to backup lifecycle settings to centrally protect backups across AWS services. S3 Glacier Vault Lock, on the other hand, applies to an individual S3 Glacier vault and enables you to enforce compliance controls designed to support long-term record retention.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-11T14:27:17.966191"}}
{"question": "What are the safeguards that AWS Backup Vault Lock implements to prevent unauthorized deletion or changes to backups?", "answer": "AWS Backup Vault Lock implements safeguards that verify backups are stored using a Write-Once-Read-Many (WORM) model, preventing manual deletion of backups and changes to backup lifecycle settings such as retention periods and transition to cold storage.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-8", "source_tokens": 331, "generated_at": "2026-02-11T14:27:17.966325"}}
{"question": "What are the three properties of AWS Backup Vault Lock?", "answer": "The three properties of AWS Backup Vault Lock are minimum acceptable retention days, maximum acceptable retention days, and grace time.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T14:27:22.099995"}}
{"question": "How does activating AWS Backup Vault Lock impact backup deletion and changes?", "answer": "Activating AWS Backup Vault Lock blocks backup deletion operations and changes to their lifecycle for all newly created recovery points in the vault.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T14:27:22.100399"}}
{"question": "What is the difference between AWS Backup Vault Lock and legal holds?", "answer": "AWS Backup Vault Lock is a configuration at the AWS Backup vault level that prevents backup deletion and changes to their lifecycle based on retention periods, while legal holds are used to retain certain data for preservation, auditing, or as evidence in legal proceedings and e-Discovery, even if their retention period is over.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T14:27:22.100752"}}
{"question": "What is a requirement for creating backups of Amazon S3 buckets and objects using AWS Backup?", "answer": "Enabling S3 Versioning is a prerequisite.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:27:27.006527"}}
{"question": "How does using both AWS Backup and Amazon S3 together benefit an organization?", "answer": "AWS Backup allows you to centrally manage backups and restores for applications across multiple AWS services, while Amazon S3 offers capabilities like Versioning, Object Lock, and Replication to help manage and preserve data in S3 buckets and objects.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:27:27.006702"}}
{"question": "What's the difference between continuous and periodic backups for Amazon S3 resources in AWS Backup?", "answer": "Continuous backups can restore Amazon S3 resources to any point in time within the last 35 days, while periodic backups retain data for an infinite period. Continuous backups are useful for undoing accidental deletions, while periodic snapshots can help meet long-term data retention needs.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:27:27.006819"}}
{"question": "What version of VMware ESXi does AWS Backup support for on-premises VMs?", "answer": "AWS Backup supports VMware ESXi 6.7.X and 7.0.X for on-premises VMs.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T14:27:31.696703"}}
{"question": "How does AWS Backup manage backups for VMware workloads?", "answer": "AWS Backup manages backups for VMware workloads by deploying a gateway in the VMware environment, discovering VMs through vCenter Server, taking snapshots, and managing data between the gateway and AWS Backup.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T14:27:31.697006"}}
{"question": "What are the differences in transport modes for copying data from source VMs to AWS using AWS Backup?", "answer": "AWS Backup supports both SCSI Hot-Add and Network Block Device (NBD) transport modes for copying data from source virtual machines (VMs) to AWS.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T14:27:31.697498"}}
{"question": "In which AWS Region is AWS Backup storing the VM backups for VMware CloudTM on AWS Outposts?", "answer": "AWS Backup stores the VM backups in the same AWS Region as your VMware CloudTM on AWS Outposts.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-11T14:27:36.437391"}}
{"question": "Why would you use AWS Backup to protect VMware CloudTM on AWS Outposts VMs instead of other backup solutions?", "answer": "AWS Backup can protect VMware CloudTM on AWS Outposts VMs while meeting low latency and local data processing needs for application data. It also allows you to store backups in the same Region as your Outposts.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-11T14:27:36.437712"}}
{"question": "How does AWS Backup compare storing backups in different AWS Regions for disaster recovery purposes?", "answer": "AWS Backup allows you to store a copy of VMware backups in a different AWS Region from your production backups to meet business continuity, disaster recovery, and compliance requirements.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-12", "source_tokens": 467, "generated_at": "2026-02-11T14:27:36.437867"}}
{"question": "What type of vault is a logically air-gapped vault in AWS Backup?", "answer": "A logically air-gapped vault is a secondary vault type in AWS Backup that allows secure sharing of access to other accounts for faster and more flexible recovery.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-11T14:27:41.364744"}}
{"question": "What are the billing implications of deploying a Backup gateway on a private network in AWS?", "answer": "You will be billed for each hour that your VPC endpoint remains provisioned and for each Gigabyte processed through the VPC endpoint, regardless of the trafficâ€™s source or destination.", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-11T14:27:41.365095"}}
{"question": "How does deploying a Backup gateway on a private network enhance your data protection strategy compared to public network?", "answer": "Deploying a Backup gateway on a private network through Direct Connect or VPN provides an extra level of account isolation and security by enabling private connectivity between AWS services using elastic network interfaces (ENI) with private IPs in your VPCs.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-13", "source_tokens": 469, "generated_at": "2026-02-11T14:27:41.365253"}}
{"question": "What encryption method is used to protect the backup copies in logically air-gapped vaults?", "answer": "The backup copies in logically air-gapped vaults are encrypted using AWS-owned keys managed through AWS Key Management Service (AWS KMS).", "question_type": "factual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-11T14:27:46.273949"}}
{"question": "How does multi-party approval work for accessing backups from logically air-gapped vaults?", "answer": "Multi-party approval for logically air-gapped vault involves setting up a team, requesting access, and having approvers review and vote on the request through the Approval portal.", "question_type": "conceptual", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-11T14:27:46.274286"}}
{"question": "What is the difference between sharing a logically air-gapped vault within an AWS Organization and sharing it with an external organization?", "answer": "Sharing a logically air-gapped vault within an AWS Organization allows backups to be restored directly in the destination account without creating additional copies. Sharing it with an external organization also enables this functionality but requires the external organization to have the necessary permissions.", "question_type": "comparison", "metadata": {"service": "BACKUP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "backup-faq-14", "source_tokens": 386, "generated_at": "2026-02-11T14:27:46.274753"}}
{"question": "What is AWS Batch and what does it enable users to do?", "answer": "AWS Batch is a service that helps users easily and efficiently run batch computing jobs on AWS. It dynamically provisions the optimal compute resources for jobs, eliminating the need for users to manage batch computing software and server clusters. Users can plan, schedule, and execute batch computing workloads using Amazon ECS, Amazon EKS, and AWS Fargate with an option to utilize spot instances.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T14:27:52.500317"}}
{"question": "Why should users choose AWS Batch over managing their own batch computing infrastructure?", "answer": "AWS Batch offers several benefits over managing your own batch computing infrastructure. It saves time by automatically provisioning the optimal compute resources, reduces costs by utilizing spot instances, increases efficiency by driving higher compute resource utilization, and enables job prioritization based on business objectives.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T14:27:52.500647"}}
{"question": "How does AWS Batch compare to other AWS services for managing batch computing workloads?", "answer": "AWS Batch supports running batch computing workloads using Amazon ECS, Amazon EKS, and AWS Fargate, making it a flexible option for managing batch computing workloads. In comparison, Amazon ECS is a container management service while Amazon EKS is a managed service for Kubernetes, and AWS Fargate is a compute engine for Amazon ECS and Amazon EKS, without the need for managing servers or clusters.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T14:27:52.501125"}}
{"question": "Which computing environment should I use in AWS Batch when I want AWS to handle infrastructure provisioning abstracted from EC2?", "answer": "You should use Fargate in this scenario.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-11T14:27:56.555558"}}
{"question": "When might it be more efficient to use Fargate instead of EC2 in AWS Batch for running jobs?", "answer": "Fargate jobs might start faster for initial scale-out of work due to the absence of the need to wait for an EC2 instance to launch.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-11T14:27:56.555771"}}
{"question": "How does the performance of Fargate jobs in AWS Batch compare to EC2 jobs when dealing with larger workloads?", "answer": "For larger workloads, EC2 jobs may be faster due to Batch's reuse of instances and container images in subsequent jobs.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-1", "source_tokens": 318, "generated_at": "2026-02-11T14:27:56.556141"}}
{"question": "What is the maximum vCPU limit for a Fargate CE in AWS Batch?", "answer": "The maximum vCPU limit for a Fargate CE in AWS Batch is the total amount of vCPU of all the jobs currently running in that CE.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-11T14:28:01.537123"}}
{"question": "Why does AWS Batch use a new Fargate CE when max vCPU is reached?", "answer": "AWS Batch uses a new Fargate CE when max vCPU is reached to ensure that the total vCPU usage does not exceed the limit set for that CE, allowing for efficient resource utilization and adherence to business requirements.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-11T14:28:01.537383"}}
{"question": "How does Fargate Spot compare to Fargate in terms of vCPU usage in AWS Batch?", "answer": "Fargate Spot is only used when the vCPU usage by jobs is greater than max vCPU for the current Fargate CE. In contrast, Fargate is used when the vCPU limit is not met in the current CE, allowing for more consistent resource allocation.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-2", "source_tokens": 347, "generated_at": "2026-02-11T14:28:01.537755"}}
{"question": "What are the benefits of using multi-container jobs in AWS Batch?", "answer": "Using multi-container jobs in AWS Batch simplifies operations, allows for alignment with production system architecture, and enables parallelization of work. It also helps keep containers small and fast to download, and simplifies DevOps.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-11T14:28:05.887960"}}
{"question": "What type of workloads can AWS Batch run with multi-container jobs?", "answer": "AWS Batch can run multi-container jobs in all job types including single-node regular jobs, array jobs, and multi-node parallel (MNP) jobs.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-11T14:28:05.888376"}}
{"question": "How does AWS Batch manage compute resources for multi-container jobs?", "answer": "AWS Batch manages compute environments and job queues, allowing you to easily run thousands of jobs of any scale using Amazon ECS, Amazon EKS, and AWS Fargate. It provides an option between Spot or on-demand resources and carefully monitors the progress of your jobs.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-3", "source_tokens": 454, "generated_at": "2026-02-11T14:28:05.888568"}}
{"question": "What type of compute resources are included in an AWS Batch Compute Environment?", "answer": "An AWS Batch Compute Environment is a collection of compute resources on which jobs are executed. AWS Batch supports two types: Managed Compute Environments, which are provisioned and managed by AWS, and Unmanaged Compute Environments, which are managed by customers.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-11T14:28:10.837022"}}
{"question": "Why would you use an Unmanaged Compute Environment instead of a Managed one?", "answer": "Unmanaged Compute Environments allow customers to leverage specialized resources like Dedicated Hosts, larger storage configurations, and Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-11T14:28:10.837398"}}
{"question": "How does AWS Batch handle EC2 Spot Instances in Compute Environments?", "answer": "AWS Batch uses EC2 Spot Instances in Managed Compute Environments with a percentage of On-Demand pricing, while Unmanaged Compute Environments can also include Spot Instances that the user launches.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-4", "source_tokens": 430, "generated_at": "2026-02-11T14:28:10.837866"}}
{"question": "What type of accelerators can be used with AWS Batch and how are they specified?", "answer": "AWS Batch currently supports GPU accelerators. To use them, you need to specify the accelerator type and number in the Job Definition or at job submission. The specified accelerator type must be present on one of the instance types specified in your Compute Environment.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-11T14:28:16.306813"}}
{"question": "How does AWS Batch determine which instances to use for a job with accelerator requirements?", "answer": "AWS Batch dynamically schedules and provisions jobs based on their accelerator needs. It will ensure that the appropriate number of accelerators are reserved against your jobs. Batch scales up your EC2 Accelerated Instances when needed and scales them down when done, allowing you to focus on your applications.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-11T14:28:16.307070"}}
{"question": "What's the difference between running a job on a regular instance and an accelerated instance in AWS Batch?", "answer": "Running a job on a regular instance does not use any accelerators, whereas running a job on an accelerated instance allows the job to take advantage of the specified accelerator type (currently only GPUs) for increased performance.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-5", "source_tokens": 476, "generated_at": "2026-02-11T14:28:16.307246"}}
{"question": "What AMI will new p-type instances launch with by default?", "answer": "New p-type instances will launch with the ECS GPU-optimized AMI by default.", "question_type": "factual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-11T14:28:20.163723"}}
{"question": "Why is an ECS GPU-optimized AMI needed for p-type instances?", "answer": "An ECS GPU-optimized AMI is needed for p-type instances as it contains the necessary libraries and runtimes for running GPU-based applications.", "question_type": "conceptual", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-11T14:28:20.164043"}}
{"question": "How does the usage of compute resources scale with AWS Batch for p-type instances?", "answer": "Resources within the compute environment for p-type instances will scale up as additional jobs are ready to run and scale down as the number of runnable jobs decreases.", "question_type": "comparison", "metadata": {"service": "BATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "batch-faq-6", "source_tokens": 155, "generated_at": "2026-02-11T14:28:20.164552"}}
{"question": "Which models does Amazon Bedrock support from each provider?", "answer": "Amazon Bedrock supports models from AI21 Labs, Amazon, Anthropic, Cohere, DeepSeek, Luma AI, Meta, Mistral AI, OpenAI, poolsid (coming soon), and Stability AI.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:28:25.207282"}}
{"question": "What capabilities does Amazon Bedrock offer for developing generative AI applications?", "answer": "Amazon Bedrock offers capabilities such as a choice of industry leading foundation models, customization using techniques like fine-tuning and retrieval-augmented generation (RAG), and the ability to create managed agents that execute complex business tasks.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:28:25.207552"}}
{"question": "How does Amazon Bedrock compare to other services for developing generative AI applications?", "answer": "Amazon Bedrock simplifies development with security, privacy, and responsible AI, and allows you to experiment with a variety of top foundation models, customize them privately with your data, and create managed agents. However, it does not provide specific comparison details in the given context.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:28:25.207731"}}
{"question": "What are the five reasons to use Amazon Bedrock for building generative AI applications?", "answer": "Amazon Bedrock offers an easy-to-use developer experience to work with a broad range of high-performing FMs from leading AI companies, allows for easy model customization with your own data, provides fully managed agents that can invoke APIs dynamically to execute tasks, has native support for RAG to extend the power of FMs with proprietary data, and gives the flexibility to use FMs from different providers.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-11T14:28:30.825603"}}
{"question": "Why would you use Amazon Bedrock to customize models with your own data?", "answer": "You can easily customize FMs with your own data through a visual interface without writing any code, and can select the training and validation data sets stored in Amazon Simple Storage Service (Amazon S3) and adjust hyperparameters to achieve the best model performance.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-11T14:28:30.825881"}}
{"question": "How does Amazon Bedrock compare to other platforms for customizing models with data?", "answer": "Amazon Bedrock allows for easy model customization with your own data through a visual interface, while also providing the flexibility to use FMs from different providers and keeping up to date with the latest model versions with minimal code changes.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-1", "source_tokens": 337, "generated_at": "2026-02-11T14:28:30.826048"}}
{"question": "What data security and compliance certifications does Amazon Bedrock support?", "answer": "Amazon Bedrock supports several data security and compliance certifications such as SOC, ISO, HIPAA, GDPR, and CSA Security Trust Assurance and Risk (STAR) Level 2.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-11T14:28:35.415014"}}
{"question": "How does Amazon Bedrock ensure data security and privacy?", "answer": "Amazon Bedrock ensures data security and privacy by encrypting data in transit and at rest, allowing customers to use their own encryption keys, and providing private connectivity with AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-11T14:28:35.415292"}}
{"question": "How does Amazon Bedrock compare to other services in terms of data security and privacy certifications?", "answer": "Amazon Bedrock is similar to other AWS services as it supports several data security and privacy certifications like SOC, ISO, HIPAA, GDPR, and CSA Security Trust Assurance and Risk (STAR) Level 2.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-2", "source_tokens": 220, "generated_at": "2026-02-11T14:28:35.415694"}}
{"question": "In which AWS services can I find Amazon Bedrock?", "answer": "Amazon Bedrock is available in various AWS Regions. For a list of Amazon Bedrock endpoints and quotas, please refer to the Amazon Bedrock Reference Guide.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-11T14:28:40.559708"}}
{"question": "What are some common use cases for Amazon Bedrock's FMs?", "answer": "Amazon Bedrock's FMs can be used for creating new content, such as short stories or essays, answering questions from a large corpus of data, generating realistic and artistic images, providing more relevant and contextual product recommendations, and summarizing textual content.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-11T14:28:40.560039"}}
{"question": "How does fine-tuning work for Amazon Bedrock's FMs?", "answer": "You can fine-tune Amazon Bedrock's FMs using tagged data or the continued pre-train feature. To get started, provide the training and validation dataset, configure hyperparameters, and submit the job. Within a couple of hours, the fine-tuned model can be accessed with the same API (InvokeModel).", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-3", "source_tokens": 464, "generated_at": "2026-02-11T14:28:40.560472"}}
{"question": "Which publicly available models can be imported into Amazon Bedrock using the Custom Model Import feature?", "answer": "Currently, the Custom Model Import feature in Amazon Bedrock supports Llama 2/3, Mistral, and Flan architectures.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-11T14:28:45.523478"}}
{"question": "How does latency-optimized inference in Amazon Bedrock improve the performance of foundation models?", "answer": "Latency-optimized inference in Amazon Bedrock reduces response times for foundation model interactions while maintaining accuracy. It achieves this by using purpose-built AI chips like AWS Trainium2 and advanced software optimizations.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-11T14:28:45.523771"}}
{"question": "How does the latency-optimized inference performance of Amazon Bedrock compare to other major cloud providers for the 405B and 70B models from Meta?", "answer": "According to the text, Llama 3.1 405B and 70B models run faster on AWS with latency-optimized inference than on any other major cloud provider.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-4", "source_tokens": 414, "generated_at": "2026-02-11T14:28:45.524207"}}
{"question": "What is the role of Amazon Bedrock Agents in creating generative-AI based applications?", "answer": "Amazon Bedrock Agents is a fully managed capability that helps developers create generative-AI based applications by automatically breaking down tasks, creating an orchestration plan, and securely connecting to company data through APIs.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-11T14:28:50.980142"}}
{"question": "How does Amazon Bedrock Agents help organizations move AI agents from proofs of concept to production?", "answer": "Amazon Bedrock Agents, through AgentCore, provides purpose-built infrastructure to securely scale agents, tools to make agents more effective and capable, and controls to monitor behavior. This enables organizations to move AI agents from proofs of concept built using open-source or custom agent frameworks to production.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-11T14:28:50.980521"}}
{"question": "How does Amazon Bedrock Agents compare to custom agent frameworks in terms of infrastructure and security?", "answer": "Amazon Bedrock Agents, through AgentCore, offers purpose-built infrastructure to securely scale agents and powerful tools to enhance them. This contrasts with custom agent frameworks which may not provide the same level of infrastructure and security required for production deployment.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-5", "source_tokens": 371, "generated_at": "2026-02-11T14:28:50.980957"}}
{"question": "What service in AgentCore provides a secure, serverless runtime for deploying and scaling dynamic AI agents and tools?", "answer": "Runtime", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T14:28:55.179220"}}
{"question": "How does AgentCore's Memory service help developers build context-aware agents?", "answer": "AgentCore's Memory service eliminates the need for complex memory infrastructure management while providing full control over what the AI agent remembers.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T14:28:55.179453"}}
{"question": "What are the differences between AgentCore's Gateway and Browser tool?", "answer": "AgentCore's Gateway provides a secure way for agents to discover and use tools and transform APIs, Lambda functions, and existing services into agent-compatible tools. AgentCore's Browser tool provides a fast, secure, cloud-based browser runtime for AI agents to interact with websites at scale.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T14:28:55.179583"}}
{"question": "What features does AgentCore offer that Amazon Bedrock does not?", "answer": "AgentCore provides upgraded tools and infrastructure for running agents at scale including identity, customizable long-term memory, an enhanced code interpreter tool, built-in browser tool, observability, native support for Model Context Protocol for connection to thousands of tools, and a runtime with industry-leading execution time, payload size, and complete session isolation.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-11T14:28:59.896079"}}
{"question": "Why should I choose AgentCore over Amazon Bedrock?", "answer": "You may want to choose AgentCore over Amazon Bedrock if you need the ability to use any agent authoring framework and any model, fine-grained control on identity, memory, and observability, and upgraded tools and infrastructure for running agents at scale.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-11T14:28:59.896340"}}
{"question": "Where is the content processed by Amazon Bedrock stored?", "answer": "The content processed by Amazon Bedrock is encrypted and stored at rest in the AWS Region where you are using Amazon Bedrock.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-7", "source_tokens": 255, "generated_at": "2026-02-11T14:28:59.896713"}}
{"question": "What compliance standards is Amazon Bedrock in scope for?", "answer": "Amazon Bedrock is in scope for common compliance standards such as Fedramp Moderate, SOC, ISO, HIPAA eligibility, and GDPR.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-11T14:29:05.349128"}}
{"question": "How does using Amazon Bedrock contribute to the security of my data?", "answer": "Amazon Bedrock offers several capabilities to support security and privacy requirements, including being included in the scope of SOC 1, 2, 3 reports, and being CSA Security Trust Assurance and Risk (STAR) Level 2 certified. You can also use AWS PrivateLink to establish private connectivity from your VPC to Amazon Bedrock, without having to expose your data to internet traffic.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-11T14:29:05.349411"}}
{"question": "How does Amazon Bedrock's support for SDKs compare between text and speech input?", "answer": "Amazon Bedrock supports SDKs for runtime services, which include iOS and Android SDKs, Java, JS, Python, CLI, .Net, Ruby, PHP, Go, and C++. All of these SDKs support both text and speech input.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-8", "source_tokens": 469, "generated_at": "2026-02-11T14:29:05.349589"}}
{"question": "What type of content in AWS Marketplace results in separate bills for customers?", "answer": "Third-Party Content sold by third party providers", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-11T14:29:09.311633"}}
{"question": "How does Amazon Bedrock handle data during the fine-tuning process?", "answer": "Amazon Bedrock keeps the data securely within the AWS network, encrypts it in transit and at rest, and enforces the same AWS access controls as other services", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-11T14:29:09.311924"}}
{"question": "What is the difference between directly fine-tuning a base model and using continued pretraining on Amazon Bedrock?", "answer": "Directly fine-tuning a base model requires large amounts of labeled training records and a long training duration, while continued pretraining on Amazon Bedrock uses large amounts of unlabeled data to adapt the base model to a new domain, reducing the need for labeled records and shortening the training duration", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-9", "source_tokens": 446, "generated_at": "2026-02-11T14:29:09.312378"}}
{"question": "What tab should I navigate to in the Amazon Bedrock console to create a continued pretraining job?", "answer": "You should navigate to the 'Training jobs' tab.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T14:29:13.151610"}}
{"question": "How does Amazon Bedrock simplify the process of continued pretraining and fine-tuning?", "answer": "Amazon Bedrock simplifies the process by unifying APIs for both continued pretraining and fine-tuning.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T14:29:13.151915"}}
{"question": "What are the differences between Amazon Titan models and models created with other services?", "answer": "Amazon Titan models are powerful, general-purpose models created by AWS and pretrained on large datasets, while other models may require more customization and setup.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T14:29:13.152134"}}
{"question": "What data formats can Amazon Bedrock Knowledge Bases process for visual data?", "answer": "Amazon Bedrock Knowledge Bases supports standard image formats like JPEG and PNG for image-only data.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-11T14:29:17.485840"}}
{"question": "How does Amazon Bedrock Knowledge Bases support multi-modal data processing?", "answer": "Amazon Bedrock Knowledge Bases allows developers to build generative AI applications that analyze both text and visual data, including images, charts, diagrams, and tables.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-11T14:29:17.486167"}}
{"question": "What are the differences between the three parsing options for Amazon Bedrock Knowledge Bases?", "answer": "The built-in default Bedrock parser is available at no additional cost and is ideal for text-only processing. Amazon Bedrock Data Automation (BDA) and foundation models can be used to parse multimodal data.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-11", "source_tokens": 399, "generated_at": "2026-02-11T14:29:17.486654"}}
{"question": "What metrics can be evaluated using automatic evaluations on Amazon Bedrock?", "answer": "Accuracy, robustness, and toxicity are the metrics that can be evaluated using automatic evaluations on Amazon Bedrock.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-11T14:29:22.008533"}}
{"question": "Why is human evaluation necessary in Model Evaluation on Amazon Bedrock?", "answer": "Human evaluation is necessary in Model Evaluation on Amazon Bedrock for evaluating more nuanced or subjective criteria that require human judgment, such as friendliness, relevance, style, and alignment to brand voice.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-11T14:29:22.008837"}}
{"question": "How does automatic evaluation and human evaluation differ in Model Evaluation on Amazon Bedrock?", "answer": "Automatic evaluation allows for the quick evaluation of standard metrics such as accuracy, toxicity, and robustness, while human evaluation is used for more nuanced and subjective criteria, such as friendliness, relevance, style, and alignment to brand voice.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-12", "source_tokens": 360, "generated_at": "2026-02-11T14:29:22.009001"}}
{"question": "What are the steps to set up human review workflows using Amazon Bedrock?", "answer": "You can set up human review workflows in a few short steps through Amazon Bedrock's intuitive interface. Human evaluators can review and give feedback on model responses by clicking thumbs up or down, rating on a scale of 1-5, choosing the best of multiple responses, or ranking prompts.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T14:29:27.275608"}}
{"question": "How does Amazon Bedrock facilitate human evaluation of model responses?", "answer": "Amazon Bedrock enables human evaluators to review and provide feedback on model responses through an intuitive interface. They can select the most accurate, relevant, or stylistic outputs by comparing models' responses to the same prompt.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T14:29:27.275894"}}
{"question": "What is the difference between Amazon Bedrock's human review workflows and guardrails features?", "answer": "Amazon Bedrock's human review workflows allow you to set up intuitive interfaces for your team to evaluate model responses, while guardrails help you implement safeguards for your generative AI applications based on your use cases and responsible AI policies.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T14:29:27.276112"}}
{"question": "What types of policies can be configured in Amazon Bedrock Guardrails for text and image content?", "answer": "Amazon Bedrock Guardrails allows the configuration of six policies: Multi modal content filters, Denied topics, Word filters, Sensitive information filters, Contextual grounding checks, and Automated Reasoning checks.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-11T14:29:32.965243"}}
{"question": "How does Amazon Bedrock Guardrails help ensure the security of generative AI applications?", "answer": "Amazon Bedrock Guardrails helps ensure the security of generative AI applications by enabling users to define and enforce policies to detect and filter harmful content, block undesirable topics, and protect sensitive information. It also checks for factual inaccuracies and hallucinations in generated content.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-11T14:29:32.965527"}}
{"question": "What's the difference between Multi modal content filters and Sensitive information filters in Amazon Bedrock Guardrails?", "answer": "Multi modal content filters are used to configure thresholds to detect and filter harmful text and/or image content across various categories. Sensitive information filters, on the other hand, are used to configure filters to help block or mask sensitive information, such as personally identifiable information, based on probabilistic detection of standard formats in entities.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-14", "source_tokens": 483, "generated_at": "2026-02-11T14:29:32.965699"}}
{"question": "Which languages does Bedrock Guardrails Standard Tier support?", "answer": "Bedrock Guardrails Standard Tier supports up to 60 languages.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-11T14:29:36.762786"}}
{"question": "How does Bedrock Guardrails help in detecting hallucinations for conversational applications?", "answer": "Bedrock Guardrails uses contextual grounding checks to detect hallucinations for conversational applications by referencing source information to validate model responses.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-11T14:29:36.763112"}}
{"question": "What is the difference between Bedrock Guardrails Standard and Classic Tiers in terms of language support?", "answer": "Standard Tier supports up to 60 languages while Classic Tier supports only English, French, and Spanish.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-15", "source_tokens": 492, "generated_at": "2026-02-11T14:29:36.763551"}}
{"question": "What IP claims is AWS indemnifying for copyright infringement related to the output of which AI services?", "answer": "AWS is indemnifying copyright claims arising from the output of Amazon models and other services listed in Section 50.10 of the Service Terms, collectively referred to as the Indemnified Generative AI Services.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:29:41.772565"}}
{"question": "How does Amazon Bedrock Guardrails help ensure that generated content follows the provided documents?", "answer": "Amazon Bedrock Guardrails uses machine learning techniques for contextual grounding checks to ensure the generated content closely follows the documents provided as input from a knowledge base.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:29:41.772907"}}
{"question": "How does the pricing model for Amazon Bedrock Guardrails compare to the pricing for Automated Reasoning Checks?", "answer": "Amazon Bedrock Guardrails is priced on a per-use model for both text and image content, whereas Automated Reasoning Checks do not provide explicit pricing details in the context.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:29:41.773297"}}
{"question": "Which image formats are supported with Bedrock Guardrails?", "answer": "PNG and JPEG image formats are supported with Bedrock Guardrails.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T14:29:46.700177"}}
{"question": "How does Amazon Bedrock Marketplace help in building and optimizing generative AI applications?", "answer": "Amazon Bedrock Marketplace offers a broad catalog of powerful models, allowing users to quickly access and deploy popular, emerging, or specialized models that can accelerate time-to-market, improve accuracy, or reduce cost for their generative AI workflows. Users can easily connect the marketplace to Bedrock's serverless models and access them through unified APIs.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T14:29:46.700473"}}
{"question": "What's the difference between accessing models through Bedrock's Invoke API and Converse API?", "answer": "Both APIs allow users to access models, but the Converse API is specifically designed for chat-tuned, text-to-text models and abstracts FM differences, enabling model switching with a single parameter change.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T14:29:46.700878"}}
{"question": "What steps are involved in using an Amazon Bedrock Marketplace model in AWS SageMaker?", "answer": "First, navigate to the Amazon Bedrock Model Catalog page in the Bedrock console and search for the desired model. After selecting the model, subscribe to it through the Model Detail page, accepting the EULA and price(s). Once the subscription is complete, deploy the model to a fully managed SageMaker endpoint by clicking on Deploy or using APIs. During deployment, choose the desired number of instances and instance types to meet the workload. After setup, which typically takes 10-15 minutes, inference calls can be made to the endpoint and the model can be used in Bedrockâ€™s advanced tools.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-11T14:29:54.329008"}}
{"question": "What is the difference between using a model from the Amazon Bedrock Marketplace and using a model fine-tuned in SageMaker but not available in Bedrock?", "answer": "Amazon Bedrock Marketplace models can be subscribed to, deployed to a fully managed SageMaker endpoint, and used in Bedrockâ€™s advanced tools, provided they are compatible with Bedrockâ€™s Converse API. On the other hand, models fine-tuned in SageMaker but not available in Bedrock can still be deployed to a SageMater endpoint for inference, but they cannot be used in Bedrockâ€™s advanced tools.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-11T14:29:54.329267"}}
{"question": "How long does it typically take to deploy a model to an AWS SageMaker endpoint after subscribing through the Amazon Bedrock Model Catalog?", "answer": "It typically takes 10-15 minutes to deploy a model to an AWS SageMaker endpoint after subscribing through the Amazon Bedrock Model Catalog.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-18", "source_tokens": 314, "generated_at": "2026-02-11T14:29:54.329429"}}
{"question": "What are the key benefits of using Amazon Bedrock Data Automation?", "answer": "Amazon Bedrock Data Automation offers industry-leading accuracy at lower cost than alternative solutions. It also features visual grounding with confidence scores for explainability and built-in hallucination mitigation, ensuring trustworthy and accurate insights from unstructured, multi-modal data sources. Customers can easily customize Bedrock Data Automation output to generate specific insights in consistent formats required by their systems and applications.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-11T14:30:00.121606"}}
{"question": "How does Amazon Bedrock Data Automation simplify AI application development?", "answer": "Amazon Bedrock Data Automation streamlines the development of generative AI applications and automates workflows involving documents, images, audio, and videos. It makes it easier for developers to build intelligent document processing, media analysis, and other multimodal data-centric automation solutions.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-11T14:30:00.121944"}}
{"question": "What are the advantages of using Amazon Bedrock Data Automation over other solutions?", "answer": "Amazon Bedrock Data Automation provides industry-leading accuracy at lower cost than alternative solutions. It also features visual grounding with confidence scores for explainability and built-in hallucination mitigation, which are not always available in other solutions.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-19", "source_tokens": 504, "generated_at": "2026-02-11T14:30:00.122111"}}
{"question": "What information does a blueprint include for output specification?", "answer": "A blueprint includes a list of fields, a data format for each field, and natural language instructions for each field.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-11T14:30:03.887917"}}
{"question": "How does a developer create a blueprint in AWS?", "answer": "A developer creates a blueprint in AWS by specifying the desired output fields, their data formats, and providing natural language instructions.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-11T14:30:03.888126"}}
{"question": "What is the difference between creating a blueprint for output requirements and directly specifying the desired output format?", "answer": "Creating a blueprint involves specifying output requirements using natural language or a schema editor, while directly specifying the output format involves manually setting the desired data format for each field.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-20", "source_tokens": 123, "generated_at": "2026-02-11T14:30:03.888246"}}
{"question": "What information is included in standard output for PDF documents?", "answer": "Standard output for PDF documents includes extraction of text from the document, generative output such as document summary and captions for tables/figures/diagrams, and can optionally be grouped by layout element. It is used for BDA integration with Bedrock Knowledge Bases.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-11T14:30:09.343324"}}
{"question": "How does Bedrock Data Automation handle custom output for documents?", "answer": "Custom Output for documents uses blueprints to specify output requirements using natural language or a schema editor. Blueprints include a list of fields to extract and a data format for each field.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-11T14:30:09.343605"}}
{"question": "What are the differences between standard output for PDF documents and standard output for images in Bedrock Data Automation?", "answer": "Standard output for PDF documents includes text extraction, generative output, and can optionally be grouped by layout element, while standard output for images provides summarization, detected explicit content, detected text, logo detection, and IAB taxonomy. The maximum file size for PDF documents is 500MB per API request, while the maximum file size for images is 5 MB.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-21", "source_tokens": 472, "generated_at": "2026-02-11T14:30:09.343737"}}
{"question": "What is the max file size for a MOV or MKV video file that can be processed by BDA in one API request?", "answer": "The max file size for a MOV or MKV video file is 2 GB.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-11T14:30:14.785402"}}
{"question": "How does Bedrock Data Automation handle audio files?", "answer": "BDA supports standard output for audio, which includes summarization, full transcription, and explicit content moderation. It also supports various audio formats such as FLAC, M4A, MP3, MP4, Ogg, WebM, WAV, and has a max duration of 4 hours and a max file size of 2 GB per API request.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-11T14:30:14.791301"}}
{"question": "What's the difference in file format support between video and audio processing in BDA?", "answer": "BDA supports MOV and MKV formats for video with H.264, VP8, VP9 and various audio formats such as FLAC, M4A, MP3, MP4, Ogg, WebM, WAV for audio. Both have a max duration of 4 hours and a max file size of 2 GB per API request.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-22", "source_tokens": 174, "generated_at": "2026-02-11T14:30:14.810809"}}
{"question": "In which AWS Regions is Amazon Bedrock Data Automation currently available?", "answer": "Amazon Bedrock Data Automation is currently available in the US West (Oregon) and US East (N. Virginia) AWS Regions.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-11T14:30:20.695126"}}
{"question": "How can users access Amazon Bedrock's capabilities within Amazon SageMaker Unified Studio?", "answer": "To access Amazon Bedrock's capabilities within Amazon SageMaker Unified Studio, users need to create a new domain, enable the Gen AI application development project profile, and then access Amazon Bedrock through the Generative AI Playground (Discover) and Generative AI App Development (Build) sections, using their company's single sign-on (SSO) credentials.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-11T14:30:20.695346"}}
{"question": "What is the difference between accessing Amazon Bedrock through the AWS Management Console and Amazon SageMaker Unified Studio?", "answer": "Accessing Amazon Bedrock through the AWS Management Console and Amazon SageMaker Unified Studio offers different experiences. The AWS Management Console provides a centralized location to manage all your AWS services, while Amazon SageMaker Unified Studio offers an intuitive interface for experimenting with models, collaborating on projects, and getting streamlined access to various Bedrock tools and resources to build generative AI applications quickly.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-23", "source_tokens": 263, "generated_at": "2026-02-11T14:30:20.695490"}}
{"question": "What new features does Amazon Bedrock offer when accessed through Amazon SageMaker Unified Studio?", "answer": "Amazon Bedrock, when accessed through Amazon SageMaker Unified Studio, provides several new features including a model hub for side-by-side AI model comparison, an expanded playground supporting chat, image, and video interactions, improved Knowledge Base creation with web crawling, Agent creation for more complex chat applications, simplified sharing of AI apps and prompts within organizations, access to underlying application code, and the ability to export chat apps as CloudFormation templates.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-11T14:30:29.081258"}}
{"question": "How does collaborating in Amazon SageMaker Unified Studio's governed environment enhance the development process for generative AI applications?", "answer": "Collaborating in Amazon SageMaker Unified Studio's governed environment allows teams to create projects, invite colleagues, and build generative AI applications together. They can receive quick feedback on their prototypes and share the applications with anyone in SageMaker Unified Studio or with specific users in the domain. Robust access controls and governance features ensure only authorized members can access project resources, supporting data privacy and compliance, and fostering secure cross-functional collaboration and sharing.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-11T14:30:29.081592"}}
{"question": "What are the main differences between the original Amazon Bedrock Studio and the new Amazon Bedrock when accessed through Amazon SageMaker Unified Studio?", "answer": "The main differences between the original Amazon Bedrock Studio and the new Amazon Bedrock, when accessed through Amazon SageMaker Unified Studio, include the governed environment for collaboration, a model hub for side-by-side AI model comparison, an expanded playground supporting chat, image, and video interactions, improved Knowledge Base creation with web crawling, Agent creation for more complex chat applications, simplified sharing of AI apps and prompts within organizations, access to underlying application code, and the ability to export chat apps as CloudFormation templates.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-24", "source_tokens": 471, "generated_at": "2026-02-11T14:30:29.082080"}}
{"question": "What development tools and capabilities can teams access through Amazon SageMaker Unified Studio with Amazon Bedrock integration?", "answer": "Teams can access the Generative AI Playground in the Discover section for model experimentation and comparison, and the Generative AI App Development in the Build section for creating production-ready generative AI applications with tools for Knowledge Base creation, Guardrail implementation, Agent and Flow development, and secure collaboration.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-11T14:30:35.773324"}}
{"question": "How does the integration of Amazon Bedrock into Amazon SageMaker Unified Studio benefit enterprise teams in terms of generative AI development?", "answer": "The integration provides a unified development experience with familiar JupyterLab environments and analytics tools, seamless collaboration, and access to Amazon Bedrock's powerful generative AI capabilities, all within the same workspace. It also enables organizations to innovate faster and more effectively while maintaining enterprise-grade security and governance.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-11T14:30:35.773543"}}
{"question": "What is the difference between the Generative AI Playground and the Generative AI App Development in Amazon SageMaker Unified Studio with Amazon Bedrock integration?", "answer": "The Generative AI Playground in the Discover section enables teams to experiment with foundation models, test different models and configurations, and collaborate on prompts and applications. The Generative AI App Development in the Build section provides teams with the tools to create production-ready generative AI applications, including Knowledge Base creation, Guardrail implementation, Agent and Flow development, and secure collaboration.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-25", "source_tokens": 495, "generated_at": "2026-02-11T14:30:35.773888"}}
{"question": "What resources in Amazon SageMaker Unified Studio does Amazon Bedrock integrate with?", "answer": "Amazon Bedrock in Amazon SageMaker Unified Studio seamlessly integrates with Amazon SageMaker's analytics, machine learning, and generative AI capabilities.", "question_type": "factual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-11T14:30:40.224231"}}
{"question": "How does the integrated use of Amazon Bedrock and Amazon SageMaker Unified Studio benefit organizations?", "answer": "This consolidated workspace streamlines complexity, enabling faster prototyping, iteration, and deployment of production-ready, responsible generative AI applications that align with specific business requirements.", "question_type": "conceptual", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-11T14:30:40.224445"}}
{"question": "What are the costs associated with using Amazon Bedrock in Amazon SageMaker Unified Studio?", "answer": "Users will only pay for the underlying resources required by their generative AI applications, such as models, Guardrails, and Knowledge Bases.", "question_type": "comparison", "metadata": {"service": "BEDROCK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "bedrock-faq-26", "source_tokens": 495, "generated_at": "2026-02-11T14:30:40.224790"}}
{"question": "What is the purpose of the AWS Billing and Cost Management service?", "answer": "AWS Billing and Cost Management measures your usage of AWS services and calculates your charges. It issues invoices for the charges youâ€™ve accrued and allows you to view your charges by service, AWS Region, or member account.", "question_type": "factual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T14:30:46.296008"}}
{"question": "How does the AWS Billing Console help organizations manage their AWS bills?", "answer": "The AWS Billing Console provides a 'cash' view of your charges and helps organizations understand how the charges on their invoice were calculated. It allows you to view your charges by service, AWS Region, or member account, and download invoices and supplemental documents for various purposes.", "question_type": "conceptual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T14:30:46.296328"}}
{"question": "What's the difference between the 'cash' view of charges in the AWS Bills page and the amortized view in Cost Explorer?", "answer": "The 'cash' view in the AWS Bills page reflects the actual amount that you pay to AWS each month, inclusive of discounts, credits, refunds, and taxes. In contrast, Cost Explorer provides an amortized view of your costs, in which upfront charges such as upfront Savings Plans are spread or 'amortized' over the term of the commitment (one year or three years).", "question_type": "comparison", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T14:30:46.296754"}}
{"question": "What steps do I take to enable CSV downloads of my monthly charges in AWS?", "answer": "Navigate to the Billing Preferences page in the Billing console, check the box to turn on the detailed billing reports in the Detailed Billing Reports section, click Configure to choose or create an S3 bucket for report delivery, and click Save Preferences.", "question_type": "factual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-11T14:30:50.655538"}}
{"question": "Why would I want to download CSV reports of my AWS billing data instead of the standard invoice format?", "answer": "CSV reports offer greater flexibility in data analysis and integration with other tools compared to the PDF invoice format.", "question_type": "conceptual", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-11T14:30:50.655759"}}
{"question": "How does the AWS Billing Preferences page for report delivery compare between CSV and PDF formats?", "answer": "The CSV format allows for more detailed analysis and easier data integration, whereas the PDF format provides a standardized invoice presentation.", "question_type": "comparison", "metadata": {"service": "BILLING", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "billing-faq-1", "source_tokens": 125, "generated_at": "2026-02-11T14:30:50.655920"}}
{"question": "What is the process for provisioning public certificates in AWS Certificate Manager?", "answer": "You can easily provision public certificates through AWS Certificate Manager by requesting a certificate and then deploying it on AWS resources such as Elastic Load Balancers, Amazon CloudFront distributions, and APIs on API Gateway.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T14:30:57.238801"}}
{"question": "What are the advantages of using AWS Certificate Manager for managing SSL/TLS certificates?", "answer": "AWS Certificate Manager allows you to easily provision, manage, and deploy public and private SSL/TLS certificates, eliminating the time-consuming manual process of purchasing, uploading, and renewing certificates. It also enables you to secure network communications and establish the identity of websites over the Internet as well as resources on private networks. You can use these certificates to securely terminate traffic on any compute workload that requires a public certificate.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T14:30:57.239178"}}
{"question": "What is the difference between managing public and private SSL/TLS certificates in AWS Certificate Manager?", "answer": "Public SSL/TLS certificates are used exclusively with ACM-integrated services such as Elastic Load Balancing, Amazon CloudFront, and Amazon API Gateway, and are free. Private SSL/TLS certificates, on the other hand, are used for internal resources and require a monthly fee for the operation of each private CA until you delete it, and for the private certificates you issue that are not used exclusively with ACM-integrated services.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T14:30:57.239542"}}
{"question": "What is the role of a certificate authority (CA) in issuing public certificates?", "answer": "A certificate authority (CA) is an entity that issues public certificates. They must follow strict rules, provide operational visibility, and meet security standards imposed by browser and operating system vendors for their certificates to be trusted automatically.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T14:31:02.772652"}}
{"question": "What's the difference between public and private certificates in terms of trust and management?", "answer": "Public certificates are trusted automatically by applications and browsers, while private certificates require administrative configuration for applications to trust them. Public CAs follow strict rules and security standards, while private CAs can make their own rules for issuing certificates.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T14:31:02.772925"}}
{"question": "How do you export a public certificate from AWS Certificate Manager (ACM) and what is it used for?", "answer": "When requesting a public certificate through ACM, you can optionally make it exportable. Once issued, you can export the certificate, private key, and certificate chain through the AWS Management Console or by writing code/scripts using the AWS SDKs or CLI. The certificate is used to secure communication between TLS applications.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T14:31:02.773424"}}
{"question": "What are the benefits of using ACM for SSL/TLS certificate management in AWS?", "answer": "ACM makes it easier to enable SSL/TLS for a website or application in AWS, eliminates manual processes associated with certificate management, helps avoid downtime due to misconfigured, revoked, or expired certificates, and provides SSL/TLS protection and easy certificate management. It also improves search rankings and meets regulatory compliance requirements for encrypting data in transit.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-11T14:31:10.349129"}}
{"question": "How does ACM help in managing SSL/TLS certificates in hybrid and multicloud environments?", "answer": "ACM helps manage SSL/TLS certificates in hybrid and multicloud environments by eliminating many of the manual processes associated with using and managing SSL/TLS certificates. It also helps avoid downtime due to misconfigured, revoked, or expired certificates and lets you use the AWS Management Console, AWS CLI, or ACM APIs to centrally manage all of the SSL/TLS ACM certificates in an AWS Region. ACM is integrated with other AWS services and lets you request and provision SSL/TLS certificates with Elastic Load Balancing load balancers or Amazon CloudFront distributions.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-11T14:31:10.349406"}}
{"question": "What's the difference between managing SSL/TLS certificates using ACM and manually?", "answer": "Managing SSL/TLS certificates manually involves the manual processes of requesting, obtaining, installing, and renewing certificates. ACM automates many of these processes, making it easier to manage SSL/TLS certificates and avoid downtime due to misconfigured, revoked, or expired certificates. It also provides SSL/TLS protection and easy certificate management, and is integrated with other AWS services for easy provisioning.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-2", "source_tokens": 244, "generated_at": "2026-02-11T14:31:10.349841"}}
{"question": "What services can you use public certificates with in ACM?", "answer": "Public certificates obtained from ACM can be used with Amazon CloudFront, Elastic Load Balancing, and Amazon API Gateway.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-11T14:31:15.405414"}}
{"question": "How does ACM manage private certificates?", "answer": "ACM can automatically renew and deploy private certificates used with ACM-integrated services, and you can easily export them to use with EC2 instances, containers, on-premises servers, and IoT devices. AWS Private CA automatically renews these certificates and sends a CloudWatch notification when the renewal is completed.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-11T14:31:15.405671"}}
{"question": "What's the difference between managing public and private certificates in ACM?", "answer": "Public certificates are managed by ACM for renewal and deployment with AWS services like Amazon CloudFront, Elastic Load Balancing, and Amazon API Gateway. Private certificates can be managed by ACM for automatic renewal and deployment, or you can export and use them with non-AWS services and environments.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-3", "source_tokens": 445, "generated_at": "2026-02-11T14:31:15.406162"}}
{"question": "What region is required to use an ACM certificate with Amazon CloudFront?", "answer": "An ACM certificate with Amazon CloudFront must be requested or imported in the US East (N. Virginia) region.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-11T14:31:20.519289"}}
{"question": "How does one use a private certificate obtained from ACM with a specific AWS service?", "answer": "To use a private certificate obtained from ACM with a specific AWS service, you can select the SSL/TLS certificate from a drop-down list in the AWS Management Console for that service or execute an AWS CLI command or call an AWS API to associate the certificate with the resource.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-11T14:31:20.519619"}}
{"question": "What's the difference between using a private certificate with ACM and exporting it for use on EC2 instances or ECS containers?", "answer": "Using a private certificate with ACM involves associating it with an AWS service, such as Elastic Load Balancing or Amazon CloudFront, whereas exporting a private certificate for use on EC2 instances or ECS containers allows for the certificate to be used outside of the ACM service.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-4", "source_tokens": 507, "generated_at": "2026-02-11T14:31:20.520000"}}
{"question": "What is the minimum length of time a domain name can be included in a certificate issued by AWS Certificate Manager (ACM)?", "answer": "Each certificate must include at least one domain name, and you can add additional names if desired. You must own or control all of the names included in your certificate request.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:31:28.219254"}}
{"question": "How does using a wildcard domain name in AWS Certificate Manager (ACM) impact the certificates protected?", "answer": "A wildcard domain name matches any first-level subdomain or hostname in a domain. It can protect multiple host names or first-level subdomains that end with the same domain name. For example, using the name *.example.com can protect www.example.com, images.example.com, and any other host name or first-level subdomain that ends with .example.com.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:31:28.219544"}}
{"question": "What is the difference in certificate validity periods between certificates issued through AWS Certificate Manager (ACM) and private CA without using ACM for certificate management?", "answer": "Certificates issued through ACM have a validity period of 13 months (395 days), whereas private certificates issued directly from a private CA and managed without using ACM for certificate management can have any validity period, including an absolute end date or a relative time that is days, months, or years from the present time. As of March 15, 2026, the maximum lifetime for a TLS certificate issued through AWS Certificate Manager (ACM) will be 398 days. As of March 15, 2027, the maximum lifetime for a TLS certificate issued through AWS Certificate Manager (ACM) will be 200 days.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:31:28.219694"}}
{"question": "What is the default key algorithm and hash algorithm used by ACM for certificates?", "answer": "The default key algorithm used by ACM for certificates is RSA with a 2048-bit modulus and the default hash algorithm is SHA-256.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:31:32.999301"}}
{"question": "Why can you request ECDSA certificates from ACM and what are the available options?", "answer": "You can request ECDSA certificates from ACM to use with services and workloads that require TLS certificates. The available options for ECDSA are P-256 and P-384.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:31:32.999577"}}
{"question": "How does the use of exportable public certificates in ACM compare to using private certificates?", "answer": "Exportable public certificates issued by ACM can be used with integrated services and exported for use with any workloads that require TLS certificates, both within and outside AWS. In contrast, private certificates issued with Private CA can only be used with specific workloads, such as EC2 instances, containers, and on-premises servers. ", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:31:32.999972"}}
{"question": "What process does Amazon Certificate Manager (ACM) follow for managing imported third-party certificates?", "answer": "ACM does not manage the renewal process for imported certificates. Users can monitor the expiration dates of imported certificates through the AWS Management Console and import a new third-party certificate to replace an expiring one.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-11T14:31:37.926893"}}
{"question": "Can ACM public certificates be used for both public and private resources?", "answer": "Yes, ACM public certificates can be used for both public resources on the Internet and private resources for secure communication between resources. However, for private resources, users need to import the certificates into ACM.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-11T14:31:37.927179"}}
{"question": "How does the trust of ACM certificates compare between different browsers and operating systems?", "answer": "ACM public certificates are trusted by most modern browsers, operating systems, and mobile devices. They have 99% browser and operating system ubiquity, including Windows XP SP3 and Java 6 and later.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-7", "source_tokens": 500, "generated_at": "2026-02-11T14:31:37.927655"}}
{"question": "What does ACM not provide in terms of service level agreements (SLAs)?", "answer": "ACM does not have an SLA.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-11T14:31:41.878689"}}
{"question": "Why don't third-party site seals with the ACM logo misrepresent the truth about a site's security or business practices?", "answer": "ACM does not allow its logo to be used in this manner to protect customers and the reputation of Amazon.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-11T14:31:41.879112"}}
{"question": "How does the process of obtaining an ACM public certificate compare to email validation versus DNS validation?", "answer": "With DNS validation, you write a record to the public DNS configuration for your domain to establish control. Once control is established, you can obtain additional certificates and choose to renew existing certificates without having to validate control again. With email validation, emails are sent to the domain owner for approval to issue the certificate.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-8", "source_tokens": 487, "generated_at": "2026-02-11T14:31:41.879420"}}
{"question": "What method does Amazon Certificate Manager use for validating domain ownership during certificate issuance?", "answer": "Amazon Certificate Manager uses DNS validation or email validation for domain ownership verification during certificate issuance.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-11T14:31:46.769990"}}
{"question": "Why should one prefer DNS validation over email validation when requesting a certificate from Amazon Certificate Manager?", "answer": "DNS validation is recommended for certificate issuance if the domain owner has control over the DNS configuration for their domain. This method provides a more efficient process and is preferred for those who can't receive validation emails from ACM or use a domain registrar that does not publish domain owner email contact information in WHOIS.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-11T14:31:46.770264"}}
{"question": "What is the difference between DNS validation and email validation for certificate issuance through Amazon Certificate Manager?", "answer": "DNS validation requires adding a CNAME record to the DNS configuration, while email validation involves receiving and approving emails from Amazon Certificate Manager for each domain name in the certificate request.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-9", "source_tokens": 423, "generated_at": "2026-02-11T14:31:46.770448"}}
{"question": "Which CAAs are authorized to issue certificates for a domain when a CAA record is present?", "answer": "The CAAs authorized to issue certificates for a domain when a CAA record is present are amazon.com, amazontrust.com, awstrust.com, or amazonaws.com.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-11T14:31:52.265979"}}
{"question": "How does ACM determine if a customer can issue a certificate for a domain?", "answer": "ACM determines if a customer can issue a certificate for a domain by checking for the presence of a DNS CAA record specifying one of the following CAAs: amazon.com, amazontrust.com, awstrust.com, or amazonaws.com.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-11T14:31:52.266253"}}
{"question": "What's the difference between DNS validation and email validation in the context of ACM certificate issuance?", "answer": "DNS validation and email validation are methods used by ACM to validate that the certificate requester owns or controls a domain. With DNS validation, the requester adds a CNAME record to their DNS configuration, while with email validation, the requester confirms their ownership by responding to an email.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-10", "source_tokens": 382, "generated_at": "2026-02-11T14:31:52.266624"}}
{"question": "What is required to validate a domain for an SSL/TLS certificate using DNS validation?", "answer": "You need to add a CNAME record to your DNS configuration for the domain you want to validate. The record contains a unique token that ACM generates specifically for your domain and your AWS account.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:31:57.868998"}}
{"question": "Why would one choose to use DNS validation over email validation when requesting an SSL/TLS certificate?", "answer": "DNS validation is preferred when you have the ability to change the DNS configuration for the domain you are requesting, as it simplifies the validation process and enables automatic certificate renewals.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:31:57.869197"}}
{"question": "Can ACM add DNS records for you if you manage your DNS records with Amazon Route 53, and how does this compare to using a different DNS provider?", "answer": "Yes, the ACM console can add DNS records to your Amazon Route 53 configuration when you request a certificate. For customers using Amazon Route 53 DNS, this simplifies the validation process. However, you can also use DNS validation with any DNS provider as long as they allow you to add a CNAME record to your DNS configuration.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:31:57.869304"}}
{"question": "What is the format of a CNAME record generated by AWS ACM for a specific domain name?", "answer": "The format of a CNAME record generated by AWS ACM for a specific domain name includes a name component and a label component. The name component is constructed from an underscore character (_) followed by a unique token tied to your AWS account and your domain name. The label component is also constructed from an underscore character followed by a unique token tied to your AWS account and your domain name, prepended to 'acm-validations.aws'. For example, _TOKEN1.www.example.com is the CNAME record format for www.example.com.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-11T14:32:04.288796"}}
{"question": "Can I use the same CNAME record for multiple certificate requests for the same domain name in the same AWS account?", "answer": "Yes, you can use the same DNS CNAME record for multiple certificate requests for the same domain name in the same AWS account.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-11T14:32:04.289078"}}
{"question": "How is the CNAME record generated for a wildcard domain name different from the CNAME record generated for a specific domain name?", "answer": "The main difference is that for a wildcard domain name (such as *.example.com), the CNAME record generated by AWS ACM does not include the wildcard label (*). Instead, it uses the same record as the one returned for the domain name without the wildcard label (example.com).", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-12", "source_tokens": 457, "generated_at": "2026-02-11T14:32:04.289214"}}
{"question": "What does ACM use to validate or re-validate a domain name when using a CNAME record?", "answer": "ACM uses a TXT record in an AWS domain (acm-validations.aws) that it can update as needed to validate or re-validate a domain name.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-11T14:32:09.526563"}}
{"question": "Why does using a CNAME record make it easier to obtain and renew certificates with ACM?", "answer": "Using a CNAME record allows you to configure the validation process once and then obtain and renew certificates for the associated domain name in any AWS Region where ACM is offered without creating another record.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-11T14:32:09.528170"}}
{"question": "How does email validation compare to using a CNAME record for certificate validation with ACM?", "answer": "Email validation requires an approval request email to be sent to the registered domain owner for each domain name in the certificate request, who then approves the certificate request by following the instructions in the email. In contrast, using a CNAME record allows ACM to validate or re-validate a domain name without any action from the user once the CNAME record is created and propagated.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-13", "source_tokens": 398, "generated_at": "2026-02-11T14:32:09.528315"}}
{"question": "What five special email addresses are used by ACM for validation when requesting a certificate for a domain?", "answer": "The five special email addresses used by ACM for validation when requesting a certificate for a domain are admin@, administrator@, hostmaster@, postmaster@, and webmaster@.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-11T14:32:14.581717"}}
{"question": "How does ACM handle email validation for domains with 'www' or wildcard names beginning with an asterisk (*)?", "answer": "ACM removes the leading 'www' or asterisk and sends email to the administrative addresses formed by pre-pending admin@, administrator@, hostmaster@, postmaster@, and webmaster@ to the remaining portion of the domain name.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-11T14:32:14.582047"}}
{"question": "How does managing email validation through ACM compare to managing it through a proxy?", "answer": "Managing email validation through ACM involves ACM sending validation emails directly to the email addresses on record, while managing it through a proxy may result in email delivery being delayed and potentially ending up in the spam folder.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-14", "source_tokens": 484, "generated_at": "2026-02-11T14:32:14.582479"}}
{"question": "Where is the private key of an ACM certificate stored if you obtain it in a specific Region?", "answer": "The private key of an ACM certificate is stored in the Region where you request the certificate.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-11T14:32:19.411788"}}
{"question": "How does ACM manage the renewal and deployment of SSL/TLS certificates?", "answer": "ACM manages the process of renewing SSL/TLS ACM certificates and deploying certificates after they are renewed. This helps avoid downtime due to expired certificates and allows centralized management and deployment of certificates on AWS.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-11T14:32:19.413699"}}
{"question": "What's the difference between managing SSL/TLS certificates manually and using ACM's managed renewal and deployment?", "answer": "Manual processes for managing SSL/TLS certificates can be error-prone and may lead to downtime due to expired certificates. ACM's managed renewal and deployment helps mitigate these risks by automating the process and integrating with other AWS services.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-15", "source_tokens": 322, "generated_at": "2026-02-11T14:32:19.414816"}}
{"question": "What happens when ACM cannot renew a public certificate without additional validation?", "answer": "ACM manages the renewal process by validating domain ownership or control for each domain name in the certificate. After each domain name in the certificate has been validated, ACM renews the certificate and automatically deploys it with your AWS resources.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-11T14:32:24.647784"}}
{"question": "How does ACM handle renewal of private certificates for use with on-premises resources and IoT devices?", "answer": "ACM renews the private certificate automatically, but you are responsible for retrieving the new certificate and private key and deploying them with your application.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-11T14:32:24.648067"}}
{"question": "What's the difference between the renewal process for public and private certificates issued with ACM?", "answer": "For public certificates, ACM can renew and deploy the certificate automatically if it's in use and validated. For private certificates, you are responsible for deploying the new certificate and private key if you exported it for use with on-premises resources, EC2 instances, and IoT devices.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-16", "source_tokens": 500, "generated_at": "2026-02-11T14:32:24.648515"}}
{"question": "What happens if I choose DNS validation for a public certificate in ACM?", "answer": "If you choose DNS validation in your certificate request for a public certificate, then ACM can renew your certificate without any further action from you, as long as the certificate is in use and your CNAME record remains in place.", "question_type": "factual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-11T14:32:30.336158"}}
{"question": "Why is it important to ensure a DNS lookup of a bare domain resolves to an AWS resource when requesting a public certificate?", "answer": "When requesting a public certificate with a bare domain, it's essential to ensure a DNS lookup of the bare domain resolves to the AWS resource that is associated with the certificate. This can be challenging unless you use Route 53 or another DNS provider that supports alias resource records for mapping bare domains to AWS resources.", "question_type": "conceptual", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-11T14:32:30.336420"}}
{"question": "What is the difference between DNS validation and email validation for public certificates in ACM?", "answer": "With DNS validation, ACM can renew your certificate without any further action if the certificate is in use and your CNAME record remains in place. In contrast, with email validation, you must ensure a DNS lookup of the bare domain resolves to the AWS resource associated with the certificate.", "question_type": "comparison", "metadata": {"service": "CERTIFICATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "certificate-faq-17", "source_tokens": 461, "generated_at": "2026-02-11T14:32:30.336607"}}
{"question": "What type of notifications can I receive through AWS Chatbot?", "answer": "You can receive notifications from AWS services such as CloudWatch alarms, Health events, Security Hub findings, Budgets alerts, CloudFormation stack events, and most AWS service events that are supported by Amazon EventBridge.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:32:36.951982"}}
{"question": "How can I interact with AWS services using AWS Chatbot?", "answer": "You can interact with AWS services by issuing AWS Command Line Interface (CLI) commands from Microsoft Teams and Slack channels. AWS Chatbot supports both read-only and mutative CLI commands for most AWS services, with the exception of commands related to credentials, authorization, and AWS Identity and Access Management (IAM) permissions.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:32:36.952297"}}
{"question": "What's the difference between using AWS Chatbot for notifications and using AWS SNS for notifications?", "answer": "AWS Chatbot and Amazon Simple Notification Service (SNS) serve different purposes. AWS Chatbot is an interactive agent that allows you to set up ChatOps for AWS in your chatrooms and receive notifications from AWS services. It also allows you to issue AWS CLI commands to retrieve diagnostic information, invoke AWS Lambda functions, and perform other actions. AWS SNS, on the other hand, is a fully managed pub/sub messaging service that enables you to send messages to multiple recipients, including email, SMS, mobile push notifications, webhooks, and other AWS services.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-0", "source_tokens": 502, "generated_at": "2026-02-11T14:32:36.952464"}}
{"question": "Which AWS service allows you to chat with a bot to get information about resources in your AWS account and troubleshoot issues?", "answer": "AWS Chatbot", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:32:41.632521"}}
{"question": "How can you use AWS Chatbot to improve your team's response to operational events and security findings?", "answer": "By configuring AWS Chatbot to publish notifications and run commands in a team channel or chatroom, team members can see and quickly act on operational events, security findings, and budget alerts, and discuss mitigation plans and resolve alarms together.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:32:41.632803"}}
{"question": "What are some of the key differences between AWS Chatbot and Amazon Lex?", "answer": "AWS Chatbot is a prebuilt interactive agent for monitoring, operating, and troubleshooting AWS resources (ChatOps), while Amazon Lex provides the advanced deep learning capabilities of automatic speech recognition (ASR) and natural language understanding (NLU) for building conversational bots.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:32:41.632972"}}
{"question": "Which services can be used to provision Microsoft Teams and Slack channel configurations in AWS?", "answer": "AWS CLI, AWS CloudFormation, AWS Cloud Control APIs, and SDKs can be used to provision Microsoft Teams and Slack channel configurations in AWS.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:32:46.276137"}}
{"question": "How can AWS Chatbot be used across multiple accounts and regions from a single channel?", "answer": "With IAM-based permissions, you can operate resources across multiple accounts and regions from a single AWS Chatbot channel.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:32:46.276402"}}
{"question": "How does managing Slack channel configurations with Terraform compare to managing them with AWS CLI and AWS CloudFormation?", "answer": "Terraform users can use the AWS provider to manage Slack channel configurations, while AWS CLI and AWS CloudFormation can also be used, but the specific comparison in terms of features, ease of use, or benefits would depend on the specific use case.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:32:46.276544"}}
{"question": "Which chat platforms does AWS Chatbot support for running commands?", "answer": "AWS Chatbot currently supports running commands in Microsoft Teams and Slack.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T14:32:50.183146"}}
{"question": "How does AWS Chatbot integrate with Amazon Chime?", "answer": "AWS Chatbot integrates with Amazon Chime via webhooks.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T14:32:50.183394"}}
{"question": "What is the difference in the installation process for AWS Chatbot in Microsoft Teams versus Slack?", "answer": "The installation for AWS Chatbot in Microsoft Teams is performed through a click-through flow in a browser or using AWS CloudFormation templates. In contrast, the installation for AWS Chatbot in Slack is carried out using an OAuth 2.0 flow in a browser.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T14:32:50.183528"}}
{"question": "What kind of notifications can AWS Chatbot send for application events?", "answer": "AWS Chatbot can send custom notifications for application events by sending the event in a Chatbot custom notification schema format to an SNS topic.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-11T14:32:54.825432"}}
{"question": "Why can't I use SNS topics from different AWS accounts in the same AWS Chatbot configuration?", "answer": "Each AWS Chatbot configuration is linked to a separate AWS account, so they will be independent of each other. Only SNS topics from the same AWS account that hosts the AWS Chatbot configuration can be used.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-11T14:32:54.825686"}}
{"question": "Can I filter AWS service event notifications using AWS Chatbot?", "answer": "While you cannot directly customize the formatting of AWS service event notifications, you can use AWS Chatbot custom notifications to add additional information and filter notifications using an Amazon SNS filter policy or Amazon CloudWatch Event Rules for events that support filtering.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-4", "source_tokens": 485, "generated_at": "2026-02-11T14:32:54.825853"}}
{"question": "Which AWS services does AWS Chatbot support notifications for?", "answer": "AWS Chatbot supports notifications for most AWS services that are handled by Amazon EventBridge.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-11T14:32:59.249582"}}
{"question": "How can I stop receiving notifications from a specific channel or chatroom in AWS Chatbot?", "answer": "To stop receiving notifications from a channel or chatroom, remove the respective configuration or remove specific Amazon SNS topics from the AWS Chatbot configuration.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-11T14:32:59.249889"}}
{"question": "What's the difference between running AWS CLI commands in AWS Chatbot and running them directly in the AWS CLI?", "answer": "You can run both read-only and mutative AWS CLI commands in Microsoft Teams and Slack channels using AWS Chatbot. However, there are limitations compared to running commands directly in the AWS CLI, such as access to certain services and commands being disabled.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-5", "source_tokens": 474, "generated_at": "2026-02-11T14:32:59.250055"}}
{"question": "What actions can be taken by clicking buttons on AWS Chatbot notifications?", "answer": "Message actions are shortcuts that let users take quick action by clicking a button on notifications and messages sent by AWS Chatbot. For example, CloudWatch Alarm notifications for Lambda functions and API Gateway stages have â€˜Show Logsâ€™ and â€˜Show Error Logsâ€™ buttons that display the logs for the affected resource in the chat channel.", "question_type": "factual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T14:33:05.646757"}}
{"question": "How does AWS Chatbot control permissions for accessing accounts?", "answer": "Customers can use chatbot policies and multi-account management services in AWS Organizations to determine which permissions models, chat applications, and chat workspaces can be used to access their accounts. For example, you can restrict access to production accounts from chat channels in designated workspaces/teams. Customers can also use Service Control Policies (SCPs) to specify guardrails on the CLI command tasks executed from chat channels.", "question_type": "conceptual", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T14:33:05.646984"}}
{"question": "What's the difference between using a shared channel IAM role and requiring channel members to choose an IAM role to run commands in AWS Chatbot?", "answer": "With a shared channel role, all channel members use a shared IAM role to run commands. Alternatively, you can configure AWS Chatbot to require channel members to choose an IAM role to run commands. The permissions scope is further controlled by channel guardrail IAM policies.", "question_type": "comparison", "metadata": {"service": "CHATBOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "chatbot-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T14:33:05.647126"}}
{"question": "What programming languages are supported by AWS CDK for defining cloud infrastructure as code?", "answer": "AWS CDK supports modern programming languages for defining cloud infrastructure as code, including but not limited to TypeScript.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:33:09.916313"}}
{"question": "How does AWS Construct Library work within the AWS CDK framework?", "answer": "AWS Construct Library packages are built using TypeScript by AWS and provide mappings into each of the supported programming languages. This allows for consistent behavior of AWS CDK constructs across different languages.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:33:09.916612"}}
{"question": "What are the main differences between using AWS CDK with CloudFormation and SAM?", "answer": "AWS CDK allows you to define and deploy AWS resources using modern programming languages, while CloudFormation and Serverless Application Model (SAM) are alternative methods for creating and managing AWS resources using templates.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-0", "source_tokens": 487, "generated_at": "2026-02-11T14:33:09.917015"}}
{"question": "Where can I find the AWS CDK code repository?", "answer": "The AWS CDK code is available on GitHub at https://github.com/awslabs/aws-cdk", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-11T14:33:13.697493"}}
{"question": "What programming languages is AWS CDK available in?", "answer": "AWS CDK is available in JavaScript, TypeScript, Python, Java, C#, and Go (in Developer Preview)", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-11T14:33:13.697735"}}
{"question": "How does the availability of AWS CDK constructs compare between local and shared package managers?", "answer": "Constructs can be defined locally or published to package managers such as npm, Maven, NuGet, or PyPI for sharing across organizations", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-1", "source_tokens": 467, "generated_at": "2026-02-11T14:33:13.698244"}}
{"question": "What services does the AWS Construct Library cover with high-level constructs?", "answer": "The AWS Construct Library covers many common AWS services and features with rich, high-level constructs.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-11T14:33:18.373751"}}
{"question": "How does the AWS Construct Library stay updated with new AWS services?", "answer": "The AWS Construct Library stays updated with new AWS services by autogenerating resource-level APIs every time the CloudFormation specification changes.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-11T14:33:18.374006"}}
{"question": "What is the difference between using the AWS Construct Library and CloudFormation directly for defining AWS infrastructure as code?", "answer": "The AWS Construct Library provides handcrafted, higher-level abstractions on top of the autogenerated CloudFormation APIs, making it easier to work with each service. With CloudFormation, you write your infrastructure as JSON or YAML templates. The AWS Construct Library applications compile down to these templates, which are then submitted to CloudFormation for provisioning.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-2", "source_tokens": 366, "generated_at": "2026-02-11T14:33:18.374173"}}
{"question": "What programming languages can AWS CDK be used to define cloud infrastructure in?", "answer": "AWS CDK can be used to define cloud infrastructure in TypeScript, Python, C#, and Java.", "question_type": "factual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-11T14:33:22.151822"}}
{"question": "How does AWS CDK compare to AWS SAM in terms of use cases and templates?", "answer": "AWS CDK offers broad coverage across all AWS services and allows users to define infrastructure in modern programming languages, while AWS SAM is specifically focused on serverless use cases and architectures and uses compact, declarative JSON/YAML templates.", "question_type": "comparison", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-11T14:33:22.152125"}}
{"question": "Why would someone prefer using AWS SAM over AWS CDK for serverless infrastructure?", "answer": "Someone would prefer using AWS SAM over AWS CDK for serverless infrastructure if they want to define their serverless infrastructure in concise, declarative templates.", "question_type": "conceptual", "metadata": {"service": "CLOUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloud-faq-3", "source_tokens": 352, "generated_at": "2026-02-11T14:33:22.152284"}}
{"question": "What is AWS CloudFormation and how does it abstract away complexity of resource APIs?", "answer": "AWS CloudFormation is a service that helps developers create and manage a collection of related AWS and third-party resources, provision and manage them in an orderly and predictable fashion. It abstracts away the complexity of specific resource APIs, allowing resource lifecycles to be managed repeatably, predictably, and safely.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-11T14:33:27.912196"}}
{"question": "What are the recent enhancements to AWS CloudFormation that allow for multiple ways to create resources?", "answer": "AWS CloudFormation now offers multiple ways to create resources, including using AWS CDK for coding in higher-level languages, importing existing resources, detecting configuration drift, and using the new Registry to create custom types that inherit many core CloudFormation benefits.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-11T14:33:27.912456"}}
{"question": "How does AWS CloudFormation with the Registry compare to other methods of creating resources in AWS?", "answer": "Using AWS CloudFormation with the Registry allows for the creation of custom types that inherit many core CloudFormation benefits, making it a convenient and powerful way to manage resources in AWS. However, other methods such as using AWS CDK or importing existing resources may offer different advantages based on specific use cases.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-0", "source_tokens": 295, "generated_at": "2026-02-11T14:33:27.912861"}}
{"question": "What is the primary function of AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk is a service that allows you to easily deploy and run applications in the cloud. It provides a one-stop experience for managing application lifecycle and is integrated with developer tools.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-11T14:33:32.852239"}}
{"question": "How does AWS CloudFormation support AWS Elastic Beanstalk?", "answer": "AWS CloudFormation supports AWS Elastic Beanstalk by allowing you to create and manage AWS Elastic Beanstalk application environments along with other resources, such as an RDS database, as part of a stack.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-11T14:33:32.852548"}}
{"question": "What is the difference between an AWS Elastic Beanstalk stack and an AWS CloudFormation stack set?", "answer": "An AWS Elastic Beanstalk stack is a single deployment unit that manages a group of resources related to an Elastic Beanstalk application, while a stack set is a group of stacks that can be managed together and can replicate the resources in each stack.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-1", "source_tokens": 450, "generated_at": "2026-02-11T14:33:32.852922"}}
{"question": "What types of elements does a CloudFormation template consist of?", "answer": "CloudFormation templates are comprised of five types of elements: an optional list of template parameters, an optional list of output values, an optional list of data tables, the list of AWS resources and their configuration values, and a template file format version number.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-11T14:33:39.184884"}}
{"question": "How can CloudFormation template parameters be used and what benefits do they offer?", "answer": "CloudFormation template parameters are used to customize aspects of your template at run time, when the stack is built. They offer benefits such as allowing for additional rules, best practices, and compliance controls. Each parameter can have a default value and description, and may be marked as â€˜NoEchoâ€™ to hide the actual value entered on the screen and in the AWS CloudFormation event logs. When creating an AWS CloudFormation stack, the AWS Management Console will present a pop-up dialog form for editing parameter values.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-11T14:33:39.185147"}}
{"question": "What is the difference between CloudFormation template output values and template parameters?", "answer": "CloudFormation template output values are a convenient way to present a stackâ€™s key resources to the user via the AWS Management Console or command line tools. Output values are the result of a stack creation. On the other hand, CloudFormation template parameters are used to customize aspects of your template at run time, when the stack is built.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-2", "source_tokens": 458, "generated_at": "2026-02-11T14:33:39.185297"}}
{"question": "What does AWS CloudFormation do when creating a stack from a template with regard to logical resource names?", "answer": "AWS CloudFormation binds the logical names assigned to resources in a template to the names of the corresponding actual AWS resources upon stack creation. This helps prevent name collisions between resources in multiple stacks.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-11T14:33:44.019777"}}
{"question": "Why doesn't AWS CloudFormation allow you to name all resources in a template?", "answer": "AWS CloudFormation restricts resource naming to avoid issues related to reusability of templates and naming conflicts that can occur when a resource is replaced during an update.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-11T14:33:44.020075"}}
{"question": "How does AWS CloudFormation compare to using Terraform for resource creation in terms of bootstrapping software on EC2 instances?", "answer": "Both AWS CloudFormation and Terraform can be used to bootstrap software on EC2 instances, but while AWS CloudFormation provides built-in support for popular software configurations and integrations with other AWS services like Systems Manager and configuration management tools, Terraform offers more flexibility and the ability to use external resource providers and integrations.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-3", "source_tokens": 500, "generated_at": "2026-02-11T14:33:44.020456"}}
{"question": "What feature allows CloudFormation to revert to the last known stable configuration when an operation fails?", "answer": "The 'automatic rollback on error' feature enables CloudFormation to revert the stack to the last known stable configuration when an operation fails.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-11T14:33:48.697155"}}
{"question": "How can you ensure that other resources in CloudFormation are only created after a specific resource is ready?", "answer": "You can use the 'WaitCondition' resource in CloudFormation to act as a barrier and block the creation of other resources until a completion signal is received from an external source.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-11T14:33:48.697370"}}
{"question": "What are some benefits of using CloudFormation to manage your AWS infrastructure instead of individual manual processes?", "answer": "CloudFormation allows you to define your infrastructure as code, apply version control, and manage updates in a controlled and predictable way. It also supports creating various AWS resources and allowing you to bring existing resources into management using Resource Import.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-4", "source_tokens": 509, "generated_at": "2026-02-11T14:33:48.697539"}}
{"question": "What is required to sign up for CloudFormation?", "answer": "Signing up for CloudFormation involves clicking 'Create Free Account' on the product page and providing a valid phone number and email address with AWS.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T14:33:53.698371"}}
{"question": "Why should you use the CloudFormation Getting Started Guide?", "answer": "The Getting Started Guide is the best way to get started with CloudFormation as it provides detailed instructions on how to deploy and use one of the sample templates, illustrating how to create the infrastructure needed to run applications such as WordPress.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T14:33:53.698700"}}
{"question": "How do CloudFormation sample templates differ from third-party templates?", "answer": "CloudFormation sample templates are provided by AWS and can be used to test drive the offering and explore its functionality. They illustrate how to interconnect and use multiple AWS resources in concert, following best practices for multiple Availability Zone redundancy, scale out, and alarming. Third-party templates must be registered before they can be used to provision resources with AWS CloudFormation templates.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T14:33:53.699206"}}
{"question": "What is a resource provider in AWS and what does it contain?", "answer": "A resource provider in AWS is a set of resource types with specifications and handlers that control the lifecycle of underlying resources via create, read, update, delete, and list operations. It includes resource types and their corresponding specifications.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:33:58.544570"}}
{"question": "How do third-party resource providers differ from AWS resource providers?", "answer": "Third-party resource providers differ from AWS resource providers in their origin. AWS resource providers are built and maintained by Amazon and AWS, while third-party resource providers are built by another company, organization, or the developer community. They can help manage both AWS and non-AWS resources.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:33:58.544796"}}
{"question": "What is a resource schema and what does it include?", "answer": "A resource schema in AWS defines a resource type in a structured and consistent format. It includes all the supported parameters and attributes for a given resource type, as well as the required permissions to create the resource.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:33:58.544970"}}
{"question": "What is the CloudFormation Public Registry and when was it launched?", "answer": "The CloudFormation Public Registry is a new, searchable and managed catalog of extensions for AWS CloudFormation. It was launched in November 2019.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-11T14:34:03.602634"}}
{"question": "How does the CloudFormation Public Registry make it easier to manage infrastructure and applications?", "answer": "The CloudFormation Public Registry provides a central location for discovering, finding, consuming, and managing Resource Types and Modules for both AWS and third-party products. This makes it easier to configure and manage infrastructure and applications in a consistent manner.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-11T14:34:03.602913"}}
{"question": "What is the difference between the CloudFormation Private Registry and the CloudFormation Public Registry?", "answer": "The CloudFormation Private Registry is a private listing that allows customers to extend CloudFormation for their own private use. The CloudFormation Public Registry is an extension of the CloudFormation Registry and adds a public, searchable catalog for sharing and discovering resource types and modules.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-7", "source_tokens": 342, "generated_at": "2026-02-11T14:34:03.603074"}}
{"question": "What is a Resource Type in AWS CloudFormation and how does it allow users to manage resources?", "answer": "A Resource Type in AWS CloudFormation is a code package containing provisioning logic that allows users to manage the lifecycle of a resource, abstracting away complex API interactions. It contains a schema that defines the shape and properties of a resource and the necessary logic to provision, update, delete, and describe a resource.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T14:34:09.437299"}}
{"question": "What are the charges for using AWS CloudFormation with resource providers outside the AWS, Alexa, and Custom namespaces?", "answer": "There is a charge per handler operation when using resource providers with AWS CloudFormation outside the mentioned namespaces. Handler operations are create, update, delete, read, or list actions on a resource.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T14:34:09.437582"}}
{"question": "How does creating a resource using AWS CloudFormation compare to creating it manually in terms of costs and charges?", "answer": "When you create an AWS resource using AWS CloudFormation within the namespaces AWS, Alexa, and Custom, there are no additional charges. You pay for the AWS resources created just as if you had created them manually. However, when you use resource providers with AWS CloudFormation outside these namespaces, you incur charges per handler operation.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T14:34:09.437730"}}
{"question": "What section in AWS CloudFormation quotas should I refer to for information about the number of parameters and outputs I can specify in a template?", "answer": "The Parameters and Outputs sections in AWS CloudFormation quotas.", "question_type": "factual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-11T14:34:14.166389"}}
{"question": "How does creating smaller templates and stacks and modularizing your application across multiple stacks benefit me in AWS CloudFormation?", "answer": "Creating smaller templates and stacks and modularizing your application across multiple stacks in AWS CloudFormation helps minimize the blast radius for your resource changes, and makes troubleshooting issues with multiple resource dependencies faster, since smaller groups of resources will have less complex dependencies than larger groups.", "question_type": "conceptual", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-11T14:34:14.166652"}}
{"question": "What's the difference between the number of resources I can declare in a template and the number of parameters and outputs I can specify?", "answer": "The number of resources you can declare in a template and the number of parameters and outputs you can specify are two separate quotas in AWS CloudFormation.", "question_type": "comparison", "metadata": {"service": "CLOUDFORMATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudformation-faq-9", "source_tokens": 208, "generated_at": "2026-02-11T14:34:14.167013"}}
{"question": "How many edge locations does Amazon CloudFront have?", "answer": "Amazon CloudFront has 16 edge locations.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-11T14:34:17.922539"}}
{"question": "What protocols does Amazon CloudFront support for content delivery?", "answer": "Amazon CloudFront supports HTTP, HTTP/2, and HTTP/3 for content delivery.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-11T14:34:17.922764"}}
{"question": "What are the benefits of using CloudFront over another self-hosted solution for content delivery?", "answer": "Using Amazon CloudFront offers several benefits over a self-hosted solution for content delivery, including a global network of edge locations for low latency and high data transfer rates, easy setup without minimum commitments or contracts, and integration with other AWS services.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-0", "source_tokens": 409, "generated_at": "2026-02-11T14:34:17.922935"}}
{"question": "What domain name should I use to distribute static files through Amazon CloudFront?", "answer": "You should use the CloudFront.net domain name or a CNAME alias for your Amazon S3 bucket as the origin for your static files.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-11T14:34:22.497584"}}
{"question": "How does Amazon CloudFront improve the performance of serving content to viewers?", "answer": "Amazon CloudFront uses a global network of edge locations and regional edge caches to cache copies of your content close to your viewers, ensuring that end-user requests are served by the closest edge location. It also keeps persistent connections with your origin servers to fetch files quickly.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-11T14:34:22.497832"}}
{"question": "What's the difference between using Amazon S3 and Amazon EC2 as an origin server for CloudFront?", "answer": "Amazon S3 is used for storing and distributing static files, while Amazon EC2 is used for dynamically generated content that is personalized or customized.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-1", "source_tokens": 482, "generated_at": "2026-02-11T14:34:22.498409"}}
{"question": "What expenses and complexities does Amazon CloudFront help you avoid compared to self-hosting?", "answer": "Amazon CloudFront spares you from the expense and complexity of operating a network of cache servers in multiple sites across the internet and eliminates the need to over-provision capacity to serve potential spikes in traffic.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-11T14:34:27.074249"}}
{"question": "What is the benefit of using a single Amazon CloudFront distribution for all content?", "answer": "Delivering all your content using a single Amazon CloudFront distribution helps ensure that performance optimizations are applied to your entire website or web application.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-11T14:34:27.074483"}}
{"question": "What are the advantages of using Amazon CloudFront over self-hosting for distributing static content?", "answer": "Amazon CloudFront helps avoid the expense and complexity of operating a network of cache servers, reduces load on origin servers, eliminates the need for over-provisioning, and effectively charges for what you use.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-2", "source_tokens": 404, "generated_at": "2026-02-11T14:34:27.074938"}}
{"question": "What protocols does Amazon CloudFront support for content delivery?", "answer": "Amazon CloudFront supports content delivery using the HTTP and WebSocket protocols.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-11T14:34:31.189108"}}
{"question": "Why is Amazon CloudFront integration with other AWS services beneficial?", "answer": "Amazon CloudFront's integration with other AWS services like Amazon S3, Amazon EC2, Elastic Load Balancing, Amazon Route 53, and AWS CloudFormation provides further performance benefits and ease of configuration.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-11T14:34:31.189367"}}
{"question": "How does having a backup origin in Amazon CloudFront help?", "answer": "A backup origin in Amazon CloudFront can be used to automatically serve traffic when the primary origin is unavailable. This failover can be triggered by specific HTTP status codes returned from the primary origin.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-3", "source_tokens": 511, "generated_at": "2026-02-11T14:34:31.189797"}}
{"question": "What method allows you to map the apex or root of a DNS name to an Amazon CloudFront distribution using Amazon Route 53?", "answer": "You can create an ALIAS record in Amazon Route 53 that lets you map the apex or root of your DNS name to your Amazon CloudFront distribution.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:34:38.206139"}}
{"question": "How does CloudFront improve content delivery performance for viewers?", "answer": "CloudFront delivers content through a worldwide network of data centers called edge locations. It also uses Regional Edge Caches (RECs), which are located between your origin webserver and AWS edge locations, to cache content and reduce the need for CloudFront to go back to your origin webserver. This helps keep more of your content closer to your viewers, improving overall performance for viewers.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:34:38.206358"}}
{"question": "What's the difference between using Amazon Route 53's ALIAS records and CloudFront's Anycast Static IPs to point your apex domain to a CloudFront distribution?", "answer": "Using Amazon Route 53's ALIAS records lets you map the apex domain to the CloudFront distribution for free, and Route 53 will respond to queries with the right IP addresses for your CloudFront distribution. With CloudFront's Anycast Static IPs, you can point your apex domain to your CloudFront distribution using any DNS provider, and this feature extends apex domain support beyond Route 53. However, using this method incurs a charge for queries to the non-Amazon DNS provider.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-4", "source_tokens": 488, "generated_at": "2026-02-11T14:34:38.206557"}}
{"question": "What is the default expiration period for CloudFront to check for updated versions of files if no cache control headers are set?", "answer": "By default, the expiration period for CloudFront to check for updated versions of files if no cache control headers are set is 24 hours.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-11T14:34:43.406525"}}
{"question": "Why does Amazon CloudFront use a global network of edge locations and regional edge caches for content delivery?", "answer": "Amazon CloudFront uses a global network of edge locations and regional edge caches for content delivery to provide fast and efficient delivery of content to viewers, reducing the latency and improving the user experience.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-11T14:34:43.406785"}}
{"question": "How does the Geo Restriction feature of CloudFront compare to specifying IP addresses for access control?", "answer": "The Geo Restriction feature of CloudFront allows users to specify a list of countries in which users can or cannot access content, whereas specifying IP addresses for access control involves manually adding and managing each IP address. The Geo Restriction feature offers a more flexible and efficient way to manage access control based on geographic locations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-5", "source_tokens": 446, "generated_at": "2026-02-11T14:34:43.407145"}}
{"question": "What are the ways to remove a file from Amazon CloudFront edge locations?", "answer": "You can delete the file from your origin and wait for it to expire, or use the Invalidation API to remove it from all edge locations before the expiration time.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-11T14:34:48.184643"}}
{"question": "Why should you use the Invalidation API instead of waiting for the file to expire?", "answer": "You should use the Invalidation API when you need to remove a file before its specified expiration time, such as in cases of offensive or potentially harmful material.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-11T14:34:48.184878"}}
{"question": "What's the difference between invalidating objects individually and using the wildcard?", "answer": "When invalidating objects individually, you can have up to 3,000 requests in progress at one time. With the wildcard, you can have up to 15 requests for invalidation paths and up to 3,000 requests for individual objects, but the limits are independent of each other.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-6", "source_tokens": 465, "generated_at": "2026-02-11T14:34:48.185264"}}
{"question": "What type of networks are CloudFront embedded POPs deployed in?", "answer": "CloudFront embedded POPs are deployed directly in ISP and MNO networks.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-11T14:34:52.424422"}}
{"question": "How does CloudFront determine which type of POP to use for content delivery?", "answer": "CloudFront's routing system dynamically utilizes both CloudFront POPs and embedded POPs to deliver content, ensuring optimal performance for end users.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-11T14:34:52.424658"}}
{"question": "What is the main difference in the content delivered by CloudFront embedded POPs and CloudFront POPs?", "answer": "CloudFront embedded POPs are designed to deliver large scale cacheable traffic such as video streams and game downloads, whereas CloudFront POPs are designed to deliver a variety of workloads including both cacheable and dynamic content.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-7", "source_tokens": 451, "generated_at": "2026-02-11T14:34:52.425038"}}
{"question": "What compliance standards does Amazon CloudFront (excluding content delivery through CloudFront Embedded POPs) adhere to?", "answer": "Amazon CloudFront (excluding content delivery through CloudFront Embedded POPs) is compliant with the Payment Card Industry Data Security Standard (PCI DSS) Merchant Level 1 and HIPAA. It is also included in AWS's expanded HIPAA compliance program.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T14:34:58.961755"}}
{"question": "Why is Amazon CloudFront (excluding content delivery through CloudFront Embedded POPs) a suitable service for handling protected health information (PHI)?", "answer": "Amazon CloudFront (excluding content delivery through CloudFront Embedded POPs) is a suitable service for handling protected health information (PHI) because it is compliant with HIPAA and if you have an executed Business Associate Agreement (BAA) with AWS, you can use it to accelerate the delivery of PHI.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T14:34:58.961993"}}
{"question": "How does the handling of POST, PUT, DELETE, and PATCH requests differ from that of GET, HEAD, OPTIONS requests in Amazon CloudFront?", "answer": "Responses to POST, PUT, DELETE, and PATCH requests are not cached in Amazon CloudFront, they are proxied back to the origin server. In contrast, responses to GET, HEAD, and OPTIONS requests can be cached.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T14:34:58.962358"}}
{"question": "What HTTP versions can I choose from when managing an existing Amazon CloudFront distribution?", "answer": "You can choose from HTTP/2, HTTP/1.1, and HTTP/1.0.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-11T14:35:03.456557"}}
{"question": "How does Amazon CloudFront handle HTTP/2 for content delivery and communication with origin servers?", "answer": "Amazon CloudFront uses HTTP/2 for content delivery to viewers' clients and browsers, but for communication between the edge location and origin servers, it continues to use HTTP/1.1.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-11T14:35:03.456848"}}
{"question": "What are the main differences between HTTP/2 and the newer HTTP/3?", "answer": "HTTP/3 uses QUIC, a UDP-based, stream-multiplexed, and secure transport protocol, compared to HTTP/2's TCP-based, stream-multiplexed, and secure transport. HTTP/3 offers faster response times and enhanced security.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-9", "source_tokens": 350, "generated_at": "2026-02-11T14:35:03.457235"}}
{"question": "What version of HTTP does CloudFront support with 1-RTT for TLS handshake?", "answer": "CloudFront supports HTTP/3 for TLS handshake with 1-RTT.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-11T14:35:06.969116"}}
{"question": "How does HTTP/3 improve web performance compared to previous versions?", "answer": "HTTP/3 offers improved web performance by supporting client-side connection migrations, allowing faster re-connections during network handoffs, and being better suited for congested networks.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-11T14:35:06.969473"}}
{"question": "What security features does HTTP/3 offer compared to previous versions of HTTP?", "answer": "HTTP/3 offers more comprehensive security by encrypting packets exchanged during TLS handshakes, making inspection by middleboxes harder and reducing man-in-the-middle attacks.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-10", "source_tokens": 365, "generated_at": "2026-02-11T14:35:06.969632"}}
{"question": "What protocols can clients use to communicate with HTTP/3 enabled CloudFront distributions?", "answer": "Clients can use HTTP/1.1, HTTP/2, or HTTP/3 to communicate with HTTP/3 enabled CloudFront distributions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-11T14:35:11.194279"}}
{"question": "Why does CloudFront automatically add the Alt-Svc header when enabling HTTP/3?", "answer": "CloudFront automatically adds the Alt-Svc header to advertise HTTP/3 support and enable fallback support for clients that don't support HTTP/3.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-11T14:35:11.194537"}}
{"question": "How does HTTP/3 communication differ between viewers and origin servers in CloudFront?", "answer": "HTTP/3 communication is used between viewersâ€™ clients/browsers and CloudFront edge locations, while HTTP/1.1 is used between the edge location and origin servers.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-11", "source_tokens": 467, "generated_at": "2026-02-11T14:35:11.194686"}}
{"question": "What type of AWS service does CloudFront SaaS Manager belong to?", "answer": "CloudFront SaaS Manager is a service offered by AWS for managing multiple websites efficiently.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-11T14:35:15.519187"}}
{"question": "In what way does CloudFront SaaS Manager benefit SaaS and web development platform providers?", "answer": "CloudFront SaaS Manager allows SaaS and web development platform providers to maintain consistent settings across their tenants' websites.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-11T14:35:15.519542"}}
{"question": "What's the difference between a multi-tenant distribution and a standard (single tenant) distribution in CloudFront?", "answer": "A multi-tenant distribution defines the base configuration that will be shared across domains, containing shared configuration settings. Unlike a standard distribution, a multi-tenant distribution cannot serve traffic directly and offers customizable, parametrized fields to meet each domain's unique needs.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-12", "source_tokens": 423, "generated_at": "2026-02-11T14:35:15.519706"}}
{"question": "What certificates does CloudFront work with for domain control validation?", "answer": "CloudFront works with AWS Certificate Manager (ACM) to provide a seamless domain control validation experience for Amazon-issued SSL/TLS certificates. It also supports certificates issued by 3rd party CAs, in which case the certificate lifecycle management is the responsibility of the account owner.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-11T14:35:21.122123"}}
{"question": "How does CloudFront simplify SSL/TLS certificate management?", "answer": "CloudFront integrates with AWS Certificate Manager (ACM) to remove the burden of certificate issuance and management and provide automated lifecycle management for Amazon-issued SSL/TLS certificates.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-11T14:35:21.122453"}}
{"question": "What's the difference between using CloudFront for apex domains with and without Route 53?", "answer": "When using Route 53 to manage DNS, customers can add an ALIAS record for their apex domain to point to a CloudFront provided domain. For customers who cannot use Route 53, Anycast Static IPs can provide dedicated IP addresses to replace CNAME/ALIAS records. The main difference is in the method of managing the DNS records.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-13", "source_tokens": 475, "generated_at": "2026-02-11T14:35:21.122646"}}
{"question": "What headers must a client include to establish a WebSocket connection with Amazon CloudFront?", "answer": "The client must include the 'Upgrade: websocket' header and the server responds with the HTTP status code 101 to confirm the switch to the WebSocket protocol.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-11T14:35:25.638597"}}
{"question": "How does gRPC communication differ from Amazon CloudFront's WebSocket connections?", "answer": "gRPC uses a persistent open connection over HTTP/2 for bidirectional communication, while Amazon CloudFront establishes WebSocket connections upon specific header conditions.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-11T14:35:25.638936"}}
{"question": "What are the requirements for Amazon CloudFront to communicate over gRPC?", "answer": "HTTP/2 must be enabled on the distribution, POST requests and gRPC must be enabled on a cache behavior, and a client must send a 'content-type' header with the value of 'application/grpc' over an HTTP/2 connection.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-14", "source_tokens": 303, "generated_at": "2026-02-11T14:35:25.639103"}}
{"question": "What encryption does HTTP/2 provide for gRPC traffic in AWS?", "answer": "HTTP/2 provides end-to-end encryption for gRPC traffic from the client to origin servers in AWS.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-11T14:35:29.822739"}}
{"question": "How does gRPC's use of Protocol Buffers help improve performance?", "answer": "gRPC's use of Protocol Buffers as a binary message format results in smaller payloads than traditional JSON used in REST APIs, making parsing less CPU-intensive and exchanging messages faster.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-11T14:35:29.822988"}}
{"question": "What are the different streaming options available with gRPC on CloudFront?", "answer": "gRPC on CloudFront supports unary (no streaming), client-to-server streaming, server-to-client streaming, and bi-directional streaming.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-15", "source_tokens": 441, "generated_at": "2026-02-11T14:35:29.823375"}}
{"question": "What encryption does CloudFront use between the end user and itself, and between CloudFront and the origin?", "answer": "CloudFront uses SSL/TLS encryption between the end user and itself, and between CloudFront and the origin.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-11T14:35:34.598528"}}
{"question": "How does field-level encryption improve security in a microservices architecture?", "answer": "Field-level encryption ensures that only authorized micro-services, which possess the private keys, can decrypt and access sensitive data. This prevents unauthorized access to sensitive information even if one micro-service is compromised.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-11T14:35:34.598761"}}
{"question": "How does field-level encryption in CloudFront compare to encryption at the origin?", "answer": "Field-level encryption in CloudFront allows edge locations to encrypt sensitive data before it reaches the origin. This means that only authorized micro-services with the private keys can decrypt the data. In contrast, encryption at the origin encrypts all data before it leaves the origin, but any micro-service with the decryption key can access it.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-16", "source_tokens": 228, "generated_at": "2026-02-11T14:35:34.599143"}}
{"question": "What is the cost of using Dedicated IP Custom SSL in AWS CloudFront per month?", "answer": "The cost of using Dedicated IP Custom SSL in AWS CloudFront is $600 per month, prorated by the hour.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-11T14:35:41.412213"}}
{"question": "How does SNI Custom SSL differ from Dedicated IP Custom SSL in terms of SSL delivery and browser compatibility?", "answer": "SNI Custom SSL delivers SSL content from each CloudFront edge location with the same security as Dedicated IP Custom SSL but relies on the SNI extension of the TLS protocol to identify the domain of the SSL request. This allows multiple domains to serve SSL traffic over the same IP address and works with most modern browsers. Dedicated IP Custom SSL, on the other hand, allocates dedicated IP addresses to serve SSL content, providing a one to one mapping between IP addresses and SSL certificates, and works with browsers and other clients that do not support SNI but has a higher cost.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-11T14:35:41.412446"}}
{"question": "Why is SNI an extension of the TLS protocol important for SSL delivery in AWS CloudFront?", "answer": "SNI (Server Name Indication) is an extension of the TLS protocol that identifies the domain (server name) of the associated SSL request, allowing multiple domains to serve SSL traffic over the same IP address. This is important for SSL delivery in AWS CloudFront as it allows for more efficient use of IP addresses and broadens the range of clients that can connect to CloudFront to load the HTTPS version of content.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-17", "source_tokens": 436, "generated_at": "2026-02-11T14:35:41.412586"}}
{"question": "What service does AWS provide for managing SSL/TLS certificates and associating them with CloudFront distributions?", "answer": "AWS Certificate Manager (ACM)", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T14:35:45.137765"}}
{"question": "How does the optional private content feature of Amazon CloudFront work?", "answer": "Amazon CloudFront only delivers files when you securely sign requests, allowing you to control when the files are delivered.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T14:35:45.137981"}}
{"question": "What's the difference between AWS Shield Standard and AWS Shield Advanced?", "answer": "AWS Shield Standard provides protection against common DDoS attacks at no additional cost. AWS Shield Advanced is an optional paid service for AWS Business Support and AWS Enterprise Support customers, offering additional protections against larger and more sophisticated attacks for applications running on Elastic Load Balancing, Amazon CloudFront, and Route 53.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T14:35:45.138338"}}
{"question": "What are the two ways CloudFront offers to protect origins?", "answer": "CloudFront offers two ways to protect origins: Origin Access Control (OAC) and CloudFront Virtual Private Cloud (VPC) origins.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-11T14:35:50.150373"}}
{"question": "How does CloudFront Origin Access Control (OAC) work and what can it restrict access to?", "answer": "CloudFront Origin Access Control (OAC) is a security feature that restricts access to Amazon Simple Storage Service (S3) Origins, AWS Elemental Origins, and Lambda Function URLs. It ensures that only CloudFront can access the content.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-11T14:35:50.150595"}}
{"question": "What's the difference between CloudFront Origin Access Control (OAC) and IP allowlisting for securing origins?", "answer": "CloudFront Origin Access Control (OAC) is a CloudFront feature that restricts access to your origins based on specific header values. IP allowlisting involves configuring your origin's security group or firewall to exclusively permit incoming traffic from CloudFront's IP ranges.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-19", "source_tokens": 426, "generated_at": "2026-02-11T14:35:50.150936"}}
{"question": "What type of applications can be used with CloudFront VPC origins?", "answer": "CloudFront VPC origins can be used with applications running on Application Load Balancer (ALB), Network Load Balancer (NLB), and EC2 instances.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-11T14:35:55.228901"}}
{"question": "Why should I use VPC origins with CloudFront?", "answer": "You should use VPC origins with CloudFront if you want to enhance your web applications' security while maintaining high performance and global scalability. It allows you to restrict access to your origins in a VPC only to your CloudFront distributions without complex configurations and optimizes IPv4 costs by allowing you to route to origins in a private subnet with internal IPv4 IP addresses.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-11T14:35:55.229111"}}
{"question": "How does using VPC origins with CloudFront compare to using origins with external DNS names?", "answer": "Using VPC origins with CloudFront allows you to restrict access to your origins in a VPC only to your CloudFront distributions without requiring externally resolvable DNS names. This enhances security and potentially simplifies configuration management.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-20", "source_tokens": 289, "generated_at": "2026-02-11T14:35:55.229469"}}
{"question": "What security benefit does VPC origin provide by making CloudFront the sole ingress point?", "answer": "VPC origin enhances the security posture of applications by making CloudFront the sole ingress point, as all user requests go from CloudFront to the VPC origins over a private, secure connection.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-11T14:36:00.304311"}}
{"question": "Why does VPC origin reduce the operational overhead for secure CloudFront - Origin connectivity?", "answer": "VPC origin reduces the operational overhead by allowing you to move your origins to private subnets with no public access, eliminating the need for Access Control Lists, secret shared headers, or other mechanisms to restrict access to origins.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-11T14:36:00.304597"}}
{"question": "How does VPC origins with Application Load Balancers compare to VPC origins with Network Load Balancers?", "answer": "Both Application Load Balancers and Network Load Balancers can be used with VPC origins. The primary difference lies in the load balancing algorithm used: Application Load Balancers use application-level protocols, while Network Load Balancers use transport-layer protocols.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-21", "source_tokens": 478, "generated_at": "2026-02-11T14:36:00.304984"}}
{"question": "What headers can be customized or overridden in Amazon CloudFront requests?", "answer": "Amazon CloudFront allows customizing or overriding headers in requests forwarded to your origin. This can help validate requests, distinguish origin requests made by different distributions, and determine the right CORS headers.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-11T14:36:05.476352"}}
{"question": "How does Amazon CloudFront handle delivery of dynamic and personalized content using cookies?", "answer": "Amazon CloudFront can forward some or all of your cookies to your custom origin server for personalized content delivery. It identifies unique objects in the cache based on the forwarded cookie values, allowing end-users to benefit from personalized content and the performance benefits of Amazon CloudFront.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-11T14:36:05.476637"}}
{"question": "How does the query string whitelisting feature in Amazon CloudFront compare to using all query parameters in the cache key?", "answer": "The query string whitelisting feature in Amazon CloudFront enables you to configure it to only use certain query parameters in the cache key while forwarding all parameters to the origin. This can help reduce the number of cached objects and improve performance.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-22", "source_tokens": 458, "generated_at": "2026-02-11T14:36:05.476780"}}
{"question": "What setting should be specified in CloudFront cache behavior for automatic data compression?", "answer": "To enable CloudFront to automatically compress objects, you need to specify this setting in your cache behavior.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-11T14:36:10.470457"}}
{"question": "How does streaming content provide a better viewing experience for users compared to traditional downloads?", "answer": "Streaming allows viewers to have more control over their content as they can easily seek forward and backward in a video. It also ensures that no file remains on their client after they finish watching, giving them more control over their storage. Additionally, it can help reduce costs by only delivering the portions of a media file that viewers actually watch.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-11T14:36:10.470809"}}
{"question": "What's the difference between CloudFront's automatic data compression and traditional download delivery?", "answer": "CloudFront's automatic data compression feature delivers compressed data directly to the user, while traditional download delivery requires the user to download the entire media file prior to playback. With traditional downloads, the whole media file is delivered even if the user only watches a portion of it.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-23", "source_tokens": 351, "generated_at": "2026-02-11T14:36:10.471266"}}
{"question": "What formats can Amazon CloudFront deliver on-demand video content in, given that the media files have been converted using AWS Elemental MediaConvert?", "answer": "Amazon CloudFront can deliver on-demand video content in HLS, MPEG-DASH, and Microsoft Smooth Streaming formats when the media files have been converted using AWS Elemental MediaConvert.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-11T14:36:16.804268"}}
{"question": "How does Amazon CloudFront handle on-demand video content delivery when the media files have been converted to the required HTTP streaming format using AWS Elemental MediaConvert?", "answer": "Amazon CloudFront can deliver on-demand video content in HLS, MPEG-DASH, and Microsoft Smooth Streaming formats directly, without requiring media servers, when the media files have been converted to the required HTTP streaming format using AWS Elemental MediaConvert.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-11T14:36:16.804623"}}
{"question": "What are the differences between using Amazon CloudFront with an Amazon S3 origin and using a third-party streaming server as the origin for live streaming video content?", "answer": "When using Amazon CloudFront with an Amazon S3 origin, the media files need to be converted to the required HTTP streaming format using AWS Elemental MediaConvert before being stored in Amazon S3. In contrast, when using a third-party streaming server as the origin, the server can convert the media file to the required HTTP streaming format and then be designated as the origin for an Amazon CloudFront web distribution.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-24", "source_tokens": 325, "generated_at": "2026-02-11T14:36:16.805107"}}
{"question": "What is Media-Quality Aware Resiliency (MQAR) and what does it do?", "answer": "Media-Quality Aware Resiliency (MQAR) is an integrated capability between Amazon CloudFront and AWS Media Services. It provides automatic cross-region origin selection and failover based on a dynamically generated video quality score. When enabled, CloudFront automatically selects the origin that has the highest quality score, which represents perceived media streaming quality issues from origins.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-11T14:36:23.903708"}}
{"question": "How does Media-Quality Aware Resiliency (MQAR) improve live event delivery and 24/7 programming channels?", "answer": "Media-Quality Aware Resiliency (MQAR) is designed to help deliver a high quality of experience to viewers by simulating 'eyes-on-glass' for live events and programming channels. It automatically switches to the origin that reports the highest media quality score, ensuring that viewers receive the best possible streaming experience.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-11T14:36:23.904047"}}
{"question": "What is the difference between MQAR and Origin Shield in terms of cache and origin request handling?", "answer": "MQAR is an integrated capability between Amazon CloudFront and AWS Media Services that automatically selects the origin with the highest quality score based on perceived media streaming quality issues. On the other hand, Origin Shield is a centralized caching layer that helps increase cache hit ratio to reduce origin load and origin operating costs. Origin Shield routes all origin fetches through its cache and only makes a request to the origin if the content is not already stored in its cache.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-25", "source_tokens": 503, "generated_at": "2026-02-11T14:36:23.904516"}}
{"question": "In which AWS Regions can I use Amazon CloudFront's Origin Shield?", "answer": "Amazon CloudFront offers Origin Shield in AWS Regions where CloudFront has a regional edge cache.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-11T14:36:29.178382"}}
{"question": "How does the architecture of Origin Shield ensure low latency?", "answer": "Origin Shield is built using a highly-available architecture that spans several Availability Zones with auto-scaling EC2 instances. Connections from CloudFront locations to Origin Shield use active error tracking for automatic routing to secondary locations if the primary location is unavailable.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-11T14:36:29.178711"}}
{"question": "What is the difference between Anycast Static IPs and origin IPs for CloudFront?", "answer": "Anycast Static IPs are a set of static IP addresses that allow connection to all CloudFront edge locations globally. They eliminate the operational challenge of updating allow-lists or IP mappings and provide a small, static list for use cases like zero-rated billing and client-side allow-listing. Origin IPs are the IP addresses of the origin servers that CloudFront fetches content from.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-26", "source_tokens": 500, "generated_at": "2026-02-11T14:36:29.179236"}}
{"question": "What geographic regions does CloudFront Anycast require IPs for?", "answer": "CloudFront Anycast requires IPs to be spread across geographic regions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-11T14:36:33.429215"}}
{"question": "How does CloudFront handle new edge locations with Anycast Static IPs?", "answer": "When CloudFront adds new edge locations, your Anycast Static IP list will continue to remain valid. Your IPs will be announced from the new edge locations as appropriate.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-11T14:36:33.429501"}}
{"question": "What AWS services can you not use with CloudFront Anycast Static IPs?", "answer": "The three exceptions to using CloudFront Anycast Static IPs are: 1) they will not support legacy clients that cannot support SNI, 2) you are required to use Price Class All, and 3) you must disable IPv6.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-27", "source_tokens": 461, "generated_at": "2026-02-11T14:36:33.429955"}}
{"question": "What delivery options are available for CloudFront standard logs?", "answer": "CloudFront standard logs can be delivered to an Amazon S3 bucket, Amazon CloudWatch logs, and Amazon Data Firehose.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-11T14:36:37.584481"}}
{"question": "How do real-time logs differ from standard logs in CloudFront?", "answer": "Standard logs (access logs) are delivered in near real-time to your chosen destination, while real-time logs provide information about requests in real time and are delivered within seconds of the request.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-11T14:36:37.584749"}}
{"question": "Why would you choose to use real-time logs instead of standard logs in CloudFront?", "answer": "Real-time logs provide information about requests in real time, which can be useful for monitoring and troubleshooting issues in near real-time. However, they come with additional charges.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-28", "source_tokens": 424, "generated_at": "2026-02-11T14:36:37.585242"}}
{"question": "What destinations can CloudFront standard access logs be delivered to?", "answer": "CloudFront standard access logs can be delivered to Amazon S3, Amazon CloudWatch, and Amazon Data Firehose.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-11T14:36:41.622060"}}
{"question": "How can I choose the output log format for CloudFront standard access logs?", "answer": "You can choose the output log format (plain, w3c, JSON, csv, and parquet) for CloudFront standard access logs.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-11T14:36:41.622392"}}
{"question": "What are the benefits of receiving CloudFront standard access logs in Amazon S3 compared to other destinations?", "answer": "In addition to the ability to select specific fields and log order, you can also enable partitioning for logs delivered to S3 on an hourly or daily basis.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-29", "source_tokens": 468, "generated_at": "2026-02-11T14:36:41.622809"}}
{"question": "What metrics are automatically published by CloudFront into CloudWatch?", "answer": "CloudFront automatically publishes six operational metrics, each at 1-minute granularity, into Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-11T14:36:46.636568"}}
{"question": "Why would you choose to use real-time logs over standard logs in CloudFront?", "answer": "You would choose real-time logs if you have time-sensitive use cases and require access log data quickly within a few seconds. On the other hand, you would choose standard logs if you need a low-cost log processing solution with no requirement for real-time data.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-11T14:36:46.636837"}}
{"question": "What's the difference between real-time logs and standard logs in terms of data delivery and cost?", "answer": "Real-time logs are built for quick data delivery and may drop log records if there are data delays, while standard logs are built for completeness and the logs are typically available in a few minutes. The cost of real-time logs is higher than standard logs as they require more resources for quick data delivery.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-30", "source_tokens": 381, "generated_at": "2026-02-11T14:36:46.636988"}}
{"question": "Which service delivers CloudFront standard logs to an S3 bucket?", "answer": "Amazon S3 receives CloudFront standard logs.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-11T14:36:51.486338"}}
{"question": "How does the process of creating dashboards from CloudFront logs differ from that of real-time logs?", "answer": "CloudFront standard logs are delivered to S3 for dashboard creation via third-party solutions like DataDog and Sumologic. Real-time logs are delivered to Kinesis Data Streams for further processing and can be sent to various services including S3, Redshift, OpenSearch Service, and external providers.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-11T14:36:51.486583"}}
{"question": "How does Amazon Kinesis Data Firehose compare to third-party solutions in terms of delivering logs from Kinesis Data Streams?", "answer": "Amazon Kinesis Data Firehose supports delivering logs from Kinesis Data Streams to various services like S3, Redshift, OpenSearch Service, and external providers, while third-party solutions only provide dashboard creation from CloudFront standard logs in S3.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-31", "source_tokens": 140, "generated_at": "2026-02-11T14:36:51.487000"}}
{"question": "What is the recommendation for adding a buffer when calculating the number of Kinesis shards based on requests per second and log record size?", "answer": "The recommendation is to add up to 25% as a buffer.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-11T14:36:56.872190"}}
{"question": "How does CloudFront Functions compare to AWS Lambda@Edge in terms of flexibility, performance, and cost?", "answer": "CloudFront Functions is a serverless edge compute feature that allows running JavaScript code at CloudFront edge locations for lightweight HTTP(s) transformations and manipulations. It is purpose-built to give customers the flexibility of a full programming environment with the performance and security that modern web applications require. Compared to AWS Lambda@Edge, CloudFront Functions is a fraction of the price and can scale instantly and affordably to support millions of requests per second.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-11T14:36:56.872518"}}
{"question": "What determines the size of a single shard in the context of Kinesis data stream?", "answer": "A single shard in the Kinesis data stream can handle no more than 1 MB per second and 1,000 requests (log records) per second.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-32", "source_tokens": 493, "generated_at": "2026-02-11T14:36:56.873014"}}
{"question": "What is CloudFront Functions used for in CloudFront?", "answer": "CloudFront Functions is a service built into CloudFront that allows customers to easily build, test, and deploy functions within the same service. It is ideal for lightweight, short-running functions like cache key normalization, header manipulation, URL redirects or rewrites, and request authorization.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-11T14:37:03.430476"}}
{"question": "How does CloudFront Functions work with CloudFront KeyValueStore?", "answer": "CloudFront Functions and CloudFront KeyValueStore work together to make functions more customizable. CloudFront KeyValueStore is a global, low-latency, fully managed key-value data store that enables the retrieval of key value data from within CloudFront Functions. This allows for independent data updates and fast reads from within CloudFront Functions.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-11T14:37:03.430743"}}
{"question": "What's the difference between CloudFront Functions and CloudFront KeyValueStore?", "answer": "CloudFront Functions is a service for building, testing, and deploying lightweight, short-running functions within CloudFront. It is ideal for functions like cache key normalization, header manipulation, URL redirects or rewrites, and request authorization. CloudFront KeyValueStore is a global, low-latency, fully managed key-value data store that enables the retrieval of key value data from within CloudFront Functions, making functions more customizable by allowing independent data updates.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-33", "source_tokens": 465, "generated_at": "2026-02-11T14:37:03.431201"}}
{"question": "What is the primary use case for CloudFront KeyValueStore for URL management?", "answer": "The primary use case for CloudFront KeyValueStore for URL management is maintaining URL rewrites and redirects, simplifying the management of geo-based URLs.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-11T14:37:08.161904"}}
{"question": "How can CloudFront KeyValueStore be used for A/B testing and feature flags?", "answer": "CloudFront KeyValueStore can be used for A/B testing and feature flags by allowing you to run experiments and update experiment weights without updating function code or your CloudFront distribution.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-11T14:37:08.162174"}}
{"question": "What is the difference between CloudFront Functions and Lambda@Edge in terms of usage?", "answer": "CloudFront Functions and Lambda@Edge serve complementary purposes. Lambda@Edge is used to manipulate streaming manifest files on-the-fly to inject custom tokens, while CloudFront Functions are used to validate those tokens when a user makes a request for a segment from the manifest.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-34", "source_tokens": 293, "generated_at": "2026-02-11T14:37:08.162327"}}
{"question": "What is CloudFront Functions best used for?", "answer": "CloudFront Functions is best used for lightweight, high scale, and latency sensitive request/response transformations and manipulations.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-11T14:37:12.959910"}}
{"question": "How does Lambda@Edge differ from CloudFront Functions in terms of capabilities?", "answer": "Lambda@Edge uses general-purpose runtimes that support a wide range of computing needs and customizations, while CloudFront Functions is purpose-built for lightweight, high scale, and latency sensitive request/response transformations and manipulations.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-11T14:37:12.960278"}}
{"question": "What use cases are well-suited for Lambda@Edge?", "answer": "Lambda@Edge is well-suited for computationally intensive operations such as computations that take longer to complete (several milliseconds to seconds), take dependencies on external 3rd party libraries, require integrations with other AWS services (e.g., S3, DynamoDB), or need networks calls for data processing.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-35", "source_tokens": 240, "generated_at": "2026-02-11T14:37:12.960687"}}
{"question": "What security mechanism does CloudFront Functions use to isolate functions and prevent data leaks?", "answer": "CloudFront Functions runs functions in a dedicated process on a dedicated CPU and executes on process workers that only serve one customer at a time. All customer-specific data is cleared (flushed) between executions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-11T14:37:18.052321"}}
{"question": "How does the process-based isolation model of CloudFront Functions compare to the V8 isolates based model offered by some other vendors?", "answer": "CloudFront Functions does not use V8 as a JavaScript engine and has a different security model that is considered more secure against side-channel attacks, timing-based attacks, or other code vulnerabilities.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-11T14:37:18.052589"}}
{"question": "What is the purpose and benefits of using the test functionality in CloudFront Functions?", "answer": "The test functionality in CloudFront Functions allows you to validate the function returns the expected result and provides a compute utilization metric. This helps ensure the function will work when associated to a CloudFront distribution and uses a reasonable amount of execution time.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-36", "source_tokens": 503, "generated_at": "2026-02-11T14:37:18.052751"}}
{"question": "What metrics are generated for CloudFront Functions and where can you view them?", "answer": "CloudFront Functions generate metrics for each invocation of a function. These metrics include the number of invocations, compute utilization, validation errors, and execution errors. You can view metrics from each function individually on the CloudFront or CloudWatch console.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-11T14:37:23.525902"}}
{"question": "How does Lambda@Edge allow you to run code at global edge locations without managing servers?", "answer": "Lambda@Edge is an extension of AWS Lambda that allows you to run code at global edge locations without provisioning or managing servers. It offers powerful and flexible serverless computing for complex functions and full application logic closer to your viewers.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-11T14:37:23.526247"}}
{"question": "What's the difference between CloudFront Functions and Lambda@Edge in terms of metrics and logging?", "answer": "CloudFront Functions generate metrics for each invocation, including the number of invocations, compute utilization, validation errors, and execution errors. Metrics are viewable on the CloudFront or CloudWatch console. Lambda@Edge also generates logs through console.log() statements, which are sent to CloudWatch.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-37", "source_tokens": 469, "generated_at": "2026-02-11T14:37:23.526652"}}
{"question": "What CloudFront events trigger Lambda@Edge functions?", "answer": "Lambda@Edge functions are triggered in response to the following Amazon CloudFront events: Viewer Request, Viewer Response, Origin Request, and Origin Response.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-11T14:37:28.641380"}}
{"question": "How does continuous deployment with CloudFront ensure a consistent experience for viewers?", "answer": "Continuous deployment with CloudFront ensures a consistent experience for viewers by binding the viewer session to the same environment, allowing you to test and validate configuration changes with a portion of live traffic before deploying them to all viewers.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-11T14:37:28.641693"}}
{"question": "What's the difference between the Origin Request event and the Viewer Request event in CloudFront?", "answer": "The Origin Request event occurs when the CloudFront edge server does not already have the requested object in its cache, and the viewer request is ready to be sent to your backend origin webserver. The Viewer Request event occurs when an end user or a device on the Internet makes an HTTP(S) request to CloudFront, and the request arrives at the edge location closest to that user.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-38", "source_tokens": 488, "generated_at": "2026-02-11T14:37:28.642144"}}
{"question": "What metrics can you measure between primary and staging distributions in CloudFront for continuous deployment?", "answer": "You can measure throughput, latency, and availability metrics between the two distributions.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-11T14:37:33.196317"}}
{"question": "Why is session stickiness important when using a weight-based configuration to route traffic to a staging distribution in CloudFront?", "answer": "Session stickiness helps ensure that CloudFront treats requests from the same viewer as a single session and serves them by one distribution, either the primary or the staging.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-11T14:37:33.196659"}}
{"question": "How does the number of unique IP addresses that can be assigned under IPv4 and IPv6 compare?", "answer": "IPv4 addresses are 32 bits long, allowing for approximately 4.3 billion unique addresses, while IPv6 addresses are 128 bits long, which allow for approximately three hundred and forty trillion, trillion unique addresses.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-39", "source_tokens": 493, "generated_at": "2026-02-11T14:37:33.196866"}}
{"question": "What IP addresses will be sent to your origins when you enable IPv6 for an Amazon CloudFront distribution?", "answer": "When you enable IPv6 for an Amazon CloudFront distribution, you will get IPv6 addresses in the â€˜X-Forwarded-Forâ€™ header that is sent to your origins.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-11T14:37:38.903964"}}
{"question": "Why do internal IPv6 address processing changes need to be made when enabling IPv6 for an Amazon CloudFront distribution?", "answer": "When you enable IPv6 for an Amazon CloudFront distribution, you may need to verify that your log processing systems continue to work for IPv6 and your origin systems continue to work for IPv6.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-11T14:37:38.904293"}}
{"question": "What should you do if you use Trusted Signer URLs with IP whitelists and want to use IPv6?", "answer": "If you use Trusted Signer URLs with IP whitelists and want to use IPv6, you should use two separate Amazon CloudFront distributions. Dedicate a distribution exclusively to your Trusted Signer URLs with IP whitelist and disable IPv6 for that distribution. Use another distribution for all other content, which will work with both IPv4 and IPv6.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-40", "source_tokens": 510, "generated_at": "2026-02-11T14:37:38.904715"}}
{"question": "What type of IP addresses will be displayed in the 'c-ip' field of the access logs when IPv6 is enabled for an Amazon CloudFront distribution?", "answer": "IPv6 addresses", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:37:43.165308"}}
{"question": "Why would you need to ensure that your origin systems can handle IPv6 addresses when enabling IPv6 for an Amazon CloudFront distribution?", "answer": "Because IPv6 addresses will be present in the 'X-Forwarded-For' header that is sent to your origins.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:37:43.165552"}}
{"question": "How does enabling IPv6 for an Amazon CloudFront distribution impact the type of record sets you can create for Route 53 alias records pointing to the distribution?", "answer": "You can create both 'A' record type for IPv4 and 'AAAA' record type for IPv6.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:37:43.165718"}}
{"question": "What is the monthly free tier limit for data transfer out in AWS CloudFront starting December 1, 2021?", "answer": "The monthly free tier limit for data transfer out in AWS CloudFront is 1 TB.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-11T14:37:48.489120"}}
{"question": "How does the free tier in AWS CloudFront impact the usage of CloudFront Functions?", "answer": "The free tier in AWS CloudFront includes 2,000,000 CloudFront Functions invocations each month.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-11T14:37:48.489402"}}
{"question": "How does the free tier in AWS CloudFront compare to the CloudFront Security Savings bundle?", "answer": "The free tier in AWS CloudFront includes 1 TB of data transfer out, 10,000,000 HTTP/HTTPS requests, and 2,000,000 CloudFront Functions invocations each month. Customers subscribed to the CloudFront Security Savings bundle also benefit from the free tier. If you wish to lower your commitment to the CloudFront Security Savings bundle due to the free tier, you can contact customer service to evaluate your request.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-42", "source_tokens": 412, "generated_at": "2026-02-11T14:37:48.489603"}}
{"question": "What are the five areas where Amazon CloudFront charges apply?", "answer": "Amazon CloudFront charges apply to Data Transfer Out, HTTP/HTTPS Requests, Invalidation Requests, Real-time Log Requests, and Dedicated IP Custom SSL certificates associated with a CloudFront distribution.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-11T14:37:52.686180"}}
{"question": "How does Amazon CloudFront charge for data transfer to an origin?", "answer": "Amazon CloudFront charges for the volume of data transferred out from its edge locations to your origin, measured in GB.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-11T14:37:52.686627"}}
{"question": "What is the difference in charging for data transfer out from Amazon CloudFront to the internet and to an origin?", "answer": "Data transfer out from Amazon CloudFront to the internet is charged separately from data transfer out to an origin. Data transfer out to the internet is measured in GB and you can see the rates here. Data transfer out to an origin is also measured in GB and you can see the rates here.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-43", "source_tokens": 418, "generated_at": "2026-02-11T14:37:52.687062"}}
{"question": "How many paths can I request for invalidation in a month without additional charges?", "answer": "1,000 paths", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-11T14:37:55.720887"}}
{"question": "Why are real-time logs charged based on log lines?", "answer": "You are charged $0.01 for every 1,000,000 log lines that CloudFront publishes to your log destination", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-11T14:37:55.721194"}}
{"question": "How much does it cost to use a custom SSL certificate with CloudFront per month compared to using it with another CloudFront distribution?", "answer": "You pay $600 per month for each custom SSL certificate", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-44", "source_tokens": 414, "generated_at": "2026-02-11T14:37:55.721427"}}
{"question": "What taxes and duties are included in AWS prices, excluding Japanese Consumption Tax?", "answer": "Our prices are exclusive of applicable taxes and duties, including VAT and sales tax.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-11T14:38:01.084401"}}
{"question": "Why is using AWS services with a Japanese billing address subject to Japanese Consumption Tax?", "answer": "Use of AWS services with a Japanese billing address is subject to Japanese Consumption Tax.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-11T14:38:01.084662"}}
{"question": "How much does it cost to use CloudFront for real-time logs per month in comparison to Kinesis Data Stream, considering a distribution serving 1,000 requests per second with a log size of 1KB and 2 shards in US East (Ohio)?", "answer": "Monthly cost of CloudFront real-time logs: 1,000 * (60 sec * 60 min * 24 hrs * 30 days) * ($0.01 /1,000,000) = $25.92 /month. Monthly cost of Kinesis Data Stream: $47.74/month.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-45", "source_tokens": 298, "generated_at": "2026-02-11T14:38:01.084820"}}
{"question": "Which edge locations are excluded when using a specific Price Class in Amazon CloudFront?", "answer": "The edge locations excluded from a price class in Amazon CloudFront depend on the specific price class selected.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-11T14:38:05.227177"}}
{"question": "How does selecting a specific Price Class in Amazon CloudFront impact the latency experienced by end-users in certain geographic locations?", "answer": "Selecting a price class that does not include all locations in Amazon CloudFront may result in higher latency for end-users in geographic locations that are not included in the price class.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-11T14:38:05.227530"}}
{"question": "What locations are included in the 'lowest-priced' Price Class in Amazon CloudFront?", "answer": "The text passage does not provide information on which locations are included in the 'lowest-priced' Price Class in Amazon CloudFront.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-46", "source_tokens": 334, "generated_at": "2026-02-11T14:38:05.227687"}}
{"question": "What percentage discount does the CloudFront Security Savings Bundle offer on CloudFront usage?", "answer": "The CloudFront Security Savings Bundle offers a discount of up to 30% on CloudFront usage.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-11T14:38:10.224480"}}
{"question": "How does the CloudFront Security Savings Bundle help users save on their CloudFront bill?", "answer": "The CloudFront Security Savings Bundle helps users save on their CloudFront bill by committing to a consistent amount of monthly usage (e.g. $100/month) for a 1 year term, in exchange for which they receive a 30% savings on CloudFront and included AWS WAF usage.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-11T14:38:10.224717"}}
{"question": "What benefits does the CloudFront Security Savings Bundle provide in addition to the 30% savings on CloudFront usage?", "answer": "The CloudFront Security Savings Bundle includes up to $10 of AWS WAF usage per month at no additional charge (up to 10% of your CloudFront commitment).", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-47", "source_tokens": 375, "generated_at": "2026-02-11T14:38:10.225101"}}
{"question": "What happens to CloudFront Security Savings Bundle benefits when the term expires?", "answer": "Once the CloudFront Security Savings Bundle term expires, standard service charges will apply for CloudFront and AWS WAF usage. The monthly commitment will no longer be billed and savings bundle benefits will no longer apply.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T14:38:15.341809"}}
{"question": "Why would I choose to purchase a CloudFront Security Savings Bundle?", "answer": "You can choose to purchase a CloudFront Security Savings Bundle to get discounts on your monthly CloudFront and AWS WAF usage based on your estimated monthly usage. The bundle provides a comparison between the monthly costs and on-demand costs and shows estimated savings to help decide on the right plan.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T14:38:15.342047"}}
{"question": "How does credit sharing work for CloudFront Security Savings Bundles in an AWS Organization?", "answer": "The benefits provided by the CloudFront Security Savings Bundle are applied as credits on the bill and are applicable to usage across all accounts within an AWS Organization by default. The credits are shared among all accounts in the organization.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T14:38:15.342416"}}
{"question": "What service does AWS Budgets allow you to set thresholds and receive notifications for CloudFront on-demand usage?", "answer": "AWS Budgets allows you to set thresholds and receive notifications for CloudFront on-demand usage covered by your CloudFront Security Savings Bundle.", "question_type": "factual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-11T14:38:20.950583"}}
{"question": "How does AWS Budgets help you manage your CloudFront costs?", "answer": "AWS Budgets helps you manage your CloudFront costs by allowing you to set thresholds for CloudFront on-demand usage covered by your CloudFront Security Savings Bundle and receive notifications when that threshold is exceeded.", "question_type": "conceptual", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-11T14:38:20.950897"}}
{"question": "What are the differences between the usage of CloudFront Security Savings Bundle for CloudFront and AWS WAF?", "answer": "CloudFront Security Savings Bundle covers up to 10% of your committed plan amount for CloudFront and includes AWS WAF usage at no additional charge for protecting CloudFront resources. Standard CloudFront and AWS WAF charges apply for any usage beyond what is covered by CloudFront Security Savings Bundle. Managed WAF rules subscribed through the AWS Marketplace are not covered by the CloudFront Security Savings Bundle.", "question_type": "comparison", "metadata": {"service": "CLOUDFRONT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudfront-faq-49", "source_tokens": 294, "generated_at": "2026-02-11T14:38:20.951297"}}
{"question": "What is the main purpose of AWS CloudHSM?", "answer": "AWS CloudHSM is a service that helps organizations meet compliance requirements for data security by using dedicated Hardware Security Module (HSM) instances within the AWS cloud to securely store and manage cryptographic keys used for data encryption.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-11T14:38:25.921299"}}
{"question": "How does AWS CloudHSM ensure secure key management?", "answer": "AWS CloudHSM uses dedicated Hardware Security Module (HSM) instances within the AWS cloud that are designed and validated to government standards for secure key management. These HSMs securely store cryptographic key material and use it for cryptographic operations without exposing it outside the cryptographic boundary of the hardware.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-11T14:38:25.921658"}}
{"question": "What are some common use cases for AWS CloudHSM?", "answer": "AWS CloudHSM can be used to support various use cases and applications, such as database encryption, Digital Rights Management (DRM), Public Key Infrastructure (PKI), authentication and authorization, document signing, and transaction processing.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-0", "source_tokens": 429, "generated_at": "2026-02-11T14:38:25.922085"}}
{"question": "What is required to create an AWS CloudHSM Cluster?", "answer": "To create an AWS CloudHSM Cluster, you first create the cluster and then initialize it. After creation, you can add and remove HSMs from the cluster using the AWS CloudHSM API or AWS CLI.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:38:31.027872"}}
{"question": "How does network connectivity work between an application and an AWS CloudHSM Cluster?", "answer": "The server or instance on which your application and HSM client are running must have network reachability to all HSMs in the cluster. This can be achieved through various methods like operating in the same VPC, VPC peering, VPN connection, or Direct Connect.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:38:31.028186"}}
{"question": "What are the differences between using an on-premises HSM and AWS CloudHSM in terms of interoperability?", "answer": "AWS CloudHSM does not interoperate directly with on-premises HSMs, but you can securely transfer exportable keys between them using supported RSA key wrap methods.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:38:31.028615"}}
{"question": "What are some third-party software solutions that have been integrated and tested with AWS CloudHSM?", "answer": "Oracle Database 19c, Apache, Nginx, and Windows Server are some third-party software solutions that have been integrated and tested with AWS CloudHSM.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T14:38:35.951466"}}
{"question": "Why would you use AWS CloudHSM to manage encryption keys for your custom application?", "answer": "AWS CloudHSM can be used to manage encryption keys for your custom application because it integrates with AWS Key Management Service, allowing you to encrypt your data for use with other AWS services while only exposing your data encrypted to those services.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T14:38:35.951807"}}
{"question": "How does AWS CloudHSM compare to AWS Payment Cryptography for managing encryption keys?", "answer": "AWS CloudHSM is a general-purpose HSM solution, while AWS Payment Cryptography provides cryptography operations in cloud-hosted payment applications. Over time, AWS may provide payment features in AWS CloudHSM.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T14:38:35.952171"}}
{"question": "What is the billing structure for AWS CloudHSM in terms of hours?", "answer": "You will be charged an hourly fee for each hour (or partial hour) that an HSM is provisioned to an AWS CloudHSM cluster.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-11T14:38:41.229141"}}
{"question": "Why is it recommended to have multiple HSMs in different Availability Zones for production workloads?", "answer": "AWS strongly recommends that you use at least two HSMs in two different Availability Zones for any production workload. For mission-critical workloads, they recommend at least three HSMs in at least two separate AZs. This setup ensures that if one HSM fails, the application can still function using the other HSMs.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-11T14:38:41.229530"}}
{"question": "How does the billing for AWS CloudHSM compare to that of EC2 for data transfer?", "answer": "While the hourly fee for AWS CloudHSM is included in the charge for the HSM itself, network data transfers to and from your HSMs are charged separately. In contrast, data transfer for EC2 instances has its own pricing.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-3", "source_tokens": 387, "generated_at": "2026-02-11T14:38:41.229721"}}
{"question": "What does AWS CloudHSM do to detect physical tampering?", "answer": "AWS CloudHSM has physical tamper detection mechanisms that trigger key deletion (zeroization) of the hardware if the physical barrier is breached.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T14:38:51.499307"}}
{"question": "How does AWS CloudHSM ensure the security of keys and data?", "answer": "AWS CloudHSM uses a FIPS-validated Deterministic Random Bit Generator (DRBG) that is seeded by a True Random Number Generator (TRNG) within the HSM hardware module for generating keys. AWS has no access to the keys or data inside the CloudHSM Cluster and cannot perform any operations other than those allowed for an HSM appliance user.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T14:38:51.499537"}}
{"question": "What's the difference between the physical and logical tamper detection mechanisms in AWS CloudHSM?", "answer": "AWS CloudHSM has physical tamper detection mechanisms that trigger key deletion (zeroization) of the hardware if the physical barrier is breached. It also has logical tamper detection mechanisms that lock out users after a fixed number of unsuccessful login attempts.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T14:38:51.499672"}}
{"question": "What happens if an AWS CloudHSM cluster only has a single HSM?", "answer": "A single AWS CloudHSM cluster can lose keys that were created since the most recent daily backup.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-11T14:38:55.539662"}}
{"question": "Why is it recommended to have two or more HSMs in an AWS CloudHSM cluster?", "answer": "Having two or more HSMs in separate Availability Zones ensures that keys are not lost if a single HSM fails.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-11T14:38:55.539907"}}
{"question": "How does AWS CloudTrail record AWS API calls compared to AWS CloudHSM device logs?", "answer": "AWS CloudTrail records AWS API calls for your account, while AWS CloudHSM device logs are provided directly to your AWS account via AWS CloudWatch Logs.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-6", "source_tokens": 480, "generated_at": "2026-02-11T14:38:55.540288"}}
{"question": "Which compliance programs cover AWS CloudHSM according to the text?", "answer": "The text mentions that certain use cases require FIPS 140-2 Level 3 compliance for AWS CloudHSM.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-11T14:38:59.760523"}}
{"question": "Why is compliance with FIPS 140-2 Level 3 important for AWS CloudHSM?", "answer": "Compliance with FIPS 140-2 Level 3 is important for document signing, payments, or operating as a public Certificate Authority for SSL certificates, as mentioned in the text.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-11T14:38:59.760810"}}
{"question": "How can you increase the performance of AWS CloudHSM?", "answer": "You can increase the performance of AWS CloudHSM by adding additional HSM instances to your clusters, as suggested in the text.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-7", "source_tokens": 463, "generated_at": "2026-02-11T14:38:59.760983"}}
{"question": "What type of connection is established between the CloudHSM Tools and CloudHSM Cluster?", "answer": "The CloudHSM Tools communicate directly with the CloudHSM Cluster via a secured, mutually authenticated channel.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-11T14:39:03.938854"}}
{"question": "How is the communication between the client, tools, and HSM in CloudHSM ensured?", "answer": "The communication between the client, tools, and HSM in CloudHSM is encrypted end-to-end and AWS cannot observe it.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-11T14:39:03.939136"}}
{"question": "What are the requirements for the host running the CloudHSM Client Library or CLI tools in terms of network reachability?", "answer": "The host running the CloudHSM Client Library or CLI tools must have network reachability to all of the HSMs in the CloudHSM Cluster.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-8", "source_tokens": 307, "generated_at": "2026-02-11T14:39:03.939296"}}
{"question": "What is the process for rotating private keys for signing using AWS CloudHSM?", "answer": "The process involves creating a new private key and corresponding CSR on AWS CloudHSM, signing the CSR with the offline enterprise root, and registering the new certificate with partners. Once the new certificate is issued, you sign all new requests with the new private key and continue to verify signatures with the original private key and corresponding public key.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T14:39:08.484925"}}
{"question": "Why and how is the Oracle Transparent Data Encryption wallet transferred between hardware keystores in AWS CloudHSM?", "answer": "The wallet is transferred by first switching to a software keystore and then back to a hardware keystore in AWS CloudHSM. No revocation is necessary during this process.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T14:39:08.485183"}}
{"question": "How does symmetric key rotation for envelope encryption differ during migration from an original HSM to AWS CloudHSM?", "answer": "The main difference is that the new wrapping key is created and used on AWS CloudHSM instead of the original HSM.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T14:39:08.485550"}}
{"question": "What does AWS do when they need to conduct maintenance on a cluster?", "answer": "AWS may conduct maintenance on a cluster for necessary upgrades or faulty hardware. They will make every effort to notify users in advance using the Personal Health Dashboard.", "question_type": "factual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-11T14:39:12.677107"}}
{"question": "Why is it important to use CloudHSM Clusters with two or more HSMs in separate Availability Zones?", "answer": "AWS strongly recommends using CloudHSM Clusters with two or more HSMs in separate Availability Zones for architecting a cluster for high availability.", "question_type": "conceptual", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-11T14:39:12.677443"}}
{"question": "How does using two or more HSMs in separate Availability Zones compare to using one HSM for availability?", "answer": "Using two or more HSMs in separate Availability Zones provides a higher level of availability compared to using one HSM.", "question_type": "comparison", "metadata": {"service": "CLOUDHSM", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudhsm-faq-10", "source_tokens": 136, "generated_at": "2026-02-11T14:39:12.677964"}}
{"question": "What tools are pre-installed in AWS CloudShell for using AWS services?", "answer": "AWS CloudShell comes with pre-installed tools such as AWS CLI, Amazon ECS CLI, AWS Serverless Application Model (AWS SAM) CLI, and runtimes and AWS SDKs for Python and Node.js.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-11T14:39:18.297519"}}
{"question": "How does AWS CloudShell help developers and operations professionals in managing AWS resources?", "answer": "AWS CloudShell provides a browser-based shell environment that is pre-authenticated with your console credentials and contains common development and operations tools. It allows you to run scripts using the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, and save your work in 1 GB of persistent storage.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-11T14:39:18.297789"}}
{"question": "What is the difference between using AWS CloudShell and setting up the AWS CLI locally?", "answer": "Using AWS CloudShell allows you to quickly start using the AWS CLI without the need to install or configure software on your local machine. It provides a pre-authenticated environment, pre-installed tools, and 1 GB of persistent storage for saving your work.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-0", "source_tokens": 492, "generated_at": "2026-02-11T14:39:18.297955"}}
{"question": "What is the maximum file size that can be uploaded to a CloudShell instance through a browser?", "answer": "Files up to 1 GB in size can be uploaded to a CloudShell instance through a browser.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-11T14:39:22.868756"}}
{"question": "What are the main differences between CloudShell and EC2 Instance Connect?", "answer": "CloudShell is a standalone, general purpose tool for running AWS CLI commands and scripts, while EC2 Instance Connect is used to connect to existing EC2 instances via SSH. CloudShell does not require resources in your account, whereas EC2 Instance Connect does. CloudShell can be used at no additional cost, whereas you are billed for the EC2 instance running a Cloud9 environment when using it.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-11T14:39:22.869085"}}
{"question": "How does accessing resources in a private VPC work with CloudShell?", "answer": "CloudShell can access resources that are in your private VPC in this release.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-1", "source_tokens": 461, "generated_at": "2026-02-11T14:39:22.869623"}}
{"question": "What is the default storage capacity for CloudShell's home directory?", "answer": "Each CloudShell home directory comes with 1 GB of persistent storage, per Region.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:39:27.067185"}}
{"question": "How can an administrator customize the CloudShell environment for their organization?", "answer": "Administrators can customize the CloudShell environment by checking out configuration files from a Git repository or by uploading them to their CloudShell environment.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:39:27.067479"}}
{"question": "What are the differences between using CloudShell and using a S3 bucket for data storage?", "answer": "CloudShell comes with 1 GB of persistent storage for the home directory per Region, while an S3 bucket can be used to store more data. Files removed from CloudShell are deleted permanently, but using an S3 bucket allows for data to be backed up.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T14:39:27.067907"}}
{"question": "What role is required to start a CloudShell session by default?", "answer": "Users with the Administrator or PowerUser role can start a CloudShell session by default.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-11T14:39:30.878639"}}
{"question": "Why is CloudShell access restricted to certain users?", "answer": "CloudShell access can be restricted to certain users for security reasons. Users who do not have the necessary permissions will not be able to start a CloudShell session.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-11T14:39:30.878962"}}
{"question": "How long do CloudShell environments preserve files stored in the home directory?", "answer": "CloudShell environments preserve files stored in the home directory for up to 120 days from the last time a CloudShell session was initiated. This limit applies on a regional basis.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-3", "source_tokens": 499, "generated_at": "2026-02-11T14:39:30.879145"}}
{"question": "What is the basis for the CloudShell retention policy?", "answer": "The CloudShell retention policy applies on a regional basis.", "question_type": "factual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-11T14:39:33.856991"}}
{"question": "How does the CloudShell data deletion process work?", "answer": "You will be notified via the personal health dashboard before your CloudShell data is deleted.", "question_type": "conceptual", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-11T14:39:33.857334"}}
{"question": "How does the retention policy for CloudShell in one region compare to another region?", "answer": "Each Region has its own timer associated with your storage.", "question_type": "comparison", "metadata": {"service": "CLOUDSHELL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudshell-faq-4", "source_tokens": 72, "generated_at": "2026-02-11T14:39:33.857513"}}
{"question": "What region(s) can I apply a CloudTrail trail to?", "answer": "You can apply a CloudTrail trail to all Regions.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:39:38.999543"}}
{"question": "How does CloudTrail help with security posture and compliance?", "answer": "CloudTrail helps with security posture and compliance by tracking user activity and API usage, recording important information about each action, and making it easier to ensure compliance with internal policies and regulatory standards.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:39:38.999855"}}
{"question": "What are the differences between CloudTrail and CloudTrail Insights in terms of log file aggregation and processing?", "answer": "CloudTrail and CloudTrail Insights are both AWS services for logging and monitoring, but they differ in their approach to log file aggregation and processing. CloudTrail stores log files in S3 for long-term retention and allows for integration with other services like CloudWatch Logs for real-time analysis. CloudTrail Insights, on the other hand, provides real-time monitoring and analysis of AWS account activity without requiring users to configure and manage their own log files.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:39:39.000291"}}
{"question": "What services does AWS CloudTrail support for recording account activity and events?", "answer": "AWS CloudTrail records account activity and service events from most AWS services. For a list of supported services, see CloudTrail Supported Services in the CloudTrail User Guide.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:39:44.680864"}}
{"question": "Why should you set up a CloudTrail trail and what are the benefits?", "answer": "You should set up a CloudTrail trail to deliver your CloudTrail events to Amazon Simple Storage Service (Amazon S3), Amazon CloudWatch Logs, and Amazon CloudWatch Events. This helps you use features to archive, analyze, and respond to changes in your AWS resources.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:39:44.681274"}}
{"question": "How does CloudTrail's event history compare to a CloudTrail trail in terms of functionality and benefits?", "answer": "CloudTrail's event history allows you to view the past 90 days of account activity without setting up a trail. However, it only shows management events and is limited to the current region. In contrast, a CloudTrail trail delivers events to Amazon S3, CloudWatch Logs, and CloudWatch Events, enabling you to archive, analyze, and respond to changes in your AWS resources.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T14:39:44.681583"}}
{"question": "What regions does CloudTrail record activity information for?", "answer": "CloudTrail records activity information for services with Regional endpoints in the same Region as the action is made, and for services with single endpoints in the Region where the CloudTrail trail is configured.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T14:39:49.048839"}}
{"question": "How does applying a CloudTrail trail to all Regions affect the log delivery?", "answer": "Applying a CloudTrail trail to all Regions results in a single S3 bucket and a single CloudWatch Logs log group receiving log files containing account activity from all Regions.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T14:39:49.049210"}}
{"question": "How does CloudTrail handle log file delivery when a new Region is launched?", "answer": "CloudTrail delivers log files containing event history for new Regions to the S3 bucket and CloudWatch Logs group without requiring any additional action from the user.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T14:39:49.049630"}}
{"question": "What is the time it typically takes to apply an existing trail to all AWS Regions?", "answer": "It typically takes less than 30 seconds to replicate the trail configuration to all Regions.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T14:39:54.038667"}}
{"question": "How does having multiple CloudTrail trails benefit different stakeholders?", "answer": "Different stakeholders such as security administrators, software developers, and IT auditors can create and manage their own trails. For example, a security administrator can create a trail that applies to all Regions and configure encryption using one Amazon KMS key, while a developer can create a trail that applies to one Region for troubleshooting operational issues.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T14:39:54.038995"}}
{"question": "How does the retention policy for CloudTrail log files compare to the default?", "answer": "By default, CloudTrail log files are stored indefinitely. However, you can use S3 Object lifecycle management rules to define your own retention policy, such as deleting old log files or archiving them to Amazon S3 Glacier.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T14:39:54.039475"}}
{"question": "What information does an event in CloudTrail contain?", "answer": "An event in CloudTrail contains information about who made the request, the services used, the actions performed, the parameters for the action, and the response elements returned by the AWS service.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:39:57.907994"}}
{"question": "Why might you receive duplicate CloudTrail events?", "answer": "Duplicate CloudTrail events occur when the same event is delivered more than once to a customer's S3 bucket. This can happen when CloudTrail is designed to support at least one delivery of subscribed events.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:39:57.908278"}}
{"question": "How does CloudTrail deliver data events compared to management events?", "answer": "Both data and management events in CloudTrail are delivered to an S3 bucket. However, data events are also available in Amazon CloudWatch Events once they are enabled, while management events are not.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:39:57.908438"}}
{"question": "What kind of events does CloudTrail record when an S3 bucket is specified?", "answer": "CloudTrail records API activities on S3 Objects within the specified S3 bucket.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-11T14:40:01.873796"}}
{"question": "How can we get details on the runtime activity of our Lambda functions?", "answer": "We can get details on Lambda function runtime by using Lambda data events, which are delivered to an S3 bucket and CloudWatch Events.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-11T14:40:01.874128"}}
{"question": "What's the difference between network activity events and data events in AWS?", "answer": "Network activity events record AWS API actions made using VPC endpoints and help with network security investigations. Data events (like S3 and Lambda events) represent API activity on specific resources.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-5", "source_tokens": 413, "generated_at": "2026-02-11T14:40:01.874524"}}
{"question": "Where can VPC Flow Log data be published?", "answer": "VPC Flow Log data can be published to Amazon CloudWatch Logs, Amazon S3, or Amazon Data Firehose.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-11T14:40:06.240225"}}
{"question": "How does CloudTrail Insights help with identifying unusual activity in AWS accounts?", "answer": "CloudTrail Insights uses machine learning models to monitor CloudTrail write management events for abnormal activity and delivers the events to CloudWatch Events, your S3 bucket, and optionally to the CloudWatch Logs group.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-11T14:40:06.240482"}}
{"question": "What are the differences between VPC Flow Logs and CloudTrail Insights?", "answer": "VPC Flow Logs capture information about IP traffic going to and from network interfaces in your VPC, while CloudTrail Insights help identify unusual activity in your AWS accounts.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-6", "source_tokens": 383, "generated_at": "2026-02-11T14:40:06.240615"}}
{"question": "What type of events does CloudTrail Insights analyze for unusual activity?", "answer": "CloudTrail Insights analyzes write management events for unusual activity.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T14:40:10.317284"}}
{"question": "How does CloudTrail Insights help in addressing operational issues in AWS accounts?", "answer": "CloudTrail Insights helps in addressing operational issues in AWS accounts by identifying unusual operational activity, minimizing operational and business impact.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T14:40:10.317672"}}
{"question": "How does CloudTrail Insights compare to Amazon GuardDuty and Amazon Macie?", "answer": "CloudTrail Insights focuses on detecting unusual operational activity, Amazon GuardDuty improves security by providing threat detection, and Amazon Macie designs to improve data protection by discovering, classifying, and protecting sensitive data.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T14:40:10.318117"}}
{"question": "What type of data does CloudTrail Lake help users examine?", "answer": "CloudTrail Lake helps users examine incidents by querying all actions logged by CloudTrail, configuration items recorded by AWS Config, evidence from Audit Manager, or events from non-AWS sources.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-11T14:40:15.767753"}}
{"question": "How does CloudTrail Lake simplify incident logging?", "answer": "CloudTrail Lake simplifies incident logging by helping remove operational dependencies and provides tools that can help reduce your reliance on complex data process pipelines that span across teams. It also maintains data fidelity and decreases dealing with low-rate limits that throttle your logs, and provides near real-time latencies.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-11T14:40:15.767984"}}
{"question": "How does CloudTrail Lake differ from using CloudTrail with custom integrations for data ingestion?", "answer": "CloudTrail Lake does not require users to move and ingest CloudTrail logs elsewhere, while using CloudTrail with custom integrations for data ingestion does. CloudTrail Lake also provides pre-curated and custom dashboards for intuitive data analysis, and the ability to summarize query results using AI.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-8", "source_tokens": 471, "generated_at": "2026-02-11T14:40:15.768116"}}
{"question": "What is the recommended use for AWS Config advanced query?", "answer": "AWS Config advanced query is recommended for customers who want to aggregate and query on current state AWS Config configuration items for inventory management, security and operational intelligence, cost optimization, and compliance data.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-11T14:40:21.153250"}}
{"question": "How does CloudTrail Lake help with security and non-compliance incidents?", "answer": "CloudTrail Lake helps infer who, when, and what changed on resources by analyzing configuration and compliance history for resources with related CloudTrail events, which aids in root-cause analysis of incidents related to security exposure or non-compliance.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-11T14:40:21.153515"}}
{"question": "What's the difference between AWS Config advanced query and CloudTrail Lake in terms of ingestion and querying?", "answer": "AWS Config advanced query is used to aggregate and query current state AWS Config configuration items, while CloudTrail Lake is recommended to aggregate and query data across CloudTrail events and historical configuration items. CloudTrail Lake will not ingest AWS Config configuration items generated before it was configured, but it can import CloudTrail logs from multiple accounts and regions.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-9", "source_tokens": 499, "generated_at": "2026-02-11T14:40:21.153726"}}
{"question": "What are some common use cases for AWS CloudTrail Lake?", "answer": "Common use cases for AWS CloudTrail Lake include investigating security incidents, enhancing security posture through audits, tracking actions taken on resources, and gaining insights on AWS services bills.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-11T14:40:25.401450"}}
{"question": "How can I filter which CloudTrail events are ingested into my event data stores?", "answer": "Enhanced event filtering capabilities allow you to control which CloudTrail events are ingested into your event data stores.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-11T14:40:25.401786"}}
{"question": "What are the differences between querying SQL-based queries and using natural language query generation for CloudTrail Lake?", "answer": "SQL-based queries offer more precise and complex querying capabilities, while natural language query generation simplifies the querying process by translating natural language queries into SQL.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-10", "source_tokens": 450, "generated_at": "2026-02-11T14:40:25.402202"}}
{"question": "What retention period will be applied to an event in CloudTrail Lake if it was ingested one year ago?", "answer": "The event will be retained in CloudTrail Lake for a retention period of 1 year starting from the event-time.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T14:40:30.592550"}}
{"question": "How does updating the event data store's pricing option affect existing data?", "answer": "Existing data in the event data store will remain available and will not incur any extended retention charges, while newly ingested data will follow the new pricing option for both ingestion and extended retention.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T14:40:30.592888"}}
{"question": "What are the differences between using seven-year retention pricing and one-year extendable retention pricing for event data stores?", "answer": "Seven-year retention pricing allows you to retain data for a longer period without incurring any additional charges for the existing data, but you cannot migrate an existing event data store to this pricing option. One-year extendable retention pricing charges for both ingestion and extended retention for newly ingested data.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T14:40:30.593310"}}
{"question": "What type of security events can the 'Security Monitoring Dashboard' help track?", "answer": "The 'Security Monitoring Dashboard' can help track access denied events, failed login attempts, and destructive actions.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-11T14:40:34.992838"}}
{"question": "How can organizations utilize the 'IAM Activity Dashboard' to support compliance efforts?", "answer": "Organizations can use the 'IAM Activity Dashboard' to identify unintended IAM actions and potential compliance issues by providing visibility into changes to IAM entities.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-11T14:40:34.993118"}}
{"question": "What is the main difference between the 'Error Analysis Dashboard' and the 'Resource Changes Dashboard'?", "answer": "The 'Error Analysis Dashboard' helps identify and troubleshoot service throttling errors and other operational issues across services, while the 'Resource Changes Dashboard' provides visibility into trends in provisioning, deletion, and modifications across AWS resources.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-12", "source_tokens": 266, "generated_at": "2026-02-11T14:40:34.993523"}}
{"question": "What information is included in CloudTrail events when resource tags are enriched?", "answer": "CloudTrail events include resource tag information when they match specific tags on AWS Resources. This allows users to easily categorize and analyze AWS activities in the context of their business operations, projects, or departments.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-11T14:40:40.183689"}}
{"question": "How does using resource tags with CloudTrail events enhance event analysis?", "answer": "Using resource tags with CloudTrail events enables users to more easily categorize and analyze AWS activities based on their organization's tagging strategy. This can help streamline event analysis in the context of business operations, projects, or departments.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-11T14:40:40.184109"}}
{"question": "What's the difference between enriching CloudTrail events with resource tags and IAM Global Condition Keys?", "answer": "Enriching CloudTrail events with resource tags involves including resource tag information in CloudTrail events, while IAM Global Condition Keys provide additional context through keys, such as Principal Tags. When enabled, CloudTrail includes information about evaluation of these keys during the authorization process in enriched events.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-13", "source_tokens": 352, "generated_at": "2026-02-11T14:40:40.184568"}}
{"question": "What factors determine whether CloudTrail includes resource tags in its events?", "answer": "The availability of resource tags in CloudTrail events depends on the resource state, timing of tag changes, and IAM policy evaluation.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:40:44.617012"}}
{"question": "How does CloudTrail handle updated resource tags in its events?", "answer": "CloudTrail uses eventual consistency, causing a brief delay before new tag values are captured and displayed in its events.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:40:44.617260"}}
{"question": "What is the difference between CloudTrail's handling of resource tags and IAM global condition keys?", "answer": "CloudTrail includes resource tags in its events based on resource state, timing of tag changes, and IAM policy evaluation. IAM global condition keys, on the other hand, are only included if they are evaluated as part of the IAM policy during the authorization process.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-14", "source_tokens": 470, "generated_at": "2026-02-11T14:40:44.617604"}}
{"question": "What region(s) support CloudTrail integration with CloudWatch Logs?", "answer": "CloudTrail integration with CloudWatch Logs is supported in the Regions where CloudWatch Logs is supported.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-11T14:40:49.640503"}}
{"question": "How does CloudTrail integration with CloudWatch Logs benefit me?", "answer": "CloudTrail integration with CloudWatch Logs helps you receive SNS notifications of account activity captured by CloudTrail. You can create CloudWatch alarms to monitor API calls that create, modify, and delete Security Groups and Network access control lists (ACLs).", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-11T14:40:49.640718"}}
{"question": "What encryption method is used by default for CloudTrail log files delivered to an S3 bucket? How does SSE-KMS encryption differ?", "answer": "By default, CloudTrail will encrypt log files delivered to your S3 bucket using S3 server-side encryption. SSE-KMS encryption for CloudTrail log files adds an additional layer of security by encrypting the log files with a KMS key.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-15", "source_tokens": 471, "generated_at": "2026-02-11T14:40:49.641056"}}
{"question": "What charges will I incur once I configure encryption for my S3 log files using SSE-KMS?", "answer": "You will incur standard AWS KMS charges.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-11T14:40:53.532202"}}
{"question": "How does CloudTrail log file integrity validation help in IT security and auditing processes?", "answer": "CloudTrail log file integrity validation helps determine whether a CloudTrail log file was unchanged, deleted, or modified since it was delivered to the specified S3 bucket.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-11T14:40:53.532531"}}
{"question": "What's the difference between the log files and the digest files delivered by CloudTrail?", "answer": "Log files contain the actual data, while digest files contain information about the log files and hash values for those log files.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-16", "source_tokens": 474, "generated_at": "2026-02-11T14:40:53.533003"}}
{"question": "What is the CloudTrail Processing Library used for?", "answer": "The CloudTrail Processing Library is a Java library used to make it easier to build an application that reads and processes CloudTrail log files. It provides functionality to handle tasks such as polling an SQS queue and reading and parsing Amazon SQS messages, downloading log files from S3, and parsing and serializing log file events in a fault-tolerant manner.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-11T14:41:00.380123"}}
{"question": "How does the CloudTrail Processing Library help in managing CloudTrail log files?", "answer": "The CloudTrail Processing Library simplifies the process of managing CloudTrail log files by providing functionality to download log files from S3, parse and serialize log file events, and continually poll an SQS queue to read and process messages. This allows users to easily process CloudTrail log files and extract useful information.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-11T14:41:00.380462"}}
{"question": "What's the difference between using a free CloudTrail trail and using CloudTrail Lake for managing CloudTrail events?", "answer": "A CloudTrail trail is a feature that delivers one free copy of your accountâ€™s management events in each region. CloudTrail Lake, on the other hand, is a paid service that provides additional functionality for managing CloudTrail events, such as the ability to store and analyze events in real-time. With CloudTrail Lake, you pay for ingestion and storage together, and querying charges are based on the compressed data you choose to analyze.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-17", "source_tokens": 497, "generated_at": "2026-02-11T14:41:00.380940"}}
{"question": "Which solutions offer integration with CloudTrail to analyze log files?", "answer": "Multiple partners offer integrated solutions to analyze CloudTrail log files.", "question_type": "factual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-11T14:41:03.520697"}}
{"question": "What features do these CloudTrail integration solutions provide?", "answer": "These solutions include features like change tracking, troubleshooting, and security analysis.", "question_type": "conceptual", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-11T14:41:03.520997"}}
{"question": "How does using these CloudTrail integration solutions compare to not using them in terms of performance?", "answer": "Turning on CloudTrail has no impact on performance for your AWS resources or API call latency.", "question_type": "comparison", "metadata": {"service": "CLOUDTRAIL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudtrail-faq-18", "source_tokens": 122, "generated_at": "2026-02-11T14:41:03.521195"}}
{"question": "What services does Amazon CloudWatch offer for monitoring?", "answer": "Amazon CloudWatch offers various services for monitoring such as metrics analytics, logs monitoring, alarms, and dashboards.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T14:41:07.957877"}}
{"question": "How can Amazon CloudWatch help you understand the health of your applications and resources?", "answer": "Amazon CloudWatch allows you to collect and track metrics, monitor log files, and set alarms for your applications and resources in the cloud and on-premises. You can use these insights to react and maintain the optimal performance of your application.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T14:41:07.958181"}}
{"question": "What are the differences between AWS services: Amazon CloudWatch Logs and Amazon CloudWatch Metrics?", "answer": "Amazon CloudWatch Logs is used for collecting and analyzing log files, while Amazon CloudWatch Metrics is used for collecting and analyzing numerical data such as CPU usage or network traffic.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T14:41:07.958326"}}
{"question": "What actions on CloudWatch can be controlled by IAM policies?", "answer": "IAM policies can be used to grant or deny access to specific CloudWatch actions, such as GetMetricStatistics.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-11T14:41:11.787202"}}
{"question": "How does using IAM impact access to CloudWatch data for specific resources?", "answer": "IAM permissions for CloudWatch apply to all cloud resources used with CloudWatch, and cannot be used to grant access to CloudWatch data for specific resources.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-11T14:41:11.787505"}}
{"question": "What is the difference between controlling access to CloudWatch actions and access to CloudWatch data using IAM?", "answer": "IAM can be used to control access to CloudWatch actions, but not to control access to CloudWatch data for specific resources.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-1", "source_tokens": 326, "generated_at": "2026-02-11T14:41:11.787677"}}
{"question": "What are some ways to use CloudWatch Logs for monitoring and storage?", "answer": "CloudWatch Logs can be used for real-time application and system monitoring by tracking the number of errors that occur in application logs and sending notifications when the error rate exceeds a specified threshold. It can also be used for long-term log retention, where log data is stored indefinitely in a highly durable and cost-effective way. The CloudWatch Logs Agent is used to move log files off the host and into the log service.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T14:41:17.799445"}}
{"question": "How does CloudWatch Logs Insights help in understanding and analyzing logs?", "answer": "CloudWatch Logs Insights is an interactive, pay-as-you-go, and integrated log analytics capability for CloudWatch Logs. It allows users to search and visualize their logs, derive actionable insights through queries with aggregations, filters, and regular expressions, and export query results to CloudWatch Dashboards.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T14:41:17.799809"}}
{"question": "What are the differences between CloudWatch Logs and CloudWatch Logs Insights in terms of functionality?", "answer": "CloudWatch Logs is a service used for monitoring and storing log data, while CloudWatch Logs Insights is a log analytics capability that enables users to search, visualize, and analyze their logs.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T14:41:17.800226"}}
{"question": "What is required to start using Logs Insights to query logs sent to CloudWatch Logs?", "answer": "No setup is required to use Logs Insights for querying logs being sent to CloudWatch Logs. Access can be gained from the AWS Management Console or through applications using the AWS SDK.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-11T14:41:23.990767"}}
{"question": "How does Anomaly Detection in CloudWatch work and what are its benefits?", "answer": "Anomaly Detection in CloudWatch uses machine-learning algorithms to analyze single time series, establish a normal baseline, and identify anomalies. It allows for auto-adjusting alarm thresholds based on natural patterns, such as time of day, day of week, seasonality, or changing trends. Users can also visualize metrics with anomaly detection bands on dashboards for easier troubleshooting.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-11T14:41:23.991065"}}
{"question": "What's the difference between Anomaly Detection and Contributor Insights in CloudWatch?", "answer": "Anomaly Detection in CloudWatch analyzes time-series data to determine and surface anomalies in system performance, whereas Contributor Insights analyzes time-series data to identify top contributors influencing system performance. Both tools run continuously without significant user intervention, but Anomaly Detection focuses on anomaly detection and threshold adjustment, while Contributor Insights focuses on identifying the contributors to system performance.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-3", "source_tokens": 435, "generated_at": "2026-02-11T14:41:23.991299"}}
{"question": "What sections of the AWS bill did CloudWatch charges appear under prior to July 2017?", "answer": "CloudWatch charges appeared under both the 'Elastic Compute Cloud' (EC2) and 'CloudWatch' detail sections of the AWS bill.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-11T14:41:37.265250"}}
{"question": "Why was the consolidation of CloudWatch charges beneficial?", "answer": "The consolidation of CloudWatch charges brought together all of the monitoring charges under the 'CloudWatch' section, simplifying monthly AWS usage and billing.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-11T14:41:37.265584"}}
{"question": "How is the billing for Logs Insights priced and billed compared to CloudWatch Metrics and Alarms?", "answer": "Logs Insights is priced per query and charges based on the amount of ingested log data scanned, while CloudWatch Metrics and Alarms were previously reported under the 'EC2' detail section and are now reported under the 'CloudWatch' detail section with no change in total billing.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-5", "source_tokens": 429, "generated_at": "2026-02-11T14:41:37.265785"}}
{"question": "Which two new account concepts are introduced with Cross-account observability in CloudWatch?", "answer": "The 'Monitoring account' is a central AWS account that can view and interact with observability data generated across other accounts. The 'Source account' is an individual AWS account that generates observability data for the resources that reside in it.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-11T14:41:42.233150"}}
{"question": "How does Cross-account observability in CloudWatch help in reducing manual effort for troubleshooting?", "answer": "Cross-account observability enables seamless data access and navigation between accounts, allowing you to identify and dive deep into correlated traces, metrics, and logs to root cause issues with reduced manual effort.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-11T14:41:42.233485"}}
{"question": "What's the difference between the role of a Monitoring account and a Source account in Cross-account observability in CloudWatch?", "answer": "A Monitoring account is a central account that can view and interact with observability data generated across other accounts. A Source account is an individual account that generates observability data for the resources residing in it.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-6", "source_tokens": 335, "generated_at": "2026-02-11T14:41:42.233903"}}
{"question": "What can you do with cross-account observability in CloudWatch regarding log groups?", "answer": "You can search for log groups stored across multiple accounts from a central view, run cross-account Logs Insights queries, Live Tail analytics, and create Contributor Insights rules across accounts to identify top-N contributors generating log entries.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-11T14:41:47.760681"}}
{"question": "How does cross-account observability in CloudWatch help in identifying anomalies and trending issues?", "answer": "You can use metrics search to visualize metrics from many accounts in a consolidated view, create alarms that evaluate metrics from other accounts to be notified of anomalies and trending issues, and visualize them on centralized dashboards.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-11T14:41:47.761030"}}
{"question": "What is the difference between cross-account monitoring in CloudWatch and cross-account observability in CloudWatch?", "answer": "Cross-account monitoring in CloudWatch allows access to metrics, logs, and traces within a single AWS account in a Region, while cross-account observability in CloudWatch allows access to organization-wide telemetry through IAM roles and provides a centralized view of logs, metrics, and traces across multiple AWS accounts in a Region.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-7", "source_tokens": 420, "generated_at": "2026-02-11T14:41:47.761238"}}
{"question": "What metrics does Amazon CloudWatch Application Signals generate for APIs and dependencies?", "answer": "Amazon CloudWatch Application Signals generates metrics for volume, latency, errors, and faults of APIs and dependencies.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-11T14:41:52.143106"}}
{"question": "How can customers reflect the business impact and importance of application services using Application Signals?", "answer": "Customers can reflect business impact and importance of application services by defining service level objectives (SLOs) on standard application metrics.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-11T14:41:52.143388"}}
{"question": "What's the difference between Application Signals' application-centric observability and traditional CloudWatch observability?", "answer": "Application Signals offers application-centric observability with new views in the AWS Management Console for CloudWatch that summarize application health against SLOs and offer drill-down capabilities to establish root causes, while traditional CloudWatch observability focuses on resource monitoring.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-8", "source_tokens": 358, "generated_at": "2026-02-11T14:41:52.143839"}}
{"question": "What are the benefits of using Application Signals for monitoring application performance?", "answer": "Application Signals offers an integrated application performance monitoring experience, allowing for automatic collection and correlation of application telemetry. It prioritizes business critical applications, enables automated actions using alarms, traces, and events data to reduce MTTR. Application Signals supports monitoring resources on Amazon EKS, Amazon EC2, Amazon ECS, databases, components, and on-premise resources.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-11T14:41:59.061498"}}
{"question": "How does Application Signals help manage critical applications?", "answer": "Application Signals enables users to create, measure, and track SLOs aligned with business and operational KPIs. SLOs are crucial in managing critical applications, improving availability, decreasing downtime, and enabling consistent customer experience. Application Signals provides access to a comprehensive view of all applications and the ability to manage application performance. It offers automatic, pre-built, and standardized dashboards with all applications, services, and telemetry data, allowing for quick scanning and access to metrics such as volume, availability latency, and errors impacting applications.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-11T14:41:59.061830"}}
{"question": "What is the difference between Application Signals' visualization capabilities and traditional monitoring tools?", "answer": "Application Signals offers visualization capabilities that help users quickly scan and access metrics such as volume, availability latency, and errors impacting applications. This is different from traditional monitoring tools, which may not provide the same level of comprehensive visualization capabilities and the ability to drill down into traces, APIs, and compute resources to get a root cause of application issues.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-9", "source_tokens": 354, "generated_at": "2026-02-11T14:41:59.061999"}}
{"question": "What key resources does CloudWatch Application Insights monitor for applications using Amazon EC2 instances?", "answer": "CloudWatch Application Insights monitors applications that use Amazon EC2 instances and other application resources. It identifies and sets up key metrics, logs, and alarms across these resources, which can include Microsoft SQL Server databases, web (IIS) and application servers, OS, load balancers, and queues.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:42:04.882270"}}
{"question": "How does CloudWatch Application Insights help in troubleshooting and root cause analysis?", "answer": "CloudWatch Application Insights creates automated dashboards for detected problems, which include correlated metric anomalies and log errors, along with additional insights to help point users to a potential root cause.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:42:04.882504"}}
{"question": "What are the main differences between CloudWatch Application Insights and X-Ray in terms of monitoring applications?", "answer": "CloudWatch Application Insights offers application-level monitoring and observability for application resources and technology stack, while CloudWatch Application Signals extends CloudWatch with standardized application metrics and application-centric observability views. X-Ray, on the other hand, helps developers analyze and debug production, distributed applications, providing an end-to-end view of requests as they travel through the application.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-10", "source_tokens": 473, "generated_at": "2026-02-11T14:42:04.882673"}}
{"question": "What does X-Ray Daemon do in comparison to directly using X-Ray APIs?", "answer": "The X-Ray Daemon simplifies the process of collecting traces and sending them to X-Ray by automatically doing this task, while directly using X-Ray APIs requires manual ingestion of request data.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-11T14:42:09.210223"}}
{"question": "How can you use X-Ray to trace web requests made to a web application?", "answer": "X-Ray can be used to trace web requests made to a web application by instrumenting the application code or using Elastic Beanstalk for web applications running on AWS.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-11T14:42:09.210604"}}
{"question": "What are annotations in X-Ray and when are they added?", "answer": "Annotations are system-defined or user-defined metadata associated with a segment, and they are added when a call results in errors.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-11", "source_tokens": 463, "generated_at": "2026-02-11T14:42:09.211088"}}
{"question": "What types of events does X-Ray log as management events and data events?", "answer": "X-Ray logs all API calls as management events and logs calls on traces as data events. Data events, such as those for PutTraceSegments and GetTimeSeriesServiceStatistics, are not logged by default.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-11T14:42:14.274985"}}
{"question": "How does CloudWatch Container Insights help with monitoring containerized applications?", "answer": "CloudWatch Container Insights collects, aggregates, and summarizes metrics and logs from containerized applications and microservices running on various platforms. It delivers container observability through automatic dashboards and allows setting alarms on Container Insights metrics.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-11T14:42:14.275230"}}
{"question": "What additional metrics does CloudWatch Container Insights with enhanced observability deliver for Amazon Elastic Kubernetes Service and Elastic Container Service?", "answer": "CloudWatch Container Insights with enhanced observability delivers detailed metrics such as container-level ECS and EKS performance metrics, EKS Kube-state metrics, and EKS control plane metrics out-of-the-box.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-12", "source_tokens": 456, "generated_at": "2026-02-11T14:42:14.275368"}}
{"question": "What performance metrics and metrics types are provided by Container Insights with enhanced observability for Amazon EKS and Amazon ECS?", "answer": "Container Insights with enhanced observability provides container-level ECS and EKS performance metrics, EKS Kube-state metrics, and EKS control plane metrics.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-11T14:42:18.661727"}}
{"question": "Why would you use Container Insights with enhanced observability instead of the regular one?", "answer": "You would use Container Insights with enhanced observability to enable out-of-the-box detailed health and performance metrics for faster problem isolation and troubleshooting.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-11T14:42:18.662024"}}
{"question": "How does Container Insights with enhanced observability for Amazon EKS compare to the regular one?", "answer": "Container Insights with enhanced observability for Amazon EKS provides container-level metrics and metrics types that are not available in the regular one.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-13", "source_tokens": 501, "generated_at": "2026-02-11T14:42:18.662518"}}
{"question": "What is the retention period for CloudWatch custom metrics ingested from Prometheus?", "answer": "The retention period for CloudWatch custom metrics ingested from Prometheus is 15 months per data point with automatic roll up.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-11T14:42:23.236842"}}
{"question": "How does CloudWatch handle retention for Prometheus metrics compared to regular CloudWatch custom metrics?", "answer": "CloudWatch automatically ingests Prometheus metrics as CloudWatch custom metrics but with a longer retention period of 15 months per data point with automatic roll up.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-11T14:42:23.237061"}}
{"question": "What is the difference in retention periods between CloudWatch custom metrics from Prometheus and regular CloudWatch custom metrics?", "answer": "Regular CloudWatch custom metrics have a default retention period of 15 days, while CloudWatch custom metrics from Prometheus have a retention period of 15 months per data point with automatic roll up.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-14", "source_tokens": 486, "generated_at": "2026-02-11T14:42:23.237227"}}
{"question": "What databases can CloudWatch Database Insights be used for?", "answer": "CloudWatch Database Insights can be used for Amazon Aurora and RDS databases.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T14:42:28.661011"}}
{"question": "How does CloudWatch Database Insights help DBAs and DevOps engineers?", "answer": "CloudWatch Database Insights helps DBAs and DevOps engineers by providing a unified view in the console of logs and metrics from applications, databases, and operating systems. It also includes pre-built dashboards, recommended alarms, and automated telemetry collection for monitoring database fleet health and troubleshooting.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T14:42:28.661339"}}
{"question": "What is the difference between CloudWatch Database Insights and RDS Performance Insights?", "answer": "CloudWatch Database Insights is a comprehensive database observability feature that includes RDS Performance Insights capabilities. While RDS Performance Insights allows customers to assess the load on their databases in a pre-built dashboard, one instance at a time, CloudWatch Database Insights provides fleet-level views, integration with application performance monitoring via Application Signals, correlation of database metrics with logs and events, and visualization of SQL query statistics.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T14:42:28.661868"}}
{"question": "What is the role of Amazon CloudWatch Internet Monitor in monitoring internet availability and performance for AWS-hosted applications?", "answer": "Amazon CloudWatch Internet Monitor is a service that helps users continually monitor internet availability and performance metrics between their AWS-hosted applications and application end users. It allows users to visualize the impact of issues, pinpoint affected locations and providers, and take action to improve their end users' network experience.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:42:34.572706"}}
{"question": "How does CloudWatch Internet Monitor help users improve their users' experience?", "answer": "CloudWatch Internet Monitor provides insights and recommendations that can help users improve their users' experience by using other AWS services. It also sends health events to Amazon EventBridge so that users can set up notifications.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:42:34.573260"}}
{"question": "What are the components of Internet Monitor's pricing and how do they differ?", "answer": "Internet Monitor has three pricing components: a fee per monitored resource, a fee per city-networks, and charges for the diagnostic logs published to CloudWatch Logs. The fee per monitored resource applies to every resource associated with the monitor, while the fee per city-networks applies to every city-network used in the monitor. The charges for diagnostic logs depend on the amount of data published to CloudWatch Logs.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-16", "source_tokens": 506, "generated_at": "2026-02-11T14:42:34.573624"}}
{"question": "In which AWS Regions can I add Internet Monitor for Amazon CloudFront distributions and WorkSpaces directories?", "answer": "Internet Monitor is available in all supported Regions for Amazon CloudFront distributions and WorkSpaces directories.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-11T14:42:40.538027"}}
{"question": "How does CloudWatch Lambda Insights simplify monitoring and troubleshooting of Lambda functions?", "answer": "CloudWatch Lambda Insights simplifies monitoring and troubleshooting of Lambda functions by providing automatic dashboards in the CloudWatch console, giving DevOps and systems engineers end-to-end operational visibility of metrics, logs, and traces summarizing the performance and health of their Lambda functions.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-11T14:42:40.538468"}}
{"question": "What is the difference between Internet Monitor and Network Monitor?", "answer": "Internet Monitor is a feature for monitoring the performance and visibility of internet connections for Amazon services like CloudFront and WorkSpaces. Network Monitor, on the other hand, provides visibility into the performance and visibility of the network connecting your AWS-hosted applications to on-premises destinations, enabling you to quickly visualize packet loss and latency, set alerts and thresholds, and improve end usersâ€™ network experience. Both are used for monitoring network performance, but they differ in the specific types of networks and services they cover.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-17", "source_tokens": 378, "generated_at": "2026-02-11T14:42:40.539001"}}
{"question": "What metrics does Network Monitor provide for each probe?", "answer": "Network Monitor provides round-trip latency and packet loss metrics for each probe.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-11T14:42:44.440340"}}
{"question": "How can you use Network Monitor metrics for hybrid network connections?", "answer": "You can use Network Monitor metrics to view the AWS Network Health Indicator for hybrid network connections over AWS Direct Connect.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-11T14:42:44.440698"}}
{"question": "How does the pricing for Network Monitor compare to Amazon CloudWatch DEM?", "answer": "Network Monitor pricing includes a fee per monitored resource and charges for metrics published to CloudWatch, while Amazon CloudWatch DEM focuses on monitoring end users' experience, including performance, availability, and usability, with no explicit mention of pricing in the context.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-18", "source_tokens": 472, "generated_at": "2026-02-11T14:42:44.441097"}}
{"question": "What is the purpose of Amazon CloudWatch RUM for application performance monitoring?", "answer": "Amazon CloudWatch RUM is a real user monitoring feature that gives visibility into an applicationâ€™s client-side performance, helping to reduce mean time to resolution (MTTR). It collects data on web application performance in real time to identify and debug issues, complementing CloudWatch Synthetics data for more comprehensive visibility.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-11T14:42:50.368675"}}
{"question": "How does Amazon CloudWatch RUM help reduce application performance issues?", "answer": "Amazon CloudWatch RUM helps reduce application performance issues by giving you visibility into an applicationâ€™s client-side performance in real time. It allows you to identify and debug issues, understand the range of end-user impacts, and prioritize bug fixes based on user data.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-11T14:42:50.369041"}}
{"question": "What is the difference between Amazon CloudWatch RUM and Amazon CloudWatch Evidently in terms of application monitoring?", "answer": "Amazon CloudWatch RUM and Amazon CloudWatch Evidently serve different purposes in application monitoring. RUM provides real-time visibility into client-side application performance and helps identify and debug issues. Evidently, on the other hand, allows you to conduct experiments and validate new features before rolling them out, reducing the risk related to new feature roll-outs.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-19", "source_tokens": 434, "generated_at": "2026-02-11T14:42:50.369548"}}
{"question": "What metrics can CloudWatch Synthetics be used to monitor for application endpoints?", "answer": "CloudWatch Synthetics can be used to monitor metrics for application endpoints such as availability, latency, transactions, broken or dead links, step by step task completions, page load errors, load latencies for UI assets, complex wizard flows, or checkout flows.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-11T14:42:55.676660"}}
{"question": "How does Amazon CloudWatch Evidently facilitate feature management and experimentation?", "answer": "Amazon CloudWatch Evidently facilitates feature management and experimentation by allowing you to run experiments on different feature variations and compare them with a baseline, or launch a feature variation on a schedule, while monitoring business metrics like visit duration and revenue.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-11T14:42:55.676991"}}
{"question": "What is the difference between CloudWatch RUM and CloudWatch Synthetics in terms of application monitoring?", "answer": "CloudWatch RUM is used for client-side application performance monitoring, while CloudWatch Synthetics is used for monitoring application endpoints for availability, latency, transactions, and other performance metrics.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-20", "source_tokens": 473, "generated_at": "2026-02-11T14:42:55.677363"}}
{"question": "What is Metrics Insights in CloudWatch and how does it help you analyze metrics?", "answer": "Metrics Insights is a built-in query engine in CloudWatch that enables users to slice and dice operational metrics in real time and create aggregations on the fly using standard SQL queries. It helps users understand the status of their application health and performance by giving them the ability to analyze metrics at scale.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-11T14:43:01.941644"}}
{"question": "What metrics can be monitored in CloudWatch and how can you get started with Metrics Insights?", "answer": "CloudWatch allows users to monitor metrics for various AWS products and services including Amazon EC2 instances, EBS volumes, Elastic Load Balancers, and more. To get started with Metrics Insights, users can click on the metrics tab in the CloudWatch console, find Metrics Insights under the Query tab, and use the visual query builder or type in raw SQL queries using the query editor.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-11T14:43:01.942004"}}
{"question": "How does Metrics Insights compare to the visual query builder in terms of query construction?", "answer": "Metrics Insights offers both a visual query builder and a query editor for constructing SQL queries. The visual query builder helps users select their metrics of interest, namespaces, and dimensions visually, while the query editor allows users to type in their raw SQL queries for more granular detail.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-21", "source_tokens": 420, "generated_at": "2026-02-11T14:43:01.942486"}}
{"question": "What is the retention period for data points with a resolution of 1 minute?", "answer": "The data is available for 15 days with 1-minute resolution.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-11T14:43:06.012952"}}
{"question": "How does CloudWatch handle long-term storage of custom metrics with different resolutions?", "answer": "CloudWatch aggregates the data and makes it available with increasing resolutions: 5 minutes after 15 days, 1 hour after 63 days, and 1 hour for data older than 455 days.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-11T14:43:06.013196"}}
{"question": "How does the retention period and resolution compare for data points with a period of 1 minute and data points with a period of 5 minutes?", "answer": "Data with a resolution of 1 minute is available for 15 days with 1-minute resolution, while data with a resolution of 5 minutes is available for 63 days with 5-minute resolution.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-22", "source_tokens": 407, "generated_at": "2026-02-11T14:43:06.013565"}}
{"question": "What is the minimum resolution supported by CloudWatch for storing metrics?", "answer": "The minimum resolution supported by CloudWatch is one-second data points, which is considered high resolution.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-11T14:43:09.938554"}}
{"question": "Why does CloudWatch change the granularity of data when requesting old data?", "answer": "CloudWatch changes the granularity of data when requesting old data to match the retention schedules and ensure that data is available.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-11T14:43:09.938925"}}
{"question": "How does CloudWatch compare in handling data from different sources?", "answer": "CloudWatch allows querying data from multiple sources, including AWS, on-premises, and other clouds. This helps users monitor metrics in one place, making troubleshooting more efficient.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-23", "source_tokens": 483, "generated_at": "2026-02-11T14:43:09.939364"}}
{"question": "In what time window is the single data point for a 5-minute period placed on the graph?", "answer": "The single data point for a 5-minute period is placed at the beginning of the 5-minute time window.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-11T14:43:14.640181"}}
{"question": "Why is it recommended to use a one-minute period for troubleshooting and other precise graphing activities in Amazon CloudWatch?", "answer": "It is recommended to use a one-minute period for troubleshooting and other precise graphing activities because the single data point is placed exactly at the 1-minute mark, providing the most accurate representation of the time period.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-11T14:43:14.640643"}}
{"question": "How does the storage resolution differ between standard and high-resolution custom metrics in Amazon CloudWatch?", "answer": "Standard resolution custom metrics are stored at a one-minute granularity, while high-resolution custom metrics are stored with a one-second granularity.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-24", "source_tokens": 448, "generated_at": "2026-02-11T14:43:14.641046"}}
{"question": "What is the one-second resolution for storing custom metrics in CloudWatch called?", "answer": "High-resolution custom metrics", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-11T14:43:17.883291"}}
{"question": "Why is it beneficial to use high-resolution custom metrics instead of standard ones in CloudWatch?", "answer": "High-resolution custom metrics allow for more detailed monitoring and analysis with shorter time intervals", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-11T14:43:17.883586"}}
{"question": "How does CloudWatch price high-resolution custom metrics compared to standard ones?", "answer": "Both are priced in the same manner", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-25", "source_tokens": 448, "generated_at": "2026-02-11T14:43:17.883956"}}
{"question": "What metrics and logs does Application Insights automatically set up for an application once it's onboarded?", "answer": "Application Insights sets up the recommended metrics and logs for an application based on the technology tier selected during onboarding. These can be customized based on the user's needs.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-11T14:43:22.931958"}}
{"question": "How does Application Insights help in troubleshooting application problems?", "answer": "Application Insights uses machine learning algorithms and built-in rules to identify application problems and provides insights such as possible root causes and impacted metrics and logs. Users can provide feedback to make the problem detection engine specific to their use case.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-11T14:43:22.932252"}}
{"question": "What is the difference between the problem detection engine in Application Insights and manual troubleshooting?", "answer": "The problem detection engine in Application Insights uses machine learning algorithms and built-in rules to dynamically monitor and analyze symptoms of a problem across the application stack and detect application problems. Manual troubleshooting involves dealing with individual metric spikes, events, or log exceptions.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-26", "source_tokens": 414, "generated_at": "2026-02-11T14:43:22.932640"}}
{"question": "What format options are available for Metric Streams output?", "answer": "Metric Streams can output in either OpenTelemetry or JSON format.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-11T14:43:27.131994"}}
{"question": "How does Metric Streams make it easier to manage CloudWatch metrics?", "answer": "Metric Streams enables you to continuously stream CloudWatch metrics to a destination of your choice with minimal setup and configuration, making it easier to manage and analyze CloudWatch metrics.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-11T14:43:27.132331"}}
{"question": "How does Metric Streams compare to polling CloudWatch APIs for metrics data?", "answer": "Metric Streams provides an alternative way of obtaining metrics data from CloudWatch without the need to poll APIs. It allows you to create a continuous, scalable stream including the most up-to-date CloudWatch metrics data to power dashboards and other tools.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-27", "source_tokens": 468, "generated_at": "2026-02-11T14:43:27.132552"}}
{"question": "What metrics are available in the monitoring section of the Metric Streams console page?", "answer": "You can see metrics related to the volume of metric updates over time in the monitoring section of the Metric Streams console page.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-11T14:43:32.181364"}}
{"question": "How can CloudWatch Logs help in monitoring and troubleshooting systems and applications?", "answer": "CloudWatch Logs allows you to monitor logs in near real time for specific phrases, values or patterns. You can create alarms based on the number of errors in system logs or view graphs of web request latency from application logs. Log data can be stored for an extended period and accessed when needed.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-11T14:43:32.181692"}}
{"question": "What's the difference between the monitoring of Metric Streams and CloudWatch Logs?", "answer": "Metric Streams provide automatic dashboards for metric updates over time, available under the AWS/CloudWatch namespace. CloudWatch Logs allows monitoring and troubleshooting using existing log files, enabling the monitoring of logs in near real-time and the creation of alarms based on log data.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-28", "source_tokens": 312, "generated_at": "2026-02-11T14:43:32.182135"}}
{"question": "What is the default frequency for CloudWatch Logs Agent to send log data?", "answer": "The CloudWatch Logs Agent sends log data every five seconds by default.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-11T14:43:35.816763"}}
{"question": "How does CloudWatch Logs help with application and system monitoring?", "answer": "CloudWatch Logs monitors applications and systems in near real time using log data for error tracking and sends notifications when error rates exceed specified thresholds.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-11T14:43:35.816992"}}
{"question": "What are the key differences between real time application and system monitoring and long term log retention with CloudWatch Logs?", "answer": "Real time application and system monitoring involves monitoring logs in near real time to track errors and send notifications, while long term log retention allows for storing log data for an extended period in highly durable and cost-effective storage.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-29", "source_tokens": 413, "generated_at": "2026-02-11T14:43:35.817355"}}
{"question": "What is the purpose of creating Metric Filters in CloudWatch Logs?", "answer": "Metric Filters turn log data into Amazon CloudWatch Metrics for graphing or alarming.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-11T14:43:39.465913"}}
{"question": "How can you create exact matches using Metric Filters in CloudWatch Logs?", "answer": "By putting double quotes around the search term in the Metric Filter pattern.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-11T14:43:39.466222"}}
{"question": "Can Metric Filters extract values from both space-delimited and JSON-formatted log events?", "answer": "Yes, Metric Filters can extract values from both space-delimited log events and JSON-formatted log events.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-30", "source_tokens": 470, "generated_at": "2026-02-11T14:43:39.466412"}}
{"question": "What can you test in CloudWatch Logs before creating a Metric Filter?", "answer": "You can test Metric Filter patterns against existing log data in CloudWatch Logs or supply your own log events for testing.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-11T14:43:43.923531"}}
{"question": "How can you process log data with regular expressions in CloudWatch Logs?", "answer": "Amazon CloudWatch Logs does not support regular expressions for log data processing. Instead, consider using Amazon Kinesis and integrating a regular expression processing engine.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-11T14:43:43.923866"}}
{"question": "How does CloudWatch Logs Standard compare to CloudWatch Logs in terms of log management features?", "answer": "CloudWatch Logs Standard offers comprehensive log management with real-time monitoring, advanced analytics capabilities like Live Tail, metric extraction, alarming, and data protection. In contrast, CloudWatch Logs does not provide these advanced features.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-31", "source_tokens": 410, "generated_at": "2026-02-11T14:43:43.924113"}}
{"question": "What region is Amazon CloudWatch Logs Infrequent Access (Logs-IA) available in?", "answer": "Amazon CloudWatch Logs Infrequent Access (Logs-IA) is available in all AWS Regions where CloudWatch Logs is available.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-11T14:43:48.961597"}}
{"question": "How does Amazon CloudWatch Logs Infrequent Access (Logs-IA) differ from CloudWatch Logs Standard in terms of functionality?", "answer": "Amazon CloudWatch Logs Infrequent Access (Logs-IA) offers managed ingestion, cross-account log analytics, and encryption similar to CloudWatch Logs Standard, but it is designed for ad-hoc querying and after-the-fact forensic analysis with a lower per GB ingestion price.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-11T14:43:48.961930"}}
{"question": "What fields are available in Logs Insights for queries?", "answer": "Logs Insights automatically discovers the logs fields from logs from various AWS services and applications, generating @message, @logStream, and @timestamp for all logs sent to CloudWatch.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-32", "source_tokens": 368, "generated_at": "2026-02-11T14:43:48.962124"}}
{"question": "Which query languages does CloudWatch Logs Insights support?", "answer": "CloudWatch Logs Insights supports three query languages: Logs Insights QL, OpenSearch Service Piped Processing Language (PPL), and OpenSearch Service Structured Query Language (SQL).", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-11T14:43:55.448000"}}
{"question": "How does OpenSearch Service PPL differ from Logs Insights QL in terms of querying and analyzing log data?", "answer": "OpenSearch Service PPL enables you to analyze your logs by querying and analyzing data using piped-together commands, making it easier to understand and compose complex queries. It offers a rich set of functions for filtering, aggregating, and analyzing data. Logs Insights QL, on the other hand, is a purpose-built query language with a few but powerful commands for retrieving log fields, finding log events, aggregating log data, and extracting ephemeral fields.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-11T14:43:55.448335"}}
{"question": "What functions can you use for analysis with OpenSearch Service SQL compared to Logs Insights QL?", "answer": "With OpenSearch Service SQL queries, you can use a rich set of JSON, mathematical, string, conditional, and other Spark SQL commands and functions for analyzing your logs. In contrast, Logs Insights QL offers a more limited set of commands for aggregation, extraction of ephemeral fields, and retrieval of log fields.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-33", "source_tokens": 432, "generated_at": "2026-02-11T14:43:55.448775"}}
{"question": "What functions are available in the AWS Logs Insights query language for string manipulation?", "answer": "The query language supports functions like concat, strlen, trim for string manipulation.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-11T14:44:00.766135"}}
{"question": "How can the results of a Logs Insights query be visualized?", "answer": "Logs Insights supports visualizing data using line charts, stacked area charts, bar charts, and pie charts. Visualizations are generated for all queries containing one or more aggregate functions.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-11T14:44:00.766471"}}
{"question": "What is the difference between the VPC Flow Logs Dashboard and the CloudTrail Dashboard in terms of the types of logs they process and the information they provide?", "answer": "The VPC Flow Logs Dashboard captures network flow data for Virtual Private Cloud and is designed to help customers analyze network traffic, detect unusual patterns, and monitor resource usage. It supports only VPC v2 fields. The CloudTrail Dashboard provides an overview of API activity within an AWS environment using CloudTrail logs and is useful for monitoring API activity, auditing actions, and identifying potential security or compliance issues.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-34", "source_tokens": 509, "generated_at": "2026-02-11T14:44:00.766677"}}
{"question": "What does Amazon CloudWatch Logs Anomaly Detection do for application logs?", "answer": "Amazon CloudWatch Logs Anomaly Detection is an automated logs analytics feature that helps monitor application logs, detect unusual behavior, and provide insights for faster remediation.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-11T14:44:09.829803"}}
{"question": "How does CloudWatch Logs Anomaly Detection identify potential log issues?", "answer": "CloudWatch Logs Anomaly Detection uses advanced algorithms to automatically detect unusual patterns and changes in application logs, alerting users to potential problems.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-11T14:44:09.830163"}}
{"question": "What is the main difference between CloudWatch Logs Anomaly Detection and DevOps Guru's anomaly detection capability?", "answer": "CloudWatch Logs Anomaly Detection is a more general solution for anomaly detection across any application log, whereas DevOps Guru's anomaly detection capability is purpose-built for specific application sources like Lambda.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-36", "source_tokens": 467, "generated_at": "2026-02-11T14:44:09.830653"}}
{"question": "What actions are required for users to start and stop a Live Tail session?", "answer": "Users need to have the logs:StartLiveTail and logs:StopLiveTail actions allowed in their policy statement to start and stop a Live Tail session.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-11T14:44:15.144603"}}
{"question": "In what ways can Live Tail be used to enhance application monitoring and debugging within AWS?", "answer": "Live Tail allows developers to gain deep visibility into application logs and debug code directly from their development environment. IT engineers, operations support, and central security teams can use Live Tail to monitor the status and health of deployments and efficiently perform root-cause analysis and reduce mean time to resolution.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-11T14:44:15.144894"}}
{"question": "How does Live Tail compare to other tools for monitoring and debugging logs within AWS?", "answer": "Live Tail provides an interactive real-time view of logs within the context of related events, allowing for efficient root-cause analysis and reduced mean time to resolution. It can be integrated directly into other services like Amazon Managed Grafana and AWS Thinkbox to provide deep-dive analytics capabilities from within your own console.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-37", "source_tokens": 437, "generated_at": "2026-02-11T14:44:15.145263"}}
{"question": "In which regions is Live Tail available according to the text?", "answer": "Live Tail is available in the US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), EU (Paris), and South America (SÃ£o Paulo) Regions.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-11T14:44:20.660038"}}
{"question": "How does CloudWatch Logs data protection help industries under strict regulations?", "answer": "CloudWatch Logs data protection automatically identifies and masks sensitive information in logs using pattern matching and machine learning without requiring anyone to access them. This helps industries under strict regulations ensure that no personal information gets stored in logs.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-11T14:44:20.660269"}}
{"question": "What is the difference between Live Tail and Logs Insights for viewing logs data?", "answer": "Live Tail provides a real-time view of the logs data collected by CloudWatch, whereas Logs Insights and Log Groups are used for historical logs.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-38", "source_tokens": 463, "generated_at": "2026-02-11T14:44:20.660654"}}
{"question": "What data identifiers can you specify when creating a data protection policy in CloudWatch Logs?", "answer": "You can specify various data identifiers such as email addresses, driverâ€™s licenses from many countries, credit card numbers, addresses, and more.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-11T14:44:24.874269"}}
{"question": "How does creating an alarm on custom metrics in CloudWatch provide flexibility?", "answer": "Creating an alarm on custom metrics provides flexibility as it allows you to monitor specific metrics that are unique to your custom applications or infrastructure.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-11T14:44:24.874514"}}
{"question": "What actions can you perform when creating an alarm in CloudWatch that exceeds a threshold?", "answer": "You can perform actions such as sending an email, publishing to an SQS queue, stopping or terminating an Amazon EC2 instance, or executing an Auto Scaling policy.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-39", "source_tokens": 479, "generated_at": "2026-02-11T14:44:24.874922"}}
{"question": "What metric do you choose when creating an Amazon CloudWatch alarm?", "answer": "When creating an Amazon CloudWatch alarm, you first choose the Amazon CloudWatch metric you want it to monitor.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T14:44:29.790786"}}
{"question": "How does an Amazon CloudWatch alarm behave once it has triggered?", "answer": "An Amazon CloudWatch alarm continues to evaluate metrics against your chosen threshold, even after it has already triggered. It will remain in the ALARM state until it no longer breaches the threshold.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T14:44:29.791024"}}
{"question": "What's the difference between using a custom dashboard and an automatic dashboard in Amazon CloudWatch?", "answer": "Custom dashboards allow you to create, customize, and save graphs of AWS resources and custom metrics. Automatic dashboards, on the other hand, are pre-built with AWS service recommended best practices, remain resource aware, and dynamically update to reflect the latest state of important performance metrics. The main difference is the level of customization and the automatic updating feature.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T14:44:29.791367"}}
{"question": "What AWS services are supported by Amazon CloudWatch Events for generating events?", "answer": "Amazon CloudWatch Events supports generating events for Amazon EC2, Auto Scaling, and AWS CloudTrail.", "question_type": "factual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:44:34.741987"}}
{"question": "How does Amazon CloudWatch Events help in implementing a scheduled application?", "answer": "Amazon CloudWatch Events allows you to generate events on a schedule you set using Unix cron syntax. By monitoring for these events, you can implement a scheduled application.", "question_type": "conceptual", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:44:34.742313"}}
{"question": "What is the main difference between Amazon CloudWatch Events and AWS Config?", "answer": "Amazon CloudWatch Events is a near real-time stream of system events that describes changes to AWS resources and allows you to define rules to monitor for specific events and perform actions in an automated manner. AWS Config, on the other hand, provides an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. Config rules help determine whether configuration changes are compliant, while CloudWatch Events is a general-purpose event stream.", "question_type": "comparison", "metadata": {"service": "CLOUDWATCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cloudwatch-faq-41", "source_tokens": 456, "generated_at": "2026-02-11T14:44:34.742815"}}
{"question": "What is AWS CodeArtifact and how does it work for package management in software development?", "answer": "AWS CodeArtifact is a fully managed package repository service that helps in securely storing, sharing, and managing software packages used in software development. It reduces the overhead of setting up and maintaining an artifact server or infrastructure and allows users to pay only for the software packages stored, number of requests made, and data transferred out of the Region. CodeArtifact can be configured to fetch from public repositories like the npm Registry, Maven Central, Python Package Index (PyPI), and NuGet. It also allows securely sharing private packages across organizations by publishing to a central organizational repository.", "question_type": "conceptual", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-11T14:44:42.028998"}}
{"question": "How does AWS CodeArtifact compare to self-hosted artifact servers in terms of cost and maintenance?", "answer": "AWS CodeArtifact is a fully managed service, meaning AWS handles the cost and maintenance of the underlying infrastructure. Users pay only for the software packages stored, number of requests made, and data transferred out of the Region. In contrast, self-hosted artifact servers require users to set up, maintain, and pay for the infrastructure, including the servers, storage, and network resources.", "question_type": "comparison", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-11T14:44:42.029341"}}
{"question": "What are the key features of AWS CodeArtifact for managing software packages?", "answer": "AWS CodeArtifact offers several key features for managing software packages in software development. These include: securely storing and sharing artifacts across accounts with appropriate levels of access, reducing overhead from setup and maintenance, configuring CodeArtifact to fetch from public repositories, and building automated approval workflows with CodeArtifact APIs and Amazon EventBridge.", "question_type": "factual", "metadata": {"service": "CODEARTIFACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeartifact-faq-0", "source_tokens": 259, "generated_at": "2026-02-11T14:44:42.029814"}}
{"question": "What does AWS CodeBuild do in the context of software development?", "answer": "AWS CodeBuild is a fully managed continuous integration service in the cloud that compiles source code, runs tests, and produces packages ready for deployment.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:44:46.280679"}}
{"question": "How does CodeBuild improve the build process over self-managed solutions?", "answer": "CodeBuild eliminates the need to manage build servers and software, automatically scales to handle build volume, and runs builds concurrently, reducing waiting times.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:44:46.281092"}}
{"question": "What are the primary components of a build project and build environment in CodeBuild?", "answer": "A build project includes information such as source code location, build environment, build commands, and output storage. A build environment is the combination of operating system, programming language runtime, and tools used by CodeBuild to run a build.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-0", "source_tokens": 486, "generated_at": "2026-02-11T14:44:46.281438"}}
{"question": "What source code repositories can CodeBuild connect to?", "answer": "CodeBuild can connect to AWS CodeCommit, S3, GitHub, GitHub Enterprise, and Bitbucket to pull source code for builds.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T14:44:51.527178"}}
{"question": "How does CodeBuild support .NET Framework builds?", "answer": "CodeBuild does not currently offer a preconfigured build environment for .NET Framework. Users can customize their own environment by creating a Docker image and uploading it to the Amazon EC2 Container Registry or the Docker Hub registry. This custom image can then be referenced in the build project.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T14:44:51.527497"}}
{"question": "What's the difference between CodeBuild's preconfigured environments for .NET Core and .NET Framework?", "answer": "CodeBuild offers a preconfigured environment for .NET Core 2.0, but does not currently offer a preconfigured environment for .NET Framework. Users can customize their own environment for .NET Framework by creating a Docker image and uploading it to the Amazon EC2 Container Registry or the Docker Hub registry.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T14:44:51.528005"}}
{"question": "What information is included in past build results?", "answer": "Past build results include outcome (success or failure), build duration, output artifact location, and log location.", "question_type": "factual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-11T14:44:55.898819"}}
{"question": "How can you use the CodeBuild dashboard to monitor build behavior?", "answer": "The CodeBuild dashboard displays number of builds attempted, succeeded, and failed, as well as build duration. It also allows you to visit the CloudWatch console for more detailed build metrics.", "question_type": "conceptual", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-11T14:44:55.899201"}}
{"question": "What are the differences in resources required between the .NET Core for Windows build environment and the build.general1.small compute instance type?", "answer": "The .NET Core for Windows build environment requires more memory and processing power than the build.general1.small compute instance type due to the size of the Windows Docker base container and additional libraries.", "question_type": "comparison", "metadata": {"service": "CODEBUILD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codebuild-faq-2", "source_tokens": 449, "generated_at": "2026-02-11T14:44:55.899615"}}
{"question": "What operating systems does AWS CodeDeploy support?", "answer": "AWS CodeDeploy supports Amazon Linux, Red Hat Enterprise Linux, Ubuntu Server, and Microsoft Windows Server.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-11T14:45:00.274498"}}
{"question": "How does AWS CodeDeploy help developers and administrators?", "answer": "AWS CodeDeploy helps developers and administrators automate code deployments to any instance, including Amazon EC2 instances and on-premises instances. It eliminates the need for error-prone manual operations and scales with infrastructure.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-11T14:45:00.274860"}}
{"question": "How does AWS CodeDeploy compare to AWS Elastic Beanstalk?", "answer": "AWS CodeDeploy is a building block service focused on helping developers deploy and update software on any instance, while AWS Elastic Beanstalk is an end-to-end application management solution.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-0", "source_tokens": 489, "generated_at": "2026-02-11T14:45:00.275289"}}
{"question": "What type of instances can AWS CodeDeploy deploy to?", "answer": "AWS CodeDeploy can deploy to any instance that can install the CodeDeploy agent and connect to AWS public endpoints.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-11T14:45:05.473464"}}
{"question": "How does a deployment group relate to an EC2 application in AWS CodeDeploy?", "answer": "A deployment group in AWS CodeDeploy is an entity for grouping EC2 instances or AWS Lambda functions in a CodeDeploy deployment. It defines a set of instances associated with an application that you target for a deployment. For EC2 deployments, it is a set of instances, and you can add instances to a deployment group by specifying a tag, an Auto Scaling group name, or both.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-11T14:45:05.473731"}}
{"question": "What is the difference between a deployment configuration and a deployment group in AWS CodeDeploy?", "answer": "A deployment group in AWS CodeDeploy is a set of instances or AWS Lambda functions associated with an application, and a deployment configuration specifies how the behavior for how deployment should proceed for a deployment group, including how to handle deployment failure.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-1", "source_tokens": 468, "generated_at": "2026-02-11T14:45:05.474125"}}
{"question": "What three parameters do you specify for a deployment in AWS CodeDeploy?", "answer": "You specify the revision, deployment group, and deployment configuration for a deployment in AWS CodeDeploy.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T14:45:10.032902"}}
{"question": "What is the purpose and format of an AppSpec file in AWS CodeDeploy?", "answer": "An AppSpec file is a configuration file used by the AWS CodeDeploy Agent. It is in YAML format, includes the root directory of your revision, and specifies the files to be copied and the scripts to be executed during each phase of the deployment.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T14:45:10.033227"}}
{"question": "How does the hooks section of an AppSpec file compare to the files section?", "answer": "The hooks section of an AppSpec file specifies scripts to run during each phase of the deployment, while the files section specifies the source files to be copied and the destination folders on each instance.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T14:45:10.033713"}}
{"question": "In what order do the deployment lifecycle events occur?", "answer": "The deployment lifecycle events occur in the following order: ApplicationStop, DownloadBundle, BeforeInstall, Install, AfterInstall, ApplicationStart, ValidateService.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-11T14:45:14.229691"}}
{"question": "What is the purpose of the BeforeInstall deployment lifecycle event?", "answer": "The BeforeInstall deployment lifecycle event is used for preinstall tasks such as decrypting files and creating a backup of the current version.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-11T14:45:14.230041"}}
{"question": "How does the ApplicationStop deployment lifecycle event compare to the ValidateService event?", "answer": "The main difference between the ApplicationStop and ValidateService deployment lifecycle events is that ApplicationStop is used to gracefully stop the application before a deployment, while ValidateService is the last opportunity to verify the deployment's success.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-3", "source_tokens": 444, "generated_at": "2026-02-11T14:45:14.230213"}}
{"question": "What is the role of the Application and Deployment Group in a deployment process according to the text?", "answer": "The Application and Deployment Group are one-time setup tasks per application in the AWS CodeDeploiy process. The Application refers to the collection of Amazon Elastic Container Service (EC2) containers, Amazon EC2 instances, or Lambda functions that make up an application. A Deployment Group is a collection of Amazon EC2 instances, Lambda functions, or IP addresses that AWS CodeDeploy can deploy a revision to.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-11T14:45:20.989723"}}
{"question": "What are the steps for deploying a revision using AWS CodeDeploy from a GitHub repository?", "answer": "To deploy a revision using AWS CodeDeploy from a GitHub repository, first ensure that the post-build artifacts are present in the GitHub repository. Then, the revision in a .zip, .tar, or .tar.gz format can be deployed directly to instances from the repository. No need to bundle and upload the revision to an Amazon S3 bucket.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-11T14:45:20.990047"}}
{"question": "Which configuration management tools can be invoked from the AppSpec file in AWS CodeDeploy and how?", "answer": "There are several configuration management systems, such as Chef, Puppet, Ansible, and Saltstack, that can be invoked from the AppSpec file in AWS CodeDeploy. This can be done by specifying the configuration management tool's recipes or scripts in the appropriate deployment lifecycle event hook in the AppSpec file.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-4", "source_tokens": 472, "generated_at": "2026-02-11T14:45:20.990529"}}
{"question": "What happens when you integrate AWS CodeDeploy with continuous integration and deployment systems?", "answer": "You can call the public APIs using AWS CLI or AWS SDKs to integrate AWS CodeDeploy with continuous integration and deployment systems.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-11T14:45:27.119816"}}
{"question": "Why is it necessary to associate an Auto Scaling group with a deployment group in AWS CodeDeploy?", "answer": "This ensures that newly launched instances always get the latest version of your application. When a new Amazon EC2 instance is launched for the Auto Scaling group, it first enters a Pending state, and a deployment of the last successful revision for that deployment group is triggered. If the deployment completes successfully, the state of the Amazon EC2 instance is changed to InService. If the deployment fails, the Amazon EC2 instance is terminated, and a new Amazon EC2 instance is launched in Pending state, with a deployment triggered for the newly launched EC2 instance.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-11T14:45:27.120142"}}
{"question": "How does the status of a deployment in AWS CodeDeploy compare to the status of an Amazon EC2 instance in an Auto Scaling group?", "answer": "The status of a deployment in AWS CodeDeploy indicates the overall status of the deployment process, while the status of an Amazon EC2 instance in an Auto Scaling group shows the current state of the instance in relation to the deployment. When an instance is launched as part of an Auto Scaling group, it first enters a Pending state, then enters the InService state if the deployment is successful.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-5", "source_tokens": 444, "generated_at": "2026-02-11T14:45:27.120620"}}
{"question": "What should be done to roll back an application to a previous revision in AWS CodeDeploy?", "answer": "To roll back an application to a previous revision in AWS CodeDeploy, you need to deploy that revision. AWS CodeDeploy keeps track of the files that were copied for the current revision and removes them before starting a new deployment. However, you need to make sure that the previous revisions are available for roll back. You can use a versioned Amazon S3 bucket and specify the version ID to uniquely identify a revision.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:45:34.933944"}}
{"question": "How do notifications work when there are events impacting your deployments in AWS CodeDeploy?", "answer": "You can create notifications for events impacting your deployments in AWS CodeDeploy. Notifications will come in the form of Amazon SNS notifications. Each notification will include a status message as well as a link to the resources whose event generated that notification. There is no additional cost for notifications, but you may be charged for other AWS services utilized by notifications, such as Amazon SNS. To get started with notifications, see the notifications user guide. Customers using AWS Chatbot can also configure notifications to be sent to their Slack Channels or Amazon Chime chat rooms.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:45:34.934272"}}
{"question": "What's the difference between deploying and rolling back an application in AWS CodeDeploy in terms of accessing previous revisions?", "answer": "In AWS CodeDeploy, there is no difference between deploying and rolling back an application in terms of accessing previous revisions. To roll back, you simply deploy the previous revision. However, you need to ensure that the previous revisions are available for roll back, which can be achieved by using a versioned Amazon S3 bucket and specifying the version ID.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:45:34.934473"}}
{"question": "What is required to deploy an application to multiple AWS regions using CodeDeploy?", "answer": "Define the application in your target regions, copy the application bundle to an Amazon S3 bucket in each region, and start the deployments using either a serial or parallel rollout across the regions.", "question_type": "conceptual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-11T14:45:39.272558"}}
{"question": "Why is there no additional charge for deployments to AWS EC2 instances through CodeDepoy?", "answer": "There is no additional charge for deployments to AWS EC2 instances through CodeDeploy.", "question_type": "factual", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-11T14:45:39.272794"}}
{"question": "How does the cost of on-premises instance updates with CodeDeploy compare to regular on-premises instance updates?", "answer": "The cost for on-premises instance updates using CodeDeploy is $0.02 per update, compared to regular on-premises instance updates for which the cost is not specified in the context.", "question_type": "comparison", "metadata": {"service": "CODEDEPLOY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codedeploy-faq-7", "source_tokens": 122, "generated_at": "2026-02-11T14:45:39.272935"}}
{"question": "Which components does AWS CodeGuru consist of?", "answer": "AWS CodeGuru has two components: Amazon CodeGuru Security and Amazon CodeGuru Profiler.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-11T14:45:42.912678"}}
{"question": "How does Amazon CodeGuru Security work?", "answer": "Amazon CodeGuru Security is an ML and program analysis-based code scanning tool that finds security vulnerabilities in application code.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-11T14:45:42.912985"}}
{"question": "What programming languages does CodeGuru Security support for code scanning?", "answer": "CodeGuru Security currently supports scanning for Java, Python, JavaScript, TypeScript, C#, CloudFormation, Terraform, Go, and Ruby.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-0", "source_tokens": 416, "generated_at": "2026-02-11T14:45:42.913171"}}
{"question": "What type of access does CodeGuru Security require for your code?", "answer": "CodeGuru Security requires read-only access to your code for the purpose of generating recommendations.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T14:45:47.658617"}}
{"question": "How does CodeGuru Security train its models to detect security issues?", "answer": "CodeGuru Security uses a combination of logistic regression and neural networks, which are trained using rule mining and supervised ML models. It performs a full code analysis for all code paths that use a resource or sensitive data and creates a feature set representing those for training.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T14:45:47.658944"}}
{"question": "What is the difference between CodeGuru Profiler and CodeGuru Security?", "answer": "CodeGuru Profiler helps developers understand the runtime behavior of their applications, improve performance, and decrease infrastructure costs. It analyzes the application runtime profile and provides intelligent recommendations and visualizations. CodeGuru Security, on the other hand, needs read-only access to your code for the purpose of generating security recommendations.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T14:45:47.659157"}}
{"question": "What are some scenarios where logging execution time is not effective for monitoring application performance?", "answer": "Logging execution time only works for a limited set of scenarios because it can only monitor latency (not CPU utilization) and is time-consuming to implement. Developers have to log every function in an application without impacting application performance.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-11T14:45:52.958760"}}
{"question": "In what ways does Amazon CodeGru Profiler differ from traditional Application Performance Management (APM) systems?", "answer": "Amazon CodeGuru Profiler complements traditional APM capabilities by providing visualizations of the applicationâ€™s runtime data, actionable recommendations for performance issues, and machine learning to detect and alert on anomalies. It also runs continuously in production without impacting the application and can profile on-premises resources.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-11T14:45:52.959091"}}
{"question": "How does Amazon CodeGuru Profiler compare to profilers that only run in test environments?", "answer": "Amazon CodeGuru Profiler can profile applications in production, under production traffic loads, and without impacting the application, while some standalone profilers are designed to only run in test environments.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-2", "source_tokens": 439, "generated_at": "2026-02-11T14:45:52.959288"}}
{"question": "What resources does Amazon CodeGuru Profiler's agent utilize when running in an AWS Lambda function?", "answer": "Amazon CodeGuru Profiler's agent uses the resources (CPU, memory) allocated to AWS Lambda functions.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T14:45:57.354583"}}
{"question": "How does the intelligent recommendation feature of Amazon CodeGuru Profiler work?", "answer": "Amazon CodeGuru Profiler uses machine learning to continuously analyze application runtime data and proactively alerts you with intelligent recommendations when performance issues are discovered.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T14:45:57.354805"}}
{"question": "What resources does Amazon CodeGuru Profiler profile for Java and other JVM languages compared to Python applications?", "answer": "Amazon CodeGuru Profiler profiles CPU (active CPU and wall clock time) and memory (heap summary) for Java and other JVM languages, and CPU (wall clock time) for Python applications.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T14:45:57.354938"}}
{"question": "In what two scenarios can using the Heap summary be beneficial?", "answer": "The Heap summary can be beneficial in two scenarios: identifying potential memory leaks and optimizing the memory footprint of an application.", "question_type": "factual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-11T14:46:02.461348"}}
{"question": "How can the Heap summary help in identifying memory leaks?", "answer": "The Heap summary can help identify memory leaks by showing a constantly growing memory utilization curve for one or more object types, which may indicate a leak and lead to out-of-memory errors and application crashes.", "question_type": "conceptual", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-11T14:46:02.461675"}}
{"question": "What is the difference between the use of Heap summary for identifying memory leaks and optimizing memory footprint?", "answer": "Using Heap summary for identifying memory leaks involves looking for a consistently growing memory utilization curve for one or more object types, which may indicate a leak. On the other hand, using Heap summary for optimizing memory footprint involves analyzing the breakdown of memory utilization per object type to focus optimization efforts on the parts of the application that are responsible for allocating and referencing objects of that type.", "question_type": "comparison", "metadata": {"service": "CODEGURU", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codeguru-faq-4", "source_tokens": 141, "generated_at": "2026-02-11T14:46:02.462179"}}
{"question": "What is AWS CodePipeline and what does it help you do?", "answer": "AWS CodePipeline is a continuous delivery service that automates the steps required to release software. It models, visualizes, and automates the full release process for building, testing, and deploying code. It ensures that all new changes go through consistent quality checks, increasing the speed and quality of software updates.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-11T14:46:07.000476"}}
{"question": "What is the definition of a stage in AWS CodePipeline?", "answer": "A stage in AWS CodePipeline is a group of one or more actions. It represents a logical step in the release process.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-11T14:46:07.000745"}}
{"question": "What is the difference between a stage and an action in AWS CodePipeline?", "answer": "A stage is a group of one or more actions, while an action is a single task performed on a revision. Stages represent logical steps in the release process, and actions represent tasks within those steps.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-0", "source_tokens": 437, "generated_at": "2026-02-11T14:46:07.000885"}}
{"question": "What are artifacts in AWS CodePipeline?", "answer": "Artifacts are files or sets of files that are acted upon by actions in AWS CodePipeline.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T14:46:11.188715"}}
{"question": "How does the transition of revisions through stages work in AWS CodePipeline?", "answer": "Revisions that successfully complete the actions in a stage are automatically sent on to the next stage through a transition represented by an arrow in the AWS CodePipeline console. Transitions can be disabled or enabled.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T14:46:11.189059"}}
{"question": "How does the parallel execution of actions in a stage compare to the sequential execution in AWS CodePipeline?", "answer": "In AWS CodePipeline, you can configure one or more actions to run in parallel for any given stage, whereas the execution of actions in different stages is always sequential due to the connection of stages by transitions.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T14:46:11.189263"}}
{"question": "What service does AWS CodePipeline use to create change sets and deploy serverless applications?", "answer": "AWS CloudFormation", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-11T14:46:15.582572"}}
{"question": "How can continuous delivery be implemented in AWS CloudFormation using AWS CodePipeline?", "answer": "AWS CodePipeline and AWS CloudFormation can be used together to automatically build and test changes to AWS CloudFormation stacks before promoting them to production stacks, allowing for rapid and reliable changes to AWS infrastructure.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-11T14:46:15.582896"}}
{"question": "What services can AWS CodePipeline integrate with besides AWS CloudFormation and AWS CodeCommit?", "answer": "AWS CodePipeline integrates with services such as AWS CodeBuild, AWS CodeDeploy, AWS Elastic Beanstalk, AWS OpsWorks, Amazon ECS, and AWS Lambda, as well as a number of partner tools. Custom actions can also be written and integrated.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-2", "source_tokens": 403, "generated_at": "2026-02-11T14:46:15.583428"}}
{"question": "What type of notifications do you receive for pipeline events in AWS?", "answer": "You receive Amazon SNS notifications for pipeline events, which include a status message and a link to the related resources.", "question_type": "factual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:46:19.835570"}}
{"question": "How can you configure notifications for your AWS CodePipeline in different communication channels?", "answer": "Customers using AWS Chatbot can configure notifications to be sent to their Slack Channels or Amazon Chime chat rooms.", "question_type": "conceptual", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:46:19.835856"}}
{"question": "What is the difference between setting resource-level permissions within an AWS CodePipeline and delegating access across AWS accounts?", "answer": "Resource-level permissions enable you to specify which user can perform what action on a pipeline or any stage or action within a pipeline. Delegating access across AWS accounts allows an IAM user in another account to access the pipeline and related resources.", "question_type": "comparison", "metadata": {"service": "CODEPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "codepipeline-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:46:19.836283"}}
{"question": "What is the primary function of Amazon Cognito mentioned in the text?", "answer": "Amazon Cognito lets you add user sign-up, sign-in, access control, and brokered AWS service access to your web and mobile applications.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-11T14:46:24.272831"}}
{"question": "How does Amazon Cognito improve application development process according to the text?", "answer": "Amazon Cognito helps you focus on creating great app experiences instead of worrying about building, securing, and scaling a solution to handle user management and authentication.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-11T14:46:24.273191"}}
{"question": "What are the two types of pools mentioned in the text and how do they differ in terms of functionality?", "answer": "Cognito user pools are for user management and authentication (separate API operations for server-side and client-side applications), while identity pools are for federated identities.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-0", "source_tokens": 461, "generated_at": "2026-02-11T14:46:24.273601"}}
{"question": "What SDKs support Amazon Cognito?", "answer": "The optional AWS Mobile SDK is available for iOS, Android, Unity, and Kindle Fire. Cognito is also available in the AWS SDK for .NET, C++, Go, Java, JavaScript, PHP v3, Python, Ruby v3, and the command line interface.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T14:46:30.846351"}}
{"question": "How can you use Amazon Cognito for authentication in your apps?", "answer": "Amazon Cognito enables you to easily and securely add sign-up and sign-in functionality to your apps. Your users can sign-up and sign-in using email, phone number, or user name. You can also implement enhanced security features, such as email verification, phone number verification, and multi-factor authentication. Developers can customize workflows by adding application-specific logic to user registration through AWS Lambda.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T14:46:30.846673"}}
{"question": "What are the differences between first-factor and multi-factor authenticators supported by Amazon Cognito?", "answer": "Amazon Cognito supports first-factor authenticators like username/password, email OTP passwordless, SMS OTP passwordless, and WebAuthn passkeys. For multi-factor authenticators, it supports email OTP, SMS OTP, and TOTP authenticators. Developers and partners can also implement support for third party products and bespoke authenticators with custom authentication flows using AWS Lambda extensions.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T14:46:30.847197"}}
{"question": "What email and phone verification options does Amazon Cognito provide?", "answer": "Amazon Cognito allows users to verify their email addresses and phone numbers during sign-up to provide access to your application. A verification code is sent to the userâ€™s phone number or email address, and they must input the verification code to complete sign-up and become confirmed.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-11T14:46:36.049439"}}
{"question": "Why is email and phone number verification important in Amazon Cognito?", "answer": "Email and phone number verification are important security measures in Amazon Cognito to ensure the security of your application and its users. By requiring verification, you can prevent unauthorized access and ensure that only confirmed users can access your application.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-11T14:46:36.049673"}}
{"question": "How does Amazon Cognito compare custom sign-up and sign-in flows using AWS Lambda to traditional methods?", "answer": "Amazon Cognito allows you to customize sign-up and sign-in flows using AWS Lambda, enabling you to perform additional validations on user data and identify fraud. This approach contrasts with traditional methods where these functionalities are not available.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-2", "source_tokens": 372, "generated_at": "2026-02-11T14:46:36.050038"}}
{"question": "How can I migrate users from my application's existing user directory or database to Amazon Cognito user pools?", "answer": "You can migrate users to Amazon Cognito user pools using just-in-time (JIT) migration or bulk migration.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T14:46:40.656647"}}
{"question": "What happens during a just-in-time migration to Amazon Cognito user pools?", "answer": "During a just-in-time migration, users are migrated to Amazon Cognito as they sign in to your application using a built-in AWS Lambda trigger.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T14:46:40.656971"}}
{"question": "How does bulk migration to Amazon Cognito user pools differ from just-in-time migration?", "answer": "During bulk migration, you upload a CSV file containing the profile data for all your application users, while during just-in-time migration, users are migrated as they sign in.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T14:46:40.657421"}}
{"question": "What is the role of an Identity Provider (IdP) in the authentication process with Cognito Identity Pools?", "answer": "An Identity Provider (IdP) authenticates the end user and returns an OpenID Connect token or a SAML assertion. This token or assertion is then passed to the Cognito Identity Pool, which returns a new Cognito ID and a set of temporary AWS credentials.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-11T14:46:47.286270"}}
{"question": "How does Cognito Identity Pools control access to AWS resources for each user?", "answer": "Cognito Identity Pools assigns users a set of temporary, limited privilege credentials to access AWS resources. The permissions for each user are controlled through AWS IAM roles created by the user. Rules can be defined to choose the IAM role for each user or, if using groups in a Cognito user pool, IAM roles can be assigned based on groups.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-11T14:46:47.286551"}}
{"question": "What is the difference in authentication flow between Cognito Identity and a traditional authentication system using Cognito Identity Pools?", "answer": "In a traditional authentication system, the app communicates directly with the app to authenticate users and retrieve Cognito IDs and OpenID Tokens. With Cognito Identity Pools, the app communicates directly with the supported public identity provider to autauthenticate users. Cognito Identity uses the token from the identity provider to obtain a unique identifier for the user, which is then used to access AWS resources.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-4", "source_tokens": 487, "generated_at": "2026-02-11T14:46:47.286968"}}
{"question": "What happens when an unauthenticated user accesses your app using Cognito identity pools?", "answer": "Cognito identity pools create a new identity for an unauthenticated user each time they call the GetId API. It is important to cache the response to avoid generating multiple identities for a single user.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:46:52.706468"}}
{"question": "How does Cognito identity pools handle authentication for guests or unauthenticated users?", "answer": "Cognito identity pools allow access for unauthenticated users without requiring them to authenticate with an identity provider. You can define a separate IAM role for these users to provide limited permissions to access your backend resources.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:46:52.706798"}}
{"question": "What is the difference between handling authenticated and unauthenticated users in Cognito identity pools?", "answer": "For authenticated users, each call to Cognito identity poolsâ€™ GetId API creates a single identity. For unauthenticated users, each call generates a new identity. It is essential to cache the response from GetId for unauthenticated users to avoid creating multiple identities per user.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T14:46:52.706959"}}
{"question": "How many monthly active users (MAUs) trigger a charge for Amazon Cognito user pools?", "answer": "Amazon Cognito user pools are charged based on the number of monthly active users (MAUs). A user is counted as a MAU if your app generates an identity operation for that user within a calendar month.", "question_type": "factual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-11T14:46:57.549637"}}
{"question": "Why is SMS messaging in Amazon Cognito charged separately?", "answer": "SMS messaging in Amazon Cognito is charged separately because it is an additional feature, and the pricing for this feature can be found on the Worldwide SMS Pricing page.", "question_type": "conceptual", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-11T14:46:57.549926"}}
{"question": "How does the charging structure for Amazon Cognito user pools compare to Amazon Cognito identity pools?", "answer": "Amazon Cognito user pools and identity pools differ in their charging structures. User pools are charged based on the number of monthly active users, while identity pools are provided at no additional charge.", "question_type": "comparison", "metadata": {"service": "COGNITO", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cognito-faq-6", "source_tokens": 386, "generated_at": "2026-02-11T14:46:57.550303"}}
{"question": "What is the main functionality of Amazon Comprehend?", "answer": "Amazon Comprehend is a natural language processing (NLP) service that uses machine learning to find meaning and insights in text. It can identify the language of the text, extract key phrases, places, people, brands, or events, understand sentiment about products or services, and identify the main topics from a library of documents.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T14:47:02.367144"}}
{"question": "How does Amazon Comprehend help in analyzing customer feedback?", "answer": "Amazon Comprehend helps in analyzing customer feedback by gauging the sentiment of the feedback as positive, neutral, negative, or mixed.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T14:47:02.367418"}}
{"question": "What is the difference between Amazon Comprehend and a traditional search engine?", "answer": "Amazon Comprehend and a traditional search engine differ in that Amazon Comprehend enables focusing the search on the intent and the context of the articles instead of basic keywords by indexing key phrases, entities, and sentiment.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T14:47:02.367568"}}
{"question": "Which security connection does Amazon Comprehend use for API and console requests?", "answer": "Amazon Comprehend uses a secure (SSL) connection for API and console requests.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-11T14:47:06.973057"}}
{"question": "What are the benefits of using Amazon Comprehend for text analysis?", "answer": "Amazon Comprehend is a fully managed and continuously trained service that allows you to analyze text without requiring NLP expertise or managing the scaling of resources. It uses machine learning and offers features like text understanding, entity recognition, and sentiment analysis.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-11T14:47:06.973325"}}
{"question": "How does the performance and confidence scoring of Amazon Comprehend compare to other text analysis services?", "answer": "Amazon Comprehend returns confidence scores for each result, indicating the service's confidence in the accuracy of the information extracted. However, specific performance comparisons and confidence scoring between Amazon Comprehend and other text analysis services are not provided in the text.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-1", "source_tokens": 399, "generated_at": "2026-02-11T14:47:06.973774"}}
{"question": "What is the purpose of storing and using text inputs processed by Amazon Comprehend?", "answer": "Amazon Comprehend may store and use text inputs processed by the service solely to provide and maintain the service, develop and improve the quality of Amazon Comprehend and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:47:11.693575"}}
{"question": "How does Amazon ensure the security and privacy of content processed by Comprehend?", "answer": "Amazon implements technical and physical controls including encryption at rest and in transit, and restricts access to authorized employees to ensure the security and privacy of content processed by Comprehend.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:47:11.693924"}}
{"question": "What is the difference in data handling between Amazon Comprehend and Amazon Comprehend Medical and Amazon Comprehend Detect PII?", "answer": "Amazon Comprehend may use content for continuous improvement of the service, while Amazon Comprehend Medical and Amazon Comprehend Detect PII do not apply to this use.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-2", "source_tokens": 398, "generated_at": "2026-02-11T14:47:11.694422"}}
{"question": "In which AWS regions is content processed by Amazon Comprehend encrypted and stored at rest?", "answer": "Content processed by Amazon Comprehend is encrypted and stored at rest in the AWS region where Amazon Comprehend is being used.", "question_type": "factual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-11T14:47:16.152323"}}
{"question": "Why is a portion of content processed by Amazon Comprehend stored in another AWS region?", "answer": "A portion of content processed by Amazon Comprehend may be stored in another AWS region in connection with the continuous improvement and development of Amazon Comprehend and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-11T14:47:16.152589"}}
{"question": "How does the storage of content processed by Amazon Comprehend in another AWS region compare to Amazon Comprehend Medical?", "answer": "The text passage does not provide enough information to make a comparison between the storage of content processed by Amazon Comprehend in another AWS region and Amazon Comprehend Medical.", "question_type": "comparison", "metadata": {"service": "COMPREHEND", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "comprehend-faq-3", "source_tokens": 338, "generated_at": "2026-02-11T14:47:16.152863"}}
{"question": "What type of AWS resources does AWS Compute Optimizer help identify the optimal configurations for?", "answer": "AWS Compute Optimizer helps identify the optimal configurations for various AWS resources including Amazon Elastic Compute Cloud (EC2) instance types, Amazon Elastic Block Store (EBS) volume configurations, task sizes of Amazon Elastic Container Service (ECS) services on AWS Fargate, commercial software licenses, AWS Lambda function memory sizes, and Amazon Relational Database Service (RDS) DB instance classes.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-11T14:47:22.878942"}}
{"question": "How does AWS Compute Optimizer help users reduce costs and improve workload performance?", "answer": "AWS Compute Optimizer helps users reduce costs and improve workload performance by delivering intuitive and easily actionable recommendations for the optimal configurations of various AWS resources such as Amazon Elastic Compute Cloud (EC2) instances, Amazon Elastic Block Store (EBS) volumes, Amazon Elastic Container Service (ECS) services on AWS Fargate, commercial software licenses, AWS Lambda functions, and Amazon Relational Database Service (RDS) DB instances.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-11T14:47:22.879189"}}
{"question": "How does the licensing optimization recommendation feature of AWS Compute Optimizer compare to the EC2 instance recommendation feature?", "answer": "The licensing optimization recommendation feature of AWS Compute Optimizer helps identify the optimal configurations for commercial software licenses, while the EC2 instance recommendation feature helps identify the optimal configurations for EC2 instances. Both features are designed to help users reduce costs and improve performance by optimizing their AWS resources.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-0", "source_tokens": 430, "generated_at": "2026-02-11T14:47:22.879353"}}
{"question": "What data does AWS Compute Optimizer require to make recommendations?", "answer": "AWS Compute Optimizer requires AWS resource configuration data, CloudWatch metrics, and Amazon RDS Performance Insights data to make recommendations.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T14:47:27.351563"}}
{"question": "What are the benefits of using AWS Compute Optimizer for engineering teams?", "answer": "Engineering teams can use Compute Optimizer to evaluate price-performance trade-offs for their workloads, receive recommendations that incorporate additional data such as memory metrics, and evaluate projected resource utilization and performance risk.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T14:47:27.351826"}}
{"question": "How does AWS Compute Optimizer differ from Cost Explorer in terms of recommendations?", "answer": "Compute Optimizer delivers all recommendations regardless of cost implications, while Cost Explorer surfaces a subset of recommendations that may lead to cost savings and augments them with customer-specific cost and savings information.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T14:47:27.352189"}}
{"question": "What setting determines if AWS Compute Optimizer considers your discounts when estimating savings?", "answer": "Savings Estimation Mode", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-11T14:47:31.301535"}}
{"question": "How does AWS Compute Optimizer determine the inferred workload type for a given resource?", "answer": "AWS Compute Optimizer infers the types of applications running on your instances by analyzing the attributes of your resources such as resource names, tags, utilization characteristics, and configuration.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-11T14:47:31.301860"}}
{"question": "Which instance types will AWS Compute Optimizer recommend based on your rightsizing preferences?", "answer": "AWS Compute Optimizer will only recommend instance types that are on your customizable list of EC2 instance types for EC2 instance and EC2 Auto Scaling group recommendations.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-2", "source_tokens": 396, "generated_at": "2026-02-11T14:47:31.302365"}}
{"question": "What percentage of time should your workload run under the utilization headroom according to AWS Compute Optimizer for normal usage?", "answer": "AWS Compute Optimizer suggests setting utilization thresholds based on the percentage of time your workload should run under your utilization headroom. For most workloads, the threshold represents the percentage of time your workload should run under headroom.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-11T14:47:36.762647"}}
{"question": "Why might decreasing the utilization threshold in AWS Compute Optimizer lead to more savings?", "answer": "Decreasing the utilization threshold can lead to more savings because Compute Optimizer may recommend rightsizing that is less sensitive to spikes, which can result in more efficient utilization and lower costs.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-11T14:47:36.762979"}}
{"question": "What are the benefits of defining a preferred instance list in AWS Compute Optimizer?", "answer": "Defining a preferred instance list in AWS Compute Optimizer allows you to control which instance types and families you want Compute Optimizer to recommend. This feature is useful when you have specific rightsizing criteria based on instances, burstable instances, or other factors, and you want to configure the recommendation outcomes to align with your criteria.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-3", "source_tokens": 429, "generated_at": "2026-02-11T14:47:36.763504"}}
{"question": "What resource types does AWS Compute Optimizer deliver recommendations for?", "answer": "AWS Compute Optimizer delivers recommendations for Amazon Elastic Compute Cloud (EC2) instances, EC2 Auto Scaling groups, Elastic Block Store (EBS) volumes, Amazon Elastic Container Service (ECS) services on AWS Fargate, Lambda functions, Relational Database Service (RDS) DB instances, and commercial software licenses.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T14:47:42.044556"}}
{"question": "How does AWS Compute Optimizer generate resource recommendations for RDS DB instances?", "answer": "AWS Compute Optimizer generates resource recommendations for RDS DB instances by analyzing metrics from the past 14 days.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T14:47:42.044884"}}
{"question": "What's the difference between savings opportunity and performance improvement opportunity metrics in AWS Compute Optimizer?", "answer": "Savings opportunity metrics quantify the monthly savings you can achieve by adopting AWS Compute Optimizer recommendations for resource efficiency and cost optimization. Performance improvement opportunity metrics quantify the percentage and number of underprovisioned resources at various levels, helping you identify and prioritize performance improvement opportunities.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T14:47:42.045388"}}
{"question": "What historic utilization data does Enhanced infrastructure metrics provide for EC2 and RDS instances?", "answer": "Enhanced infrastructure metrics provides up to six times more utilization metrics history than the default Compute Optimizer option, which is up to three months compared to 14 days.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T14:47:47.184788"}}
{"question": "How does AWS Compute Optimizer determine whether SQL Server instances are optimized?", "answer": "AWS Compute Optimizer determines whether SQL Server instances are optimized by analyzing current configurations such as SQL Server edition, licensing options, and specific database level features. Based on the analysis, it generates recommendations to optimize instances.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T14:47:47.184997"}}
{"question": "What are the benefits of using AWS Compute Optimizer for SQL Server instances compared to the standard edition?", "answer": "AWS Compute Optimizer can help you save up to 73% of SQL Server license cost by generating recommendations to downgrade from Enterprise to Standard edition. Additionally, it offers EC2 instances rightsizing recommendations to help reduce SQL Server license cost by recommending instances with fewer vCPUs.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T14:47:47.185171"}}
{"question": "What metrics does AWS Compute Optimizer analyze for EC2 instances?", "answer": "AWS Compute Optimizer analyzes default CloudWatch metrics such as CPU utilization, network packets per second, local storage throughput, local storage IOPS, and memory utilization (when published by CloudWatch agent) for EC2 instances.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-11T14:47:52.863424"}}
{"question": "How does AWS Compute Optimizer determine performance risk?", "answer": "AWS Compute Optimizer determines performance risk by evaluating each resource specification of the recommended instance type, including CPU, memory, EBS throughput and IOPS, disk throughput and IOPS, and network throughput and PPS. It calculates the risk score as the proportion of time during the lookback period when capacity might be constrained and selects the highest risk score among all analyzed resource specifications as the overall performance risk.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-11T14:47:52.863758"}}
{"question": "How does the pricing information influence AWS Compute Optimizer's recommendations?", "answer": "AWS Compute Optimizer considers EC2 instance pricing information when delivering recommendations and incorporates a variety of pricing dimensions to calculate savings and rank the recommendations, including on-demand pricing and discounted pricing through Savings Plans or Reserved Instances.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-6", "source_tokens": 434, "generated_at": "2026-02-11T14:47:52.864203"}}
{"question": "Whatinstance types does AWS Compute Optimizer recommend for EC2 Auto Scaling groups without automatic scaling?", "answer": "AWS Compute Optimizer recommends appropriate EC2 instance types and sizes for workloads in EC2 Auto Scaling groups without automatic scaling.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:47:57.663896"}}
{"question": "How does AWS Compute Optimizer determine performance risk for recommended instance types?", "answer": "AWS Compute Optimizer calculates the proportion of time during the lookback period when capacity might be constrained for each resource specification of a recommended instance type, and selects the highest risk score as the overall performance risk.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:47:57.664207"}}
{"question": "What kind of recommendations does AWS Compute Optimizer provide for EC2 Auto Scaling groups with different instance types?", "answer": "For EC2 Auto Scaling groups with only one type of instance, AWS Compute Optimizer provides single-instance-type recommendations. For groups with multiple instance types, it provides mixed-instance-type recommendations.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:47:57.664390"}}
{"question": "What pricing dimensions does AWS Compute Optimizer consider for EC2 Auto Scaling groups?", "answer": "AWS Compute Optimizer considers on-demand pricing and discounted pricing through Savings Plans or Reserved Instances.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-11T14:48:02.326751"}}
{"question": "Why doesn't AWS Compute Optimizer consider transient pricing factors like spot pricing?", "answer": "AWS Compute Optimizer does not consider transient pricing factors, such as spot pricing, when delivering recommendations for EC2 Auto Scaling groups.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-11T14:48:02.327072"}}
{"question": "Which categories of Lambda functions does AWS Compute Optimizer help optimize and how?", "answer": "AWS Compute Optimizer helps optimize Lambda functions that may be overprovisioned in memory sizes by downsizing their memory sizes to save costs. It also helps optimize compute-intensive Lambda functions by increasing their memory sizes to trigger an equivalent increase in CPU available to these functions and reduce runtime.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-8", "source_tokens": 462, "generated_at": "2026-02-11T14:48:02.327539"}}
{"question": "What information does AWS Compute Optimizer consider when calculating the 'would-be' cost for Lambda functions?", "answer": "AWS Compute Optimizer uses public Lambda pricing, expected function runtime, and number of function invocations over the past 14 days to calculate a 'would-be' cost number for Lambda functions.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-11T14:48:07.862577"}}
{"question": "How does AWS Compute Optimizer determine idle workloads on Amazon ECS services for cost savings?", "answer": "AWS Compute Optimizer identifies idle workloads on Amazon ECS services where utilization is low for 14 days consecutively and provides recommendations to save cost by deleting, scaling down, turning off, or snapshotting and deleting the resources.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-11T14:48:07.862925"}}
{"question": "How does the cost calculation for Amazon ECS services on AWS Fargate differ from Lambda functions in AWS Compute Optimizer?", "answer": "For Amazon ECS services on AWS Fargate, AWS Compute Optimizer considers public AWS Fargate pricing, new CPU and memory configurations, and runtime history over the past 14 days to calculate a 'would-be' cost.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-9", "source_tokens": 494, "generated_at": "2026-02-11T14:48:07.863114"}}
{"question": "What metrics does AWS Compute Optimizer use to generate recommendations for RDS DB instances?", "answer": "AWS Compute Optimizer analyzes CloudWatch metrics such as CPU utilization, network utilization, and database connections, as well as Amazon RDS Performance Insights metrics, like DBLoad.", "question_type": "factual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-11T14:48:12.682850"}}
{"question": "How does AWS Compute Optimizer determine the optimal DB instance class for an RDS DB instance?", "answer": "AWS Compute Optimizer calculates performance risk scores for each resource dimension of the recommended instance, including CPU, EBS throughput, EBS IOPS, and network throughput. The instance with the lowest performance risk score across all analyzed resource specifications is recommended.", "question_type": "conceptual", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-11T14:48:12.683154"}}
{"question": "How does the performance risk calculation in AWS Compute Optimizer differ between different resource dimensions?", "answer": "The performance risk score for each resource dimension is computed as the proportion of time over the historical lookback period where capacity may be constrained in that specific resource dimension.", "question_type": "comparison", "metadata": {"service": "COMPUTE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "compute-faq-10", "source_tokens": 412, "generated_at": "2026-02-11T14:48:12.683343"}}
{"question": "What information does AWS Config provide about resource configuration changes?", "answer": "AWS Config provides full visibility into resource configuration changes, including who made the change, from what IP address, and the effect of the change on AWS resources and related resources.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:48:24.391200"}}
{"question": "Why is AWS Config beneficial for organizations aiming to improve their security and governance posture on AWS?", "answer": "AWS Config is beneficial for organizations looking to improve their security and governance posture on AWS as it allows them to continuously evaluate the configuration of their resources, assess compliance over a period, and generate reports for auditors.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:48:24.391651"}}
{"question": "What's the difference between using AWS Config rules and conformance packs for managing AWS resource configurations?", "answer": "AWS Config rules evaluate resource configurations against rules you specify, while conformance packs are used to build and deploy compliance packages for your AWS resource configurations across several accounts. Conformance packs can be used to assess compliance, generate reports, and configure remediation actions for non-compliant resources.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:48:24.391858"}}
{"question": "What is the role of AWS Config rules in recording resource configurations?", "answer": "AWS Config rules evaluate resource configurations only after a configuration change has been completed and recorded by AWS Config. They do not directly affect how end users consume AWS, but instead help in recording configurations for third-party resources or custom resource types.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-11T14:48:29.121757"}}
{"question": "How does AWS Config help in controlling what can be provisioned on AWS?", "answer": "To control what can be provisioned on AWS and the configuration parameters used during provisioning, AWS Config recommends using AWS Identity and Access Management (IAM) Policies and AWS Service Catalog.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-11T14:48:29.122083"}}
{"question": "What's the difference between proactive and detective modes for AWS Config rules?", "answer": "Proactive mode allows AWS Config to evaluate resource configurations before they are committed, while detective mode evaluates resource configurations after they have been committed. AWS Config rules can be set to proactive only, detective only, or both proactive and detective modes.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-2", "source_tokens": 346, "generated_at": "2026-02-11T14:48:29.122587"}}
{"question": "What information does AWS CloudTrail provide about API activity?", "answer": "AWS CloudTrail records user API activity on your account and provides full details about API actions including the identity of the caller, the time of the API call, request parameters, and response elements.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-11T14:48:33.626648"}}
{"question": "How does AWS Config help in answering questions about AWS resources?", "answer": "AWS Config records point-in-time configuration details for AWS resources as Configuration Items (CIs). This enables you to answer questions about the state of your resources at a specific point in time.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-11T14:48:33.626917"}}
{"question": "What is the difference between AWS CloudTrail and AWS Config in terms of monitoring AWS resources?", "answer": "AWS CloudTrail records user API activity and provides details about who made API calls to modify resources. AWS Config records the configuration details of resources and answers questions about the state of resources at a specific point in time.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-3", "source_tokens": 259, "generated_at": "2026-02-11T14:48:33.627111"}}
{"question": "In which marketplaces can I find the AWS Service Management Connector for ServiceNow and Jira Service Desk?", "answer": "The AWS Service Management Connector for ServiceNow is available in the ServiceNow Store, and the AWS Service Management Connector for Jira Service Desk is available in the Atlassian Marketplace.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-11T14:48:38.373888"}}
{"question": "How does the AWS Service Management Connector simplify AWS product management for ServiceNow and Jira Service Desk users?", "answer": "The AWS Service Management Connector allows ServiceNow and Jira Service Desk end users to provision, manage, and operate AWS resources natively using their respective platforms. This simplifies AWS product request actions and provides administrators with governance and oversight.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-11T14:48:38.374282"}}
{"question": "Which AWS regions support the use of both connectors for ServiceNow and Jira Service Desk?", "answer": "Both connectors are generally available in all AWS Regions where AWS Service Catalog is available.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-4", "source_tokens": 470, "generated_at": "2026-02-11T14:48:38.374777"}}
{"question": "What time is recorded for each Configuration Item in AWS Config?", "answer": "The time recorded for each Configuration Item in AWS Config is the time at which the configuration was recorded for a resource.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T14:48:42.043964"}}
{"question": "How does AWS Config represent relationships among resources in Configuration Items?", "answer": "AWS Config records changes to a resource's configuration and takes relationships among resources into account when recording changes. If a new EC2 Security Group is associated with an EC2 Instance, AWS Config records the updated configurations of both the primary resource, the EC2 Security Group, and related resources, if these resources changed.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T14:48:42.044258"}}
{"question": "What information is included in a Configuration Item's Map of relationships?", "answer": "A Configuration Item's Map of relationships includes information about the relationships between a resource and other resources.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T14:48:42.044662"}}
{"question": "What is the period for periodic recording of configuration changes in AWS Config?", "answer": "AWS Config delivers the latest configuration of a resource at the end of a 24-hour period if it has changed.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-11T14:48:46.298679"}}
{"question": "Why might you choose to use periodic recording over continuous recording in AWS Config?", "answer": "Periodic recording allows you to decide how often to receive updates on your resource configurations, making the cost of gathering configuration data more predictable for use cases such as operational planning and audit.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-11T14:48:46.299002"}}
{"question": "How does periodic recording in AWS Config compare to continuous recording in terms of sending notifications?", "answer": "AWS Config sends notifications only when the compliance status changes for continuous recording. However, for periodic recording, AWS Config sends notifications when the compliance status changes to â€˜compliantâ€™.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-6", "source_tokens": 487, "generated_at": "2026-02-11T14:48:46.299490"}}
{"question": "What type of information does AWS Config use to evaluate resource compliance?", "answer": "AWS Config uses the Configuration Item (CI) for a resource, along with any other relevant information such as other attached resources and business hours, to evaluate resource compliance.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-11T14:48:52.389912"}}
{"question": "What are AWS Config rules and how do they differ in management and application?", "answer": "AWS Config rules represent desired Configuration Item (CI) attribute values for resources and are managed and applied differently. AWSâ€“managed rules are preâ€“built and managed by AWS, while customer managed rules are custom rules, defined and built by customers. With AWSâ€“managed rules, updates to the rule are automatically applied to any account using that rule, but with customer managed rules, customers have a full copy of the rule and apply it within their own account.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-11T14:48:52.390239"}}
{"question": "How does the number of rules in an AWS account compare between AWSâ€“managed and customer managed?", "answer": "By default, you can create up to 150 rules in your AWS account. However, the management and application of these rules differ. With AWSâ€“managed rules, the limit of 150 applies to all accounts using that rule, while with customer managed rules, each account has a full copy of the rule and applies it within their own account, so the effective limit depends on the number of accounts using the rule.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-7", "source_tokens": 398, "generated_at": "2026-02-11T14:48:52.390762"}}
{"question": "What triggers an evaluation for a change-triggered rule in AWS Config?", "answer": "A change-triggered rule in AWS Config is evaluated when AWS Config records a configuration change for any of the resources specified in the rule.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-11T14:48:56.702553"}}
{"question": "How does AWS Config determine the compliance status of a rule?", "answer": "AWS Config determines the compliance status of a rule by evaluating the rule against the configuration of a resource. A rule is compliant if all resources evaluated by the rule comply with the rule.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-11T14:48:56.702931"}}
{"question": "What is the difference between a change-triggered rule and a periodic rule in AWS Config?", "answer": "A change-triggered rule is applied when AWS Config records a configuration change for any of the resources specified in the rule. A periodic rule, on the other hand, is initiated at a specified frequency.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-8", "source_tokens": 394, "generated_at": "2026-02-11T14:48:56.703339"}}
{"question": "What information does the AWS Config rules dashboard provide about resources and compliance?", "answer": "The AWS Config rules dashboard provides an overview of resources tracked by AWS Config and a summary of current compliance by resource and by rule. It allows users to determine if any rule that applies to a resource is currently non-compliant, and to view compliance by rule to see if any resource under the rule's purview is non-compliant. It also enables users to explore the AWS Config timeline view of resources to determine which configuration parameters changed.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-11T14:49:03.304942"}}
{"question": "How does using conformance packs simplify compliance management in AWS Config?", "answer": "Conformance packs simplify compliance management in AWS Config by allowing users to package rules along with remediation actions into a single entity that can be deployed across an entire organization with a single selection. They provide aggregated compliance reporting at the pack level and immutability, ensuring that managed AWS Config rules and remediation documents within the conformance pack are not modified or deleted by individual member accounts.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-11T14:49:03.305220"}}
{"question": "What is the difference between using AWS Config rules through AWS Security Hub CSPM and using them directly?", "answer": "Both AWS Security Hub CSPM and AWS Config rules are used to evaluate the configuration of AWS resources, but the primary difference lies in how they are used. AWS Security Hub CSPM is a security and compliance service that provides security and compliance posture management as a service and uses AWS Config rules as its primary mechanism. In contrast, AWS Config rules can also be used directly to evaluate resource configuration without the need for a separate service.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-9", "source_tokens": 361, "generated_at": "2026-02-11T14:49:03.305374"}}
{"question": "Which AWS service makes it easier to operationalize existing compliance standards in AWS Security Hub CSE?", "answer": "AWS Security Hub CSPM", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T14:49:08.422519"}}
{"question": "How can you create and customize AWS Config conformance packs for your organization's compliance needs?", "answer": "You can create a conformance pack using one of the provided sample templates through the CLI or the AWS Config console. These templates can be modified to suit your environment and even include custom AWS Config rules.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T14:49:08.422852"}}
{"question": "In what ways do AWS Security Hub CSPM and AWS Config conformance packs differ in terms of monitoring and reporting compliance?", "answer": "AWS Security Hub CSPM is an easier way to operationalize existing compliance standards, allowing users to investigate findings and build automated remediation actions through integrations with Amazon Detective and Amazon EventBridge. On the other hand, AWS Config conformance packs simplify management of AWS Config rules and enable aggregated reporting by packaging a group of AWS Config rules and associated remediation actions into a single entity.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T14:49:08.423343"}}
{"question": "What is the purpose of the data aggregation capability in AWS Config?", "answer": "The data aggregation capability in AWS Config is a reporting feature that provides visibility into the compliance of multiple accounts and Regions. It cannot be used for provisioning rules across multiple accounts.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-11T14:49:13.097437"}}
{"question": "How can you specify the accounts to aggregate AWS Config data from?", "answer": "You can specify the accounts to aggregate AWS Config data from by uploading a file or by individually entering accounts. Note that for accounts not part of an AWS organization, each account must explicitly authorize the aggregator account.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-11T14:49:13.097689"}}
{"question": "What is the difference between the data aggregation capability and AWS CloudFormation StackSets for provisioning rules across multiple accounts and Regions?", "answer": "The data aggregation capability is a reporting feature that provides visibility into the compliance of multiple accounts and Regions. AWS CloudFormation StackSets are used to provision rules across accounts and Regions.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-11", "source_tokens": 487, "generated_at": "2026-02-11T14:49:13.097853"}}
{"question": "What are the three factors on which AWS Config charges are based?", "answer": "AWS Config charges are based on the number of configuration items recorded, the number of active AWS Config rule evaluations, and the number of conformance pack evaluations in your account.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-11T14:49:17.988862"}}
{"question": "How does AWS Config handle the delivery of configuration data?", "answer": "AWS Config delivers configuration data either continuously or periodically. Continuous recording records and delivers configuration changes whenever a change occurs. Periodic recording delivers configuration data once every 24 hours, only if a change has occurred.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-11T14:49:17.989273"}}
{"question": "What is the difference between managed and custom AWS Config rules in terms of charges and maintenance?", "answer": "Managed rules are fully maintained by AWS and you do not pay any additional Lambda charges to run them. Custom rules, on the other hand, incur additional monthly charges for an active rule and standard Lambda function application rates apply. You are responsible for maintaining the Lambda function associated with a custom rule.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-12", "source_tokens": 387, "generated_at": "2026-02-11T14:49:17.989667"}}
{"question": "Which APN Partner solutions offer integrations with AWS Config?", "answer": "Splunk, ServiceNow, Evident.io, CloudCheckr, Redseal, and Red Hat CloudForms are some of the APN Partner solutions that offer integrations with AWS Config.", "question_type": "factual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-11T14:49:22.318556"}}
{"question": "How do APN Partner solutions integrated with AWS Config help in managing AWS resource configurations?", "answer": "APN Partner solutions integrated with AWS Config offer capabilities such as change management and security analysis, helping you visualize, monitor, and manage AWS resource configurations.", "question_type": "conceptual", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-11T14:49:22.318889"}}
{"question": "What's the difference between an APN Partner solution that offers AWS Config integration and one that doesn't?", "answer": "APN Partner solutions that offer AWS Config integration can assist with managing AWS resource configurations through capabilities like change management and security analysis, whereas solutions that don't offer this integration cannot provide these functionalities.", "question_type": "comparison", "metadata": {"service": "CONFIG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "config-faq-13", "source_tokens": 129, "generated_at": "2026-02-11T14:49:22.319351"}}
{"question": "What service does AWS Control Tower provide for creating and managing multi-account AWS environments?", "answer": "AWS Control Tower is a service that helps create and manage multi-account AWS environments using best-practices blueprints and governance controls.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-11T14:49:27.283167"}}
{"question": "How does AWS Control Tower benefit someone looking to govern an AWS environment?", "answer": "AWS Control Tower benefits someone looking to govern an AWS environment by offering prescriptive guidance, control, and automation for setting up and managing a well-architected multi-account environment. It also allows for the application of prepackaged policies organization-wide or to specific groups of accounts.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-11T14:49:27.283495"}}
{"question": "How does AWS Control Tower compare to other services for managing multiple AWS accounts?", "answer": "AWS Control Tower compares to other services for managing multiple AWS accounts by offering built-in best-practices blueprints and controls for setting up and governing a multi-account environment. It provides a single location for easily setting up new accounts and applying organization-wide policies.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-0", "source_tokens": 397, "generated_at": "2026-02-11T14:49:27.283860"}}
{"question": "What are some of the features provided by AWS Control Tower for automating the creation of a landing zone?", "answer": "AWS Control Tower automates the creation of a landing zone with best-practices blueprints that configure AWS Organizations for a multi-account structure, provide identity management using AWS IAM Identity Center, create a central log archive using AWS CloudTrail and AWS Config, enable security audits across accounts using IAM Identity Center, implement network configurations using Amazon Virtual Private Cloud (Amazon VPC), and define workflows for provisioning accounts and associated AWS Control Tower solutions.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-11T14:49:34.912448"}}
{"question": "How does AWS Control Tower help with ongoing governance of a multi-account environment?", "answer": "AWS Control Tower offers preventive, detective, and proactive controls that help you govern your resources and monitor compliance across groups of AWS accounts. Controls are prepackaged governance rules for security, operations, and compliance that you can select and apply enterprise-wide or to specific groups of AWS accounts. AWS Control Tower automatically implements controls using multiple building blocks such as AWS CloudFormation to establish a baseline, AWS Organizations service control policies (SCPs) to prevent configuration changes, AWS Config rules to continuously detect nonconformance, and AWS CloudFormation Hooks to scan your resources before they are provisioned and make sure that the resources are compliant with that control.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-11T14:49:34.912766"}}
{"question": "How does AWS Control Towerâ€™s Account Factory compare to the process of manually creating AWS accounts?", "answer": "AWS Control Towerâ€™s Account Factory automates the provisioning of AWS accounts that are preconfigured to meet your business, security, and compliance requirements. This contrasts with the manual process of creating AWS accounts, which can be time-consuming and error-prone.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-1", "source_tokens": 403, "generated_at": "2026-02-11T14:49:34.913237"}}
{"question": "Which digital sovereignty controls are offered by AWS Control Tower?", "answer": "AWS Control Tower offers a set of digital sovereignty controls in the AWS Control Tower control library to implement controls that prevent actions, enforce configurations, detect resource changes for data residency, granular access restriction, encryption, and resiliency capabilities.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:49:40.485253"}}
{"question": "How does AWS Control Tower's customizable Region deny control work and what types of restrictions can be applied?", "answer": "AWS Control Tower's customizable Region deny control applies regional restrictions that best fit a unique business need, with capabilities including prevention of actions, enforcement of configurations, detection of resource changes for data residency, granular access restriction, encryption, and resiliency.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:49:40.485530"}}
{"question": "What is the difference between using AWS Service Catalog and AWS CloudTrail with AWS Control Tower compared to using them individually?", "answer": "When using AWS Control Tower, you only pay for AWS services enabled by AWS Control Tower, such as AWS Service Catalog and AWS CloudTrail, and the underlying services that deploy controls. In contrast, when using AWS Service Catalog and AWS CloudTrail individually, you pay for each service separately.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:49:40.485980"}}
{"question": "What service does AWS Control Tower use to enable provisioning of new accounts?", "answer": "AWS Service Catalog", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-11T14:49:44.978292"}}
{"question": "How does AWS Control Tower and AWS Security Hub complement each other in terms of security?", "answer": "AWS Control Tower applies preventive controls at an account level to enforce policies, while AWS Security Hub performs security best practice checks at a resource level to identify potential security issues. They are mutually reinforcing and help ensure that AWS accounts and resources are in a secure state.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-11T14:49:44.978544"}}
{"question": "What are the differences between the roles of AWS Control Tower and AWS Security Hub in an AWS environment?", "answer": "AWS Control Tower provides central governance at an account level, setting up policies and enforcing them through controls. AWS Security Hub, on the other hand, performs security best practice checks and aggregates security findings from multiple sources.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-3", "source_tokens": 483, "generated_at": "2026-02-11T14:49:44.978832"}}
{"question": "What is the purpose of AWS Systems Manager in relation to AWS Control Tower?", "answer": "AWS Systems Manager is used for handling the ongoing day-to-day operations of an AWS environment that has been set up and governed by AWS Control Tower.", "question_type": "conceptual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-11T14:49:48.924618"}}
{"question": "What can you do with the unified user interface in AWS Systems Manager?", "answer": "You can view operational data from multiple AWS services and automate operational tasks across your AWS resources.", "question_type": "factual", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-11T14:49:48.924918"}}
{"question": "How does AWS Control Tower's account factory customization feature compare to predefined blueprints?", "answer": "Both features help in setting up customized AWS accounts. Account factory customization is automated for future provisioning, while predefined blueprints are built and managed by AWS Partners.", "question_type": "comparison", "metadata": {"service": "CONTROLTOWER", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "controltower-faq-4", "source_tokens": 292, "generated_at": "2026-02-11T14:49:48.925346"}}
{"question": "What infrastructure does AWS Copilot provision when deploying containerized applications?", "answer": "AWS Copilot provisions Amazon ECS clusters, tasks, services (for EC2 and Fargate launch types), load balancers, VPC, and ECR registries.", "question_type": "factual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-11T14:49:54.298147"}}
{"question": "How does AWS Copilot simplify the experience of deploying containers to AWS for developers?", "answer": "AWS Copilot simplifies the experience of deploying containers to AWS for developers by providing an easy-to-use CLI that creates the step-by-step pipeline, manages resources, and guides users in deploying containerized applications to the cloud.", "question_type": "conceptual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-11T14:49:54.298526"}}
{"question": "What is the difference between the resources created by AWS Copilot and those created through the AWS Management Console?", "answer": "The main difference is that AWS Copilot creates resources like ECS clusters, tasks, services, load balancers, VPC, and ECR registries on the user's behalf when deploying containerized applications, whereas resources created through the AWS Management Console are manually created by the user.", "question_type": "comparison", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-0", "source_tokens": 494, "generated_at": "2026-02-11T14:49:54.298985"}}
{"question": "What is the license under which AWS Copilot is distributed?", "answer": "AWS Copilot is distributed under the terms of the Apache 2.0 license.", "question_type": "factual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-11T14:49:57.792685"}}
{"question": "How does one access the up-to-date documentation for AWS Copilot commands?", "answer": "The AWS Copilot wiki provides the latest documentation on the available commands.", "question_type": "conceptual", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-11T14:49:57.793006"}}
{"question": "What resources does a customer pay for when using AWS Copilot?", "answer": "Customers pay for the resources they create through the CLI, which can include Fargate tasks, Amazon VPC, or AWS CodePipeline.", "question_type": "comparison", "metadata": {"service": "COPILOT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "copilot-faq-1", "source_tokens": 294, "generated_at": "2026-02-11T14:49:57.793456"}}
{"question": "What information does the AWS Cost and Usage Report provide?", "answer": "The AWS Cost and Usage Report provides the most comprehensive set of cost and usage data available, including data broken down by hour, day, month, product or product resource, and tags. It delivers exports to an Amazon S3 bucket at least once a day as either a CSV or Parquet file.", "question_type": "factual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:50:03.338385"}}
{"question": "How can you use the Split Cost Allocation Data feature in relation to the AWS Cost and Usage Report?", "answer": "You can use the Split Cost Allocation Data feature to access Amazon ECS task cost and usage data in the AWS Cost and Usage Report. This allows for cost visibility for all Amazon ECS container objects across your entire consolidated billing family.", "question_type": "comparison", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:50:03.338659"}}
{"question": "What are the benefits of using the AWS Cost and Usage Reports for cost optimization and reporting?", "answer": "The AWS Cost and Usage Reports allow for the most detailed cost optimization, reporting, and allocation activities due to the extensive cost and usage data they provide. Users can process the export using analytics tools or spreadsheet applications and create visualizations using business intelligence tools to share insights with teams.", "question_type": "conceptual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T14:50:03.339067"}}
{"question": "What type of AWS accounts have access to Split Cost Allocation Data for Amazon ECS and AWS Batch?", "answer": "Regular and payer accounts have access to Split Cost Allocation Data.", "question_type": "factual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-11T14:50:07.591816"}}
{"question": "How does Split Cost Allocation Data for Amazon ECS and AWS Batch work?", "answer": "Split Cost Allocation Data analyzes each containerâ€™s Amazon EC2 instance resource consumption to generate container-level costs based on the price of the instance and the percentage of CPU and memory resources consumed.", "question_type": "conceptual", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-11T14:50:07.592089"}}
{"question": "How does the cost allocation of Amazon ECS compare to AWS Fargate regarding Split Cost Allocation Data?", "answer": "Both Amazon ECS and AWS Fargate support Split Cost Allocation Data, allowing customers running workloads using these compute environments to see their cost and usage in the CUR.", "question_type": "comparison", "metadata": {"service": "COST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "cost-faq-1", "source_tokens": 204, "generated_at": "2026-02-11T14:50:07.592258"}}
{"question": "What regions does AWS Data Exchange currently support?", "answer": "AWS Data Exchange is currently available in the following regions: Service endpoints", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-11T14:50:11.551534"}}
{"question": "How does AWS Data Exchange simplify the process of accessing third-party data?", "answer": "AWS Data Exchange simplifies the process of accessing third-party data by providing a single global product catalog offered by providers, making it easy for AWS customers to securely exchange and use data on AWS.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-11T14:50:11.551754"}}
{"question": "What is the difference between a subscriber and a provider in the context of AWS Data Exchange?", "answer": "A subscriber is an AWS customer who wants to access data from providers, while a provider is an organization that makes their data available for others to consume through AWS Data Exchange.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 307, "generated_at": "2026-02-11T14:50:11.551876"}}
{"question": "What are the differences in authentication and subscription management between AWS Data Exchange for open data sets and commercial/free data sets?", "answer": "For open data sets on AWS Data Exchange, there is no authentication required to access the data via S3 APIs. Customers do not need to agree to any terms of use, as these data sets are governed only by the provider's open data license. In contrast, for commercial or free data sets on AWS Data Exchange, customers must authenticate using their AWS account to subscribe. Data providers, on the other hand, receive detailed subscription activity reports while open data providers must analyze their own logs to track usage.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:50:18.976448"}}
{"question": "How does the process of becoming a data provider on AWS Data Exchange compare to adding free data to the Registry of Open Data on AWS?", "answer": "To become a data provider on AWS Data Exchange and list both free and commercial products, qualified customers must register as a data provider on the AWS Marketplace Management Portal. Any customer can add free data to the Registry of Open Data on AWS through GitHub, and may apply to the Open Data Sponsorship Program for AWS to sponsor the costs of storage and bandwidth for select open data sets.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:50:18.976784"}}
{"question": "What are the key benefits of using AWS Data Exchange for APIs compared to accessing open data sets directly from the Registry of Open Data on AWS?", "answer": "AWS Data Exchange for APIs enables customers to find, subscribe to, and use third-party API products from providers on AWS Data Exchange. Customers can use AWS-native authentication and governance, explore consistent API documentation, and utilize supported AWS SDKs to make API calls. Data providers can reach a larger customer base by adding their APIs to the AWS Data Exchange catalog, and more easily manage subscriber authentication, entitlement, and billing.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T14:50:18.977197"}}
{"question": "What happens to existing subscriptions when a data provider updates the terms?", "answer": "Existing subscriptions are not affected by a data provider's decision to update the terms. However, for auto-renewing subscriptions, AWS Data Exchange will automatically renew at the latest terms specified by the provider.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:50:34.845203"}}
{"question": "Why do data providers need to specify their refund policy for AWS Data Exchange?", "answer": "Data providers must specify their refund policy to enable AWS to process and issue approved refunds for subscribers.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:50:34.845528"}}
{"question": "How does AWS handle compliance and security in AWS Data Exchange?", "answer": "AWS, data providers, and subscribers share the responsibility for security and compliance in AWS Data Exchange. AWS has detailed restrictions in the Terms and Conditions for AWS Marketplace Providers, and providers and subscribers must conduct their own due diligence to ensure compliance with data privacy laws.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 448, "generated_at": "2026-02-11T14:50:34.845960"}}
{"question": "What happens if AWS terms are breached?", "answer": "AWS may remove the subscriber's access to the data product and the data provider or the subscriber may be suspended or terminated from future use of AWS Data Exchange.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-11T14:50:39.359877"}}
{"question": "How does AWS Data Exchange simplify data acquisition?", "answer": "AWS Data Exchange centralizes, simplifies, and accelerates your data acquisition process by allowing you to consolidate your ingestion across data providers, receive data using a single API, and automate ingestion with CloudWatch Events.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-11T14:50:39.360156"}}
{"question": "What's the difference in billing between upfront and multiple payment data products in AWS Data Exchange?", "answer": "For upfront payment data products, you'll receive an invoice from AWS immediately. For multiple payment data products, you'll receive an invoice based on the dates specified in the payment schedule.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 480, "generated_at": "2026-02-11T14:50:39.360556"}}
{"question": "What steps are required to subscribe to an API product on AWS Data Exchange?", "answer": "First, find the desired API product and select its product detail page. Then, choose 'Continue to subscribe', review the subscription terms, and click 'Subscribe' at the bottom. You may be asked to submit information to the data provider before subscribing. For more information, see the 'Subscribing to a product containing APIs' topic in the AWS Data Exchange User Guide.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-11T14:50:46.143243"}}
{"question": "How can I utilize AWS SDK to sign my API requests on AWS Data Exchange?", "answer": "After subscribing to an API product on AWS Data Exchange, navigate to the productâ€™s asset detail page to view API schemas and code snippets. Utilize the AWS SDK to automatically sign your API requests with your AWS credentials. For more information, see the 'Making an API call (console)' in the AWS Data Exchange User Guide.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-11T14:50:46.143501"}}
{"question": "How does the duration and auto-renewal process work for API subscriptions on AWS Data Exchange?", "answer": "Providers list products with subscription durations ranging from 1 to 36 months. Subscription duration options can be found on each productâ€™s detail page. Data providers have the option to enable auto-renewal on individual offers. As a subscriber, you can choose to set your subscription to auto-renew for offers with this functionality. Auto-renewal is available for public and private offers without payment schedules.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 507, "generated_at": "2026-02-11T14:50:46.143649"}}
{"question": "What happens to existing subscriptions when a data provider updates the terms?", "answer": "Existing subscriptions are not affected by a data provider's decision to update the terms of their offer. However, for auto-renewing subscriptions, AWS Data Exchange will automatically renew at the latest terms specified by the provider.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T14:50:50.947800"}}
{"question": "How does the refund process work for AWS Data Exchange subscriptions?", "answer": "If you wish to request a refund for a subscription, you must contact the data provider directly. Once the provider approves the request, AWS will process and issue the approved refund.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T14:50:50.948184"}}
{"question": "How does AWS Data Exchange handle security and compliance?", "answer": "Security and Compliance is a shared responsibility between AWS, data providers, and subscribers. AWS sets forth detailed restrictions in the Terms and Conditions for AWS Marketplace Providers, which every data provider must agree to before listing data products. If AWS learns of a breach, the content will be removed and the provider may be suspended.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T14:50:50.948567"}}
{"question": "What should you do if you suspect AWS Data Exchange resources are being used for abusive or illegal purposes?", "answer": "You can complete and submit the form found on Report Amazon AWS abuse.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:50:55.505849"}}
{"question": "How does AWS Data Exchange simplify the data acquisition process?", "answer": "AWS Data Exchange centralizes, simplifies, and accelerates your data acquisition process by allowing you to consolidate your ingestion across data providers, receive data using a single API, and easily subscribe to new data products.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:50:55.506071"}}
{"question": "What is the difference between purchasing a data product on AWS Data Exchange with upfront payments and multiple payments?", "answer": "When you purchase a data product on AWS Data Exchange with upfront payments, you'll receive an invoice from AWS immediately. When you purchase a data product on AWS Data Exchange with multiple payments, you'll receive an invoice based on the dates specified in the payment schedule.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 480, "generated_at": "2026-02-11T14:50:55.506454"}}
{"question": "What steps should be followed after finding an API to subscribe to on AWS Data Exchange?", "answer": "After finding an API to subscribe to on AWS Data Exchange, select the product to learn more on the product detail page. Next, choose 'Continue to subscribe', review the subscription terms, and then choose the 'Subscribe' button at the bottom of the page. Note that you may be asked to submit information to the data provider before you can request to subscribe to their product.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-11T14:51:01.993576"}}
{"question": "What operations have been added to which AWS SDKs for working with AWS Data Exchange for APIs?", "answer": "AWS Data Exchange for APIs-specific operations have been added to the AWS SDK for Go, AWS SDK for JavaScript, AWS SDK for Node.js, AWS SDK for PHP, and AWS SDK for Python.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-11T14:51:01.993912"}}
{"question": "Why is it necessary for a data provider to agree to the AWS Marketplace Terms & Conditions when listing a product on AWS Data Exchange?", "answer": "Data providers must agree to the AWS Marketplace Terms & Conditions to list their products on AWS Data Exchange. They must use a valid legal entity domiciled in the United States or a member state of the EU, supply valid banking and taxation identification, and be qualified by the AWS Data Exchange business operations team. Each data provider also undergoes a detailed review by the AWS Data Exchange team before being granted permission to list data products on the catalog.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 448, "generated_at": "2026-02-11T14:51:01.994323"}}
{"question": "What type of files can be packaged in AWS Data Exchange?", "answer": "AWS Data Exchange allows you to package files in any file format.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:51:06.480621"}}
{"question": "How does enabling subscription verification for a public product impact the subscription process?", "answer": "Enabling subscription verification on a public product requires prospective subscribers to fill out a subscription request form with their identity and intended use-case details before subscribing. You'll have up to 45 days to either approve or decline the subscription request.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:51:06.762892"}}
{"question": "How do Parquet formatted files compare to binary or other proprietary file formats in AWS Data Exchange?", "answer": "Parquet formatted files allow subscribers to instantly run queries using Amazon Athena in a cost-effective way, while binary or other proprietary file formats will require subscribers to understand how to parse the information.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 506, "generated_at": "2026-02-11T14:51:06.763079"}}
{"question": "What legal agreement must subscribers agree to before gaining access to data sets on AWS Data Exchange?", "answer": "Subscribers must legally agree to the Data Subscription Agreement (DSA) specified by the data provider before gaining access to data sets contained in a product.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-11T14:51:10.902844"}}
{"question": "How does AWS Data Exchange help data providers with their DSA?", "answer": "AWS Data Exchange provides an optional DSA template that data providers can choose to use or modify with their own terms and conditions. AWS Data Exchange will associate the DSA specified for the product without any further modifications.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-11T14:51:10.903047"}}
{"question": "How does pricing vary for subscription-based data products on AWS Data Exchange?", "answer": "AWS Data Exchange supports subscription-based pricing from 1- to 36-month duration terms.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 451, "generated_at": "2026-02-11T14:51:10.903190"}}
{"question": "What happens when I unpublish a product on AWS Data Exchange?", "answer": "When you unpublish a product, no new subscribers are able to view and subscribe to it. Existing subscriptions will remain in effect until their next renewal, and you'll need to keep data current for any existing subscribers until each subscription expires.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-11T14:51:16.724862"}}
{"question": "Why would you unpublish a product on AWS Data Exchange?", "answer": "You might unpublish a product to ensure that no new subscribers are able to view and subscribe to it, including cancelling auto-renewal for existing subscribers. This could be useful if you need to update the product, remove it temporarily, or if there's an error in the published data.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-11T14:51:16.725233"}}
{"question": "How does the tax handling work for data products on AWS Data Exchange?", "answer": "When listing your data sets, you can enable collection and remittance of US sales and use tax. You can also configure your tax nexus to account for places where you have a physical presence, to direct AWS to collect appropriate taxes. AWS will disburse all funds that AWS has received from subscribers by a certain date to the bank account linked to the AWS account.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 384, "generated_at": "2026-02-11T14:51:16.725526"}}
{"question": "What are the three main constructs in the AWS Data Exchange data model?", "answer": "The three main constructs in the AWS Data Exchange data model are data sets, revisions, and assets.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-11T14:51:21.132852"}}
{"question": "How does AWS Data Exchange simplify managing and publishing data?", "answer": "AWS Data Exchange simplifies managing and publishing data through its data model, which allows for the reuse of data sets, revisions, and assets.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-11T14:51:21.133302"}}
{"question": "What's the difference between using AWS Data Exchange and Bring Your Own Subscription (BYOS) to manage subscriptions?", "answer": "AWS Data Exchange allows you to publish data to customers through an easy-to-use API and console and automatically grants entitlements to subscribers, while BYOS allows you to configure entitlements for existing subscribers at no additional cost.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 412, "generated_at": "2026-02-11T14:51:21.133710"}}
{"question": "What is the timeframe for responding to subscriber support inquiries for products containing APIs on AWS Data Exchange?", "answer": "Providers must respond to subscriber support inquiries within 1 business day.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-11T14:51:25.039838"}}
{"question": "Why is it important for data providers to respond to subscriber inquiries promptly on AWS Data Exchange?", "answer": "Failure to adhere to the response time guidelines may result in products being removed from AWS Data Exchange.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-11T14:51:25.040099"}}
{"question": "How do file formats like Parquet benefit subscribers when accessing data sets on AWS Data Exchange?", "answer": "Parquet formatted files allow subscribers to instantly run queries using Amazon Athena in a cost-effective way.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 512, "generated_at": "2026-02-11T14:51:25.040499"}}
{"question": "What is the duration range for AWS Data Exchange's subscription-based pricing?", "answer": "AWS Data Exchange offers subscription-based pricing with duration terms ranging from 1- to 36 months.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T14:51:29.938853"}}
{"question": "Why can't data products on AWS Data Exchange include all personally identifiable information?", "answer": "Data products listed on AWS Data Exchange may not include information that can be used to identify any person, except for information that is already legally available to the public. AWS Data Exchange has publishing guidelines and Terms and Conditions for AWS Marketplace Providers that restrict certain categories of data. Providers not enrolled in the Extended Provider Program are subject to these restrictions.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T14:51:29.939187"}}
{"question": "How does unpublishing a product on AWS Data Exchange affect existing subscribers?", "answer": "Unpublishing a product on AWS Data Exchange prevents new subscribers from accessing the product. However, you will need to keep data current for any existing subscribers until each subscription expires.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T14:51:29.939672"}}
{"question": "What is the payment schedule for disbursements of funds from AWS for subscriptions less fulfillment fees?", "answer": "AWS disburses all funds that have been received from subscribers once a month.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-11T14:51:34.646798"}}
{"question": "How does AWS handle tax collection when listing data sets on the AWS Marketplace?", "answer": "AWS allows sellers to enable collection and remittance of US sales and use tax and configure tax nexus for places where they have a physical presence. Sellers should review the AWS Marketplace U.S Tax Collection Support Terms and Conditions for more information.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-11T14:51:34.647098"}}
{"question": "How does AWS's handling of tax collection on the AWS Marketplace compare to Amazon.com's handling of customer data?", "answer": "Unlike Amazon.com, AWS does not provide customer data on AWS Data Exchange. AWS is vigilant about customersâ€™ privacy and does not access or use data products except as necessary to provide the AWS Data Exchange service.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-15", "source_tokens": 230, "generated_at": "2026-02-11T14:51:34.647485"}}
{"question": "What are the three reusable constructs used in AWS Data Exchange for managing and publishing data?", "answer": "The three reusable constructs used in AWS Data Exchange for managing and publishing data are data sets, revisions, and assets.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-11T14:51:40.772700"}}
{"question": "How does AWS Data Exchange simplify managing and publishing data for providers?", "answer": "AWS Data Exchange simplifies managing and publishing data for providers by providing reusable constructs for data sets, revisions, and assets. Providers can publish data to their customers through an easy-to-use API and console. AWS customers can subscribe to these published data products directly from AWS Marketplace, and the service automatically grants entitlements to subscribers and sends an Amazon CloudWatch Events event when new revisions are published.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-11T14:51:40.772959"}}
{"question": "What's the difference between AWS Data Exchange and AWS Marketplace for providers?", "answer": "AWS Data Exchange is a service that helps providers publish their data to customers through the AWS Marketplace. With AWS Data Exchange, providers can manage and publish data through reusable constructs called data sets, revisions, and assets. AWS Marketplace is a catalog where AWS customers can find, purchase, and subscribe to software and services that run on AWS. Providers can list their products on AWS Marketplace, and customers can subscribe to and pay for those products.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 412, "generated_at": "2026-02-11T14:51:40.773452"}}
{"question": "What is the response time requirement for AWS Data Exchange providers regarding subscriber support inquiries?", "answer": "Providers must respond to subscriber support inquiries within 1 business day, as outlined in the AWS Data Exchange User Guide.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-11T14:51:45.092771"}}
{"question": "Why is it essential for AWS Data Exchange product providers to adhere to the subscriber support guidelines?", "answer": "Failure to comply with the subscriber support guidelines may result in the removal of products from AWS Data Exchange, as stated in the AWS Data Exchange User Guide.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-11T14:51:45.093057"}}
{"question": "How does the response time requirement for AWS Data Exchange provider support compare to that of other AWS agreements?", "answer": "The AWS Data Exchange User Guide requires providers to respond to subscriber support inquiries within 1 business day, while the Terms and Conditions for AWS Marketplace Sellers and the AWS Customer Agreement have different response time requirements, if any.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-17", "source_tokens": 124, "generated_at": "2026-02-11T14:51:45.093458"}}
{"question": "What is the definition of Streaming ETL in the context of Amazon Data Firehose?", "answer": "Streaming ETL is the process of collecting, transforming, and loading real-time data into data stores or analytical tools. Amazon Data Firehose is a streaming ETL solution that makes it easy to perform this process, allowing data to be captured, transformed, and loaded into various destinations including Amazon S3, Amazon Redshift, and others.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-11T14:51:50.418370"}}
{"question": "What data transformations can be performed using Amazon Data Firehose before loading data into Amazon S3?", "answer": "Built-in data transformations for Amazon S3 include batching, compressing, and encrypting the data before loading it.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-11T14:51:50.418620"}}
{"question": "How does Amazon Data Firehose compare to other ETL solutions in terms of data delivery and destinations?", "answer": "Amazon Data Firehose can deliver and load data into various destinations such as Amazon S3, Amazon Redshift, Snowflake, and others. It allows for near real-time analytics with existing business intelligence tools and dashboards.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-0", "source_tokens": 387, "generated_at": "2026-02-11T14:51:50.418997"}}
{"question": "What are some ways to connect a source to Amazon Data Firehose?", "answer": "Sources can be connected to Amazon Data Firehose using the AWS SDK for Java, .NET, Node.js, Python, or Ruby and the Amazon Data Firehose API. Other methods include Kinesis Data Stream, Amazon MSK, and natively supported AWS services like AWS Cloudwatch, AWS EventBridge, AWS IoT, or AWS Pinpoint.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-11T14:51:56.830978"}}
{"question": "How does Amazon Data Firehose handle data destinations?", "answer": "Amazon Data Firehose delivers data to various destinations including Amazon S3, Amazon Redshift, Amazon OpenSearch Service, Snowflake, Apache Iceberg tables, Splunk, Datadog, NewRelic, Dynatrace, Sumo Logic, LogicMonitor, MongoDB, and HTTP End Point.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-11T14:51:56.831232"}}
{"question": "What's the difference between connecting a source to Firehose via Amazon MSK and via the AWS SDK?", "answer": "Both methods allow you to connect a source to Amazon Data Firehose. However, when using Amazon MSK, Firehose reads data easily from an existing MSK cluster and loads it into Amazon S3 buckets, while when using the AWS SDK, Firehose uses the SDK for Java, .NET, Node.js, Python, or Ruby to capture and deliver data.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-1", "source_tokens": 383, "generated_at": "2026-02-11T14:51:56.831662"}}
{"question": "What is the maximum size of a record that can be sent to a Firehose stream from Amazon MSK?", "answer": "The maximum size of a record (before Base64-encoding) that can be sent to a Firehose stream from Amazon MSK is 10 MB.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T14:52:02.282720"}}
{"question": "How does Data Firehose handle the underlying infrastructure for transporting data to the specified destinations?", "answer": "Data Firehose manages all underlying infrastructure, including storage, networking, and configuration, needed to capture and load data into various AWS services such as Amazon S3, Amazon Redshift, Amazon OpenSearch Service, Snowflake, and Apache Iceberg tables or Splunk.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T14:52:02.283042"}}
{"question": "What is the difference in record size limitations between using Direct PUT or Amazon MSK as the data source for a Firehose stream?", "answer": "The maximum size of a record (before Base64-encoding) that can be sent to a Firehose stream from Direct PUT or Kinesis Data Streams is 1024 KB, while the maximum size from Amazon MSK is 10 MB.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T14:52:02.283442"}}
{"question": "What operating systems support the installation of Kinesis Agent?", "answer": "Kinesis Agent can be installed on Amazon Linux, Red Hat Enterprise Linux, and Microsoft Windows.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-11T14:52:07.625073"}}
{"question": "How does Kinesis Agent work to send data to a Firehose stream?", "answer": "Kinesis Agent is a pre-built Java application that monitors certain files and continuously sends data to a Firehose stream. It can be installed on Linux-based server environments and supports Amazon Linux, Red Hat Enterprise Linux, and Microsoft Windows.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-11T14:52:07.625353"}}
{"question": "What is the difference between using Kinesis Agent versus Firehose's PutRecord and PutRecordBatch operations to add data to a Firehose stream?", "answer": "Using Kinesis Agent allows you to collect and send data to a Firehose stream continuously by monitoring certain files, while using Firehose's PutRecord and PutRecordBatch operations requires manually sending data within API calls. Kinesis Agent also supports automatic delivery retries, data retention, auto scaling, and redundancy, while Firehose operations do not provide these features.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-3", "source_tokens": 503, "generated_at": "2026-02-11T14:52:07.625513"}}
{"question": "What is the starting point for Firehose when reading data from an Amazon MSK topic?", "answer": "Firehose starts reading data from the LATEST position of an Amazon MSK topic when it is configured as the source of a Firehose stream.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-11T14:52:12.748327"}}
{"question": "Why does Firehose call Kinesis Data Streams GetRecords() once every second for each shard?", "answer": "Firehose calls Kinesis Data Streams GetRecords() once every second for each shard to read data and load it to the specified destinations.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-11T14:52:12.748636"}}
{"question": "How does configuring a Firehose stream as the source of another Firehose stream impact the Kinesis Data Stream's PutRecord and PutRecords operations?", "answer": "When a Kinesis Data Stream is configured as the source of a Firehose stream, Firehose's PutRecord and PutRecordBatch operations are disabled. You should add data to the Kinesis Data Stream through the Kinesis Data Streams PutRecord and PutRecords operations instead.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-4", "source_tokens": 482, "generated_at": "2026-02-11T14:52:12.749071"}}
{"question": "What source can you use to add data to a Firehose stream through the console or APIs?", "answer": "Direct PUT", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-11T14:52:15.729896"}}
{"question": "How can you configure a Firehose stream as a source in VPC Flow logs?", "answer": "By configuring the created Firehose stream in the Vended Logs section of the VPC Flow logs console", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-11T14:52:15.730232"}}
{"question": "What methods can you use to add data to a Firehose stream from CloudWatch Logs or Events?", "answer": "You can use CloudWatch Logs subscription filters or CloudWatch Events rules, respectively", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-5", "source_tokens": 347, "generated_at": "2026-02-11T14:52:15.730684"}}
{"question": "What format does Firehose use when compressing data from CloudWatch Logs?", "answer": "Firehose leaves the data uncompressed when receiving compressed data from CloudWatch Logs to avoid double-compression.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-11T14:52:20.323550"}}
{"question": "How does Firehose facilitate data transformation before delivering data to S3?", "answer": "Firehose allows users to use AWS Lambda functions for data transformation before loading data to S3. Users can configure this function when creating or editing a Firehose stream.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-11T14:52:20.323864"}}
{"question": "What are the differences between compressing data with Firehose versus using CloudWatch Logs subscription feature?", "answer": "Firehose compresses data before delivering it to S3 using GZIP, ZIP, or SNAPPY formats. However, when data is further loaded to Amazon Redshift, only GZIP is supported. CloudWatch Logs, on the other hand, already compresses log events in gzip format, so Firehose's compression configuration should be set as uncompressed to avoid double-compression.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-6", "source_tokens": 400, "generated_at": "2026-02-11T14:52:20.324244"}}
{"question": "What parameter must transformed records in Lambda have an identical recordId to for Firehose to consider the transformation successful?", "answer": "The transformed records in Lambda must have an identical recordId to the original recordId for Firehose to consider the transformation successful.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-11T14:52:25.663608"}}
{"question": "Why does Firehose treat records with 'ProcessingFailed' status differently than records with 'Ok' or 'Dropped' status during data processing?", "answer": "Firehose treats records with 'Ok' and 'Dropped' statuses as successfully processed records, and the ones with 'ProcessingFailed' status as unsuccessfully processed records when it generates SucceedProcessing.Records and SucceedProcessing.Bytes metrics.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-11T14:52:25.663898"}}
{"question": "How does enabling data transformation with Lambda and source record backup impact the delivery of un-transformed records?", "answer": "Enabling data transformation with Lambda and source record backup allows Amazon Data Firehose to deliver the un-transformed incoming data to a separate S3 bucket with an extra prefix added to the 'YYYY/MM/DD/HH' UTC time prefix generated by Firehose.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-7", "source_tokens": 368, "generated_at": "2026-02-11T14:52:25.664041"}}
{"question": "What key feature allows marketing automation customers to query optimized data sets in Firehose?", "answer": "Dynamic partitioning based on customer id", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-11T14:52:29.325152"}}
{"question": "How does dynamic partitioning in Firehose improve query performance for IT operations or security monitoring customers?", "answer": "By enabling them to create groupings based on event timestamp and query optimized data sets", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-11T14:52:29.325364"}}
{"question": "What are the advantages of using Firehose for streaming ETL to S3 compared to manual partitioning?", "answer": "Firehose eliminates complexities and delays of manual partitioning, makes data immediately available for analytics tools, and enhances access control", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-8", "source_tokens": 465, "generated_at": "2026-02-11T14:52:29.325496"}}
{"question": "What determines the frequency of data delivery from Amazon Firehose to Amazon S3?", "answer": "The frequency of data delivery from Amazon Firehose to Amazon S3 is determined by the S3 buffer size and buffer interval value you configured for your Firehose stream.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-11T14:52:34.667687"}}
{"question": "How does Firehose handle data delivery when data ingestion falls behind?", "answer": "In circumstances where data delivery to the destination is falling behind data ingestion into the Firehose stream, Firehose raises the buffer size automatically to catch up and make sure that all data is delivered to the destination.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-11T14:52:34.668028"}}
{"question": "Which cloud services can Firehose deliver data to, and how does it handle delivery to Redshift compared to Snowflake?", "answer": "Amazon Data Firehose can deliver data to Amazon S3 and Amazon Redshift. For Redshift destinations, Firehose delivers data to your Amazon S3 bucket first and then issues the Redshift COPY command to load data from your S3 bucket to your Redshift instance. A single Firehose stream can only deliver data to one Snowflake table.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-9", "source_tokens": 435, "generated_at": "2026-02-11T14:52:34.668207"}}
{"question": "What does Firehose ensure in terms of data delivery semantics for Snowflake?", "answer": "Firehose ensures exactly-once delivery semantics for Snowflake, meaning each record is delivered to Snowflake exactly once, but it doesn't prevent duplicates in the data end to end.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T14:52:39.691189"}}
{"question": "How can Firehose be used with Amazon OpenSearch Service?", "answer": "Firehose can be used with Amazon OpenSearch Service by rotating the index based on a time duration, and you can provide a backup Amazon S3 bucket when loading data into Amazon OpenSearch Service to prevent data loss.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T14:52:39.691575"}}
{"question": "How does Firehose delivery to Amazon OpenSearch Service compare to the delivery to a VPC destination?", "answer": "When delivering to Amazon OpenSearch Service, Firehose can change the configuration at any time, while when delivering to a VPC destination, you need to re-create the Firehose stream for changes to VPC, subnets, and security groups.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T14:52:39.691811"}}
{"question": "What are the requirements for delivering data from AWS Firehose to Amazon OpenSearch Service through public and private endpoints?", "answer": "Firehose can deliver data to a different account in Amazon OpenSearch Service only through a public endpoint. In contrast, when Firehose and Amazon OpenSearch Service are connected through a private VPC, the stream and the destination domain VPC must be in the same account and region.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:52:45.308009"}}
{"question": "How does Firehose handle the frequency of data delivery to Amazon OpenSearch Service?", "answer": "The frequency of data delivery to Amazon OpenSearch Service is determined by the OpenSearch buffer size and buffer interval values that you configured for your Firehose stream. Firehose buffers incoming data before delivering it to Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:52:45.308359"}}
{"question": "What happens when there's a difference between data ingestion into the Firehose stream and data delivery to the destination (Amazon OpenSearch Service)?", "answer": "When data delivery to the destination is falling behind data ingestion into the Firehose stream, Amazon Data Firehose raises the buffer size automatically to catch up and make sure that all data is delivered to the destination.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T14:52:45.308826"}}
{"question": "What is the limit for data delivery per second for one Firehose stream by default?", "answer": "One Firehose stream can intake up to 2,000 transactions/second, 5,000 records/second, and 5 MB/second by default.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-11T14:52:50.732187"}}
{"question": "Why would you create multiple Firehose streams to deliver data to multiple Amazon OpenSearch domains or indexes?", "answer": "Each Firehose stream can only deliver data to one Amazon OpenSearch Service domain and one index currently. To have data delivered to multiple domains or indexes, you need to create multiple Firehose streams.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-11T14:52:50.732475"}}
{"question": "How does the data delivery retries behavior differ between Direct PUT and Kinesis Data Streams as data sources?", "answer": "If data delivery to an Amazon S3 bucket fails with a Direct PUT data source, Firehose will retry every 5 seconds for up to a maximum of 24 hours. With a Kinesis Data Streams data source, Firehose retries every 5 seconds for a period configured on Kinesis Data Streams.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-12", "source_tokens": 459, "generated_at": "2026-02-11T14:52:50.732910"}}
{"question": "What is the maximum retry duration for Amazon Data Firehose when delivering data to a Redshift instance?", "answer": "The maximum retry duration for Amazon Data Firehose when delivering data to a Redshift instance is 120 minutes.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-11T14:52:57.165088"}}
{"question": "How does Amazon Data Firehose handle failed data delivery to Amazon Redshift and Amazon OpenSearch Service destinations?", "answer": "Amazon Data Firehose retries failed data delivery to both Amazon Redshift and Amazon OpenSearch Service destinations. For Redshift, the maximum retry duration is 120 minutes, after which the current batch is skipped and details about the skipped objects are delivered to the S3 bucket in the errors folder. For OpenSearch Service, the retry duration can be specified between 0 and 7200 seconds. After the retrial period, the current batch is skipped and details about the skipped documents are delivered to the S3 bucket in the opensearch_failed folder.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-11T14:52:57.165424"}}
{"question": "What's the difference in retry duration settings between Amazon Data Firehose delivery to Amazon Redshift and Amazon OpenSearch Service destinations?", "answer": "The main difference in retry duration settings between Amazon Data Firehose delivery to Amazon Redshift and Amazon OpenSearch Service destinations is that the maximum retry duration for Redshift is 120 minutes, while for OpenSearch Service, the retry duration can be specified between 0 and 7200 seconds.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-13", "source_tokens": 249, "generated_at": "2026-02-11T14:52:57.165881"}}
{"question": "What happens when Firehose encounters network timeouts or Lambda invocation limits, and how many times does it retry before giving up?", "answer": "When Firehose experiences failure scenarios due to network timeouts or Lambda invocation limits, it retries the invocation three times by default and then skips the batch of records. These records are considered unsuccessfully processed records.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-11T14:53:02.096232"}}
{"question": "How does Firehose handle records whose transformation results are set to â€˜ProcessingFailedâ€™ by the Lambda function?", "answer": "Firehose considers records with â€˜ProcessingFailedâ€™ transformation results as unsuccessfully processed records.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-11T14:53:02.096580"}}
{"question": "What's the difference between the records that end up in the processing_failed folder versus the errors folder?", "answer": "Records in the processing_failed folder are unsuccessfully processed records due to invocation failures or network timeouts, while records in the errors folder are failed S3 objects that couldn't be loaded to Redshift or OpenSearch.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-14", "source_tokens": 490, "generated_at": "2026-02-11T14:53:02.097010"}}
{"question": "What is the pricing unit for Amazon Data Firehose based on?", "answer": "Amazon Data Firehose pricing is based on the data volume (GB) ingested by Firehose.", "question_type": "factual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-11T14:53:09.666150"}}
{"question": "How does Firehose calculate the data volume for billing?", "answer": "The data volume from a PutRecordBatch call is metered in 5KB increments per record. For example, if a PutRecordBatch call contains two 1KB records, the data volume from that call is metered as 10KB.", "question_type": "conceptual", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-11T14:53:09.666474"}}
{"question": "What are the additional costs associated with using Firehose, compared to just Firehose itself?", "answer": "You will be billed separately for charges associated with Amazon S3, Amazon Redshift, Amazon OpenSearch Service, and AWS Lambda usage.", "question_type": "comparison", "metadata": {"service": "DATA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "data-faq-16", "source_tokens": 437, "generated_at": "2026-02-11T14:53:09.666954"}}
{"question": "What are the key features of AWS Glue for data integration?", "answer": "AWS Glue is a serverless service that simplifies, accelerates, and reduces the cost of data integration. It allows users to discover and connect to over 100 diverse data sources, manage data in a centralized data catalog, and create, run, and monitor data pipelines to load data into various data stores. AWS Glue also offers built-in generative AI capabilities for modernizing Spark jobs and ETL authoring, as well as Spark troubleshooting.", "question_type": "conceptual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:53:16.113462"}}
{"question": "What are the benefits of using AWS Glue for serverless data integration?", "answer": "AWS Glue offers several benefits for serverless data integration, including automatic scaling for data processing jobs, eliminating infrastructure management, and providing cost-effective solutions. AWS Glue automatically scales from gigabytes to petabytes, eliminates the need for managing servers, and allows teams to focus on building data workflows instead.", "question_type": "factual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:53:16.113872"}}
{"question": "How does AWS Glue compare to traditional data integration tools?", "answer": "AWS Glue is a fully managed, serverless toolkit for designing and automating modern data pipelines. Compared to traditional data integration tools, AWS Glue offers several advantages, such as automatic scaling, cost-effectiveness, and eliminating infrastructure management. However, a direct comparison of features and capabilities would require a more detailed comparison.", "question_type": "comparison", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-0", "source_tokens": 414, "generated_at": "2026-02-11T14:53:16.114123"}}
{"question": "What data processing capabilities are available in Amazon SageMaker using AWS Glue?", "answer": "AWS Glue data processing capabilities are available in Amazon SageMaker notebooks and Amazon SageMaker visual ETL.", "question_type": "factual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-11T14:53:20.449458"}}
{"question": "How does AWS Glue simplify data integration needs in Amazon SageMaker?", "answer": "AWS Glue simplifies data integration needs in Amazon SageMaker by providing automatic provisioning and worker management, and consolidating data integration services into a single platform.", "question_type": "conceptual", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-11T14:53:20.449818"}}
{"question": "How does AWS Glue in Amazon SageMaker compare to other data processing services for handling various workloads and frameworks?", "answer": "AWS Glue in Amazon SageMaker supports various data processing frameworks, such as ETL and ELT, and various workloads, including batch, micro-batch, and streaming.", "question_type": "comparison", "metadata": {"service": "DATAPIPELINE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datapipeline-faq-1", "source_tokens": 240, "generated_at": "2026-02-11T14:53:20.450257"}}
{"question": "Which AWS services can AWS DataSync be used to transfer data to and from?", "answer": "AWS DataSync can be used to transfer data to and from Network File System (NFS) shares, Server Message Block (SMB) shares, Hadoop Distributed File Systems (HDFS), self-managed object storage, object storage in other clouds such as Google Cloud Storage and Wasabi Cloud Storage, Azure Files, Azure Blob Storage (including Azure Data Lake Storage Gen2), Amazon S3 compatible storage on Snow, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS) file systems, Amazon FSx for Windows File Server file systems, Amazon FSx for Lustre file systems, Amazon FSx for OpenZFS file systems, and Amazon FSx for NetApp ONTAP file systems.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T14:53:27.697018"}}
{"question": "Why is AWS DataSync beneficial for moving data to and from AWS Storage?", "answer": "AWS DataSync simplifies, automates, and accelerates the process of moving data to and from AWS Storage. It allows users to securely and quickly transfer large amounts of data without the need to build custom solutions or manage expensive commercial network acceleration software.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T14:53:27.697412"}}
{"question": "How does AWS DataSync compare to manually transferring large datasets to Amazon S3?", "answer": "AWS DataSync automates and accelerates the process of transferring large datasets to Amazon S3, compared to manually transferring the data. Users can securely and quickly move their data to AWS, without the need to build custom solutions or manage expensive commercial network acceleration software.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T14:53:27.697629"}}
{"question": "Which standard storage protocols does AWS DataSync support for connecting to existing storage systems and data sources?", "answer": "AWS DataSync supports standard storage protocols such as NFS, SMB, and uses the Amazon S3 API or other cloud storage APIs.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-11T14:53:32.101935"}}
{"question": "How does AWS DataSync handle data transfers and what features does it provide?", "answer": "AWS DataSync handles moving files and objects, scheduling data transfers, monitoring the progress of transfers, encryption, verification of data transfers, and notifying you of any issues.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-11T14:53:32.102190"}}
{"question": "What types of cloud storage does AWS DataSync support for transferring data to and from?", "answer": "AWS DataSync supports transferring data to and from various cloud storage providers including Amazon S3, Google Cloud Storage, Wasabi Cloud Storage, Azure Blob Storage, and Azure Files.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-1", "source_tokens": 321, "generated_at": "2026-02-11T14:53:32.102610"}}
{"question": "What storage services can you migrate data to using AWS DataSync?", "answer": "AWS DataSync can be used to migrate data to Amazon S3, Amazon EFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon FSx for OpenZFS, and Amazon FSx for NetApp ONTAP.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T14:53:38.476847"}}
{"question": "How does AWS DataSync help during a storage migration?", "answer": "AWS DataSync helps during a storage migration by making an initial copy of the entire dataset and then scheduling subsequent incremental transfers of changing data. It also includes encryption and integrity validation to ensure data security and integrity. Users can also schedule migrations to run during off-hours or limit bandwidth usage to minimize impact on workloads.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T14:53:38.477117"}}
{"question": "What's the difference between migrating data to Amazon S3 Glacier Flexible Retrieval and Amazon S3 Glacier Deep Archive using AWS DataSync?", "answer": "Both Amazon S3 Glacier Flexible Retrieval and Amazon S3 Glacier Deep Archive are durable and secure long-term storage solutions. However, the main difference is the retrieval speed. With Amazon S3 Glacier Flexible Retrieval, data can be retrieved in minutes, while with Amazon S3 Glacier Deep Archive, data retrieval takes hours.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T14:53:38.477471"}}
{"question": "What are some storage services that AWS DataSync can replicate data to?", "answer": "AWS DataSync can replicate data to Amazon S3, Amazon EFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon FSx for OpenZFS, or Amazon FSx for NetApp ONTAP.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-11T14:53:43.319360"}}
{"question": "How does AWS DataSync help in industries that need to move active files into AWS quickly?", "answer": "AWS DataSync helps industries that need to move active files into AWS quickly by providing timely delivery, ensuring that dependent processes are not delayed.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-11T14:53:43.319650"}}
{"question": "How does AWS DataSync compare when copying data from Azure Blob Storage using Basic mode versus Enhanced mode?", "answer": "When using Enhanced mode tasks, no agent is required to connect to Azure Blob Storage. However, when using Basic mode, a DataSync agent must be deployed in the cloud environment or on Amazon EC2.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-3", "source_tokens": 428, "generated_at": "2026-02-11T14:53:43.320061"}}
{"question": "What protocols does AWS DataSync support for transferring data?", "answer": "AWS DataSync supports transferring data using standard storage protocols (NFS, SMB), as an HDFS client, using the Amazon S3 API, or using other cloud storage APIs.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-11T14:53:48.342144"}}
{"question": "How can you ensure data security and integrity when using AWS DataSync?", "answer": "AWS DataSync includes encryption and integrity validation to help make sure your data arrives securely, intact, and ready to use.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-11T14:53:48.342508"}}
{"question": "How does transferring data between different AWS services using AWS DataSync compare to transferring data within the same AWS service?", "answer": "You can transfer data between different AWS services (in the same AWS account) and between services in different Commercial AWS Regions (except for China) using AWS DataSync. This does not require deploying a DataSync agent, and can be configured end to end using the AWS DataSync console, AWS Command Line Interface (CLI), or AWS Software Development Kit (SDK).", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-4", "source_tokens": 412, "generated_at": "2026-02-11T14:53:48.343000"}}
{"question": "What is the purpose of AWS DataSync in the context of Amazon WorkDocs Migration Service?", "answer": "AWS DataSync automates file upload to the Amazon S3 bucket used for Amazon WorkDocs Migration Service, making it easier and faster to migrate home directories and department shares to WorkDocs.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-11T14:53:53.380223"}}
{"question": "How can you initiate a data transfer using AWS DataSync?", "answer": "You can initiate a data transfer using AWS DataSync through the AWS Management Console or the AWS Command Line Interface (CLI).", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-11T14:53:53.380574"}}
{"question": "What are the steps involved in using AWS DataSync for transferring data to Amazon WorkDocs?", "answer": "1. Deploy an agent and associate it with your AWS account via the Management Console or API to access your data source. 2. Create a data transfer task by specifying the location of your data source and destination and any desired options. 3. Start the transfer, monitor data movement in the console or with Amazon CloudWatch, and audit transfer tasks using task reports.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-5", "source_tokens": 335, "generated_at": "2026-02-11T14:53:53.381075"}}
{"question": "What protocols does the AWS DataSync agent use to access on-premises file servers?", "answer": "The AWS DataSync agent uses NFS and SMB protocols to access on-premises file servers.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:53:58.959967"}}
{"question": "What are the benefits of deploying the AWS DataSync agent on your own hypervisor or Amazon EC2 instead of using Enhanced mode tasks?", "answer": "Deploying the AWS DataSync agent on your own hypervisor or Amazon EC2 allows you to reduce egress fees because AWS DataSync compresses data in flight between the agent and AWS Storage services. However, when using Enhanced mode tasks, no agent is required to connect to your cloud storage.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:53:58.960311"}}
{"question": "How does transferring data between AWS Storage services within the same AWS account differ from transferring data between AWS Storage services in different AWS accounts?", "answer": "To transfer data between AWS Storage services within the same AWS account, you launch an Amazon EC2 instance using a DataSync agent AMI. In contrast, to transfer data between AWS Storage services in different AWS accounts, no agent is required, but you must ensure that the necessary IAM roles and policies are in place.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-6", "source_tokens": 494, "generated_at": "2026-02-11T14:53:58.960718"}}
{"question": "What is the difference between the number of objects that can be processed in Basic and Enhanced modes in AWS DataSync?", "answer": "Basic mode is subject to quotas on the number of files and objects in a dataset and processes them sequentially, while Enhanced mode can process datasets with virtually unlimited numbers of objects at higher performance levels.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-11T14:54:03.568837"}}
{"question": "How does AWS DataSync ensure the integrity of data during transfers between source and destination?", "answer": "AWS DataSync performs integrity checks during transfers by calculating and comparing full-file checksums of the data in the source and destination.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-11T14:54:03.569073"}}
{"question": "Why would a user choose Enhanced mode over Basic mode in AWS DataSync for large data transfers?", "answer": "A user might choose Enhanced mode for large data transfers because it optimizes and streamlines the data transfer process, enabling parallel processing and providing enhanced metrics and reporting capabilities.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-7", "source_tokens": 303, "generated_at": "2026-02-11T14:54:03.569261"}}
{"question": "What information can you get from task reports about the files transferred?", "answer": "Task reports provide information about the number and size of files transferred, their paths, timestamps, checksums, object version IDs, and whether they were verified or deleted.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-11T14:54:08.094530"}}
{"question": "How can task reports be used to gain insights into data transfer processes?", "answer": "Task reports can be used with AWS Glue, Amazon Athena, and Amazon QuickSight to automatically catalog, query, and visualize data transfer statistics, providing critical insights into data transfer processes.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-11T14:54:08.094902"}}
{"question": "How does using CloudWatch Metrics and CloudWatch Logs for data transfer compare to using task reports?", "answer": "CloudWatch Metrics provides real-time information on the number and amount of files and data being transferred, while task reports provide a summary and detailed reports on specific task executions, including file attributes and results of content integrity verification.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-8", "source_tokens": 260, "generated_at": "2026-02-11T14:54:08.095103"}}
{"question": "What file or object keys are included in a DataSync task based on an include filter?", "answer": "An include filter specifies the file and folder paths or object keys that should be included in a DataSync task.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-11T14:54:12.341283"}}
{"question": "How does an exclude filter impact the files and objects transferred in a DataSync task?", "answer": "An exclude filter specifies the file and folder paths or object keys that should be excluded from being copied in a DataSync task.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-11T14:54:12.341642"}}
{"question": "What's the difference between using filters and manifests for limiting the scope of DataSync tasks?", "answer": "Filters and manifests are two different methods for limiting the scope of files or objects transferred in a DataSync task. Filters specify which files or objects to include or exclude, while manifests list the file paths or object keys that should be transferred.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-9", "source_tokens": 312, "generated_at": "2026-02-11T14:54:12.342190"}}
{"question": "What is an include filter in AWS DataSync?", "answer": "An include filter is a string specification in AWS DataSync used to transfer files or objects from the source location based on patterns. Only files and folders that match the patterns in the filter are copied.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T14:54:17.291409"}}
{"question": "Why is using an include filter beneficial in AWS DataSync?", "answer": "Using an include filter in AWS DataSync is beneficial for customers who only want to copy a small set of files or objects, or specific folders. It allows them to avoid scanning their entire file or object storage systems to determine changes.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T14:54:17.291670"}}
{"question": "How does the use of an include filter compare to using a manifest file in AWS DataSync?", "answer": "Both include filters and manifest files are used in AWS DataSync for file transfers but they serve different purposes: Include filters allow for transferring files based on patterns, while manifest files enable the transfer of specific versions of objects from the source and specify millions of source files or objects to be transferred.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T14:54:17.292054"}}
{"question": "What service does AWS DataSync use for creating VPC endpoints?", "answer": "AWS PrivateLink", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-11T14:54:20.891706"}}
{"question": "How does using VPC endpoints for AWS DataSync increase data security?", "answer": "By keeping network traffic within the Amazon Virtual Private Cloud (Amazon VPC) and not requiring public IP addresses, using VPC endpoints increases the security of data transferred by AWS DataSync.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-11T14:54:20.891963"}}
{"question": "What are the differences between using AWS PrivateLink for VPC endpoints for AWS DataSync and using public IP addresses?", "answer": "Using AWS PrivateLink for VPC endpoints for AWS DataSync keeps network traffic within the Amazon Virtual Private Cloud and doesn't require public IP addresses, increasing data security. Using public IP addresses allows data to traverse the public internet.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-11", "source_tokens": 360, "generated_at": "2026-02-11T14:54:20.892146"}}
{"question": "Which S3 storage classes can be selected when configuring an S3 bucket for use with AWS DataSync?", "answer": "AWS DataSync supports storing data directly into S3 Standard, S3 Intelligent-Tiering, S3 Standard-Infrequent Access (S3 Standard-IA), S3 One Zone-Infrequent Access (S3 One Zone-IA), Amazon S3 Glacier Instant Retrieval, Amazon S3 Glacier Flexible Retrieval, and Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive).", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T14:54:27.354562"}}
{"question": "Why would you use different S3 storage classes when working with AWS DataSync?", "answer": "Different S3 storage classes offer varying cost and performance trade-offs. For example, S3 Standard is used for objects smaller than the minimum charge capacity per object, while S3 Standard-IA and S3 One Zone-IA are used for infrequently accessed objects that incur retrieval fees based on the size of the objects.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T14:54:27.354904"}}
{"question": "What is the difference in retrieval fees when using AWS DataSync with S3 Standard and S3 Standard-IA storage classes?", "answer": "Retrieving objects from S3 Standard storage does not incur any retrieval fees, while retrieving objects from S3 Standard-IA storage incurs a retrieval fee based on the size of the objects.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T14:54:27.355327"}}
{"question": "What metadata is stored in S3 user metadata when copying files from an NFS share to Amazon S3 using AWS DataSync?", "answer": "File and folder timestamps and POSIX permissions, including user ID, group ID, and permissions, are stored in S3 user metadata when copying files from an NFS share to Amazon S3 using AWS DataSync.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T14:54:33.558675"}}
{"question": "Why is the metadata stored in S3 user metadata important when using AWS DataSync to copy files between on-premises NFS shares and Amazon S3?", "answer": "The metadata stored in S3 user metadata is important because it allows for on-premises file-based access to data stored in Amazon S3 through File Gateway, providing interoperability between the two.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T14:54:33.558887"}}
{"question": "What's the difference in how AWS DataSync handles metadata when transferring files between NFS and S3 compared to transferring between SMB and S3?", "answer": "When transferring files between NFS and S3, AWS DataSync stores and restores file metadata (timestamps, user ID, group ID, and permissions) in S3 user metadata. When transferring files between SMB and S3, AWS DataSync stores default POSIX permissions in S3 user metadata, and ownership and permissions are set when copying back to the SMB file share.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T14:54:33.559238"}}
{"question": "What Amazon S3 storage class minimizes minimum capacity charge per object?", "answer": "S3 Standard", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-11T14:54:36.810648"}}
{"question": "How can DataSync help minimize data retrieval fees?", "answer": "By configuring DataSync to verify only files that were transferred by a given task.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-11T14:54:36.810929"}}
{"question": "What's the difference between copying objects between Amazon S3 on AWS Outposts and Amazon S3 in AWS Regions using DataSync?", "answer": "With Amazon S3 on AWS Outposts, you can only transfer data to and from Amazon S3 buckets in AWS Regions. With Amazon S3 in AWS Regions, you can also copy objects between different S3 buckets.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-14", "source_tokens": 420, "generated_at": "2026-02-11T14:54:36.811415"}}
{"question": "What action must be allowed in an IAM policy for AWS DataSync to access EFS as the root user?", "answer": "The elasticfilesystem:ClientRootAccess action", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-11T14:54:41.762235"}}
{"question": "How does AWS DataSync replicate Amazon EFS file systems?", "answer": "AWS DataSync schedules periodic replication of an Amazon EFS file system to a second Amazon EFS file system within the same AWS account. This can be done for both same-region and cross-region deployments without requiring a DataSync agent.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-11T14:54:41.762622"}}
{"question": "What metadata does AWS DataSync copy from an Amazon FSx for Windows File Server when accessing it using the SMB protocol?", "answer": "AWS DataSync copies file and folder timestamps, file owner, standard file attributes, NTFS discretionary access lists (DACLs), and NTFS system access control lists (SACLs) from an Amazon FSx for Windows File Server when accessing it using the SMB protocol.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-15", "source_tokens": 465, "generated_at": "2026-02-11T14:54:41.762861"}}
{"question": "What permissions does AWS DataSync require to access an FSx for Lustre file system?", "answer": "AWS DataSync requires outbound access from the DataSync service on the required network ports and inbound access from the security groups assigned to the DataSync location resource on the FSx for Lustre file system.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-11T14:54:47.188634"}}
{"question": "How does AWS DataSync handle file timestamps and permissions when copying between FSx for Lustre file systems?", "answer": "AWS DataSync copies file and folder timestamps and POSIX permissions, including user ID, group ID, and permissions.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-11T14:54:47.188977"}}
{"question": "What's the difference between using AWS DataSync for replication of FSx for Windows and FSx for Lustre file systems?", "answer": "AWS DataSync can schedule periodic replication of FSx for Windows and FSx for Lustre file systems within the same AWS account. The main difference lies in the file layout and striping configuration on the destination file system, as files are written using the layout and striping configuration on the destination's file system for both types.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-16", "source_tokens": 465, "generated_at": "2026-02-11T14:54:47.189479"}}
{"question": "What ENIs are created when I use AWS DataSync with FSx for OpenZFS?", "answer": "AWS DataSync creates Elastic Network Interfaces (ENIs) in the same VPC and subnet where your FSx for OpenZFS file system is located.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T14:54:52.780395"}}
{"question": "How do security groups come into play when using AWS DataSync with FSx for OpenZFS?", "answer": "When you create a DataSync location resource for your FSx for OpenZFS file system, you can specify up to five security groups to apply to the ENIs. The security groups on your FSx for OpenZFS file system should be configured to allow inbound access from the security groups you assigned to the DataSync location resource.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T14:54:52.780738"}}
{"question": "Can I use AWS DataSync to copy from one FSx for OpenZFS file system to another within the same AWS account? And is it available for cross-region deployments?", "answer": "Yes, you can use AWS DataSync to copy from one FSx for OpenZFS file system to another within the same AWS account for both same-region and cross-region deployments without requiring a DataSync agent.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T14:54:52.781364"}}
{"question": "What subnet does DataSync use to create ENIs when creating a task for accessing an FSx for ONTAP file system?", "answer": "DataSync creates ENIs in the Preferred Subnet of the same VPC where your FSx for ONTAP file system is located.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-11T14:54:58.529406"}}
{"question": "Why is it necessary to configure security groups on both the DataSync Location resource and the FSx for ONTAP file system?", "answer": "You need to configure security groups on your FSx for ONTAP file system to allow inbound access from the security groups you assigned to the DataSync Location resource for your FSx for ONTAP file system.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-11T14:54:58.529741"}}
{"question": "What protocols does AWS DataSync support for accessing FSx for ONTAP file systems and what metadata is copied during the transfer?", "answer": "AWS DataSync supports using NFSv3, SMB 2.1, and SMB 3 for accessing FSx for ONTAP file systems. When using NFS, DataSync copies file and folder timestamps and POSIX permissions. When using SMB, DataSync copies file and folder timestamps, ownership, and ACLs.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-18", "source_tokens": 319, "generated_at": "2026-02-11T14:54:58.530247"}}
{"question": "What protocol should be used when migrating from Windows servers or NAS shares to FSx for ONTAP with an NTFS file system?", "answer": "SMB protocol should be used for the FSx for ONTAP location when migrating from Windows servers or NAS shares with an NTFS file system.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T14:55:03.428471"}}
{"question": "Why should a specific security style be configured when using FSx for ONTAP with DataSync for migrations?", "answer": "The security style for the FSx for ONTAP volume should be configured based on the source protocol (NFS for Unix, NTFS for Windows) to ensure proper data transfer.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T14:55:03.428819"}}
{"question": "What's the difference in replication approaches between AWS DataSync and NetApp SnapMirror when working with FSx for ONTAP?", "answer": "DataSync is used for copying file data to or from FSx for ONTAP using NFS or SMB protocols, while NetApp SnapMirror is recommended for replicating between FSx for ONTAP file systems to achieve lower RPOs.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T14:55:03.429272"}}
{"question": "What encrypts the data transferred between the source and destination in AWS DataSync?", "answer": "The data is encrypted via Transport Layer Security (TLS).", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-11T14:55:07.367511"}}
{"question": "How does configuring a bandwidth limit for an AWS DataSync task reduce its impact on other clients?", "answer": "By limiting the I/O against your storage system, configuring a bandwidth limit reduces the impact on other clients who rely on the same network connection.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-11T14:55:07.367854"}}
{"question": "What encryption options does AWS DataSync support for different types of storage?", "answer": "AWS DataSync supports default encryption for S3 buckets, Amazon EFS file system encryption of data at rest, and Amazon FSx encryption at rest and in transit.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-20", "source_tokens": 448, "generated_at": "2026-02-11T14:55:07.368281"}}
{"question": "What role does the AWS DataSync agent play when accessing a Hadoop cluster?", "answer": "The AWS DataSync agent acts as an HDFS client and communicates with the NameNodes and DataNodes in your Hadoop cluster to copy files and folders to or from HDFS.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-11T14:55:12.692641"}}
{"question": "Why is an agent required when using Basic mode tasks in AWS DataSync for accessing Azure Blob Storage?", "answer": "An agent is required when using Basic mode tasks because DataSync authenticates to your Azure container using a SAS token that is specified when creating a DataSync Azure Blob location.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-11T14:55:12.692978"}}
{"question": "How does the use of VPC endpoints in AWS DataSync differ from routing through a firewall using standard network ports when copying data to or from on-premises?", "answer": "When using VPC endpoints, data transferred between the DataSync agent and AWS services does not need to traverse the public internet or require public IP addresses. This is different from routing through a firewall using standard network ports, where data still needs to go through the public internet.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-21", "source_tokens": 462, "generated_at": "2026-02-11T14:55:12.693485"}}
{"question": "Which AWS Regions can I choose to have my DataSync agent connect to?", "answer": "You can choose to have your DataSync agent connect to public internet facing endpoints, Federal Information Processing Standards (FIPS) validated endpoints, or endpoints within one of your VPCs.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-11T14:55:18.137851"}}
{"question": "How does AWS ensure the security of DataSync?", "answer": "AWS DataSync has been assessed to meet various global and industry security standards such as PCI DSS, ISO 9001, 27001, 27017, and 27018; SOC 1, 2, and 3; and is HIPAA eligible. It is also authorized in the AWS US East/West Regions under FedRAMP Moderate and in the AWS GovCloud (US) Regions under FedRamp High.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-11T14:55:18.138262"}}
{"question": "What is the difference between using a public internet facing DataSync endpoint and a VPC endpoint?", "answer": "Public internet facing endpoints are accessible from the internet, while VPC endpoints are only accessible within your VPC.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-22", "source_tokens": 470, "generated_at": "2026-02-11T14:55:18.138644"}}
{"question": "What regions has AWS DataSync received a Provisional Authority to Operate (P-ATO) from FedRAMP for?", "answer": "AWS DataSync has received a P-ATO from FedRAMP for the US East/West Regions at the Moderate baseline and the US GovCloud Region at the High baseline.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T14:55:23.463829"}}
{"question": "How does AWS DataSync ensure security during data transfer?", "answer": "AWS DataSync ensures security during data transfer by using TLS encryption for all data transferred between the source and destination, enabling VPC endpoints to prevent data from traversing the public internet, and integrating with AWS security mechanisms such as IAM roles.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T14:55:23.464123"}}
{"question": "How does the security of AWS DataSync compare to data transfer using a regular HTTPS connection?", "answer": "AWS DataSync provides end-to-end security during data transfer by using TLS encryption, VPC endpoints, and AWS security mechanisms, whereas a regular HTTPS connection only encrypts the data during transmission, not the data at rest or in transit between the source and the AWS storage service.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T14:55:23.464569"}}
{"question": "Which AWS services can be used for copying objects between Amazon S3 buckets?", "answer": "AWS DataSync, S3 Replication, and S3 Batch Operations can be used for copying objects between Amazon S3 buckets.", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-11T14:55:29.505989"}}
{"question": "What are the ideal use cases for AWS DataSync and AWS Snowball Edge for data transfer?", "answer": "AWS DataSync is ideal for online data transfers, such as migrating active data to AWS, transferring data to the cloud for analysis and processing, archiving data to free up on-premises storage capacity, or replicating data to AWS for business continuity. AWS Snowball Edge is ideal for offline data transfers, for customers who are bandwidth constrained, or transferring data from remote, disconnected, or austere environments.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-11T14:55:29.506283"}}
{"question": "How does AWS DataSync compare to AWS S3 Replication for transferring objects between Amazon S3 buckets?", "answer": "AWS DataSync and S3 Replication are different services for transferring objects between Amazon S3 buckets. AWS DataSync is ideal for online data transfers and offers features like accelerated data transfer, ongoing data distribution, and data lake ingest. S3 Replication is ideal for continuous replication of data to a specific destination bucket.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-24", "source_tokens": 457, "generated_at": "2026-02-11T14:55:29.506471"}}
{"question": "What service should I use for transferring large files to S3 with higher throughput if my applications are already integrated with the Amazon S3 API?", "answer": "S3 Transfer Acceleration", "question_type": "factual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-11T14:55:35.179187"}}
{"question": "How can AWS DataSync simplify and automate data transfer compared to using traditional methods like SFTP and NFS?", "answer": "AWS DataSync provides built-in retry and network resiliency mechanisms, data integrity verification, and flexible configuration options like bandwidth throttling. It also supports various file systems and storage types, making it ideal for online migrations, timely transfers, and replication.", "question_type": "conceptual", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-11T14:55:35.179530"}}
{"question": "What are the main differences between S3 Transfer Acceleration and AWS DataSync in terms of use cases and supported features?", "answer": "S3 Transfer Acceleration is designed for higher throughput when transferring large files to S3, assuming your applications are already integrated with the Amazon S3 API. AWS DataSync, on the other hand, supports various file systems and storage types, including NFS servers, SMB file shares, Hadoop clusters, and self-managed or cloud object storage. It also provides additional features like data integrity verification, bandwidth throttling, and automation capabilities.", "question_type": "comparison", "metadata": {"service": "DATASYNC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "datasync-faq-25", "source_tokens": 289, "generated_at": "2026-02-11T14:55:35.179926"}}
{"question": "What does Amazon Detective do for security investigations?", "answer": "Amazon Detective simplifies the investigative process and helps security teams conduct faster and more effective investigations by automatically collecting log data from AWS resources, using machine learning, statistical analysis, and graph theory to build a linked set of data, and providing prebuilt data aggregations, summaries, and context to help determine the nature and extent of possible security issues.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-11T14:55:41.688721"}}
{"question": "How does Amazon Detective support security teams in their investigations?", "answer": "Amazon Detective provides security teams with simplified investigative processes and faster, more effective investigations by automatically collecting and analyzing log data from AWS resources, offering prebuilt data aggregations, summaries, and context, and maintaining up to a year of aggregated data for easy analysis.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-11T14:55:41.688980"}}
{"question": "What are the main differences between Amazon Detective for AWS Security Hub and Amazon Detective for Amazon Security Lake?", "answer": "Both Amazon Detective for AWS Security Hub and Amazon Detective for Amazon Security Lake help security teams analyze log data for potential security issues using machine learning and statistical analysis. However, Amazon Detective for AWS Security Hub integrates directly with AWS Security Hub, allowing users to centrally manage security and compliance across their AWS environment. Amazon Detective for Amazon Security Lake, on the other hand, provides a centralized, serverless data lake where you can perform analytics using various SQL-based query engines or tools like Amazon Athena.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-0", "source_tokens": 357, "generated_at": "2026-02-11T14:55:41.689344"}}
{"question": "What types of time-based events can Amazon Detective extract from various AWS services?", "answer": "Amazon Detective can extract time-based events such as login attempts, API calls, and network traffic from AWS CloudTrail, Amazon VPC Flow Logs, Amazon GuardDuty findings, AWS Security Hub findings, and Amazon Elastic Kubernetes Service audit logs.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T14:55:47.044534"}}
{"question": "How does Amazon Detective help in investigating AWS Security Findings?", "answer": "Amazon Detective creates a behavior graph using machine learning to provide a unified, interactive view of resource behaviors and their interactions over time. By exploring the behavior graph, you can analyze security events and find groups of related security findings and resources to help investigate the root cause of AWS Security Findings.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T14:55:47.044765"}}
{"question": "What is the difference between investigating individual security findings and using finding groups in Amazon Detective?", "answer": "Investigating individual security findings separately requires more triage time, while finding groups offer a more complete understanding of the potential security incident by grouping related findings and resources together. Findings groups also provide interactive visualizations that help explore specific findings and insights in natural language.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T14:55:47.044960"}}
{"question": "What type of data does Amazon Detective ingest for analysis?", "answer": "Amazon Detective ingests data from AWS CloudTrail logs, Amazon VPC Flow Logs, Amazon Elastic Kubernetes Service (Amazon EKS) audit logs, Amazon GuardDuty findings, and findings sent from integrated AWS services to AWS Security Hub.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:55:51.775138"}}
{"question": "How does Amazon Detective help in investigating AWS IAM entities?", "answer": "Amazon Detective helps in investigating AWS IAM entities by querying your behavior graph and using machine learning to identify if the IAM entity exhibits anomalous behavior or shows indicators of compromise.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:55:51.775487"}}
{"question": "How does the pricing of Amazon Detective compare between different AWS regions?", "answer": "Amazon Detective pricing is region-specific, and you are charged per Gigabyte (GB) ingested per account/region/month. Therefore, the cost may vary between different AWS regions.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T14:55:51.775933"}}
{"question": "What data sources does Amazon Detective support for summaries and analytical data?", "answer": "Amazon Detective supports summaries and analytical data from Amazon Virtual Private Cloud (Amazon VPC) Flow Logs, AWS CloudTrail logs, Amazon Elastic Kubernetes Service (Amazon EKS) audit logs, AWS Security Hub findings, and Amazon GuardDuty findings.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:55:57.145603"}}
{"question": "How does Amazon Detective improve the security experience when used with Amazon GuardDuty?", "answer": "Amazon Detective enhances the security experience when used with Amazon GuardDuty by providing detailed summaries, analysis, and visualizations of the behaviors and interactions amongst AWS accounts, EC2 instances, AWS users, roles, and IP addresses. This information can help in understanding security issues or operational account activity.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:55:57.145848"}}
{"question": "What is the difference between Amazon Detective's recent activity analysis and historical baseline comparisons?", "answer": "Amazon Detective's recent activity analysis provides summaries and analytics on the most recent data, while historical baseline comparisons establish a baseline after two weeks of account monitoring and compare recent activity against that baseline.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:55:57.146256"}}
{"question": "What data sources does Amazon Detective process to analyze security data?", "answer": "Amazon Detective processes data from AWS CloudTrail logs, Amazon VPC Flow Logs, Amazon EKS audit logs, findings sent from integrated AWS services to AWS Security Hub, and Amazon GuardDuty findings.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-11T14:56:02.736286"}}
{"question": "How does Amazon Detective simplify investigating security findings?", "answer": "Amazon Detective simplifies investigating security findings by automatically creating a graph model from trillions of events across multiple data sources, providing a unified, interactive view of resources, users, and interactions.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-11T14:56:02.736626"}}
{"question": "What's the difference between Amazon Detective and Amazon GuardDuty for analyzing security data?", "answer": "Amazon Detective analyzes data from multiple AWS services, including Amazon VPC Flow Logs, AWS CloudTrail logs, Amazon EKS audit logs, findings sent from integrated AWS services to AWS Security Hub, and Amazon GuardDuty findings, to provide a unified view of resources, users, and interactions. Amazon GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect AWS accounts and workloads.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-4", "source_tokens": 498, "generated_at": "2026-02-11T14:56:02.737117"}}
{"question": "Which services does Amazon Detective integrate with for cross-service user workflows?", "answer": "Amazon Detective integrates with Amazon GuardDuty, AWS Security Hub, and Amazon Security Lake for cross-service user workflows.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T14:56:07.257478"}}
{"question": "How does Amazon Detective enable investigation for findings from integrated AWS services?", "answer": "Amazon Detective automatically ingests security findings forwarded from integrated AWS services to AWS Security Hub and adds them to the graph for investigation.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T14:56:07.257759"}}
{"question": "What services can you conduct investigations for in Amazon Detective, given that you have Security Hub enabled?", "answer": "You can conduct investigations for AWS Config, AWS Firewall Manager, Amazon GuardDuty, AWS Health, AWS Identity and Access Management Access Analyzer, Amazon Inspector, AWS IoT Device Defender, Amazon Macie, and AWS Systems Manager Patch Manager in Amazon Detective.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T14:56:07.257909"}}
{"question": "What does enabling AWS security findings do for Amazon Detective?", "answer": "Enabling AWS security findings as a data source for Amazon Detective allows the service to access and analyze security findings from your AWS account. This is a required step for using Amazon Detective with AWS security services.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-11T14:56:12.306871"}}
{"question": "How does the consumption of AWS security findings by Amazon Detective impact AWS security services performance and costs?", "answer": "Amazon Detective consumption of AWS security findings is designed not to affect the performance of your AWS security services, as it uses independent and duplicative log streams. Additionally, the consumption of AWS security findings by Amazon Detective does not increase your costs for using AWS Security Hub or any integrated AWS security service.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-11T14:56:12.307119"}}
{"question": "How does the pricing of Amazon Detective for AWS security findings compare to the pricing of directly using AWS Security Hub?", "answer": "Amazon Detective consumption of AWS security findings is priced based on the volume of findings processed and analyzed by Amazon Detective, while the cost of using AWS Security Hub and integrated AWS security services remains the same.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-6", "source_tokens": 279, "generated_at": "2026-02-11T14:56:12.307518"}}
{"question": "What services does Amazon Detective retrieve logs from after integration?", "answer": "Amazon Detective can query and retrieve AWS CloudTrail logs and Amazon VPC Flow Logs from Amazon Security Lake for security investigations.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-11T14:56:17.222241"}}
{"question": "Why can using Amazon Detective and Amazon Security Lake together help with security investigations?", "answer": "Using Amazon Detective and Amazon Security Lake together allows you to start investigations in Amazon Detective, preview or download specific AWS CloudTrail logs or Amazon VPC Flow Logs for additional details, and eliminates the need to craft SQL queries from scratch and preview and download results without leaving the Amazon Detective console.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-11T14:56:17.222595"}}
{"question": "What are the differences in charges between using Amazon Detective and Amazon Security Lake individually compared to using them together?", "answer": "You will be charged for each service according to Amazon Detective pricing and Amazon Security Lake pricing, as well as for each query using Amazon Athena and the additional AWS services deployed in your account to support the integration.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-7", "source_tokens": 509, "generated_at": "2026-02-11T14:56:17.222987"}}
{"question": "What data sources does Amazon Detective use for Amazon EKS audit logs?", "answer": "Amazon Detective uses Amazon EKS audit logs as a data source for analysis.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-11T14:56:21.653405"}}
{"question": "How does Amazon Detective's analysis of Amazon EKS audit logs impact performance and costs?", "answer": "Amazon Detective's consumption of Amazon EKS audit logs does not impact the performance of your Amazon EKS workloads and is priced based on the volume of logs processed and analyzed.", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-11T14:56:21.653657"}}
{"question": "How does the pricing for Amazon Detective's consumption of Amazon EKS audit logs compare to the cost of storing the logs manually?", "answer": "Amazon Detective's consumption of Amazon EKS audit logs is a paid service priced based on the volume processed and analyzed, whereas manually storing the logs incurs separate costs for storage and retrieval.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-8", "source_tokens": 445, "generated_at": "2026-02-11T14:56:21.654037"}}
{"question": "What types of Amazon EKS deployments can Detective provide visibility for?", "answer": "Detective currently supports Amazon EKS deployments running on EC2 instances in an AWS account.", "question_type": "factual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-11T14:56:25.717803"}}
{"question": "In what ways can Detective monitor Kubernetes environments?", "answer": "Detective provides support for Amazon EKS on EC2 instances, Amazon GuardDuty EKS Runtime Monitoring, and Amazon ECS Runtime monitoring (including Amazon ECS on Fargate).", "question_type": "conceptual", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-11T14:56:25.718024"}}
{"question": "How does Detective's visibility for managed Kubernetes differ from non-managed Kubernetes on EC2?", "answer": "Detective currently provides visibility for managed Kubernetes running on EC2 instances in the AWS account, but it does not support non-managed Kubernetes on EC2 or any Kubernetes running on ES.", "question_type": "comparison", "metadata": {"service": "DETECTIVE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "detective-faq-9", "source_tokens": 79, "generated_at": "2026-02-11T14:56:25.718393"}}
{"question": "What devices are used for testing in AWS Device Farm?", "answer": "AWS Device Farm uses a mixture of OEM and carrier-branded real devices for testing.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T14:56:30.307305"}}
{"question": "How does AWS Device Farm benefit developers and QA teams?", "answer": "AWS Device Farm accelerates the development process by executing tests on multiple devices, allowing developers and QA teams to perform automated tests, reproduce customer issues, and execute manual test plans, while also eliminating the need for internal device labs and saving significant costs.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T14:56:30.307619"}}
{"question": "How does testing on real devices in AWS Device Farm compare to testing on emulators?", "answer": "Testing on real devices in AWS Device Farm provides more accurate results compared to testing on emulators, as it accounts for differences in device models, variations in firmware and OS versions, carrier and manufacturer customizations, and dependencies on remote services and other apps.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T14:56:30.308060"}}
{"question": "What is the default duration for which apps and test packages are kept in AWS Device Farm?", "answer": "Apps and test packages are automatically removed after 30 days.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:56:36.609895"}}
{"question": "Why should users avoid providing sensitive information during automated tests and remote access sessions in AWS Device Farm?", "answer": "It is recommended that users avoid providing sensitive information such as account info, personal information, and other security-sensitive details during their automated test and remote access sessions due to the possibility of data persisting between sessions and video and log recordings.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:56:36.610141"}}
{"question": "What are the differences in the cleanup process on iOS and Android devices in AWS Device Farm?", "answer": "On iOS devices, the embedded provisioning profile is replaced with a wildcard profile, and auxiliary data is added to the application package before installation. Resigning the iOS app results in the removal of certain entitlements like App Group, Associated Domains, Game Center, HealthKit, HomeKit, Wireless Accessory Configuration, In-App Purchase, Inter-App Audio, Apple Pay, Push Notifications, and VPN Configuration & Control. On Android devices, the app is resigned, which may break functionality that depends on the app signature and trigger anti-piracy and anti-tamper detection. For built-in tests, the manifest is modified to include permissions required to capture and save screenshots.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:56:36.610330"}}
{"question": "Which operating systems does AWS Device Farm support for Remote Access?", "answer": "AWS Device Farm supports Android, iOS, and Fire OS for Remote Access.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T14:56:40.621946"}}
{"question": "How does AWS Device Farm determine which devices to use for Automated Testing?", "answer": "AWS Device Farm uses device pools for Automated Testing. Tests will be run against all devices in the specified pool that are compatible with your application and tests.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T14:56:40.622191"}}
{"question": "What are the differences between testing on devices with and without network shaping in AWS Device Farm?", "answer": "Testing on devices with network shaping in AWS Device Farm allows you to simulate various connection types and conditions, providing more comprehensive testing. Devices without network shaping do not offer this functionality.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T14:56:40.622621"}}
{"question": "Which device cameras can be used in AWS Device Farm?", "answer": "Both front- and rear-facing device cameras can be used in AWS Device Farm.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:56:44.704846"}}
{"question": "How does AWS Device Farm help in testing app UI?", "answer": "AWS Device Farm performs fuzz testing on your app's UI immediately after launch, streaming random user input to simulate various interactions.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:56:44.705074"}}
{"question": "What's the difference between using Appium Java JUnit and Appium Java TestNG in AWS Device Farm?", "answer": "Both are Java-based frameworks supported by AWS Device Farm for testing mobile apps. The main difference is that Appium Java TestNG supports testNG annotations, while Appium Java JUnit supports JUnit annotations.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T14:56:44.705235"}}
{"question": "What is the maximum size of a .zip archive that can be uploaded to AWS Device Farm?", "answer": "The maximum size of a .zip archive that can be uploaded to AWS Device Farm is 4 GB.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-11T14:56:49.187476"}}
{"question": "Why would you override the default GPS setting on a device during testing?", "answer": "You might want to override the default GPS setting on a device during testing to simulate a specific location for testing location-based features or apps.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-11T14:56:49.187723"}}
{"question": "How does the test report generation and download process compare between AWS Device Farm and a local testing solution?", "answer": "Both AWS Device Farm and a local testing solution generate test reports. However, AWS Device Farm automatically queues tests for execution and provides test reports containing detailed per-device data and high-level results, while a local testing solution would require you to execute tests manually and generate reports manually.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-4", "source_tokens": 493, "generated_at": "2026-02-11T14:56:49.188109"}}
{"question": "What type of logs are included in AWS Device Farm reports?", "answer": "AWS Device Farm reports include complete logcat (Android) and device logs (iOS), as well as logs from the device host and specified test framework.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-11T14:56:53.700504"}}
{"question": "Why would log entries be included in AWS Device Farm reports when written to logcat (Android) or device log (iOS)?", "answer": "Log entries are included in AWS Device Farm reports when written to logcat (Android) or the device log (iOS) because AWS Device Farm collects these logs as part of the report.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-11T14:56:53.700815"}}
{"question": "How does AWS Device Farm pricing compare for the free trial and standard rate per device minute?", "answer": "During the free trial, customers receive 1000 device minutes at no cost. After the trial, customers are charged $0.17 per device minute under the standard rate.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-5", "source_tokens": 449, "generated_at": "2026-02-11T14:56:53.700967"}}
{"question": "What is the cost of an unmetered device slot per month?", "answer": "$250", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:56:57.909326"}}
{"question": "How does the number of device slots purchased impact the execution of tests or remote access sessions?", "answer": "The number of device slots purchased determines the maximum number of tests or remote access sessions that can be run concurrently. Purchasing more slots enables faster results.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:56:57.909590"}}
{"question": "What is the difference between unmetered and metered billing in terms of device usage and flexibility?", "answer": "Unmetered billing is based on the number of device slots purchased and is a flat rate, whereas metered billing charges per device minute used. With metered billing, there is no limit to concurrency, providing greater flexibility for running tests or accessing devices.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T14:56:57.909967"}}
{"question": "Which browsers are hosted on EC2 Windows instances in AWS Device Farm?", "answer": "All browsers are hosted on EC2 Windows instances which run on Microsoft Windows Server.", "question_type": "factual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-11T14:57:02.717627"}}
{"question": "How does the execution model work for Selenium testing on Device Farm?", "answer": "Device Farm follows a client-side execution model for Selenium testing, meaning your tests execute on your own local machine but interact with browsers hosted on AWS Device Farm through the Selenium API.", "question_type": "conceptual", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-11T14:57:02.717894"}}
{"question": "How does the pricing for Desktop Browser Testing on Device Farm compare to mobile device testing?", "answer": "Pricing is based on instance minutes, which are determined by the duration of tests on each selected browser instance. The unit price is $0.005 per browser instance minute for Desktop Browser Testing and may vary for mobile device testing, as it follows a server-side execution model and requires you to upload your tests to the service.", "question_type": "comparison", "metadata": {"service": "DEVICE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "device-faq-7", "source_tokens": 489, "generated_at": "2026-02-11T14:57:02.718322"}}
{"question": "What is the main function of AWS DevOps Guru?", "answer": "AWS DevOps Guru is a machine learning (ML) powered service designed to help improve an applicationâ€™s operational performance and availability. It detects behaviors that deviate from normal operating patterns and alerts users of critical issues, providing a summary of related anomalies, context for when and where the issue occurred, and recommendations on how to remediate the issue.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-11T14:57:08.864054"}}
{"question": "How does AWS DevOps Guru help users identify operational issues?", "answer": "AWS DevOps Guru uses ML models informed by years of Amazon.com and AWS operational excellence to help identify anomalous application behavior, such as increased latency, error rates, resource constraints, and others. It also provides recommendations on how to remediate the issue and reduce application downtime.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-11T14:57:08.864308"}}
{"question": "What are the main differences between Amazon DevOps Guru for RDS and DevOps Guru for Serverless?", "answer": "Both Amazon DevOps Guru for RDS and DevOps Guru for Serverless are services offered by AWS DevOps Guru, but they are designed for different use cases. DevOps Guru for RDS is designed specifically for Amazon RDS databases, while DevOps Guru for Serverless is designed for applications built using AWS Lambda and other serverless technologies.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-0", "source_tokens": 407, "generated_at": "2026-02-11T14:57:08.864703"}}
{"question": "What resources does DevOps Guru analyze when the coverage boundary is set to an entire AWS account?", "answer": "DevOps Guru analyzes all supported AWS resources in the chosen coverage boundary when the boundary is set to an entire AWS account.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:57:13.696858"}}
{"question": "How does DevOps Guru help operators when it identifies anomalous application behavior?", "answer": "DevOps Guru helps operators by alerting them with issue details like the resources involved, the issue timeline, and other related events when it identifies anomalous application behavior. It also provides options for remediation or mitigation.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:57:13.697133"}}
{"question": "What's the difference between enabling DevOps Guru analysis for an entire AWS account and for specific CloudFormation stacks?", "answer": "Enabling DevOps Guru analysis for an entire AWS account means that it analyzes all supported AWS resources in your account, whereas analyzing specific CloudFormation stacks means that it only analyzes the resources within those stacks.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-1", "source_tokens": 473, "generated_at": "2026-02-11T14:57:13.697514"}}
{"question": "What metrics and logs does Amazon DevOps Guru analyze to detect operational issues?", "answer": "Amazon DevOps Guru analyzes metrics and logs from Amazon CloudWatch, AWS Config, AWS System Manager OpsCenter, AWS CloudFormation, and AWS X-Ray to detect operational issues.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-11T14:57:19.725196"}}
{"question": "In what ways does Amazon DevOps Guru reduce false and redundant alarms?", "answer": "Amazon DevOps Guru reduces false and redundant alarms by correlating and grouping related application and infrastructure metrics, such as web application latency spikes, running out of disk space, bad code deployments, or memory leaks.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-11T14:57:19.725540"}}
{"question": "How does Amazon DevOps Guru compare to AWS Systems Manager OpsCenter in terms of operational insights?", "answer": "Amazon DevOps Guru and AWS Systems Manager OpsCenter both provide operational insights. Amazon DevOps Guru uses machine learning to correlate anomalies in metrics and logs with operational events and provides contextual insights to help remediation steps. AWS Systems Manager OpsCenter displays operational data in real time and allows users to interactively investigate and respond to operational issues. Both services can integrate with each other, with DevOps Guru operational insights being surfaced directly within the OpsCenter dashboard as OpsItems.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-2", "source_tokens": 465, "generated_at": "2026-02-11T14:57:19.725913"}}
{"question": "What is the time range for Amazon DevOps to baseline an application?", "answer": "The time range for Amazon DevOps to baseline an application can range from minutes to an hour, depending on the number of resources being analyzed.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-11T14:57:24.274162"}}
{"question": "How does Amazon DevOps Guru for RDS help database administrators?", "answer": "Amazon DevOps Guru for RDS helps database administrators by automatically detecting and diagnosing performance and operational issues within a database, sending alerts, explaining findings, and recommending actions to resolve issues, making database administration more accessible to non-experts and assisting database experts.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-11T14:57:24.274570"}}
{"question": "What does Amazon DevOps Guru for RDS analyze to detect issues?", "answer": "Amazon DevOps Guru for RDS analyzes telemetry data collected by Amazon RDS Performance Insights to detect problematic patterns and alarms customers when such patterns are detected.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-3", "source_tokens": 442, "generated_at": "2026-02-11T14:57:24.275000"}}
{"question": "What services does Amazon DevOps Guru support for performance monitoring and issue detection?", "answer": "Amazon DevOps Guru supports Amazon RDS, Amazon Aurora, and Serverless Applications built using AWS resources for performance monitoring and issue detection.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-11T14:57:29.434515"}}
{"question": "How does Amazon DevOps Guru for RDS identify performance issues in Amazon RDS databases?", "answer": "Amazon DevOps Guru for RDS identifies performance issues in Amazon RDS databases by monitoring performance metrics and analyzing the data to detect issues such as lock pile ups, connection storms, SQL regressions, CPU and I/O contention, memory issues, or misconfigured parameters.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-11T14:57:29.434811"}}
{"question": "What are the key differences between Amazon DevOps Guru for RDS and Amazon DevOps Guru for Serverless?", "answer": "Amazon DevOps Guru for RDS is designed for performance monitoring and issue detection in Amazon RDS databases. Amazon DevOps Guru for Serverless is designed for performance and operational issue detection and diagnosis for Serverless Applications.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-4", "source_tokens": 491, "generated_at": "2026-02-11T14:57:29.435210"}}
{"question": "What are the requirements to use Amazon DevOps Guru for Serverless?", "answer": "No manual setup, ML expertise, or deep serverless expertise is required. Enabling Amazon DevOps Guru on the AWS Account for your serverless application gets you started.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-11T14:57:34.160949"}}
{"question": "How does Amazon DevOps Guru for Serverless help in resolving operational issues for serverless applications?", "answer": "Amazon DevOps Guru for Serverless analyzes metrics and logs for all resources of the serverless application to detect deviations from normal operating bounds and alerts operators with relevant details and remediation options.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-11T14:57:34.161243"}}
{"question": "What's the difference between manually setting the coverage boundary and using AWS tags for resource grouping in Amazon DevOps Guru for Serverless?", "answer": "Manually setting the coverage boundary involves enabling Amazon DevOps Guru for an entire AWS account, while using AWS tags for resource grouping allows for specific CloudFormation stacks to be analyzed.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-5", "source_tokens": 299, "generated_at": "2026-02-11T14:57:34.161688"}}
{"question": "What type of issue does DevOps Guru for Serverless detect regarding underutilized resources?", "answer": "DevOps Guru for Serverless detects that the application has resources, such as DynamoDB, that have provisioned capacity units which are significantly over what is actually consumed.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:57:40.145516"}}
{"question": "How does DevOps Guru for Serverless help in reducing potential issues with applications and infrastructure?", "answer": "DevOps Guru for Serverless uses Machine Learning to detect potential issues early, such as resources setup not following AWS best practices or resources reaching their limit, and provides contextual insights and recommendations to help users respond quickly and reduce costly downtime or operating costs.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:57:40.145772"}}
{"question": "How does the resource utilization issue detection in DevOps Guru for Serverless compare to the resource exhaustion issue detection?", "answer": "Both resource utilization and resource exhaustion issue detections are proactive insights provided by DevOps Guru for Serverless. The resource utilization detection identifies resources with provisioned capacity units that are significantly over what is actually consumed, and recommends scaling back the resources to save costs. The resource exhaustion detection identifies resources reaching their limit based on the application usage trends and predicts when the limit will be hit, and recommends fixing the issue to prevent potential downtime.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-6", "source_tokens": 440, "generated_at": "2026-02-11T14:57:40.146186"}}
{"question": "What determines the bill for using Amazon DevOps Guru?", "answer": "The bill for using Amazon DevOps Guru is determined by charges for AWS resource analysis and charges for DevOps Guru API calls.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T14:57:43.946469"}}
{"question": "How does DevOps Guru determine which AWS resources to analyze?", "answer": "DevOps Guru analyzes the operational data for all supported AWS resources within the specified resource analysis coverage boundary.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T14:57:43.946758"}}
{"question": "How does the pricing for Amazon DevOps Guru differ between resource types in pricing groups A and B?", "answer": "The pricing for Amazon DevOps Guru varies between resource types in pricing groups A and B, but the text does not provide specific information on the differences.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T14:57:43.947141"}}
{"question": "What is the pricing for Group A resources in DevOps Guru?", "answer": "Group A resources in DevOps Guru are priced at $0.0028 per resource per hour.", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-11T14:57:48.991314"}}
{"question": "How does the pricing model for Group A and Group B resources in DevOps Guru differ?", "answer": "Group A resources, which include AWS Lambda and Amazon S3, are priced lower than Group B resources, which include Amazon RDS, Amazon EC2, and other AWS resources, at $0.0028 per hour compared to $0.0042 per hour, respectively.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-11T14:57:48.991541"}}
{"question": "What resources does Group B in DevOps Guru include and how does the cost of analyzing these resources differ from Group A?", "answer": "Group B in DevOps Guru includes Amazon RDS, Amazon EC2, Amazon Redshift clusters, and 25 other AWS resource types. The cost of analyzing these resources is higher than Group A, at $0.0042 per hour.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-8", "source_tokens": 382, "generated_at": "2026-02-11T14:57:48.991686"}}
{"question": "In which AWS regions is Amazon DevOps Guru currently available?", "answer": "Amazon DevOps Guru is available in the following AWS regions: US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (London), Europe (Paris), Asia Pacific (Mumbai), Asia Pacific (Seoul), South America (SÃ£o Paulo), Asia Pacific (Singapore), Asia Pacific (Sydney), and Asia Pacific (Tokyo).", "question_type": "factual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-11T14:57:54.505271"}}
{"question": "Why are there different AWS regions available for Amazon DevOps Guru?", "answer": "Amazon DevOps Guru is available in multiple AWS regions to provide users with location options for deploying and managing their applications.", "question_type": "conceptual", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-11T14:57:54.505555"}}
{"question": "How does the availability of Amazon DevOps Guru in multiple regions compare to a single region?", "answer": "Having Amazon DevOps Guru available in multiple regions allows users to deploy and manage their applications in a region that best suits their geographical and performance requirements, whereas a single region limits users to the services and performance available in that specific location.", "question_type": "comparison", "metadata": {"service": "DEVOPS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "devops-faq-9", "source_tokens": 133, "generated_at": "2026-02-11T14:57:54.506077"}}
{"question": "What are some AWS services that can be used with AWS Direct Connect?", "answer": "Amazon Elastic Compute Cloud (EC2), Amazon Virtual Private Cloud (VPC), Amazon Simple Storage Service (S3), Amazon DynamoDB, and all other AWS services can be used with AWS Direct Connect.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T14:58:01.320491"}}
{"question": "What is the purpose of AWS Direct Connect SiteLink and how does it contribute to the high availability and resilience of AWS Direct Connect?", "answer": "AWS Direct Connect SiteLink is a feature that lets you establish multiple dedicated connections from the same location to multiple AWS Direct Connect destinations. This feature increases the availability and resilience of your AWS Direct Connect connections by allowing you to establish multiple connections to different AWS services or regions. If one connection goes down, traffic can be automatically rerouted to another connection.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T14:58:01.320738"}}
{"question": "How does AWS Transit Gateway support compare to Link Aggregation Groups in terms of handling multiple VPCs and AWS services in AWS Direct Connect?", "answer": "Link Aggregation Groups allow you to combine multiple dedicated connections into a single logical connection for increased bandwidth. They do not support routing traffic between multiple VPCs or AWS services in the same or different regions. AWS Transit Gateway, on the other hand, is a networking component that enables you to connect and manage multiple VPCs and AWS services within a single hub. It allows you to route traffic between VPCs and AWS services using IP addresses and allows for central control and monitoring of traffic.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T14:58:01.321220"}}
{"question": "Which AWS tab should I use to create a new AWS Direct Connect connection?", "answer": "The AWS Management Console's AWS Direct Connect tab", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:58:04.981660"}}
{"question": "What role can AWS Direct Connect Partners play in setting up a connection to AWS?", "answer": "AWS Direct Connect Partners can help extend your office or data center network to a AWS Direct Connect location", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:58:04.981953"}}
{"question": "What's the difference between a public virtual interface and a private virtual interface in AWS Direct Connect?", "answer": "A public virtual interface enables access to public services, such as Amazon S3. A private virtual interface enables access to your VPC", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-1", "source_tokens": 481, "generated_at": "2026-02-11T14:58:04.982334"}}
{"question": "What protocol does AWS Direct Connect use for link aggregation?", "answer": "Link aggregation control protocol (LACP)", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:58:09.391146"}}
{"question": "How does a link aggregation group simplify configuration in AWS Direct Connect?", "answer": "A link aggregation group (LAG) allows multiple dedicated connections at a single AWS Direct Connect endpoint to be treated as a single managed connection, making the configuration simpler.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:58:09.391488"}}
{"question": "What is the difference between using one LAG and multiple LAGs in AWS Direct Connect?", "answer": "Using a single LAG allows multiple dedicated connections to be treated as a single managed connection, streamlining configuration. Using multiple LAGs enables improved failover times between paths due to bidirectional forwarding detection (BFD) support and achieving the appropriate number of dedicated connections in multiple locations using the AWS Direct Connect Resiliency Toolkit.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T14:58:09.391888"}}
{"question": "What ASN can be set on the AWS side of a BGP session for private or transit VIFs on an AWS Direct Connect Gateway?", "answer": "The ASN that can be set on the AWS side of a BGP session for private or transit VIFs on an AWS Direct Connect Gateway is a configurable private autonomous system number.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:58:15.043749"}}
{"question": "How can a transit virtual interface be used on an AWS Direct Connect connection?", "answer": "A transit virtual interface can be used on an AWS Direct Connect connection by creating it on an AWS Direct Connect gateway and attaching it to interface with up to six AWS Transit Gateways in any supported AWS Regions. It can only be used for establishing one IPv4 BGP session and one IPv6 BGP session over a single transit virtual interface.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:58:15.044036"}}
{"question": "How does multi-account support for AWS Direct Connect gateway differ from transit virtual interfaces?", "answer": "Multi-account support for AWS Direct Connect gateway allows up to 20 Amazon VPCs or up to six AWS Transit Gateways from multiple AWS accounts to be associated with an AWS Direct Connect gateway. Transit virtual interfaces, on the other hand, are used to create on an AWS Direct Connect gateway and attach to interface with up to six AWS Transit Gateways in any supported AWS Regions.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-3", "source_tokens": 394, "generated_at": "2026-02-11T14:58:15.044224"}}
{"question": "What does a LAG (Low Availability Gateway) not protect against in terms of AWS connectivity?", "answer": "A LAG does not protect against single device failure or device maintenance at AWS where your LAG is terminating.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:58:19.577720"}}
{"question": "How can I ensure high availability connectivity to AWS?", "answer": "You can achieve high availability connectivity to AWS by making connections at multiple AWS Direct Connect locations and following the resiliency best practices detailed in the AWS Direct Connect Resiliency Recommendations page.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:58:19.578005"}}
{"question": "What's the difference between having a backup AWS Direct Connect link and an IPsec VPN connection for AWS VPC traffic?", "answer": "A backup AWS Direct Connect link allows traffic to/from AWS resources to continue flowing during a failure, while an IPsec VPN connection routes traffic over the internet to public resources if the primary AWS Direct Connect link fails.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T14:58:19.578403"}}
{"question": "What is the minimum duration for a Border Gateway Protocol test?", "answer": "The minimum duration for a Border Gateway Protocol test is 1 minute.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-11T14:58:23.953000"}}
{"question": "Why is it necessary to enable AWS Direct Connect SiteLink at two or more VIFs?", "answer": "AWS Direct Connect SiteLink is a feature that enables you to establish a connection using AWS Direct Connect between two or more Virtual Interfaces (VIFs) at two or more AWS Direct Connect locations. It is necessary to enable AWS Direct Connect SiteLink at both VIFs to establish the connection.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-11T14:58:23.953279"}}
{"question": "How does the billing for AWS Direct Connect SiteLink differ from other AWS Direct Connect charges?", "answer": "On billing statements, charges related to AWS Direct Connect SiteLink will appear on a separate line from other AWS Direct Connect-related charges.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-5", "source_tokens": 493, "generated_at": "2026-02-11T14:58:23.953704"}}
{"question": "What is required to create a simple network using AWS Direct Connect SiteLink?", "answer": "To create a simple network using AWS Direct Connect SiteLink, you need to configure a private virtual interface (VIF) and enable the service on that VIF at each site. Then, create an AWS Direct Connect gateway and associate each of your SiteLink-enabled VIFs with it to create a network.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T14:58:29.887107"}}
{"question": "How does a hub-and-spoke architecture differ from a simple network using AWS Direct Connect SiteLink?", "answer": "In a hub-and-spoke architecture, you create an AWS Direct Connect gateway and associate it with all SiteLink-enabled private VIFs. This allows communication between all VIFs connected to the hub, whereas in a simple network, each gateway only communicates with its associated VIFs.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T14:58:29.887370"}}
{"question": " Which AWS Direct Connect services can be used with AWS Direct Connect SiteLink and which cannot?", "answer": "AWS Direct Connect SiteLink can be used with private and transit VIFs, but an AWS Direct Connect gateway cannot be attached to an AWS Transit Gateway if the Direct Connect gateway was previously associated with a virtual private gateway, or is attached to a private virtual interface.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T14:58:29.887734"}}
{"question": "What is the maximum MTU size for data packets traveling to an AWS Local Zone via an AWS Direct Connect link?", "answer": "The maximum MTU size for data packets traveling to an AWS Local Zone via an AWS Direct Connect link is 1468.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:58:35.713631"}}
{"question": "How does the routing process differ between connecting to an AWS Local Zone directly with AWS Direct Connect and connecting through a parent Region?", "answer": "When connecting directly to an AWS Local Zone with AWS Direct Connect, the data travels directly to and from the Local Zone over the connection, without entering the parent Region. In contrast, when connecting through a parent Region, the traffic enters the Region first, is processed, and then sent to the Local Zone. This can lead to increased latency.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:58:35.713880"}}
{"question": "What is the difference in single flow limits between connecting to an AWS Local Zone directly with AWS Direct Connect and connecting through a parent Region?", "answer": "The single flow limit (5-tuple) for connectivity to an AWS Local Zone directly with AWS Direct Connect is approximately 2.5 Gbps at the maximum MTU (1468), while the limit for connectivity through a parent Region is 5 Gbps. This difference in limits may impact the performance of certain applications.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T14:58:35.714027"}}
{"question": "What is the maximum number of links in a LAG group when using 1 or 10 Gbps connections?", "answer": "The maximum number of links in a LAG group is 4x.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-11T14:58:40.925221"}}
{"question": "Can you explain how the Link Aggregation Control Protocol (LACP) works in AWS Direct Connect?", "answer": "The LAG at your endpoint can be configured with LACP active or passive modes. The AWS side is always configured as active mode LACP. The ports send Link Aggregation Control Protocol Data Units (LACPDUs) continuously, which are in active/active mode.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-11T14:58:40.925625"}}
{"question": "What's the difference between the maximum number of links in a LAG group when using 1 or 10 Gbps connections versus 100 or 400 Gbps connections?", "answer": "The maximum number of links is 4x when using 1 or 10 Gbps connections and 2x when using 100 or 400 Gbps connections.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-8", "source_tokens": 508, "generated_at": "2026-02-11T14:58:40.926062"}}
{"question": "What types of ports support LAG in AWS Direct Connect?", "answer": "1, 10, 100, and 400 Gbps Dedicated Connection ports support LAG in AWS Direct Connect.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-11T14:58:45.110850"}}
{"question": "Can we create a LAG using different types of AWS Direct Connect devices?", "answer": "No, LAG can only include ports on the same AWS Direct Connect device. We donâ€™t support multi-chassis LAG.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-11T14:58:45.111192"}}
{"question": "How does the process of creating a LAG with multiple ports differ from creating a single port connection?", "answer": "When creating a LAG, you must request another port for each additional port in the LAG. If no ports are available on the same device, you must order a new LAG and migrate your connections. When creating a single port connection, there is no need to request additional ports or order new LAGs.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-9", "source_tokens": 508, "generated_at": "2026-02-11T14:58:45.111601"}}
{"question": "What are the two separate charges for AWS Direct Connect?", "answer": "AWS Direct Connect has two separate charges: port hours and data transfer.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:58:49.851459"}}
{"question": "How does AWS Direct Connect handle minimum links in a LAG?", "answer": "With AWS Direct Connect, you can set the minimum number of links that must be active in a bundle for the bundle to be active and pass traffic. If fewer than the minimum number of links are active, the bundle will not be active.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:58:49.851792"}}
{"question": "What's the difference between connecting a single 40 GE interface to a 4x 10 GE LAG and using 4x 10 GE interfaces directly to AWS?", "answer": "A single 40 GE interface connecting to a 4x 10 GE LAG is not supported. You need 4x 10 GE interfaces on your router to connect to AWS directly.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T14:58:49.852274"}}
{"question": "What label will I find on my bill for the port-hour charges of multiple 200 Mbps Hosted Connections at a single AWS Direct Connect location?", "answer": "The label will end with 'HCPortUsage:200M'.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-11T14:58:55.749953"}}
{"question": "How does AWS Direct Connect bill for Hosted Connection port hours?", "answer": "Port hours are billed once you have accepted the Hosted Connection and will continue as long as the Hosted Connection is provisioned. The billing is summarized under a single item with a label ending in 'HCPortUsage' and the capacity of the Hosted Connection.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-11T14:58:55.750282"}}
{"question": "What is the difference in labeling between the bill for a single 200 Mbps Hosted Connection and a bill for multiple 200 Mbps Hosted Connections at an AWS Direct Connect location?", "answer": "A single 200 Mbps Hosted Connection will have a label ending with 'HCPortUsage:200M', while multiple 200 Mbps Hosted Connections at a single location will have a label ending with 'HCPortUsage:200M' but the total hours billed will be the sum of all the hours for each connection.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-11", "source_tokens": 377, "generated_at": "2026-02-11T14:58:55.750705"}}
{"question": "Which AWS resources will lead to outbound Data Transfer Out (DTO) usage being metered towards the resource owner at the AWS Direct Connect data transfer rate if the outbound traffic is destined for public prefixes owned by the same AWS payer account and actively advertised to AWS through an AWS Direct Connect public virtual interface?", "answer": "For publicly addressable AWS resources such as Amazon S3 buckets, Classic EC2 instances, or EC2 traffic that goes through an internet gateway, the DTO usage will be metered towards the resource owner at the AWS Direct Connect data transfer rate if the outbound traffic is destined for public prefixes owned by the same AWS payer account and actively advertised to AWS through an AWS Direct Connect public virtual interface.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-11T14:59:02.963334"}}
{"question": "How does the AWS account responsibility for Data Transfer Out (DTO) charges differ between private and transit virtual interfaces in the context of AWS Direct Connect?", "answer": "For private virtual interfaces, the AWS account that owns the AWS resources responsible for the Data Transfer Out will be charged. For transit virtual interfaces, the AWS account that owns the Amazon Virtual Private Clouds attached to the AWS Transit Gateway associated with the AWS Direct Connect gateway attached to the transit virtual interface is charged.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-11T14:59:02.963664"}}
{"question": "What happens to the AWS Direct Connect data transfer usage and how is it aggregated?", "answer": "AWS Direct Connect transfers data out of AWS through the connections made at your AWS Direct Connect location. The data is not transferred over the internet. The AWS Direct Connect data transfer usage will be aggregated to your management account.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-12", "source_tokens": 444, "generated_at": "2026-02-11T14:59:02.964105"}}
{"question": "What should be done to cancel an AWS Direct Connect service?", "answer": "To cancel AWS Direct Connect, delete your ports from the AWS Management Console and contact the necessary providers to disconnect any associated cross-connects and network connectivity.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-11T14:59:07.464493"}}
{"question": "Why is it necessary to cancel services purchased by third parties when cancelling AWS Direct Connect?", "answer": "It is necessary to cancel services purchased by third parties when cancelling AWS Direct Connect because those services are associated with the AWS Direct Connect connection and will continue to be billed if not cancelled.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-11T14:59:07.464826"}}
{"question": "How does the number of routes advertised over a Border Gateway Protocol session impact the AWS Direct Connect connection?", "answer": "Advertising over 100 routes over a Border Gateway Protocol session will cause the connection to go down until the number of routes is reduced to less than 100.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-13", "source_tokens": 497, "generated_at": "2026-02-11T14:59:07.465028"}}
{"question": "What information is needed to complete an AWS Direct Connect connection using a custom ASN?", "answer": "To complete an AWS Direct Connect connection using a custom ASN, you need a public or private ASN, a new unused VLAN tag, and public IPs (/31 or /30) allocated to the BGP session.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-11T14:59:12.888274"}}
{"question": "How does AWS handle IP address allocation for a Direct Connect virtual interface connected to a VPC?", "answer": "If a virtual interface is connected to a VPC and you choose to have AWS automatically generate the peer IP CIDR, the IP address space for both ends of the connection is allocated by AWS and is in the 169.254.0.0/16 range.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-11T14:59:12.888573"}}
{"question": "How does the BFD liveness detection setting compare between an AWS Direct Connect virtual interface and my router?", "answer": "AWS sets the BFD liveness detection minimum interval to 300 and the BFD liveness detection multiplier to 3 for each AWS Direct Connect virtual interface, but this setting will not take effect until it's configured on your router.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-14", "source_tokens": 505, "generated_at": "2026-02-11T14:59:12.888968"}}
{"question": "What ASN range should I use for a private ASN with AWS Direct Connect?", "answer": "The private ASN for AWS Direct Connect should be in the range of 64512 to 65535.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-11T14:59:16.477544"}}
{"question": "How does AWS Direct Connect differ from VPN connections in terms of setup and functionality?", "answer": "AWS Direct Connect establishes dedicated, private network connections between your network and AWS, bypassing the internet, while VPN connections use IPsec to establish network connectivity over the public internet.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-11T14:59:16.477886"}}
{"question": "Can I use the same VGW ID for both AWS Direct Connect and a VPN connection?", "answer": "No, each connection type requires a unique VGW ID.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-15", "source_tokens": 507, "generated_at": "2026-02-11T14:59:16.478401"}}
{"question": "How long does it take to establish an association between an AWS Transit Gateway and an AWS Direct Connect gateway?", "answer": "It can take up to 40 minutes.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-11T14:59:20.270386"}}
{"question": "What functions does an AWS Direct Connect gateway perform in relation to AWS Transit Gateways?", "answer": "An AWS Direct Connect gateway allows you to interface with VPCs in multiple AWS Regions, share a private virtual interface with up to 20 VPCs to reduce BGP sessions, and associate multiple transit virtual interfaces with a single gateway to connect to multiple Transit Gateways.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-11T14:59:20.270666"}}
{"question": "Can you use jumbo frames with a transit virtual interface connected to an AWS Direct Connect gateway?", "answer": "Yes, the maximum transmission unit size is limited to 8,500.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-16", "source_tokens": 492, "generated_at": "2026-02-11T14:59:20.271097"}}
{"question": "How many Transit Gateways can be associated with an AWS Direct Connect gateway without overlapping IP CIDR blocks?", "answer": "Up to six Transit Gateways can be associated with an AWS Direct Connect gateway.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-11T14:59:25.696103"}}
{"question": "Why can't traffic using an AWS Direct Connect gateway take the shortest path to the destination AWS Region if the Transit Gateway and Direct Connect gateway are in different accounts?", "answer": "When using an AWS Direct Connect gateway, your traffic takes the shortest path to and from your AWS Direct Connect location to the destination AWS Region, regardless of the home AWS Region of the Direct Connect gateway.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-11T14:59:25.696455"}}
{"question": "How does networking with Elastic File System differ when using an AWS Direct Connect gateway compared to other networking features such as Elastic Load Balancing?", "answer": "AWS Direct Connect gateway supports networking features like Elastic File System, Elastic Load Balancing, Application Load Balancer, Security Groups, Access Control List, and AWS PrivateLink. However, it does not support AWS VPN CloudHub functionality. If you use a Site-to-Site VPN connection to a virtual gateway (VGW) associated with your Direct Connect gateway, you can use the VPN connection for failover.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-17", "source_tokens": 460, "generated_at": "2026-02-11T14:59:25.696922"}}
{"question": "What can you still do with a virtual private gateway (VGW) in terms of attaching virtual interfaces (VIFs) after setting up an AWS Direct Connect gateway?", "answer": "You can continue to attach VIFs to a VGW and will have intra-Region VPC connectivity, but will be charged the egress rate for the related geographic Regions.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-11T14:59:30.917662"}}
{"question": "Why is it not possible to have a VGW-VPC pair be part of more than one AWS Direct Connect gateway?", "answer": "This is a restriction to ensure that the VPC traffic is properly routed through the correct AWS Direct Connect gateway.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-11T14:59:30.917990"}}
{"question": "How does attaching a VIF directly to a VGW affect the AWS VPN CloudHub functionality?", "answer": "Attaching a VIF directly to a VGW allows you to use the VPN <-> AWS Direct Connect AWS VPN CloudHub use case, while existing AWS VPN CloudHub functionality will continue to be supported.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-18", "source_tokens": 501, "generated_at": "2026-02-11T14:59:30.918199"}}
{"question": "What prefixes can be announced towards an on-premises network with an AWS Direct Connect gateway for low preference?", "answer": "Prefixes marked with the community 7224:7100 can be announced towards an on-premises network with an AWS Direct Connect gateway for low preference.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-11T14:59:37.318485"}}
{"question": "How does selective announcement of prefixes towards on-premises networks work with an AWS Direct Connect gateway?", "answer": "With an AWS Direct Connect gateway, you can selectively announce prefixes towards your on-premises networks. Each VPC associated with an AWS Direct Connect gateway receives all prefixes announced from your on-premises networks. If you want to limit traffic to and from any specific VPC, you should consider using Access Control Lists (ACLs) for each VPC.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-11T14:59:37.318752"}}
{"question": "What is the difference in preference between prefixes announced towards an on-premises network with a community of 7224:7100 and 7224:7200 with an AWS Direct Connect gateway?", "answer": "Prefixes marked with the community 7224:7100 have a lower preference than prefixes marked with the community 7224:7200 when announcing towards an on-premises network with an AWS Direct Connect gateway.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-19", "source_tokens": 508, "generated_at": "2026-02-11T14:59:37.319099"}}
{"question": "What is the default local preference for egress traffic when no Local Preference communities are specified for a private VIF?", "answer": "The default local preference is based on the distance to the AWS Direct Connect Locations from the local Region.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-11T14:59:41.761670"}}
{"question": "How does advertising prefixes with higher local preference over a primary VIF influence egress traffic behavior?", "answer": "It makes the prefix advertised over the primary VIF the preferred path for egress traffic. If the primary VIF fails or the prefix is withdrawn, the backup VIF becomes the return path.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-11T14:59:41.762015"}}
{"question": "What's the difference in egress traffic behavior between a private VIF with higher local preference and one without?", "answer": "A private VIF with higher local preference will be the preferred path for egress traffic, while one without may have arbitrary egress behavior across multiple VIFs.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-20", "source_tokens": 466, "generated_at": "2026-02-11T14:59:41.762216"}}
{"question": "What private ASN can AWS assign to a new Direct Connect gateway if I don't provide one?", "answer": "AWS will provide an ASN of 64512 for the AWS Direct Connect gateway if you don't choose one.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-11T14:59:45.672069"}}
{"question": "Why can't I use a public ASN as the AWS side ASN for an AWS Direct Connect gateway?", "answer": "AWS does not allow public ASNs for the AWS side ASN to protect customers from BGP spoofing.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-11T14:59:45.672366"}}
{"question": "Can I use the same private ASN for both my AWS Direct Connect Gateway and Virtual Private Gateway?", "answer": "Yes, you can use the same private ASN for both your AWS Direct Connect Gateway and Virtual Private Gateway, the AWS side ASN you receive depends on your private virtual interface association.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-21", "source_tokens": 482, "generated_at": "2026-02-11T14:59:45.672572"}}
{"question": "What is the role of the AWS side ASN in a BGP session between my network and AWS using AWS Direct Connect Gateway?", "answer": "The AWS side ASN is the ASN used by AWS on the BGP session between your network and AWS. You can select your own private ASN in the AWS Direct Connect gateway console.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-11T14:59:51.155043"}}
{"question": "Why is MACsec an optional additional encryption technology in AWS Direct Connect instead of a replacement for existing encryption technologies?", "answer": "MACsec is not intended as a replacement for any specific encryption technology. You should continue to use any encryption technologies that you already use for security purposes. AWS offers MACsec as an encryption option that can be integrated into your network in addition to other encryption technologies.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-11T14:59:51.155372"}}
{"question": "How does the support for MACsec on AWS Direct Connect differ between 1 Gbps and higher dedicated connections?", "answer": "MACsec is supported on 10 Gbps, 100 Gbps, and 400 Gbps dedicated AWS Direct Connect connections at selected points of presence. It is not supported on 1 Gbps dedicated connections or any hosted connections.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-22", "source_tokens": 421, "generated_at": "2026-02-11T14:59:51.155539"}}
{"question": "What MACsec cipher suites does AWS support for different connection speeds?", "answer": "AWS supports GCM-AES-XPN-256 for 100 Gbps and 400 Gbps connections, and GCM-AES-256 and GCM-AES-XPN-256 for 10Gbps connections.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-11T14:59:56.753090"}}
{"question": "Why is extended packet numbering necessary for high-speed MACsec connections?", "answer": "High-speed MACsec connections can quickly exhaust the original 32-bit packet numbering space, requiring frequent key rotation. Extended packet numbering, with a 64-bit numbering space, eases the timeliness requirement for key rotation.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-11T14:59:56.753393"}}
{"question": "What is the difference between MACsec's handling of VLAN tags for 10Gbps and high-speed connections?", "answer": "For 10Gbps connections, AWS supports both moving the VLAN tag outside of the encrypted payload and keeping it within the encrypted payload. However, for high-speed connections, AWS requires the VLAN tag to be kept within the encrypted payload.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-23", "source_tokens": 422, "generated_at": "2026-02-11T14:59:56.753854"}}
{"question": "What is the timeline for scheduled maintenance notifications for Direct Connect?", "answer": "Scheduled maintenance notifications for Direct Connect are provided in three increments: 14 calendar days, 7 calendar days, and 1 calendar day.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T15:00:01.126326"}}
{"question": "Why are there different types of notifications for Direct Connect maintenance?", "answer": "Different types of notifications for Direct Connect maintenance exist to provide sufficient time for customers to prepare for potential downtime, with longer notifications for scheduled maintenance and shorter ones for emergency maintenance.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T15:00:01.126695"}}
{"question": "What options do I have to ensure minimal impact during Direct Connect maintenance?", "answer": "You can take actions such as requesting a redundant Direct Connect connection or configuring an AWS Site-to-Site VPN connection as a backup to prevent production traffic disruption during Direct Connect maintenance.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-24", "source_tokens": 489, "generated_at": "2026-02-11T15:00:01.126891"}}
{"question": "What happens if all my AWS connections are on the same logical device during maintenance?", "answer": "If all your AWS connections are on the same logical device, then you will be impacted by the maintenance.", "question_type": "factual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-11T15:00:04.508228"}}
{"question": "How can I minimize the risk of partner maintenance windows overlapping?", "answer": "One solution would be to use two different partners in different Direct Connect locations.", "question_type": "comparison", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-11T15:00:04.508589"}}
{"question": "Why is it important for me to know my partner's maintenance schedule?", "answer": "It's crucial to know your partner's maintenance schedule as AWS does not have visibility to partner maintenance activities.", "question_type": "conceptual", "metadata": {"service": "DIRECTCONNECT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "directconnect-faq-25", "source_tokens": 137, "generated_at": "2026-02-11T15:00:04.509092"}}
{"question": "What databases can be used as sources in AWS Database Migration Service?", "answer": "AWS Database Migration Service supports a wide range of commercial and open-source databases as sources, including Oracle, Microsoft SQL Server, MySQL, PostgreSQL, and more. It also supports both homogeneous and heterogeneous migrations.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-11T15:00:09.345333"}}
{"question": "How does AWS Database Migration Service facilitate database replication?", "answer": "AWS Database Migration Service performs database replication by assessing, converting, and migrating data to and from various databases. It can replicate data in real-time with low latency to support data lake solutions or consolidate databases into a data warehouse. The source database remains operational during the migration, minimizing downtime.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-11T15:00:09.345699"}}
{"question": "Which target databases can I stream data to from AWS Database Migration Service?", "answer": "You can stream data to Amazon Redshift or Amazon S3 as target databases using AWS Database Migration Service.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-0", "source_tokens": 478, "generated_at": "2026-02-11T15:00:09.346147"}}
{"question": "What does AWS DMS provide for free in the database migration process?", "answer": "AWS DMS provides Schema Conversion for free as a part of the database migration process.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-11T15:00:13.558835"}}
{"question": "How does the production environment switchover process differ between a typical database migration and continuous data replication using AWS DMS?", "answer": "During a typical database migration, there is a production environment switchover once the target database is caught up with the source database. However, this step is absent for continuous data replication, as the data replication task runs until it is changed or terminated.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-11T15:00:13.559086"}}
{"question": "Which AWS services does AWS Database Migration Service integrate with for monitoring and logging?", "answer": "AWS Database Migration Service integrates with CloudTrail and CloudWatch Logs for monitoring and logging.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-1", "source_tokens": 471, "generated_at": "2026-02-11T15:00:13.559485"}}
{"question": "Which databases and analytics services are supported by AWS DMS Serverless for homogeneous data migrations?", "answer": "AWS DMS Serverless supports popular databases and analytics services such as Oracle, Microsoft SQL Server, PostgreSQL, MySQL, Amazon Redshift, Amazon RDS, Amazon Aurora, and more. For homogeneous data migrations including PostgreSQL and MySQL, see the full list of supported engines.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-11T15:00:20.140302"}}
{"question": "How does AWS DMS Schema Conversion automate database code conversion?", "answer": "AWS DMS Schema Conversion automates the conversion of Oracle PL/SQL and SQL Server T-SQL code to equivalent code in the Amazon RDS for MySQL dialect of SQL or the equivalent PL/pgSQL code in PostgreSQL. When a code fragment cannot be automatically converted to the target language, it will document the locations that require manual input from the application developer.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-11T15:00:20.140653"}}
{"question": "What are the differences between using AWS DMS Schema Conversion and downloading AWS Schema Conversion Tool for heterogeneous database migrations?", "answer": "AWS DMS Schema Conversion is a built-in feature of AWS DMS for heterogeneous migrations. It allows for more customizable schema migration processes when moving production databases and requires manual input for stored procedures and secondary database objects. The AWS Schema Conversion Tool is a downloadable version that can be used for homogeneous migrations. It automates the conversion of database and data warehouse schema between different engine versions or editions.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-2", "source_tokens": 409, "generated_at": "2026-02-11T15:00:20.141063"}}
{"question": "What is the role of AWS DMS and AWS SCT in database migration and replication on AWS?", "answer": "AWS DMS and AWS SCT are two services that work together to facilitate database migration and support ongoing replication on AWS. AWS DMS is used to move smaller relational workloads (<10 TB) and supports ongoing replication. AWS SCT, on the other hand, is used for large data warehouse workloads, particularly for schema conversion and migration.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:00:25.889009"}}
{"question": "How does AWS SCT assist in database migrations on AWS?", "answer": "AWS SCT is primarily used for schema conversion during database migrations on AWS. It can copy database schemas for homogeneous and heterogeneous migrations. Once a schema has been created on an empty target, AWS DMS or AWS SCT can be used to move the data.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:00:25.889370"}}
{"question": "What are the main differences between AWS DMS and AWS SCT for database migrations and replication on AWS?", "answer": "AWS DMS is typically used for smaller relational workloads (<10 TB) and supports ongoing replication. AWS SCT, on the other hand, is primarily used for large data warehouse workloads and is primarily used for schema conversion during migrations.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:00:25.889844"}}
{"question": "Which tool does AWS recommend for homogeneous database migrations and why?", "answer": "AWS recommends using DMS built-in native tooling for homogeneous migrations due to its familiarity and seamless migration process. You don't need to provision or monitor the migration, and you only pay for the hours used during the migration.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T15:00:31.540710"}}
{"question": "How does AWS DMS Serverless help in handling heterogeneous migrations or continuous data replications?", "answer": "AWS DMS Serverless automatically monitors and scales resources to meet demand without manual intervention or over provisioning resources. It is recommended for heterogeneous migrations or continuous data replications with data fluctuations.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T15:00:31.540995"}}
{"question": "What is the main difference between using AWS DMS built-in native tooling for homogeneous migrations and AWS DMS Serverless for heterogeneous migrations?", "answer": "AWS DMS built-in native tooling for homogeneous migrations does not require manual intervention or resource provisioning and is recommended for seamless migrations when source and target engines are the same. AWS DMS Serverless, on the other hand, is recommended for heterogeneous migrations or continuous data replications with data fluctuations, as it automatically monitors and scales resources to meet demand without manual intervention.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T15:00:31.541167"}}
{"question": "What is the intended use for AWS DMS Fleet Advisor?", "answer": "AWS DMS Fleet Advisor is a service intended for users looking to migrate a large number of database and analytics servers to AWS. It allows users to discover and analyze OLTP and OLAP database workloads and build a customized migration plan.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:00:38.913547"}}
{"question": "How does AWS Application Discovery Service (ADS) and Migration Evaluator differ from AWS DMS Fleet Advisor?", "answer": "AWS DMS Fleet Advisor is used for discovering and analyzing database workloads for migration to AWS services, while AWS Application Discovery Service (ADS) and Migration Evaluator are targeted for compute and block storage discovery and creating a data-driven business case for AWS migration. ADS feeds the AWS Migration Hub for visualizing dependencies, creating application groups, and tracking migration progress.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:00:38.913811"}}
{"question": "What is the recommended collector to use for migrating databases and why? Also, where is the AWS Application Discovery Service (ADS) Agentless Collector available?", "answer": "For most customers, the AWS Application Discovery Service (ADS) Agentless Collector is recommended as it supports server migration through AWS Migration Hub and allows discovering on-premises databases. It is available in regions where the AWS Application Discovery Service (ADS) Agentless Collector is supported. For all other regions, the AWS DMS Fleet Advisor collector is recommended and can be installed on a Microsoft Windows Server 2012 or higher. Both collectors will have their metadata and utilization metrics available in AWS DMS Fleet Advisor.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:00:38.914220"}}
{"question": "What information about the end of support for AWS DMS versions can be found?", "answer": "The end of support information for each AWS DMS version is included in the DMS Release Notes and the new â€˜Support lifecycle policyâ€™ section in the DMS console.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T15:00:42.846089"}}
{"question": "Why is AWS automatically upgrading certain DMS instances?", "answer": "AWS is automatically upgrading certain DMS instances because they have reached the end of support date, making them ineligible for further support.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T15:00:42.846395"}}
{"question": "How does the support policy for major and minor AWS DMS version releases compare?", "answer": "AWS DMS does not differentiate between major and minor version releases and has the same support policy for both.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T15:00:42.846602"}}
{"question": "What happens if the tables in a migration task are in the replicating ongoing changes phase (CDC) when a patch is applied?", "answer": "AWS DMS pauses the task while the patch is applied and then continues the migration from where it was left off.", "question_type": "factual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-11T15:00:46.847372"}}
{"question": "How does AWS DMS handle a patch application during a full load operation?", "answer": "AWS DMS restarts the migration for the table.", "question_type": "conceptual", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-11T15:00:46.847776"}}
{"question": "What is the difference between how AWS DMS handles patch applications during a migration task with ongoing changes and during a full load operation?", "answer": "During ongoing changes, AWS DMS pauses the task and continues from where it was left off. During full load operations, AWS DMS restarts the migration for the table.", "question_type": "comparison", "metadata": {"service": "DMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dms-faq-7", "source_tokens": 195, "generated_at": "2026-02-11T15:00:46.848096"}}
{"question": "What are some use cases for Amazon DocumentDB besides content management and personalization?", "answer": "Amazon DocumentDB is used by a wide variety of customers for use cases such as catalogs, mobile and web applications, IoT, semantic search, and user profile management.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-11T15:00:51.717513"}}
{"question": "How does the cost savings of Amazon DocumentDB's memory-optimized instances compare to other popular document databases?", "answer": "Amazon DocumentDB's memory-optimized instances offer up to 43% cost savings compared to other popular document databases.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-11T15:00:51.717878"}}
{"question": "What is Amazon DocumentDB and what benefits does it provide?", "answer": "Amazon DocumentDB is a serverless, fully managed, MongoDB API-compatible document database service that offers Improved resilience, low latency, leading security and compliance, transparent pricing, and no hidden costs. It removes the undifferentiated heavy lifting of database management tasks such as patching, backups, and monitoring.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-0", "source_tokens": 412, "generated_at": "2026-02-11T15:00:51.718317"}}
{"question": "What open source licenses does Amazon DocumentDB use for MongoDB API compatibility?", "answer": "Amazon DocumentDB uses the Apache 2.0 open source license for MongoDB API compatibility.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-11T15:00:56.064321"}}
{"question": "Why is Amazon DocumentDB compatible with MongoDB APIs?", "answer": "Amazon DocumentDB is compatible with MongoDB APIs to allow customers to use the same drivers, applications, and tools with minimal changes.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-11T15:00:56.064642"}}
{"question": "How does migrating to Amazon DocumentDB from a MongoDB database on EC2 differ from migrating from an on-premises MongoDB database?", "answer": "Both migrations can be done using AWS Database Migration Service (DMS), but the difference lies in the source database being on-premises or an Amazon Elastic Compute Cloud (EC2) instance.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-1", "source_tokens": 462, "generated_at": "2026-02-11T15:00:56.065050"}}
{"question": "What database technology allows for ACID transactions across multiple documents and statements in Amazon DocumentDB?", "answer": "MongoDB 4.0", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T15:00:59.835634"}}
{"question": "How does Amazon DocumentDB handle support lifecycles compared to MongoDB?", "answer": "Amazon DocumentDB does not follow the same support lifecycles as MongoDB.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T15:00:59.835994"}}
{"question": "Which AWS services can access Amazon DocumentDB instances and how?", "answer": "Amazon DocumentDB instances are accessible by Amazon EC2 instances and other AWS services that are deployed in the same VPC or via VPC peering. Access is done using the mongo shell or MongoDB drivers and requires authentication.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-2", "source_tokens": 475, "generated_at": "2026-02-11T15:00:59.836463"}}
{"question": "What does AWS invest in regarding open source DocumentDB and Amazon DocumentDB?", "answer": "AWS invests in both open source DocumentDB and Amazon DocumentDB, contributing Amazon DocumentDB innovations to the open source project and adopting features and capabilities from open source DocumentDB to the managed Amazon DocumentDB service.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:01:04.615890"}}
{"question": "How does Amazon DocumentDB Serverless help with resource management for applications with variable workloads?", "answer": "Amazon DocumentDB Serverless offers simplified resource management for applications with variable workloads, allowing you to only pay for the database capacity used and avoid upfront commitments or additional costs.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:01:04.616232"}}
{"question": "What are the main differences between open source DocumentDB and Amazon DocumentDB in terms of origin and management?", "answer": "Open source DocumentDB is an extension of PostgreSQL, developed under the Linux Foundation and built by the community. Amazon DocumentDB, on the other hand, is a managed database service provided by AWS.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:01:04.616617"}}
{"question": "What measurements are used for computing costs in Amazon DocumentDB Serverless?", "answer": "Compute costs for running your workloads on Amazon DocumentDB Serverless depend on the database cluster configuration that you choose: Amazon DocumentDB Standard or Amazon DocumentDB I/O-Optimized storage.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-11T15:01:08.919172"}}
{"question": "How does Amazon DocumentDB Serverless measure database capacity?", "answer": "In Amazon DocumentDB Serverless, database capacity is measured in Amazon DocumentDB Capacity Units (DCUs).", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-11T15:01:08.919443"}}
{"question": "What's the difference between Amazon DocumentDB Serverless and traditional databases in terms of write performance?", "answer": "Amazon DocumentDB only persists write-ahead logs in Serverless, whereas traditional databases write full buffer page syncs. This optimization results in faster writes in Amazon DocumentDB Serverless.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-4", "source_tokens": 432, "generated_at": "2026-02-11T15:01:08.919871"}}
{"question": "What is the maximum storage capacity for Amazon DocumentDB Elastic Clusters?", "answer": "Amazon DocumentDB Elastic Clusters have a maximum storage capacity of 4 PiB.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-11T15:01:13.534376"}}
{"question": "How does scaling storage in Amazon DocumentDB work?", "answer": "Amazon DocumentDB allows storage to automatically scale from 10 GB up to 128 TiB in 10 GiB increments for instance-based clusters, and up to 4 PiB for Amazon DocumentDB Elastic Clusters.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-11T15:01:13.534749"}}
{"question": "How does Amazon DocumentDB I/O-Optimized compare to standard storage configurations in terms of storage capacity?", "answer": "Amazon DocumentDB I/O-Optimized has a higher maximum storage capacity compared to standard storage configurations, with a limit of 4 PiB compared to 128 TiB for instance-based clusters and 10 GiB increment growth.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-5", "source_tokens": 467, "generated_at": "2026-02-11T15:01:13.535214"}}
{"question": "What are the charges for I/O operations when using Amazon DocumentDB I/O-Optimized for data replication?", "answer": "Amazon DocumentDB I/O-Optimized does not charge for read and write I/O operations during data replication.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-11T15:01:18.133093"}}
{"question": "How does Elastic Clusters in Amazon DocumentDB enable scaling beyond the limits of a single database?", "answer": "Elastic Clusters uses sharding to partition data across Amazon DocumentDBâ€™s distributed storage system, which allows customers to scale out their database beyond the vertical scaling limits of a single database.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-11T15:01:18.133388"}}
{"question": "How does Elastic Clusters compare to single instance Amazon DocumentDB in terms of handling large workloads?", "answer": "Elastic Clusters can handle millions of writes and reads, and supports elastic scalability by allowing users to add or remove compute resources based on their workload needs.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-6", "source_tokens": 441, "generated_at": "2026-02-11T15:01:18.133824"}}
{"question": "What is the impact on application performance when scaling an Elastic Cluster compared to MongoDB?", "answer": "Scaling an Elastic Cluster typically results in little to no application downtime or impact to performance, whereas scaling MongoDB can impact application performance and take hours or even days.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-11T15:01:23.052057"}}
{"question": "How does Elastic Clusters enable users to manage their databases more effectively?", "answer": "Elastic Clusters offers differentiated management capabilities such as no-impact backups and rapid point-in-time restore, allowing users to focus more time on their applications rather than managing their database.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-11T15:01:23.052393"}}
{"question": "Which characteristic makes a good shard key for Elastic Clusters based on the text passage?", "answer": "A good shard key for Elastic Clusters has two characteristics: high frequency and high cardinality. For example, user_id could be a good shard key since all orders related to a given user are typically retrieved in DocumentDB.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-7", "source_tokens": 508, "generated_at": "2026-02-11T15:01:23.052599"}}
{"question": "What is the maximum backup window for point-in-time restores in Amazon DocumentDB?", "answer": "The maximum backup window for point-in-time restores in Amazon DocumentDB is 35 days.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-11T15:01:27.834720"}}
{"question": "How does data recovery work in Amazon DocumentDB when the data is unavailable?", "answer": "When data is unavailable in Amazon DocumentDB storage, you can restore from a cluster snapshot or perform a point-in-time restore operation to a new cluster. Automated backups created for point-in-time restore are not kept after the instance is deleted, only user-created snapshots are retained.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-11T15:01:27.835038"}}
{"question": "What is the difference between restoring from a cluster snapshot and performing a point-in-time restore operation in Amazon DocumentDB?", "answer": "Restoring from a cluster snapshot requires creating a new cluster, while a point-in-time restore operation restores the instance to a previous state within five minutes in the past.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-8", "source_tokens": 430, "generated_at": "2026-02-11T15:01:27.835241"}}
{"question": "What can you do with the snapshots created in Amazon DocumentDB?", "answer": "You can use snapshots to restore a cluster, share them with other AWS accounts, and keep backups of your data in a separate account for security.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-11T15:01:31.759642"}}
{"question": "How does sharing a snapshot in Amazon DocumentDB work?", "answer": "You can manually create a copy of a snapshot and then share the copy with another AWS account. The recipient account can use the shared snapshot to restore a new cluster.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-11T15:01:31.759893"}}
{"question": "Can you share encrypted Amazon DocumentDB snapshots?", "answer": "Yes, you can share encrypted snapshots, but the recipient account must have access to the KMS key that was used to encrypt the snapshot.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-9", "source_tokens": 478, "generated_at": "2026-02-11T15:01:31.760274"}}
{"question": "What makes Amazon DocumentDB's database restart time less than 60 seconds?", "answer": "Amazon DocumentDB does not need to replay the redo log from the last checkpoint and confirm all changes have been applied before making the database available for operations.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T15:01:36.254935"}}
{"question": "How does having read replicas impact the performance of Amazon DocumentDB?", "answer": "Replication is asynchronous and typically completes in milliseconds with low impact on the performance of the primary instance.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T15:01:36.255566"}}
{"question": "What is the difference between replicas with different priority tiers in Amazon DocumentDB?", "answer": "The replica with the highest priority tier is promoted to primary if the primary instance fails. However, if all replicas with higher priority tiers are unavailable, Amazon DocumentDB will promote the replica with the next highest available priority tier.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T15:01:36.255819"}}
{"question": "What happens to the CNAME record when Amazon DocumentDB fails over?", "answer": "Amazon DocumentDB flips the canonical name record (CNAME) for your instance to point at the healthy replica, which is in turn promoted to become the new primary.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:01:42.504231"}}
{"question": "How does failover in Amazon DocumentDB work conceptually?", "answer": "When Amazon DocumentDB detects a problem with the primary instance, it begins routing read/write traffic to an Amazon DocumentDB replica instance. The replica is then promoted to become the new primary, and the CNAME record is updated to point to the new primary. This process typically completes within 30 seconds, and read traffic interruption is brief.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:01:42.504576"}}
{"question": "What's the difference in failover experience between a single instance cluster and a multi-replica cluster in Amazon DocumentDB?", "answer": "In a single instance cluster, Amazon DocumentDB will attempt to create a new instance in the same Availability Zone as the original instance on a best-effort basis. This replacement may not succeed if there is a broader issue affecting the Availability Zone. In contrast, in a multi-replica cluster, replicas are distributed across multiple Availability Zones, and Amazon DocumentDB automatically includes them in failover primary selection. This results in quicker failover and minimized service interruption.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:01:42.504788"}}
{"question": "What networking requirements does Amazon DocumentDB have for instance creation?", "answer": "All Amazon DocumentDB instances must be created in an Amazon VPC.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T15:01:46.487659"}}
{"question": "How does Amazon DocumentDB utilize Amazon VPC for security?", "answer": "Amazon DocumentDB uses Amazon VPC to enforce network and authorization boundaries, and also uses VPC for authentication and authorization of its management APIs.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T15:01:46.488006"}}
{"question": "What encryption mechanisms does Amazon DocumentDB support for data at rest?", "answer": "Amazon DocumentDB supports encryption of clusters using keys managed through AWS Key Management Service (KMS). Data stored at rest in the underlying storage, as well as automated backups, snapshots, and replicas in the same cluster are encrypted.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-12", "source_tokens": 512, "generated_at": "2026-02-11T15:01:46.488208"}}
{"question": "What version of Amazon DocumentDB does in-place Major Version Upgrade (MVU) support as a source?", "answer": "Amazon DocumentDB 3.6 or 4.0", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-11T15:01:51.629531"}}
{"question": "Why is in-place MVU a beneficial upgrade method for Amazon DocumentDB?", "answer": "In-place MVU allows you to upgrade Amazon DocumentDB clusters to version 5.0 without the need to create new clusters, change endpoints, perform backup and restore, or use data migration tools. This reduces the time and effort associated with the usual upgrade process.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-11T15:01:51.629874"}}
{"question": "How does in-place MVU upgrade compare to a regular upgrade in terms of downtime?", "answer": "The downtime associated with in-place MVU upgrade can vary depending on the number of collections, indexes, databases, and instances in the cluster. Before performing an in-place MVU on a production cluster, it is recommended to test it in a lower environment to estimate downtime, verify application functionality post upgrade, and ensure performance.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-13", "source_tokens": 423, "generated_at": "2026-02-11T15:01:51.630405"}}
{"question": "What is the method used in machine learning for finding similar data points based on their vector representations?", "answer": "Vector search is a method used in machine learning to find similar data points to a given data point by comparing their vector representations using distance or similarity metrics.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-11T15:01:56.540281"}}
{"question": "How does vector search for Amazon DocumentDB improve the user experience in e-commerce applications?", "answer": "Vector search for Amazon DocumentDB enables semantic search, which improves the user experience in e-commerce applications by retrieving results with similar items based on their meaning, context, and intent, not just based on exact keyword matches.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-11T15:01:56.540611"}}
{"question": "What are the differences between keyword search and semantic search in the context of Amazon DocumentDB?", "answer": "Keyword search finds documents based on the actual text or pre-defined synonym mappings, while semantic search retrieves results based on their meaning, context, and intent. In the context of Amazon DocumentDB, semantic search can improve the user experience by returning more relevant results.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-14", "source_tokens": 377, "generated_at": "2026-02-11T15:01:56.541052"}}
{"question": "What data source can you use to build machine learning models in Amazon SageMaker Canvas without writing code?", "answer": "You can use Amazon DocumentDB as a data source in Amazon SageMaker Canvas to build machine learning models.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T15:02:01.646434"}}
{"question": "How does the integration of Amazon DocumentDB with Amazon SageMaker Canvas make machine learning development easier?", "answer": "The in-console integration of Amazon DocumentDB with Amazon SageMaker Canvas eliminates the need to develop custom data and ML pipelines between the two services, resulting in a low code no code experience for machine learning development.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T15:02:01.646782"}}
{"question": "What are the charges for using Amazon DocumentDB as a data source in Amazon SageMaker Canvas?", "answer": "You are charged for your use of Amazon SageMaker Canvas and for the resulting I/Os when SageMaker Canvas reads data from your Amazon DocumentDB instance. There is no additional charge to use DocumentDB as a data source in Amazon SageMaker Canvas.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T15:02:01.647245"}}
{"question": "What is the benefit of using Amazon DocumentDB for vector search with MongoDB APIs?", "answer": "Amazon DocumentDB allows users to perform vector search on documents using its native capabilities. It also integrates with Amazon OpenSearch Service to offer seamless data replication and indexing for vectors with over 2,000 dimensions.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T15:02:07.182580"}}
{"question": "How does the zero-ETL integration of Amazon DocumentDB and Amazon OpenSearch Service work conceptually?", "answer": "The integration uses Amazon OpenSearch Ingestion to automatically move operational data from Amazon DocumentDB to Amazon OpenSearch Service, mapping the data to yield the most performant search results. Users can synchronize data from multiple Amazon DocumentDB collections and specify custom data processors.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T15:02:07.182950"}}
{"question": "How does the zero-ETL integration of Amazon DocumentDB and Amazon OpenSearch Service compare to using custom transformational logic?", "answer": "The zero-ETL integration leverages the native data transformational capabilities of Amazon OpenSearch Ingestion pipelines to aggregate and filter data while it is in motion. Alternatively, users can write custom transformation logic and Amazon OpenSearch Ingestion will manage the transformation process.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T15:02:07.183165"}}
{"question": "What console dashboards can I use to view metrics related to my zero-ETL integration with Amazon DocumentDB and OpenSearch Ingestion pipeline?", "answer": "The console dashboards provided by Amazon DocumentDB and OpenSearch Ingestion pipeline can be used to view all the metrics related to your zero-ETL integration.", "question_type": "factual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-11T15:02:13.045930"}}
{"question": "How can I gain a better understanding of the monitoring and alerting capabilities offered by Amazon DocumentDB and OpenSearch Ingestion pipeline for my zero-ETL integration?", "answer": "You can view and analyze various metrics on the console dashboards provided by Amazon DocumentDB and OpenSearch Ingestion pipeline. Additionally, you can query real-time logs in Amazon CloudWatch and set up custom alerting using Amazon CloudWatch that are triggered when user-defined thresholds are breached.", "question_type": "conceptual", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-11T15:02:13.046173"}}
{"question": "What are the differences between monitoring and alerting capabilities offered by Amazon DocumentDB's console dashboards and Amazon CloudWatch for my zero-ETL integration?", "answer": "The console dashboards provided by Amazon DocumentDB and OpenSearch Ingestion pipeline allow you to view various metrics related to your zero-ETL integration in one place. Amazon CloudWatch, on the other hand, enables you to query real-time logs and set up custom alerting based on user-defined thresholds.", "question_type": "comparison", "metadata": {"service": "DOCUMENTDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "documentdb-faq-17", "source_tokens": 74, "generated_at": "2026-02-11T15:02:13.046325"}}
{"question": "What are the benefits of using Amazon DynamoDB for high availability and resilience?", "answer": "Amazon DynamoDB offers zero infrastructure management, zero downtime maintenance, instant scaling to any application demand, and pay-per-request billing. It provides single-digit millisecond performance at any scale and supports multi-Region strong consistency ensuring applications always stay available and read the same data from any Region. DynamoDB also has a broad set of security controls and compliance standards.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T15:02:18.449744"}}
{"question": "How does Amazon DynamoDB ensure high availability and data durability?", "answer": "Amazon DynamoDB synchronously replicates data across three Availability Zones (AZs) in an AWS Region, giving you high availability and data durability. It automatically scales throughput capacity to meet workload demands and partitions and repartitions your data as your table size grows.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T15:02:18.449989"}}
{"question": "How does Amazon DynamoDB compare to other databases in terms of high availability and resilience?", "answer": "Amazon DynamoDB offers up to 99.999% availability and the highest database resilience compared to other databases due to its multi-Region, multi-active database design and multi-Region strong consistency.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-0", "source_tokens": 425, "generated_at": "2026-02-11T15:02:18.450169"}}
{"question": "What performance does DynamoDB offer for tables with unpredictable workloads?", "answer": "DynamoDB Standard is the default table class designed for workloads that require maximum performance and is best suited for tables with unpredictable workloads.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T15:02:22.931529"}}
{"question": "Why would you choose DynamoDB Standard-Infrequent Access table class?", "answer": "You would choose DynamoDB Standard-Infrequent Access table class when your table stores infrequently accessed data and storage is the dominant cost.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T15:02:22.931868"}}
{"question": "How does the cost and performance compare between DynamoDB Standard and Standard-Infrequent Access table classes for tables with predictable workloads?", "answer": "DynamoDB Standard has lower costs for reads and writes but higher storage costs, while DynamoDB Standard-Infrequent Access has lower storage costs but higher costs for reads and writes.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T15:02:22.932064"}}
{"question": "What is the maximum size of an item that can be stored in a DynamoDB table?", "answer": "The maximum size of an item that can be stored in a DynamoDB table is 400 KB.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-11T15:02:28.642237"}}
{"question": "Why is it recommended to store pointers to Amazon S3 objects instead of images in a DynamoDB table?", "answer": "It is recommended to store pointers to Amazon S3 objects instead of images directly in a DynamoDB table because of the 400 KB item size limit. This architectural pattern allows for more efficient management of larger data and eliminates potential limitations due to size.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-11T15:02:28.642613"}}
{"question": "How does storing pointers to Amazon S3 objects in a DynamoDB table compare to storing images directly in a DynamoDB table?", "answer": "Storing pointers to Amazon S3 objects in a DynamoDB table instead of storing images directly allows for more efficient management of larger data and eliminates potential limitations due to size within the 400 KB item limit. Directly storing images in a DynamoDB table could result in larger items, which may impact performance and incur additional costs.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-2", "source_tokens": 487, "generated_at": "2026-02-11T15:02:28.643009"}}
{"question": "What data types can DynamoDB use to store lists?", "answer": "DynamoDB uses the List or Set data types to store lists.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-11T15:02:32.579848"}}
{"question": "How does DynamoDB handle list data when querying?", "answer": "When querying a table attribute that contains a list, DynamoDB returns the full list.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-11T15:02:32.580196"}}
{"question": "How does AWS PrivateLink compare to public network access for DynamoDB?", "answer": "AWS PrivateLink provides private network connectivity to DynamoDB tables, maintaining security by not requiring traffic to leave the Amazon network. Public network access, on the other hand, sends requests through network gateways, which may increase latency and expose data to potential interception.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-3", "source_tokens": 368, "generated_at": "2026-02-11T15:02:32.580398"}}
{"question": "What AWS services does DynamoDB's resource-based policies support for table and stream access control?", "answer": "DynamoDB's resource-based policies support integrations with AWS Identity and Access Management (IAM) Access Analyzer and Block Public Access (BPA).", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:02:38.327461"}}
{"question": "How does DynamoDB's fine-grained access control (FGAC) work with Amazon IAM for controlling access to table data?", "answer": "Fine-grained access control in DynamoDB lets the table owner provide permissions for access to items or attributes of the table and associated actions using AWS Identity and Access Management (IAM) policies and conditions.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:02:38.327705"}}
{"question": "What is the difference between using DynamoDB via a gateway endpoint and using it with AWS PrivateLink for accessing it from a VPC?", "answer": "A gateway endpoint allows access to DynamoDB from your VPC without requiring an internet gateway or NAT device, but it does not allow access from on-premises networks, peered VPCs in other AWS Regions, or through a transit gateway. AWS PrivateLink is available for an additional cost and enables access from these scenarios.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:02:38.328103"}}
{"question": "What encryption method is used for HTTPS protocol?", "answer": "HTTPS protocol uses Secure Sockets Layer encryption.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-11T15:02:44.487636"}}
{"question": "How does encryption at rest in DynamoDB work and what are the key type options?", "answer": "Encryption at rest in DynamoDB uses encryption keys stored in AWS Key Management Service (AWS KMS). There are three key types: AWS owned keys, AWS managed keys, and customer managed keys. AWS owned keys are managed entirely by AWS and are used by default. AWS managed keys are customer master keys (CMKs) stored in AWS KMS that are managed and used on the customer's behalf by AWS. Customer managed keys are CMKs that you create, own, and manage in AWS KMS. Each key type provides a different balance of convenience, control, and cost.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-11T15:02:44.487981"}}
{"question": "How does encryption at rest in DynamoDB compare to AWS managed keys in terms of control and cost?", "answer": "Encryption at rest in DynamoDB and AWS managed keys both use AWS Key Management Service (AWS KMS) for managing encryption keys. However, AWS managed keys offer additional control and auditing capabilities compared to encryption at rest. The cost difference depends on the usage - encryption at rest is included in the DynamoDB pricing, while using AWS managed keys incurs additional costs.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-5", "source_tokens": 372, "generated_at": "2026-02-11T15:02:44.488276"}}
{"question": "What actions are logged at the item level in DynamoDB with AWS CloudTrail?", "answer": "DynamoDB logs creates, updates, deletes, and conditional check failures at the item level with AWS CloudTrail.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-11T15:02:49.223881"}}
{"question": "Why can DynamoDB be used to build HIPAA-compliant applications?", "answer": "DynamoDB supports HIPAA compliance through various certifications, including HIPAA eligibility, and allows customers to execute Business Associate Agreements (BAA) with AWS.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-11T15:02:49.224164"}}
{"question": "How does using Amazon DynamoDB global tables improve application availability and resiliency?", "answer": "Amazon DynamoDB global tables provide 99.999% availability and improve application resiliency by replicating tables across your choice of AWS Regions, enabling high availability in the unlikely event of isolation or degradation of an entire Region.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-6", "source_tokens": 497, "generated_at": "2026-02-11T15:02:49.224599"}}
{"question": "Which versions of DynamoDB global tables are available?", "answer": "The available versions are version 2019.11.21 (Current) and version 2017.11.29 (Legacy).", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-11T15:02:53.848227"}}
{"question": "Why is it recommended to use the latest version of DynamoDB global tables?", "answer": "The latest version is more efficient and consumes less write capacity.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-11T15:02:53.848577"}}
{"question": "What's the difference between a replica table and the primary table in a DynamoDB global table?", "answer": "A replica table is a single DynamoDB table that stores the same set of data items, has the same table name, and the same primary key schema. When an application writes data to a replica table in one Region, DynamoDB automatically replicates the writes to other replica tables in the other AWS Regions.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-7", "source_tokens": 470, "generated_at": "2026-02-11T15:02:53.849105"}}
{"question": "What is a requirement for creating a new replica in a different region for a DynamoDB global table?", "answer": "The table must have DynamoDB Streams enabled, have the same name as all other replicas, have the same partition key as all other replicas, and have the same write capacity settings specified.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-11T15:02:58.078941"}}
{"question": "How does enabling multi-Region strong consistency in a DynamoDB global table improve application resiliency?", "answer": "It allows building applications with zero Recovery Point Objective (RPO) and the highest levels of resiliency.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-11T15:02:58.079286"}}
{"question": "What are the two streaming models DynamoDB offers for change data capture?", "answer": "DynamoDB Streams and Kinesis Data Streams for DynamoDB.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-8", "source_tokens": 403, "generated_at": "2026-02-11T15:02:58.079493"}}
{"question": "What is the purpose of DynamoDB Streams in relation to DynamoDB tables?", "answer": "DynamoDB Streams is a service that captures and stores information about changes to items in a DynamoDB table as an ordered flow. It stores this information in a log for up to 24 hours and automatically scales capacity.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-11T15:03:05.252927"}}
{"question": "Why would you use DynamoDB Streams instead of Kinesis Data Streams for DynamoDB when processing item-level modifications?", "answer": "You would use DynamoDB Streams if you want record ordering, deduplication, and native integration with AWS Lambda for triggers, near real-time response to data changes, and improved application resiliency through replicating item-level transactional data. Use Kinesis Data Streams if you need longer data retention (up to 365 days), replayability, customized shard management for downstream consumption and streaming analytics, and if you require integration with the Kinesis ecosystem (like the Kinesis Client Library, Amazon Managed Service for Apache Flink, or Amazon Data Firehose).", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-11T15:03:05.253138"}}
{"question": "What are the benefits of using DynamoDB Streams to build applications that consume stream events?", "answer": "Using DynamoDB Streams to build applications that consume stream events allows you to respond to data changes with triggers using native integration with AWS Lambda, track and analyze customer interactions or monitor application performance in near real time, capture ordered sequences of events, and improve application resiliency through replicating item-level transactional data.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-9", "source_tokens": 441, "generated_at": "2026-02-11T15:03:05.253278"}}
{"question": "What information is included in a data record sent out by a DynamoDB table when a stream is enabled?", "answer": "A data record sent out by a DynamoDB table when a stream is enabled includes the specific time any item was recently created, updated, or deleted, that item's primary key, an image of the item before the modification, and an image of the item after the modification.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-11T15:03:10.571867"}}
{"question": "Why would I choose to use DynamoDB Streams over Kinesis Data Streams?", "answer": "You would choose to use DynamoDB Streams over Kinesis Data Streams when you specifically need to track DynamoDB table changes.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-11T15:03:10.572244"}}
{"question": "How does the Amazon DynamoDB Time to Live (TTL) feature compare to DynamoDB Streams?", "answer": "DynamoDB Streams and DynamoDB TTL are two different features with distinct purposes. DynamoDB Streams are used to track table changes, while DynamoDB TTL is used to automatically delete expired items from a table to reduce storage usage and lower costs.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-10", "source_tokens": 313, "generated_at": "2026-02-11T15:03:10.572710"}}
{"question": "What is the required attribute for items in a DynamoDB table?", "answer": "The primary key is the only required attribute for items in a DynamoDB table.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:03:15.383707"}}
{"question": "How does DynamoDB allow for flexible querying?, and what are the two types of indexes it provides for this?", "answer": "DynamoDB allows for flexible querying by letting you query on nonprimary key attributes using global secondary indexes and local secondary indexes.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:03:15.384079"}}
{"question": "What's the difference between a single-attribute partition key and a composite partition-sort key in DynamoDB?", "answer": "A single-attribute partition key, such as UserID, allows for quick read and write operations for an item associated with a given user ID. A composite partition-sort key (UserID and Timestamp) maintains a hierarchy between the first and second element values and allows you to search across the sort key element to retrieve items.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:03:15.384525"}}
{"question": "What does the DynamoDB-OpenSearch Service integration abstract away in terms of data pipeline management?", "answer": "The DynamoDB-OpenSearch Service integration abstracts away the operational complexity in orchestrating the replication of data from a transactional datastore to a search datastore.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T15:03:21.339416"}}
{"question": "Why is the zero-ETL integration between DynamoDB and OpenSearch Service beneficial for customers?", "answer": "The zero-ETL integration between DynamoDB and OpenSearch Service benefits customers by offering a fully managed solution for making transactional data from DynamoDB available in OpenSearch Service within seconds, enabling near real-time search results and consolidating their core analytics assets for cost savings and operational efficiencies.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T15:03:21.339640"}}
{"question": "What are the options for data replication from DynamoDB to OpenSearch Service and what do they offer?", "answer": "Customers can choose either DynamoDB Streams for near real-time replication or DynamoDB Incremental Exports for delayed replication as the Change Data Capture (CDC) mechanism to keep the data between the two systems in sync. DynamoDB Streams offer near real-time replication while DynamoDB Incremental Exports provide delayed replication.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T15:03:21.339812"}}
{"question": "What permissions does DynamoDB zero-ETL integration grant to OpenSearch Ingestion for data transfer?", "answer": "DynamoDB zero-ETL integration creates an IAM role with necessary permissions to read data from DynamoDB tables and writes to an OpenSearch domain or collection. OpenSearch Ingestion pipelines assume this role to ensure the right security posture during data transfer.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T15:03:26.944162"}}
{"question": "How does the DynamoDB zero-ETL integration with OpenSearch Service enable data transformation?", "answer": "The integration uses the native data transformational capabilities of OpenSearch Ingestion pipelines to aggregate and filter data as it moves from DynamoDB to OpenSearch Service. Customers can also write custom logic for OpenSearch Ingestion for bespoke transformational capability.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T15:03:26.944423"}}
{"question": "How does the DynamoDB zero-ETL integration with OpenSearch Service compare to traditional ETL processes?", "answer": "Unlike traditional ETL processes, this zero-ETL integration does not require extracting, transforming, and loading data into a separate data warehouse. Instead, it uses native data transformational capabilities of OpenSearch Ingestion pipelines in real time.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-13", "source_tokens": 414, "generated_at": "2026-02-11T15:03:26.944590"}}
{"question": "What is the cost of using DynamoDB zero-ETL integration with OpenSearch Service, aside from the costs of the underlying components?", "answer": "The cost involves the OpenSearch Compute Units (OCUs) needed for OpenSearch Ingestion to replicate the data.", "question_type": "factual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-11T15:03:31.432247"}}
{"question": "How does DynamoDB zero-ETL integration with OpenSearch Service work conceptually?", "answer": "OpenSearch Ingestion reads data from DynamoDB tables and replicates it to OpenSearch Service.", "question_type": "conceptual", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-11T15:03:31.432601"}}
{"question": "What is the difference in costs between using incremental exports and DynamoDB streams for DynamoDB zero-ETL integration with OpenSearch Service?", "answer": "For incremental exports, there is a cost associated with writing data to S3 buckets. For DynamoDB streams, customers would be charged the standard charges for using DynamoDB streams.", "question_type": "comparison", "metadata": {"service": "DYNAMODB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "dynamodb-faq-14", "source_tokens": 210, "generated_at": "2026-02-11T15:03:31.432953"}}
{"question": "What are the six types of Amazon EBS volumes and what are their performance characteristics?", "answer": "Amazon EBS provides six types of volumes: Provisioned IOPS SSD (io2 and io1), General Purpose SSD (gp3 and gp2), Throughput Optimized HDD (st1), and Cold HDD (sc1). io2 Block Express volumes have the lowest latency with an average of sub-milliseconds, while the average latency between EC2 instances and EBS is single-digit milliseconds.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-11T15:03:37.124046"}}
{"question": "What is the difference between using Amazon EBS as a root partition and local instance store, in terms of data persistence?", "answer": "Data stored on Amazon EBS volumes can persist independently of the life of the instance, while data stored on a local instance store persists only as long as that instance is alive. Therefore, it is recommended to use local instance store for temporary data and Amazon EBS for data requiring a higher level of durability.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-11T15:03:37.124382"}}
{"question": "What is the average latency between EC2 instances and Amazon EBS volumes?", "answer": "The average latency between EC2 instances and Amazon EBS volumes is single-digit milliseconds.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-0", "source_tokens": 367, "generated_at": "2026-02-11T15:03:37.124883"}}
{"question": "Which two major categories does Amazon EBS include?", "answer": "Amazon EBS includes two major categories of storage: SSD-backed storage and HDD-backed storage.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-11T15:03:42.504543"}}
{"question": "What type of workloads are SSD-backed volumes suitable for and why?", "answer": "SSD-backed volumes are suitable for transactional workloads, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. They offer better performance compared to HDD-backed volumes due to their lower latency and higher durability.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-11T15:03:42.504798"}}
{"question": "How does the performance of io2 Block Express volumes compare to that of other EBS volumes?", "answer": "Io2 Block Express volumes offer 10X fewer I/Os exceeding 800 microseconds than General Purpose volumes and an average latency below 500 microseconds for 16KiB I/O operations. They are designed for business-critical applications and offer 100X greater durability at 99.999% compared to other EBS volumes.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-1", "source_tokens": 438, "generated_at": "2026-02-11T15:03:42.505176"}}
{"question": "What type of replication does Amazon EBS volume data undergo at no additional cost?", "answer": "Amazon EBS volume data is replicated across multiple servers in an Availability Zone to prevent data loss from the failure of any single component.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-11T15:03:47.120082"}}
{"question": "Why is it recommended to use manual mechanisms for disaster recovery in case of EBS volume failure?", "answer": "Manual mechanisms for disaster recovery, such as detaching unavailable volumes and attaching backup recovery volumes, are recommended in case of EBS volume failure in addition to automated monitoring and failover mechanisms.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-11T15:03:47.120443"}}
{"question": "How does the Elastic Volumes feature differ from EBS Magnetic volumes in terms of functionality?", "answer": "The Elastic Volumes feature allows increasing capacity, tuning performance, or changing volume type with a single call, while EBS Magnetic volumes, formerly known as EBS Standard Volumes, have no functional differences.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-2", "source_tokens": 371, "generated_at": "2026-02-11T15:03:47.120904"}}
{"question": "What IOPS and throughput can be achieved with EBS-optimized EC2 instances and io1 or io2 Block Express volumes?", "answer": "EBS-optimized EC2 instances support io1 and io2 Block Express volumes. The dedicated throughput between Amazon EC2 and Amazon EBS for EBS-optimized instances ranges from 62.5 MB/s to 12,500 MB/s based on the instance type. To achieve the limit of 256,000 IOPS and 4,000 MB/s throughput, io2 Block Express volumes must be attached to Nitro System-based instances.io1 Block Express volumes provide a minimum guaranteed IOPS, while io2 Block Express volumes aim to deliver within 10% of the provisioned IOPS performance 99.9% of the time.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-11T15:03:55.745173"}}
{"question": "What advantages does using io2 Block Express volumes with Nitro System-based EC2 instances offer over General Purpose volumes?", "answer": "When attached to Nitro System-based EC2 instances, io2 Block Express volumes are designed to deliver an average latency of under 500 microseconds for 16KiB I/O operations. This results in a better outlier latency experience compared to General Purpose volumes, as it reduces the frequency of IOs that exceed 800 microseconds by more than 10 times.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-11T15:03:55.745518"}}
{"question": "How does the performance of io2 Block Express volumes on Nitro System-based EC2 instances compare to io2 Block Express volumes on non-Nitro System-based EC2 instances?", "answer": "Io2 Block Express volumes on Nitro System-based EC2 instances deliver an average latency of under 500 microseconds for 16KiB I/O operations. In contrast, the exact performance of io2 Block Express volumes on non-Nitro System-based EC2 instances is not specified in the provided context.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-3", "source_tokens": 339, "generated_at": "2026-02-11T15:03:55.746004"}}
{"question": "What is the relationship between the IOPS rate and the I/O size when using Provisioned IOPS for io2 Block Express volumes?", "answer": "The IOPS rate achieved with Provisioned IOPS for io2 Block Express volumes depends on the I/O size of your application reads and writes. For example, if you have provisioned a volume with 40,000 IOPS for an I/O size of 16KB, it will achieve up to 40,000 IOPS at that size. However, if the I/O size is increased to 256 KB, then you will achieve up to 16,000 IOPS.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:04:03.910690"}}
{"question": "How does using io2 Block Express volumes with Nitro System-based EC2 instances improve the outlier latency experience compared to General Purpose volumes?", "answer": "Io2 Block Express volumes attached to Nitro System-based EC2 instances deliver a better outlier latency experience compared to General Purpose volumes due to reduced frequency of IOs that exceed 800 microseconds by more than 10 times.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:04:03.911022"}}
{"question": "What is the base I/O size for Provisioned IOPS volumes and how does it impact the IOPS rate?", "answer": "The base I/O size for Provisioned IOPS volumes is 16KB. The IOPS rate you get depends on this base I/O size. For instance, if you have provisioned a volume with 40,000 IOPS for a 16KB I/O size, it will achieve up to 40,000 IOPS at that size. However, if the I/O size is increased, the IOPS rate will decrease accordingly.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:04:03.911185"}}
{"question": "What is the guaranteed throughput performance for st1 and sc1 HDD volumes when attached to EBS-optimized instances?", "answer": "The guaranteed throughput performance for st1 and sc1 HDD volumes when attached to EBS-optimized instances is to deliver within 10% of the expected throughput performance 99% of the time in a given year.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-11T15:04:08.519561"}}
{"question": "How does the performance of HDD-backed volumes on EBS compare to transactional workloads with small, random IOs?", "answer": "HDD-backed volumes on EBS do not perform well on transactional workloads with small, random IOs, such as databases.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-11T15:04:08.519870"}}
{"question": "What type of I/O operations does HDD-backed volumes on EBS process and how does it affect performance?", "answer": "HDD-backed volumes on EBS process I/O operations in I/O sizes of 1MB. Sequential I/Os and large I/O sizes will achieve the advertised performance, while small, random IOs will not.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-5", "source_tokens": 227, "generated_at": "2026-02-11T15:04:08.520040"}}
{"question": "What is the expected throughput performance of st1 and sc1 HDD volumes, and what percentage of that performance is guaranteed?", "answer": "The expected throughput performance of st1 and sc1 HDD volumes is designed to offer consistent performance, delivering within 10% of the expected throughput performance 99% of the time in a given year.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T15:04:14.544068"}}
{"question": "How can the balance between random and sequential I/O operations affect the performance of st1 and sc1 HDD volumes?", "answer": "Too many random small I/O operations can quickly deplete I/O credits and lower performance down to the baseline rate.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T15:04:14.544269"}}
{"question": "How does the performance of st1 HDD volumes compare to io2 Block Express volumes when achieving high IOPS or Mbps?", "answer": "You can stripe multiple st1 or sc1 volumes together to achieve up to 400,000 IOPS or 12,500 Mbps when attached to larger EC2 instances. However, io2 Block Express volumes are recommended for higher performance requirements without needing the operational management of striping multiple volumes. The performance for st1 and sc1 scales linearly with volume size, so there may not be as much of a benefit to stripe these volumes together.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-6", "source_tokens": 425, "generated_at": "2026-02-11T15:04:14.544412"}}
{"question": "What is the defined performance for General Purpose SSD (gp3 and gp2) volumes when attached to EBS-optimized instances?", "answer": "General Purpose SSD (gp3 and gp2) volumes can deliver within 10% of the provisioned IOPS performance 99% of the time and achieve single digit millisecond latencies.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T15:04:20.767687"}}
{"question": "How does EBS ensure adequate performance for General Purpose SSD (gp3 and gp2) volumes attached to EBS-optimized instances?", "answer": "EBS uses defined performance criteria and instance-level performance definition, along with monitoring and infrastructure allocation, to ensure adequate performance for General Purpose SSD (gp3 and gp2) volumes attached to EBS-optimized instances.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T15:04:20.768020"}}
{"question": "How does the performance of General Purpose SSD (gp3) volumes compare to the performance of General Purpose SSD (gp2) volumes when attached to EBS-optimized instances?", "answer": "Both General Purpose SSD (gp3 and gp2) volumes have defined performance characteristics, but the exact performance depends on the application's I/O requirements. The main difference is that gp3 volumes include 3,000 IOPS and 125 MB/s of consistent performance at no additional cost.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-7", "source_tokens": 473, "generated_at": "2026-02-11T15:04:20.768408"}}
{"question": "What is the burst IOPS performance for gp2 volumes under 1,000 GB?", "answer": "gp2 volumes under 1,000 GB receive burst IOPS performance up to 3,000 IOPS for at least 30 minutes.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T15:04:24.993115"}}
{"question": "How does EBS Block Express differ from gp2 volumes in terms of performance?", "answer": "EBS Block Express offers sub-millisecond latency, higher IOPS, and larger capacity in a single volume compared to gp2 volumes.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T15:04:24.993449"}}
{"question": "For which types of workloads is io2 Block Express ideal?", "answer": "io2 Block Express is suited for performance and capacity intensive workloads such as relational and NoSQL databases and critical business operation workloads.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-8", "source_tokens": 447, "generated_at": "2026-02-11T15:04:24.993946"}}
{"question": "What should be used for quickly initialized EBS volumes?", "answer": "Provisioned Rate for Volume Initialization should be used for quickly initialized EBS volumes.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-11T15:04:28.328070"}}
{"question": "Why is Provisioned Rate for Volume Initialization useful?", "answer": "Provisioned Rate for Volume Initialization is useful for workloads that need the underlying EBS volumes to be fully initialized as quickly as possible.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-11T15:04:28.328384"}}
{"question": "What's the difference between gp3 and io2 Block Express volumes?", "answer": "gp3 volumes are ideal for applications that require a balance between cost and performance, while io2 Block Express volumes are recommended for applications that need higher durability, better latency consistency, or higher IOPS and throughput.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-9", "source_tokens": 247, "generated_at": "2026-02-11T15:04:28.328803"}}
{"question": "Which APIs can be used to work with Amazon EBS snapshots in AWS?", "answer": "The List Snapshot Blocks, List Changed Blocks, Get Snapshot Blocks, Start Snapshot, Put Snapshot Block, and Complete Snapshot APIs can be used to manage Amazon EBS snapshots in AWS.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-11T15:04:32.644379"}}
{"question": "How does the process of creating an Amazon EBS snapshot work?", "answer": "You can start a snapshot using the Start Snapshot operation, then add data to the snapshot using the PutSnapshotBlock operation. Once all data has been added, you can complete the snapshot using the Complete Snapshot operation.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-11T15:04:32.644732"}}
{"question": "How does the block size differ between GetSnapshotBlock and PutSnapshotBlock APIs?", "answer": "Both APIs support a 512KiB block size.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-10", "source_tokens": 456, "generated_at": "2026-02-11T15:04:32.645191"}}
{"question": "How long does it take to create a snapshot of a 16 TB EBS volume, according to the text?", "answer": "The text states that by design, creating a snapshot of a 16 TB EBS volume should take no longer than the time it takes to snapshot a 1 TB volume.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-11T15:04:37.499094"}}
{"question": "Why would you enable Fast Snapshots (FSR) on an EBS snapshot?", "answer": "According to the text, you should enable FSR on an EBS snapshot to help with use cases such as virtual desktop infrastructure (VDI), backup & restore, test/dev volume copies, and booting from custom AMIs, and to improve and predictable performance whenever you need to restore data from that snapshot.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-11T15:04:37.499365"}}
{"question": "How does enabling Fast Snapshots (FSR) on an EBS snapshot impact snapshot creation time?", "answer": "The text states that enabling FSR on an EBS snapshot does not speed up snapshot creation time.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-11", "source_tokens": 410, "generated_at": "2026-02-11T15:04:37.499742"}}
{"question": "What number of credits is associated with an FSR-enabled snapshot of a given size in the AWS console?", "answer": "The number of credits associated with an FSR-enabled snapshot can be estimated by dividing 1,024 by the snapshot size.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-11T15:04:42.311153"}}
{"question": "How does enabling Fast Snapshot Restores (FSR) on a snapshot impact the volume creation process?", "answer": "Enabling FSR on a snapshot allows volumes to be created from the snapshot with full initialization. The number of volumes that can be created at once is determined by the credit bucket size, which is a function of the snapshot size.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-11T15:04:42.311446"}}
{"question": "How does the credit bucket size and refill rate for an FSR-enabled snapshot in one Availability Zone (AZ) compare to another AZ?", "answer": "Each AZ in which an FSR-enabled snapshot is located has its own independent credit bucket with its own size and refill rate.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-12", "source_tokens": 469, "generated_at": "2026-02-11T15:04:42.311906"}}
{"question": "What is the relationship between the maximum size and balance of a credit bucket when using FSR?", "answer": "The maximum size of a credit bucket represents the maximum number of creates, and the balance of the credit bucket represents the number of creates available. When using FSR, both the maximum size and credit bucket balance are published as CloudWatch metrics, allowing up to 10 initialized volumes to be created from an FSR-enabled snapshot at once.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-11T15:04:47.841024"}}
{"question": "How does enabling FSR for a shared snapshot affect billing?", "answer": "When you enable FSR for a shared snapshot, you will be billed at standard FSR rates. Only your account will be billed for the FSR of the shared snapshot, while the owner of the snapshot will not be billed.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-11T15:04:47.841420"}}
{"question": "What happens to the FSR and billing when a shared snapshot is deleted or permissions are revoked?", "answer": "When the owner of a shared snapshot deletes the snapshot or stops sharing it by revoking your permissions to create volumes from the snapshot, the FSR for the shared snapshot is automatically disabled, and FSR billing for the snapshot is terminated.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-13", "source_tokens": 465, "generated_at": "2026-02-11T15:04:47.841866"}}
{"question": "What encryption algorithm does Amazon EBS use for data at rest?", "answer": "Amazon EBS uses the industry-standard AES-256 encryption algorithm for data at rest.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-11T15:04:52.472841"}}
{"question": "How does Amazon EBS encryption handle key management for data at rest?", "answer": "Amazon EBS encryption creates a unique 256-bit AES key for each newly created volume. Volumes created from encrypted snapshots share the same key. These keys are protected by Amazon's key management infrastructure and encrypted using AES-256.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-11T15:04:52.473200"}}
{"question": "What is the difference between creating an encrypted EBS volume with a default CMK and a custom CMK?", "answer": "Creating an encrypted EBS volume with a default CMK means using an AWS-managed key, while creating an encrypted EBS volume with a custom CMK means using a customer-managed key.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-14", "source_tokens": 503, "generated_at": "2026-02-11T15:04:52.473347"}}
{"question": "What happens when you detach an encrypted EBS volume and it's not immediately deleted?", "answer": "You will be billed for the IOPS provisioned when the volume is disconnected. To reduce costs, it's recommended to create a snapshot and delete the volume.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-11T15:04:57.074818"}}
{"question": "How does using a customer-managed customer master key (CMK) for sharing encrypted snapshots and AMIs benefit users?", "answer": "Users can share encrypted snapshots and AMIs with other AWS accounts using their own managed keys, enhancing security and control.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-11T15:04:57.075119"}}
{"question": "How does Provisioned Rate for Volume Initialization compare to not using it for EBS volumes?", "answer": "Provisioned Rate for Volume Initialization ensures quick initialization of EBS volumes and is beneficial for workloads that require predictable performance and rapid volume availability. Without it, volumes may take longer to become fully performant.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-15", "source_tokens": 417, "generated_at": "2026-02-11T15:04:57.075557"}}
{"question": "What determines the deleteOnTermination behavior of an Amazon Elastic Block Store (EBS) volume?", "answer": "The deleteOnTermination behavior of an Amazon Elastic Block Store (EBS) volume is determined by the configuration of the last attached instance that is terminated.", "question_type": "factual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-11T15:05:02.404557"}}
{"question": "Why is it important to configure deleteOnTermination for all instances attached to an EBS volume?", "answer": "It is important to configure deleteOnTermination consistently for all instances attached to an EBS volume to ensure predictable behavior. If deleteOnTermination is enabled for some instances and disabled for others, the volume may be deleted on termination for some instances but not for others.", "question_type": "conceptual", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-11T15:05:02.404891"}}
{"question": "How does Multi-Attach impact the deleteOnTermination behavior of an EBS volume compared to a single-attached volume?", "answer": "Multi-Attach allows an EBS volume to be attached to and used by multiple instances at the same time. The deleteOnTermination behavior of a Multi-Attach volume is determined in the same way as for a single-attached volume, based on the configuration of the last attached instance that is terminated.", "question_type": "comparison", "metadata": {"service": "EBS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ebs-faq-16", "source_tokens": 180, "generated_at": "2026-02-11T15:05:02.405093"}}
{"question": "How many billing and purchase options are available in Amazon EC2?", "answer": "There are 11 billing and purchase options available in Amazon EC2.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-11T15:05:05.606254"}}
{"question": "Why would you consider using Nitro System support for previous generation instances?", "answer": "The context does not provide enough information to answer this question conceptually.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-11T15:05:05.606494"}}
{"question": "How does the number of networking and security options compare to the number of instance types in Amazon EC2?", "answer": "There are 6 networking and security options and 10 instance types in Amazon EC2.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-0", "source_tokens": 95, "generated_at": "2026-02-11T15:05:05.606880"}}
{"question": "What service does Amazon EC2 provide in AWS?", "answer": "Amazon EC2 is a web service that provides resizable compute capacity in AWS.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T15:05:08.919361"}}
{"question": "How does Amazon EC2 help developers?", "answer": "Amazon EC2 helps developers by making web-scale computing easier for them with minimal friction, reducing the time required to obtain and boot new server instances, allowing quick scaling of capacity, and offering pay-as-you-go pricing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T15:05:08.919606"}}
{"question": "How does Amazon EC2 compare to traditional computing?", "answer": "Amazon EC2 differs from traditional computing by providing on-demand, scalable computing resources without requiring upfront investment or performance compromises.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-1", "source_tokens": 488, "generated_at": "2026-02-11T15:05:08.919999"}}
{"question": "What are the steps to launch an Amazon EC2 instance using the RunInstances API?", "answer": "To launch an Amazon EC2 instance using the RunInstances API, you need to indicate the number of instances you wish to launch and select or create your Amazon Machine Image (AMI). If your quota allows, the API call will return success and the instances will start launching. You can check on the status of your instances using the DescribeInstances API call, terminate instances using the TerminateInstances API call, and release compute resources while preserving data on the boot partition using the StopInstances API call. You also have the option to use Spot Instances to reduce computing costs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T15:05:16.923106"}}
{"question": "How does using the Elastic Block Store (EBS) for the root device differ from using the local instance store in Amazon EC2?", "answer": "Using the Elastic Block Store (EBS) for the root device in Amazon EC2 allows you to have more flexibility in managing your instances, as you can stop and start instances while preserving the data on the boot partition. In contrast, using the local instance store means that the data will not be persisted if the instance is stopped or terminated. Additionally, EBS supports larger volumes and snapshots, allowing for data backup and recovery.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T15:05:16.923449"}}
{"question": "Why is the 'Elastic' nature of Amazon EC2 beneficial for developers compared to traditional hosting services?", "answer": "The 'Elastic' nature of Amazon EC2 allows developers to instantly respond to changes in computing requirements, meaning that they have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, limiting users' ability to easily respond when their usage is rapidly changing, unpredictable, or experiences large peaks.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T15:05:16.923890"}}
{"question": "What are the two options for storing root device data when launching Amazon EC2 instances?", "answer": "When launching Amazon EC2 instances, you have the option to store your root device data on Amazon EBS or the local instance store.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-11T15:05:21.845472"}}
{"question": "What are some use cases for using the local instance store instead of Amazon EBS for storing root device data?", "answer": "Some customers use the local instance store option to run large web sites where each instance is a clone to handle web traffic. This is an inexpensive way to launch instances where data is not stored to the root device.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-11T15:05:21.845734"}}
{"question": "How does the use of Amazon EBS impact the ability to stop and restart instances in comparison to the local instance store?", "answer": "By using Amazon EBS, data on the root device will persist independently from the lifetime of the instance, enabling you to stop and restart the instance at a subsequent time. In contrast, the local instance store only persists during the life of the instance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-3", "source_tokens": 484, "generated_at": "2026-02-11T15:05:21.846136"}}
{"question": "What are the DNS names I can use to access my systems in Amazon EC2?", "answer": "The RunInstances call that initiates execution of your application stack will return a set of DNS names, one for each system that is being booted. These names can be used to access the system exactly as you would if it were in your own data center.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:05:28.546964"}}
{"question": "How is Amazon S3 used in conjunction with Amazon EC2?", "answer": "Amazon EC2 and Amazon S3 are used together for instances with root devices backed by local instance storage. Amazon S3 provides the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of websites. Developers use the tools provided to load their AMIs into Amazon S3 and move them between Amazon S3 and Amazon EC2.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:05:28.547310"}}
{"question": "What are the limitations in the number of instances I can run in Amazon EC2 compared to Amazon S3?", "answer": "You can run a certain number of On-Demand Instances per your vCPU-based On-Demand Instance limit, purchase 20 Reserved Instances, and request Spot Instances per your dynamic Spot limit in each region. New AWS accounts may start with limits that are lower than the limits described here. If you need more instances, you can submit a limit increase request form with your use case, and your limit increase will be considered. Limit increases are tied to the region they were requested for.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-4", "source_tokens": 473, "generated_at": "2026-02-11T15:05:28.547805"}}
{"question": "What operating systems are supported by Amazon EC2 for instance creation?", "answer": "Amazon EC2 currently supports a variety of operating systems including: Amazon Linux, Ubuntu, Windows Server, Red Hat Enterprise Linux, SUSE Linux Enterprise Server, openSUSE Leap, Fedora, Fedora CoreOS, Debian, CentOS, Gentoo Linux, Oracle Linux, and FreeBBS.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-11T15:05:34.331097"}}
{"question": "Why would we use Amazon EC2 instead of a traditional hosting service?", "answer": "Amazon EC2 offers flexibility, control, and significant cost savings compared to traditional hosting services. It allows developers to treat it as their own personal data center with the benefit of Amazon.com's robust infrastructure. Amazon EC2 can instantly respond to changes in computing requirements, while traditional hosting services generally provide a fixed number of resources for a fixed amount of time, limiting users' ability to easily respond when usage is rapidly changing or unpredictable.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-11T15:05:34.331442"}}
{"question": "How does the memory in Amazon EC2 instances compare to regular hosting services?", "answer": "All the hardware underlying Amazon EC2 uses ECC memory, which is necessary for server infrastructure. This is a key difference compared to traditional hosting services, which may not always use ECC memory.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-5", "source_tokens": 499, "generated_at": "2026-02-11T15:05:34.331977"}}
{"question": "What is unique about Amazon EC2's resource control compared to other hosting services?", "answer": "Amazon EC2 allows developers to initiate or shut down instances at any time and customize their instance configurations to suit their needs, while many other hosting services offer limited ability to change these.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-11T15:05:38.850172"}}
{"question": "How does the resource consumption billing differ between Amazon EC2 and other hosting services?", "answer": "Amazon EC2 developers pay only for their actual resource consumption at very low rates, while other hosting services require users to pay a fixed, upfront fee irrespective of their actual computing power used.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-11T15:05:38.850513"}}
{"question": "In what way can developers control the compute resources in Amazon EC2 that is different from other hosting services?", "answer": "Developers can initiate or shut down Amazon EC2 instances and completely customize their instance configurations to suit their needs at any time, whereas other hosting services offer limited ability to change these.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-6", "source_tokens": 163, "generated_at": "2026-02-11T15:05:38.850964"}}
{"question": "What is the number of vCPUs for the nano instance size?", "answer": "1", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-11T15:05:43.065910"}}
{"question": "How does the vCPU-based limit system work in Amazon EC2?", "answer": "Amazon EC2 measures usage towards each vCPU-based limit based on the total number of vCPUs assigned to running On-Demand instances in an AWS account. Each instance family has a defined vCPU limit, and all usage of instances within that family, regardless of size or configuration variant, accrues towards that limit.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-11T15:05:43.066253"}}
{"question": "What is the difference between the default vCPU limit for Running On-Demand Standard instances and the vCPU limit for Running On-Demand F instances?", "answer": "The default vCPU limit for Running On-Demand Standard instances is 1152 vCPUs, while the vCPU limit for Running On-Demand F instances is 128 vCPUs.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-7", "source_tokens": 511, "generated_at": "2026-02-11T15:05:43.066425"}}
{"question": "Are the On-Demand Instance vCPU limits regional?", "answer": "Yes, the On-Demand Instance limits for an AWS account are set on a per-region basis.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:05:46.514193"}}
{"question": "How does the vCPU limit increase work?", "answer": "Amazon EC2 automatically increases your On-Demand Instance limits based on your usage, but you can also request a limit increase from the Service Quotas console or API.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:05:46.514444"}}
{"question": "What is the difference between vCPU-based and count-based limits for On-Demand Instances?", "answer": "vCPU-based limits allow the same number of instances as count-based limits, but they limit based on total vCPU capacity instead of instance count.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:05:46.514813"}}
{"question": "What impact does vCPU limit have on monthly bill?", "answer": "vCPU limits do not affect the monthly bill as EC2 usage is still calculated based on hourly or secondly rates.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-11T15:05:50.270499"}}
{"question": "Why do we need to use Service Quotas APIs instead of the API for max-instances?", "answer": "We need to use the Service Quotas APIs instead of the API for max-instances because the API for max-instances no longer returns the max-instances value.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-11T15:05:50.270879"}}
{"question": "How does the availability of vCPU limits compare between commercial Regions and other AWS Regions?", "answer": "vCPU-based instance limits are available in all commercial AWS Regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-9", "source_tokens": 141, "generated_at": "2026-02-11T15:05:50.271407"}}
{"question": "What change was made to Amazon EC2 regarding email traffic on port 25?", "answer": "As of January 7, 2020, Amazon EC2 began restricting email traffic over port 25 by default to protect customers and other recipients from spam and email abuse.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-11T15:05:55.476948"}}
{"question": "What should I do if I need to send emails using port 25 from EC2?", "answer": "If you have a valid use case for sending emails to port 25 (SMTP) from EC2, you can submit a Request to Remove Email Sending Limitations to have these restrictions lifted. Alternatively, you can send emails using a different port or leverage an existing authenticated email relay service like Amazon Simple Email Service (Amazon SES).", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-11T15:05:55.477148"}}
{"question": "How does the Amazon EC2 SLA compare to the Amazon EBS SLA?", "answer": "Both Amazon EC2 and Amazon EBS have an SLA guarantee of a Monthly Uptime Percentage of at least 99.99% within a Region.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-10", "source_tokens": 389, "generated_at": "2026-02-11T15:05:55.477298"}}
{"question": "What are AWS Trainium and AWS Inferentia instances used for and how do they save costs compared to EC2 instances?", "answer": "AWS Trainium and AWS Inferentia instances are designed for deep learning and generative AI workloads. They offer high performance and can save up to 50% on training and inference costs compared to comparable EC2 instances. The Neuron SDK supports a range of model architectures on these instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-11T15:06:07.252772"}}
{"question": "What options do I have for obtaining NVIDIA drivers, libraries, frameworks, and development tools for P-series and G-series instances?", "answer": "There are listings on the AWS Marketplace for Amazon Linux AMIs and Windows Server AMIs with pre-installed NVIDIA drivers. You can also launch 64-bit HVM AMIs and install the drivers yourself, but you must visit the NVIDIA driver website for the right drivers based on the instance's GPUs. Additionally, NVIDIA AI enterprise offers the NVIDIA development tools, frameworks, and pre-trained models.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-11T15:06:07.253073"}}
{"question": "What are the differences between Amazon EC2 Flex instances (M7i-flex and C7i-flex) and comparable instances (M7i and C7i)? When should I use Flex instances?", "answer": "Amazon EC2 Flex instances (M7i-flex and C7i-flex) provide more flexibility and cost savings compared to comparable instances (M7i and C7i). Flex instances let you burst CPU capacity and can automatically switch between instance types to optimize costs. Flex instances are ideal when your workload has varying CPU requirements or when you want to minimize costs.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-12", "source_tokens": 439, "generated_at": "2026-02-11T15:06:07.253234"}}
{"question": "What is the baseline CPU performance of Flex instances?", "answer": "Flex instances provide a baseline CPU performance of 40%.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-11T15:06:11.849859"}}
{"question": "In what scenarios would Flex instances be preferred over Burstable Performance Instances?", "answer": "Flex instances are ideal for workloads that fit on instance sizes up to 16xlarge and use a majority of the workload time below the baseline CPU performance. Burstable Performance Instances, on the other hand, may be preferred for workloads that require the largest instance sizes or high sustained CPU, network, or EBS performance, and that can burst above the baseline performance as needed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-11T15:06:11.850088"}}
{"question": "What is the maximum instance size for M7i-flex instances?", "answer": "M7i-flex instances support instance sizes up to 16xlarge, with a maximum of 64 vCPUs and 256 GB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-13", "source_tokens": 488, "generated_at": "2026-02-11T15:06:11.850251"}}
{"question": "What is the CPU Credits per hour for a t2.small instance?", "answer": "288 CPU Credits per hour", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-11T15:06:16.271606"}}
{"question": "How does the CPU credit system in T2 instances impact baseline and burst CPU performance?", "answer": "T2 instances' baseline performance and ability to burst are governed by CPU Credits. T2 instances accrue CPU Credits when they are idle and consume CPU credits when they are active. A CPU Credit provides the performance of a full CPU core for one minute.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-11T15:06:16.271963"}}
{"question": "What's the difference in CPU Credits between a t2.small and t2.medium instance?", "answer": "A t2.small instance receives 288 CPU Credits per hour, while a t2.medium instance receives 576 CPU Credits per hour.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-14", "source_tokens": 478, "generated_at": "2026-02-11T15:06:16.272175"}}
{"question": "What is the CPU credit balance for a T2 instance with 1 core usage?", "answer": "The text passage states that a single threaded application on a T2.2xlarge instance can use all of 1 core. It does not specify if this usage results in a positive or negative CPU credit balance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T15:06:20.607714"}}
{"question": "How does the CPU credit system impact single threaded applications on T2 instances?", "answer": "When a single threaded application on a T2 instance uses all of one core, does it impact the CPU credit balance? If so, how and why?", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T15:06:20.608000"}}
{"question": "How does the CPU credit system on a T2 instance compare to a dedicated CPU instance?", "answer": "What are the advantages and disadvantages of using a T2 instance with the CPU credit system compared to a dedicated CPU instance?", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T15:06:20.608405"}}
{"question": "Does the CPU Credit balance of a T2 instance persist during instance stop and start?", "answer": "No, a stopped T2 instance does not retain its previously earned CPU Credit balance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-11T15:06:25.349351"}}
{"question": "What types of instances can T2 instances be purchased as?", "answer": "T2 instances can be purchased as On-Demand Instances, Reserved Instances, or Spot Instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-11T15:06:25.349615"}}
{"question": "What are T4g instances and what are their benefits? How do they differ from T2 or T3 instances?", "answer": "T4g instances are the next-generation of general purpose burstable instances powered by Arm-based AWS Graviton2 processors. They offer up to 40% better price performance over T3 instances and are built on the AWS Nitro System. T2 instances are similar but not the same, providing baseline CPU performance of 10% of a physical CPU core that can be burst beyond. T3 instances also provide the ability to burst above the baseline but do not offer the same level of price performance improvement as T4g instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-16", "source_tokens": 433, "generated_at": "2026-02-11T15:06:25.349806"}}
{"question": "What number of free hours per month does a customer receive during the T4g free trial period for a t4g.small instance?", "answer": "Customers receive 750 free hours per month for a t4g.small instance during the T4g free trial period.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T15:06:32.101215"}}
{"question": "How does the T4g free trial impact customers' bills for using a t4g.small instance?", "answer": "During the free-trial period, customers who run a t4g.small instance will have 750 hours deducted from their bill each month. They will need to pay for any surplus CPU credits if they exceed the instances' allocated credits during the free hours.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T15:06:32.101546"}}
{"question": "How does the T4g free trial compare to the existing AWS Free Tier for the availability of regions?", "answer": "The T4g free trial is available in the same AWS Regions as the existing AWS Free Tier: US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), South America (Sao Paulo), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), China(Beijing), China (Ningxia), Europe (Frankfurt), Europe (Ireland), Europe (London), and Europe (Stockholm).", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-17", "source_tokens": 447, "generated_at": "2026-02-11T15:06:32.101980"}}
{"question": "What is included in the t4g.small free trial in terms of Amazon Machine Images?", "answer": "The t4g.small free trial covers the infrastructure costs for running Amazon Linux 2, RHEL, and SUSE Linux AMIs for a maximum of 750 hours per month. After the free hours limit, regular On-Demand prices, including any AMI charges, will apply.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-11T15:06:37.856517"}}
{"question": "What happens if I exceed the 750 free hours per month limit on my t4g.small instances?", "answer": "Once you exceed the limit of 750 free hours per month for your t4g.small instances, you will be charged regular On-Demand prices for the additional hours, including any applicable Amazon Machine Image charges.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-11T15:06:37.856760"}}
{"question": "How does the free trial for running t4g.small instances in multiple Regions work in comparison to running in a single Region?", "answer": "Under the t4g.small free trial, you can run instances in one or multiple Regions, with a maximum of 750 free hours per month across all regions combined. The hours used in each region do not need to be the same, but the total cannot exceed 750 hours per month.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-18", "source_tokens": 284, "generated_at": "2026-02-11T15:06:37.857139"}}
{"question": "What happens if customers exceed 750 hours of usage during the T4g free trial monthly billing cycle?", "answer": "Customers will be charged based on regular On-Demand pricing for the exceeded hours for that month. For customers with a Compute Savings Plan or T4g Instance Savings Plan, Savings Plan (SV) discount will be applied to On-Demand pricing for hours exceeding the 750 free trial hours.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-11T15:06:43.731187"}}
{"question": "How does the T4g free trial billing plan handle surplus CPU credits?", "answer": "Customers must pay for surplus CPU credits when they exceed the instances allocated credits during the 750 free hours of the T4g free trial program.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-11T15:06:43.731435"}}
{"question": "What's the difference between how the T4g free trial billing plan handles surplus CPU credits and the Compute Savings Plan or T4g Instance Savings Plan?", "answer": "The T4g free trial billing plan charges customers for surplus CPU credits beyond the 750 free hours, while the Compute Savings Plan or T4g Instance Savings Plan applies Savings Plan discount to On-Demand pricing for hours exceeding the 750 free trial hours.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-19", "source_tokens": 512, "generated_at": "2026-02-11T15:06:43.731828"}}
{"question": "When will customers be billed for t4g.small instances after the free trial ends?", "answer": "Customers will be charged regular On-Demand pricing for t4g.small instances after the free trial ends, unless they have a Reserved Instance (RI) plan or a Compute Savings Plan, in which case the Savings Plan discount will be applied.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-11T15:06:47.911604"}}
{"question": "For what type of applications are Compute Optimized instances suitable?", "answer": "Compute Optimized instances are suitable for applications that benefit from high compute power, such as high-performance web servers, high-performance computing (HPC), scientific modelling, distributed analytics, machine learning inference, and ad-serving.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-11T15:06:47.911869"}}
{"question": "How do the performance capabilities of C7g instances compare to those of C6g instances?", "answer": "C7g instances offer up to 25% better performance than C6g instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-20", "source_tokens": 509, "generated_at": "2026-02-11T15:06:47.912012"}}
{"question": "What storage options are available on C6g instances and what are their respective bandwidths?", "answer": "C6g instances offer EBS-optimized dedicated EBS bandwidth up to 19,000 Mbps for both encrypted and unencrypted EBS volumes. They support only the NVMe interface for accessing EBS storage volumes. Additionally, local NVMe instance storage is available through C6gd instance types.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-11T15:06:53.634157"}}
{"question": "How would you explain the benefits of using C6g instances for compute-intensive workloads?", "answer": "C6g instances provide significant price performance benefits for compute-intensive workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference. They are particularly appealing for customers deploying applications built on open source software and for Arm developers.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-11T15:06:53.634389"}}
{"question": "What is the difference in network interface support between C6g and other instances?", "answer": "C6g instances support ENA based Enhanced Networking, which delivers up to 25 Gbps of network bandwidth between instances when launched within a Placement Group.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-21", "source_tokens": 509, "generated_at": "2026-02-11T15:06:53.634819"}}
{"question": "What is the all-core turbo frequency of C6a instances' processors?", "answer": "The all-core turbo frequency of C6a instances' processors is 3.6 GHz.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-11T15:07:02.498343"}}
{"question": "What are the advantages of using C6a instances over C5a instances?", "answer": "C6a instances offer up to 15% better price performance, support always-on memory encryption using AMD TSME, provide larger instance sizes with up to 192 vCPUs and 384 GiB of memory, and offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-11T15:07:02.498646"}}
{"question": "How does the networking performance of C6i instances compare to that of C5i instances?", "answer": "C6i instances offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, which is twice that of C5i instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-23", "source_tokens": 443, "generated_at": "2026-02-11T15:07:02.499043"}}
{"question": "What are the key features of C5 instances?", "answer": "C5 instances are based on Intel Xeon Platinum processors, available in 9 sizes, offer up to 96 vCPUs and 192 GiB memory, and deliver a 25% improvement in price/performance compared to C4 instances. C5d instances have local NVMe storage for low latency workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-11T15:07:07.626184"}}
{"question": "How do C5 instances differ from C5a instances in terms of processing power?", "answer": "C5 instances are based on Intel Xeon Platinum processors, while C5a instances feature 2nd Gen 3.3GHz AMD EPYC processors. The specifications for vCPUs and memory vary, but C5 instances offer a 25% improvement in price/performance over C4 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-11T15:07:07.626432"}}
{"question": "For what type of workloads are C5n instances best suited?", "answer": "C5n instances are best suited for applications requiring high network bandwidth and packet rate, such as HPC, data lakes, network appliances, and inter-node communication using the Message Passing Interface (MPI).", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-24", "source_tokens": 429, "generated_at": "2026-02-11T15:07:07.626820"}}
{"question": "What is the performance improvement of Hpc7g instances compared to previous-generation AWS Graviton-based instances for HPC workloads?", "answer": "Hpc7g instances deliver up to 70% better performance and almost 3x better price performance compared to previous-generation AWS Graviton-based instances for compute-intensive HPC workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-11T15:07:22.601898"}}
{"question": "How does the network bandwidth of Hpc7g instances compare to Hpc7a instances?", "answer": "Hpc7g instances provide up to 200 Gbps network bandwidth, while Hpc7a instances offer 300 Gbps of network bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-11T15:07:22.602271"}}
{"question": "What are the main differences between Hpc7g and Hpc7a instances in terms of performance improvements and features?", "answer": "Hpc7g instances are powered by AWS Graviton 3E processors and provide up to 35% higher vector instruction performance, up to 2x better floating-point performance, and 200 Gbps network bandwidth. Hpc7a instances, on the other hand, are powered by 4th Gen AMD EPYC processors and feature 2x higher core density, 2.1x higher memory bandwidth throughput, and 3x higher network bandwidth. Hpc7g instances are built on the AWS Nitro System, while Hpc7a instances offer 300 Gbps of Elastic Fabric Adapter (EFA) network bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-26", "source_tokens": 477, "generated_at": "2026-02-11T15:07:22.602749"}}
{"question": "What are the key features of Hpc6a instances?", "answer": "Hpc6a instances are powered by 96 cores of 3rd Gen AMD EPYC processors with an all-core turbo frequency of 3.6 GHz and 384 GiB RAM. They offer 100 Gbps EFA networking for high throughput internode communications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-11T15:07:28.238576"}}
{"question": "How do Hpc6a instances compare to Hpc7g instances in terms of processing power?", "answer": "Hpc6a instances use 3rd Gen AMD EPYC processors, while Hpc7g instances use Arm-based Graviton3E processors. Graviton3E processors provide up to 35% higher vector instruction performance than existing Graviton3 processors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-11T15:07:28.238871"}}
{"question": "Which instance types are Hpc7g instances available as?", "answer": "Hpc7g instances are available for purchase through various pricing models, including 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, and both EC2 On-Demand Instances and EC2 Reserved Instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-27", "source_tokens": 382, "generated_at": "2026-02-11T15:07:28.239279"}}
{"question": "Which pricing models does the text mention for Hpc7a instances?", "answer": "Hpc7a instances are available for purchase through the 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, EC2 On-Demand Instances, and EC2 Reserved Instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-11T15:07:33.859145"}}
{"question": "What features make Hpc7a instances better for HPC workloads compared to Hpc6a instances?", "answer": "Hpc7a instances feature 4th Gen AMD EPYC processors with 2x higher core density (up to 192 cores), 2.1x higher memory bandwidth throughput (768 GB of memory), and 3x higher network bandwidth (300 Gbpsof EFA network bandwidth). They also offer faster and low latency internode communications through the AWS Nitro System.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-11T15:07:33.859494"}}
{"question": "What pricing models do Hpc6a instances support compared to Hpc7a instances?", "answer": "Both Hpc6a and Hpc7a instances are available for purchase through the same pricing models: the 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, EC2 On-Demand Instances, and EC2 Reserved Instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-28", "source_tokens": 441, "generated_at": "2026-02-11T15:07:33.859923"}}
{"question": "What operating systems are supported on Hpc6id instances?", "answer": "Hpc6id instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T15:07:40.450458"}}
{"question": "What are the differences between Hpc6id and Hpc6a instances in terms of supported operating systems?", "answer": "Hpc6id instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, and FreeBSD 11.1 or later. Hpc6a instances also support Windows Server 2012, 2012 R2, 2016, and 2019 in addition to the aforementioned operating systems.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T15:07:40.450797"}}
{"question": "What pricing models are available for Hpc6a instances?", "answer": "Hpc6a instances are available for purchase through 1-year and 3-year Standard Reserved Instances, Convertible Reserved Instances, Savings Plans, and On-Demand Instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T15:07:40.451300"}}
{"question": "What specifications distinguish the AWS Graviton2 processors from the first generation AWS Graviton processors?", "answer": "The AWS Graviton2 processors deliver up to 7x performance, 4x the number of compute cores, 2x larger caches, 5x faster memory, and 50% faster per core encryption performance than first generation AWS Graviton processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-11T15:07:46.017291"}}
{"question": "How does the memory encryption work in AWS Graviton2 processors?", "answer": "AWS Graviton2 processors offer always-on 256-bit memory encryption. Encryption keys are securely generated within the host system, do not leave the host system, and are irrecoverably destroyed when the host is rebooted or powered down.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-11T15:07:46.017567"}}
{"question": "In what ways do M6g instances outperform M instances for general-purpose workloads?", "answer": "M6g instances deliver significant performance and price performance benefits for a broad spectrum of general-purpose workloads such as application servers, gaming servers, microservices, mid-size databases, and caching fleets.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-30", "source_tokens": 437, "generated_at": "2026-02-11T15:07:46.017924"}}
{"question": "What type of network interface is supported on M6g instances?", "answer": "M6g instances support Enhanced Networking (ENA) based network interface.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-11T15:07:49.912382"}}
{"question": "Which applications might require modifications to run on M6g instances?", "answer": "Applications developed using compiled languages (C, C++, GoLang) will need to be re-compiled to generate Arm binaries.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-11T15:07:49.912772"}}
{"question": "How do the first-generation AWS Graviton Processors compare to M6g instances' processors?", "answer": "The first-generation AWS Graviton Processors are custom designed by AWS and are the processors used in Amazon EC2 A1 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-31", "source_tokens": 435, "generated_at": "2026-02-11T15:07:49.913183"}}
{"question": "What are the memory resources available on M6g instances?", "answer": "M6g instances offer 4GB of memory per vCPU, compared to 2GB memory per vCPU on A1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-11T15:08:00.866138"}}
{"question": "What is the networking bandwidth offered by M6g instances?", "answer": "M6g instances support up to 25 Gbps of networking bandwidth, which is higher than the 10 Gbps supported by A1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-11T15:08:00.866519"}}
{"question": "In what ways do A1 and M6g instances differ in terms of compute and memory resources?", "answer": "A1 instances offer significant cost benefits for scale-out workloads that can run on multiple smaller cores and fit within the available memory footprint. In contrast, M6g instances are a good fit for applications that require more compute, memory, networking resources, and can benefit from scaling up across platform capabilities. M6g instances offer up to 16xlarge instance size, with 4GB of memory per vCPU, and up to 25 Gbps of networking bandwidth, compared to A1's 4xlarge instance size, 2GB memory per vCPU, and up to 10 Gbps networking bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-33", "source_tokens": 378, "generated_at": "2026-02-11T15:08:00.866725"}}
{"question": "What is the main performance improvement of EC2 M5 Instances compared to M4 Instances?", "answer": "EC2 M5 Instances deliver greater compute and storage performance, with up to 20% improvement in price/performance compared to M4 instances due to the latest generation Intel Xeon Scalable processors (Skylake-SP or Cascade Lake) and AVX-512 support.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-11T15:08:07.057395"}}
{"question": "How does the usage of the latest generation processors in EC2 M5 Instances benefit customers?", "answer": "The usage of the latest generation Intel Xeon Scalable processors (Skylake-SP or Cascade Lake) in EC2 M5 Instances provides customers with higher floating point performance, achieving up to 2x performance improvement in workloads requiring floating point operations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-11T15:08:07.057763"}}
{"question": "How does the networking and Amazon EBS performance of EC2 M5 Instances compare to EC2 M6i Instances?", "answer": "EC2 M5 Instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. In contrast, EC2 M6i Instances provide up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-34", "source_tokens": 479, "generated_at": "2026-02-11T15:08:07.057966"}}
{"question": "What are the benefits of using Intel AVX-512 on M5 and M6i instances?", "answer": "Intel AVX-512 offers exceptional processing of encryption algorithms, helping to reduce the performance overhead for cryptography on M5 and M6i instances. This allows customers to deploy more secure data and services into distributed environments without compromising performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-11T15:08:13.434826"}}
{"question": "What are the key features of M5zn instances?", "answer": "M5zn instances are powered by the fastest Intel Xeon Scalable processor in the cloud with an all-core turbo frequency of up to 4.5 GHz. They also offer 100 Gbps networking and support for Amazon Elastic Fabric Adapter (EFA). M5zn instances are ideal for workloads such as gaming, financial applications, simulation modeling, and other High Performance Computing applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-11T15:08:13.435163"}}
{"question": "How do M5zn instances differ from z1d instances?", "answer": "M5zn instances are general purpose instances, while z1d instances are memory-optimized. M5zn instances offer up to 100 Gbps networking performance and support for EFA, whereas z1d instances feature high frequency Intel Xeon Scalable processors up to 4.0 GHz and local NVMe storage. M5zn instances offer improved price performance compared to z1d instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-35", "source_tokens": 507, "generated_at": "2026-02-11T15:08:13.435819"}}
{"question": "What type of instances does Amazon EC2 offer for large in-memory databases and business applications?,", "answer": "Amazon EC2 offers High Memory (U-1 and U7i) instances with varying amounts of memory from 3 to 32 TiB.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-11T15:08:18.394230"}}
{"question": "How do the processing units of different High Memory instances differ?,", "answer": "EC2 High Memory (U-1) instances with 3, 6, 9, and 12 TiB are powered by Intel Xeon Platinum 8176M or 8280L processors, while U7i instances have 1.9 GHz 4th Generation Intel Xeon Scalable processors.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-11T15:08:18.394456"}}
{"question": "How does the memory capacity of U-1 and U7i High Memory instances compare?", "answer": "U-1 instances offer up to 32 TiB and use Intel Xeon Platinum processors, while U7i instances support up to 1920 vCPUs and have 18-32 TiB of memory with 4th Generation Intel Xeon Scalable processors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-36", "source_tokens": 417, "generated_at": "2026-02-11T15:08:18.394644"}}
{"question": "Which instance sizes are available for High Memory instances?", "answer": "High Memory instances are available in sizes with 3, 6, 8, 9, 12, 16, 18, 24, and 32 TiB of memory.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-11T15:08:23.192293"}}
{"question": "What are the advantages of using High Memory Virtualized instances compared to High Memory Bare Metal instances?", "answer": "High Memory Virtualized instances offer benefits such as significantly better launch/reboot times, flexible purchase options, choice of tenancy type, self-service options, and support for a higher number of EBS volumes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-11T15:08:23.192676"}}
{"question": "When should I consider using a High Memory Metal instance instead of a High Memory Virtualized instance?", "answer": "You may need to use a High Memory Metal instance if you're using an unsupported OS version, running applications that require non-virtualized mode or specific hardware features, or using a custom hypervisor.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-37", "source_tokens": 494, "generated_at": "2026-02-11T15:08:23.193091"}}
{"question": "What hypervisor does AWS use for High Memory instances?", "answer": "High Memory instances use the lightweight Nitro Hypervisor based on core KVM technology.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-11T15:08:27.731020"}}
{"question": "Why is the network performance so high on High Memory instances?", "answer": "High Memory instances use the Elastic Network Adapter (ENA) and support Enhanced Networking, enabling network bandwidth of up to 100 Gbps (U-1) and up to 200Gbps (U7i).", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-11T15:08:27.731237"}}
{"question": "How does the network and storage interface of High Memory instances compare to other instances?", "answer": "High Memory instances use the Elastic Network Adapter (ENA) for networking and access EBS volumes via PCI attached NVM Express (NVMe) interfaces, supporting up to 100 Gbps or 200Gbps of network bandwidth and NVMe devices respectively. This compares to other instances which may use different network and storage interfaces with varying levels of performance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-38", "source_tokens": 433, "generated_at": "2026-02-11T15:08:27.731585"}}
{"question": "Which Amazon Machine Images (AMIs) can be used with High Memory instances?", "answer": "EBS-backed HVM AMIs with support for ENA networking can be used with High Memory instances. The latest Amazon Linux, Red Hat Enterprise Linux, SUSE Enterprise Linux Server, and Windows Server AMIs are supported. For SAP HANA workloads, SUSE Linux Enterprise Server 12 SP3 for SAP, Red Hat Enterprise Linux 7.4 for SAP, Red Hat Enterprise Linux 7.5 for SAP, SUSE Linux Enterprise Server 12 SP4 for SAP, SUSE Linux Enterprise Server 15 for SAP, and Red Hat Enterprise Linux 7.6 for SAP are supported.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-11T15:08:35.480742"}}
{"question": "How does configuring C-states and P-states affect High Memory instances' performance?", "answer": "Configuring C-states on High Memory instances enables higher turbo frequencies, up to 4.0 GHz. In contrast, using P-states keeps all cores at P1 or higher P states, which is similar to disabling Turbo and runs the instance consistently at the base CPU clock speed. This helps lower performance variability.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-11T15:08:35.481101"}}
{"question": "What is the difference between purchasing High Memory instances as On-Demand and purchasing as a Reserved Instance?", "answer": "On-Demand instances are available for immediate use without any reservation, and the cost is higher per hour than Reserved Instances. Reserved Instances are purchased for a term of 1 or 3 years and offer significant discounts compared to On-Demand instances. Additionally, High Memory instances as EC2 Dedicated Hosts are only available for purchase as a 1-Year or 3-Year Reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-39", "source_tokens": 511, "generated_at": "2026-02-11T15:08:35.481619"}}
{"question": "What type of instances are AWS Quick Start reference SAP HANA deployments available for on AWS?", "answer": "AWS Quick Start reference SAP HANA deployments are available for High Memory instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-11T15:08:39.883320"}}
{"question": "Why are memory-optimized instances like R6g beneficial for certain applications?", "answer": "Memory-optimized instances like R6g are beneficial for memory-intensive applications as they offer large memory sizes. They are ideal for in-memory databases, in-memory analytics solutions, and other memory-intensive applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-11T15:08:39.883670"}}
{"question": "How does the R6g instance compare to the R5 instance in terms of memory-optimized performance and price?", "answer": "R6g instances deliver up to 40% better price performance over R5 instances in terms of memory-optimized performance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-40", "source_tokens": 505, "generated_at": "2026-02-11T15:08:39.884201"}}
{"question": "What type of network interface is supported on R6g instances?", "answer": "R6g instances support ENA based Enhanced Networking.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-11T15:08:43.749506"}}
{"question": "What modifications are required to run applications on R6g instances?", "answer": "The modifications required depend on the application. Open source software applications and most Linux distributions, containers (Docker, Kubernetes, Amazon ECS, Amazon EKS, Amazon ECR) are expected to work, but applications based on compiled languages (C, C++, GoLang) will need to be re-compiled.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-11T15:08:43.749719"}}
{"question": "What is the difference between R6i and R5 instances in terms of choice?", "answer": "No direct comparison information is provided in the context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-41", "source_tokens": 301, "generated_at": "2026-02-11T15:08:43.750155"}}
{"question": "What is the all-core turbo frequency of Amazon EC2 R6i instances?", "answer": "The all-core turbo frequency of Amazon EC2 R6i instances is 3.5 GHz.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-11T15:08:48.894829"}}
{"question": "How does the performance of R6i instances compare to R5 instances?", "answer": "R6i instances offer up to 15% better compute price performance over R5 instances and provide up to 20% higher memory bandwidth per vCPU. They also have up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, twice that of R5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-11T15:08:48.895168"}}
{"question": "For what types of applications are R5b instances optimal?", "answer": "R5b instances are ideal for applications that require high EBS performance, as they deliver up to 3x better EBS performance compared to same sized R5 instances, with up to 60 Gbps bandwidth and 260K IOPS.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-42", "source_tokens": 504, "generated_at": "2026-02-11T15:08:48.895658"}}
{"question": "What storage options are available with R5b instances for accessing EBS volumes?", "answer": "R5b instances support EBS-optimized storage with up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS. They only support the NVMe interface and are not compatible with io2 volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-11T15:08:54.528006"}}
{"question": "Why are R5b instances suitable for large relational database workloads?", "answer": "R5b instances are ideal for large relational database workloads due to their EBS-optimization and high network performance, making them suitable for applications such as commerce platforms, ERP systems, and health record systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-11T15:08:54.528388"}}
{"question": "How does the storage performance of R5b instances compare to High Memory instances?", "answer": "R5b instances offer up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS, while High Memory instances offer up to 38Gbps of storage bandwidth. However, R5b instances are EBS-optimized by default and only support the NVMe interface, while High Memory instances support all volume types.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-43", "source_tokens": 485, "generated_at": "2026-02-11T15:08:54.528837"}}
{"question": "What type of workloads are X2gd instances ideal for?", "answer": "X2gd instances are ideal for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-11T15:09:02.651921"}}
{"question": "Why would you use X2gd instances over other instance types like X1, X2i, R, X2iezn, or X2idn?", "answer": "X2gd instances are suitable for memory bound workloads that require low latency memory access and have a high memory to vCPU ratio. They offer the lowest cost per gigabyte of memory within EC2 and are well suited for workloads like Redis and Memcached in-memory databases, PostgreSQL, MariaDB, MySQL, and RDS Aurora. Customers running single threaded workloads and memory intensive workloads will also benefit from X2gd.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-11T15:09:02.652297"}}
{"question": "How does X2gd compare to X2iezn and X2idn in terms of processor architecture and suitability for certain workloads?", "answer": "X2gd instances use Arm-compatible processors and are ideal for memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers. X2iezn and X2idn instances use x86 processors and are suitable for memory-intensive enterprise-class, scale-up workloads such as Windows workloads and relational databases. Customers can leverage X2gd for memory bound workloads that need less than 1 TiB memory and have no dependency on x86 instruction set. X2iezn and X2idn can be used for larger memory sizes up to 4 TiB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-44", "source_tokens": 500, "generated_at": "2026-02-11T15:09:02.652824"}}
{"question": "What is the all-core turbo frequency for X2idn and X2iedn instances?", "answer": "The all-core turbo frequency for X2idn and X2iedn instances is up to 3.5 GHz.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-11T15:09:07.044330"}}
{"question": "How do X2idn and X2iedn instances differ in terms of memory?", "answer": "X2idn instances offer up to 2 TiB of memory, while X2iedn instances offer up to 4 TiB of memory.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-11T15:09:07.044675"}}
{"question": "For what types of workloads are X2idn and X2iedn instances ideal?", "answer": "X2idn and X2iedn instances are ideal for workloads such as small-to large-scale traditional and in-memory databases, analytics, and SAP-Certified applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-45", "source_tokens": 465, "generated_at": "2026-02-11T15:09:07.045120"}}
{"question": "What operating systems are supported on X1e.xlarge, X1e.2xlarge, X1e.4xlarge, X1e.8xlarge, X1e.16xlarge, and X1.32xlarge instances?", "answer": "These instances support Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-11T15:09:13.091280"}}
{"question": "How can CPU power be managed on X1e instances for SAP HANA deployments?", "answer": "You can configure C-states and P-states on X1e instances to enable higher turbo frequencies or to lower performance variability by pinning all cores at P1 or higher P states. X1e.32xlarge also supports Windows Server 2012 R2 and 2012 RTM.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-11T15:09:13.091551"}}
{"question": "What are the differences between using AWS Launch Wizard for SAP and the AWS Quick Start reference SAP HANA for deploying SAP HANA on X1 instances?", "answer": "The text does not provide enough information for a comparison question.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-46", "source_tokens": 510, "generated_at": "2026-02-11T15:09:13.091742"}}
{"question": "Why are M1, C1, CC2, and HS1 instances no longer available on the pricing pages?", "answer": "They have been moved to the Previous Generation Instances page.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-11T15:09:16.860974"}}
{"question": "Are Previous Generation instances still supported for use?", "answer": "Yes, they are fully supported.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-11T15:09:16.861319"}}
{"question": "How do Dense-storage instances compare to High I/O instances in terms of storage optimization?", "answer": "Dense-storage instances offer the best price-per-GB-storage and price-per-disk-throughput among other EC2 instances and are designed for workloads requiring high sequential read and write access to large data sets.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-47", "source_tokens": 456, "generated_at": "2026-02-11T15:09:16.861760"}}
{"question": "What is the disk throughput capability of Dense-storage and HDD-storage instances?", "answer": "The largest Dense HDD-storage instance, d3en.12xlarge, can deliver up to 6.2 GiB/s read and write disk throughput with a 128k block size.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T15:09:23.713156"}}
{"question": "How does data redundancy and fault tolerance differ between Dense-storage and HDD-storage instances and Amazon EBS?", "answer": "Dense-storage and HDD-storage instances do not provide any built-in redundancy or fault tolerance. They rely on users to build their own redundancy, use file systems that support it, or back up data periodically to other storage solutions like Amazon EBS or Amazon S3. Amazon EBS, on the other hand, provides data durability and availability through replicas and snapshots.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T15:09:23.713434"}}
{"question": "What are the use cases for Dense-storage and HDD-storage instances compared to Amazon EBS?", "answer": "Dense-storage and HDD-storage instances are optimized for applications that require low latency, high random I/O and moderate storage density. They offer the best price/IOPS across other EC2 instance types. Amazon EBS, on the other hand, is a network-attached block storage service designed for use with EC2 instances for both throughput and latency-sensitive workloads. It offers scalability and durability with data replication and snapshots.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-48", "source_tokens": 461, "generated_at": "2026-02-11T15:09:23.713836"}}
{"question": "What type of storage does a High I/O instance use for local storage?", "answer": "A High I/O instance uses NVMe based local instance storage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-11T15:09:28.115361"}}
{"question": "How does Amazon EBS optimized instances benefit D2 instances?", "answer": "D2 instances are EBS optimized by default and benefit from the increased EBS throughput above the general-purpose network throughput provided to the instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-11T15:09:28.115699"}}
{"question": "How does a High I/O instance compare to a Dense-storage instance in terms of I/O performance?", "answer": "A High I/O instance uses NVMe based local instance storage to deliver very high, low latency I/O capacity to applications, while a Dense-storage instance is targeted at customers who want high sequential read/write access to large data sets on local storage.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-49", "source_tokens": 489, "generated_at": "2026-02-11T15:09:28.116163"}}
{"question": "What failover mechanisms or redundancy features are available for High I/O instances?", "answer": "High I/O instances do not come with built-in failover mechanisms or redundancy. Amazon recommends building application resilience and using databases and file systems that support redundancy and fault tolerance. Customers should also back up data periodically to Amazon S3 for improved data durability.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-11T15:09:35.074210"}}
{"question": "How do High I/O instances (Im4gn, Is4gen, I4i, I3 and I3en) support data management for IOPS-intensive applications?", "answer": "High I/O instances provide instance storage that persists during the life of the instance. Customers are expected to use databases and file systems that support redundancy and fault tolerance, and should back up data periodically to Amazon S3 for improved data durability. These instances also support TRIM, allowing the operating system to inform SSDs which blocks of data are no longer considered in use and can be wiped internally, ensuring optimal write performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-11T15:09:35.074553"}}
{"question": "How do D3 instances compare to D2 instances in terms of compute performance, disk throughput, price, and Intel AVX extensions?", "answer": "D3 instances offer up to 30% higher compute performance, up to 45% higher disk throughput, are priced 5% lower, and include Intel AVX 512, offering up to 2X the FLOPS per cycle compared to AVX 2 on D2 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-50", "source_tokens": 472, "generated_at": "2026-02-11T15:09:35.075030"}}
{"question": "What is the total storage capacity for a single D3en instance?", "answer": "A single D3en instance offers 336 TB of total storage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-11T15:09:39.000781"}}
{"question": "How does the network bandwidth of D3 and D3en instances compare?", "answer": "D3 instances offer up to 25 Gbps of network bandwidth on their largest sizes, while D3en instances offer up to 75 Gbps.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-11T15:09:39.001120"}}
{"question": "What features differentiate D3 and D3en instances, aside from their size and network performance?", "answer": "D3 instances have more memory per vCPU and less total storage, while D3en instances have less memory per vCPU but larger total storage and offer larger instance sizes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-51", "source_tokens": 198, "generated_at": "2026-02-11T15:09:39.001596"}}
{"question": "What is the baseline CPU performance of Flex instances?", "answer": "Flex instances provide a baseline CPU performance of 40%.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-11T15:09:43.922728"}}
{"question": "How does the performance of Flex instances compare to non-flex instances?", "answer": "Flex instances offer better price performance compared to non-flex instances and can be used for workloads that don't fully utilize compute resources. They provide a baseline CPU performance of 40% and can scale up to 100% CPU for 95% of the time.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-11T15:09:43.923066"}}
{"question": "When would it be ideal to use Flex instances instead of non-flex instances?", "answer": "Flex instances are ideal for workloads that fit on instance sizes up to 16xlarge, including web and application servers, databases, virtual desktops, batch processing, microservices, caches, enterprise applications, Apache Kafka, and Elasticsearch. They are designed to meet the compute requirements for the majority of workloads and offer better price performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-52", "source_tokens": 341, "generated_at": "2026-02-11T15:09:43.923563"}}
{"question": "What is the baseline CPU performance of a t2.medium Burstable Performance Instance?", "answer": "The baseline CPU performance of a t2.medium Burstable Performance Instance is 40% of a core.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-11T15:09:48.799042"}}
{"question": "How do the CPU Credits and baseline performance of T2 instances differ from those of Fixed Performance Instances?", "answer": "T2 instances receive CPU Credits continuously based on their size and provide a baseline level of CPU performance that can burst above the baseline. In contrast, Fixed Performance Instances have a consistent CPU performance without the ability to burst.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-11T15:09:48.799323"}}
{"question": "What is the difference in maximum CPU Credit balance between a t2.small and a t2.large Burstable Performance Instance?", "answer": "A t2.small Burstable Performance Instance has a maximum CPU Credit balance of 288, while a t2.large Burstable Performance Instance has a maximum CPU Credit balance of 576.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-53", "source_tokens": 491, "generated_at": "2026-02-11T15:09:48.799469"}}
{"question": "How many cores can I use for a single threaded application on a t2.2xlarge instance?", "answer": "A single threaded application on a t2.2xlarge instance can use all of 1 core.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-11T15:09:53.542806"}}
{"question": "What are the advantages of using a Burstable Performance Instance, such as T2, over a Dedicated Performance Instance?", "answer": "T2 instances offer a cost-effective solution for general purpose production workloads. They provide the flexibility to burst above the baseline CPU performance when needed, but if your workloads consistently require high CPU usage, you may want to consider a dedicated CPU instance for sustained performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-11T15:09:53.543149"}}
{"question": "How does the CPU Credit balance impact the performance of a T2 instance?", "answer": "The CPU Credit balance affects the performance of a T2 instance by influencing the amount of CPU credits available for bursting. When the CPU Credit balance is near zero, the instance may experience reduced CPU performance until more credits are earned or purchased.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-54", "source_tokens": 477, "generated_at": "2026-02-11T15:09:53.543667"}}
{"question": "Does the CPU Credit balance of a T2 instance persist during instance pausing?", "answer": "No, a paused instance does not retain its previously earned CPU Credit balance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-11T15:09:56.308180"}}
{"question": "In what ways can I procure T2 instances?", "answer": "T2 instances can be purchased as On-Demand Instances, Reserved Instances, or Spot Instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-11T15:09:56.308403"}}
{"question": "How does the performance and pricing of T4g instances compare to T3 instances?", "answer": "T4g instances provide up to 40% better price performance over T3 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-55", "source_tokens": 433, "generated_at": "2026-02-11T15:09:56.308534"}}
{"question": "What is the duration of the T4g free trial period?", "answer": "The T4g free trial is available for a limited time until December 31, 2025.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-11T15:10:00.759331"}}
{"question": "What happens during the free-trial period if a customer exceeds the allocated CPU credits?", "answer": "Customers must pay for surplus CPU credits when they exceed the instances allocated credits during the 750 free hours of the T4g free trial program.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-11T15:10:00.759671"}}
{"question": "How does the availability of the T4g free trial compare to the existing AWS Free Tier?", "answer": "The T4g free trial is available in addition to the existing AWS Free Tier in multiple regions for t3.micro, t3.small, t4g.micro, t4g.small, C7i-flex. large and M7i-flex.large instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-56", "source_tokens": 447, "generated_at": "2026-02-11T15:10:00.760190"}}
{"question": "What is included in the t4g.small free trial in terms of AMI charges?", "answer": "The Amazon Machine Image (AMI) charges for Amazon Linux 2, RHEL and SUSE Linux AMIs that are available through the EC2 console Quick Start are waived for the first 750 free hours per month.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-11T15:10:05.654019"}}
{"question": "Why are there no AMI charges during the first 750 hours of the t4g.small free trial?", "answer": "The free trial allows customers to run t4g.small instances across one or multiple Regions without AMI charges for the specified Linux AMIs during the first 750 hours per month.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-11T15:10:05.654311"}}
{"question": "Does the t4g.small free trial cover AMI charges for other Linux distributions?", "answer": "The t4g.small free trial covers only Amazon Linux 2, RHEL, and SUSE Linux AMIs available through the EC2 console Quick Start, and there is no waiver for other Linux distribution AMIs.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-57", "source_tokens": 284, "generated_at": "2026-02-11T15:10:05.654522"}}
{"question": "What happens if customers exceed the 750 free hours under the T4g free trial plan?", "answer": "Customers will be charged based on regular On-Demand pricing for the exceeded hours for that month. For customers with a Compute Savings Plan or T4g Instance Savings Plan, Savings Plan (SV) discount will be applied to On-Demand pricing for the hours exceeding the 750 free trial hours.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-11T15:10:11.336516"}}
{"question": "How does the T4g free trial work for customers with a Compute Savings Plan or T4g Instance Savings Plan?", "answer": "Savings Plan (SV) discount is applied to On-Demand pricing for hours exceeding the 750 free trial hours.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-11T15:10:11.336879"}}
{"question": "What's the difference between the T4g free trial and the T4g Reserved Instance plan regarding free hours and billing?", "answer": "Under the T4g free trial, customers get 750 free hours for the remainder of the month after sign-up. The T4g Reserved Instance plan applies first to any usage on an hourly basis, and for any remaining usage after the RI plan has been applied, the free trial billing plan is in effect.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-58", "source_tokens": 512, "generated_at": "2026-02-11T15:10:11.337075"}}
{"question": "When will customers using t4g.small instances be billed under the On-Demand pricing plan?", "answer": "Starting January 1, 2026, customers using t4g.small instances will be billed under the On-Demand pricing plan.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-11T15:10:15.935755"}}
{"question": "How does the billing change for t4g.small instances after the free trial period?", "answer": "After the free trial period, customers will be automatically switched to the On-Demand pricing plan or the Reserved Instance (RI) plan if purchased. Accumulated credits will be set to zero.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-11T15:10:15.936093"}}
{"question": "What is the difference between the billing for t4g.small instances during the free trial and after it?", "answer": "During the free trial, there is no charge. After the free trial period, customers will be charged according to the On-Demand pricing plan or the Reserved Instance (RI) plan if purchased.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-59", "source_tokens": 226, "generated_at": "2026-02-11T15:10:15.936607"}}
{"question": "What are the ideal use cases for Compute Optimized instances?", "answer": "Compute Optimized instances are ideal for applications that benefit from high compute power, such as high-performance web servers, high-performance computing (HPC), scientific modelling, distributed analytics, machine learning inference, and gaming.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-11T15:10:19.827768"}}
{"question": "How does the performance of C7g instances compare to C6g instances?", "answer": "C7g instances offer up to 25% better performance over C6g instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-11T15:10:19.827999"}}
{"question": "What are the storage options available on C6g instances?", "answer": "The text passage does not provide information on the specific storage options available on C6g instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-60", "source_tokens": 434, "generated_at": "2026-02-11T15:10:19.828368"}}
{"question": "Which network interface is supported on C6g instances for accessing EBS storage?", "answer": "C6g instances support the NVMe interface for accessing EBS storage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-11T15:10:23.411748"}}
{"question": "Why do applications need to be re-compiled when moving from x86 to Arm architecture for C6g instances?", "answer": "Applications need to be re-compiled to generate Arm binaries because the Arm architecture has different instruction sets than x86.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-11T15:10:23.411967"}}
{"question": "How does the networking performance of C6g instances compare to C4 instances?", "answer": "C6g instances offer up to 25 Gbps of network bandwidth between instances when launched within a Placement Group, while no specific networking performance is mentioned for C4 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-61", "source_tokens": 428, "generated_at": "2026-02-11T15:10:23.412389"}}
{"question": "What is the default EBS throughput for each C4 instance type?", "answer": "C4 instances come with EBS-optimized network throughput, ranging from 500 Mbps to 4000 Mbps.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-11T15:10:28.750192"}}
{"question": "How does the processor state control feature impact the performance of c4.8xlarge instances?", "answer": "The processor state control feature on c4.8xlarge instances allows the operating system to control processor C-states and P-states, which can help increase performance consistency, reduce latency, or tune the instance for specific workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-11T15:10:28.750526"}}
{"question": "How do C6g and C6a instances compare in terms of CPU performance and price performance?", "answer": "C6g instances, powered by AWS Graviton2 processors, offer up to 40% better price performance over C5 instances and are ideal for running compute-intensive workloads. C6a instances, powered by AMD EPYC processors, offer up to 15% better price performance over C5a instances for a wide variety of workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-62", "source_tokens": 482, "generated_at": "2026-02-11T15:10:28.750960"}}
{"question": "What is the networking speed of C6a instances?", "answer": "C6a instances offer up to 50 Gbps of networking speed.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T15:10:34.983396"}}
{"question": "How does C6i instance performance compare to C5i instances, especially in terms of memory and networking?", "answer": "C6i instances offer up to 33% more memory and 9% higher memory bandwidth per vCPU than C5i instances. They also provide twice the networking speed and bandwidth to the Amazon Elastic Block Store. In terms of price performance, C6i instances offer up to 15% better performance than C5i instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T15:10:34.983733"}}
{"question": "What are some benefits of using C6i instances over C5i instances, aside from the larger instance sizes and networking speeds?", "answer": "C6i instances are powered by 3rd generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.5 GHz. They also offer always-on memory encryption using Intel Total Memory encryption (TME). The new c6i.32xlarge size provides 128 vCPUs and 256 GiB of memory. C6i instances also offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T15:10:34.984167"}}
{"question": "What is the memory capacity of C5a instances?", "answer": "C5a instances offer up to 192 GiB of memory.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-11T15:10:40.634717"}}
{"question": "How does the network bandwidth and packet rate of C5n instances compare to C5a instances?", "answer": "C5n instances offer ideal network bandwidth and packet rate for applications requiring high inter-node communication and the Message Passing Interface (MPI), while C5a instances are optimized for compute-intensive workloads with up to 192 GiB of memory and local NVMe storage for very low latency and high random read and write IOPS.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-11T15:10:40.635060"}}
{"question": "Which instance type, C4, C5a, or C5n, would be best for a customer with a compute-intensive workload and high network requirements?", "answer": "C5a instances would be optimal for a customer with a compute-intensive workload, as they offer leading x86 price-performance for such workloads and up to 192 GiB of memory. However, if the customer also requires high network bandwidth and packet rate, they may want to consider C5n instances instead.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-64", "source_tokens": 467, "generated_at": "2026-02-11T15:10:40.635518"}}
{"question": "What portion of the EC2 instance memory is reserved for the virtual BIOS and AWS Nitro Hypervisor?", "answer": "Portions of the EC2 instance memory are reserved for the virtual BIOS for video RAM, DMI, and ACPI, and for instances that are powered by the AWS Nitro Hypervisor, a small percentage of the instance memory is reserved by the Amazon EC2 Nitro Hypervisor.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-11T15:10:45.232733"}}
{"question": "How does the memory allocation for EC2 instances differ from the reported total memory?", "answer": "The reported total memory on EC2 instance types does not exactly match the actual memory available to the operating system due to memory being reserved for the virtual BIOS and the AWS Nitro Hypervisor.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-11T15:10:45.233098"}}
{"question": "Does C5 instances support SATA EBS or only NVMe EBS?", "answer": "C5 instances support only NVMe EBS device model.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-65", "source_tokens": 301, "generated_at": "2026-02-11T15:10:45.233429"}}
{"question": "Which processors power Hpc7g instances?", "answer": "Hpc7g instances are powered by AWS Graviton 3E processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-11T15:10:49.012823"}}
{"question": "How does Hpc7g instances performance compare to previous-generation HPC instances?", "answer": "Hpc7g instances provide up to 70% better performance and almost 3x better price performance compared to previous-generation AWS Graviton-based instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-11T15:10:49.013169"}}
{"question": "How does the network bandwidth of Hpc7g instances compare to Hpc7a instances?", "answer": "Hpc7g instances provide 200 Gbps network bandwidth, while Hpc7a instances offer 300 Gbps Elastic Fabric Adapter network bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-66", "source_tokens": 503, "generated_at": "2026-02-11T15:10:49.013594"}}
{"question": "What processors are Hpc6a instances equipped with?", "answer": "Hpc6a instances are equipped with 96 cores of 3rd Gen AMD EPYC processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-11T15:10:54.459309"}}
{"question": "How does Hpc7g instance architecture differ from traditional x86-based instances?", "answer": "Hpc7g instances are based on Arm-based Graviton3E processors, offering up to 35% higher vector instruction performance compared to existing Graviton3 processor-based instances. They also deliver 64 physical cores, 128 GiB memory, and 200 Gbps network bandwidth optimized for traffic between instances in the same VPC.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-11T15:10:54.459643"}}
{"question": "How does the pricing model of Hpc7g instances compare to Hpc6a instances?", "answer": "Hpc7g instances are available for purchase through the 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, EC2 On-Demand Instances, and EC2 Reserved Instances, while Hpc6a instances are not explicitly mentioned as having any specific pricing model in the context.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-67", "source_tokens": 382, "generated_at": "2026-02-11T15:10:54.460182"}}
{"question": "What pricing models do Hpc7a instances support?", "answer": "Hpc7a instances can be purchased through the 1- and 3-year Amazon EC2 Instance Savings Plans, Compute Savings Plans, EC2 On-Demand Instances, and EC2 Reserved Instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-11T15:11:00.423216"}}
{"question": "What operating systems are supported on Hpc7a instances?", "answer": "Hpc7a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.6 or later, SUSE Linux Enterprise Server 12 SP3 or later, CentOS 7 or later, and FreeBSD 11.1 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-11T15:11:00.423590"}}
{"question": "How do Hpc7a instances compare to Hpc6a instances in terms of processor performance and network bandwidth?", "answer": "Hpc7a instances feature 4th Gen AMD EPYC processors with up to 192 cores and 768 GB of memory, offering 2x higher core density and 2.1x higher memory bandwidth than Hpc6a instances. In addition, Hpc7a instances offer 300 Gbpsof EFA network bandwidth, which is 3x higher than Hpc6a instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-68", "source_tokens": 441, "generated_at": "2026-02-11T15:11:00.424139"}}
{"question": "Which operating systems are compatible with Hpc6id instances?", "answer": "Hpc6id instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-11T15:11:08.092978"}}
{"question": "What operating systems can you use with Hpc6id instances for a better understanding?", "answer": "To get the best performance for memory-bound, data-intensive HPC workloads on Hpc6id instances, you can use Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-11T15:11:08.093265"}}
{"question": "What are the main differences in operating system support between Hpc6id and Hpc6a instances?", "answer": "Hpc6id instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later. Hpc6a instances, on the other hand, also support Windows Server 2012, 2012 R2, 2016, and 2019.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-69", "source_tokens": 405, "generated_at": "2026-02-11T15:11:08.093674"}}
{"question": "What specifications does the AWS Graviton2 Processor have for memory?", "answer": "The AWS Graviton2 processors offer 5x faster memory than the first generation AWS Graviton processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-11T15:11:13.690289"}}
{"question": "How does the performance of the AWS Graviton2 Processor compare to the first generation version?", "answer": "The AWS Graviton2 processors deliver up to 7x performance, 4x the number of compute cores, and 50% faster per core encryption performance than the first generation AWS Graviton processors.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-11T15:11:13.690718"}}
{"question": "Why are M6g instances a good choice for general-purpose workloads?", "answer": "M6g instances are a good choice for general-purpose workloads because they deliver up to 40% better price/performance over M5 instances, are built on the AWS Nitro System, and offer always-on fully encrypted DRAM memory, hardware acceleration for compression workloads, dedicated engines per vCPU for floating-point performance, and instructions for int8/fp16 CPU-based machine learning inference acceleration.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-70", "source_tokens": 415, "generated_at": "2026-02-11T15:11:13.691176"}}
{"question": "What memory per vCPU does A1 instances offer?", "answer": "A1 instances offer 2GB of memory per vCPU.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-11T15:11:28.386754"}}
{"question": "How does the memory capacity of A1 instances compare to M6g instances?", "answer": "A1 instances offer less memory per vCPU (2GB) than M6g instances (4GB).", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-11T15:11:28.387058"}}
{"question": "Which network interface does A1 instances use for accessing EBS storage?", "answer": "A1 instances use the NVMe interface to access EBS storage volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-73", "source_tokens": 396, "generated_at": "2026-02-11T15:11:28.387265"}}
{"question": "What is the performance improvement of M5 Instances compared to M4 Instances in terms of price/performance?", "answer": "M5 Instances deliver up to 20% improvement in price/performance compared to M4 Instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-11T15:11:33.966250"}}
{"question": "How does the usage of the latest generation processors impact the performance of M5 Instances compared to M4 Instances?", "answer": "M5 Instances use the latest generation Intel Xeon Scalable processors (Skylake-SP or Cascade Lake), which delivers up to 20% improvement in price/performance compared to M4. Additionally, M5 instances have AVX-512 support which provides 2x higher performance in workloads requiring floating point operations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-11T15:11:33.966621"}}
{"question": "What are the main differences in networking and EBS performance between M5 and M6i instances?", "answer": "M5 instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. M6i instances provide up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-74", "source_tokens": 479, "generated_at": "2026-02-11T15:11:33.967129"}}
{"question": "What are the benefits of Intel AVX-512 for customers using EC2 M5 family or M6i family instances?", "answer": "Intel AVX-512 provides exceptional processing of encryption algorithms, reducing performance overhead for cryptography and enabling customers to deploy more secure data and services into distributed environments without compromising performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-11T15:11:40.009766"}}
{"question": "What are the key features of M5zn instances?", "answer": "M5zn instances are a variant of the M5 general purpose instances, powered by the fastest Intel Xeon Scalable processor in the cloud, with an all-core turbo frequency of up to 4.5 GHz, 100 Gbps networking, and support for Amazon Elastic Fabric Adapter (EFA). They are ideal for workloads such as gaming, financial applications, simulation modeling, and other High Performance Computing applications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-11T15:11:40.010138"}}
{"question": "How do M5zn instances compare to z1d instances?", "answer": "M5zn instances offer general purpose performance with high frequency Intel Xeon Scalable processors, 100 Gbps networking, and support for EFA. In contrast, z1d instances are memory-optimized with local NVMe storage and high frequency Intel Xeon Scalable processors. M5zn instances offer improved price performance compared to z1d instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-75", "source_tokens": 504, "generated_at": "2026-02-11T15:11:40.010596"}}
{"question": "What size of memory does an EC2 High Memory U-1 instance offer?", "answer": "An EC2 High Memory U-1 instance offers 3 or 6 TiB of memory.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-11T15:11:44.090809"}}
{"question": "What processors are used in EC2 High Memory U-1 instances?", "answer": "EC2 High Memory U-1 instances use Intel Xeon Platinum 8176M (Skylake) or 8280L (Cascade Lake) processors.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-11T15:11:44.091070"}}
{"question": "Which EC2 High Memory instance type has the first DDR5 memory based 8-socket offering in the cloud?", "answer": "EC2 U7i instances are the first DDR5 memory based 8-socket offering by a leading cloud provider.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-76", "source_tokens": 495, "generated_at": "2026-02-11T15:11:44.091244"}}
{"question": "What storage interface is supported on High Memory instances?", "answer": "Amazon Elastic Block Store (EBS) interface is supported on High Memory instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-11T15:11:47.730856"}}
{"question": "What are the advantages of using High Memory Virtualized instances over Bare Metal instances?", "answer": "High Memory Virtualized instances offer significantly better launch/reboot times, flexible purchase options, choice of tenancy type, self-service options, and support for a higher number of EBS volumes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-11T15:11:47.731194"}}
{"question": "How does the storage option vary between High Memory Metal and High Memory Virtualized instances?", "answer": "Both types of instances support Amazon EBS volumes for storage. However, High Memory Virtualized instances are EBS-optimized by default while there is no such default setting for High Memory Metal instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-77", "source_tokens": 512, "generated_at": "2026-02-11T15:11:47.731665"}}
{"question": "What storage interface does High Memory instances use to access EBS volumes?", "answer": "High Memory instances use PCI attached NVM Express (NVMe) interfaces to access EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-11T15:11:51.476407"}}
{"question": "Why is NVMe an efficient storage interface for High Memory instances?", "answer": "NVMe is an efficient and scalable storage interface that provides latency reduction and results in increased disk I/O and throughput for High Memory instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-11T15:11:51.476753"}}
{"question": "How does the network performance of High Memory instances compare to other instances?", "answer": "High Memory instances support up to 100 Gbps (U-1) and up to 200Gbps (U7i) of network bandwidth with Enhanced Networking, which is higher than the network performance of some other instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-78", "source_tokens": 487, "generated_at": "2026-02-11T15:11:51.477282"}}
{"question": "Is there an End of Sale (EOS) date for u-3tb1 and u-6tb1 High Memory instances?", "answer": "According to the context, only u-9tb1, u-12tb1, u-18tb1, and u-24tb1 instances are reaching End of Sale as of June 20, 2025.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-11T15:11:56.661802"}}
{"question": "Why might you use High Memory instances for SAP HANA deployments on AWS?", "answer": "High Memory instances are recommended for SAP HANA deployments on AWS due to their high performance and reliability, which follows SAPâ€™s recommendations.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-11T15:11:56.662086"}}
{"question": "How does using a Dedicated Host change the way you manage instances compared to using 'shared' tenancy?", "answer": "When using a Dedicated Host, you can launch, stop/start, and terminate instances using the RunInstances API and AWS Management Console, while with 'shared' tenancy you might need to deal with availability and capacity of shared resources.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-79", "source_tokens": 502, "generated_at": "2026-02-11T15:11:56.662492"}}
{"question": "Does the End of Sale (EOS) apply to all AWS regions including GovCloud and China?", "answer": "Yes. This EOS is for all AWS Commercial, GovCloud, and China regions.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-11T15:12:01.997521"}}
{"question": "What qualifies a customer as an existing Amazon EC2 High Memory U-1 instance customer?", "answer": "Existing Amazon EC2 High Memory U-1 instance customers are those who have documented U-1 instance usage within the 12-month period preceding the EOS date, have High Memory U-1 Savings Plans, Standard Reserved Instances, or Compute Savings Plans expiring on or after May 1, 2024, and have run or have active High Memory U-1 on-demand instances at the EOS date.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-11T15:12:01.997866"}}
{"question": "How does the End of Sale (EOS) for U-1 (u-9tb1, u-12tb1, u-18tb1, and u-24tb1) instances compare to a typical End of Sale process?", "answer": "The EOS for U-1 instances allows existing customers to retain the ability to restart or launch instances, whereas a typical EOS might prevent the purchase and usage of instances altogether.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-80", "source_tokens": 408, "generated_at": "2026-02-11T15:12:01.998283"}}
{"question": "What is the compute performance improvement of U7i instances compared to U-1 instances?", "answer": "U7i instances offer up to 140% better compute performance compared to U-1 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-11T15:12:05.943461"}}
{"question": "Why should I consider using the latest Amazon EC2 High Memory U7i instances instead of U-1 instances?", "answer": "U7i instances provide substantially better performance and value, with up to 140% better compute performance and twice the network and EBS bandwidth.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-11T15:12:05.943706"}}
{"question": "What network and EBS bandwidth does the U-1 instance provide?", "answer": "U-1 instances offer half the network and EBS bandwidth compared to the U7i instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-81", "source_tokens": 500, "generated_at": "2026-02-11T15:12:05.944072"}}
{"question": "What instance type should I purchase after the end-of-sales date for new Amazon EC2 High Memory instances if I want improved performance and enhanced network and storage capabilities?", "answer": "Amazon EC2 U7i High Memory instances are recommended for new purchases. They offer significant performance improvements, including up to 140% more compute performance, 2X higher networking bandwidth, and 2X higher EBS bandwidth.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-11T15:12:11.413548"}}
{"question": "How does the support policy change for Amazon EC2 High Memory U-1 instances post end-of-sales date?", "answer": "There is no change to the support policy for existing customers and existing commitments. However, software and firmware updates will still be provided.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-11T15:12:11.413798"}}
{"question": "What are the possible modifications for existing Amazon EC2 High Memory U-1 instances post end-of-sales date?", "answer": "Existing customers can modify certain attributes like security groups and IAM roles but cannot change the instance type to another High Memory instance within the affected U-1 family. For a higher performance and long-term usage, it's recommended to migrate to U7i instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-82", "source_tokens": 463, "generated_at": "2026-02-11T15:12:11.413922"}}
{"question": "Which EC2 instance types can be migrated to U7i instances and their corresponding U7i instance sizes?", "answer": "u-9tb1 can be migrated to U7i 8TB or 12TB, u-12tb1 to U7i 12TB, u-18tb1 to U7i 16TB or 24TB, and u-24tb1 to U7i 24TB.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-11T15:12:17.323134"}}
{"question": "How does the migration process from EC2 High Memory U-x to U7i instances differ between customers?", "answer": "The migration process may vary depending on each customer's requirements and configurations, and it is recommended to engage with the AWS account team to discuss the specific situation and explore available migration options.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-11T15:12:17.323389"}}
{"question": "What are the main differences between the storage capacity of U7i instances and the previous U-x instance types?", "answer": "U7i instances offer enhanced compute performance and increased network and storage bandwidth compared to the previous U-x instance types. Specifically, U7i instances come in 8TB, 12TB, 16TB, and 24TB sizes, depending on the original U-x instance type.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-83", "source_tokens": 276, "generated_at": "2026-02-11T15:12:17.323734"}}
{"question": "What memory-optimized instances are powered by Arm-based AWS Graviton2 Processors and deliver up to 40% better price performance over R5 instances?", "answer": "Amazon EC2 R6g instances", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-11T15:12:21.664261"}}
{"question": "In what way do R6g instances provide an advantage for memory-intensive workloads?", "answer": "R6g instances offer significant price performance benefits for memory-intensive workloads such as in-memory databases, in-memory caches, and real-time big data analytics.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-11T15:12:21.664560"}}
{"question": "How do the storage options on R6g instances compare to those on other instance types?", "answer": "R6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. They only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-84", "source_tokens": 472, "generated_at": "2026-02-11T15:12:21.664984"}}
{"question": "What software packages are available for installation on the Arm architecture?", "answer": "Commonly used software packages are available for installation on the Arm architecture through the same mechanisms used currently.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-11T15:12:25.859360"}}
{"question": "Why do applications based on interpreted languages not require recompilation on Arm architecture?", "answer": "Interpreted language applications, such as Java, Node, and Python, do not rely on native CPU instruction sets and should run with minimal to no changes on the Arm architecture.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-11T15:12:25.859645"}}
{"question": "How does the networking speed and bandwidth of R6i instances compare to R5 instances?", "answer": "R6i instances offer up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the Amazon Elastic Block Store, which is twice that of R5 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-85", "source_tokens": 490, "generated_at": "2026-02-11T15:12:25.860075"}}
{"question": "What are the networking requirements for using 32xlarge and metal sized Amazon EC2 instances?", "answer": "On the 32xlarge and metal sizes, enabling low-latency and high-scale inter-node communication may require an Elastic Network Adapter (ENA) driver update for optimal networking performance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-11T15:12:32.413387"}}
{"question": "In what scenarios would R5b instances provide better performance compared to regular R5 instances?", "answer": "R5b instances deliver up to 3x better EBS performance compared to same sized R5 instances, offering up to 60 Gbps bandwidth and 260K IOPS of EBS performance. This makes them ideal for large relational database workloads, including performance intensive applications such as commerce platforms, ERP systems, and health record systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-11T15:12:32.413636"}}
{"question": "What are the storage interface and volume type differences between R5b and R5 instances?", "answer": "R5b instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes, and they are EBS-optimized by default, offering up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS. R5 instances, on the other hand, do not have dedicated EBS bandwidth, and they are not EBS-optimized by default. R5b instances do not support io2 volumes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-86", "source_tokens": 438, "generated_at": "2026-02-11T15:12:32.414035"}}
{"question": "What type of instances support Amazon EBS volumes for storage?", "answer": "High Memory instances support Amazon EBS volumes for storage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-11T15:12:38.479631"}}
{"question": "What are the benefits of using X2gd instances for memory-optimized workloads?", "answer": "X2gd instances are ideal for customers with Arm-compatible memory bound scale-out workloads, offering lower costs, better price performance, and support for the AWS Nitro System. They are suitable for in-memory databases like Redis and Memcached, as well as relational databases and real-time analytics. They also offer a 1:16 vCPU to memory ratio and local NVMe SSD block storage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-11T15:12:38.479971"}}
{"question": "What is the difference between using X2gd instances and R5b instances for memory-intensive workloads?", "answer": "Both X2gd and R5b instances can be used for memory-intensive workloads, but X2gd instances are powered by AWS Graviton2 processors, offer a lower cost per GiB of memory, and have a higher vCPU to memory ratio (1:16) compared to R5b instances. However, R5b instances offer up to 38Gbps of storage bandwidth to both encrypted and unencrypted EBS volumes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-87", "source_tokens": 490, "generated_at": "2026-02-11T15:12:38.480485"}}
{"question": "What types of workloads are X2gd instances suitable for?", "answer": "X2gd instances are suitable for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-11T15:12:43.424999"}}
{"question": "Why would I choose X2gd instances over X2iezn instances?", "answer": "You would choose X2gd instances over X2iezn instances if your workload is memory bound and you're looking for the lowest cost per gigabyte of memory within EC2, as X2gd instances offer sizes up to 1 TiB of memory and are the lowest cost per gigabyte of memory.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-11T15:12:43.425351"}}
{"question": "How do the memory sizes of X2gd and X2iezn instances compare?", "answer": "X2gd instances offer memory sizes up to 1 TiB, while X2iezn instances offer larger memory sizes up to 4 TiB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-88", "source_tokens": 480, "generated_at": "2026-02-11T15:12:43.425744"}}
{"question": "What are some ideal use cases for X2iezn instances?", "answer": "X2iezn instances are best suited for workloads that require high single-threaded performance, a high memory-to-vCPU ratio, and high-speed networking. They are particularly effective for electronic design automation (EDA) workloads like physical verification, static timing analysis, power signoff, and full chip gate-level simulation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-11T15:12:48.854775"}}
{"question": "What's the difference in processing power between X1 and X2iezn instances?", "answer": "X1 instances are optimized for in-memory databases, big data processing engines, and high performance computing applications. In contrast, X2iezn instances have a higher all-core turbo frequency (up to 4.5 GHz) and a higher memory-to-vCPU ratio (32:1), making them better suited for workloads that need high single-threaded performance and a large amount of memory per core.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-11T15:12:48.855104"}}
{"question": "Can X1 instances manage CPU power usage?", "answer": "The text passage does not provide information on whether X1 instances have CPU power management state control.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-89", "source_tokens": 393, "generated_at": "2026-02-11T15:12:48.855296"}}
{"question": "Which Amazon Elastic Compute Cloud (EC2) instance types support C-states and P-states?", "answer": "x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge, and x1.16xlarge instances support C-states and P-states.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-11T15:12:55.120439"}}
{"question": "What are the benefits of using C-states and P-states on an EC2 instance?", "answer": "C-states enable higher turbo frequencies, while P-states help lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo and running consistently at the base CPU clock speed.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-11T15:12:55.120755"}}
{"question": "How does the support for C-states and P-states on the x1e.32xlarge instance compare to other supported instance types?", "answer": "The x1e.32xlarge instance is the only one among x1e.xlarge, x1e.2xlarge, x1e.4xlarge, x1e.8xlarge, x1e.16xlarge, and x1.32xlarge that supports C-states and P-states for all cores. Other instance types only support these states for specific cores or do not support them at all.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-90", "source_tokens": 424, "generated_at": "2026-02-11T15:12:55.121171"}}
{"question": "What type of instances have been moved from the pricing pages?", "answer": "M1, C1, CC2 and HS1 instances have been moved to the Previous Generation Instance page.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-11T15:12:59.097593"}}
{"question": "Why are Previous Generation instances still supported?", "answer": "Previous Generation instances are still supported because they offer customers an option for cost savings, while the latest generation instances provide better performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-11T15:12:59.097840"}}
{"question": "How does the availability of Previous Generation instances compare to the latest generation?", "answer": "Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instances through APIs, CLI, and the EC2 Management Console interface. The latest generation instances, on the other hand, typically offer better performance for the price.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-91", "source_tokens": 310, "generated_at": "2026-02-11T15:12:59.098222"}}
{"question": "What disk throughput can Dense-storage instances deliver?", "answer": "The largest current generation of Dense-storage instances can deliver up to 6.2 GiB/s read and 6.2 GiB/s write disk throughput.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-11T15:13:03.997309"}}
{"question": "How do conceptually Dense-storage and HDD-storage instances differ in terms of workloads?", "answer": "Dense-storage instances are designed for workloads requiring high sequential read and write access to large data sets, offering the best price/GB-storage and price/disk-throughput. HDD-storage instances, on the other hand, are optimized for applications requiring low cost storage for very large data sets.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-11T15:13:03.997659"}}
{"question": "How does the disk throughput of Dense-storage instances compare to that of HDD-storage instances?", "answer": "The text passage does not explicitly provide enough information for a comparison of disk throughput between Dense-storage and HDD-storage instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-92", "source_tokens": 434, "generated_at": "2026-02-11T15:13:03.998176"}}
{"question": "What type of storage does D2 and H1 instances provide and how does it differ from Amazon EBS?", "answer": "D2 and H1 instances provide local, dense HDD-storage that persists only for the life of the instance. Amazon EBS, on the other hand, offers elastic, reliable, and persistent block level storage for Amazon EC2 instances and abstracts the underlying storage media. Dense HDD-storage instances are targeted at customers who want high sequential read/write access to large data sets for applications such as Hadoop and data warehousing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-11T15:13:09.816278"}}
{"question": "Can D2 instances be launched as Amazon EBS optimized instances?", "answer": "No, this is not necessary as each D2 instance type is EBS optimized by default.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-11T15:13:09.816557"}}
{"question": "What is the difference between D2 instances and High I/O instances?", "answer": "D2 instances are general-purpose instances that come with EBS optimized local HDD-storage and higher network throughput. They are suitable for applications requiring high sequential read/write access to large data sets. High I/O instances are a specific instance type optimized for I/O-intensive workloads with very high network throughput.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-93", "source_tokens": 458, "generated_at": "2026-02-11T15:13:09.817005"}}
{"question": "What features of Amazon EC2 are supported by High I/O instances?", "answer": "High I/O instances support all Amazon EC2 features.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-11T15:13:13.593772"}}
{"question": "For what types of applications are High I/O instances suitable?", "answer": "High I/O instances are suitable for applications that require millions of low latency IOPS, manage data redundancy and availability, and leverage NoSQL databases, in-memory databases, Elasticsearch, analytics workloads, and OLTP systems.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-11T15:13:13.594154"}}
{"question": "What is the difference between High I/O instances and D2 instances?", "answer": "High I/O instances (Im4gn, Is4gen, I4i, I3 and I3en) offer improved specifications over D2 instances in terms of compute, storage, and network attributes.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-94", "source_tokens": 478, "generated_at": "2026-02-11T15:13:13.594654"}}
{"question": "What is the compute performance benefit of D3 and D3en instances over D2 instances?", "answer": "D3 and D3en instances offer up to 30% higher compute performances than equivalent D2 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-11T15:13:17.716831"}}
{"question": "Why would you choose D3en instances over D2 instances in terms of storage performance and cost?", "answer": "D3en instances offer up to 100% higher disk throughput and a lower cost per TB of storage compared to D2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-11T15:13:17.717161"}}
{"question": "How does the network bandwidth of D3 instances compare to D3en instances?", "answer": "D3 instances offer up to 25 Gbps of network bandwidth on their largest sizes, while D3en instances offer up to 75 Gbps.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-95", "source_tokens": 355, "generated_at": "2026-02-11T15:13:17.717321"}}
{"question": "What happens to local instance store data when an instance terminates?", "answer": "Local instance store data persists only as long as the instance is alive.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-11T15:13:23.507508"}}
{"question": "How does Amazon EBS perform in terms of throughput for workloads?", "answer": "Amazon EBS provides Throughput Optimized HDD (st1) volumes for frequently accessed, throughput intensive workloads. These volumes deliver up to 500 MB/s per volume, with a baseline throughput of 40 MB/s per TB and a burst performance of up to 250 MB/s per TB.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-11T15:13:23.507857"}}
{"question": "What are the differences between Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types for Amazon EBS?", "answer": "Throughput Optimized HDD (st1) volumes are ideal for frequently accessed, throughput intensive workloads, delivering up to 500 MB/s per volume with a baseline throughput of 40 MB/s per TB. Cold HDD (sc1) volumes, on the other hand, are designed for infrequent access workloads and deliver a baseline throughput of 5 MB/s per TB.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-96", "source_tokens": 461, "generated_at": "2026-02-11T15:13:23.508342"}}
{"question": "What type of data is SC1 volume best suited for?", "answer": "SC1 volumes are best suited for less frequently accessed workloads with large, cold datasets as they provide the lowest cost per GB of all EBS volume types and are backed by HDDs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-11T15:13:29.261813"}}
{"question": "How does the performance of SC1 volumes compare to other HDD-backed EBS volumes?", "answer": "SC1 volumes have a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. They can burst up to 80 MB/s per TB. For infrequently accessed data, they provide extremely inexpensive storage. They are designed to deliver the expected throughput performance 99% of the time and have enough I/O credits to support a full-volume scan at the burst rate.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-11T15:13:29.262153"}}
{"question": "Can I access my EBS snapshots using the regular Amazon S3 APIs?", "answer": "No, you cannot access your EBS snapshots using the regular Amazon S3 APIs. However, you can copy EBS snapshots to Amazon S3 using the AWS Management Console, AWS CLI, or Amazon S3 APIs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-97", "source_tokens": 503, "generated_at": "2026-02-11T15:13:29.262652"}}
{"question": "What resource center should I visit to find a list of Amazon Public Data Sets?", "answer": "All information on Public Data Sets is available in the Public Data Sets Resource Center.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-11T15:13:41.196304"}}
{"question": "How can I access information about Amazon EBS in detail?", "answer": "You can learn more about Amazon EBS by visiting the Amazon EBS FAQ.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-11T15:13:41.196591"}}
{"question": "How does EBS encryption compare to encryption of data volumes and snapshots in other solutions?", "answer": "EBS encryption enables seamless encryption of data volumes and snapshots, which better enables users to meet security and encryption compliance requirements.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-99", "source_tokens": 124, "generated_at": "2026-02-11T15:13:41.196788"}}
{"question": "What is the protocol used by Amazon EFS for file system access?", "answer": "Amazon EFS uses the NFSv4.1 protocol for file system access.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-11T15:13:45.942454"}}
{"question": "Why can I mount and access Amazon EFS file systems from both Amazon EC2 instances and on-premises servers?", "answer": "Amazon EFS file systems can be mounted on Amazon EC2 instances and on-premises servers using standard Linux tools. Any data accessible to these servers can be read and written to Amazon EFS.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-11T15:13:45.942674"}}
{"question": "How does accessing a file system from an Amazon EC2 instance compare to accessing it from an on-premises server?", "answer": "Accessing a file system from an Amazon EC2 instance allows you to work with files and directories just like a local file system, while accessing it from an on-premises server requires the use of standard Linux tools to mount the file system.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-100", "source_tokens": 510, "generated_at": "2026-02-11T15:13:45.943019"}}
{"question": "How many Amazon EC2 instances can connect to an Amazon EFS file system concurrently?", "answer": "One to thousands of Amazon EC2 instances can connect to an Amazon EFS file system concurrently.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-11T15:13:49.304268"}}
{"question": "What are some resources where I can learn more about Amazon EFS?", "answer": "You can visit the Amazon EFS FAQ page.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-11T15:13:49.304613"}}
{"question": "How does the number of Amazon EC2 instances that can connect to Amazon EFS compare to other file systems?", "answer": "Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-101", "source_tokens": 74, "generated_at": "2026-02-11T15:13:49.305035"}}
{"question": "What encryption method is used for data on Amazon EC2 NVMe instance storage?", "answer": "Data on Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-11T15:13:53.698711"}}
{"question": "How is encryption implemented on Amazon EC2 NVMe instance storage?", "answer": "All data is encrypted in an AWS Nitro hardware module prior to being written on the locally attached SSDs. Encryption keys are unique and are securely generated within the Nitro hardware module.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-11T15:13:53.699045"}}
{"question": "How does encryption on Amazon EC2 NVMe instance storage compare to AWS KMS?", "answer": "Encryption on Amazon EC2 NVMe instance storage is handled within the Nitro hardware module and does not support integration with AWS KMS. Keys are unique and are irrecoverably destroyed upon storage de-allocation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-102", "source_tokens": 348, "generated_at": "2026-02-11T15:13:53.699506"}}
{"question": "What protocols are supported by ENA Express for TCP and UDP communications?", "answer": "ENA Express supports TCP by default and optionally UDP through an API argument or within the management console.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-11T15:13:58.878392"}}
{"question": "What are the benefits of using ENA Express for network communication in AWS?", "answer": "ENA Express enhances traditional TCP and UDP networking with the Scalable Reliable Datagram (SRD) protocol, improving single flow bandwidths and reducing tail latencies in throughput-intensive workloads.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-11T15:13:58.878784"}}
{"question": "How does ENA Express compare to Elastic Fabric Adapter (EFA) in terms of support for different instances and protocols?", "answer": "ENA Express supports a broader range of EC2 instances (Graviton-, Intel-, and AMD-based), whereas Elastic Fabric Adapter (EFA) focuses specifically on network-intensive workloads and is limited to specific instance types. ENA Express also supports both TCP (by default) and UDP, while EFA primarily works with the iSCSI protocol.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-103", "source_tokens": 446, "generated_at": "2026-02-11T15:13:58.879272"}}
{"question": "What operating systems support ENA Express SRD functionality?", "answer": "The SRD functionality is supported on all operating systems, but EthTool counters and metrics are available only on the latest Amazon Linux AMI or by installing ENA driver version 2.8.0 or later.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-11T15:14:03.259649"}}
{"question": "In what scenarios does ENA Express fall back to normal operation?", "answer": "ENA Express falls back to normal operation when communicating with another instance that doesn't support or hasn't enabled ENA Express.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-11T15:14:03.260000"}}
{"question": "What are the main differences between EFA and ENA Express?", "answer": "EFA is a network interface built for HPC and ML applications that uses the SRD protocol and requires a different network programming model, while ENA Express helps you run your application transparently on TCP and UDP and offers additional monitoring tools.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-104", "source_tokens": 422, "generated_at": "2026-02-11T15:14:03.260408"}}
{"question": "What specific benefits does EFA bring to HPC applications compared to traditional TCP channels?", "answer": "EFA provides lower and more consistent latency and higher throughput than traditional TCP channels, enabling HPC applications to scale better.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-11T15:14:07.859857"}}
{"question": "Which types of applications can benefit from using EFA for communication?", "answer": "HPC applications that distribute computational workloads across a cluster of instances for parallel processing and use middleware like MPI or other HPC middleware that supports the libfabric communication stack.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-11T15:14:07.860110"}}
{"question": "What are the key differences between an EFA ENI and an ENA ENI?", "answer": "An EFA ENI provides all ENA ENI functionalities plus a new OS bypass hardware interface for user-space applications to communicate directly with the hardware-provided reliable transport functionality. However, communication using the OS bypass functionality is limited to instances within the same Availability Zone.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-105", "source_tokens": 425, "generated_at": "2026-02-11T15:14:07.860239"}}
{"question": "What are the ways to enable an EFA ENI on an AWS instance?", "answer": "An EFA ENI can be enabled during the instance launch or added to a stopped instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-11T15:14:11.719247"}}
{"question": "In what scenarios can you use an EFA ENI instead of a regular ENA ENI?", "answer": "An EFA ENI is preferred when applications require direct hardware communication with the ENI, bypassing the instance kernel.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-11T15:14:11.719536"}}
{"question": "What are the differences in the networking capabilities between an ENA ENI and an EFA ENI?", "answer": "An ENA ENI supports traditional IP networking features necessary for VPC networking, while an EFA ENI offers these features plus hardware support for OS-bypass communication.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-106", "source_tokens": 145, "generated_at": "2026-02-11T15:14:11.719689"}}
{"question": "What networking capabilities does Enhanced Networking support?", "answer": "Enhanced Networking supports networking capabilities using SR-IOV (Single Root I/O Virtualization), which provides higher I/O performance and lower CPU utilization.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-11T15:14:16.349684"}}
{"question": "Why is Enhanced Networking beneficial for applications?", "answer": "Enhanced Networking is beneficial for applications that require high packet-per-second performance and/or low latency networking.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-11T15:14:16.350057"}}
{"question": "How does Intel 82599 VF interface compare to other instance types for Enhanced Networking support?", "answer": "The Intel 82599 VF interface supports network speeds of up to 10 Gbps and is used by C3, C4, D2, I2, M4 (excluding m4.16xlarge), and R3 instances for Enhanced Networking.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-107", "source_tokens": 472, "generated_at": "2026-02-11T15:14:16.350481"}}
{"question": "How many network interfaces can a c6i instance with two network cards launch?", "answer": "The c6i instance can launch 14 network interfaces in total, with 7 interfaces on each network card.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-11T15:14:19.857728"}}
{"question": "What are the benefits of using multiple network cards for an EC2 instance?", "answer": "Using multiple network cards for an EC2 instance can increase overall system performance and provide higher network bandwidth and improved packet-rate performance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-11T15:14:19.858068"}}
{"question": "What instance types support the use of two network cards?", "answer": "Accelerated instances, such as p4d.24xlarge, and network optimized instances, such as c6in.32xlarge, support the use of two network cards.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-108", "source_tokens": 333, "generated_at": "2026-02-11T15:14:19.858494"}}
{"question": "What are the two types of load balancers offered by Elastic Load Balancing?", "answer": "Elastic Load Balancing offers two types of load balancers: Classic Load Balancer and Application Load Balancer.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-11T15:14:24.092860"}}
{"question": "How does each type of load balancer in Elastic Load Balancing differ in routing traffic?", "answer": "Classic Load Balancer routes traffic based on either application or network level information, while Application Load Balancer routes traffic based on advanced application level information.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-11T15:14:24.093085"}}
{"question": "In which scenarios would I use the Classic Load Balancer and in which scenarios would I use the Application Load Balancer?", "answer": "Classic Load Balancer is ideal for simple load balancing of traffic across multiple EC2 instances. Application Load Balancer is ideal for applications needing advanced routing capabilities, microservices, and container-based architectures.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-109", "source_tokens": 175, "generated_at": "2026-02-11T15:14:24.093462"}}
{"question": "How many Elastic IP addresses am I allowed by default in each region?", "answer": "The default limit for Elastic IP addresses per region is 5.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-11T15:14:28.328023"}}
{"question": "Why is there a charge for an Elastic IP address when it's not associated with a running instance?", "answer": "Amazon EC2 charges for Elastic IP addresses not associated with a running instance to encourage efficient use of Elastic IP addresses.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-11T15:14:28.328313"}}
{"question": "Is it necessary to have an Elastic IP address for every instance I have running?", "answer": "No, you don't need an Elastic IP address for all instances. Instances come with private and public IP addresses by default. The public IP address is associated with the instance until it's stopped, terminated, or replaced with an Elastic IP address.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-110", "source_tokens": 467, "generated_at": "2026-02-11T15:14:28.328731"}}
{"question": "What process should customers follow to configure the reverse DNS record for a custom Elastic IP address?", "answer": "Customers should fill out the form provided to configure the reverse DNS record of their Elastic IP address.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-11T15:14:32.759464"}}
{"question": "Why would a customer choose to delegate the management of reverse DNS for their Elastic IPs to Amazon Route 53?", "answer": "Customers may choose to delegate reverse DNS management to Amazon Route 53 so that they can manage their own PTR records to support specific use-cases.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-11T15:14:32.759853"}}
{"question": "How does configuring the reverse DNS record for a custom Elastic IP address differ from delegating its management to Amazon Route 53?", "answer": "Configuring the reverse DNS record for a custom Elastic IP involves filling out a form, while delegating its management to Amazon Route 53 allows customers to manage their own PTR records.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-111", "source_tokens": 147, "generated_at": "2026-02-11T15:14:32.760296"}}
{"question": "What options do I have to control the visibility of my EC2 instances?", "answer": "You can place your running instances into arbitrary groups of your choice and use the web services interface to specify which groups may communicate with each other and which IP subnets on the Internet can talk to which groups.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-11T15:14:37.364947"}}
{"question": "How does the security system on AWS allow me to control access to my EC2 instances?", "answer": "By allowing you to place your instances into groups and controlling communication between those groups, you have the ability to control access to your instances in the AWS dynamic environment.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-11T15:14:37.365288"}}
{"question": "How does the security control on EC2 compare to the ability to control access to my instances through group settings?", "answer": "Both methods allow you to control access to your EC2 instances, but the EC2 security system also provides the ability to control communication between groups and specify which IP subnets can talk to which groups.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-112", "source_tokens": 253, "generated_at": "2026-02-11T15:14:37.365772"}}
{"question": "What is the minimum time interval for CloudWatch to receive and aggregate metrics?", "answer": "Metrics are received and aggregated at 1 minute intervals.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-11T15:14:41.446730"}}
{"question": "Which operating systems can CloudWatch receive metrics for?", "answer": "Amazon CloudWatch receives and provides metrics for all Amazon EC2 instances and should work with any operating system currently supported by the Amazon EC2 service.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-11T15:14:41.447072"}}
{"question": "How does the graphing of 1 week period look different between 5 minute and 1 minute intervals?", "answer": "When graphing a 1 week period, data points will be displayed differently between a 5 minute and a 1 minute period due to the way CloudWatch calculates aggregate points. In a 5 minute period, the single data point is placed at the beginning of the 5 minute time window, while in a 1 minute period, the single data point is placed at the 1 minute mark.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-113", "source_tokens": 464, "generated_at": "2026-02-11T15:14:41.447527"}}
{"question": "What is the purpose of Amazon EC2 Auto Scaling?", "answer": "Amazon EC2 Auto Scaling is a fully managed service designed to automatically launch or terminate Amazon EC2 instances based on predefined conditions to maintain application availability and optimize capacity.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-11T15:14:46.179313"}}
{"question": "How does the capacity-optimized allocation strategy in EC2 Auto Scaling work?", "answer": "The capacity-optimized allocation strategy in Amazon EC2 Auto Scaling analyzes capacity metrics to launch Spot Instances from the most available pools. It's a good choice for workloads with a higher cost of interruption.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-11T15:14:46.179670"}}
{"question": "What's the difference between capacity-optimized and lowest-price allocation strategies in EC2 Auto Scaling?", "answer": "The capacity-optimized strategy analyzes capacity metrics to launch Spot Instances from the most available pools, while the lowest-price strategy launches instances strictly based on the lowest priced pools.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-114", "source_tokens": 285, "generated_at": "2026-02-11T15:14:46.180045"}}
{"question": "What information is persisted when I hibernate an instance?", "answer": "When you hibernate an instance, data from your EBS root volume and any attached EBS data volumes is persisted, as well as the contents from the instanceâ€™s memory (RAM) to the EBS root volume.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-11T15:14:50.781393"}}
{"question": "Why should I choose hibernation over stopping an instance?", "answer": "Hibernation allows you to keep the memory state across Stop/Start cycles and quickly resume your instance, reducing the time it takes for the instance to return to service. In contrast, stopping an instance clears the RAM and requires more time to boot up.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-11T15:14:50.781696"}}
{"question": "What is the difference in cost between hibernating and stopping an instance?", "answer": "Both hibernation and stopping an instance do not incur instance usage fees while the instance is not running. However, hibernating instances are charged at standard EBS rates for storage, while stopped instances do not incur any additional charges.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-115", "source_tokens": 495, "generated_at": "2026-02-11T15:14:50.781869"}}
{"question": "Can an existing instance be put into hibernation?", "answer": "No, hibernation must be enabled during instance launch.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-11T15:14:54.516237"}}
{"question": "How can you tell if an instance is hibernated?", "answer": "Check the instance state reason in the console or API response. It should be 'Client.UserInitiatedHibernate' for a hibernated instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-11T15:14:54.516567"}}
{"question": "What is the difference between hibernating and stopping an instance in terms of data persistence?", "answer": "Both hibernation and stopping save the EBS volume and private IP address. However, hibernation also saves the instance's memory on the EBS root volume and maintains the elastic IP address. The network behavior is similar to the EC2 Stop-Start workflow.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-116", "source_tokens": 420, "generated_at": "2026-02-11T15:14:54.517051"}}
{"question": "What is the maximum duration for which an instance can be hibernated?", "answer": "An instance can be hibernated for a maximum duration of 60 days.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-11T15:15:01.944437"}}
{"question": "Why can't we keep hibernated instances indefinitely on the AWS platform?", "answer": "We cannot keep hibernated instances indefinitely because upgrades and security patches can conflict with old hibernated instances, and AWS needs to perform critical updates that require users to resume the hibernated instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-11T15:15:01.944788"}}
{"question": "What are the differences in hibernation support between Amazon Linux, Ubuntu, and Windows operating systems for various instance types?", "answer": "For Amazon Linux, Amazon Linux 2, Ubuntu, and Windows, hibernation is supported across C3, C4, C5, C5d, I3, M3, M4, M5, M5a, M5ad, M5d, R3, R4, R5, R5a, R5ad, R5d, T2, T3, and T3a instances. For CentOS, Fedora, and Red Hat Enterprise Linux, hibernation is supported across C5, C5d, M5, M5a, M5ad, M5d, R5, R5a, R5ad, R5d, T3, and T3a instances. Hibernation is supported for instances with less than 150 GB of RAM for other operating systems. For Windows instances, hibernation is supported up to 16 GB of RAM.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-117", "source_tokens": 476, "generated_at": "2026-02-11T15:15:01.945212"}}
{"question": "What size EBS root volume is required to enable hibernation?", "answer": "The EBS root volume should be large enough to store the instance memory (RAM) contents and accommodate the expected usage.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-11T15:15:06.440938"}}
{"question": "Why does the root volume size matter when enabling hibernation?", "answer": "The root volume is used to store the instance memory during hibernation. If the volume is not large enough, hibernation will fail and the instance will be shut down.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-11T15:15:06.441320"}}
{"question": "How does the size of an EBS root volume used for hibernation compare to that of a non-hibernation instance?", "answer": "For hibernation, the root volume should be large enough to store the instance memory in addition to the operating system and applications. For a non-hibernation instance, only the operating system and applications need to be stored on the root volume.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-118", "source_tokens": 175, "generated_at": "2026-02-11T15:15:06.441551"}}
{"question": "What file formats does VM Import/Export support for importing?", "answer": "VM Import/Export supports importing VMware ESX VMDK images, Citrix Xen VHD images, Microsoft Hyper-V VHD images, and RAW images.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-11T15:15:11.202533"}}
{"question": "How do I prepare a VMDK file for import?", "answer": "To prepare a VMDK file for import, use the 'File-Export-Export to OVF template' feature in the VMware vSphere Client. The resulting VMDK file should be compressed to reduce the image size and be compatible with VM Import/Export.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-11T15:15:11.202780"}}
{"question": "What is the difference between VMDK and VHD file formats?", "answer": "VMDK is a file format used by VMware for encapsulating virtual machine hard disks, while VHD is a file format used by Microsoft Hyper-V and Citrix Xen for the same purpose.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-119", "source_tokens": 503, "generated_at": "2026-02-11T15:15:11.202923"}}
{"question": "What are the steps to initiate an export of a virtual machine in XenCenter?", "answer": "Open Citrix XenCenter, select the virtual machine you want to export, go to the Tools menu, choose 'Virtual Appliance Tools', and select 'Export Appliance' to initiate the export task.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-11T15:15:15.610145"}}
{"question": "Why is it necessary to ensure remote access is enabled when importing a virtual machine to Amazon EC2?", "answer": "You will not be able to access your instance after the import is complete if your host firewall (Windows firewall, iptables, or similar) does not allow access to RDP or SSH.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-11T15:15:15.610531"}}
{"question": "How does the process of exporting a virtual machine in XenCenter compare to exporting one in Hyper-V?", "answer": "In both XenCenter and Hyper-V, you initiate the export task through the management interface, and upon completion, you can locate the resulting image file in a specified directory.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-120", "source_tokens": 458, "generated_at": "2026-02-11T15:15:15.610931"}}
{"question": "What command is used to export an Amazon EC2 instance?", "answer": "The ec2-create-instance-export-task command is used to export an Amazon EC2 instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-11T15:15:22.278785"}}
{"question": "How can you export an Amazon EC2 instance and what is the process like?", "answer": "To export an Amazon EC2 instance, you use the ec2-create-instance-export-task command which captures the necessary parameters to export the instance to your chosen format (VMDK, OVA or VHD) and saves the exported file in an S3 bucket. The progress of the export can be monitored using the ec2-describe-export-tasks command.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-11T15:15:22.279050"}}
{"question": "What's the difference between using the ec2-import-instance and the AWS Management Portal for vCenter to import a VM to Amazon EC2?", "answer": "The main difference between using the ec2-import-instance command and the AWS Management Portal for vCenter to import a VM to Amazon EC2 is the user interface and the level of manual intervention required. The ec2-import-instance command requires more manual steps including importing the disk image, configuring instance properties, and uploading the disk image to S3. The AWS Management Portal for vCenter, on the other hand, provides a graphical user interface for the import process and handles exporting the VM from vCenter, uploading it to S3, and converting it into an EC2 instance for you.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-121", "source_tokens": 505, "generated_at": "2026-02-11T15:15:22.279431"}}
{"question": "What fees are associated with exporting an EC2 instance using VM Import/Export?", "answer": "You will be charged standard Amazon S3 storage fees for storing the exported VM image file, standard S3 data transfer charges when downloading the file to your on-premise virtualization environment, and standard EBS charges for storing a temporary snapshot of the EC2 instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-11T15:15:27.371843"}}
{"question": "Why can't you export EC2 instances with multiple network interfaces using VM Import/Export?", "answer": "The reason why you cannot export an EC2 instance with multiple network interfaces using VM Import/Export is because the tool only exports the boot volume of the EC2 instance and does not support exporting EBS data volumes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-11T15:15:27.372097"}}
{"question": "How does the cost of importing a VM compare to exporting a VM with VM Import/Export?", "answer": "Both importing and exporting a VM with VM Import/Export incur standard Amazon S3 data transfer and storage fees. However, importing a VM also incurs Amazon EC2 instance hour and EBS service fees, while exporting a VM only incurs standard S3 storage and data transfer fees and temporary EBS charges.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-122", "source_tokens": 447, "generated_at": "2026-02-11T15:15:27.372488"}}
{"question": "What happens to my on-premise Windows license key when I import a VM that has reached end-of-support (EOS) in AWS?", "answer": "You can reuse the on-premise Windows license key for another VM within your on-premises environment, but the license key is not available when running the imported VM as an EC2 instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-11T15:15:33.045652"}}
{"question": "What is the process for maintaining the operating system licenses when importing a Red Hat Enterprise Linux (RHEL) VM into AWS?", "answer": "With license portability, you are responsible for maintaining the RHEL licenses for imported instances, which you can do using Cloud Access subscriptions for Red Hat Enterprise Linux.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-11T15:15:33.045911"}}
{"question": "How does the time it takes to import a virtual machine compare between a 10 GB Windows Server 2008 SP2 VMDK image and a larger disk image, considering a 10 Mbps network connection?", "answer": "The 10 GB Windows Server 2008 SP2 VMDK image takes approximately 2 hours to import, but a larger disk image may take significantly longer due to the size of the disk and the network connection speed.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-123", "source_tokens": 506, "generated_at": "2026-02-11T15:15:33.046308"}}
{"question": "Which command-line interfaces and APIs does AWS provide for VM Import/Export?", "answer": "AWS provides VM Import/Export commands via EC2 CLI and API.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-11T15:15:36.587341"}}
{"question": "How can you use the AWS Management Portal for vCenter to import VMs into Amazon EC2?", "answer": "You can import VMs into Amazon EC2 using the AWS Management Portal for vCenter.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-11T15:15:36.587617"}}
{"question": "What are the benefits of using the AWS Management Console after importing instances via the AWS Management Portal for vCenter?", "answer": "After importing instances via the AWS Management Portal for vCenter, you can manage and use them via the AWS Management Console.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-124", "source_tokens": 58, "generated_at": "2026-02-11T15:15:36.588008"}}
{"question": "What is the billing rate for Amazon EC2 instances based on?", "answer": "You pay based on the hour or second for each instance type, as displayed in the pricing section on the EC2 detail page.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-11T15:15:40.706947"}}
{"question": "How does billing for Amazon EC2 instances work conceptually?", "answer": "Billing starts when Amazon EC2 initiates the boot sequence of an instance and ends when the instance terminates. Instances in a 'running' state are billed, and you can avoid additional charges by stopping or terminating the instance.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-11T15:15:40.707284"}}
{"question": "How does billing for data transfer between instances in different regions compare to billing for data transfer between instances in the same region?", "answer": "Data transfer between instances in different regions is charged at 'Data Transfer Out from EC2 to Another AWS Region' for the first instance and 'Data Transfer In from Another AWS Region' for the second instance.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-125", "source_tokens": 460, "generated_at": "2026-02-11T15:15:40.707814"}}
{"question": "What rates will I be charged for inter-region data transfer between two EC2 instances in my monthly bill?", "answer": "You will be charged Inter-Region Data Transfer Out for the first instance and Inter-Region Data Transfer In for the second instance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-11T15:15:44.506560"}}
{"question": "How is per-second usage displayed in my monthly EC2 billing report?", "answer": "Although EC2 charges are calculated on a per second basis, the monthly billing report will show cumulative usage for each instance in decimal hours.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-11T15:15:44.506808"}}
{"question": "How does inter-region data transfer pricing compare between instances in the same region versus different regions?", "answer": "Inter-Region Data Transfer charges apply when data is transferred between instances in different regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-126", "source_tokens": 230, "generated_at": "2026-02-11T15:15:44.506971"}}
{"question": "What is the condition for receiving free data transfer out from AWS when moving data off the platform?", "answer": "Customers are eligible for free data transfer out from AWS when they move all of their data off of AWS or all of their data off of a particular AWS service. To request this, customers must contact AWS Customer Support and provide necessary information to evaluate their moving plans and calculate a proper credit amount. The credit is temporary and counts against data transfer out usage only, and customers have 90 days to complete the move off AWS.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-11T15:15:50.591075"}}
{"question": "What steps should be taken before initiating a data transfer out from AWS to receive free data transfer?", "answer": "Before starting a data transfer out from AWS to receive free data transfer, the customer must contact their dedicated AWS account team, review the criteria and process, contact AWS Customer Support, and provide necessary information to evaluate the moving plans and calculate a proper credit amount.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-11T15:15:50.591350"}}
{"question": "How does the free data transfer out process for moving data off AWS differ from the process for EU customers under the EU Data Act?", "answer": "The free data transfer out process for moving data off AWS involves contacting AWS Customer Support to evaluate the moving plans and calculate a proper credit amount. EU customers under the EU Data Act have additional steps and criteria to follow in accordance with the AWS EU Data Act Addendum.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-127", "source_tokens": 493, "generated_at": "2026-02-11T15:15:50.591746"}}
{"question": "What is the reason AWS requires customers to request pre-approval for free data transfer out to the internet?", "answer": "AWS requires customers to request pre-approval for free data transfer out to the internet before moving their data out of AWS, as they need to verify that the data transfer is for the purpose of moving off of AWS.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-11T15:15:56.554356"}}
{"question": "Is there a limit to the amount of free data transfer out available for customers with less than 100 GB of data stored in their AWS account?", "answer": "Customers with less than 100 GB of data stored in their AWS account can move this data off of AWS for free under AWSâ€™s existing 100 GB monthly free tier for data transfer out. Those customers are not required to follow the process described in the text and are not eligible for additional credits.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-11T15:15:56.554644"}}
{"question": "How does the free data transfer out process differ between customers with more and less than 100 GB of data stored in their AWS account?", "answer": "Customers with less than 100 GB of data stored in their AWS account can move their data off of AWS for free without following the process described in the text, while those with more data must request pre-approval and follow the process to receive free data transfer out.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-128", "source_tokens": 504, "generated_at": "2026-02-11T15:15:56.555044"}}
{"question": "What is the process to request free DTIR when migrating data from Singapore to Malaysia or Thailand region?", "answer": "1. Contact your AWS account team if you have one and inform them of your plans. 2. Review the eligibility criteria and process. 3. Contact AWS Customer Support and indicate that your request is for 'free data transfer inter-region (DTIR) to migrate data from Singapore region to Malaysia or Thailand region'. 4. Provide required information for review. 5. If approved, receive a temporary credit for DTIR based on the volume of data to be migrated. 6. Complete migration within 60 days and delete migrated data and workloads from Singapore region within 30 days.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-11T15:16:04.282625"}}
{"question": "What is the difference between requesting free DTIR for migrating data from Singapore to Malaysia or Thailand region and a regular data transfer?", "answer": "Free DTIR involves requesting a credit for the cost of data transfer inter-region (DTIR) when migrating data from Singapore region to Malaysia or Thailand region. A regular data transfer does not involve receiving a credit for the transfer cost.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-11T15:16:04.282900"}}
{"question": "What are the steps to request free DTIR to migrate data from the Singapore region to Malaysia or Thailand region?", "answer": "1. Contact your AWS account team if you have one and inform them of your plans. 2. Review the eligibility criteria and process. 3. Contact AWS Customer Support and provide required information for review. 4. If approved, receive a temporary credit for DTIR based on the volume of data to be migrated. 5. Complete migration within 60 days and delete migrated data and workloads from Singapore region within 30 days.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-129", "source_tokens": 504, "generated_at": "2026-02-11T15:16:04.283303"}}
{"question": "What is the reason AWS requires pre-approval for free DTIR during data migration from Singapore to Malaysia or Thailand regions?", "answer": "AWS doesn't know the reason for every data transfer and needs customers to specify if the data transfer is for inter-region migration from Singapore to Malaysia or Thailand regions to qualify for free DTIR.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-11T15:16:09.116573"}}
{"question": "How does AWS determine if a data transfer qualifies for free DTIR during inter-region migration from Singapore to Malaysia or Thailand regions?", "answer": "AWS determines if a data transfer qualifies for free DTIR based on customer's pre-approval and verification of migration intent.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-11T15:16:09.116896"}}
{"question": "What's the difference between AWS's approach to free DTIR for data migration between Singapore, Malaysia, and Thailand regions compared to other regions?", "answer": "AWS requires pre-approval from customers for free DTIR during migration between Singapore, Malaysia, and Thailand regions, while the approach may be different for other regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-130", "source_tokens": 240, "generated_at": "2026-02-11T15:16:09.117277"}}
{"question": "What attributes can be changed on a Convertible RI during its term?", "answer": "A Convertible RI allows the changing of its instance type, operating system, tenancy, and payment option during its term.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-11T15:16:12.577712"}}
{"question": "When would it be more beneficial to purchase a Convertible RI over a Standard RI?", "answer": "A Convertible RI is more beneficial when a customer can commit to using EC2 instances for a three-year term, is uncertain about future instance needs, or wants to take advantage of price changes.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-11T15:16:12.577953"}}
{"question": "What are the term length options available for Convertible RIs?", "answer": "Convertible RIs are available for purchase with a one-year or three-year term.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-131", "source_tokens": 468, "generated_at": "2026-02-11T15:16:12.578141"}}
{"question": "What is the total value in the context of Amazon EC2 Convertible Reservations?", "answer": "The total value is the sum of all expected payments that youâ€™d make during the term for the RI.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-11T15:16:17.151349"}}
{"question": "How is the true-up cost calculated during a conversion between two All Upfront Convertible Reservations?", "answer": "The true-up cost is calculated by subtracting the remaining value on the original Convertible RI from the upfront cost of the desired Convertible RI.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-11T15:16:17.151644"}}
{"question": "What is the difference in the conversion process between All Upfront and No Upfront Convertible Reservations?", "answer": "During All Upfront Convertible RI conversions, there is a true-up charge based on the difference between the original and the new Convertible RI's upfront value. During No Upfront Convertible RI conversions, there is no true-up charge but the new hourly usage cost must be greater than or equal to the old hourly usage cost.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-132", "source_tokens": 437, "generated_at": "2026-02-11T15:16:17.152121"}}
{"question": "What is the minimum number of Convertible RIs I'll receive when exchanging for another, given the hourly rate?", "answer": "EC2 uses the value of the Convertible RIs youâ€™re trading in to calculate the minimal number of Convertible RIs youâ€™ll receive while ensuring the result of the exchange gives you Convertible RIs of equal or greater value.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-11T15:16:21.580640"}}
{"question": "How does the exchange process work when I want to trade in one Convertible RI for another?", "answer": "EC2 ensures that the result of the exchange gives you Convertible RIs of equal or greater value, based on the hourly rate of the Convertible RIs involved.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-11T15:16:21.580936"}}
{"question": "What is the difference between exchanging Convertible RIs with different hourly rates?", "answer": "You'll receive a different number of Convertible RIs based on the hourly rates, with the value of the RIs youâ€™re trading in determining the minimum number of RIs youâ€™ll receive in the exchange.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-133", "source_tokens": 407, "generated_at": "2026-02-11T15:16:21.581351"}}
{"question": "What instance types, Availability Zones, and purchase models does Amazon EC2 Fleet support?", "answer": "Amazon EC2 Fleet lets you provision compute capacity across different instance types, Availability Zones, and On-Demand, Reserved Instances (RI), and Spot Instances purchase models.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-11T15:16:25.214784"}}
{"question": "What is the difference between using Amazon EC2 Spot Fleet and Amazon EC2 Fleet?", "answer": "Both offer similar functionality, but there is no requirement to migrate from Amazon EC2 Spot Fleet to Amazon EC2 Fleet.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-11T15:16:25.215051"}}
{"question": "How can I use Reserved Instance discounts with Amazon EC2 Fleet?", "answer": "Yes, if the On-Demand instance launched by EC2 Fleet matches an existing RI, that instance will receive the RI discount.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-134", "source_tokens": 467, "generated_at": "2026-02-11T15:16:25.215441"}}
{"question": "What allocation strategies does EC2 Fleet offer for Spot Instances?", "answer": "EC2 Fleet offers three allocation strategies for Spot Instances: capacity-optimized, lowest price, and diversified.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-11T15:16:29.519671"}}
{"question": "How does the capacity-optimized allocation strategy for EC2 Fleet work?", "answer": "The capacity-optimized allocation strategy for EC2 Fleet analyzes capacity metrics to provision Spot Instances from the most available pools. It is suitable for workloads with a higher cost of interruption.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-11T15:16:29.520139"}}
{"question": "What is the difference between the capacity-optimized and lowest price allocation strategies for EC2 Fleet?", "answer": "The capacity-optimized strategy attempts to provision Spot Instances from the most available pools based on capacity metrics, while the lowest price strategy provision Spot Instances from pools with the lowest price per unit of capacity.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-135", "source_tokens": 344, "generated_at": "2026-02-11T15:16:29.520349"}}
{"question": "What is the purpose of Amazon EC2 Capacity Blocks for ML?", "answer": "Amazon EC2 Capacity Blocks for ML allow you to reserve GPU instances in an Amazon EC2 UltraClusters to run machine learning workloads, with the ability to reserve GPU capacity starting on a future date for durations up to 6 months and in cluster sizes of one to 64 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-11T15:16:35.797649"}}
{"question": "Why would I choose to use Amazon EC2 Capacity Blocks over On-Demand Capacity Reservations?", "answer": "You should use EC2 Capacity Blocks when you need short-term capacity assurance to train or fine-tune ML models, run experiments, build prototypes, or handle surges in demand for ML applications. On the other hand, you should use On-Demand Capacity Reservations for all other workload types that need assurance, such as business-critical applications, regulatory requirements, or disaster recovery.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-11T15:16:35.797916"}}
{"question": "How does reserving capacity with Amazon EC2 Capacity Blocks benefit ML workloads?", "answer": "Reserving capacity with Amazon EC2 Capacity Blocks ensures capacity availability for GPU instances, allowing you to plan ML development with confidence and leverage the best network latency and throughput performance available in EC2. This can be particularly useful in the face of industry-wide GPU shortages.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-136", "source_tokens": 445, "generated_at": "2026-02-11T15:16:35.798063"}}
{"question": "What is the notice period before an EC2 Capacity Block expires for receiving an event from EventBridge?", "answer": "Around 30 minutes before the EC2 Capacity Block expires, AWS will emit an event through EventBridge.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-11T15:16:44.462405"}}
{"question": "How does the process work for using an EC2 Capacity Block?", "answer": "Once you purchase an EC2 Capacity Block, a reservation is created in your account. When the start time of the reservation arrives, EC2 will emit an event through Amazon EventBridge to indicate that the reservation is now active. To use an active EC2 Capacity Block, you need to select the â€˜Capacity Blockâ€™ purchase option and target the capacity reservation ID for your EC2 Capacity Block while launching EC2 instances. When your EC2 Capacity Block end time approaches, EC2 will emit another event through EventBridge to let you know your reservation is ending soon, allowing you to checkpoint your workload. Around 30 minutes before the EC2 Capacity Block expires, AWS will begin terminating any running instances. The amount you are charged for your EC2 Capacity Block does not include the last 30 minutes of the reservation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-11T15:16:44.462648"}}
{"question": "How does an EC2 p5e.48xlarge instance capacity block compare to an EC2 p4d.24xlarge instance capacity block in terms of availability?", "answer": "Both EC2 p5e.48xlarge and EC2 p4d.24xlarge instances have different availability in various regions. The p5e.48xlarge instance is available in US East (Ohio) and US East (N. Virginia), US East (Ohio), US West (Oregon), and Asia Pacific (Tokyo) regions. The p4d.24xlarge instance is available in US East (Ohio) and US West (Oregon) regions. Therefore, the comparison is based on the availability of the specific instance types in these regions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-137", "source_tokens": 441, "generated_at": "2026-02-11T15:16:44.463145"}}
{"question": "What time does an EC2 Capacity Block reservation begin and end?", "answer": "An EC2 Capacity Block reservation begins at 11:30 AM Coordinated Universal Time (UTC) and ends at 11:30 AM UTC.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-11T15:16:48.341486"}}
{"question": "Why can't I modify or cancel an EC2 Capacity Block reservation?", "answer": "EC2 Capacity Block reservations cannot be modified or canceled once they are made.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-11T15:16:48.341763"}}
{"question": "How does the pricing of EC2 Capacity Blocks compare to Savings Plans and Reserved Instances?", "answer": "EC2 Capacity Blocks are not covered by Savings Plans or Reserved Instances discounts.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-138", "source_tokens": 440, "generated_at": "2026-02-11T15:16:48.341965"}}
{"question": "What is the purpose of Capacity Reservations in AWS?", "answer": "Capacity Reservations allow you to reserve compute capacity for Amazon EC2 instances in a specific Availability Zone for any duration, ensuring access to Amazon EC2 capacity when needed.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-11T15:16:52.604624"}}
{"question": "In what scenarios would Capacity Reservations be beneficial?", "answer": "Capacity Reservations are beneficial for business-critical workloads that require long or short-term capacity assurance and have strict capacity requirements.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-11T15:16:52.604919"}}
{"question": "How does the pricing model for Capacity Reservations work?", "answer": "Capacity Reservations are charged at the equivalent On-Demand rate, with no upfront or additional charges. Discounts from Savings Plans or Regional Reserved Instances apply to both used and unused portions of the reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-139", "source_tokens": 506, "generated_at": "2026-02-11T15:16:52.605104"}}
{"question": "What match criteria can be used for Capacity Reservations?", "answer": "Capacity Reservations can have either 'Open' or 'Targeted' match criteria. 'Open' match criteria will automatically cover running instances or newly launched instances that match the reservation. 'Targeted' match criteria allows specifying which instances can use the reservation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-11T15:16:57.076789"}}
{"question": "What determines the number of instances that can be reserved?", "answer": "The number of instances that can be reserved is based on the account's On-Demand instance limit and the number of instances already running.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-11T15:16:57.077048"}}
{"question": "How does Capacity Reservation match criteria (Open vs. Targeted) compare in terms of instance allocation?", "answer": "Open match criteria automatically covers running and newly launched instances that match the reservation, while Targeted match criteria allows specifying which instances can use the reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-140", "source_tokens": 503, "generated_at": "2026-02-11T15:16:57.077454"}}
{"question": "What documentation should I refer to for creating and using Capacity Reservations in AWS?", "answer": "Refer to Linux or Windows technical documentation to learn about creating and using a Capacity Reservation.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-11T15:17:00.864707"}}
{"question": "How does resource sharing with AWS RAM work for Capacity Reservations?", "answer": "You can create a Resource Share using AWS RAM, add Capacity Reservations to the Resource Share, and specify target accounts to share the resources with.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-11T15:17:00.864983"}}
{"question": "How does AWS RAM resource sharing for Capacity Reservations compare to sharing in other AWS services?", "answer": "AWS RAM allows you to create a Resource Share, add Capacity Reservations to it, and specify target accounts to share the resources with.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-141", "source_tokens": 101, "generated_at": "2026-02-11T15:17:00.865385"}}
{"question": "What is the difference between a zonal RI and a regional RI in terms of capacity reservation?", "answer": "A zonal RI is a type of Reserved Instance scoped to a specific Availability Zone (AZ), which provides instance capacity matching the exact RI configuration for that AZ, referred to as 'capacity reservation'. A regional RI, on the other hand, is scoped to a region and applies the discount to usage across AZs and instance sizes within that region, without the capacity reservation.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-11T15:17:06.520531"}}
{"question": "What is the advantage of purchasing a Convertible RI over a Standard RI in terms of flexibility?", "answer": "A Convertible RI allows you to change your instance configuration during the term while still receiving a discount on your EC2 usage. In contrast, a Standard RI offers a significant discount on EC2 instance usage when you commit to a particular instance family but does not provide the same level of flexibility in terms of changing the instance type.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-11T15:17:06.520872"}}
{"question": "What is the discounted rate for a regional RI applied to?", "answer": "The discounted rate for a regional RI is applied to usage across Availability Zones and instance sizes within the region.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-142", "source_tokens": 396, "generated_at": "2026-02-11T15:17:06.521288"}}
{"question": "What is the normalization factor for a small instance size in EC2?", "answer": "The normalization factor for a small instance size in EC2 is 1.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-11T15:17:12.604222"}}
{"question": "How does changing the instance size of an RI affect its discounted rate?", "answer": "Changing the instance size of an RI within the same instance family results in the discounted rate being applied to the normalized usage of the new instance size.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-11T15:17:12.604482"}}
{"question": "What payment options are available for RIs in EC2?", "answer": "The available payment options for RIs in EC2 include All Up Front, Partial Up Front, and No Up Front.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-144", "source_tokens": 423, "generated_at": "2026-02-11T15:17:12.604939"}}
{"question": "What percentage of upfront discount do I get if my total list value for RI purchases is $2M?", "answer": "The upfront discount is 5% for a total list value within the range of $500k-$4M.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-11T15:17:16.872754"}}
{"question": "How does the payment option for RIs impact the hourly rate for an instance?", "answer": "The Partial Upfront option requires a low upfront payment and offers a discounted hourly rate for the duration of the RI term.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-11T15:17:16.873062"}}
{"question": "What's the difference between a Reserved Instance and a Dedicated Host Reservation?", "answer": "Reserved Instances provide discounted hourly rates and capacity reservation for specific instance types, while Dedicated Host Reservations offer discounts for instances running on a dedicated host.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-145", "source_tokens": 510, "generated_at": "2026-02-11T15:17:16.873215"}}
{"question": "What is the list value of a three-year partial upfront m3.xlarge RI in the US-East region?", "answer": "The list value of a three-year partial upfront m3.xlarge RI in the US-East region is $2,922.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-11T15:17:21.976737"}}
{"question": "How does the calculation of volume discounts differ when using Consolidated Billing?", "answer": "When using Consolidated Billing, AWS calculates volume discounts based on the aggregate total list price of active RIs across all of your consolidated accounts.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-11T15:17:21.977086"}}
{"question": "How does the list value of a three-year partial upfront m3.xlarge RI compare to that of a c3.xlarge RI in the US-East region?", "answer": "The list value of a three-year partial upfront m3.xlarge RI in the US-East region is higher than that of a c3.xlarge RI, which is $2,199.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-146", "source_tokens": 502, "generated_at": "2026-02-11T15:17:21.977297"}}
{"question": "What happens to the cost of my RIs if I become eligible for other discount tiers in the future?", "answer": "The cost of your RIs will remain the same.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-11T15:17:25.439199"}}
{"question": "How does the process of receiving volume discounts on RIs work?", "answer": "You will automatically receive volume discounts when you purchase RIs using the PurchaseReservedInstance API or EC2 Management Console interface.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-11T15:17:25.439487"}}
{"question": "How does the cost of RIs with volume discounts compare to RIs without volume discounts?", "answer": "RIs with volume discounts have a lower cost than RIs without discounts.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-147", "source_tokens": 163, "generated_at": "2026-02-11T15:17:25.439631"}}
{"question": "What is the purpose of the RI Marketplace in the context of AWS?", "answer": "The RI Marketplace is an online platform where AWS customers can buy and sell Amazon EC2 Reserved Instances (RIs) from other businesses and organizations, providing a wider selection of RI term lengths and pricing options.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-11T15:17:29.911766"}}
{"question": "Under what conditions can I sell an RI on the RI Marketplace?", "answer": "You can list an RI on the RI Marketplace once you've registered as a seller, paid for the RI, and owned it for over 30 days.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-11T15:17:29.912043"}}
{"question": "Is it allowed to sell RIs that were purchased through discount programs on the EC2 RI Marketplace?", "answer": "No, AWS prohibits the resale of RIs purchased as part of a discount program according to the AWS Service Terms.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-148", "source_tokens": 451, "generated_at": "2026-02-11T15:17:29.912531"}}
{"question": "What information do I need to provide during the tax interview pipeline to sell RIs on the Marketplace?", "answer": "You will need to provide your company name, contact name, address, and Tax Identification Number using the TIMS workflow.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-11T15:17:34.941078"}}
{"question": "Why do I need to provide tax information and file a limit increase to sell RIs on the RI Marketplace?", "answer": "You need to provide tax information and file a limit increase if you exceed $20,000 in sales of RI or plan to sell 50 or more RIs, or if you plan to sell RIs worth more than $50,000 per year.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-11T15:17:34.941346"}}
{"question": "Is there a difference between the tax interview pipeline and the registration pipeline for listing RIs for sale on the RI Marketplace?", "answer": "The registration pipeline is used to add a bank account, complete the registration process, and receive a confirmation email. The tax interview pipeline is used to provide tax information and file a limit increase.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-149", "source_tokens": 505, "generated_at": "2026-02-11T15:17:34.941535"}}
{"question": "When can I view my listed RIs in the Amazon EC2 console?", "answer": "Your listed RIs, both third-party and those offered by AWS, can be viewed in the 'Reserved Instances' section of the Amazon EC2 console.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-11T15:17:39.464324"}}
{"question": "How does the RI Marketplace help buyers find the right RIs?", "answer": "The RI Marketplace groups listed RIs based on their type, term remaining, upfront price, and hourly price, making it easier for buyers to find the right RIs to purchase.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-11T15:17:39.464547"}}
{"question": "Can I set the hourly price when listing an RI?", "answer": "No, when listing an RI on the RI Marketplace, you can only set the upfront price you're willing to accept. The hourly price, which remains the same as the original RI, is not modifiable.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-150", "source_tokens": 477, "generated_at": "2026-02-11T15:17:39.464919"}}
{"question": "What bank account is required for selling RIs in the RI Marketplace?", "answer": "A US bank account is required for selling RIs in the RI Marketplace.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-11T15:17:43.138140"}}
{"question": "Why do I need a US bank account to sell RIs in the RI Marketplace?", "answer": "Selling RIs in the RI Marketplace requires a US bank account for payment processing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-11T15:17:43.138370"}}
{"question": "How does the payment process work for selling RIs in the RI Marketplace?", "answer": "Once AWS receives funds from the buyer, they will wire transfer the funds to the seller's US bank account and send an email notification.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-151", "source_tokens": 496, "generated_at": "2026-02-11T15:17:43.138776"}}
{"question": "What information is provided to sellers about the buyer's location?", "answer": "The buyerâ€™s city, state, zip+4, and country information will be provided to sellers via a disbursement report.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-11T15:17:46.963386"}}
{"question": "Why is the buyer's location information important for sellers?", "answer": "The buyerâ€™s location information is important for sellers as it enables them to calculate any necessary transaction taxes they need to remit to the government.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-11T15:17:46.963634"}}
{"question": "Is it allowed to purchase RIs from the RI Marketplace for your own listed RIs?", "answer": "No, you cannot purchase your own listed RIs, including those in any of your linked accounts, from the RI Marketplace.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-152", "source_tokens": 185, "generated_at": "2026-02-11T15:17:46.964051"}}
{"question": "What are the two types of Savings Plans offered by AWS?", "answer": "AWS offers Compute Savings Plans and EC2 Instance Savings Plans.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-11T15:17:52.912937"}}
{"question": "What are the benefits of using Compute Savings Plans over EC2 Instance Savings Plans?", "answer": "Compute Savings Plans offer more flexibility and can be applied to EC2 instance usage regardless of instance family, size, AZ, region, OS or tenancy, as well as to Fargate and Lambda usage. They help to reduce costs by up to 66%. In contrast, EC2 Instance Savings Plans provide the lowest prices but are only applicable to specific instance families in a particular region and offer savings up to 72%.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-11T15:17:52.913182"}}
{"question": "In what ways are Compute Savings Plans and EC2 Instance Savings Plans different?", "answer": "Compute Savings Plans provide more flexibility and can be used for any EC2 instances, Fargate, and Lambda usage within a commitment. They offer savings up to 66%. EC2 Instance Savings Plans, on the other hand, are specific to individual instance families within a region and offer savings up to 72%. They provide lower prices compared to Compute Savings Plans.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-153", "source_tokens": 445, "generated_at": "2026-02-11T15:17:52.913323"}}
{"question": "What savings does Compute Savings Plans offer compared to On Demand?", "answer": "Compute Savings Plans offer significant savings over On Demand, providing up to 66% savings.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-11T15:17:56.853368"}}
{"question": "How does the EC2 Instance Savings Plans' savings compare to EC2 RIs?", "answer": "EC2 Instance Savings Plans offer savings up to 72%, which is more than EC2 RIs' savings of up to 72%.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-11T15:17:56.853633"}}
{"question": "Which AWS service can I use to get started with Savings Plans?", "answer": "You can get started with Savings Plans from AWS Cost Explorer in the AWS Management Console or by using the API/CLI.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-154", "source_tokens": 482, "generated_at": "2026-02-11T15:17:56.854015"}}
{"question": "What discount can I get by using a Spot Instance instead of an On-Demand instance?", "answer": "Spot Instances can offer a discount of up to 90% off of On-Demand prices.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-11T15:18:01.585966"}}
{"question": "What's the main difference between a Spot Instance and an On-Demand instance in terms of usage?", "answer": "The main differences are that Spot Instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification, and Spot prices adjust gradually based on supply and demand for spare EC2 capacity.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-11T15:18:01.586338"}}
{"question": "How does the pricing model for a Spot Instance compare to that of an On-Demand instance?", "answer": "With a Spot Instance, you pay the Spot price that's in effect at the beginning of each instance-hour for your running instance, while with an On-Demand instance, you pay the On-Demand price for each instance-hour.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-155", "source_tokens": 511, "generated_at": "2026-02-11T15:18:01.586684"}}
{"question": "What is a Spot capacity pool and how many can I have?", "answer": "A Spot capacity pool is a set of unused EC2 instances with the same instance type, operating system, and Availability Zone. You can have multiple different Spot capacity pools to maximize the amount of Spot capacity available to you.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-11T15:18:06.457341"}}
{"question": "How does using multiple Spot capacity pools benefit me?", "answer": "Using multiple Spot capacity pools allows EC2 to find the most cost-effective capacity across the pools for your workload using features like EC2 Auto Scaling, EC2 Fleet, or Spot Fleet.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-11T15:18:06.457625"}}
{"question": "Can Spot Instances be used with Red Hat Enterprise Linux and third-party software?", "answer": "Spot Instances can be used with Linux/UNIX, Windows Server, but not Windows Server with SQL Server, or Red Hat Enterprise Linux (RHEL) at this time. However, they cannot be used with third-party software running on a paid AMI.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-156", "source_tokens": 498, "generated_at": "2026-02-11T15:18:06.457782"}}
{"question": "How can I start a stopped Spot Instance?", "answer": "You can start a stopped Spot Instance by calling the StartInstances API and providing the Instance Id or through the AWS Management Console by selecting the instance and clicking Actions > Instance State > Start.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-11T15:18:11.540712"}}
{"question": "What is the difference between stopping a Spot Instance by the user and it being interrupted?", "answer": "If the Spot Request Status code is 'instance-stopped-by-user', it means that you have stopped the Spot instance yourself. If it is interrupted by Amazon EC2, it means that the Spot capacity was no longer available and the instance was terminated.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-11T15:18:11.541005"}}
{"question": "What happens to the charging when a Spot Instance is stopped or interrupted?", "answer": "If an instance is terminated or stopped by Amazon EC2 in the first hour, no charge is incurred. If you stop or terminate the instance yourself, you will be charged for the nearest second. If the instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. For Windows or RHEL, stopping or terminating the instance yourself will result in a charge for an entire hour.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-157", "source_tokens": 426, "generated_at": "2026-02-11T15:18:11.541152"}}
{"question": "Why is my Spot instance terminated when it gets interrupted?", "answer": "Your Spot instance is terminated by default when it gets interrupted. You can choose to have it stopped or hibernated instead, but stop and hibernate options are only available for persistent Spot requests and Spot Fleets with the â€˜maintainâ€™ option enabled.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-11T15:18:17.994759"}}
{"question": "What is the difference between hibernating and stopping a Spot instance upon interruption?", "answer": "Hibernating your Spot instance results in it getting hibernated and the RAM data being persisted. Stopping, on the other hand, results in the instance getting shut down and the RAM being cleared. In both cases, data from the EBS root volume and any attached EBS data volumes is persisted, and your private IP address and elastic IP address (if applicable) remain the same. The network layer behavior is similar to that of EC2's Stop-Start workflow.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-11T15:18:17.995022"}}
{"question": "What happens to the memory state of my instance when I choose to hibernate it upon interruption?", "answer": "If your EBS root volume has sufficient space to write data from memory, hibernating your instance upon interruption will result in the instance being hibernated and the RAM data being persisted. If the EBS root volume does not have enough space, hibernation will fail and the instance will be shut down instead.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-158", "source_tokens": 496, "generated_at": "2026-02-11T15:18:17.995368"}}
{"question": "Which operating systems support hibernation for Spot instances?", "answer": "Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu, and Microsoft Windows operating systems.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-11T15:18:22.712196"}}
{"question": "Why would I use hibernation for my Spot instances?", "answer": "You would use hibernation for your Spot instances when your applications running on them depend on contextual, business, or session data stored in RAM.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-11T15:18:22.712463"}}
{"question": "How does hibernation for Spot instances compare to not using hibernation?", "answer": "With hibernation, Spot instances can pause and resume around any interruptions, allowing your workloads to pick up from exactly where they left off. There is no additional charge for hibernating your instances beyond EBS storage costs and any other EC2 resources you may be using. However, you will not be able to resume a hibernated instance directly.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-159", "source_tokens": 496, "generated_at": "2026-02-11T15:18:22.712865"}}
{"question": "What is the cost for making Spot Fleet requests?", "answer": "There is no additional charge for Spot Fleet requests.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-11T15:18:26.859274"}}
{"question": "Why can't I always fulfill a Spot Fleet request if I exceed my regional Spot request limit?", "answer": "If a Spot Fleet request exceeds the regional Spot request limit, individual Spot instance requests may fail with a 'Spot request limit exceeded' error. The Spot Fleet request's history will show any Spot request limit errors.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-11T15:18:26.859638"}}
{"question": "What is the difference between a Spot Fleet and a single Spot Instance request?", "answer": "A Spot Fleet request allows you to place multiple Spot Instance requests simultaneously, while a single Spot Instance request only requests one instance. Spot Fleet requests are subject to the same availability and prices as a single Spot Instance request.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-160", "source_tokens": 501, "generated_at": "2026-02-11T15:18:26.860066"}}
{"question": "Which allocation strategy does capacity-optimized Spot Fleet use in allocating resources?", "answer": "Capacity-optimized Spot Fleet analyzes capacity metrics to provision resources from the most available Spot Instance pools.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-11T15:18:30.645403"}}
{"question": "What are the benefits of using the diversified allocation strategy in Spot Fleet?", "answer": "The diversified allocation strategy provisions resources across multiple Spot Instance pools, maintaining target capacity and increasing application availability as Spot capacity fluctuates. It also helps reduce long-term fleet operating costs.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-11T15:18:30.645684"}}
{"question": "How does the lowestPrice allocation strategy in Spot Fleet differ from the capacity-optimized strategy?", "answer": "The lowestPrice allocation strategy provisions resources in instance pools that provide the lowest price per unit of capacity, while the capacity-optimized strategy analyzes capacity metrics to provision resources from the most available pools.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-161", "source_tokens": 459, "generated_at": "2026-02-11T15:18:30.646041"}}
{"question": "What happens when a Spot Instance in a Spot Fleet request is no longer running in the lowest priced or capacity-optimized pool?", "answer": "If a Spot Instance in a Spot Fleet request is no longer running in the lowest priced or capacity-optimized pool, and you terminate it, Spot Fleet will replenish it with a new Spot Instance from the new lowest priced or capacity-optimized pool based on your allocation strategy.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-11T15:18:35.722529"}}
{"question": "How does Spot Fleet handle termination and hibernation interruptions?", "answer": "Spot Fleet supports stop-start and hibernate-resume behaviors with the 'maintain' fleet option enabled.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-11T15:18:35.722792"}}
{"question": "What is the difference between the way Spot Fleet and Elastic MapReduce handle fleet management?", "answer": "Spot Fleet allows you to use its features like target tracking, health checks, CloudWatch metrics, and attach instances to Elastic Load Balancers with your Auto Scaling groups. Elastic MapReduce has a feature named 'Instance fleets' which provides capabilities similar to Spot Fleet.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-162", "source_tokens": 214, "generated_at": "2026-02-11T15:18:35.722966"}}
{"question": "What is the IP address for the NTP service?", "answer": "169.254.169.123", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-11T15:18:39.864959"}}
{"question": "Why is it beneficial to use Amazon Time Sync Service?", "answer": "It provides a consistent and accurate time reference that can be securely accessed from an instance without requiring VPC configuration changes and updates. It is built on Amazonâ€™s proven network infrastructure and uses redundant reference time sources to ensure high accuracy and availability.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-11T15:18:39.865225"}}
{"question": "Is there a difference in data transfer charges when transferring data between instances in the same Availability Zone versus different Availability Zones using public IP addresses?", "answer": "No, you will only be charged once for Regional Data Transfer even if you are using public IP addresses.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-163", "source_tokens": 511, "generated_at": "2026-02-11T15:18:39.865643"}}
{"question": "What network performance can I expect when launching Cluster Compute Instances in a cluster placement group?", "answer": "The network performance for a Cluster Compute Instance in a cluster placement group depends on the instance type and its networking performance specification. Inter-instance traffic within the same region can utilize 5 Gbps for single-flow and up to 25 Gbps for multiflow traffic. When launched in a placement group, select EC2 instances can utilize up to 10 Gbps for single-flow traffic.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-11T15:18:47.000022"}}
{"question": "How do Cluster Compute Instances and Cluster GPU Instances differ in terms of performance and usage?", "answer": "Cluster Compute Instances provide high compute resources and high performance networking for HPC applications and network-bound applications. They are engineered to provide high performance networking and are suitable for applications that require low-latency, high bandwidth network performance for tightly coupled node-to-node communication. Cluster GPU Instances, on the other hand, provide general-purpose GPUs with proportionally high CPU and increased network performance for applications that can benefit from highly parallelized processing accelerated by GPUs using the CUDA and OpenCL programming models. They are designed for HPC workloads and offer an additional option to further customize high performance clusters in the cloud.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-11T15:18:47.000275"}}
{"question": "What types of applications can benefit from using Cluster GPU Instances?", "answer": "Cluster GPU Instances are suitable for applications that can benefit from the parallel computing power of GPUs for highly parallelized processing. Common applications include modeling and simulation, rendering and media processing.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-164", "source_tokens": 495, "generated_at": "2026-02-11T15:18:47.000618"}}
{"question": "What is the difference between Cluster Compute and Cluster GPU Instances and other Amazon EC2 instance types in terms of virtualization and launching?", "answer": "Cluster Compute and Cluster GPU Instances use Hardware Virtual Machine (HVM) based virtualization and can only be launched using Amazon Machine Images (AMIs) based on HVM virtualization. In contrast, Paravirtual Machine (PVM) based AMIs cannot be used with Cluster Compute or Cluster GPU Instances. Also, to fully benefit from the available low latency, full bisection bandwidth between instances, Cluster Compute and Cluster GPU Instances must be launched into a cluster placement group through the Amazon EC2 API or AWS Management Console.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-11T15:18:54.609045"}}
{"question": "What is a cluster placement group and how does it help in launching Cluster Compute and Cluster GPU Instances?", "answer": "A cluster placement group is a logical entity that enables creating a cluster of instances by launching instances as part of a group. This grouping provides low latency connectivity between instances in the group, making it necessary for launching Cluster Compute and Cluster GPU Instances to fully benefit from the available low latency, full bisection bandwidth between instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-11T15:18:54.609304"}}
{"question": "What limitations are there for the number of Cluster Compute or Cluster GPU Instances I can use and the size of clusters I can create?", "answer": "There is no specific limit for the number of Cluster Compute Instances. However, for Cluster GPU Instances, you can launch a maximum of 2 Instances on your own. For larger clusters, you'll need to complete the required process through the Amazon EC2 API or AWS Management Console.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-165", "source_tokens": 506, "generated_at": "2026-02-11T15:18:54.609448"}}
{"question": "What is the recommendation for launching instances to optimize receiving the full number of instances in a cluster placement group?", "answer": "The recommendation is to launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, launch multiple placement groups and combine them to create a larger cluster.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-11T15:18:58.950070"}}
{"question": "Why should different cluster instance types be launched into separate placement groups?", "answer": "At this time, Amazon EC2 only supports homogenous placement groups, meaning all instances in a group must be the same type.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-11T15:18:58.950377"}}
{"question": "What happens if an instance in a cluster placement group is stopped and then started again?", "answer": "The instance will be started as part of the cluster placement group it was in when it stopped. If capacity is not available for it to start within its cluster placement group, the start will fail.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-166", "source_tokens": 236, "generated_at": "2026-02-11T15:18:58.950787"}}
{"question": "Which CPU options are available on EC2 instances for Arm architecture?", "answer": "AWS Graviton/Graviton2 processors are the CPU options available on EC2 instances for Arm architecture.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-11T15:19:03.435236"}}
{"question": "What are the benefits of using EC2's non-intrusive maintenance technologies?", "answer": "EC2's non-intrusive maintenance technologies, such as live update and live migration, help improve application uptime and reduce operational effort by deploying software to servers quickly with minimal impact on customer instances and moving running instances from one server to another for hardware maintenance or optimization, without requiring instances to be stopped or rebooted.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-11T15:19:03.435516"}}
{"question": "How does the CPU performance and cost compare between Intel and AMD EC2 instances?", "answer": "The text does not provide enough information to make a comparison between the CPU performance and cost of Intel and AMD EC2 instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-167", "source_tokens": 389, "generated_at": "2026-02-11T15:19:03.435925"}}
{"question": "What is an 'EC2 Compute Unit' and why does Amazon EC2 provide it?", "answer": "An 'EC2 Compute Unit' is a measure of the processing power provided by an Amazon EC2 instance. It was introduced to provide a consistent way to measure and compare the processing power of different instances, regardless of the underlying hardware. This is important because Amazon EC2 is built on commodity hardware, which may change over time.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-11T15:19:09.167831"}}
{"question": "Can you explain the differences between General Purpose and Compute Optimized EC2 instances?", "answer": "Yes, General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance. In contrast, Compute Optimized instances have proportionally more CPU resources than memory and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-11T15:19:09.168092"}}
{"question": "What are the benefits of using Memory Optimized Instances for database applications?", "answer": "Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications. This makes them well-suited for these types of workloads where having a large amount of memory available is important for performance.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-168", "source_tokens": 401, "generated_at": "2026-02-11T15:19:09.168276"}}
{"question": "What measures does Amazon EC2 use to ensure consistent performance of instance types over time?", "answer": "Amazon EC2 conducts performance benchmarking at regular intervals of Linux and Windows compute performance on EC2 instance types to ensure consistent performance over time.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-11T15:19:13.824721"}}
{"question": "In what way does Amazon EC2 make it easy to compare CPU capacity between different instance types?", "answer": "Amazon EC2 expresses the amount of CPU allocated to a particular instance in terms of Amazon EC2 Compute Units (ECUs), which provides a consistent and predictable measure of compute capacity.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-11T15:19:13.824980"}}
{"question": "How does the performance management of Amazon EC2 Compute Units compare to other methods for measuring and comparing CPU capacity in cloud computing?", "answer": "Amazon EC2 uses several benchmarks and tests to manage the consistency and predictability of the performance from an EC2 Compute Unit. This method allows for easy comparison between different instance types in terms of compute capacity.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-169", "source_tokens": 249, "generated_at": "2026-02-11T15:19:13.825378"}}
{"question": "What is the compute power provided by a Micro instance?", "answer": "Micro instances provide a small amount of consistent CPU resources and allow bursting up to 2 ECUs for short periods of time.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-11T15:19:18.253723"}}
{"question": "How does a Micro instance's compute power compare to that of a Standard Small instance?", "answer": "At steady state, Micro instances receive less compute resources than Small instances. However, Micro instances can burst up to 2 ECUs, while Small instances can only burst up to 1 ECU.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-11T15:19:18.254130"}}
{"question": "Which CloudWatch metric can tell me if my application needs more CPU resources than a Micro instance provides?", "answer": "CloudWatch reporting 100% CPU utilization indicates that the instance is bursting so much that it exceeds its available CPU resources, which may be a signal to consider scaling up to a larger instance type or horizontally.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-170", "source_tokens": 356, "generated_at": "2026-02-11T15:19:18.254318"}}
{"question": "How many EBS volumes can be attached to instances running on the Nitro Hypervisor?", "answer": "The text passage does not provide information on the number of EBS volumes that can be attached to instances running on the Nitro Hypervisor.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-11T15:19:24.164165"}}
{"question": "What is the difference between the Nitro Hypervisor and the Xen-based hypervisor in terms of customer benefits?", "answer": "The Nitro Hypervisor provides consistent performance and increased compute and memory resources for EC2 virtualized instances by removing host system software components, allowing AWS to offer larger instance sizes. On the other hand, Xen-based hypervisor continues to be a core component of EC2 instances for certain requirements, and AWS continues to invest in it as a part of its global cloud infrastructure expansion.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-11T15:19:24.164416"}}
{"question": "What role does the Nitro Hypervisor play in providing networking and storage resources for EC2 instances?", "answer": "The Nitro Hypervisor allows AWS to implement VPC networking and EBS storage resources by dedicated hardware components, Nitro Cards, which are part of all current generation EC2 instance families. This enables the Nitro Hypervisor to be very small and uninvolved in data processing tasks for networking and storage.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-171", "source_tokens": 511, "generated_at": "2026-02-11T15:19:24.164876"}}
{"question": "What number of PCI devices can the Nitro Hypervisor support for EBS volumes and VPC ENIs?", "answer": "The Nitro Hypervisor supports a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-11T15:19:28.992183"}}
{"question": "How does the Nitro Hypervisor differ from the Xen Hypervisor in terms of instance boot methods?", "answer": "Instances running under the Nitro Hypervisor boot from EBS volumes using an NVMe interface, while instances running under the Xen Hypervisor boot from an emulated IDE hard drive and switch to the Xen paravirtualized block device drivers.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-11T15:19:28.992414"}}
{"question": "Can I use the same process to identify EC2 instances running under both the Nitro and Xen Hypervisors?", "answer": "Yes, operating systems will detect they are running under a hypervisor when they run under the Nitro Hypervisor, so the process used to identify EC2 instances running under the Xen Hypervisor can also be used to identify EC2 instances running under both hypervisors.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-172", "source_tokens": 466, "generated_at": "2026-02-11T15:19:28.992557"}}
{"question": "How does the Nitro Hypervisor handle EC2 API requests for instance reboot and termination?", "answer": "The Nitro Hypervisor signals the operating system to shut down cleanly using industry standard ACPI methods. For Linux instances, acpid should be installed and functioning correctly to ensure timely response.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-11T15:19:35.030327"}}
{"question": "How does accessing EBS volumes via NVMe interfaces differ from using Xen paravirtual block drivers?", "answer": "When using NVMe interfaces, operating system NVMe device names will be different than those used in EBS volume attachment requests and block device mapping entries. NVMe devices are enumerated by the operating system and are not persistent mappings to volumes. Instead, file system UUIDs or labels should be used for mounting. The EBS volume ID is available via the controller serial number and the device name provided in EC2 API requests is supplied by an NVMe vendor extension.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-11T15:19:35.030595"}}
{"question": "What is the main difference between accessing EBS volumes via NVMe interfaces and using Xen paravirtual block drivers?", "answer": "The main difference lies in the device naming and the way volume identities are mapped. With NVMe interfaces, the operating system enumerates the devices and provides different device names than those used in EBS volume attachment requests. The EBS volume ID is available via the controller serial number and the device name provided in EC2 API requests is supplied by an NVMe vendor extension.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-173", "source_tokens": 429, "generated_at": "2026-02-11T15:19:35.030775"}}
{"question": "What happens if an I/O operation does not complete within the default time in Linux NVMe driver?", "answer": "The Linux NVMe driver will attempt to cancel the I/O, retry it, or return an error to the component that issued the I/O if it does not complete within an implementation-specific amount of time, usually tens of seconds.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-11T15:19:42.059555"}}
{"question": "How does the timeout behavior differ between the NVMe and Xen PV block device interfaces?", "answer": "The NVMe interface does not time out I/O, which can result in processes that cannot be terminated if they are waiting for I/O. In contrast, the Xen PV block device interface times out I/O. The Linux NVMe driver behavior can be modified by specifying a higher value for the nvme.io.timeout kernel module parameter, and the Xen PV block device interface timeout can be adjusted by modifying the specific implementation.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-11T15:19:42.059854"}}
{"question": "How does the data transfer capability and I/O request handling of NVMe compare to Xen PV block device interface?", "answer": "The NVMe interface can transfer much larger amounts of data per I/O and may be able to support more outstanding I/O requests compared to the Xen PV block device interface. This can cause higher I/O latency in throughput optimized volumes and may result in I/O timeouts in NVMe drivers if the I/O timeout is not adjusted. The I/O timeout can be adjusted in the Linux driver by specifying a larger value for the nvme_core.io_timeout kernel module parameter.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-174", "source_tokens": 303, "generated_at": "2026-02-11T15:19:42.060237"}}
{"question": "What are the two ways Optimize CPUs can help save costs on EC2 instances?", "answer": "Optimize CPUs can help save costs on EC2 instances by allowing you to specify a custom number of vCPUs when launching new instances and by disabling Intel Hyper-Threading Technology for certain workloads.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-11T15:19:46.335511"}}
{"question": "Why would disabling hyper-threading on EC2 instances be beneficial?", "answer": "Disabling hyper-threading on EC2 instances can be beneficial for workloads that perform well with single-threaded CPUs, such as certain HPC applications.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-11T15:19:46.335911"}}
{"question": "What is the pricing structure for CPU optimized EC2 instances compared to full-sized instances?", "answer": "CPU optimized EC2 instances will be priced the same as equivalent full-sized instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-175", "source_tokens": 399, "generated_at": "2026-02-11T15:19:46.336147"}}
{"question": "What is the billing model for Amazon EC2 running IBM?", "answer": "You pay only for what you use with no minimum fee. Pricing is per instance-hour consumed for each instance type. Partial instance-hours are billed as full hours.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-11T15:19:50.614669"}}
{"question": "Why is data transfer for Amazon EC2 running IBM billed separately?", "answer": "Data transfer for Amazon EC2 running IBM is billed separately due to it being a different AWS service within the same region and data transferred between different regions being charged as Internet Data Transfer on both sides.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-11T15:19:50.614882"}}
{"question": "How does licensing work for software in the Windows environment on Amazon EC2?", "answer": "Software license terms vary from vendor to vendor. It is recommended to check with the software vendor to determine if existing licenses are authorized for use in Amazon EC2.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-176", "source_tokens": 385, "generated_at": "2026-02-11T15:19:50.615020"}}
{"question": "What operating systems are available for x86-based EC2 Mac instances?", "answer": "Customers can choose from macOS Mojave (10.14), macOS Catalina (10.15), macOS Big Sur (11), and macOS Monterey (12) as Amazon Machine Images (AMIs) for x86-based EC2 Mac instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-11T15:19:55.823579"}}
{"question": "What benefits can developers see when using EC2 Mac instances for building applications?", "answer": "Developers can experience up to 75% better build performance, up to 80% lower build failure rates, and up to 5x the number of parallel builds compared to running macOS on-premises.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-11T15:19:55.823810"}}
{"question": "What's the difference between x86-based EC2 Mac instances and M1 Mac instances?", "answer": "x86-based EC2 Mac instances are built on Apple Mac mini computers featuring Intel Core i7 processors, while M1 Mac instances are built on Apple M1 Mac mini computers.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-177", "source_tokens": 463, "generated_at": "2026-02-11T15:19:55.823948"}}
{"question": "Which regions support EC2 M1 Ultra Mac instances?", "answer": "EC2 M1 Ultra Mac instances are available in 2 regions: US East (N. Virginia) and US West (Oregon)", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-11T15:19:59.928683"}}
{"question": "How does the performance of EC2 M2 Mac instances compare to EC2 M1 Mac instances?", "answer": "EC2 M2 Mac instances are up to 10% more performant than EC2 M1 Mac instances for iOS and macOS application build workloads", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-11T15:19:59.928933"}}
{"question": "What operating systems does the latest EC2 Mac instance type support?", "answer": "EC2 M1 Ultra Mac instances support macOS Ventura (13) or later as Amazon Machine Images (AMIs)", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-178", "source_tokens": 450, "generated_at": "2026-02-11T15:19:59.929328"}}
{"question": "Which pricing models are available for EC2 M2 Pro Mac instances?", "answer": "EC2 M2 Pro Mac instances are available as Dedicated Hosts through both On-Demand and Savings Plans pricing models.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-11T15:20:03.782363"}}
{"question": "How is a Dedicated Host for EC2 M2 Pro Mac instances released?", "answer": "After the allocation period of 24 hours for an EC2 M2 Pro Mac instance Dedicated Host has exceeded, first stop or terminate the instance running on the host, then release the host using the aws ec2 release-hosts CLI command or the AWS Management Console.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-11T15:20:03.782600"}}
{"question": "Can different AWS accounts share an EC2 M2 Pro Mac Dedicated Host?", "answer": "No, EC2 M2 Pro Mac Dedicated Hosts cannot be shared between AWS accounts.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-179", "source_tokens": 470, "generated_at": "2026-02-11T15:20:03.782783"}}
{"question": "How many EC2 Mac instances can be run on one EC2 Mac Dedicated Host?", "answer": "One EC2 Mac instance can be run on each EC2 Mac Dedicated Host.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-11T15:20:08.259164"}}
{"question": "Can the EFI NVRAM variables be updated and persist on an EC2 Mac instance?", "answer": "Yes, certain EFI NVRAM variables can be updated on an EC2 Mac instance to persist across reboots, but they will be reset upon instance stop or termination.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-11T15:20:08.259441"}}
{"question": "What is the difference between using FileVault and Amazon EBS encryption for boot volumes on EC2 Mac instances?", "answer": "FileVault requires a login before booting into macOS and remote access cannot be enabled when it's enabled, causing data loss upon reboot, stop, or terminate. Amazon EBS encryption, on the other hand, encrypts both the boot and data EBS volumes on EC2 Mac instances, ensuring data security without the need for login or remote access restrictions.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-180", "source_tokens": 417, "generated_at": "2026-02-11T15:20:08.259597"}}
{"question": "Which versions of macOS can you run on x86-based EC2 Mac instances?", "answer": "You can run macOS High Sierra, Sierra, or older versions on x86-based EC2 Mac instances using a type-2 virtualization layer.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-11T15:20:12.690419"}}
{"question": "Why can't we run older versions of macOS on M1 Mac instances in EC2?", "answer": "M1 Mac instances use Apple Silicon, and Apple only supports newer versions of macOS on their hardware.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-11T15:20:12.690698"}}
{"question": "How does installing Xcode on an EC2 Mac instance differ from Linux instances?", "answer": "Instead of using cloud-init, EC2 Mac instances use ec2-macos-init and pass the user data through the EC2 Launch Wizard as plain-text, a file, or base64-encoded-text.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-181", "source_tokens": 505, "generated_at": "2026-02-11T15:20:12.691098"}}
{"question": "What software comes pre-installed in AWS's macOS AMIs, specifically the Xcode IDE?", "answer": "AWS's macOS AMIs do not come with Xcode IDE pre-installed. Users can install Xcode from the App Store or Apple Developer website once the macOS system is launched.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-11T15:20:17.902670"}}
{"question": "How frequently are new macOS AMIs released by AWS?", "answer": "AWS targets releasing official macOS AMIs 30-60 days after a macOS minor version update and 90-120 days after a macOS major version update.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-11T15:20:17.902915"}}
{"question": "Which agents and packages are included in the base macOS image for EC2 instances, and how can you update them?", "answer": "The base macOS image for EC2 instances includes the ENA Driver for macOS, AWS CLI, EC2-macos-init, Amazon CloudWatch Agent, Chrony, Homebrew, and AWS Systems Manager Agent. Users can update agents and packages via Homebrew, which is included in the base image.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-182", "source_tokens": 446, "generated_at": "2026-02-11T15:20:17.903060"}}
{"question": "How many EBS volumes are supported by EC2 Mac instances running on x86 architecture?", "answer": "x86-based EC2 Mac instances support up to 16 EBS volumes.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-11T15:20:21.730075"}}
{"question": "What is the role of AWS Systems Manager Session Manager in connecting to EC2 Mac instances?", "answer": "AWS Systems Manager Session Manager allows secure and auditable instance management, and is used to connect to EC2 Mac instances without the need to maintain bastion hosts or manage SSH keys.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-11T15:20:21.730323"}}
{"question": "How does the support for Elastic Network Interfaces (ENIs) compare between x86-based and M1 Mac instances?", "answer": "x86-based EC2 Mac instances support up to 8 ENI attachments, while M1 Mac instances support up to 8 ENI attachments.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-183", "source_tokens": 501, "generated_at": "2026-02-11T15:20:21.730718"}}
{"question": "What protocol does Amazon FSx use for EC2 Mac instances?", "answer": "Amazon FSx uses the SMB protocol for EC2 Mac instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-11T15:20:25.029063"}}
{"question": "How does EC2 Mac instances interaction with Amazon FSx work?", "answer": "EC2 Mac instances interact with Amazon FSx using the SMB protocol and need to be enrolled in a supported directory service.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-11T15:20:25.029320"}}
{"question": "What is the difference in protocols used for Amazon FSx and Amazon Elastic File System (EFS) with EC2 Mac instances?", "answer": "Amazon FSx uses the SMB protocol and Amazon Elastic File System (EFS) uses the NFSv4 protocol for EC2 Mac instances.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-184", "source_tokens": 139, "generated_at": "2026-02-11T15:20:25.029490"}}
{"question": "Which instance types will receive Nitro System support in 2022 and 2023?", "answer": "Nitro system support has been enabled for Amazon EC2 C1, H1, M1, T1, D2, M2, T2, C3, I3, M3, R3, C4, M4, and R4 instances.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-11T15:20:30.104372"}}
{"question": "How does Nitro System support impact the usage of older generation EC2 instances?", "answer": "Nitro System support allows older generation EC2 instances to continue running their workloads and applications on the instance families they were built on, extending their length of service beyond the typical lifetime of the underlying hardware.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-11T15:20:30.104597"}}
{"question": "How does Nitro System support for older generation instances compare to support for newer instances?", "answer": "Both older and newer generation instances will receive Nitro System support, allowing them to continue running their workloads and applications on their respective instance families. The key difference is the underlying hardware and the maintenance schedule.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-185", "source_tokens": 450, "generated_at": "2026-02-11T15:20:30.104979"}}
{"question": "What happens to the instance specifications when running on Nitro hardware after migration?", "answer": "There will be no change to instance specifications.", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-11T15:20:33.640184"}}
{"question": "Why doesn't a migration to AWS Nitro System require rebuilding or recertifying workloads?", "answer": "Customers donâ€™t need to rebuild or recertify workloads because the features and AMIs supported on previous generation instances will be maintained during migration.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-11T15:20:33.640520"}}
{"question": "How does the pricing and billing change when migrating instances to AWS Nitro System?", "answer": "There will be no change to billing and pricing. The same pricing models (On-Demand, 1yr/3yr Reserved Instance, Savings Plan, Spot) will continue to be supported.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-186", "source_tokens": 333, "generated_at": "2026-02-11T15:20:33.640954"}}
{"question": "What resource does the text passage discuss for learning how to build with Amazon EC2?", "answer": "Amazon EC2", "question_type": "factual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-11T15:20:36.946670"}}
{"question": "Why is the AWS Management Console mentioned as a starting point for building with Amazon EC2?", "answer": "The AWS Management Console provides instant access to Amazon EC2, allowing users to begin building and managing their EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-11T15:20:36.947025"}}
{"question": "Is there any mention of a difference between building with Amazon EC2 and another cloud service in the text passage?", "answer": "No, the text passage does not provide any comparison or contrast between Amazon EC2 and other cloud services.", "question_type": "comparison", "metadata": {"service": "EC2", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ec2-faq-187", "source_tokens": 46, "generated_at": "2026-02-11T15:20:36.947212"}}
{"question": "What is Amazon ECR and how does it simplify container image deployment?", "answer": "Amazon ECR is a fully managed container registry that makes it easy for developers to share and deploy container images and artifacts. It is integrated with Amazon ECS, Amazon EKS, AWS Lambda, and the Docker CLI, simplifying the development to production workflow. Amazon ECR eliminates the need to operate and scale the infrastructure required to power a container registry, and uses Amazon S3 for storage and HTTPS for image transfers.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T15:20:43.272081"}}
{"question": "What security features does Amazon ECR offer?", "answer": "Amazon ECR offers several security features, including resource-level control of each repository using AWS IAM, transfer of container images over HTTPS, and automatic encryption of images at rest. You can also configure policies to manage permissions for each repository and restrict access to IAM users, roles, or other AWS accounts.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T15:20:43.272352"}}
{"question": "How does Amazon ECR compare to self-hosted container registries?", "answer": "Amazon ECR eliminates the need to operate and scale the infrastructure required for a container registry, as it uses Amazon S3 for storage and integrates with AWS services like Amazon ECS and Amazon EKS. Self-hosted container registries, on the other hand, require you to manage the underlying infrastructure, which can be time-consuming and complex.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T15:20:43.272526"}}
{"question": "What is required for someone to pull images from a public Amazon ECR repository?", "answer": "No AWS account or IAM credentials are needed to pull images from a public Amazon ECR repository.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-11T15:20:47.182322"}}
{"question": "How does authentication work for private Amazon ECR repositories?", "answer": "Amazon IAM-based authentication using AWS account credentials is required for pulling images from private Amazon ECR repositories.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-11T15:20:47.182643"}}
{"question": "What are the advantages of using a private Amazon ECR repository compared to a public one?", "answer": "Private Amazon ECR repositories offer advanced security features, including IAM-based authentication and no public content search, while public repositories allow anyone to search and download images.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-1", "source_tokens": 511, "generated_at": "2026-02-11T15:20:47.182844"}}
{"question": "What is the format of an Amazon ECR image URL with a custom alias?", "answer": "public.ecr.aws/<alias>/<image>:<tag>", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T15:20:51.811844"}}
{"question": "How does Amazon ECR help in managing and deploying Docker container images?", "answer": "Amazon ECR allows you to create deployment pipelines that build images, push them to Amazon ECR in one Region, and automatically replicate them to other Regions and accounts for deployment to multi-Region clusters. It also integrates with Amazon ECS, allowing you to easily store, run, and manage container images for applications running on Amazon ECS, and supports AWS Elastic Beanstalk.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T15:20:51.812182"}}
{"question": "Which container engine versions and API specifications does Amazon ECR support?", "answer": "Amazon ECR supports Docker Engine 1.7.0 and up and the Docker Registry V2 API specification.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-2", "source_tokens": 494, "generated_at": "2026-02-11T15:20:51.812686"}}
{"question": "Which CI/CD solutions does Amazon ECR integrate with to provide image hosting capability?", "answer": "Amazon ECR integrates with a number of popular CI/CD solutions for image hosting. Refer to the Amazon ECR Partners page for more information.", "question_type": "factual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T15:20:56.233860"}}
{"question": "How does Amazon ECR support access control for container images?", "answer": "Amazon ECR supports access control using AWS Identity and Access Management (IAM), which allows for identity federation for delegated access to the AWS Management Console or APIs.", "question_type": "conceptual", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T15:20:56.234202"}}
{"question": "What are the differences between pushing and pulling OCI images to/from Amazon ECR compared to Docker images?", "answer": "Amazon ECR supports pushing and pulling OCI images and artifacts, and can translate between Docker Image Manifest V2, Schema 2 images and OCI images on pull.", "question_type": "comparison", "metadata": {"service": "ECR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecr-faq-3", "source_tokens": 490, "generated_at": "2026-02-11T15:20:56.234716"}}
{"question": "What is Amazon ECS and how does it simplify container deployment and management on AWS?", "answer": "Amazon ECS is a fully managed container orchestration service on AWS that simplifies building, deploying, and managing containerized applications at any scale. It eliminates the need to provision or scale servers, choose server types, or optimize cluster packing. Amazon ECS provides tooling and built-in support, such as Amazon CloudWatch Container Insights and Amazon ECS Service Connect, to collect metrics, manage logs, simplify service discovery, and provide connectivity and traffic observability.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T15:21:03.475569"}}
{"question": "What is the difference between launching a container on Amazon Elastic Compute Cloud (EC2) and AWS Fargate in Amazon ECS?", "answer": "With Amazon ECS, you can launch containers on Amazon Elastic Compute Cloud (EC2) instances or on a serverless compute plane with AWS Fargate. The main difference lies in the management of infrastructure. With EC2, you are responsible for managing the underlying infrastructure, such as provisioning and scaling servers. With AWS Fargate, Amazon ECS manages the infrastructure, and you only need to specify the container requirements.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T15:21:03.475922"}}
{"question": "What are some features provided by Amazon ECS for managing and optimizing containerized applications?", "answer": "Amazon ECS provides features such as service discovery, connectivity, and traffic observability with Amazon ECS Service Connect. It also collects, aggregates, and summarizes metrics and logs using Amazon CloudWatch Container Insights. Users can specify CPU and memory requirements, networking and IAM policies, and launch type and data volumes for their containers.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T15:21:03.476437"}}
{"question": "What does Amazon ECS allow you to do without having to manage your own cluster infrastructure?", "answer": "Amazon ECS makes it easy to use containers to deploy and manage long-running applications, services, and batch processes without needing to install, operate, and scale your own cluster management infrastructure.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-11T15:21:08.561700"}}
{"question": "How does Amazon ECS help in reducing the time it takes to build, deploy, or migrate containerized applications?", "answer": "When used with AWS Fargate, Amazon ECS allows you to deploy applications without needing to provision, manage, or scale compute infrastructure, reducing the time it takes for you to build, deploy, or migrate your containerized applications successfully.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-11T15:21:08.562041"}}
{"question": "What are some of the features that Amazon ECS is integrated with?", "answer": "Amazon ECS is integrated with familiar features like ELB, Amazon Virtual Private Cloud (VPC), IAM, Application AutoScaling, Amazon CloudWatch, and Amazon Elastic File System (EFS), meaning that you donâ€™t need to build or maintain generalized abstractions for these services.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-1", "source_tokens": 194, "generated_at": "2026-02-11T15:21:08.562275"}}
{"question": "What are the two serverless compute options provided by AWS for containerized applications?", "answer": "Amazon ECS with AWS Fargate and AWS Lambda are the two serverless compute options provided by AWS for containerized applications.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:21:13.056726"}}
{"question": "How does Amazon ECS with AWS Fargate simplify container orchestration?", "answer": "Amazon ECS with AWS Fargate simplifies container orchestration by providing serverless functionality, allowing users to leverage AWS's operational excellence for scaling, maintaining availability, and securing containerized workloads.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:21:13.056994"}}
{"question": "What's the difference between Amazon ECS with AWS Fargate and Amazon ECS on Amazon EC2 in terms of control over application characteristics?", "answer": "Amazon ECS with AWS Fargate provides less control over the characteristics of how your applications run, as AWS manages the underlying infrastructure. Amazon ECS on Amazon EC2, on the other hand, allows users to have more control over the infrastructure and the operating properties of their containers.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:21:13.057405"}}
{"question": "What compute choices does Amazon EDA offer for managing resources?", "answer": "Amazon EDA offers compute choices including Amazon ECS with AWS Fargate and AWS Lambda.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-11T15:21:16.900445"}}
{"question": "How does AWS serverless compute provide advantages over traditional compute methods?", "answer": "AWS serverless compute provides advantages such as scale, agility, and cost savings.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-11T15:21:16.900790"}}
{"question": "What are the main differences between Amazon ECS with AWS Fargate and AWS Lambda?", "answer": "Amazon ECS with AWS Fargate and AWS Lambda are different serverless compute choices offered by AWS. AWS Fargate allows you to run containers without having to manage the underlying infrastructure, while AWS Lambda lets you run code without provisioning or managing servers.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-3", "source_tokens": 72, "generated_at": "2026-02-11T15:21:16.901045"}}
{"question": "What is the charging model for Amazon ECS on AWS Outposts?", "answer": "The charging model for Amazon ECS on AWS Outposts is the same as Amazon EC2 Launch Type, which means there is no additional charge for Amazon ECS and you pay only for the AWS resources you use.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:21:22.507491"}}
{"question": "How does the pricing model for AWS Fargate differ from Amazon ECS on AWS Outposts?", "answer": "The main difference is that with AWS Fargate, you pay for the amount of vCPU and memory resources that your containerized application requests, while with Amazon ECS on AWS Outposts, there is no additional charge for Amazon ECS and you pay only for the AWS resources you use.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:21:22.507832"}}
{"question": "Why would you use Amazon ECS instead of AWS Lambda for running and managing distributed applications?", "answer": "Amazon ECS is a container orchestration service that allows you to run and manage distributed applications that run in containers, while AWS Lambda is an event-driven task compute service that runs your code in response to events. You might choose Amazon ECS if you need more control over the infrastructure and the ability to manage and scale multiple containers in a distributed application.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:21:22.508233"}}
{"question": "What information does Amazon ECS use to make placement decisions for tasks?", "answer": "The tasks in Amazon ECS contain all the information Amazon ECS needs to make the placement decision.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-11T15:21:26.555133"}}
{"question": "How does the Amazon ECS service scheduler help manage long-running applications?", "answer": "The Amazon ECS service scheduler helps maintain application availability and allows scaling up or down to meet capacity requirements while distributing traffic across containers with ELB and automatically recovering unhealthy containers.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-11T15:21:26.555474"}}
{"question": "How does scaling an Amazon ECS service with the service scheduler differ from launching a single container?", "answer": "Scaling an Amazon ECS service involves changing the number of containers to run and updating the application definition, while launching a single container only includes the container definition.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-5", "source_tokens": 301, "generated_at": "2026-02-11T15:21:26.555971"}}
{"question": "What CloudWatch metrics does Amazon ECS use for Application Auto Scaling based on observed service utilization?", "answer": "Amazon ECS uses the CloudWatch metrics ECSServiceAverageCPUUtilization and ECSServiceAverageMemoryUtilization for Application Auto Scaling based on observed service utilization.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-11T15:21:31.772406"}}
{"question": "Why might using a custom metric be more suitable for scaling an Amazon ECS service than just using average CPU and memory usage?", "answer": "Using a custom metric for scaling an Amazon ECS service might be more suitable than just using average CPU and memory usage when the service's average CPU and memory usage alone are not reliable indicators of when and to what degree to execute a scaling action.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-11T15:21:31.772754"}}
{"question": "How does using a custom CloudWatch metric for scaling Amazon ECS tasks compare to scaling based on average CPU and memory utilization?", "answer": "Scaling an Amazon ECS service based on a custom CloudWatch metric allows for more specific and accurate scaling actions compared to scaling based on average CPU and memory utilization, as the custom metric may track other application aspects that better indicate the need for scaling.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-6", "source_tokens": 267, "generated_at": "2026-02-11T15:21:31.772973"}}
{"question": "What does AWS Fargate provide in terms of compute engine for Amazon ECS?", "answer": "AWS Fargate is a serverless, pay-as-you-go compute engine that removes the burden of server provisioning, cluster management, and orchestration. It automatically scales, load balances, and manages scheduling of containers.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T15:21:36.576619"}}
{"question": "How does Amazon ECS handle compute infrastructure for applications requiring Amazon EC2 capacity?", "answer": "Amazon ECS provides Auto Scaling Group Capacity Providers which automatically scale Amazon EC2 instances in response to the capacity requirement of your applications.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T15:21:36.576960"}}
{"question": "How does running applications on AWS Fargate differ from running them on Amazon EC2 in terms of infrastructure management?", "answer": "With AWS Fargate, Amazon ECS manages the compute infrastructure and you are billed based on usage, while with Amazon EC2, you own the instances and have complete control over the infrastructure management.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T15:21:36.577174"}}
{"question": "What role do capacity providers play in Amazon ECS?", "answer": "Capacity providers are the interface through which users can define the capacity needs for their applications in Amazon ECS. They allow users to manage the scaling of capacity and define flexible rules for how applications run on different types of compute capacity. Capacity Providers work with both Amazon EC2 and AWS Fargate.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T15:21:41.737991"}}
{"question": "How does managing capacity work when using Amazon ECS?", "answer": "When running Amazon ECS tasks and services, you can manage capacity by splitting them across multiple capacity providers. For instance, you can run a service in a predefined split percentage across AWS Fargate and Fargate Spot capacities.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T15:21:41.738333"}}
{"question": "What's the difference between using Amazon ECS with AWS Fargate and Amazon EC2?", "answer": "Amazon ECS with AWS Fargate offers serverless compute and allows users to launch containers without having to manage Amazon EC2 instances. Amazon ECS with Amazon EC2, on the other hand, requires users to manage their own Amazon EC2 instances.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T15:21:41.738836"}}
{"question": "What integration does Amazon ECS have with Elastic Load Balancing that allows traffic distribution?", "answer": "Amazon ECS integrates with Elastic Load Balancing, allowing traffic distribution across containers using Application Load Balancers or Network Load Balancers.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-11T15:21:46.288360"}}
{"question": "How does Amazon ECS handle container connectivity with Elastic Load Balancing?", "answer": "Amazon ECS automatically adds and removes containers from the load balancer based on task definition and specification of a load balancer to use.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-11T15:21:46.288709"}}
{"question": "What are the differences between VPC Mode and Bridge Mode in terms of container networking with Amazon ECS?", "answer": "VPC Mode assigns each running Amazon ECS task a dedicated elastic networking interface, allowing containers full networking features in a VPC, while Bridge Mode creates a Linux bridge that connects all containers running on the host in a local virtual network accessible through the host's default network connection.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-9", "source_tokens": 291, "generated_at": "2026-02-11T15:21:46.289249"}}
{"question": "What is Amazon ECS Service Connect used for in Amazon ECS?", "answer": "Amazon ECS Service Connect is used to simplify service discovery, connectivity, and traffic observability for Amazon ECS. It helps you define logical names for service endpoints and use them in client applications to connect to dependencies. It also sends traffic to healthy endpoints and provides rich traffic telemetry in the Amazon ECS console and Amazon CloudWatch.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-11T15:21:52.976094"}}
{"question": "How does Amazon ECS Service Connect help in building and operating resilient distributed applications?", "answer": "Amazon ECS Service Connect helps in building and operating resilient distributed applications by letting you define logical names for service endpoints and use them in client applications to connect to dependencies. It also monitors and distributes traffic between Amazon ECS tasks without deploying and configuring load balancers, enabling seamless integration of Amazon ECS microservices comprising an application.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-11T15:21:52.976296"}}
{"question": "What is the difference between Amazon ECS Service Connect and AWS Cloud Map in terms of service discovery?", "answer": "Amazon ECS Service Connect and AWS Cloud Map serve different purposes in Amazon ECS. Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability for Amazon ECS and helps you define logical names for service endpoints. AWS Cloud Map, on the other hand, is a cloud resource discovery service that lets you define custom names for your application resources and increases application availability by always discovering the most up-to-date locations of these dynamically changing resources.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-10", "source_tokens": 312, "generated_at": "2026-02-11T15:21:52.976472"}}
{"question": "What metrics can CloudWatch Container Insights collect for Amazon ECS?", "answer": "CloudWatch Container Insights can collect metrics at the cluster, task and service levels for Amazon ECS running on Amazon EC2 and AWS Fargate. It collects metrics for resources such as CPU, memory, disk, and network.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-11T15:21:57.699338"}}
{"question": "How does CloudWatch Container Insights help in monitoring and troubleshooting Amazon ECS?", "answer": "CloudWatch Container Insights enhances monitoring of Amazon ECS by collecting, aggregating, and summarizing metrics and logs from containerized applications and microservices. It provides diagnostic information to help users isolate issues and resolve them quickly.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-11T15:21:57.699687"}}
{"question": "What is the difference between CloudWatch metrics available for containers in bridge network mode and host network mode?", "answer": "Network metrics are available only for containers in bridge network mode and awsvpc network mode. They are not available for containers in host network mode.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-11", "source_tokens": 510, "generated_at": "2026-02-11T15:21:57.700186"}}
{"question": "Which companies have partnered with Amazon ECS?", "answer": "The exact list of companies that have partnered with Amazon ECS can be found on the Amazon ECS Partners page.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-11T15:22:01.267432"}}
{"question": "How does partnering with Amazon ECS benefit a company?", "answer": "Partnering with Amazon ECS allows a company to leverage Amazon's container management technology and expertise, potentially improving their own container deployment and management.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-11T15:22:01.267767"}}
{"question": "How does Amazon ECS compare to other container management solutions in terms of partnerships?", "answer": "The text passage does not provide enough information to make a comparison between Amazon ECS and other container management solutions in terms of partnerships.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-12", "source_tokens": 10, "generated_at": "2026-02-11T15:22:01.268288"}}
{"question": "What reports provide cost information for Amazon ECS tasks running on AWS Fargate?", "answer": "AWS Cost and Usage Reports (CUR) and AWS Cost Explorer provide cost information for Amazon ECS tasks running on AWS Fargate.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T15:22:06.336122"}}
{"question": "How can you aggregate and allocate costs for Amazon ECS tasks running on Amazon EC2 instances?", "answer": "You can aggregate and allocate costs for Amazon ECS tasks running on Amazon EC2 instances by opting into Split Cost Allocation Data for Amazon ECS. This generates task-level costs for Amazon ECS tasks based on resource consumption and ingests managed and user-added tags.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T15:22:06.336456"}}
{"question": "What is the difference between cost reporting for Amazon ECS tasks on AWS Fargate and Amazon EC2 instances?", "answer": "Cost reporting for Amazon ECS tasks on AWS Fargate and Amazon EC2 instances differ in that for AWS Fargate, costs are automatically available in CUR and Cost Explorer, while for Amazon EC2 instances, you need to opt into Split Cost Allocation Data.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-13", "source_tokens": 288, "generated_at": "2026-02-11T15:22:06.336609"}}
{"question": "What IP range is used for your Amazon EC2 instances in Amazon ECS?", "answer": "You specify the IP range for your Amazon EC2 instances in a Virtual Private Cloud (VPC).", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T15:22:10.514897"}}
{"question": "How does using Amazon ECS with AWS Fargate impact security?", "answer": "Using Amazon ECS with AWS Fargate provides higher isolation, network access control, and IAM control. Each task runs in a separate virtual machine (VM) with its own network interface and security group. ", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T15:22:10.515144"}}
{"question": "How does accessing a private container image registry in Amazon ECS differ from an external registry?", "answer": "A private container image registry within a VPC is configured for your Amazon EC2 instances, whereas an external registry like Amazon ECR is accessible outside the VPC.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T15:22:10.515269"}}
{"question": "What IAM role should you create first for your task in Amazon ECS?", "answer": "You should create an IAM role using the 'Amazon EC2 Container Service Task Roleâ€™ service role and attach a policy with the required permissions.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-11T15:22:15.397929"}}
{"question": "Why is it necessary to specify a role when creating a new task definition in Amazon ECS?", "answer": "Specifying a role in Amazon ECS when creating a new task definition allows you to grant the required permissions for your task to run.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-11T15:22:15.398171"}}
{"question": "How does Amazon ECS support compliance with different standards and regulations?", "answer": "Amazon ECS supports compliance with various standards and regulations, including PCI DSS Level 1, ISO 9001, ISO 27001, HIPAA eligibility, and others. It also offers AWS GovCloud (US) for sensitive data and regulated workloads, and AWS Fargate in a FIPS 140-2 compliant manner.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-15", "source_tokens": 419, "generated_at": "2026-02-11T15:22:15.398573"}}
{"question": "What is the minimum monthly uptime percentage guaranteed by AWS for Amazon ECS under the Compute SLA?", "answer": "The minimum monthly uptime percentage guaranteed by AWS for Amazon ECS under the Compute SLA is 99.99%.", "question_type": "factual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-11T15:22:20.414709"}}
{"question": "How does the Compute SLA for Amazon ECS ensure high availability?", "answer": "The Compute SLA for Amazon ECS ensures high availability by making two commitments: (1) a Multi-AZ Included Container Service SLA and (2) a Single Task/Pod SLA, which govern tasks and pods individually.", "question_type": "conceptual", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-11T15:22:20.414997"}}
{"question": "How does the Multi-AZ Included Container Service SLA differ from the Single Task/Pod SLA for Amazon ECS under the Compute SLA?", "answer": "The Multi-AZ Included Container Service SLA governs Included Container Services deployed across multiple Availability Zones, while the Single Task/Pod SLA governs Included Container Service tasks and pods individually.", "question_type": "comparison", "metadata": {"service": "ECS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "ecs-faq-16", "source_tokens": 230, "generated_at": "2026-02-11T15:22:20.415183"}}
{"question": "What storage classes are ideal for workloads with the highest levels of durability and availability in Amazon EFS?", "answer": "Amazon EFS Standard storage classes are ideal for such workloads.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T15:22:25.196529"}}
{"question": "How does Amazon EFS provide consistency and file locking to multiple instances accessing the same file system?", "answer": "Amazon EFS provides full file system access semantics, including strong consistency and file locking, enabling consistent performance for each compute instance.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T15:22:25.196869"}}
{"question": "How does Amazon EFS One Zone storage classes compare to Amazon EFS Standard storage classes in terms of durability and availability?", "answer": "Amazon EFS One Zone storage classes offer lower durability and availability compared to Amazon EFS Standard storage classes, making them suitable for development, build, staging environments, analytics, simulation, media transcoding, backups, or replicas of on-premises data that donâ€™t require Multi-AZ resilience.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T15:22:25.197324"}}
{"question": "What type of cloud storage service does AWS EFS provide?", "answer": "AWS EFS is a file storage service.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-11T15:22:29.969629"}}
{"question": "How does AWS EFS compare to other AWS storage services like Amazon EBS and Amazon S3 in terms of use cases?", "answer": "AWS EFS is a file storage service that provides a file system interface, file system access semantics, and concurrently accessible storage for up to thousands of EC2 instances. Amazon EBS is a block-level storage service that delivers performance for workloads requiring low-latency access to data from a single EC2 instance. Amazon S3 is an object storage service that makes data available through an internet API that can be accessed anywhere.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-11T15:22:29.969907"}}
{"question": "Which protocol does AWS EFS use for accessing the file system?", "answer": "AWS EFS uses the Network File System version 4 (NFS v4) protocol for accessing the file system.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-1", "source_tokens": 441, "generated_at": "2026-02-11T15:22:29.970284"}}
{"question": "What does Amazon EFS offer that reduces the complexity of managing file system infrastructure?", "answer": "Amazon EFS is a fully managed service that eliminates the need to deploy and maintain complex file system infrastructure. It automatically grows and shrinks based on the number of files, and provides console, CLI, and API/SDK access for administration.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-11T15:22:35.421119"}}
{"question": "How does Amazon EFS allow for easy access to file systems from on-premises servers?", "answer": "Amazon EFS can be synced with existing file systems using AWS DataSync, which supports various network connections including AWS Direct Connect and VPN. Standard Linux copy tools can also be used to move data files to Amazon EFS.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-11T15:22:35.421508"}}
{"question": "What are the benefits of using Amazon EFS for large-scale data storage compared to other solutions?", "answer": "Amazon EFS offers elastic file systems that grow and shrink automatically based on the number of files, and supports storing petabytes of data without the need to provision file system size up front. It also supports a large number of Amazon Elastic Compute Cloud instances connecting to a file system concurrently.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-2", "source_tokens": 486, "generated_at": "2026-02-11T15:22:35.421731"}}
{"question": "What throughput mode offers automatic scaling and pay-as-you-go pricing?", "answer": "Elastic Throughput", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-11T15:22:40.113328"}}
{"question": "Why is Elastic Throughput recommended for applications with uncertain or spiky throughput needs?", "answer": "Elastic Throughput is recommended for applications that are uncertain of their peak throughput needs or have a low baseline activity, using less than 5% of capacity on average.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-11T15:22:40.113558"}}
{"question": "What is the difference between EFS Regional file systems and EFS One Zone file systems in terms of durability and availability?", "answer": "EFS Regional file systems store data with and across multiple Availability Zones, offering the highest levels of durability and availability. EFS One Zone file systems store data redundantly within a single Availability Zone, which results in lower durability and availability as data in these file systems will be unavailable and might be lost during a disaster or other fault within the Availability Zone.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-3", "source_tokens": 365, "generated_at": "2026-02-11T15:22:40.113939"}}
{"question": "What level of durability does Amazon EFS One Zone provide?", "answer": "Amazon EFS One Zone provides redundant storage within a single Availability Zone, but it is not resilient to a complete Availability Zone outage, which may result in data loss during disasters or other faults within the Availability Zone.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:22:46.117444"}}
{"question": "How does Amazon EFS ensure data availability during AZ outages for EFS Regional file systems?", "answer": "Amazon EFS Regional file systems ensure data availability during AZ outages by replicating data across multiple Availability Zones and providing highly available EFS mount targets in all AZs within the Region.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:22:46.117739"}}
{"question": "What's the difference in data availability between Amazon EFS One Zone and Amazon EFS Regional file systems during an AZ outage?", "answer": "Amazon EFS One Zone file systems support only one highly available EFS mount target in a single Availability Zone, which means data may become unavailable during a disaster or other fault within that Availability Zone. Amazon EFS Regional file systems are designed with redundancy across multiple Availability Zones and provide highly available EFS mount targets in all AZs within the Region, ensuring higher data availability during AZ outages.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T15:22:46.118240"}}
{"question": "What are the three storage classes offered by Amazon EFS and what are their intended usage scenarios?", "answer": "Amazon EFS offers three storage classes: EFS Standard, EFS Infrequent Access (IA), and EFS Archive. EFS Standard is designed for data that requires sub-millisecond latencies due to frequent access. EFS Infrequent Access (IA) is a cost-optimized storage class for data accessed only a few times a quarter, offering up to 95% cost savings compared to EFS Standard. EFS Archive is optimized for and supported on EFS Regional file systems, designed for data accessed a few times a year or less, offering up to 50% cost savings compared to EFS Infrequent Access, with a higher request charge when that data is accessed.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-11T15:22:54.409657"}}
{"question": "How does EFS determine which files to transition between storage classes based on access patterns?", "answer": "Amazon EFS automatically tiers files between storage classes based on access patterns using EFS Lifecycle Management. The default policy tiers files from EFS Standard to EFS Infrequent Access (IA) after 30 consecutive days without access and to EFS Archive after 90 consecutive days without access. Users can also specify a custom policy for transitioning files between storage classes based on the number of days since a fileâ€™s last access.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-11T15:22:54.410008"}}
{"question": "How does the performance of files in EFS Infrequent Access and EFS Archive compare to EFS Standard?", "answer": "Files in EFS Infrequent Access and EFS Archive are initially accessed with low double-digit millisecond latencies. Once promoted back to EFS Standard using EFS Intelligent-Tiering, these files provide subsequent reads with the faster, sub-millisecond latencies of EFS Standard. EFS Standard is designed for data that requires sub-millisecond latencies due to frequent access.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-5", "source_tokens": 435, "generated_at": "2026-02-11T15:22:54.410411"}}
{"question": "What is the first-byte latency difference between EFS Standard, EFS IA, and EFS Archive?", "answer": "EFS Standard has sub-millisecond read latencies, while EFS IA and Archive have low double-digit millisecond read latencies.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-11T15:22:59.709876"}}
{"question": "Why are EFS IA and Archive better suited for storing larger files compared to EFS Standard?", "answer": "EFS IA and Archive are cost-optimized storage classes designed for storing colder, inactive data. They have no minimum file size but charge for files smaller than 128 KiB as if they were 128 KiB.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-11T15:22:59.710167"}}
{"question": "How does the cost and latency comparison between EFS IA and EFS Archive differ from EFS Standard?", "answer": "EFS Standard offers lower first-byte latencies (sub-millisecond) but has a different cost structure than EFS IA and Archive, which are designed for colder, inactive data and have higher first-byte latencies (low double-digit milliseconds).", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-6", "source_tokens": 327, "generated_at": "2026-02-11T15:22:59.710380"}}
{"question": "What storage class can you configure independently of the original file system for cost savings with EFS Replication?", "answer": "You can configure the cost-optimized storage classes and shorter age-off lifecycle management policy for your replica file system to save up to 92% on your costs.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T15:23:06.250497"}}
{"question": "Why would you use EFS Replication for business continuity planning and what benefits does it offer?", "answer": "EFS Replication is used for business continuity planning as it allows you to maintain a replica of your file system many miles apart. In the event of a disaster, you can failover to your replica file system and resume operations for your business-critical applications within minutes. While replication is enabled, your applications can use the replica file system in read-only mode for low network latency cross-Region access.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T15:23:06.250845"}}
{"question": "How does the replication process work when you failover to the replica file system and what happens to the unsynced changes?", "answer": "When you failover to the replica file system, files from the source file system might have been transferred but are not yet copied to their final locations. These files and their contents can be found on your replica file system in a lost+found directory created by EFS Replication under the root directory. Once the disaster event is over, you can failback by transferring only incremental changes from your replica back to your original file system.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T15:23:06.251051"}}
{"question": "What is the nature of the backups created with Amazon EFS and AWS Backup?", "answer": "During the initial backup, a full copy of the entire file system is made in the backup vault. Subsequent backups are incremental, where only files and directories that have been changed, added, or removed are copied.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-11T15:23:11.102122"}}
{"question": "How can you manage network traffic and client access to an Amazon EFS file system?", "answer": "Use VPC security groups to control network traffic, attach IAM policies to your file system for client access, and use EFS Access Points to manage application access and enforce file- and folder-level permissions.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-11T15:23:11.102346"}}
{"question": "What's the difference between managing network traffic with VPC security groups and IAM policies in an Amazon EFS file system?", "answer": "VPC security groups control the network traffic to and from the file system, while IAM policies determine which clients can mount the file system and with what permissions.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-8", "source_tokens": 397, "generated_at": "2026-02-11T15:23:11.102684"}}
{"question": "What is the benefit of using Amazon EFS Access Points for simplifying data sharing compared to traditional POSIX ACLs and Kerberos?", "answer": "Amazon EFS Access Points simplify data sharing by integrating with IAM, allowing cloud native applications to use POSIX-based shared file storage without the need for complex setup, management, and maintenance that traditional POSIX ACLs and Kerberos require, which can introduce risk.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-11T15:23:16.799131"}}
{"question": "What happens when you create an Amazon EFS Access Point and configure a root directory and owner?", "answer": "When you create an Amazon EFS Access Point and configure a root directory and owner, EFS will automatically create the directory with the permissions you provide the first time a client connects to the access point. The root directoryâ€™s owner is specified by you.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-11T15:23:16.799496"}}
{"question": "How does data encryption in transit with Amazon EFS differ from data encryption at rest?", "answer": "Data encryption at rest with Amazon EFS is transparently encrypted while being written and decrypted while being read, while data encryption in transit uses industry-standard Transport Layer Security (TLS) 1.2 to encrypt data sent between your clients and EFS file systems.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-9", "source_tokens": 428, "generated_at": "2026-02-11T15:23:16.799874"}}
{"question": "What service does AWS KMS help users create and manage?", "answer": "AWS KMS is a managed service that helps users create and manage encryption keys used to encrypt their data.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-11T15:23:20.887432"}}
{"question": "Why is AWS KMS integrated with AWS CloudTrail?", "answer": "AWS KMS is integrated with AWS CloudTrail to provide logs of all key usage, helping users meet their regulatory and compliance needs.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-11T15:23:20.887769"}}
{"question": "How does encryption in transit between EFS and its clients differ from encryption at rest?", "answer": "Encryption in transit between an Amazon EFS file system and its clients encrypts data as it travels between the file system and the clients. Encryption at rest, on the other hand, encrypts data when it is stored in the file system.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-10", "source_tokens": 358, "generated_at": "2026-02-11T15:23:20.888260"}}
{"question": "What is the third use case for moving data to and from Amazon EFS file systems?", "answer": "Periodically copying on-premises file data to Amazon EFS for backup and disaster recovery scenarios.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-11T15:23:25.678211"}}
{"question": "How can you support cloud bursting workloads using Amazon EFS?", "answer": "By moving data from your on-premises servers into your Amazon EFS file systems, analyzing it on a cluster of EC2 instances in your Amazon VPC, and storing the results permanently in your Amazon EFS file systems or moving the results back to your on-premises servers.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-11T15:23:25.678550"}}
{"question": "How does the network latency between on-premises datacenter and Amazon VPC affect the read and write throughput when accessing Amazon EFS?", "answer": "The network latency directly impacts the read and write throughput by limiting the volume of data that can be read or written during a period of time. To maximize throughput, parallelize file operations using tools like GNU parallel so that multiple reads and writes are processed by Amazon EFS concurrently.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-11", "source_tokens": 443, "generated_at": "2026-02-11T15:23:25.679095"}}
{"question": "What is AWS DataSync and how does it help in copying data into Amazon EFS?", "answer": "AWS DataSync is an online data transfer service that makes it faster and simpler to securely copy and migrate data into Amazon EFS. It uses a purpose-built protocol to accelerate and secure data transfer over the internet or Direct Connect, at speeds up to 10 times faster than standard Linux copy tools.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-11T15:23:31.859419"}}
{"question": "What is the difference between using AWS DataSync over the internet and AWS Direct Connect for copying data into Amazon EFS?", "answer": "AWS DataSync over the internet uses the public internet for data transfer, while AWS DataSync over Direct Connect uses a dedicated network connection. Direct Connect offers a higher bandwidth and lower latency for data transfer, resulting in faster data transfer speeds into Amazon EFS.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-11T15:23:31.859761"}}
{"question": "What are the key features of AWS DataSync?", "answer": "AWS DataSync is an online data transfer service that makes it faster and simpler to move data between on-premises storage and Amazon EFS. It uses a purpose-built protocol to accelerate and secure transfer over the internet or Direct Connect. It allows for one-time data migrations, transfer of on-premises data for timely in-cloud analysis, and automation of data replication for data protection and recovery.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-12", "source_tokens": 356, "generated_at": "2026-02-11T15:23:31.860192"}}
{"question": "What protocol does Amazon EFS use for advisory locking?", "answer": "Amazon EFS uses the NFS v4.1 protocol for advisory locking.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:23:37.616276"}}
{"question": "How can I ensure that my AWS Transfer Family users have access to my Amazon EFS file system?", "answer": "To ensure that your AWS Transfer Family users have access to your Amazon EFS file system, you need to create a Transfer Family endpoint and user(s) in the same Region as your Amazon EFS file system, and configure your Amazon EFS file system to be accessed by AWS Transfer Family using another account if necessary.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:23:37.616619"}}
{"question": "What services can I use with Amazon EFS to monitor, manage, and label my file systems?", "answer": "You can use services like CloudWatch, CloudFormation, CloudTrail, IAM, AWS tagging services, and AWS Budgets with Amazon EFS. CloudWatch helps you monitor file system activity using metrics, CloudFormation helps you create and manage file systems using templates, CloudTrail helps you record all EFS API calls in log files, IAM helps you control who can administer your file system, and AWS tagging services help you label your file systems with metadata that you define.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:23:37.617109"}}
{"question": "What is the pricing model for Amazon EFS in terms of primary and backup storage, metadata, and data read/write activity?", "answer": "You pay for the primary and backup storage you use, and for your metadata and data read, write, and tiering activity to your EFS file system. You pay for read and write access using Elastic Throughput, and for tiering data to EFSâ€™s Infrequent Access and Archive storage classes.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-11T15:23:44.342108"}}
{"question": "How does Amazon EFS's pricing and storage classes differ from each other in terms of performance and cost?", "answer": "Amazon EFS offers three storage classes: EFS Standard, which delivers sub-millisecond latency performance for actively-used data; EFS Infrequent Access (EFS IA), which is cost-optimized for data accessed only a few times a quarter; and EFS Archive, which is cost-optimized for long-lived data accessed a few times a year or less.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-11T15:23:44.342316"}}
{"question": "Why would you choose to use Amazon EFS's backup and replication features over managing additional infrastructure or custom processes?", "answer": "With EFS Backup, you pay only for the amount of backup storage you use and the amount of backup data you restore in the month. There is no minimum fee and there are no setup charges. Use EFS Replication to replicate your file system to a Region or Availability Zone (AZ) of your choice without having to manage additional infrastructure or custom processes.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-14", "source_tokens": 344, "generated_at": "2026-02-11T15:23:44.342459"}}
{"question": "What is the billing period for Amazon EFS usage?", "answer": "You will be charged for Amazon EFS usage at the end of each month.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-11T15:23:49.225940"}}
{"question": "How does Amazon EFS billing work for new customers?", "answer": "New EFS customers receive 5 GB of Amazon EFS Standard each month for one year under the AWS Free Tier, and starting July 15, 2025, new customers also receive up to $200 in AWS Free Tier credits which can be applied towards Amazon EFS. Upon sign up, customers can choose between a free plan and a paid plan, and unused Free Tier credits will apply to AWS bills if upgraded to a paid plan.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-11T15:23:49.226262"}}
{"question": "How does the billing for Amazon EFS compare between the free and paid plans?", "answer": "The main difference is that under the free plan, new customers receive 5 GB of Amazon EFS Standard each month for one year and up to $200 in AWS Free Tier credits, while under the paid plan, customers are charged based on their usage of storage, throughput, and data protection.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-15", "source_tokens": 447, "generated_at": "2026-02-11T15:23:49.226476"}}
{"question": "What is the total number of GB-Hours used for EFS Standard in the given scenario?", "answer": "108,000 GB-Hours", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-11T15:23:53.848384"}}
{"question": "How does EFS Lifecycle Management move files between different classes in the absence of Intelligent Tiering?", "answer": "EFS Lifecycle Management moves 50% of the EFS Standard files to the IA class and 10% of the EFS IA files to the Archive class after 14 days of having not been accessed.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-11T15:23:53.848723"}}
{"question": "How does the usage of EFS Standard compare to the usage of EFS IA in the given scenario?", "answer": "The text passage states that 108,000 GB-Hours are used for EFS Standard and 168,000 GB-Hours are used for EFS IA.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-16", "source_tokens": 478, "generated_at": "2026-02-11T15:23:53.849201"}}
{"question": "What is the total EFS IA usage in GB-Hours, as calculated from the text?", "answer": "392,400 GB-Hours", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-11T15:23:58.146789"}}
{"question": "How does the process of moving files from EFS Standard to EFS IA impact the EFS IA usage?", "answer": "The process of moving files from EFS Standard to EFS IA increases the EFS IA usage by the size of the files being moved multiplied by the number of days they are in EFS IA.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-11T15:23:58.146985"}}
{"question": "How does the EFS IA usage compare to the EFS Archive usage, according to the context?", "answer": "The EFS IA usage is lower than the EFS Archive usage, based on the GB-Hours calculated in the text.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-17", "source_tokens": 511, "generated_at": "2026-02-11T15:23:58.147108"}}
{"question": "What is the total EFS access charge for the month?", "answer": "$16.50", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-11T15:24:02.363203"}}
{"question": "How does EFS IA tiering and access charging compare to EFS Archive tiering and access charging?", "answer": "EFS IA tiering and access charging is $1.50 more expensive than EFS Archive tiering and access charging on a per-gigabyte basis for read access and Elastic Throughput read charges, but EFS IA has a lower data tiering charge.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-11T15:24:02.363535"}}
{"question": "What factors contribute to the cost of using EFS IA and EFS Archive?", "answer": "The cost of using EFS IA and EFS Archive includes data tiering charges, read access charges, and Elastic Throughput read charges.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-18", "source_tokens": 409, "generated_at": "2026-02-11T15:24:02.364042"}}
{"question": "What is the total monthly Elastic Throughput charge based on the given usage?", "answer": "$486.00", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-11T15:24:06.967521"}}
{"question": "How does Elastic Throughput charging work and what factors influence the cost?", "answer": "Elastic Throughput charging is based on the data transferred for read and write operations in a month, measured in GB. The charge is calculated by multiplying the amount of data transferred for each operation type by the respective price per GB. The peak throughput usage also affects the charge, as it determines the total monthly Elastic Throughput data usage.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-11T15:24:06.967788"}}
{"question": "How does the Elastic Throughput charge compare between read and write operations?", "answer": "The Elastic Throughput charge for read operations is lower than the charge for write operations, as the price per GB for read data is $0.03, while the price per GB for write data is $0.06.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-19", "source_tokens": 476, "generated_at": "2026-02-11T15:24:06.967951"}}
{"question": "What are the data transfer charges for metadata operations in EFS?", "answer": "There are additional data transfer charges for metadata operations such as list (ls), remove (rm), and create directory (mkdir) in EFS.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T15:24:17.394595"}}
{"question": "How are metadata operations in EFS metered for Elastic Throughput?", "answer": "Metadata operations in EFS for Elastic Throughput are metered at a minimum of 4 KiB.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T15:24:17.394972"}}
{"question": "How does the data transfer charge for creating a directory compare to the charge for viewing directory details in EFS?", "answer": "Creating a new directory with 'mkdir directoryname' is metered at 4 KiB, while viewing details of a directory with 'ls' for 10 files is metered at 10 x 4 KiB = 40 KiB.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T15:24:17.395371"}}
{"question": "What is the initial storage charge for replicating a 1 TB EFS file system from US East (North Virginia) to US West (Oregon) using EFS Replication?", "answer": "$67.74", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-11T15:24:23.445292"}}
{"question": "How does the storage cost differ between using EFS Replication and AWS Backup for data protection?", "answer": "With EFS Replication, you pay for the storage, access charges from Infrequent Access and Archive classes, and data transfer changes if the destination file system is in a different AWS Region. With AWS Backup, you pay for the average amount of data backed up and restored in a month. The initial sync cost for replicating a file system using EFS Replication is calculated based on the pro-rated storage usage in the destination file system.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-11T15:24:23.445636"}}
{"question": "What is the difference in the storage cost for replicating a file system using EFS Replication compared to using AWS Backup, given that the source file system is 1 TB and both replications are across different AWS Regions?", "answer": "The initial storage charge for replicating a 1 TB EFS file system using EFS Replication is $67.74, while the storage cost for using AWS Backup is not explicitly stated in the context.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-22", "source_tokens": 498, "generated_at": "2026-02-11T15:24:23.445857"}}
{"question": "What is the total cost for the initial sync in this scenario?", "answer": "$107.10", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T15:24:27.539125"}}
{"question": "How does AWS calculate the charges for incremental replication in this scenario?", "answer": "AWS calculates the charges for incremental replication by first converting the new data's storage usage into GB-hours, then converting that to GB-months, and finally multiplying by the respective storage charges for the EFS Standard and EFS Infrequent Access classes.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T15:24:27.539467"}}
{"question": "What is the difference between the charges for the initial sync and the incremental replication in this scenario?", "answer": "The initial sync charges include both total storage and data transfer charges for the initial replication of the file system, while the incremental replication charges only include the storage charges for new data added to the destination file system and the data transfer charges for that new data.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-23", "source_tokens": 505, "generated_at": "2026-02-11T15:24:27.539933"}}
{"question": "What is the total charge for incremental replication in the text passage?", "answer": "$15.22", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-11T15:24:31.463207"}}
{"question": "How does the pricing for EFS replication break down into initial sync and incremental replication?", "answer": "The total charge for EFS replication is the sum of the charge for the initial sync and the charge for incremental replication.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-11T15:24:31.463478"}}
{"question": "What's the difference in charges between incremental replication and EFS replication in the text passage?", "answer": "The text passage states that the total charge for incremental replication is $15.22, while the total charge for EFS replication is $122.32. This difference is $107.10.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-24", "source_tokens": 134, "generated_at": "2026-02-11T15:24:31.463687"}}
{"question": "What tax is applicable for customers with a Japanese billing address?", "answer": "Apart from the prices mentioned, there is an additional charge for customers with a Japanese billing address in the form of Japanese Consumption Tax.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-11T15:24:35.167833"}}
{"question": "Why is there an extra charge for customers with a Japanese billing address?", "answer": "The extra charge is due to the applicability of Japanese Consumption Tax for such customers.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-11T15:24:35.168171"}}
{"question": "How does the tax situation differ for customers with Japanese billing addresses compared to other customers?", "answer": "Customers with Japanese billing addresses are subject to Japanese Consumption Tax in addition to the prices mentioned, while other customers' prices are exclusive of applicable taxes and duties.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-25", "source_tokens": 54, "generated_at": "2026-02-11T15:24:35.168382"}}
{"question": "What is the average storage size of the example file system in the US East (N. Virginia) Region?", "answer": "The average storage size of the example file system is 2.7 TB.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-11T15:24:39.614607"}}
{"question": "How does Amazon EFS differ from a non-elastic (provisioned) cloud solution in terms of storage and throughput management?", "answer": "Amazon EFS automatically scales storage and throughput up and down, while a non-elastic solution requires managing storage and throughput capacity at peak usage and doesn't allow for capacity reduction.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-11T15:24:39.614950"}}
{"question": "Compare the cost savings of using Amazon EFS versus a non-elastic solution for a general purpose workload with an average storage size of 2.7 TB and a peak throughput of 25 MBps.", "answer": "With EFS, the TCO is $0.0315/GB-mo, while the effective TCO of a non-elastic solution is 60% more expensive.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-26", "source_tokens": 441, "generated_at": "2026-02-11T15:24:39.615162"}}
{"question": "What is the recommended storage utilization for this provisioned cloud solution?", "answer": "The recommended storage utilization for this provisioned cloud solution is 50%.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-11T15:24:43.570906"}}
{"question": "How does the storage cost comparison look between the SSD and IA storage classes in this provisioned cloud solution?", "answer": "The SSD storage costs $34.00 per month, while the IA storage costs $56.15 per month.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-11T15:24:43.571134"}}
{"question": "What is the concept behind the data tiering feature mentioned in this text?", "answer": "Data tiering is a storage optimization technique that moves frequently accessed data to faster storage tiers and infrequently accessed data to slower, lower-cost storage tiers.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-27", "source_tokens": 509, "generated_at": "2026-02-11T15:24:43.571324"}}
{"question": "What is the total GB-monthly storage cost for EFS with SSD in the given example?", "answer": "The total GB-monthly storage cost for EFS with SSD in the given example is $25.60.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-11T15:24:48.046095"}}
{"question": "How does elasticity in EFS benefit the stock market modeling workload in terms of storage cost savings?", "answer": "Elasticity in EFS allows the stock market modeling workload to only pay for what they use, resulting in a TCO savings of 84% compared to a provisioned solution.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-11T15:24:48.046462"}}
{"question": "What is the difference in monthly storage cost between EFS and a provisioned solution for the given workload?", "answer": "The monthly storage cost for EFS is $25.60, while for a provisioned solution, it is $166.50.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-28", "source_tokens": 507, "generated_at": "2026-02-11T15:24:48.046663"}}
{"question": "What is the effective cost per GB for the first setup?", "answer": "$0.2172", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-11T15:24:51.653034"}}
{"question": "How does the cost savings percentage for EFS differ between the two setups?", "answer": "The first setup achieves an 84% cost savings percentage, while the second setup achieves a 0% cost savings percentage.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-11T15:24:51.653407"}}
{"question": "Why would the second setup have a lower effective cost per GB, despite a higher total cost?", "answer": "The second setup has a higher total cost due to a higher throughput cost, but also a higher data transfer volume, leading to a lower effective cost per GB due to economies of scale.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-29", "source_tokens": 161, "generated_at": "2026-02-11T15:24:51.653934"}}
{"question": "Which launch types support accessing EFS in Amazon ECS?", "answer": "Both EC2 and Fargate launch types in Amazon ECS allow accessing EFS.", "question_type": "factual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-11T15:24:55.151277"}}
{"question": "How does Amazon EKS enable accessing EFS from containerized applications?", "answer": "Amazon EKS enables accessing EFS from containerized applications using the EFS CSI driver.", "question_type": "conceptual", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-11T15:24:55.151614"}}
{"question": "What's the difference in accessing EFS from Amazon ECS and Amazon EKS?", "answer": "Both Amazon ECS and Amazon EKS allow accessing EFS from containerized applications using different launch types and drivers.", "question_type": "comparison", "metadata": {"service": "EFS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "efs-faq-30", "source_tokens": 219, "generated_at": "2026-02-11T15:24:55.151811"}}
{"question": "What is Amazon EKS and how does it work?", "answer": "Amazon EKS is a managed service provided by AWS that makes it easy to run Kubernetes on AWS without managing the control plane or worker nodes. Kubernetes is an open-source container orchestration system that arranges containers into logical groupings and launches them onto clusters of Amazon EC2 instances. Amazon EKS provisions and scales the control plane, manages the API servers and backend persistence layer across multiple AWS Availability Zones for high availability and fault tolerance. Users can run EKS using AWS Fargate, which provides serverless compute for containers and removes the need to manage servers.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T15:25:01.580404"}}
{"question": "How does Amazon EKS integrate with other AWS services?", "answer": "Amazon EKS is integrated with several AWS services including Elastic Load Balancing for load distribution, AWS Identity and Access Management (IAM) for authentication, Amazon Virtual Private Cloud (VPC) for isolation, and AWS CloudTrail for logging.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T15:25:01.580777"}}
{"question": "What are the differences between running Kubernetes on AWS Fargate and managing your own EC2 instances?", "answer": "Running Kubernetes on AWS Fargate provides serverless compute for containers, removes the need to manage servers and improves security through application isolation by design. In contrast, managing your own EC2 instances allows more control over the underlying infrastructure, but requires more time and resources for managing and scaling the instances.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-0", "source_tokens": 424, "generated_at": "2026-02-11T15:25:01.581210"}}
{"question": "What operating systems does Amazon EKS support for worker nodes?", "answer": "Amazon EKS supports Kubernetes-compatible Linux x86, ARM, and Windows Server operating system distributions.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T15:25:05.690510"}}
{"question": "How does Amazon EKS simplify the operational burden of managing Kubernetes?", "answer": "Amazon EKS removes the operational burden of managing the Kubernetes control plane and worker nodes by provisioning, scaling, and managing them for you.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T15:25:05.690852"}}
{"question": "How does Amazon EKS compare to running Kubernetes on my own in terms of managing the control plane?", "answer": "With Amazon EKS, AWS handles provisioning, scaling, and managing the Kubernetes control plane in a highly available and secure configuration, whereas without Amazon EKS, you have to manage it yourself.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-1", "source_tokens": 470, "generated_at": "2026-02-11T15:25:05.691386"}}
{"question": "What operational software does Amazon EKS add-ons help manage in Kubernetes clusters?", "answer": "Amazon EKS add-ons simplifies the management of Kubernetes operational software, ensuring clusters are secure and stable, and reducing the work needed to start and manage production-ready Kubernetes clusters on AWS.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-11T15:25:10.516240"}}
{"question": "How does Amazon EKS Auto Mode simplify Kubernetes cluster management on AWS?", "answer": "Amazon EKS Auto Mode fully automates Kubernetes cluster management on AWS by automatically provisioning infrastructure, scaling resources, managing core add-ons, optimizing costs, and providing secure and scalable cluster infrastructure managed by AWS with integrated Kubernetes capabilities.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-11T15:25:10.516576"}}
{"question": "What are the main differences between using Amazon EKS with and without Auto Mode?", "answer": "With Amazon EKS Auto Mode, AWS manages infrastructure, scales resources, optimizes costs, and keeps up-to-date with proven best practices. Without Auto Mode, users need to manage these aspects manually.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-2", "source_tokens": 436, "generated_at": "2026-02-11T15:25:10.516716"}}
{"question": "What infrastructure components does Amazon EKS Auto Mode manage by default?", "answer": "Amazon EKS Auto Mode manages the compute, storage, networking, and monitoring infrastructure components for EKS clusters.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-11T15:25:14.612776"}}
{"question": "How does Amazon EKS Auto Mode ensure applications have the necessary infrastructure?", "answer": "Amazon EKS Auto Mode continuously observes applications and configures, creates, and optimizes AWS-managed resources to meet their needs.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-11T15:25:14.613116"}}
{"question": "What are the differences in management responsibilities between AWS infrastructure in EKS clusters with and without EKS Auto Mode?", "answer": "With EKS Auto Mode enabled, AWS takes responsibility for securing, configuring, and managing the AWS infrastructure in EKS clusters, but with limitations on instance management compared to customer-managed counterparts.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-3", "source_tokens": 380, "generated_at": "2026-02-11T15:25:14.613616"}}
{"question": "What are the three ways Amazon EKS Auto Mode improves the security of EKS clusters?", "answer": "Amazon EKS Auto Mode improves the security of EKS clusters in three ways: 1) the AWS-managed infrastructure created by EKS Auto Mode is configured according to AWS security best practices and hardened according to the Center for Internet Securityâ€™s (CIS) Level 1 benchmarks. 2) EKS Auto Modeâ€™s AWS-managed EC2 instances are automatically updated with the latest security and bug fixes as soon as theyâ€™re available. 3) By default, EKS Auto Mode sets a 14-day maximum lifetime for its AWS-managed EC2 instances.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:25:23.636013"}}
{"question": "Why is Amazon EKS Auto Mode the recommended approach for running Kubernetes on AWS instead of using EKS with AWS Fargate?", "answer": "Amazon EKS Auto Mode is the recommended approach for running Kubernetes on AWS instead of using EKS with AWS Fargate because EKS Auto Mode is fully Kubernetes conformant and supports all upstream Kubernetes primitives and platform tools, while Fargate does not. EKS Auto Mode also fully supports all EC2 runtime purchase options and isolation model, enabling customers to leverage negotiated EC2 discounts and other savings mechanisms. These capabilities are not available when using EKS with Fargate.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:25:23.636365"}}
{"question": "How does the security of Amazon EKS Auto Mode compare to EKS with AWS Fargate?", "answer": "The security of Amazon EKS Auto Mode is superior to that of EKS with AWS Fargate because EKS Auto Mode is fully Kubernetes conformant, supports all upstream Kubernetes primitives and platform tools like Istio, and provides the ability to leverage the entire breadth of EC2 and purchasing options while retaining the ease of use and abstraction from infrastructure management that Fargate provides. EKS Auto Mode also offers enhanced security features such as infrastructure configured according to AWS security best practices and hardened according to the Center for Internet Securityâ€™s (CIS) Level 1 benchmarks, automatic updates, and a configurable instance lifetime.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T15:25:23.636827"}}
{"question": "What is the maximum time it takes for an Amazon EKS cluster to be fully upgraded after upgrading the control plane's Kubernetes version?", "answer": "By default, an Amazon EKS cluster will be fully and automatically upgraded no later than 14 days after upgrading the EKS clusterâ€™s Kubernetes version.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-11T15:25:29.150603"}}
{"question": "How does Amazon EKS Auto Mode manage the Kubernetes software on instances in a cluster?", "answer": "Amazon EKS Auto Mode launches new instances with the latest Kubernetes software that matches the control plane version, while existing instances are gradually updated. This ensures that the entire cluster runs on the new software within the default 14-day maximum instance lifetime.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-11T15:25:29.150932"}}
{"question": "What components does Amazon EKS Auto Mode replace the need for, in terms of essential Kubernetes capabilities?", "answer": "Amazon EKS Auto Mode provides integrated and managed versions of several essential Kubernetes capabilities, including the EKS Auto Mode agent, containerd, kubelet, network proxy, Karpenter controller, Amazon EBS CSI controller, AWS VPC CNI, CoreDNS, and AWS Load Balancer Controller.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-5", "source_tokens": 472, "generated_at": "2026-02-11T15:25:29.152308"}}
{"question": "What AWS service can be used to view managed EC2 instances launched by EKS Auto Mode?", "answer": "The managed EC2 instances launched by EKS Auto Mode can be viewed using the EC2 DescribeInstances API or AWS Console.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T15:25:33.363715"}}
{"question": "How does Amazon EKS Auto Mode deliver its Kubernetes capabilities?", "answer": "Amazon EKS Auto Mode delivers its Kubernetes capabilities via a set of integrated controllers that emit Kubernetes events.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T15:25:33.364038"}}
{"question": "How does the application of Compute Savings Plans and Reserved Instances differ between EKS Auto Mode and non-EKS Auto Mode?", "answer": "Compute Savings Plans and Reserved Instances are automatically applied when eligible EC2 instances are launched in EKS Auto Mode, but not in non-EKS Auto Mode.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-6", "source_tokens": 512, "generated_at": "2026-02-11T15:25:33.364504"}}
{"question": "What version of Kubernetes does the most up-to-date EKS-optimized AMI include?", "answer": "The most up-to-date EKS-optimized AMI includes the latest version of Kubernetes, Docker, and Kubelet.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T15:25:37.576655"}}
{"question": "Why should you consider managing your EKS cluster versioning manually?", "answer": "Manually managing your EKS cluster versioning allows you to test applications against new versions of Kubernetes before upgrading your production clusters.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T15:25:37.576987"}}
{"question": "How does the extended support for Kubernetes versions in Amazon EKS compare to the standard support?", "answer": "The extended support for Kubernetes versions in Amazon EKS provides ongoing security patches for the Kubernetes control plane managed by Amazon EKS, while the standard support lasts for a shorter period.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T15:25:37.577472"}}
{"question": "What AWS services can be used for hybrid deployments with Amazon EKS?", "answer": "Amazon EKS, Amazon EKS Anywhere, and Amazon EKS Connector are the three options for hybrid deployments with Amazon EKS. Amazon EKS can be used to run nodes on AWS-hosted infrastructure or in your own on-premises facilities with AWS Outposts and Amazon EKS Hybrid Nodes.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-11T15:25:43.147647"}}
{"question": "How does Amazon EKS support hybrid deployments in isolated or air-gapped environments?", "answer": "Amazon EKS Anywhere is a customer-managed, AWS-supported Kubernetes management software that runs on infrastructure you manage, allowing you to use Amazon EKS in isolated or air-gapped environments.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-11T15:25:43.147911"}}
{"question": "What are the differences between running Amazon EKS on AWS Outposts with nodes on AWS Outposts versus deploying the entire Kubernetes cluster on AWS Outposts?", "answer": "When you run Amazon EKS on AWS Outposts with nodes on AWS Outposts, you use many of the same integrations as for workloads in AWS Cloud and pay for both the Amazon EKS cluster and the AWS Outposts capacity. Alternatively, when you deploy the entire Kubernetes cluster on AWS Outposts with Amazon EKS local clusters on AWS Outposts, you run the entire cluster on the same infrastructure.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-8", "source_tokens": 414, "generated_at": "2026-02-11T15:25:43.148341"}}
{"question": "What does Amazon EKS Hybrid Nodes allow users to do with their on-premises and edge infrastructure?", "answer": "Amazon EKS Hybrid Nodes enables users to use their on-premises and edge infrastructure as nodes in Amazon EKS clusters, allowing AWS to manage the control plane and users to manage the hybrid nodes.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:25:48.187910"}}
{"question": "How does Amazon EKS Hybrid Nodes differ from Amazon EKS Anywhere in terms of management responsibilities?", "answer": "Amazon EKS Hybrid Nodes is a service offered by AWS where they manage the control plane, while Amazon EKS Anywhere is a customer-managed product where customers are responsible for cluster lifecycle operations and maintenance.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:25:48.188262"}}
{"question": "Which Amazon EKS features can be used with Amazon EKS Hybrid Nodes?", "answer": "Amazon EKS features like Amazon EKS add-ons, Amazon EKS Pod Identity, cluster access entries, cluster insights, and extended Kubernetes version support can be used with Amazon EKS Hybrid Nodes.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:25:48.188667"}}
{"question": "What can you do with a connected cluster in the Amazon EKS console after registration with the Amazon EKS Connector?", "answer": "You can view the status, configuration, and workloads for the connected cluster in the Amazon EKS console.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-11T15:25:53.995363"}}
{"question": "How does managing a Kubernetes cluster differ between Amazon EKS Hybrid Nodes and Amazon EKS Anywhere?", "answer": "With Amazon EKS Hybrid Nodes, AWS manages the security, availability, and scalability of the Kubernetes control plane, while you manage the nodes on your infrastructure. With Amazon EKS Anywhere, you are responsible for managing the Kubernetes clusters that run entirely on your infrastructure.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-11T15:25:53.995699"}}
{"question": "Why would you use Amazon EKS Hybrid Nodes instead of Amazon EKS Anywhere?", "answer": "Amazon EKS Hybrid Nodes are suitable for customers with on-premises environments that can be connected to the cloud, as AWS manages the security, availability, and scalability of the Kubernetes control plane in the AWS Cloud, while only nodes run on your infrastructure. Amazon EKS Anywhere is designed for customers with isolated or air-gapped on-premises environments, as they are responsible for managing the Kubernetes clusters that run entirely on their infrastructure.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-10", "source_tokens": 351, "generated_at": "2026-02-11T15:25:53.996201"}}
{"question": "What do I pay for when using Amazon EKS Hybrid Nodes?", "answer": "You pay for the Amazon EKS cluster and node usage with Amazon EKS Hybrid Nodes.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T15:25:58.632952"}}
{"question": "How does the pricing model differ between Amazon EKS Hybrid Nodes and Amazon EKS on AWS Outposts?", "answer": "With Amazon EKS Hybrid Nodes, you pay for the Amazon EKS cluster and node usage. With Amazon EKS on AWS Outposts, you pay for the Amazon EKS cluster and AWS Outposts capacity.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T15:25:58.633274"}}
{"question": "What features does the EKS Dashboard provide for managing and visualizing Kubernetes clusters?", "answer": "The EKS Dashboard provides features such as an inventory of Kubernetes clusters, EKS managed node groups, and EKS add-ons in a tabular format, search functionality, and the ability to customize the dashboard to match operational needs.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-11", "source_tokens": 453, "generated_at": "2026-02-11T15:25:58.633543"}}
{"question": "What AWS account(s) can be used to access the EKS Dashboard?", "answer": "The EKS Dashboard can be accessed through the management account of an AWS Organization or through a delegated administrator account.", "question_type": "factual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-11T15:26:03.991996"}}
{"question": "How does having access to the EKS Dashboard benefit Kubernetes cluster management?", "answer": "The EKS Dashboard provides a centralized view of Kubernetes clusters across AWS Regions and accounts, enabling unified visibility, governance, and operational planning. It also allows users to filter and search for specific clusters based on certain criteria.", "question_type": "conceptual", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-11T15:26:03.992263"}}
{"question": "What are the differences between the EKS Dashboard and observability tools like Amazon CloudWatch or Prometheus?", "answer": "The EKS Dashboard offers a centralized view of raw and aggregated Kubernetes cluster metadata across AWS Regions and accounts. However, it isn't designed for deep cluster-level metrics or troubleshooting time-sensitive operational incidents. Tools like Amazon CloudWatch and Prometheus offer granular operational and security insights, making them more suitable for addressing time-sensitive issues and in-depth monitoring needs.", "question_type": "comparison", "metadata": {"service": "EKS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eks-faq-12", "source_tokens": 455, "generated_at": "2026-02-11T15:26:03.992439"}}
{"question": "What is Amazon ElastiCache and how does it improve application performance?", "answer": "Amazon ElastiCache is a web service that allows you to retrieve information from a fast, managed, in-memory system instead of relying on slower disk-based systems. It improves application performance by storing critical pieces of data in memory for low-latency access. Cached information can include the results of I/O-intensive database queries or computationally intensive calculations.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:26:10.693878"}}
{"question": "What are the benefits of using Amazon ElastiCache over traditional disk-based systems?", "answer": "Using Amazon ElastiCache can significantly improve latency and throughput for many read-heavy application workloads or compute-intensive workloads. It automates common administrative tasks required to operate a distributed in-memory key-value environment, allowing your engineering resources to focus on developing applications. ElastiCache is protocol compliant with Valkey, Memcached, and Redis OSS, and there are no up-front investments required. You pay only for the resources you use.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:26:10.694246"}}
{"question": "How does the performance of Amazon ElastiCache compare to a traditional disk-based database?", "answer": "Amazon ElastiCache provides significantly improved latency and throughput compared to traditional disk-based databases for many read-heavy application workloads or compute-intensive workloads. This is because it stores critical pieces of data in memory for low-latency access.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:26:10.694770"}}
{"question": "What tasks does ElastiCache automate when managing a self-created cache cluster?", "answer": "ElastiCache automates common administrative tasks such as software patching and failure detection and recovery.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-11T15:26:14.851730"}}
{"question": "Why would someone choose to use ElastiCache Serverless instead of managing their own cache cluster?", "answer": "ElastiCache Serverless allows users to create and use a cache without having to configure and manage any infrastructure.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-11T15:26:14.852073"}}
{"question": "How does ElastiCache Serverless compare to managing a self-created ElastiCache cache cluster in terms of setup time?", "answer": "ElastiCache Serverless allows users to create and begin using a cache in under a minute, while managing a self-created ElastiCache cache cluster requires setting up and configuring infrastructure.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-1", "source_tokens": 370, "generated_at": "2026-02-11T15:26:14.852567"}}
{"question": "What infrastructure provisions are required to use ElastiCache Serverless?", "answer": "None, ElastiCache Serverless lets you get started with a cache in under a minute without infrastructure provisioning.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T15:26:19.392886"}}
{"question": "How does ElastiCache Serverless handle cache scaling?", "answer": "ElastiCache Serverless continuously monitors a cacheâ€™s memory, compute, and network utilization, and can instantly scale to meet demand without downtime or performance degradation by allowing the cache to scale up and initiating scale-out in parallel.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T15:26:19.393248"}}
{"question": "What is the difference between ElastiCache and ElastiCache Serverless in terms of capacity planning?", "answer": "ElastiCache requires time-consuming capacity planning, while ElastiCache Serverless removes the need for capacity planning by continuously monitoring a cacheâ€™s utilization and instantly scaling to meet demand.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T15:26:19.393753"}}
{"question": "What is the difference between ElastiCache Serverless and ElastiCache with Reserved Nodes in terms of pricing?", "answer": "ElastiCache Serverless only charges for the data you store and the compute your application uses, while ElastiCache with Reserved Nodes allows you to make a one-time payment for a significant discount off the ongoing hourly usage charge for a specific term. ElastiCache Serverless is not compatible with Reserved Nodes.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:26:25.869702"}}
{"question": "How does the purchase process work for ElastiCache Reserved Nodes?", "answer": "You can purchase a reservation for a node with the same class within the same Region as the node you are currently running. If the reservation purchase is successful, ElastiCache will apply the new hourly usage charge to your existing node.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:26:25.870047"}}
{"question": "What are the three types of Reserved Node contracts and how do they differ in upfront payment and effective hourly price?", "answer": "The three types of Reserved Node contracts are All Upfront, No Upfront, and Partial Upfront. All Upfront requires a one-time, up-front payment for the entire term, while No Upfront allows you to pay for the term monthly with no up-front payment. Partial Upfront allows you to split your up-front payment into multiple equal payments at the beginning of the term. The amount you pay upfront and your effective hourly price varies between these contracts.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:26:25.870564"}}
{"question": "When is the discounted price for a Reserved Node activated?", "answer": "The discounted price for a Reserved Node is activated once the request is received and while the payment authorization is processed.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-11T15:26:29.268321"}}
{"question": "Why can't you cancel a Reserved Node reservation?", "answer": "You cannot cancel a Reserved Node reservation and the one-time payment (if applicable) is not refundable.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-11T15:26:29.268662"}}
{"question": "How does the pricing work for a Reserved Node under the Partial Upfront payment option?", "answer": "With the Partial Upfront payment option for a Reserved Node, you make a small upfront payment and are billed a low hourly rate for every hour in the term regardless of usage.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-4", "source_tokens": 458, "generated_at": "2026-02-11T15:26:29.269109"}}
{"question": "What encryption methods does ElastiCache support for data at rest and in transit?", "answer": "ElastiCache supports encryption of data at rest using AWS Key Management Service (AWS KMS) and encryption of data in transit using Transport Layer Security (TLS).", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T15:26:33.036760"}}
{"question": "How can I control access to my ElastiCache resources?", "answer": "Access to ElastiCache resources can be controlled through a combination of network security groups and IAM authentication.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T15:26:33.037101"}}
{"question": "How does ElastiCache compare to other AWS services in terms of compliance programs?", "answer": "ElastiCache supports several compliance programs such as SOC 1, SOC 2, SOC 3, ISO, MTCS, C5, PCI DSS, HIPAA, and FedRAMP.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T15:26:33.037606"}}
{"question": "Which AWS services include ElastiCache as a FedRAMP-authorized offering?", "answer": "AWS GovCloud (US-East) and AWS GovCloud (US-West) Regions offer ElastiCache as a FedRAMP-authorized service.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T15:26:37.618433"}}
{"question": "Why would one choose ElastiCache for Valkey over the open-source Redis version?", "answer": "One can benefit from a fully managed experience, security, operational excellence, and cost optimization with ElastiCache for Valkey.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T15:26:37.618780"}}
{"question": "How does the cost of ElastiCache for Valkey compare to ElastiCache Redis OSS?", "answer": "ElastiCache Serverless for Valkey has a 33% reduced price and a minimum data storage of 100 MB, which is 90% lower than ElastiCache Redis OSS.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-6", "source_tokens": 448, "generated_at": "2026-02-11T15:26:37.619279"}}
{"question": "What version of ElastiCache can I directly upgrade to from Redis OSS version 5.0 and above without downtime?", "answer": "You can directly upgrade to the most recent version of Valkey from Redis OSS version 5.0 and above without downtime using the AWS Management Console, Software Development Kit (SDK), or Command Line Interface (CLI).", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:26:42.931219"}}
{"question": "How does ElastiCache handle node failures and promote read replicas to the primary role?", "answer": "When a node fails in ElastiCache, a new node is provisioned upon failure, and upon failure of the primary node, ElastiCache will automatically promote an existing read replica to the primary role. For more details, visit understanding replication.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:26:42.931569"}}
{"question": "What are the differences in features, SLAs, and functionality between ElastiCache for Redis OSS and ElastiCache for Valkey?", "answer": "Both ElastiCache for Redis OSS and ElastiCache for Valkey offer the same features, SLAs, and functionality.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:26:42.932073"}}
{"question": "What are the three differences between ElastiCache for Valkey and ElastiCache for Redis OSS?", "answer": "First, ElastiCache Valkey offers faster scaling and 20% more memory efficiency than ElastiCache for Redis OSS. Second, ElastiCache Valkey is priced up to 33% lower than ElastiCache for Redis OSS. Lastly, ElastiCache Valkey uses Valkey, the open source project, which avoids vendor lock-in.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-11T15:26:48.375756"}}
{"question": "Why might someone choose ElastiCache Valkey over ElastiCache for Redis OSS?", "answer": "ElastiCache Valkey offers faster scaling, higher memory efficiency, lower pricing, and avoids vendor lock-in due to its use of the open source Valkey project.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-11T15:26:48.376102"}}
{"question": "How does the pricing of ElastiCache Valkey compare to ElastiCache for Redis OSS?", "answer": "ElastiCache Valkey is priced up to 33% lower than ElastiCache for Redis OSS.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-8", "source_tokens": 511, "generated_at": "2026-02-11T15:26:48.376588"}}
{"question": "What discount does ElastiCache Valkey receive compared to Redis OSS?", "answer": "ElastiCache Valkey receives a 20% discount relative to Redis OSS.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:26:54.700833"}}
{"question": "How does ElastiCache Valkey improve performance compared to ElastiCache for Redis OSS?", "answer": "ElastiCache Valkey delivers up to 100% more throughput and 50% lower P99 latency than ElastiCache version 7.0 for Redis OSS. It also achieves over 1 million requests per second per node or 500 million requests per second per cluster on r7g.4xlarge nodes or larger.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:26:54.701168"}}
{"question": "How does the performance of ElastiCache Valkey compare to ElastiCache for Redis OSS in terms of memory usage and latency?", "answer": "ElastiCache Valkey has a new hash table that results in up to 40% lower memory usage for node-based clusters with Cluster Mode compared to ElastiCache version 7.2 for Valkey and version 7.1 for Redis OSS. It also achieves microsecond read latency in the Serverless configuration, which scales to 5 million requests per second per cache in minutes, up to 5x faster than Valkey 7.2.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-9", "source_tokens": 450, "generated_at": "2026-02-11T15:26:54.701649"}}
{"question": "What metrics does ElastiCache provide to measure CPU utilization for Serverless deployments?", "answer": "ElastiCache provides the ElastiCache Processing Units (ECPU) metric to measure CPU utilization for ElastiCache Serverless deployments.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-11T15:26:59.618512"}}
{"question": "Why is it necessary to monitor both EngineCPUUtilization and CPUUtilization for ElastiCache?", "answer": "Both EngineCPUUtilization and CPUUtilization metrics are needed to get a detailed understanding of CPU utilization for ElastiCache as the main engine process uses only one CPU of the multiple CPU cores available on an instance, and CPUUtilization does not provide precise visibility into the CPU utilization rates at the process level.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-11T15:26:59.618866"}}
{"question": "What's the difference between CPUUtilization and EngineCPUUtilization in ElastiCache?", "answer": "CPUUtilization measures the CPU utilization for the entire instance, while EngineCPUUtilization measures the utilization at the engine process level.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-10", "source_tokens": 492, "generated_at": "2026-02-11T15:26:59.619347"}}
{"question": "How many read replicas can be created for a single primary cache node in ElastiCache Serverless?", "answer": "Five (5) read replicas can be created for a given primary cache node in ElastiCache Serverless.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-11T15:27:04.364744"}}
{"question": "Why would you deploy read replicas for a cache in ElastiCache Serverless?", "answer": "Read replicas can be deployed in ElastiCache Serverless for scalability, to serve read traffic when the primary node is unavailable, and for data protection scenarios.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-11T15:27:04.364981"}}
{"question": "What's the difference between connecting to a read replica and a primary cache node in ElastiCache Serverless (valkey or Redis with cluster mode disabled)?", "answer": "For Valkey or Redis OSS clusters with cluster mode disabled, you use the individual node endpoints for read operations (referred to as read endpoints in the API/CLI).", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-11", "source_tokens": 461, "generated_at": "2026-02-11T15:27:04.365374"}}
{"question": "What metric does ElastiCache provide to help you understand the inconsistency between a read replica and its primary cache node?", "answer": "ElastiCache emits a metric to help you understand the inconsistency between a read replica and its primary cache node.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-11T15:27:09.907052"}}
{"question": "Why might a read replica fall behind its primary cache node in terms of data consistency?", "answer": "A read replica may fall behind its primary cache node due to write I/O volume on the primary cache node exceeding the rate at which changes can be applied to the read replica, or due to network partitions or latency between the primary cache node and the read replica.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-11T15:27:09.907398"}}
{"question": "How does the billing for a primary cache node and a read replica differ?", "answer": "You are not charged for the data transfer incurred in replicating data between a primary cache node and a read replica. The billing for a read replica begins when it is successfully created and continues until you issue a command to delete it, at which point it is billed at the same standard ElastiCache cache node hour rates as a primary cache node.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-12", "source_tokens": 336, "generated_at": "2026-02-11T15:27:09.907928"}}
{"question": "What message is sent when the Test Failover API is called for a cache node group?", "answer": "A replication group message is sent.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-11T15:27:14.453235"}}
{"question": "How does ElastiCache handle failover and recovery process?", "answer": "During failover, ElastiCache flips the DNS record for the cache node to point at the read replica, which is then promoted to become the new primary. After failover, ElastiCache recovers the cache nodes.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-11T15:27:14.453606"}}
{"question": "Can a read replica be provisioned in a different AWS Region from the primary cache node?", "answer": "No, a read replica can only be provisioned in the same or different Availability Zone of the same Region as the primary cache node. However, ElastiCache's Global Datastore feature allows for creating cross-Region read replica clusters for low-latency reads and disaster recovery.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-13", "source_tokens": 319, "generated_at": "2026-02-11T15:27:14.454023"}}
{"question": "What is the role of a read replica during ElastiCache's initiated failover process?", "answer": "A read replica is promoted to become the new primary during ElastiCache's initiated failover process.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-11T15:27:18.819064"}}
{"question": "How does Multi-AZ feature work in ElastiCache for failover purposes?", "answer": "Multi-AZ is a feature in ElastiCache that automatically detects and promotes a read replica to become the new primary when a primary or an AZ fails.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-11T15:27:18.819430"}}
{"question": "How does ElastiCache's initiated failover compare to Multi-AZ's automatic failover?", "answer": "ElastiCache's initiated failover involves manually triggering the failover process, whereas Multi-AZ's automatic failover is an automated process triggered by a detected failure.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-14", "source_tokens": 426, "generated_at": "2026-02-11T15:27:18.819836"}}
{"question": "What happens when ElastiCache runs in Multi-AZ mode and the primary node fails?", "answer": "When ElastiCache runs in Multi-AZ mode and the primary node fails, automatic failover occurs, and one of the available read replicas is promoted to become the new primary. ElastiCache also spins up a new node to replace the promoted read replica in the same AZ of the failed primary.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T15:27:25.183238"}}
{"question": "Why is running ElastiCache in Multi-AZ mode beneficial for cache availability and administration?", "answer": "Running ElastiCache in Multi-AZ mode enhances availability and reduces the need for administration. ElastiCache offers a 99.99% availability SLA, and automatic failover is triggered when the primary node fails, minimizing downtime. Additionally, node failover and replacement are handled automatically.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T15:27:25.183715"}}
{"question": "What is the difference between running ElastiCache in Multi-AZ mode with both primary and read replicas in the same AZ and Multi-AZ mode with them in different AZs?", "answer": "When running ElastiCache with both the primary and read replicas in the same AZ, the ElastiCache replication group is not resilient to an AZ disruption. In Multi-AZ mode, with primary and read replicas in different AZs, ElastiCache can automatically failover to a read replica in another AZ in case of an AZ disruption.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-15", "source_tokens": 454, "generated_at": "2026-02-11T15:27:25.183969"}}
{"question": "What is the benefit of using multiple AZs for application architecture in the same AWS Region?", "answer": "Using multiple AZs for application architecture in the same AWS Region ensures low latency network connectivity between the AZs and provides redundancy for your application in the event of an AZ disruption.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T15:27:30.565889"}}
{"question": "What happens to ElastiCache snapshots when you delete an ElastiCache cache?", "answer": "When you delete an ElastiCache cache, your manual snapshots are retained, and you will have an option to create a final snapshot before the cache is deleted. Automatic cache snapshots are not retained.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T15:27:30.566188"}}
{"question": "Can you restore an ElastiCache for Redis OSS backup to ElastiCache for Memcached?", "answer": "No, you cannot restore an ElastiCache for Redis OSS backup to ElastiCache for Memcached. However, you can restore a backup taken from any version of ElastiCache for Redis OSS to the same version of ElastiCache for Redis OSS or ElastiCache for Redis Enterprise.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-16", "source_tokens": 441, "generated_at": "2026-02-11T15:27:30.566360"}}
{"question": "What enhancements does ElastiCache's engine offer compared to Valkey and Redis OSS for memory usage?", "answer": "ElastiCache's engine allows for more usable memory for applications with no increased swap usage during syncs and snapshots.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T15:27:34.351302"}}
{"question": "Why is encryption at rest an important feature in ElastiCache?", "answer": "Encryption at rest in ElastiCache guards against unauthorized access of data by encrypting the disk during sync, backup, and swap operations, as well as backups stored in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T15:27:34.351713"}}
{"question": "Can I use both encryption in transit and Role-Based Access Control (RBAC) in ElastiCache?", "answer": "Yes, you can select both encryption in transit and RBAC when creating your ElastiCache cache.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T15:27:34.351938"}}
{"question": "Which ElastiCache versions support Global Datastore for Memcached (Valley) and Redis OSS?", "answer": "Global Datastore is supported on ElastiCache version 7.2 for Memcached (Valley) and ElastiCache version 5.0.6 onward for Redis OSS.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-11T15:27:40.297799"}}
{"question": "What are the benefits of using Global Datastore in ElastiCache for applications with a global footprint?", "answer": "Global Datastore provides low-latency reads by replicating data across Regions in under one second, enabling geolocal reads closer to end users. In case of Regional degradation, a healthy cross-Region replica cache can be promoted to become the primary with full read and write capabilities, ensuring application availability.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-11T15:27:40.298139"}}
{"question": "What is the difference between automatic and manual failover in ElastiCache Global Datastore?", "answer": "ElastiCache doesn't automatically promote a secondary cluster to be the primary when the primary cluster (Region) is degraded. Instead, you can manually initiate the failover by promoting a secondary cluster to become the primary with full read and write capabilities. Once initiated, the failover and promotion of a secondary cluster typically completes in less than one minute.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-18", "source_tokens": 424, "generated_at": "2026-02-11T15:27:40.298638"}}
{"question": "What is the RPO of ElastiCache's Global Datastore typically?", "answer": "The RPO of ElastiCache's Global Datastore is typically under one second.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-11T15:27:44.597617"}}
{"question": "How does ElastiCache's Global Datastore handle data availability across Regions?", "answer": "ElastiCache's Global Datastore ensures that data written in a primary Region is available in secondary Regions within one second.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-11T15:27:44.597956"}}
{"question": "How does ElastiCache's performance compare to an ideal front end for data stores like Amazon RDS or DynamoDB?", "answer": "ElastiCache is an ideal front end for data stores like Amazon RDS or DynamoDB, providing a high-performance middle tier for applications with extremely high request rates or low latency requirements.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-19", "source_tokens": 371, "generated_at": "2026-02-11T15:27:44.598438"}}
{"question": "What standard Memcached operations are supported by ElastiCache?", "answer": "ElastiCache supports standard Memcached operations like get, set, incr, and decr.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-11T15:27:49.628474"}}
{"question": "How does updating the Memcached config file for ElastiCache work?", "answer": "To configure the cache servers your application accesses, update your application's Memcached config file to include the endpoints of the servers (nodes) provided by AWS. You can use the Copy Node Endpoints option in the console or the DescribeCacheClusters API to get a list of the endpoints.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-11T15:27:49.628751"}}
{"question": "What is the difference between using ElastiCache with and without an Amazon VPC?", "answer": "When using ElastiCache within an Amazon VPC, you can access the clusters from either the Amazon EC2 network or from your own data center. In contrast, when not using a VPC, ElastiCache uses DNS entries to allow client applications to locate servers (nodes), but the IP address of a node can change over time.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-20", "source_tokens": 324, "generated_at": "2026-02-11T15:27:49.629142"}}
{"question": "How many nodes can I run in a single AWS Region with ElastiCache?", "answer": "You can run a maximum of 300 nodes in a single AWS Region with ElastiCache.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-11T15:27:55.827907"}}
{"question": "What are the factors to consider when deciding on the initial configuration of ElastiCache?", "answer": "The two main factors to consider when deciding on the initial configuration of ElastiCache are the total memory required for your data to achieve your target cache-hit rate and the number of nodes required to maintain acceptable application performance without overloading the database backend in the event of node failures.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-11T15:27:55.828240"}}
{"question": "How does choosing the number of nodes in different Availability Zones (AZs) impact ElastiCache performance and fault tolerance?", "answer": "Choosing the number of nodes in different Availability Zones (AZs) can improve ElastiCache's fault tolerance by allowing the application to survive the loss of one or two nodes. This is because the remaining nodes can distribute the workload and maintain acceptable performance. Additionally, you can specify the number of nodes in each AZ or select 'Spread Nodes Across Zones' to automatically distribute the nodes across AZs. However, if the cluster is in Amazon VPC, nodes can only be placed in AZs that are part of the selected cache subnet group.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-21", "source_tokens": 409, "generated_at": "2026-02-11T15:27:55.828667"}}
{"question": "What happens when a node fails in ElastiCache and how does it affect DNS and IP addresses?", "answer": "When a node fails in ElastiCache, the service will repair the node by acquiring new resources and then redirect the node's DNS name to point to the new resources. For Amazon VPC installations, both the DNS name and IP address of the node remain the same. For non-Amazon VPC installations, only the DNS name remains the same, but the underlying IP address can change.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T15:28:02.406864"}}
{"question": "How does ElastiCache ensure application performance while improving the request volume for AWS services like RDS and DynamoDB?", "answer": "ElastiCache is ideally suited as a front end for AWS services like Amazon RDS and DynamoDB, providing extremely low latency for high-performance applications and offloading some of the request volume while these services provide long-lasting data durability.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T15:28:02.407203"}}
{"question": "What's the difference in handling DNS and IP addresses during node recovery between Amazon VPC and non-Amazon VPC installations in ElastiCache?", "answer": "In Amazon VPC installations, ElastiCache ensures that both the DNS name and IP address of the node remain the same during node recovery. In contrast, for non-Amazon VPC installations, only the DNS name remains the same, but the underlying IP address can change.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T15:28:02.407701"}}
{"question": "What is the role of Auto Discovery in ElastiCache?", "answer": "Auto Discovery is a feature in ElastiCache that enables automatic discovery of cache nodes by clients when they are added to or removed from an ElastiCache cluster. It saves developers time and effort, reduces complexity, and eliminates the need for manual updates and application downtime.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-11T15:28:08.885074"}}
{"question": "How does a client connect to an ElastiCache cluster using Auto Discovery?", "answer": "To connect to an ElastiCache cluster using Auto Discovery, the client first queries the configuration endpoint, which returns endpoints for all the nodes of the cluster. The client then connects to the cluster nodes using the Memcached protocol commands such as get, set, incr, and decr.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-11T15:28:08.885451"}}
{"question": "What is the difference between using a named endpoint and Auto Discovery in ElastiCache?", "answer": "When creating an ElastiCache cluster, you can use named endpoints for the nodes. With Auto Discovery, the cluster is also given a unique configuration endpoint, which contains the DNS Names of the nodes that belong to the cluster. The main difference is that with named endpoints, you need to manually update the list of cache node endpoints when there are changes in the cluster, while with Auto Discovery, clients automatically determine the current members of the ElastiCache cluster using the configuration endpoint, eliminating the need for manual updates.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-23", "source_tokens": 449, "generated_at": "2026-02-11T15:28:08.885653"}}
{"question": "What is required to download the ElastiCache Cluster Client?", "answer": "An ElastiCache account is necessary to download the ElastiCache Cluster Client. If you don't have an account, you can sign up from the ElastiCache detail page.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-11T15:28:13.803273"}}
{"question": " How does using the ElastiCache Cluster Client with Auto Discovery differ from using traditional Memcached clients?", "answer": "The ElastiCache Cluster Client with Auto Discovery enables automatic discovery of ElastiCache clusters. This feature is not available in traditional Memcached clients. Users of Memcached clients need to manually configure their clients to connect to ElastiCache.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-11T15:28:13.804503"}}
{"question": "Can a single ElastiCache cluster be connected to through both a client capable of Auto Discovery and a traditional Memcached client?", "answer": "Yes, a single ElastiCache cluster can be connected to through both a client capable of Auto Discovery and a traditional Memcached client at the same time.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-24", "source_tokens": 447, "generated_at": "2026-02-11T15:28:13.804754"}}
{"question": "What option do I use to disable Auto Discovery in ElastiCache?", "answer": "You can disable Auto Discovery by specifying the mode of operation during the ElastiCache Cluster client initialization.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-11T15:28:19.219293"}}
{"question": "How does ElastiCache's Engine Version Management function work for Memcached software upgrades?", "answer": "ElastiCache's Engine Version Management function allows you to control if and when your Memcached software powering your cluster is upgraded. Version upgrades involve some compatibility risk, so they will not occur automatically and must be initiated by you. ElastiCache offloads the work of patch application to you, giving you flexibility in managing version upgrades.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-11T15:28:19.219544"}}
{"question": "What are the differences between creating a new ElastiCache cluster with a new engine version and upgrading an existing cluster?", "answer": "Creating a new ElastiCache cluster with a new engine version lets you test the new version with your application before deciding whether or not to upgrade your original cluster. Upgrading an existing cluster, on the other hand, applies the new version immediately or during the next scheduled maintenance window.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-25", "source_tokens": 486, "generated_at": "2026-02-11T15:28:19.219703"}}
{"question": "What version of Memcached requires adjustment of max_chunk_size for slab_chunk_max during upgrades?", "answer": "Memcached version 1.4.33 or newer", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-11T15:28:22.424347"}}
{"question": "Why is it necessary to modify max_chunk_size during Memcached upgrades?", "answer": "To satisfy conditions needed for slab_chunk_max", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-11T15:28:22.424666"}}
{"question": "How does ElastiCache handle read replica promotion compared to Memcached?", "answer": "ElastiCache automatically promotes an existing read replica to the primary role in case of node failure, while Memcached requires designing your own cache to handle node failures", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-26", "source_tokens": 511, "generated_at": "2026-02-11T15:28:22.425203"}}
{"question": "What specific improvements to throughput and latency does ElastiCache's enhanced I/O threads provide?", "answer": "Enhanced I/O threads provide significant improvements to throughput and latency at scale through multiplexing, presentation layer offloading, and more. ElastiCache version 7.1 and above for Redis OSS extends this functionality to handle the presentation layer logic, improving thread efficiency and achieving up to 100% more throughput and 50% lower P99 latency compared to prior versions.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-11T15:28:29.391864"}}
{"question": "How does ElastiCache's enhanced I/O threads enhance Redis OSS performance?", "answer": "Enhanced I/O threads improve Redis OSS performance by using more cores for processing I/O, dynamically adjusting to the workload, offloading encryption to the same enhanced I/O threads, and handling the presentation layer logic to provide performance gains. This results in up to 100% more throughput and 50% lower P99 latency, and the ability to achieve over 1 million requests per second (RPS) per node on r7g.4xlarge or larger.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-11T15:28:29.392207"}}
{"question": "How does ElastiCache's enhanced I/O threads compare to previous versions in terms of performance?", "answer": "ElastiCache's enhanced I/O threads version 7.1 and above for Redis OSS significantly outperforms previous versions, achieving up to 100% more throughput and 50% lower P99 latency. On r7g.4xlarge or larger nodes, it can handle over 1 million requests per second (RPS) per node.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-27", "source_tokens": 291, "generated_at": "2026-02-11T15:28:29.392689"}}
{"question": "What metrics does ElastiCache provide to measure CPU utilization for cache deployments using ElastiCache Serverless?", "answer": "ElastiCache provides the ElastiCache Processing Units (ECPU) metric to measure CPU utilization for cache deployments using ElastiCache Serverless.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-11T15:28:35.115766"}}
{"question": "How does ElastiCache calculate the number of ECPUs required for a Redis OSS command based on vCPU time and data transferred?", "answer": "ElastiCache calculates the number of ECPUs required for a Redis OSS command based on the vCPU time taken by the command and the amount of data transferred. Each kilobyte (KB) of data transferred requires 1 ECPU.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-11T15:28:35.116081"}}
{"question": "What is the difference between the EngineCPUUtilization and CPUUtilization metrics for Redis OSS clusters?", "answer": "The CPUUtilization metric measures the CPU utilization for the instance (node), while the EngineCPUUtilization metric measures the utilization at the engine process level. The Redis OSS process is single threaded and uses just one CPU, so the CPUUtilization metric does not provide precise visibility into the CPU utilization rates at the engine process level.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-28", "source_tokens": 445, "generated_at": "2026-02-11T15:28:35.116288"}}
{"question": "What are the two primary purposes of read replicas in Redis OSS?", "answer": "Failure handling and read scaling are the two primary purposes of read replicas in Redis OSS.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-11T15:28:39.915782"}}
{"question": "How does using a read replica benefit read-heavy workloads in Redis OSS?", "answer": "Using a read replica in Redis OSS can benefit read-heavy workloads by distributing excess read traffic to the replica, allowing the primary node to focus on handling write traffic.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-11T15:28:39.916089"}}
{"question": "What's the difference between connecting to a read replica and a primary cache node in Redis OSS?", "answer": "In Redis OSS (cluster mode disabled), individual node endpoints are used for read operations on a cache cluster. In Redis OSS (cluster mode enabled), the cluster's configuration endpoint is used for all operations, but read traffic can still be directed to individual node endpoints.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-29", "source_tokens": 482, "generated_at": "2026-02-11T15:28:39.916586"}}
{"question": "What happens to read replicas during a failover in ElastiCache?", "answer": "Read replicas automatically resume replication once the failover has completed, acquiring updates from the newly promoted read replica.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-11T15:28:44.153376"}}
{"question": "Why can read replicas fall behind their primary cache nodes in ElastiCache?", "answer": "Read replicas can fall behind their primary cache nodes due to high write I/O volume, network partitions, or latency.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-11T15:28:44.153708"}}
{"question": "How does the billing for a primary cache node and its read replica differ in ElastiCache?", "answer": "Both the primary cache node and the read replica are billed at the same standard cache node hour rates. However, you are not charged for data transfer between the primary cache node and read replica.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-30", "source_tokens": 371, "generated_at": "2026-02-11T15:28:44.154204"}}
{"question": "What message is sent when the Test Failover API is called for a node group in ElastiCache?", "answer": "Replication group message: Test Failover API called for node group", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-11T15:28:49.131962"}}
{"question": "Why is it recommended to implement cache node connection retry at the application layer when using ElastiCache's automatic failover?", "answer": "It is recommended to implement cache node connection retry at the application layer while using ElastiCache's automatic failover to ensure quick resumption of cache operations after a failover event.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-11T15:28:49.132298"}}
{"question": "Can a read replica be provisioned in a different Region than the primary cache node in ElastiCache?", "answer": "No, a read replica can only be provisioned in the same or different Availability Zone (AZ) of the same Region as the primary cache node in ElastiCache. However, you can use the Global Datastore feature to create cross-Region read replica clusters forElastiCache to enable low-latency reads and disaster recovery across AWS Regions.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-31", "source_tokens": 345, "generated_at": "2026-02-11T15:28:49.132826"}}
{"question": "What happens if the ElastiCache primary node fails when running in Multi-AZ mode?", "answer": "When the ElastiCache primary node fails in Multi-AZ mode, ElastiCache will automatically detect the failure, select a read replica, and promote it to become the new primary. ElastiCache will also propagate the DNS changes of the promoted replica, allowing your application to continue writing to the primary endpoint.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-11T15:28:56.300433"}}
{"question": "Why is Multi-AZ mode beneficial for ElastiCache users in terms of availability and administration?", "answer": "Multi-AZ mode enhances ElastiCache availability and reduces the need for administration. When ElastiCache is running in Multi-AZ configuration, it becomes eligible for the 99.99% availability SLA. If a failure occurs, automatic failover completes the promotion of a read replica to be the new primary, limiting the impact on read and write capabilities. Furthermore, ElastiCache handles node failover and DNS propagation automatically.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-11T15:28:56.300819"}}
{"question": "What is the difference between Multi-AZ mode in ElastiCache and running a cache without Multi-AZ?", "answer": "The main difference is the enhanced availability and automatic administration provided by Multi-AZ mode. In Multi-AZ mode, ElastiCache is eligible for the 99.99% availability SLA, and automatic failover and DNS propagation occur upon primary node failure. In contrast, running a cache without Multi-AZ would require manual intervention for node failover and DNS updates.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-32", "source_tokens": 454, "generated_at": "2026-02-11T15:28:56.301314"}}
{"question": "What event is triggered when ElastiCache performs automatic failover?", "answer": "An event is created to inform users about automatic failover in ElastiCache.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-11T15:29:00.189195"}}
{"question": "How does ElastiCache determine which replica to promote during automatic failover?", "answer": "The replica with the smallest asynchronous replication lag to the primary is promoted during automatic failover in ElastiCache.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-11T15:29:00.189555"}}
{"question": "What are the benefits of creating snapshots for ElastiCache and how are they stored?", "answer": "Snapshots provide protection against data loss due to node failure and hardware failure. They are also useful for archiving purposes. ElastiCache stores snapshots in Amazon S3.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-33", "source_tokens": 417, "generated_at": "2026-02-11T15:29:00.189757"}}
{"question": "What is ElastiCache's snapshot retention period for manual backups?", "answer": "The retention period for manual ElastiCache backups can be up to 35 days.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-11T15:29:03.949073"}}
{"question": "How does ElastiCache handle snapshot restoration?", "answer": "When you choose a snapshot to restore, ElastiCache creates a new cache and populates it with the snapshot's data.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-11T15:29:03.949410"}}
{"question": "What are the differences between initiating a backup in the console, ElastiCache APIs, and AWS CLI?", "answer": "The only difference is the interface used to initiate the backup: console, APIs, or AWS CLI.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-34", "source_tokens": 418, "generated_at": "2026-02-11T15:29:03.949602"}}
{"question": "What aspects of ElastiCache are encrypted when encryption at rest is enabled?", "answer": "Encryption at rest encrypts the disk during sync, backup, and swap operations, as well as backups stored in Amazon S3.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-11T15:29:08.971187"}}
{"question": "How does ElastiCache's encryption at rest enhance security compared to Redis OSS?", "answer": "ElastiCache's encryption at rest guards against unauthorized access of your data and encrypts aspects like disk during sync, backup, and swap operations, as well as backups stored in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-11T15:29:08.971531"}}
{"question": "What's the difference between ElastiCache's encryption at rest and encryption in transit?", "answer": "Encryption at rest encrypts data at rest, specifically the disk during sync, backup, and swap operations, as well as backups stored in Amazon S3. Encryption in transit encrypts communications between clients and ElastiCache, as well as between the servers (primary and read replicas).", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-35", "source_tokens": 510, "generated_at": "2026-02-11T15:29:08.972047"}}
{"question": "In how many Regions can you replicate a Global Datastore for ElastiCache?", "answer": "You can replicate a Global Datastore for ElastiCache to up to two secondary Regions.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-11T15:29:13.683029"}}
{"question": "What is the purpose of using Global Datastore for ElastiCache with a global footprint application?", "answer": "The purpose of using Global Datastore for ElastiCache with a global footprint application is to enable low-latency reads and disaster recovery across Regions, increasing the responsiveness of your applications by providing geolocal reads closer to end users.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-11T15:29:13.683360"}}
{"question": "How does Global Datastore for ElastiCache compare to automatic promotion of a secondary cluster?", "answer": "Global Datastore for ElastiCache allows for manual promotion of a secondary cluster to become a primary in the event of Regional degradation, while ElastiCache doesn't automatically promote a secondary cluster in this situation.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-36", "source_tokens": 397, "generated_at": "2026-02-11T15:29:13.683919"}}
{"question": "What is the typical RPO of ElastiCache's Global Datastore?", "answer": "The typical RPO of ElastiCache's Global Datastore is under one second.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-11T15:29:18.505669"}}
{"question": "How does data tiering in ElastiCache impact application performance?", "answer": "Data tiering in ElastiCache can result in an additional 300Âµs latency on average for requests to data stored on SSD compared to requests to data in memory.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-11T15:29:18.506005"}}
{"question": "How does ElastiCache's data tiering compare to memory-only nodes in terms of price savings and storage capacity?", "answer": "ElastiCache's data tiering with memory and SSDs can help you achieve over 60% savings in price when running at maximum use compared to ElastiCache's memory-only nodes. R6gd nodes with memory and SSDs have nearly 5x more total storage capacity.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-37", "source_tokens": 508, "generated_at": "2026-02-11T15:29:18.506466"}}
{"question": "What versions of ElastiCache for Redis support data tiering?", "answer": "ElastiCache for Redis OSS versions 6.2 and above support data tiering.", "question_type": "factual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-11T15:29:21.853052"}}
{"question": "How does ElastiCache support data tiering on Redis OSS clusters?", "answer": "ElastiCache supports data tiering on clusters using R6gd nodes.", "question_type": "conceptual", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-11T15:29:21.853394"}}
{"question": "How does the cost of ElastiCache clusters with data tiering compare to those without?", "answer": "The only additional cost for using data tiering is the node's hourly cost.", "question_type": "comparison", "metadata": {"service": "ELASTICACHE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticache-faq-38", "source_tokens": 149, "generated_at": "2026-02-11T15:29:21.853918"}}
{"question": "What programming languages and development stacks does AWS Elastic Beanstalk currently support?", "answer": "AWS Elastic Beanstalk currently supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker web applications. It also supports Apache Tomcat for Java applications, Apache HTTP Server for PHP and Python applications, Nginx or Apache HTTP Server for Node.js applications, Passenger or Puma for Ruby applications, Microsoft IIS for .NET applications, and Java SE and Go.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-11T15:29:27.738858"}}
{"question": "How can AWS Elastic Beanstalk be described for developers who want to quickly deploy and manage applications in the AWS Cloud?", "answer": "AWS Elastic Beanstalk is a service that makes it easier for developers to deploy and manage applications in the AWS Cloud by handling the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-11T15:29:27.739205"}}
{"question": "How does AWS Elastic Beanstalk for Go applications compare to its support for Java applications?", "answer": "Both Go and Java applications are supported in AWS Elastic Beanstalk, but the specific runtime environments and server configurations may differ. For instance, Java applications use Apache Tomcat, while Go applications do not have a specific application server required.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-0", "source_tokens": 389, "generated_at": "2026-02-11T15:29:27.739752"}}
{"question": "What operating systems can I choose from when using AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk allows you to select the operating system that matches your application requirements, such as Amazon Linux or Windows Server 2016.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-11T15:29:33.137699"}}
{"question": "How does AWS Elastic Beanstalk compare to other application container or PaaS solutions regarding developers' control and flexibility?", "answer": "Unlike most existing application container or PaaS solutions that significantly diminish developersâ€™ flexibility and control, AWS Elastic Beanstalk allows developers to retain full control over the AWS resources powering their application and seamlessly manage various elements of their infrastructure.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-11T15:29:33.137917"}}
{"question": "What are some benefits of using different Amazon EC2 instances with AWS Elastic Beanstalk?", "answer": "By choosing from several Amazon EC2 instances including On-Demand, Reserved instances, and Spot instances, you can quickly improve application reliability by running in more than one Availability Zone and enhance application security by enabling HTTPS protocol on the load balancer, access built-in Amazon CloudWatch monitoring, and get notifications on application health and other important events.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-1", "source_tokens": 501, "generated_at": "2026-02-11T15:29:33.138097"}}
{"question": "Which operating systems does AWS Elastic Beanstalk support for its environments?", "answer": "AWS Elastic Beanstalk runs on the Amazon Linux AMI and the Windows Server AMI.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-11T15:29:37.569270"}}
{"question": "How does AWS Elastic Beanstalk handle deployment of non-web applications?", "answer": "Although AWS Elastic Beanstalk is ideal for web applications, its open architecture allows for the deployment of non-web applications as well.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-11T15:29:37.569645"}}
{"question": "What operating systems does Amazon Web Services provide for the Amazon EC2 Cloud computing and which one does AWS Elastic Beanstalk use?", "answer": "Amazon Web Services supports and maintains both the Amazon Linux AMI and the Windows Server AMI for Amazon EC2. AWS Elastic Beanstalk uses one of these two AMIs to create a stable, secure, and high-performance execution environment.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-2", "source_tokens": 470, "generated_at": "2026-02-11T15:29:37.570055"}}
{"question": "What service does AWS Elastic Beanstalk use for storing application files and log files?", "answer": "AWS Elastic Beanstalk uses Amazon S3 for storing application files and, optionally, server log files.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-11T15:29:41.872337"}}
{"question": "Why is it beneficial to include the AWS SDK as part of an application's deployable file?", "answer": "Including the AWS SDK as part of an application's deployable file makes it easier to use Amazon S3 for application storage.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-11T15:29:41.872669"}}
{"question": "What are the differences in database options when using AWS Elastic Beanstalk?", "answer": "AWS Elastic Beanstalk supports Amazon RDS, Amazon DynamoDB, and other relational databases running on Amazon EC2, and allows users to specify the connection information in the environment configuration.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-3", "source_tokens": 494, "generated_at": "2026-02-11T15:29:41.873197"}}
{"question": "What document should I refer to for more information about AWS security processes?", "answer": "Amazon Web Services: Overview of Security Processes", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:29:45.671688"}}
{"question": "How can I control access to AWS Elastic Beanstalk for different IAM users?", "answer": "You can grant IAM users access to AWS Elastic Beanstalk by using policies. The IAM console offers read-only and full-access templates, or you can use the AWS Policy Generator to create custom policies.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:29:45.671917"}}
{"question": "What's the difference between granting read-only access and full access to IAM users for AWS Elastic Beanstalk?", "answer": "Read-only access grants read access to Elastic Beanstalk resources, while full access grants full access to all Elastic Beanstalk operations and permissions to manage dependent resources.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:29:45.672057"}}
{"question": "What are the three ways an IAM user can access AWS Elastic Beanstalk?", "answer": "An IAM user can access the AWS Elastic Beanstalk console using their username and password, use their access key and secret key to perform operations using the Elastic Beanstalk API, or use their access key and secret key to perform operations using the AWS Elastic Beanstalk command line interface (CLI).", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T15:29:50.794744"}}
{"question": "Why can't AWS Elastic Beanstalk automatically perform major platform version updates?", "answer": "AWS Elastic Beanstalk cannot automatically perform major platform version updates because they include backwards incompatible changes and require additional testing.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T15:29:50.795110"}}
{"question": "How does updating to a new major version of an AWS Elastic Beanstalk platform differ from updating to a new minor or patch version?", "answer": "Updating to a new major version of an AWS Elastic Beanstalk platform requires manual initiation because it includes backwards incompatible changes and requires additional testing. Updating to a new minor or patch version can be done automatically.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-5", "source_tokens": 495, "generated_at": "2026-02-11T15:29:50.795599"}}
{"question": "What mechanism does AWS Elastic Beanstalk use to apply updates?", "answer": "AWS Elastic Beanstalk uses an immutable deployment mechanism to apply updates, ensuring availability during maintenance windows and no impact on consumers.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T15:29:55.232009"}}
{"question": "Why does AWS Elastic Beanstalk use an immutable deployment mechanism for updates?", "answer": "AWS Elastic Beanstalk uses an immutable deployment mechanism for updates to maintain application availability during the maintenance window and minimize impact on end users.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T15:29:55.232254"}}
{"question": "How does the immutable deployment mechanism for updates compare to a mutable one?", "answer": "An immutable deployment mechanism, like the one used for updates in AWS Elastic Beanstalk, ensures application availability during the maintenance window and minimizes impact on end users. A mutable deployment mechanism, on the other hand, may require downtime and could impact end users.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T15:29:55.232651"}}
{"question": "What type of events are tagged with 'MAINTENANCE' in the Elastic Beanstalk events page when there is a managed platform update?", "answer": "Events related to managed platform updates are tagged with 'MAINTENANCE' in the Elastic Beanstalk events page.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-11T15:30:01.568964"}}
{"question": "Why do you need to update the build command when deploying a workload written in Go or .Net Core to Elastic Beanstalk's arm64 instance type?", "answer": "You need to update the build command for Go or .Net Core workloads to deploy them on Elastic Beanstalk's arm64 instance type. This is required due to the need to recompile binary dependencies or use arm64-compatible releases of binary dependencies for these languages.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-11T15:30:01.569222"}}
{"question": "What are the main differences between deploying an application on Elastic Beanstalk's x86 and arm64 instance types, regarding required updates and compatibility?", "answer": "For x86 instance types, there is no need to recompile the workload or update the build command, while for arm64 instance types, you need to update the build command for Go or .Net Core workloads and recompile binary dependencies or use arm64-compatible releases of binary dependencies. Docker images must also be multi-architecture and support both x86 and arm64.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-7", "source_tokens": 502, "generated_at": "2026-02-11T15:30:01.569403"}}
{"question": "What is the pricing model for AWS Elastic Beanstalk?", "answer": "You pay only for the AWS resources actually used to store and run your application with AWS Elastic Beanstalk.", "question_type": "factual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-11T15:30:05.437638"}}
{"question": "How does AWS Support cover issues with AWS Elastic Beanstalk?", "answer": "AWS Support covers issues related to your use of AWS Elastic Beanstalk.", "question_type": "conceptual", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-11T15:30:05.437997"}}
{"question": "How does AWS Elastic Beanstalk's pricing compare to other AWS services like Amazon EC2 or S3?", "answer": "With AWS Elastic Beanstalk, you pay only for the AWS resources actually used to store and run your application, while for Amazon EC2 and S3, you can find pricing information on their respective detail pages.", "question_type": "comparison", "metadata": {"service": "ELASTICBEANSTALK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "elasticbeanstalk-faq-8", "source_tokens": 214, "generated_at": "2026-02-11T15:30:05.438202"}}
{"question": "What are the advantages of using Amazon EMR on Amazon EC2 over traditional on-premises solutions?", "answer": "Amazon EMR on Amazon EC2 offers several advantages over traditional on-premises solutions. It allows you to run petabyte-scale analysis at less than half the cost and over 1.7x faster than standard Apache Spark. It lets you focus on transforming and analyzing your data without worrying about managing compute capacity or open-source applications. You can instantly provision as much or as little capacity as you like and set up scaling rules to manage changing compute demand. It also offers optimized runtimes which speed your analysis and save time and money.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:30:13.235129"}}
{"question": "How does Amazon EMR help with security and data access control while developing and debugging?", "answer": "Amazon EMR helps with security and data access control while developing and debugging by letting you set up CloudWatch alerts to notify you of changes in your infrastructure and take actions immediately. It also allows you to use Kubernetes for security and access control.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:30:13.235493"}}
{"question": "What's the difference between deploying workloads to Amazon EMR on Amazon EC2 and Amazon Elastic Kubernetes Service (EKS)?", "answer": "Both Amazon EMR on Amazon EC2 and Amazon Elastic Kubernetes Service (EKS) allow you to deploy and manage workloads on Amazon EMR. However, with Amazon EMR on Amazon EC2, you run your workloads on Amazon EC2 instances and manage them using the EMR Console, API, SDK or CLI, and orchestrate them using Amazon Managed Workflows for Apache Airflow (MWAA) or AWS Step Functions. With Amazon EKS, you run your workloads on Amazon EKS clusters and manage them using Kubernetes.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-0", "source_tokens": 469, "generated_at": "2026-02-11T15:30:13.235994"}}
{"question": "What services do you need to be signed up for to use Amazon EMR?", "answer": "You need to be signed up for Amazon EC2 and Amazon S3 to access Amazon EMR.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T15:30:18.142057"}}
{"question": "How can you use Amazon EMR Studio for data processing?", "answer": "You can develop, visualize and debug data science and data engineering applications written in R, Python, Scala, and PySpark in Amazon EMR Studio. You can also run a data processing job on your desktop and run it on Amazon EMR.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T15:30:18.142392"}}
{"question": "What is the difference between using the Command Line Tools or APIs and the AWS Management Console for Amazon EMR?", "answer": "The Command Line Tools or APIs allow you to programmatically launch and monitor clusters, create additional functionality around clusters, or build value-added tools for other Amazon EMR customers. In contrast, the AWS Management Console provides an easy-to-use graphical interface for launching and monitoring clusters directly from a web browser.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-1", "source_tokens": 456, "generated_at": "2026-02-11T15:30:18.142593"}}
{"question": "What can you do with an SNS topic after your Amazon EMR cluster finishes?", "answer": "You can have your Amazon EMR cluster post to your SNS topic when it is finished. You can also view your cluster progress on the AWS Management Console or use the Command Line, SDK, or APIs to get a status on the cluster.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-11T15:30:23.198996"}}
{"question": "Why is using a custom Amazon Linux 2 AMI in Amazon EMR beneficial?", "answer": "Using a custom Amazon Linux 2 AMI in Amazon EMR allows you to perform sophisticated pre-configuration for virtually any application. This can be particularly useful if you have complex configuration requirements.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-11T15:30:23.199338"}}
{"question": "What are the differences between using Bootstrap Actions and the Hadoop distributed cache mechanism for installing third-party software on an Amazon EMR cluster?", "answer": "Bootstrap Actions are used to install third-party software packages on your cluster. The Hadoop distributed cache mechanism, on the other hand, is used to upload statically compiled executables to the cluster.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-2", "source_tokens": 414, "generated_at": "2026-02-11T15:30:23.199786"}}
{"question": "What programming languages can be used in EMR Studio?", "answer": "EMR Studio supports the use of R, Python, Scala, and PySpark", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:30:27.584561"}}
{"question": "How does collaboration work in EMR Studio?", "answer": "EMR Studio allows users to collaborate by sharing notebooks via GitHub and other repositories and chaining notebooks in scheduled workflows using workflow orchestration services", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:30:27.584895"}}
{"question": "How does EMR Studio compare to using the AWS Console and Apache Airflow for data processing?", "answer": "EMR Studio offers the ability to log in directly to managed Jupyter notebooks using corporate credentials, start notebooks quickly, customize environments, collaborate with peers, and debug clusters and jobs using native application interfaces, while the AWS Console and Apache Airflow require more manual setup and configuration", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:30:27.585394"}}
{"question": "What is required to access EMR Studio without using the AWS Management Console?", "answer": "Your team can log in to EMR Studio directly using corporate credentials provided by an administrator after they set up the Studio.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-11T15:30:32.360881"}}
{"question": "Why is using EMR Studio outside of the AWS Management Console beneficial?", "answer": "EMR Studio is beneficial because it allows access without requiring users to have access to the AWS Management Console and provides a simplified user interface.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-11T15:30:32.361158"}}
{"question": "What are the main differences between using EMR Studio and Amazon SageMaker Studio in terms of accessing resources and performing tasks?", "answer": "EMR Studio allows team members to log in directly using corporate credentials and access resources configured by an administrator without needing to access the AWS Management Console. Amazon SageMaker Studio, on the other hand, gives users complete access, control, and visibility into each step required to build, train, and deploy models in a single web-based interface.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-4", "source_tokens": 505, "generated_at": "2026-02-11T15:30:32.361558"}}
{"question": "What is the role of AWS IAM Identity Center in managing EMR Studio's single sign-on service?", "answer": "AWS IAM Identity Center is the single sign-on service provider for EMR Studio.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-11T15:30:36.650875"}}
{"question": "How does linking a GitHub repository to a Workspace benefit the user?", "answer": "Linking a GitHub repository to a Workspace allows the user to save their notebooks in a version controlled environment.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-11T15:30:36.651154"}}
{"question": "What's the difference between saving a Workspace without attaching it to a cluster and attaching it to a cluster?", "answer": "A Workspace can be saved and configured before connecting it to a cluster. However, to execute queries, it needs to be attached to a cluster with the performance-optimized Amazon EMR runtime for Apache Spark.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-5", "source_tokens": 454, "generated_at": "2026-02-11T15:30:36.651364"}}
{"question": "What are the two ways to create an EMR cluster in EMR Studio?", "answer": "You can create an EMR cluster in EMR Studio by using a pre-configured cluster template via AWS Service Catalog or by specifying the cluster name, number of instances, and instance type.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-11T15:30:42.195294"}}
{"question": "How does one detach and then re-attach a cluster to an EMR studio?", "answer": "To detach a cluster from an EMR studio, you can press the â€˜Detachâ€™ button, select the cluster from the â€˜Select clusterâ€™ drop-down list, and then press the â€˜Attachâ€™ button. This process allows you to re-associate the cluster with a different EMR studio.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-11T15:30:42.195568"}}
{"question": "What are the differences in creating an EMR cluster via AWS Service Catalog and specifying the cluster details?", "answer": "Creating an EMR cluster using a pre-configured cluster template via AWS Service Catalog and specifying the cluster name, number of instances, and instance type are two different methods for creating an EMR cluster in EMR Studio. The former utilizes pre-configured templates, while the latter provides more customization options.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-6", "source_tokens": 442, "generated_at": "2026-02-11T15:30:42.195931"}}
{"question": "What is the recommended tool for new AWS customers to use for data processing and analysis?", "answer": "Amazon EMR Studio is the recommended tool for new AWS customers to use for data processing and analysis.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-11T15:30:47.965375"}}
{"question": "What capabilities does EMR Notebooks provide for data scientists and analysts?", "answer": "EMR Notebooks provide a managed environment for data scientists, analysts, and developers to prepare and visualize data, collaborate with peers, build applications, and perform interactive analysis using EMR clusters. They also come prepackaged with libraries from the Anaconda repository and have integrated Spark monitoring capabilities.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-11T15:30:47.965598"}}
{"question": "How does using EMR Notebooks for data processing and analysis compare to using EMR Studio?", "answer": "Both EMR Notebooks and EMR Studio are tools provided by AWS for data processing and analysis. EMR Notebooks are a managed environment based on Jupyter Notebooks that allow you to build Apache Spark applications and run interactive queries on your EMR cluster, with prepackaged libraries and integrated Spark monitoring capabilities. EMR Studio, on the other hand, is a separate tool recommended for new customers, but EMR Notebooks are also supported for compatibility.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-7", "source_tokens": 490, "generated_at": "2026-02-11T15:30:47.965996"}}
{"question": "What method does Amazon EMR use to transfer logs to Amazon S3?", "answer": "Amazon EMR transfers logs to Amazon S3 using built-in features of Amazon EMR.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-11T15:30:52.101335"}}
{"question": "Why are logs in Amazon EMR placed in Amazon S3 and not on the cluster?", "answer": "Logs in Amazon EMR are placed in Amazon S3 to ensure their persistence and availability for future use.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-11T15:30:52.101584"}}
{"question": "How does the billing for Amazon EMR compare to Amazon EC2?", "answer": "Amazon EMR billing commences when the cluster is ready to execute steps and ends when you request to shut down the cluster. In contrast, Amazon EC2 billing begins as soon as the instance is launched and ends when the instance is terminated.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-8", "source_tokens": 439, "generated_at": "2026-02-11T15:30:52.101959"}}
{"question": "What is the meaning of Normalized Instance Hours in the context of AWS EMR?", "answer": "Normalized Instance Hours is an approximation of the compute time used by an AWS EMR cluster, based on the standard of 1 hour of m1.small usage = 1 hour normalized compute time.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-11T15:30:57.095289"}}
{"question": "How many Normalized Instance Hours are displayed for a 10-node r3.8xlarge cluster running for 1 hour?", "answer": "The total number of Normalized Instance Hours displayed for a 10-node r3.8xlarge cluster running for 1 hour would be 640 (10 nodes x 64 normalization factor x 1 hour).", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-11T15:30:57.095568"}}
{"question": "What is the difference between Normalized Instance Hours and billable Amazon EMR usage?", "answer": "Normalized Instance Hours is an approximate number displayed on the console for the compute time used by an AWS EMR cluster, while billable Amazon EMR usage is the actual amount charged.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-9", "source_tokens": 338, "generated_at": "2026-02-11T15:30:57.095929"}}
{"question": "What security groups does Amazon EMR use by default for its instances?", "answer": "Amazon EMR uses two security groups by default: one for the master instance and another for the other cluster nodes.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-11T15:31:01.063323"}}
{"question": "How does Amazon EMR manage security for data transfer between Amazon S3 and Amazon EC2?", "answer": "Amazon EMR uses HTTPS to securely transfer data between Amazon S3 and Amazon EC2.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-11T15:31:01.063658"}}
{"question": "What is the difference in access control between Amazon EMR and Amazon S3 by default?", "answer": "By default, only the customer who uploads data to Amazon S3 can access it, while Amazon EMR instances are isolated in their own security groups and by default do not allow external access.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-10", "source_tokens": 420, "generated_at": "2026-02-11T15:31:01.064167"}}
{"question": "What is the default instance profile used by Amazon EMR application processes when they call other AWS services?", "answer": "Amazon EMR application processes use EC2 instance profiles by default when they call other AWS services.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:31:07.515273"}}
{"question": "How can you define and manage fine-grained authorization policies for accessing Amazon S3 data in Amazon EMR?", "answer": "You can define and manage fine-grained authorization policies in AWS Lake Formation or Apache Ranger to access databases, tables, and columns in AWS Glue Data Catalog.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:31:07.515613"}}
{"question": "What are the differences between integrating Amazon EMR with AWS Lake Formation and Apache Ranger in terms of managing authorization policies and accessing AWS resources?", "answer": "Integration with AWS Lake Formation enables you to define and manage fine-grained authorization policies in AWS Lake Formation, enforce the policies on jobs submitted through Amazon EMR Notebooks and Apache Zeppelin, and send auditing events to AWS CloudTrail and enable federated Single Sign-On. Native integration with Apache Ranger allows you to set up a new or existing Apache Ranger server to define and manage fine-grained authorization policies for users to access databases, tables, and columns of Amazon S3 data via Hive Metastore. Amazon EMR User Role Mapper allows you to leverage AWS IAM permissions to manage accesses to AWS resources through AWS Labs.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:31:07.515989"}}
{"question": "In which Availability Zone does Amazon EMR launch nodes by default for a given cluster?", "answer": "Amazon EMR launches nodes for a given cluster in the Availability Zone with the most available resources by default.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-11T15:31:13.244983"}}
{"question": "Why does Amazon EMR perform better when running in the same Availability Zone as the data?", "answer": "Running Amazon EMR in the same Availability Zone as the data improves performance because it reduces network latency and allows for faster data transfer between the cluster and data storage.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-11T15:31:13.245210"}}
{"question": "What are the differences between Amazon EMR on Amazon EC2, Amazon EMR on Amazon EKS, and Amazon EMR on AWS Outposts?", "answer": "Amazon EMR on Amazon EC2 is a managed service for running big data processing jobs using Amazon EMR's managed Apache Hadoop environment. Amazon EMR on Amazon EKS is a managed service for running Kubernetes-based big data and machine learning workloads using Amazon EMR's managed Kubernetes environment. Amazon EMR on AWS Outposts is a fully managed, extendable on-premises version of Amazon EMR that allows customers to run workloads on their own infrastructure while still benefiting from AWS services and integrations.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-12", "source_tokens": 433, "generated_at": "2026-02-11T15:31:13.245731"}}
{"question": "What type of node is responsible for managing the cluster and coordinating the distribution of data and tasks among other nodes?", "answer": "Master node", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-11T15:31:17.897632"}}
{"question": "Can you explain how different types of nodes in an Amazon EMR cluster contribute to processing and data storage?", "answer": "The master node manages the cluster and coordinates the distribution of data and tasks among other nodes (core and task nodes). Core nodes run tasks and store data in the Hadoop Distributed File System (HDFS), while task nodes only run tasks and do not store data. ", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-11T15:31:17.897854"}}
{"question": "How does the state of a step in an Amazon EMR cluster compare to the state of the cluster itself?", "answer": "A step can be in the states of PENDING, RUNNING, COMPLETED, CANCELLED, FAILED, while the cluster can be in the states of STARTING, BOOTSTRAPPING, RUNNING, WAITING, TERMINATING, TERMINATED, TERMINATED_WITH_ERRORS. ", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-13", "source_tokens": 467, "generated_at": "2026-02-11T15:31:17.898019"}}
{"question": "What information does one need to provide when launching a cluster through the AWS Management Console?", "answer": "When launching a cluster through the AWS Management Console, one needs to specify the name of the cluster, the location of the input data in Amazon S3, the processing application, the desired data output location, and the number and type of Amazon EC2 instances.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-11T15:31:23.778003"}}
{"question": "Why is it necessary to specify the location of input data and processing application in Amazon S3 when launching a cluster?", "answer": "The input data and processing application are pulled by Amazon EMR into the launched Amazon EC2 instances using the S3 URI scheme. Once the cluster is finished, the output data is transferred back to Amazon S3, where it can be retrieved or used as input in another cluster.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-11T15:31:23.778263"}}
{"question": "How does the use of Amazon S3 in EMR impact the process of launching and managing clusters?", "answer": "Amazon S3 plays a crucial role in the process of launching and managing Amazon EMR clusters. The input data and processing application are stored in Amazon S3 and are pulled by the launched Amazon EC2 instances using the S3 URI scheme. Once the cluster is finished, the output data is transferred back to Amazon S3 for retrieval or use in another cluster.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-14", "source_tokens": 393, "generated_at": "2026-02-11T15:31:23.778405"}}
{"question": "What programming model does Amazon EMR use for computations?", "answer": "Amazon EMR uses the MapReduce programming model for computations.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-11T15:31:27.799023"}}
{"question": "How does Amazon EMR handle the failure of a master node?", "answer": "Amazon EMR automatically fails over to a standby master node if the primary master node fails or if critical processes crash. This feature ensures that long-lived clusters run without interruption.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-11T15:31:27.799270"}}
{"question": "What is the difference between a master node and a core node in Amazon EMR?", "answer": "A master node is responsible for managing and coordinating tasks among the other nodes in the cluster, while a core node is used for running the map and reduce functions on the data it has been allocated.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-15", "source_tokens": 498, "generated_at": "2026-02-11T15:31:27.799638"}}
{"question": "What language can I use to write a Bootstrap Action script in Amazon EMR?", "answer": "You can write a Bootstrap Action script in any language already installed on the cluster instance including Bash, Perl, Python, Ruby, C++, or Java.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-11T15:31:32.055876"}}
{"question": "How does using a Bootstrap Action benefit my Amazon EMR cluster?", "answer": "Bootstrap Actions allow you to install software or configure instances before running your cluster, enabling customized settings for specific memory and processing requirements.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-11T15:31:32.056122"}}
{"question": "What's the difference between a core node and a task node in Amazon EMR?", "answer": "Core nodes host persistent data using Hadoop Distributed File System (HDFS) and run Hadoop tasks, while task nodes only run Hadoop tasks.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-16", "source_tokens": 473, "generated_at": "2026-02-11T15:31:32.056514"}}
{"question": "What are the roles of core and task nodes in an Amazon EMR cluster?", "answer": "Core nodes host persistent data in HDFS and cannot be removed, making them ideal for long-term capacity requirements. Task nodes, on the other hand, can be added or removed and do not contain HDFS, making them suitable for temporary capacity needs.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-11T15:31:36.759151"}}
{"question": "Why would you consider increasing the number of core nodes in an Amazon EMR cluster?", "answer": "You might want to increase the number of core nodes to improve cluster performance if it's running slower than expected, or if timing requirements change.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-11T15:31:36.759488"}}
{"question": "How does launching task instance fleets on Spot Instances affect the number of nodes in an Amazon EMS cluster?", "answer": "Launching task instance fleets on Spot Instances allows you to increase capacity while minimizing costs without affecting the number of core nodes, as task nodes are ideal for temporary capacity needs.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-17", "source_tokens": 508, "generated_at": "2026-02-11T15:31:36.759984"}}
{"question": "What tags does Amazon EMR add to the underlying EC2 instances?", "answer": "Amazon EMR adds two system tags to the underlying EC2 instances: aws:elasticmapreduce:instance-group-role and aws:elasticmapreduce:job-flow-id.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-11T15:31:42.025045"}}
{"question": "Why should you use IAM policies for Amazon EC2 when using Amazon EMR's tagging functionality?", "answer": "You should grant permission to use the Amazon EC2 tagging APIs CreateTags and DeleteTags in your IAM policy if you plan to use Amazon EMR's tagging functionality, as the EMR tags will also be applied to the related EC2 instances.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-11T15:31:42.025379"}}
{"question": "How does tagging work in Amazon EMR compared to EC2?", "answer": "In Amazon EMR, tags are added and removed from the console, CLI, or API to ensure that the cluster and its associated EC2 instances have the correct tags. In contrast, you can add or remove tags directly on the EC2 instances, but the changes will not be synced with Amazon EMR.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-18", "source_tokens": 499, "generated_at": "2026-02-11T15:31:42.025924"}}
{"question": "Which open-source frameworks can be used with EMR Serverless?", "answer": "Data engineers, analysts, and scientists can use EMR Serverless to build applications using open-source frameworks such as Apache Spark and Apache Hive.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-11T15:31:46.940872"}}
{"question": "What are the benefits of using EMR Studio with EMR Serverless?", "answer": "EMR Studio can be used with EMR Serverless to submit jobs, track job status, and build data pipelines. Users can sign into the AWS Management Console, navigate to Amazon EMR under the Analytics category, and select Amazon EMR Serverless to get started.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-11T15:31:46.941213"}}
{"question": "How does EMR Serverless in Asia Pacific (Mumbai) compare to EMR Serverless in Europe (London) in terms of availability?", "answer": "Both Asia Pacific (Mumbai) and Europe (London) regions support EMR Serverless. However, the text passage does not provide information on the specific availability or performance differences between these two regions.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-19", "source_tokens": 403, "generated_at": "2026-02-11T15:31:46.941735"}}
{"question": "Which AWS services does Amazon EMR support for running applications?", "answer": "Amazon EMR supports running applications on EC2 based clusters, EKS clusters, Outposts, and Serverless.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-11T15:31:51.615273"}}
{"question": "What are the advantages of using Amazon EMR on EC2 clusters compared to EMR Serverless?", "answer": "With Amazon EMR on EC2 clusters, customers can choose the EC2 instance type, customize the Linux AMI, EC2 instance configuration, customize and extend open-source frameworks, and install additional custom software on cluster instances. In contrast, EMR Serverless is designed for customers who want to avoid managing and operating clusters and prefer to run applications using open-source frameworks.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-11T15:31:51.615625"}}
{"question": "Which open-source frameworks can be used with Amazon EMR on EKS?", "answer": "Amazon EMR on EKS supports multiple open-source frameworks, including Spark and Hive.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-20", "source_tokens": 498, "generated_at": "2026-02-11T15:31:51.616082"}}
{"question": "What release labels does EMR Serverless support for EMR?", "answer": "EMR Serverless supports EMR release labels 6.6 and above.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-11T15:31:56.179559"}}
{"question": "How does BilledResourceUtilization differ from TotalResourceUtilization in EMR Serverless?", "answer": "BilledResourceUtilization only factors in the duration for which pre-initialized capacity was utilized for a job, whereas TotalResourceUtilization rounds up the duration to the nearest second. Additionally, BilledResourceUtilization excludes 20GB of free storage from the calculation.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-11T15:31:56.179888"}}
{"question": "Why is it beneficial to use EMR Serverless for running data processing jobs or interactive requests?", "answer": "EMR Serverless automatically scales workers up or down depending on the workload and parallelism required at every stage of the job, thereby removing the need for you to estimate the number of workers required to run your workloads.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-21", "source_tokens": 479, "generated_at": "2026-02-11T15:31:56.180326"}}
{"question": "What is pre-initialized capacity in EMR Serverless?", "answer": "Pre-initialized capacity is a feature in EMR Serverless that keeps workers initialized and ready to respond in seconds, effectively creating an on-call pool of workers for an application.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-11T15:32:00.997933"}}
{"question": "Why is pre-initialized capacity useful in EMR Serverless?", "answer": "Pre-initialized capacity allows jobs to start immediately, making it ideal for implementing time-sensitive jobs. It also automatically adds more workers if needed, up to the maximum concurrent limit, and reverts back to maintaining the pre-initialized workers after the job finishes.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-11T15:32:00.998287"}}
{"question": "How does pre-initialized capacity compare to not using it in EMR Serverless?", "answer": "Without pre-initialized capacity, an EMR Serverless application takes up to 120 seconds to determine the required resources and provision them. With pre-initialized capacity, workers are kept ready to respond in seconds, allowing jobs to start immediately.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-22", "source_tokens": 496, "generated_at": "2026-02-11T15:32:00.998795"}}
{"question": "What type of UDFs are supported by EMR Serverless for Spark and HiveQL scripts?", "answer": "EMR Serverless supports Java-based UDFs.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-11T15:32:05.856804"}}
{"question": "How can you customize the ephemeral storage for EMR Serverless workers?", "answer": "You can customize the ephemeral storage capacity for EMR Serverless workers during job submission. EMR Serverless offers two storage options: standard storage (up to 200 GB per worker) and shuffle-optimized Disk storage (up to 2 TB per worker).", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-11T15:32:05.857075"}}
{"question": "What's the difference between on-demand and pre-initialized workers in EMR Serverless?", "answer": "On-demand workers are launched only when needed for a job and released automatically when the job is complete, helping you save costs. Pre-initialized workers are an optional feature where you can keep workers ready to respond in seconds, allowing jobs to start instantly.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-23", "source_tokens": 390, "generated_at": "2026-02-11T15:32:05.857264"}}
{"question": "Which Amazon EMR Serverless worker types allow jobs to run in multiple AZs?", "answer": "When using On-Demand workers only, jobs run in multiple AZs by default. When using Pre-Initialized workers, jobs run in the specified AZ until the application is stopped.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:32:11.764482"}}
{"question": "Why do you need to set up VPC access and a NAT gateway for an EMR Serverless application to access resources in a different Region?", "answer": "EMR Serverless can only access certain AWS resources in the same Region when configured without VPC connectivity. To access resources in a different Region or non-AWS resources, you need to set up VPC access and a NAT gateway for routing to public endpoints.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:32:11.764684"}}
{"question": "How does the new Max concurrent vCPUs per account quota for Amazon EMR Serverless differ from the Maximum active workers quota?", "answer": "The new Max concurrent vCPUs per account quota is a vCPU-based quota that sets the maximum number of aggregate vCPUs your applications are able to scale up to within a Region. The Maximum active workers quota is an application-level, worker-based quota that sets the maximum number of active workers in an application.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:32:11.764807"}}
{"question": "What is the function of the account-level vCPU-based quota in EMR Serverless?", "answer": "The account-level vCPU-based quota in EMR Serverless limits the maximum concurrent vCPUs used by all applications in a Region.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-11T15:32:16.516287"}}
{"question": "Why should we use both the account-level vCPU-based quota and the maximumCapacity property in EMR Serverless?", "answer": "You should use the account-level vCPU-based quota to limit the maximum concurrent vCPUs used by all applications in a Region, and the maximumCapacity property to limit the resources used by a specific application.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-11T15:32:16.516568"}}
{"question": "What happens if we exceed the account-level vCPU quota in EMR Serverless?", "answer": "If you exceed the account-level vCPU quota in EMR Serverless, EMR Serverless will stop provisioning new capacity and both application creation and job submission will fail with an error message.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-25", "source_tokens": 337, "generated_at": "2026-02-11T15:32:16.516750"}}
{"question": "What are the three ways Amazon EMR Serverless helps save costs?", "answer": "Amazon EMR Serverless helps save costs by eliminating operational overhead, automatically scaling workers, and using a high-performance runtime.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-11T15:32:21.175619"}}
{"question": "How does automatic scaling in Amazon EMR Serverless benefit cost savings?", "answer": "Automatic scaling in Amazon EMR Serverless allows users to incur costs for only the workers needed at each stage of processing a job, reducing costs for underutilized resources.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-11T15:32:21.175868"}}
{"question": "What is the difference in cost savings between using EMR Serverless and EMR on EC2 with Savings Plans or On-Demand Instances?", "answer": "EMR Serverless offers lower total cost of ownership compared to EMR on EC2 when current cluster utilization is less than 70% with On-Demand Instances, or less than 50% with Savings Plans.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-26", "source_tokens": 490, "generated_at": "2026-02-11T15:32:21.176250"}}
{"question": "What method should I use for packaging Python dependencies for PySpark on AWS EMR Serverless?", "answer": "You should use virtualenv to package your Python dependencies and pass the archive file using the --archives option.", "question_type": "factual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-11T15:32:25.303086"}}
{"question": "How do I handle Scala or Java dependencies for AWS EMR Serverless using PySpark?", "answer": "You can package your dependencies as jars, upload them to Amazon S3, and pass them using the --jars or --packages options.", "question_type": "conceptual", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-11T15:32:25.303310"}}
{"question": "What's the difference in dependency handling for PySpark between Python and Scala/Java on AWS EMR Serverless?", "answer": "Python dependencies are packaged using virtualenv and passed as archives, while Scala and Java dependencies are packaged as jars and uploaded to Amazon S3 for use.", "question_type": "comparison", "metadata": {"service": "EMR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "emr-faq-27", "source_tokens": 86, "generated_at": "2026-02-11T15:32:25.303431"}}
{"question": "What is the process for setting up Amazon EventBridge with an AWS service as an event source?", "answer": "To set up Amazon EventBridge with an AWS service as an event source, log in to your AWS account, navigate to the EventBridge console, choose the event source from a list of AWS services, and configure any necessary settings. EventBridge will automatically create an event bus and deliver events to the chosen target, such as AWS Lambda, Amazon SNS, or Amazon Kinesis Data Firehose.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:32:31.608668"}}
{"question": "How can you create and publish custom application-level events to Amazon EventBridge?", "answer": "You can create and publish custom application-level events to Amazon EventBridge using the service's API operations. This allows for generating events that are not emitted by the event source itself.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:32:31.609017"}}
{"question": "What are the differences between using an AWS service as an event source in Amazon EventBridge and configuring a filtering rule and attaching a target?", "answer": "Using an AWS service as an event source involves selecting the service in the EventBridge console and following the setup process to have events automatically delivered to the configured target. Configuring a filtering rule and attaching a target, on the other hand, allows you to apply specific conditions to the events before they reach the target and process them accordingly.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:32:31.609468"}}
{"question": "What top-level fields does every event have in AWS EventBridge?", "answer": "Every event in AWS EventBridge has the same top-level envelope fields, including the source of the event, timestamp, and Region.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:32:35.723673"}}
{"question": "Can a single rule in EventBridge route to multiple targets?", "answer": "Yes, a single rule in EventBridge can route events to multiple targets, all of which are processed in parallel.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:32:35.724019"}}
{"question": "Which AWS services can be used both as event sources and targets in EventBridge?", "answer": "Some AWS services, such as Lambda, SQS, SNS, Kinesis Streams, and Kinesis Data Firehose, can be used both as event sources and targets in EventBridge.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:32:35.724478"}}
{"question": "What is the purpose of Event Replay in EventBridge?", "answer": "Event Replay is a new feature for EventBridge that enables developers to reprocess past events back to an event bus or a specific EventBridge rule. This feature facilitates easier application debugging, extension, and error recovery.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-11T15:32:41.072538"}}
{"question": "How does API Destinations work in EventBridge?", "answer": "API Destinations in EventBridge allows developers to send events to on-premises or SaaS applications with controlled throughput and authentication. EventBridge transforms the event based on the specified conditions and sends it to the configured web service with provided authentication information.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-11T15:32:41.072876"}}
{"question": "What's the difference between Event Replay and API Destinations in EventBridge?", "answer": "Event Replay is a feature that helps reprocess past events back to an event bus or a specific EventBridge rule, enabling easier application debugging and error recovery. API Destinations, on the other hand, allow developers to send events to on-premises or SaaS applications with controlled throughput and authentication.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-2", "source_tokens": 472, "generated_at": "2026-02-11T15:32:41.073398"}}
{"question": "What is the process to request a higher EventBridge throughput limit?", "answer": "To request a higher EventBridge throughput limit, submit a case through the AWS Support Center by choosing 'Create Case' and then choosing 'Service Limit Increase.'", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:32:45.549529"}}
{"question": "How does EventBridge schema discovery help developers?", "answer": "EventBridge schema discovery automates the process of finding event schemas and adding them to the registry, allowing developers to easily access and generate code bindings for the schemas, enabling features such as validation and autocomplete.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:32:45.549874"}}
{"question": "What's the difference between manually adding a schema to the registry and using schema discovery?", "answer": "Manually adding a schema to the registry requires manual intervention, while schema discovery automates the process by finding and adding event schemas to the registry as they are sent to the event bus.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:32:45.550273"}}
{"question": "What is the cost of using the AWS Schema Registry for schema discovery?", "answer": "There is no cost to use the Schema Registry itself. However, there is a cost per ingested event when schema discovery is turned on. The free tier offers 5 M ingested events per month, and the fee for additional usage is $0.10 per million ingested events.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-11T15:32:51.005501"}}
{"question": "Why is the AWS Schema Registry beneficial for event-driven application development?", "answer": "The Schema Registry simplifies event-driven application development by automatically identifying and storing schema for any events sent to an EventBridge event bus. It eliminates the need to manage event schema manually, reduces the overhead for deserialization, validation, and guesswork for event handlers, and allows developers to focus solely on their application code.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-11T15:32:51.005862"}}
{"question": "How does the cost of using the AWS Schema Registry for schema discovery compare to the free tier usage?", "answer": "The free tier of the Schema Registry offers 5 M ingested events per month. For additional usage, there is a fee of $0.10 per million ingested events.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-4", "source_tokens": 366, "generated_at": "2026-02-11T15:32:51.006275"}}
{"question": "What does the AWS SAM CLI interactive mode help you create in EventBridge?", "answer": "The AWS SAM CLI interactive mode helps you create new serverless applications on EventBridge for any schema as an event type.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-11T15:32:56.127846"}}
{"question": "How does the AWS SAM CLI simplify working with EventBridge?", "answer": "The AWS SAM CLI enables you to treat an event trigger like a normal object in your code and use features such as validation and autocomplete in your IDE.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-11T15:32:56.128111"}}
{"question": "What are the differences between EventBridge and EventBridge Pipes when it comes to integration between event producers and consumers?", "answer": "Both EventBridge and EventBridge Pipes help create integration between event producers and consumers. However, EventBridge requires writing, managing, and scaling undifferentiated integration code, while EventBridge Pipes simplify this process with features like customizable batching, starting position, concurrency, and an optional filtering and enrichment step.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-5", "source_tokens": 469, "generated_at": "2026-02-11T15:32:56.128499"}}
{"question": "What sources can I use to create a pipe in EventBridge?", "answer": "You can use Amazon SQS, Amazon Kinesis, Amazon DynamoDB, Amazon Managed Streaming Kafka, self-managed Kafka, and Amazon MQ as sources to create a pipe in EventBridge.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-11T15:33:00.939218"}}
{"question": "How can I transform events in EventBridge Pipes?", "answer": "EventBridge Pipes support basic transformations using Velocity Template Language (VTL) for simple transformations. For more powerful transformations, you can specify a Lambda function or Step Functions workflow to process your event.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-11T15:33:00.939548"}}
{"question": "What is the difference between transforming events using VTL and a Lambda function in EventBridge Pipes?", "answer": "VTL is a basic transformation language provided by EventBridge Pipes, suitable for simple transformations. Lambda functions and Step Functions workflows offer more powerful transformation capabilities.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-6", "source_tokens": 395, "generated_at": "2026-02-11T15:33:00.940029"}}
{"question": "What is EventBridge Pipes used for in relation to EventBridge event buses?", "answer": "EventBridge Pipes is used for point-to-point integrations between event publishers and consumers, while EventBridge event buses are used for many-to-many routing of events between event-driven services.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-11T15:33:05.553016"}}
{"question": "Can EventBridge Pipes be used with an existing EventBridge event bus?", "answer": "Yes, EventBridge Pipes can be used with an existing EventBridge event bus as a target.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-11T15:33:05.553353"}}
{"question": "How does EventBridge Pipes compare to EventBridge event buses in terms of event processing?", "answer": "EventBridge event buses are designed for many-to-many event routing, while EventBridge Pipes are used for point-to-point integrations, with support for advanced transformations and enrichments.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-7", "source_tokens": 488, "generated_at": "2026-02-11T15:33:05.553885"}}
{"question": "What AWS service is used for creating, executing, and managing millions of schedules across different AWS services without managing infrastructure?", "answer": "Amazon EventBridge Scheduler", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-11T15:33:09.752342"}}
{"question": "How does Amazon EventBridge Scheduler differ from Scheduled Rules in terms of features and functionality?", "answer": "Amazon EventBridge Scheduler offers a richer feature set than Scheduled Rules, including support for time zones, increased scale, customized target payloads, added time expressions, and a dashboard for monitoring schedules.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-11T15:33:09.752678"}}
{"question": "How does the scheduling experience differ between AWS services when using Amazon EventBridge Scheduler?", "answer": "The scheduling experience is consistent across AWS services when using Amazon EventBridge Scheduler, with configurations for time patterns and retries being uniform.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-8", "source_tokens": 481, "generated_at": "2026-02-11T15:33:09.753175"}}
{"question": "What happens if at least one delivery of an EventBridge Scheduler event fails?", "answer": "At least one delivery succeeds with a response from the target.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-11T15:33:13.742108"}}
{"question": "Can users enable delete upon completion for EventBridge Scheduler at any time?", "answer": "Yes, users can update their schedule to configure delete upon completion at any time before the schedule is invoked.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-11T15:33:13.742440"}}
{"question": "How does EventBridge Scheduler's delete upon completion feature compare to its failure handling?", "answer": "EventBridge Scheduler's delete upon completion feature ensures that the schedule is deleted after it's last invocation, while at-least-once event delivery ensures that at least one delivery succeeds with a response from the target.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-9", "source_tokens": 462, "generated_at": "2026-02-11T15:33:13.742943"}}
{"question": "What region is the event bus located in after publishing events in the global endpoint?", "answer": "The event bus is located in the primary Region.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-11T15:33:18.472792"}}
{"question": "Why would a user choose to use a global endpoint in EventBridge instead of a specific region?", "answer": "A user might choose to use a global endpoint in EventBridge if their application does not require idempotency, is tolerant of up to 420 seconds of events not being replicated, and if they want to avoid having subscriber metrics included in their health check.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-11T15:33:18.473110"}}
{"question": "How does the latency reporting metric in EventBridge help users determine if there are errors requiring failover to the secondary Region?", "answer": "The latency reporting metric in EventBridge provides users with the entire latency of EventBridge, making it easier for them to determine if there are errors within EventBridge that require failover to the secondary Region for event ingestion.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-10", "source_tokens": 395, "generated_at": "2026-02-11T15:33:18.473309"}}
{"question": "What is the Recovery Time Objective (RTO) and Recovery Point Objective (RPO) for global endpoints following prescriptive guidance for alarm configuration?", "answer": "The RTO is 360 seconds with a maximum of 420, and the RPO is also 360 seconds.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:33:23.063689"}}
{"question": "How does setting up a global endpoint with replication help minimize data loss during a service disruption?", "answer": "By replicating events to the secondary Region, you can ensure that none of your events are lost during a disruption and you can recover quickly by continuing to process your events in the secondary Region.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:33:23.063949"}}
{"question": "How does replicating your architecture in the secondary Region using AWS CloudFormation StackSets compare to manually setting it up?", "answer": "Using AWS CloudFormation StackSets makes it easier to replicate your architecture across AWS Regions.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-11", "source_tokens": 472, "generated_at": "2026-02-11T15:33:23.064128"}}
{"question": "In which Regions are global endpoints currently available for Amazon EventBridge?", "answer": "Global endpoints are currently available in US East (Ohio and N. Virginia), US West (N. California and Oregon), Asia Pacific (Mumbai, Osaka, Seoul, Singapore, Sydney and Tokyo), Canada (Central), Europe (Frankfurt, Ireland, London, Paris and Stockholm), and South America (SÃ£o Paulo)", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-11T15:33:28.075993"}}
{"question": "Why are global endpoints important in Amazon EventBridge?", "answer": "Global endpoints in Amazon EventBridge allow users to publish and receive events across different AWS Regions, enabling centralized monitoring and audit of events, as well as keeping data in sync between accounts.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-11T15:33:28.076266"}}
{"question": "What is the pricing difference between using a global endpoint and a regional endpoint in Amazon EventBridge?", "answer": "Using a global endpoint in Amazon EventBridge incurs an additional charge of $1 per million events for event replication, while using a regional endpoint does not.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-12", "source_tokens": 420, "generated_at": "2026-02-11T15:33:28.076433"}}
{"question": "What services can EventBridge be used with to build event-driven applications?", "answer": "EventBridge can be used with your own applications, SaaS applications, and AWS services.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-11T15:33:31.865442"}}
{"question": "How does EventBridge differ from SNS in terms of application development?", "answer": "EventBridge is recommended for applications that need to react to events from various sources and integrate with third-party SaaS partners, while SNS is recommended for applications with high fan-out requirements.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-11T15:33:31.865776"}}
{"question": "What are the main differences between EventBridge and SNS in terms of event structure and targets?", "answer": "EventBridge uses a defined JSON-based structure for events and supports over 20 AWS services as targets, while SNS has unstructured messages and supports six different types of targets.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-13", "source_tokens": 360, "generated_at": "2026-02-11T15:33:31.865974"}}
{"question": "What service does AWS AppFabric enhance for companies?", "answer": "AWS AppFabric enhances companiesâ€™ existing investment in software as a service (SaaS) applications.", "question_type": "factual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-11T15:33:37.293841"}}
{"question": "How does AWS EventBridge simplify the integration process for SaaS vendors?", "answer": "AWS EventBridge makes it easier for SaaS vendors to integrate their service into their customersâ€™ event-driven architectures built on AWS. It provides a fully auditable, secure, and scalable pathway to send events without the SaaS vendor managing any event infrastructure.", "question_type": "conceptual", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-11T15:33:37.294190"}}
{"question": "How does AWS AppFabric compare to EventBridge in terms of application data handling?", "answer": "AWS AppFabric aggregates and normalizes SaaS log data from various applications and productivity suites to increase application observability and reduce operational costs associated with building and maintaining point-to-point integrations. AWS EventBridge, on the other hand, is a serverless integration service that focuses on routing events from various sources to consumer applications, providing a simple and consistent way to ingest, filter, transform, and deliver events.", "question_type": "comparison", "metadata": {"service": "EVENTBRIDGE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "eventbridge-faq-14", "source_tokens": 380, "generated_at": "2026-02-11T15:33:37.294760"}}
{"question": "What are the benefits of using AWS Fargate for compute in terms of security and compliance?", "answer": "AWS Fargate improves security through application isolation by design. It eliminates the need to manage servers, which shifts security tasks to AWS and lowers the total cost of ownership (TCO).", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:33:42.376731"}}
{"question": "How does AWS Fargate compare to traditional server management for cost and operational efficiency?", "answer": "AWS Fargate is a serverless, pay-as-you-go compute engine that shifts tasks such as server management, resource allocation, and scaling to AWS, allowing development teams to focus on writing code and reducing the total cost of ownership (TCO).", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:33:42.377071"}}
{"question": "What types of applications can AWS Fargate be used for?", "answer": "AWS Fargate can be used for a broad range of workloads, including web applications, APIs, microservices architectures, data processing, artificial intelligence and machine learning applications, and application modernization. It supports multiple CPU architectures and operating systems.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:33:42.377278"}}
{"question": "What type of compute instances does AWS Fargate use for each workload?", "answer": "AWS Fargate uses single use, single tenant compute instances for each workload.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:33:48.146989"}}
{"question": "Why should you use AWS Fargate instead of Amazon ECS or Amazon EKS?", "answer": "You should use AWS Fargate if you want an isolated and secure environment, don't need to manage EC2 instances, and prefer built-in integrations with AWS services and third-party tools. Use Amazon ECS or Amazon EKS if you require greater control or broader customization options, or for GPU workloads.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:33:48.147332"}}
{"question": "What's the difference between using AWS Fargate for Arm-based applications and Amazon EC2 for Arm workloads on Amazon EKS?", "answer": "When using AWS Fargate for Arm-based applications, you can use Arm-compatible container images or multi-architecture container images in Amazon ECR and specify the CPU Architecture as Arm64 in your Task Definition. AWS Fargate is a serverless compute engine that manages the necessary patches and updates. However, Amazon EKS on Amazon EC2 is required for Arm workloads not supported on AWS Fargate.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:33:48.147805"}}
{"question": "What is the basis for AWS Fargate service quotas in terms of vCPU cores?", "answer": "AWS Fargate service quotas are based on the number of vCPU cores used in a given region in a given account.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T15:33:52.094212"}}
{"question": "How does reducing container image compression format impact AWS Fargate startup times?", "answer": "Using zstd for container image compression instead of gzip can result in faster task launch times in AWS Fargate.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T15:33:52.094570"}}
{"question": "Why is it important to load test applications before deploying them to AWS Fargate?", "answer": "Load testing applications locally or in development environments helps size the workload appropriately, ensuring optimal performance and cost efficiency in AWS Fargate.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-2", "source_tokens": 474, "generated_at": "2026-02-11T15:33:52.095094"}}
{"question": "What type of network interface is allocated to each workload on AWS Fargate?", "answer": "Each workload on AWS Fargate is given a dedicated elastic network interface (ENI) attached into the virtual private cloud (VPC).", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-11T15:33:56.761532"}}
{"question": "How does using VPC Security Groups and network ACLs impact traffic security on AWS Fargate?", "answer": "VPC Security Groups and network ACLs can be used to secure the ENI and monitor traffic flows on AWS Fargate.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-11T15:33:56.761865"}}
{"question": "What is the difference in ephemeral storage allocation between Amazon ECS and Amazon EKS on AWS Fargate?", "answer": "Each workload on AWS Fargate is given full access to 20 GiB of ephemeral storage, but this can be expanded to 200 GiB on Amazon ECS and 175 GiB on Amazon EKS.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-3", "source_tokens": 413, "generated_at": "2026-02-11T15:33:56.762289"}}
{"question": "What regulatory compliance does AWS Fargate support for handling Protected Health Information (PHI)?", "answer": "AWS Fargate supports HIPAA compliance if you have an executed Business Associate Addendum (BAA) with AWS.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T15:34:01.187895"}}
{"question": "How can third-party solutions integrate with AWS Fargate for added functionality?", "answer": "Third-party solutions can integrate with AWS Fargate by running a sidecar container within a Fargate task, allowing interaction with the primary application container.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T15:34:01.188237"}}
{"question": "When comparing AWS Fargate's monitoring tools to Amazon CloudWatch Container Insights, which one is specifically designed for collecting and analyzing logs and creating operational dashboards?", "answer": "CloudWatch Container Insights is a monitoring tool specifically designed for collecting and analyzing logs and creating operational dashboards for AWS Fargate resources.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-4", "source_tokens": 451, "generated_at": "2026-02-11T15:34:01.188438"}}
{"question": "What is the pricing model for AWS Fargate based on?", "answer": "AWS Fargate pricing is based on the amount of vCPU, memory, and storage resources provisioned for containerized applications.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-11T15:34:06.557215"}}
{"question": "How does AWS Fargate Savings Plans compare to Spot instances for pricing?", "answer": "AWS Fargate Savings Plans provide the same discounts as Reserved Instances in exchange for a commitment to use a specific amount of compute power over a one- or three-year period. Spot instances, on the other hand, utilize spare compute capacity and offer up to a 70% discount off the AWS Fargate price, but come with the risk of interruptions.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-11T15:34:06.557576"}}
{"question": "What are the benefits of using AWS Graviton processors with AWS Fargate?", "answer": "AWS Graviton processors offer up to 40% better price performance and up to 60% less energy consumption compared to comparable x86-based instances. They are also included in the AWS Compute Optimizer, which helps identify and remediate inefficient configurations.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-5", "source_tokens": 401, "generated_at": "2026-02-11T15:34:06.557773"}}
{"question": "What is the price performance improvement of AWS Fargate with Graviton processors compared to Intel x86-based Fargate?", "answer": "AWS Fargate with Graviton processors delivers up to 40% improved price/performance.", "question_type": "factual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-11T15:34:11.663381"}}
{"question": "How does AWS Fargate with Graviton processors compare to Intel x86-based Fargate in terms of performance optimization and cost reduction?", "answer": "AWS Fargate with Graviton processors delivers up to 40% improved price/performance at 20% lower cost over comparable Intel x86-based Fargate.", "question_type": "comparison", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-11T15:34:11.663747"}}
{"question": "What are the benefits of using AWS Fargate with Graviton processors for running containerized workloads?", "answer": "AWS Fargate with Graviton processors offers the same serverless benefits of AWS Fargate while optimizing performance and cost for running containerized workloads such as application servers, web services, high-performance computing, and media processing.", "question_type": "conceptual", "metadata": {"service": "FARGATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fargate-faq-6", "source_tokens": 125, "generated_at": "2026-02-11T15:34:11.663947"}}
{"question": "What is AWS Firewall Manager used for?", "answer": "AWS Firewall Manager is a security management service that allows you to centrally configure and manage firewall rules across your accounts and applications in AWS Organization.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-11T15:34:16.000392"}}
{"question": "How does AWS Firewall Manager make it easier to manage firewall rules?", "answer": "AWS Firewall Manager makes it easier to manage firewall rules by allowing you to build firewall rules, create security policies, and enforce them in a consistent, hierarchical manner across your entire infrastructure.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-11T15:34:16.000747"}}
{"question": "What are the benefits of using AWS Firewall Manager over managing firewall rules individually for each application?", "answer": "AWS Firewall Manager offers several benefits over managing firewall rules individually for each application. It allows you to enforce a common set of security rules across your entire infrastructure, making it easier to keep all your applications and resources secure.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-0", "source_tokens": 160, "generated_at": "2026-02-11T15:34:16.001184"}}
{"question": "What AWS services can you centrally manage with Firewall Manager?", "answer": "AWS Firewall Manager allows you to centrally manage AWS WAF rules, AWS Shield Advanced protections, VPC security groups and network access control lists (ACLs), AWS Network Firewalls, and Amazon Route 53 Resolver DNS Firewall rules.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-11T15:34:21.390372"}}
{"question": "How does Firewall Manager help you manage security policies across multiple accounts?", "answer": "Firewall Manager enables you to enforce a mandatory set of security policies across multiple AWS accounts and resources from a single place. You can delegate the creation of application-specific rules within an account while retaining the ability to enforce global security policies.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-11T15:34:21.390725"}}
{"question": "What are the differences between centrally deploying VPC security groups with Firewall Manager and auditing existing ones?", "answer": "With Firewall Manager, you can centrally deploy security group rules for EC2 instances, Application Load Balancers, and Elastic Network Interfaces (ENIs), as well as audit any existing security groups in your VPCs for over permissive rules and remediate them.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-1", "source_tokens": 447, "generated_at": "2026-02-11T15:34:21.391257"}}
{"question": "Which services can you apply AWS WAF rules using AWS Firewall Manager?", "answer": "AWS WAF rules can be applied to Application Load Balancer, API Gateways, and Amazon CloudFront distributions.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:34:26.205356"}}
{"question": "How does AWS Firewall Manager allow you to configure security for your VPCs?", "answer": "AWS Firewall Manager allows you to configure new VPC network access control lists (ACLs) for your VPC subnets.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:34:26.205735"}}
{"question": "What's the difference between associating Amazon Route 53 Resolver DNS Firewall rules with AWS Firewall Manager and configuring new VPC network access control lists?", "answer": "Associating Amazon Route 53 Resolver DNS Firewall rules with AWS Firewall Manager allows you to apply DNS firewall rules across VPCs in your organization. Configuring new VPC network access control lists allows you to create and manage access control lists for your VPC subnets.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T15:34:26.206255"}}
{"question": "What number of accounts can be scoped in a single Firewall Manager policy?", "answer": "Each Firewall Manager policy can be scoped to have at most 2,500 accounts.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T15:34:30.235542"}}
{"question": "How does Firewall Manager handle policy drift in different modes?", "answer": "Firewall Manager offers two modes: automatic remediation, which monitors for policy drift and applies rules on non-compliant resources, and manual remediation, which creates a new policy but does not enforce rules on resources until manual action is taken.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T15:34:30.235778"}}
{"question": "How does Firewall Manager's resource management capacity compare between different regions?", "answer": "There is not a limit on the number of resources managed by Firewall Manager in any region.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T15:34:30.236389"}}
{"question": "Which firewall types can be associated with a Firewall Manager security policy?", "answer": "Firewall Manager security policies can be associated with AWS WAF, AWS Shield Advanced, VPC security groups, AWS Network Firewall, Amazon Route 53 Resolver DNS Firewall, and AWS Marketplace third-party firewalls.", "question_type": "factual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T15:34:35.780867"}}
{"question": "How does Firewall Manager help customers manage compliance for their security policies?", "answer": "Firewall Manager provides a central compliance dashboard, allowing customers to view which accounts and resources are non-compliant with a given policy, and why. Customers can also view non-compliant events for each account on AWS Security Hub, and can create new SNS notification channels to receive real-time notifications.", "question_type": "conceptual", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T15:34:35.781214"}}
{"question": "How does CloudWatch metrics aggregation for Firewall Manager policies compare to the metrics aggregation for individual policies?", "answer": "For each Firewall Manager policy created, you can aggregate CloudWatch metrics for each Rule in the Rule Group across the entire organization, giving you a central place to set up alerts for threats. This is different from individual policies where metrics are aggregated on a per-policy basis.", "question_type": "comparison", "metadata": {"service": "FIREWALL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "firewall-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T15:34:35.781425"}}
{"question": "What are the benefits of using Amazon Forecast for business operations?", "answer": "Amazon Forecast helps businesses easily and accurately forecast business outcomes using machine learning. It allows for scaling operations by forecasting millions of items, reducing waste with accurate forecasts, optimizing inventory, improving capital utilization, increasing customer satisfaction, and forecasting workforce staffing. The service also enables the forecasting of product demand at specific probability levels, and can be used to forecast foot traffic, visitor counts, and channel demand.", "question_type": "factual", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-11T15:34:42.114527"}}
{"question": "How does Amazon Forecast help businesses make long-term decisions?", "answer": "Amazon Forecast improves capital utilization and makes long-term decisions more confident by providing accurate and granular level forecasts. This enables businesses to optimize inventory, reduce waste, and increase customer satisfaction.", "question_type": "conceptual", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-11T15:34:42.114879"}}
{"question": "What is the difference between forecasting product demand and forecasting workforce staffing with Amazon Forecast?", "answer": "Amazon Forecast can be used to forecast both product demand and workforce staffing. Product demand forecasting involves predicting the future demand for a specific product or group of products, while workforce staffing forecasting involves predicting the future demand for staffing resources to meet varying demand levels. The granularity of the forecast, with product demand being at a specific probability level and workforce staffing at 15-minute increments, is the primary difference between the two.", "question_type": "comparison", "metadata": {"service": "FORECAST", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "forecast-faq-0", "source_tokens": 256, "generated_at": "2026-02-11T15:34:42.115380"}}
{"question": "What type of fraud does Amazon Fraud Detector specialize in detecting?", "answer": "Amazon Fraud Detector specializes in real-time machine learning modeling for various types of online fraud, such as new account fraud, payment fraud for online orders, guest checkout fraud, and loyalty account protection.", "question_type": "conceptual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T15:34:47.767297"}}
{"question": "How is a customized fraud detection model created in Amazon Fraud Detector?", "answer": "To create a customized fraud detection model in Amazon Fraud Detector, users first define the event they want to assess, upload their historical event dataset to Amazon S3, select a fraud detection model type, and allow the service to automatically train, test, and deploy the model. During this process, users can boost performance by using pre-trained fraud detection models based on AWS and Amazonâ€™s expertise.", "question_type": "factual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T15:34:47.767635"}}
{"question": "What is the main difference between Amazon Fraud Detector and other fraud detection solutions in the market?", "answer": "The main difference between Amazon Fraud Detector and other fraud detection solutions is its fully managed service that makes it easy to identify potentially fraudulent activity, automatic training and deployment of customized fraud detection models, and integration into website transactional functions for real-time fraud predictions.", "question_type": "comparison", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T15:34:47.768162"}}
{"question": "What data can be used as fraud evaluation inputs in Amazon Fraud Detector?", "answer": "Email addresses, phone numbers, and IP addresses can be used as fraud evaluation inputs in Amazon Fraud Detector.", "question_type": "factual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T15:34:52.691355"}}
{"question": "How does Amazon Fraud Detector help users tap into Amazon's fraud expertise?", "answer": "Amazon Fraud Detector uses a series of models trained on patterns from AWS and Amazon's own fraud expertise to boost your model's performance during the automated model training process.", "question_type": "conceptual", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T15:34:52.691702"}}
{"question": "What are the differences between rule-based fraud predictions and ML-based predictions in Amazon Fraud Detector?", "answer": "With Amazon Fraud Detector, you can perform rule-based fraud predictions with or without ML. Rule-based predictions are made using a simple rule-writing language and the order in which rules trigger during an evaluation can be specified using an intuitive interface. ML-based predictions, on the other hand, are made using machine learning models trained on historical fraud data.", "question_type": "comparison", "metadata": {"service": "FRAUD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fraud-faq-1", "source_tokens": 492, "generated_at": "2026-02-11T15:34:52.692195"}}
{"question": "Which file systems does Amazon FSx support?", "answer": "Amazon FSx supports NetApp ONTAP, OpenZFS, Windows File Server, and Lustre file systems.", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:34:57.110217"}}
{"question": "How does Amazon FSx help with managing file systems?", "answer": "Amazon FSx is a fully managed service that handles hardware provisioning, patching, and backups, freeing you up to focus on your applications and end users.", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:34:57.110554"}}
{"question": "How does Amazon FSx for NetApp ONTAP compare to Amazon FSx for OpenZFS in terms of performance?", "answer": "Both Amazon FSx for NetApp ONTAP and Amazon FSx for OpenZFS deliver sub-millisecond latencies and high throughput. However, specific performance characteristics might vary based on the requirements of your workload.", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:34:57.111038"}}
{"question": "What type of data encryption does Amazon FSx support for data at-rest?", "answer": "Amazon FSx encrypts your data at-rest using AWS Key Management Service (AWS KMS)", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T15:35:01.378825"}}
{"question": "Why does Amazon FSx offer both SSD and HDD storage options?", "answer": "Amazon FSx offers both SSD and HDD storage options to support a broad spectrum of use cases and optimize price and performance", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T15:35:01.379237"}}
{"question": "How does Amazon FSx compare to traditional on-premises file systems for security?", "answer": "Amazon FSx automatically encrypts data at-rest and in-transit, replicates data across availability zones for high availability, and integrates with AWS Backup for centralized backup management and increased compliance levels", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T15:35:01.379532"}}
{"question": "What deployment options does Amazon FSx provide for highly performant and scalable file storage?", "answer": "Amazon FSx provides a range of cost-effective deployment options that can deliver millions of IOPS and ensure sub-millisecond latency to prevent storage from becoming a bottleneck for machine learning, analytics, and HPC applications.", "question_type": "factual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-11T15:35:06.278880"}}
{"question": "Why is managing backups and long-term data retention on-premises complex and costly?", "answer": "Managing backups and long-term data retention on-premises can be complex, time-consuming, and costly.", "question_type": "conceptual", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-11T15:35:06.279215"}}
{"question": "How does Amazon FSx storage compare to on-premises storage for Media & Entertainment workloads?", "answer": "Amazon FSx storage offers scalability to deliver media projects on time and within budget and flexibility to connect from Linux, Windows, and macOS environments compared to on-premises storage for Media & Entertainment workloads.", "question_type": "comparison", "metadata": {"service": "FSX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "fsx-faq-2", "source_tokens": 309, "generated_at": "2026-02-11T15:35:06.279646"}}
{"question": "What IP addresses does AWS Global Accelerator provide and how are they used?", "answer": "AWS Global Accelerator provides static IP addresses that can be associated with regional AWS resources or endpoints, such as Network Load Balancers, Application Load Balancers, EC2 Instances, and Elastic IP addresses. These IP addresses are anycast from AWS edge locations, providing onboarding to the AWS global network close to users.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:35:11.641754"}}
{"question": "How does AWS Global Accelerator optimize the routing of user traffic?", "answer": "AWS Global Accelerator optimizes the routing of user traffic by always routing it to the optimal endpoint based on performance, reacting instantly to changes in application health, user location, and configured policies.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:35:11.642119"}}
{"question": "What are the benefits of using AWS Global Accelerator compared to traditional DNS configuration?", "answer": "Using AWS Global Accelerator offers benefits such as easier endpoint movement between Availability Zones or AWS Regions without needing to update DNS configuration, traffic management with percentage dial for specific regions, and control over the proportion of traffic directed to each endpoint within an endpoint group.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:35:11.642648"}}
{"question": "What is the improvement in first byte latency that AWS Global Accelerator can provide at the 90th percentile (p90) according to third party measurements?", "answer": "AWS Global Accelerator can decrease first byte latency by up to 49% at the 90th percentile (p90) according to third party measurements.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-11T15:35:16.554801"}}
{"question": "How does enabling AWS Global Accelerator impact application load times for a multinational customer?", "answer": "AWS Global Accelerator can lead to a reduction in mean end-to-end app load times of up to 51.2% for a multinational customer.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-11T15:35:16.555143"}}
{"question": "How does the performance improvement of AWS Global Accelerator compare to the public internet in terms of first byte latency and jitter reduction?", "answer": "AWS Global Accelerator can decrease first byte latency by up to 49% and jitter by up to 58% as compared to the public internet.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-1", "source_tokens": 268, "generated_at": "2026-02-11T15:35:16.555640"}}
{"question": "What are the two IP addresses that AWS Global Accelerator provisions when creating an accelerator?", "answer": "AWS Global Accelerator provisions two static IP addresses for each accelerator.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-11T15:35:20.936760"}}
{"question": "How does AWS Global Accelerator determine which endpoints in an endpoint group to route traffic to?", "answer": "AWS Global Accelerator routes traffic to endpoints in an endpoint group based on the health check settings and the traffic dial percentage configured for each endpoint group.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-11T15:35:20.937045"}}
{"question": "What's the difference between setting up AWS Global Accelerator using the API versus the AWS Management Console?", "answer": "Setting up AWS Global Accelerator using the API and the AWS Management Console both allow you to create, configure, and manage an accelerator, but the API provides a programmatic way to interact with AWS services, while the Console offers a graphical user interface.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-2", "source_tokens": 314, "generated_at": "2026-02-11T15:35:20.937403"}}
{"question": "What region does AWS Global Accelerator extend the capabilities of ELB beyond?", "answer": "AWS Global Accelerator extends the capabilities of ELB beyond a single AWS Region.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:35:25.686421"}}
{"question": "Why would you use AWS Global Accelerator instead of an Application or Network Load Balancer for a global client base?", "answer": "You would use AWS Global Accelerator instead of an Application or Network Load Balancer for a global client base because it provides traffic management across multiple AWS Regions.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:35:25.686758"}}
{"question": "How does AWS Global Accelerator differ from Amazon CloudFront in terms of integration with on-premises resources?", "answer": "AWS Global Accelerator allows you to register a Network Load Balancer (NLB) in each AWS Region as an endpoint in your Global Accelerator configuration to address your on-premises endpoints, while Amazon CloudFront does not support direct configuration of on-premises resources as endpoints.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:35:25.687258"}}
{"question": "What can a custom routing accelerator be used for in AWS?", "answer": "A custom routing accelerator can be used in AWS to route user traffic to a specific Amazon EC2 IP and port in a single or multiple regions, using your own application logic. Examples of use cases include multi-player games, VoIP, EdTech, and social media applications.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-11T15:35:32.645534"}}
{"question": "How does using a custom routing accelerator improve application performance in AWS?", "answer": "Using a custom routing accelerator in AWS improves application performance by allowing you to assign multiple users to a specific media server to initiate voice, video, and messaging sessions, based on factors such as geographic location, player skill, and gaming configuration. It also automatically routes application requests over the AWS global network to the S3 bucket with the lowest network latency, allowing applications to avoid congested network segments on the public internet.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-11T15:35:32.645883"}}
{"question": "How does a custom routing accelerator compare to Amazon S3 Multi-Region Access Points in terms of functionality?", "answer": "A custom routing accelerator and Amazon S3 Multi-Region Access Points both provide benefits for routing user traffic in AWS. A custom routing accelerator allows you to route traffic to a specific Amazon EC2 IP and port in a single or multiple regions, using your own application logic. Amazon S3 Multi-Region Access Points, on the other hand, provide a single global endpoint to access a data set that spans multiple S3 buckets in different regions and automatically route requests to the S3 bucket with the lowest network latency.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-4", "source_tokens": 276, "generated_at": "2026-02-11T15:35:32.646371"}}
{"question": "What benefit does AWS Global Accelerator provide for handling application endpoint failures and configuration updates?", "answer": "AWS Global Accelerator automatically reacts to route user traffic to available and healthy application endpoints when there's a health status change or configuration update.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T15:35:37.512976"}}
{"question": "How does AWS Global Accelerator ensure high availability and fault tolerance for client applications?", "answer": "AWS Global Accelerator uses two isolated network zones, each with their own physical infrastructure and unique IP subnet. If one static IP address becomes unavailable, it reroutes traffic to the healthy static IP address from the other isolated network zone.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T15:35:37.513316"}}
{"question": "In what ways does AWS Global Accelerator improve performance when compared to relying on client devices for IP address caching?", "answer": "AWS Global Accelerator reduces application downtime by propagating change propagation in a matter of seconds, while relying on client devices for IP address caching may take long periods of time.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-5", "source_tokens": 430, "generated_at": "2026-02-11T15:35:37.513844"}}
{"question": "What type of IP addresses does AWS Global Accelerator provide for applications and how does it simplify endpoint movements?", "answer": "AWS Global Accelerator provides static IP addresses that function as a fixed entry point to applications. These addresses simplify endpoint movements by eliminating the need to update DNS configurations or client-facing applications when moving between Availability Zones or AWS Regions.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-11T15:35:43.070422"}}
{"question": "How does AWS Global Accelerator allow for fine-grained control during performance testing and application updates?", "answer": "AWS Global Accelerator enables users to set traffic dials for regional endpoint groups, allowing for up or down traffic adjustments in a specific AWS Region. Additionally, it offers the ability to direct all requests from a user to the same endpoint, regardless of source port and protocol, to maintain client affinity.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-11T15:35:43.070642"}}
{"question": "What is the difference in traffic control features between AWS Global Accelerator and a traditional DNS setup?", "answer": "AWS Global Accelerator offers the ability to set traffic dials for regional endpoint groups to control traffic flow in a specific AWS Region during performance testing or application updates. This contrasts with traditional DNS setups, which do not provide this level of control.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-6", "source_tokens": 194, "generated_at": "2026-02-11T15:35:43.070787"}}
{"question": "What is one advantage of using static IP addresses with AWS Global Accelerator?", "answer": "One advantage of using static IP addresses with AWS Global Accelerator is that it increases the Quality of Service (QoS) for users by onboarding their traffic onto the AWS global network as close to them as possible.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-11T15:35:48.773953"}}
{"question": "How does AWS Global Accelerator improve application availability and performance?", "answer": "AWS Global Accelerator improves application availability and performance by leveraging the AWS globally redundant network to help improve application availability, reduce latency, and provide graceful shutdown and startup of new endpoints in case of failures.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-11T15:35:48.774296"}}
{"question": "How does using static IP addresses with AWS Global Accelerator compare to not using them?", "answer": "Using static IP addresses with AWS Global Accelerator allows for improved traffic routing and redundancy, as it onboards user traffic onto the AWS global network as close to them as possible, and automatically redirects traffic to the next optimal AWS Region in case of failures. Without static IP addresses and AWS Global Accelerator, traffic must take multiple hops through the public internet, potentially over congested and non-redundant network paths.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-7", "source_tokens": 406, "generated_at": "2026-02-11T15:35:48.774719"}}
{"question": "Which certifications does AWS Global Accelerator comply with?", "answer": "AWS Global Accelerator complies with PCI DSS, ISO 9001, ISO 27001, ISO 27017, ISO 27018, SOC, and is HIPAA-eligible.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:35:53.716492"}}
{"question": "Why can't I bring multiple IPv4 pools to AWS Global Accelerator from both services?", "answer": "You can only bring a maximum of two IP ranges to your account for AWS Global Accelerator.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:35:53.716833"}}
{"question": "How does the use of IP addresses differ between AWS Global Accelerator and EC2 Elastic IPs?", "answer": "AWS Global Accelerator IP addresses can be associated with one or more endpoints in any number of AWS Regions and support client-generated connections. EC2 Elastic IPs are tied to a single AWS resource in a single AWS Region and support both client- and server-generated connections.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:35:53.717370"}}
{"question": "What IP addresses does a VPC subnet endpoint contain?", "answer": "A VPC subnet endpoint contains the IP addresses of the EC2 instances that host your application.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-11T15:36:03.962666"}}
{"question": "How does custom routing with accelerators determine which EC2 instance to route traffic to?", "answer": "Custom routing accelerators determine which EC2 instance to route traffic to by mapping the accelerator port to a specific EC2 instance private IP address and port. Your application can monitor the health of the EC2 instances and control traffic failover to another healthy instance by directing user traffic to a different accelerator IP address and port combination.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-11T15:36:03.963006"}}
{"question": "What is the difference between a custom routing accelerator and an external health check for EC2 instances?", "answer": "A custom routing accelerator maps the accelerator port to a specific EC2 instance private IP address and port, allowing your application to monitor the health of the EC2 instances and control traffic failover. An external health check, on the other hand, is not provided by custom routing accelerators. Instead, your application must monitor the health of the EC2 instances and redirect user traffic to a healthy instance based on the accelerator port and IP address mapping.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-10", "source_tokens": 495, "generated_at": "2026-02-11T15:36:03.963504"}}
{"question": "What type of traffic does AWS Global Accelerator support towards Application Load Balancer Endpoints?", "answer": "AWS Global Accelerator supports IPv6 traffic towards Application Load Balancer Endpoints.", "question_type": "factual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-11T15:36:07.680668"}}
{"question": "How does AWS Global Accelerator reduce application downtime?", "answer": "AWS Global Accelerator reduces application downtime by allowing change propagation to take place in a matter of seconds, which eliminates the reliance on client device IP address caching settings.", "question_type": "conceptual", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-11T15:36:07.681022"}}
{"question": "What protocols does AWS Global Accelerator support for both of its endpoints?", "answer": "AWS Global Accelerator supports both TCP and UDP protocols for both its endpoints.", "question_type": "comparison", "metadata": {"service": "GLOBAL", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "global-faq-11", "source_tokens": 209, "generated_at": "2026-02-11T15:36:07.681233"}}
{"question": "What is AWS Glue and what are its primary use cases?", "answer": "AWS Glue is a serverless data integration service that helps discover, prepare, and combine data for analytics, machine learning (ML), and application development. It provides visual and code-based interfaces to make data integration easier, and includes features for data catalog, ETL, data quality, data preparation, schema registry, and product integrations.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T15:36:13.891202"}}
{"question": "How does AWS Glue help users find and access data?", "answer": "AWS Glue helps users find and access data by providing a data catalog that makes it easier to discover and catalog data stores and data in various formats. This allows data engineers and ETL developers to create, run, and monitor ETL workflows, and data analysts and data scientists to visually enrich, clean, and normalize data.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T15:36:13.891571"}}
{"question": "What are the main differences between AWS Glue and AWS Glue DataBrew?", "answer": "AWS Glue is a serverless data integration service that provides capabilities for data catalog, ETL, data quality, data preparation, schema registry, and product integrations. AWS Glue DataBrew, on the other hand, is a visual interface in AWS Glue that allows data analysts and data scientists to visually enrich, clean, and normalize data without writing code.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T15:36:13.892017"}}
{"question": "What is the main component of AWS Glue?", "answer": "AWS Glue is composed of a Data Catalog, a data processing engine, and a flexible scheduler.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-11T15:36:17.829758"}}
{"question": "How does AWS Glue help in managing data?", "answer": "AWS Glue automates the process of discovering, categorizing, cleaning, enriching, and moving data, allowing users to spend more time analyzing their data.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-11T15:36:17.830119"}}
{"question": "What types of data can AWS Glue discover and process?", "answer": "AWS Glue can discover and process both structured and semi-structured data stored in Amazon S3, data warehouse in Amazon Redshift, various databases running on AWS, and Amazon SageMaker open data lakehouse.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-1", "source_tokens": 246, "generated_at": "2026-02-11T15:36:17.830580"}}
{"question": "Which databases can AWS Glue natively access within an Amazon VPC running on Amazon EC2?", "answer": "AWS Glue can natively access databases such as Amazon Aurora, Amazon RDS for MySQL, Amazon RDS for Oracle, Amazon RDS for PostgreSQL, Amazon RDS for SQL Server, Amazon Redshift, Amazon DynamoDB, and Amazon S3, as well as MySQL, Oracle, Microsoft SQL Server, and PostgreSQL.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T15:36:23.185462"}}
{"question": "How does AWS Glue handle unsupported data sources?", "answer": "AWS Glue allows users to write custom Scala or Python code and import custom libraries and Jar files into their AWS Glue ETL jobs to access data sources not natively supported by AWS Glue.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T15:36:23.185806"}}
{"question": "What are the main differences between AWS Glue and Lake Formation?", "answer": "AWS Glule is focused on ETL code creation, job monitoring, and data catalog, while Lake Formation builds upon these features and includes additional capabilities designed to help build, secure, and manage a data lake.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-2", "source_tokens": 459, "generated_at": "2026-02-11T15:36:23.186320"}}
{"question": "What data processing capabilities does Amazon SageMaker Data Processing and Analytics bring together?", "answer": "Amazon SageMaker Data Processing and Analytics brings together data processing capabilities from Amazon Athena, Amazon EMR, AWS Glue, and Amazon Managed Workflows for Apache Airflow.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-11T15:36:29.174763"}}
{"question": "How does the Data Catalog in Amazon SageMaker help in having a common view of data between different services?", "answer": "The Data Catalog in Amazon SageMaker provides built-in integration with Amazon Athena, Amazon EMR, and Amazon Redshift Spectrum. Once you add your table definitions to the Data Catalog, they are available for ETL and readily available for querying in Amazon Athena, Amazon EMR, and Amazon Redshift Spectrum.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-11T15:36:29.175126"}}
{"question": "How does AWS Glue compare to using Amazon EMR's Apache Hive Metastore with the Data Catalog?", "answer": "AWS Glue provides numerous ways to populate metadata into the Data Catalog, including automatic schema inference, crawlers, manual updates, and Hive DDL statements. If you already have a persistent Apache Hive Metastore, you can perform a bulk import of that metadata into the Data Catalog using AWS Glue.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-3", "source_tokens": 469, "generated_at": "2026-02-11T15:36:29.175328"}}
{"question": "What does an AWS Glue crawler do when it connects to a data store?", "answer": "An AWS Glue crawler connects to a data store, progresses through a prioritized list of classifiers to extract the schema of your data and other statistics, and then populates the Data Catalog with this metadata.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T15:36:33.954408"}}
{"question": "How can you customize the behavior of AWS Glue crawlers?", "answer": "You can customize AWS Glue crawlers to classify your own file types.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T15:36:33.954774"}}
{"question": "How does the AWS Glue Data Catalog compare to a Hive Metastore?", "answer": "The AWS Glue Data Catalog is Hive Metastore compatible, and can be used as a Hive Metastore replacement. However, before you can use the AWS Glue Data Catalog with Amazon Athena, Redshift Spectrum, and AWS Glue, you need to upgrade your Athena data catalog.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T15:36:33.954973"}}
{"question": "What programming languages can be used for AWS Glue ETL scripts?", "answer": "AWS Glue ETL scripts can be generated in Scala or Python.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-11T15:36:37.908573"}}
{"question": "How does AWS Glue simplify access to data sources and manage job execution?", "answer": "AWS Glue simplifies access to data sources and manages job execution through its custom ETL library.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-11T15:36:37.908883"}}
{"question": "What are the differences between using AWS Glue's custom ETL library and writing custom Scala or Python code for AWS Glue jobs?", "answer": "Using AWS Glue's custom ETL library simplifies access to data sources and manages job execution, while writing custom Scala or Python code allows for more flexibility and control.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-5", "source_tokens": 436, "generated_at": "2026-02-11T15:36:37.909359"}}
{"question": "What specific actions can be triggered in CloudWatch based on AWS Glue notifications?", "answer": "You can trigger AWS Lambda functions based on error or success notifications from AWS Glue.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-11T15:36:41.556940"}}
{"question": "How does AWS Glue handle job failures before sending an error notification?", "answer": "AWS Glue provides default retry behavior that will retry all failures three times before sending an error notification.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-11T15:36:41.557306"}}
{"question": "What's the difference between using AWS Glue and the Data Catalog for ETL processes?", "answer": "While using both AWS Glue and the Data Catalog provides a complete ETL experience, you can use either one of them independently.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-6", "source_tokens": 259, "generated_at": "2026-02-11T15:36:41.557502"}}
{"question": "What is AWS Glue recommended for in terms of use cases and platform?", "answer": "AWS Glue is recommended for use cases primarily focused on ETL and for running jobs on a serverless Apache Spark-based platform.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-11T15:36:46.656758"}}
{"question": "How does AWS Glue handle use cases that involve streaming data processing?", "answer": "AWS Glue handles streaming data processing by generating customizable ETL code, preparing data while in transit, and providing built-in functionality to process semi-structured or evolving schema data. It also allows users to apply both built-in and Spark-native transforms to data streams.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-11T15:36:46.657131"}}
{"question": "What are the main differences between AWS Glue and Kinesis Data Analytics for processing streaming data?", "answer": "The main differences between AWS Glue and Kinesis Data Analytics lie in the recommended use cases and underlying platforms: AWS Glue is recommended for ETL use cases and uses Apache Spark, while Kinesis Data Analytics is recommended for real-time analytics and more general stream data processing, using Apache Flink.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-7", "source_tokens": 253, "generated_at": "2026-02-11T15:36:46.657615"}}
{"question": "What are the key features of AWS Glue for streaming ETL?", "answer": "AWS Glue for streaming ETL enables advanced ETL on streaming data, generates customizable ETL code, and has built-in functionality to process semi-structured or evolving schema data. It also allows applying complex transforms, enriching records with information from other streams and persistent data stores, and loading records into data lakes or data warehouses.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:36:53.189084"}}
{"question": "How does AWS Glue compare to Kinesis Data Firehose for streaming ETL?", "answer": "AWS Glue provides advanced ETL capabilities, including the ability to apply complex transforms, enrich records with information from other streams and persistent data stores, and load records into data lakes or data warehouses. On the other hand, Kinesis Data Firehose is recommended for data delivery and preparing data to be processed after it is delivered, and includes serverless data transformation through AWS Lambda and format conversion from JSON to Parquet.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:36:53.189457"}}
{"question": "What is the purpose of data quality in the context of data lakes on AWS?", "answer": "Data quality is the measure of how well suited a dataset is to serve its specific purpose, such as analytics to improve operations, business decision making, and planning. Hundreds of thousands of customers use data lakes on AWS, but many struggle to use their data assets effectively due to poor data quality.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-8", "source_tokens": 498, "generated_at": "2026-02-11T15:36:53.189996"}}
{"question": "What rule categories does AWS Glue Data Quality support?", "answer": "AWS Glue Data Quality supports four rule categories: Consistency, Accuracy, Integrity, and Completeness.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-11T15:36:57.293207"}}
{"question": "How does AWS Glue Data Quality determine the appropriate data quality rules?", "answer": "AWS Glue Data Quality uses Deequ, an Amazon developed open-source framework, to gather data statistics and identify the right set of checks or rules to validate data quality.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-11T15:36:57.293544"}}
{"question": "What's the difference between AWS Glue Data Quality and Deequ?", "answer": "AWS Glue Data Quality is a fully managed service that automates data quality checks in your data lakes and pipelines using Deequ, an open-source framework developed by Amazon.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-9", "source_tokens": 480, "generated_at": "2026-02-11T15:36:57.293974"}}
{"question": "What action can you take in the Data Catalog to respond to a data quality issue?", "answer": "You can write metrics to Amazon CloudWatch and set up alerts in CloudWatch to notify you when scores go below a threshold.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T15:37:01.788076"}}
{"question": "How can you use the Data Catalog to manage metadata for different user types?", "answer": "Data stewards and data engineers use the Data Catalog to manage metadata. Data engineers need more technical data quality rules compared to business analysts who write functional rules.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T15:37:01.788424"}}
{"question": "What tools does AWS Glue Studio offer for data preparation, and for whom are they intended?", "answer": "AWS Glue Studio offers a visual data preparation tool for data analysts and data scientists to prepare data without writing code. Data preparation in AWS Glue is built for users who need to clean and normalize data for analytics and ML.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T15:37:01.788925"}}
{"question": "What file formats does DataBrew support for input data?", "answer": "DataBrew supports commonly used file formats such as comma-separated values (.csv), JSON and nested JSON, Apache Parquet and nested Apache Parquet, and Excel sheets for input data.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:37:08.378287"}}
{"question": "Who are the primary users of DataBrew for data preparation?", "answer": "The primary users of DataBrew for data preparation are data analysts and data scientists. Examples of job functions for data analysts include business intelligence analysts, operations analysts, market intelligence analysts, legal analysts, financial analysts, economists, quants, or accountants. For data scientists, examples of job functions are materials scientists, bioanalytical scientists, and scientific researchers.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:37:08.378616"}}
{"question": "How does DataBrew compare to other data preparation tools in terms of transformation capabilities?", "answer": "DataBrew offers over 250 built-in transformations to combine, pivot, and transpose data without writing code. It also automatically recommends transformations such as filtering anomalies, correcting invalid, incorrectly classified, or duplicate data, normalizing data to standard date and time values, or generating aggregates for analyses. For complex transformations, DataBrew provides transformations that use advanced ML techniques such as natural language processing (NLP). Users can group multiple transformations together, save them as recipes, and apply the recipes directly to the new incoming data.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-11", "source_tokens": 480, "generated_at": "2026-02-11T15:37:08.379048"}}
{"question": "What is the number of free interactive sessions available for first-time users of AWS Glue DataBrew?", "answer": "The first 40 interactive sessions are free for first-time users of AWS Glue DataBrew.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-11T15:37:14.497678"}}
{"question": "How does using AWS Glue Data Catalog or Lake Formation impact the use of AWS Glue DataBrew?", "answer": "AWS Glue DataBrew can be used without using either the Data Catalog or Lake Formation, but if you use either, DataBrew users can select the datasets available to them from their centralized data catalog.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-11T15:37:14.497919"}}
{"question": "What are the benefits of using the Schema Registry in AWS Glue compared to not using it?", "answer": "Using the Schema Registry in AWS Glue allows for validation and control of the evolution of streaming data using schemas registered in Apache Avro and JSON Schema data formats. It integrates with various applications, including Java applications developed for Apache Kafka, Amazon MSK, Amazon Kinesis Data Streams, Apache Flink, Amazon Kinesis Data Analytics for Apache Flink, and AWS Lambda. It also improves data quality and safeguards against unexpected changes through compatibility checks that govern schema evolution and enables the creation or update of AWS Glue tables and partitions using Apache Avro schemas stored within the registry.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-12", "source_tokens": 378, "generated_at": "2026-02-11T15:37:14.498072"}}
{"question": "What are the three main benefits of using AWS Schema Registry?", "answer": "The three main benefits of using AWS Schema Registry are: centrally controlling data quality by validating schemas, safeguarding schema evolution by setting rules on how schemas can and cannot evolve, and improving data quality and processing efficiency by validating schemas used by data producers.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-11T15:37:19.932452"}}
{"question": "How does the Schema Registry improve processing efficiency when dealing with data streams containing records of different schemas?", "answer": "The Schema Registry enables applications that read from data streams to selectively process each record based on the schema without having to parse its contents, increasing processing efficiency.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-11T15:37:19.932817"}}
{"question": "What are the compatibility modes available for schema evolution in the Schema Registry and how does Backward compatibility mode differ from Forward compatibility mode?", "answer": "The following compatibility modes are available for schema evolution in the Schema Registry: Backward, Backward All, Forward, Forward All, Full, Full All, None, and Disabled. Backward compatibility mode allows new versions to read old versions, while Forward compatibility mode allows old versions to read new versions.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-13", "source_tokens": 507, "generated_at": "2026-02-11T15:37:19.933081"}}
{"question": "What service does AWS PrivateLink allow you to connect your VPC to for secure communication?", "answer": "AWS Glue", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T15:37:23.806108"}}
{"question": "How does the use of a VPC interface endpoint in AWS Glue impact communication between your VPC and AWS Glue?", "answer": "Communication between your VPC and AWS Glue is conducted entirely within the AWS network", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T15:37:23.806455"}}
{"question": "How does the standard execution class in AWS Glue compare to the flexible execution class in terms of job execution properties?", "answer": "The standard execution class starts jobs immediately with dedicated resources, while the flexible execution class runs on non-dedicated compute resources and has start and completion times that may vary", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T15:37:23.806982"}}
{"question": "What execution class do I need to use in AWS Glue for flexible execution?", "answer": "You need to change the default setting of the execution class parameter from STANDARD to FLEX.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-11T15:37:27.900559"}}
{"question": "Why is the flexible execution class not suitable for certain workloads in AWS Glue?", "answer": "The flexible execution class is not suitable for time-sensitive workloads or long-running data integration workloads due to the potential for interruptions and frequent cancellations.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-11T15:37:27.900898"}}
{"question": "How does the availability of AWS Glue Flex jobs compare to standard jobs?", "answer": "AWS Glue Flex jobs depend on the availability of non-dedicated AWS capacity and may not start during peak times. In contrast, standard jobs have dedicated resources.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-15", "source_tokens": 459, "generated_at": "2026-02-11T15:37:27.901326"}}
{"question": "What types of jobs can be run using the flexible execution class in AWS Glue?", "answer": "AWS Glue's flexible execution class supports only AWS Glue Spark jobs.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-11T15:37:32.176489"}}
{"question": "Why is AWS Glue recommended for ETL use cases instead of AWS Batch?", "answer": "AWS Glue is a fully managed ETL service that provides a serverless Apache Spark environment to run ETL jobs, while AWS Batch is recommended for other batch-oriented use cases.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-11T15:37:32.176706"}}
{"question": "How does AWS Glue compare to Amazon EMR for data transformation jobs?", "answer": "AWS Glue simplifies the process of creating and maintaining data transformation jobs by inferring, evolving, and monitoring your ETL jobs, whereas Amazon EMR provides lower-level access and greater flexibility in using tools beyond Spark.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-16", "source_tokens": 372, "generated_at": "2026-02-11T15:37:32.176843"}}
{"question": "What is the monthly fee for storing and accessing metadata in AWS Glue Data Catalog after the free tier?", "answer": "You will pay a simple monthly fee for storing and accessing metadata in the Data Catalog above the AWS Glue Data Catalog free tier.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-11T15:37:36.925758"}}
{"question": "Why would you use Usage Profiles in AWS Glue for cost control?", "answer": "Admins can create different cost profiles for different classes of users in AWS Glue using Usage Profiles, which is a cost control capability.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-11T15:37:36.926099"}}
{"question": "How does the billing work for AWS Glue ETL jobs compared to the development endpoints?", "answer": "AWS Glue ETL jobs require a minimum of 2 DPUs and by default, AWS Glue allocates 10 DPUs to each ETL job, while development endpoints have an hourly rate billed per second with a 10-minute minimum.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-17", "source_tokens": 487, "generated_at": "2026-02-11T15:37:36.926516"}}
{"question": "What is the eligibility requirement for an SLA credit for AWS Glue?", "answer": "You are eligible for an SLA credit for AWS Glue if more than one Availability Zone in the same Region has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle.", "question_type": "factual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-11T15:37:42.032078"}}
{"question": "How does the AWS Glue SLA determine credit eligibility?", "answer": "The AWS Glue SLA determines credit eligibility by evaluating the Monthly Uptime Percentage of more than one Availability Zone in the same Region during a monthly billing cycle.", "question_type": "conceptual", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-11T15:37:42.032420"}}
{"question": "How does the AWS Glue SLA compare to an SLA with only one Availability Zone requirement?", "answer": "The AWS Glue SLA requires that more than one Availability Zone in the same Region experiences less than 99.9% Monthly Uptime Percentage for SLA credit eligibility, whereas an SLA with only one Availability Zone requirement would only consider the availability of that one zone.", "question_type": "comparison", "metadata": {"service": "GLUE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "glue-faq-18", "source_tokens": 105, "generated_at": "2026-02-11T15:37:42.032969"}}
{"question": "What service does Amazon GuardDuty provide and what does it monitor?", "answer": "Amazon GuardDuty is a fully managed threat detection service provided by AWS. It continuously monitors AWS accounts, workloads, runtime activity, and data for malicious activity such as anomalous behavior, credential exfiltration, and command and control infrastructure communication.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-11T15:37:48.495653"}}
{"question": "How does Amazon GuardDuty work and what benefits does it offer?", "answer": "Amazon GuardDuty is designed to operate independently from resources and have zero performance or availability impact to workloads. It utilizes machine learning anomaly detection, malware scanning, and integrated threat intelligence to continuously monitor AWS accounts, workloads, runtime activity, and data for malicious activity. The service generates detailed security findings that can be used for security visibility and assisting in remediation. There are no upfront costs and you pay only for the events analyzed.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-11T15:37:48.495995"}}
{"question": "How does GuardDuty Malware Protection compare to GuardDuty Runtime Monitoring?", "answer": "GuardDuty Malware Protection and GuardDuty Runtime Monitoring are both services provided by Amazon GuardDuty. Malware Protection monitors AWS workloads for malware while Runtime Monitoring continuously monitors AWS accounts, workloads, and runtime activity for malicious activity. The specific comparison between these two services would depend on the particular security needs of your organization, such as the importance of malware detection versus broader threat detection.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-0", "source_tokens": 400, "generated_at": "2026-02-11T15:37:48.496206"}}
{"question": "What factors determine the cost of using GuardDuty?", "answer": "GuardDuty pricing is based on the volume of analyzed service logs, vCPUs or ACUs for Amazon RDS event analysis, the number and size of EKS or ECS workloads being monitored at runtime, and the volume of data scanned for malware.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T15:37:53.940549"}}
{"question": "Why is it more cost-effective to use GuardDuty with EKS instead of separate VPC Flow Log analysis?", "answer": "GuardDuty integrates directly with EKS and provides more contextual network telemetry data through its runtime security agent. This avoids double charging customers for VPC Flow Logs from Amazon EC2 instances where the agent is installed.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T15:37:53.940888"}}
{"question": "How does the cost of GuardDuty for analyzing Amazon RDS event logs differ from analyzing EKS or ECS workloads?", "answer": "GuardDuty pricing for analyzing Amazon RDS event logs is based on the vCPUs or ACUs for Amazon RDS instance, while the cost for analyzing EKS or ECS workloads is based on the number and size of the workloads being monitored.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T15:37:53.941429"}}
{"question": "What is the length of the free trial for GuardDuty?", "answer": "The free trial for GuardDuty lasts for 30 days.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T15:37:58.312658"}}
{"question": "How does GuardDuty ensure regional data analysis?", "answer": "GuardDuty ensures regional data analysis by keeping all security findings in the same Region where the underlying data was generated. Users can also aggregate findings across Regions using Amazon EventBridge, pushing findings to a data store, or using AWS Security Hub.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T15:37:58.312973"}}
{"question": "What services does GuardDuty offer a free trial for, and how long is it?", "answer": "GuardDuty offers a free trial for its full feature set and Malware Protection feature for 30 days. The free trial for Malware Protection is available for GuardDuty-initiated malware scans only for Amazon EBS data volumes.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T15:37:58.313175"}}
{"question": "What foundational data sources does GuardDuty analyze?", "answer": "GuardDuty analyzes AWS CloudTrail management event logs, CloudTrail management events, and Amazon EC2 VPC Flow Logs and DNS query logs.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T15:38:02.953381"}}
{"question": "How does GuardDuty help organizations meet PCI DSS requirements?", "answer": "GuardDuty, as assessed in a Foregenix white paper, is effective in meeting requirements like PCI DSS requirement 11.4, which requires intrusion detection techniques at critical points in the network.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T15:38:02.953720"}}
{"question": "What's the difference between the multiple account management feature and the integration with AWS Organizations in GuardDoot?", "answer": "The multiple account management feature allows associating and managing multiple AWS accounts from a single administrator account, while the integration with AWS Organizations allows delegating an administrator account for GuardDuty for your organization and consolidating all findings.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-3", "source_tokens": 507, "generated_at": "2026-02-11T15:38:02.954249"}}
{"question": "What does GuardDuty analyze after being enabled?", "answer": "GuardDuty analyzes for malicious or unauthorized activity in real time after being enabled.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-11T15:38:06.356900"}}
{"question": "Why doesn't GuardDuty look at historical data?", "answer": "GuardDuty does not look at historical data to maintain efficiency and cost effectiveness.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-11T15:38:06.357268"}}
{"question": "How does GuardDuty compare to AWS logging and monitoring services for log retention?", "answer": "GuardDuty does not manage or retain logs, whereas AWS logging and monitoring services provide full-featured log delivery and retention options.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-4", "source_tokens": 420, "generated_at": "2026-02-11T15:38:06.357464"}}
{"question": "What happens when I suspend GuardDuty?", "answer": "When you suspend GuardDuty, the service immediately stops analyzing data. Your existing findings and configurations are not deleted.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-11T15:38:10.430022"}}
{"question": "Why would I choose to disable GuardDuty instead of suspending it?", "answer": "You would choose to disable GuardDuty instead of suspending it if you want to delete all existing findings, configurations, and service permissions.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-11T15:38:10.430393"}}
{"question": "How does disabling GuardDuty's S3 Protection differ from suspending the entire service?", "answer": "Disabling S3 Protection allows you to keep the rest of the GuardDuty service running while stopping analysis for only S3 data sources. Suspending the entire service stops analysis for all data sources and deletes existing findings and configurations if the service is later disabled.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-5", "source_tokens": 123, "generated_at": "2026-02-11T15:38:10.430790"}}
{"question": "What are the primary detection categories for GuardDuty?", "answer": "The primary detection categories for GuardDuty include Reconnaissance, Instance compromise, Account compromise, Bucket compromise, and Malware.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T15:38:17.106392"}}
{"question": "How does GuardDuty detect instance compromise?", "answer": "GuardDuty detects instance compromise by monitoring for activities such as cryptocurrency mining, malware using domain generation algorithms (DGAs), outbound denial of service activity, an unusually high volume of network traffic, unusual network protocols, outbound instance communication with a known malicious IP, temporary Amazon EC2 credentials used by an external IP address, and data exfiltration using DNS.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T15:38:17.106736"}}
{"question": "What's the difference between how GuardDuty detects instance compromise and bucket compromise?", "answer": "GuardDuty detects instance compromise by monitoring Amazon EC2 instances for activities such as cryptocurrency mining, malware using domain generation algorithms (DGAs), outbound denial of service activity, an unusually high volume of network traffic, unusual network protocols, outbound instance communication with a known malicious IP, temporary Amazon EC2 credentials used by an external IP address, and data exfiltration using DNS. In contrast, GuardDuty detects bucket compromise by monitoring Amazon S3 buckets for suspicious data access patterns indicating credential misuse, unusual Amazon S3 API activity from a remote host, and unauthorized Amazon S3 access from known malicious IP addresses.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T15:38:17.107181"}}
{"question": "What are the different types of GuardDuty findings?", "answer": "The text passage lists the types of GuardDuty findings.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-11T15:38:20.326883"}}
{"question": "How does GuardDuty identify different types of findings?", "answer": "The text passage does not provide information on how GuardDuty identifies different types of findings.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-11T15:38:20.328202"}}
{"question": "What is the difference between a 'Malicious' finding and a 'High Severity' finding in GuardDuty?", "answer": "The text passage does not provide enough context to make a comparison between 'Malicious' and 'High Severity' findings.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-7", "source_tokens": 16, "generated_at": "2026-02-11T15:38:20.328365"}}
{"question": "What types of threat intelligence does GuardDuty provide?", "answer": "GuardDuty provides threat intelligence made up of IP addresses and domains known to be used by attackers. This intelligence is provided by AWS and third-party providers, such as Proofpoint and CrowdStrike.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-11T15:38:25.351874"}}
{"question": "How does GuardDuty make security findings more actionable?", "answer": "GuardDuty makes security findings more actionable by delivering detailed findings to the GuardDuty console and EventBridge. The findings include the category, resource affected, and metadata associated with the resource, such as a severity level.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-11T15:38:25.352224"}}
{"question": "How does the threat intelligence format in GuardDuty compare to Amazon Macie and Amazon Inspector?", "answer": "The threat intelligence format in GuardDuty comes in a common JSON format, which is also used by Amazon Macie and Amazon Inspector. This makes it easier for customers and partners to consume security findings from all three services and incorporate them into broader event management, workflow, or security solutions.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-8", "source_tokens": 512, "generated_at": "2026-02-11T15:38:25.352754"}}
{"question": "What new features does GuardDuty add during the 30-day free trial?", "answer": "During the 30-day free trial, GuardDuty adds the S3 Protection feature to your account.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T15:38:29.461724"}}
{"question": "How does GuardDuty incorporate customer feedback into its detections?", "answer": "GuardDuty obtains customer feedback through mechanisms like thumbs-up and thumbs-down in the UI, which might be incorporated into future iterations of the service.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T15:38:29.462069"}}
{"question": "What is the difference between enabling GuardDuty and S3 Protection?", "answer": "GuardDuty is the main AWS security service, while S3 Protection is a specific feature within GuardDuty that monitors Amazon S3 buckets.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T15:38:29.462556"}}
{"question": "What type of logs does GuardDuty EKS Protection use for monitoring Amazon EKS clusters?", "answer": "GuardDuty EKS Protection uses Amazon EKS audit logs for monitoring Amazon EKS clusters.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-11T15:38:34.064312"}}
{"question": "How does GuardDuty identify threats in Amazon EKS clusters using audit logs?", "answer": "GuardDuty identifies threats in Amazon EKS clusters by analyzing Amazon EKS audit logs for security-relevant activity and applying threat intelligence and anomaly detection.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-11T15:38:34.064661"}}
{"question": "How does the threat detection capability of GuardDuty in Amazon EKS compare to using Amazon EKS audit logs directly?", "answer": "GuardDuty's threat detection capability in Amazon EKS is a more efficient alternative to analyzing Amazon EKS audit logs directly, as GuardDuty applies intelligent filters to only consume a subset of the audit logs that are relevant for security threat detection and includes proven threat intelligence and anomaly detection.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-10", "source_tokens": 431, "generated_at": "2026-02-11T15:38:34.064864"}}
{"question": "What is the length of the free trial for GuardDuty EKS Protection?", "answer": "The free trial for GuardDuty EKS Protection lasts for 30 days.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-11T15:38:38.306960"}}
{"question": "How can a user activate GuardDuty EKS Protection across their entire organization?", "answer": "A user can activate GuardDuty EKS Protection across their entire organization from the GuardDuty administrator account GuardDuty EKS Protection page.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-11T15:38:38.307298"}}
{"question": "What's the difference between activating GuardDuty EKS Protection for an individual account and activating it for an entire organization?", "answer": "Activating GuardDuty EKS Protection for an individual account is done from the GuardDuty console for that account, while activating it for an entire organization is done from the GuardDuty administrator account.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-11", "source_tokens": 456, "generated_at": "2026-02-11T15:38:38.307831"}}
{"question": "What action is required to re-enable GuardDuty EKS Protection in the console?", "answer": "You can re-enable GuardDuty EKS Protection in the console by going to the GuardDuty EKS Protection console page and enabling the feature for your accounts.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-11T15:38:42.669676"}}
{"question": "How can you enable GuardDuty EKS Protection for multiple accounts at once?", "answer": "You can enable GuardDuty EKS Protection for multiple accounts at once by enabling the feature on the GuardDuty administrator account GuardDuty EKS Protection console page.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-11T15:38:42.670017"}}
{"question": "What are the monitoring implications of enabling GuardDuty EKS Protection for an account that doesn't use Amazon EKS?", "answer": "If you enable GuardDuty EKS Protection for an account that doesn't use Amazon EKS, there will be no monitoring implications or charges.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-12", "source_tokens": 422, "generated_at": "2026-02-11T15:38:42.670553"}}
{"question": "What level of resources can GuardDuty Runtime Monitoring be activated for?", "answer": "GuardDuty Runtime Monitoring can be activated for Amazon EKS resources running on Amazon EC2, Amazon ECS clusters running on Amazon EC2 or AWS Fargate, and Amazon EC2 instances.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-11T15:38:47.471854"}}
{"question": "How does GuardDuty Runtime Monitoring provide security analytics processing?", "answer": "GuardDuty Runtime Monitoring provides security analytics processing by collecting runtime events using a lightweight, fully managed security agent, which is deployed as a Daemon set. The security agent delivers the collected events to GuardDuty for analysis.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-11T15:38:47.472201"}}
{"question": "What's the difference between GuardDuty Runtime Monitoring and other GuardDuty protection plans?", "answer": "The main difference is that GuardDuty Runtime Monitoring is the only protection plan that is not enabled by default when you turn on GuardDuty for the first time. It can be activated from the GuardDuty console or through the API.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-13", "source_tokens": 353, "generated_at": "2026-02-11T15:38:47.472698"}}
{"question": "What update method is used for the GuardDuty agent in Amazon ECS on Fargate?", "answer": "The GuardDuty agent in Amazon ECS on Fargate pulls the latest version automatically.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-11T15:38:52.307135"}}
{"question": "Why do users have the option to manually deploy the GuardDuty agent for Amazon ECS on EC2 or Amazon EKS?", "answer": "Users can manually deploy the GuardDuty agent for Amazon ECS on EC2 or Amazon EKS if they prefer to manage the update process themselves.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-11T15:38:52.307470"}}
{"question": "How does the update process differ between Amazon ECS on EC2 and Amazon ECS on Fargate for the GuardDuty agent?", "answer": "For Amazon ECS on EC2, users can update to the latest ECS optimized AMI or ECS agent to receive the latest GuardDuty agent version. In contrast, for Amazon ECS on Fargate, the Fargate agent pulls the latest GuardDuty agent version automatically.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-14", "source_tokens": 498, "generated_at": "2026-02-11T15:38:52.308004"}}
{"question": "WhatAmazon services can be selectively monitored for threat detection with GuardDuty Runtime Monitoring?", "answer": "Amazon EKS clusters and Amazon ECS clusters can be selectively monitored for threat detection with GuardDuty Runtime Monitoring.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-11T15:38:56.946611"}}
{"question": "Whyis it beneficial to selectively monitor specific clusters with GuardDuty Runtime Monitoring?", "answer": "Selectively monitoring specific clusters with GuardDuty Runtime Monitoring allows for targeted threat detection, while continuing to monitor all clusters account-wide can be done if preferred.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-11T15:38:56.946959"}}
{"question": "Whatis the difference in resource utilization and costs between selectively deploying and automatically deploying the GuardDuty security agent?", "answer": "Manually deploying the GuardDuty security agent for selective monitoring introduces additional resource utilization and creates VPC endpoints, while automatic deployment by GuardDuty also incurs the cost impact of monitoring covered workloads.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-15", "source_tokens": 460, "generated_at": "2026-02-11T15:38:56.947474"}}
{"question": "What types of Amazon EBS volumes does GuardDuty scan for malware?", "answer": "GuardDuty scans replica Amazon EBS volumes that it generates based on the snapshot of your Amazon EBS volume for malware.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-11T15:39:01.960283"}}
{"question": "How does GuardDuty handle malware detection in S3?", "answer": "Once a bucket is configured for malware protection, GuardDuty automatically scans newly uploaded files and generates an Amazon EventBridge notification with details about the malware if it's detected. You can then configure to automatically quarantine malware by moving the object to an isolated bucket or use object tags to add the disposition of the scan result.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-11T15:39:01.960647"}}
{"question": "What are the differences between GuardDuty's malware scanning for Amazon EBS and S3?", "answer": "GuardDuty scans replica Amazon EBS volumes for malware when it identifies suspicious behavior, while S3 object scanning automatically scans newly uploaded files and generates notifications with malware details.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-16", "source_tokens": 463, "generated_at": "2026-02-11T15:39:01.961141"}}
{"question": "What types of threats does AWS GuardDuty Malware Protection scan for?", "answer": "AWS GuardDuty Malware Protection scans for threats such as trojans, worms, crypto miners, rootkits, and bots.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-11T15:39:06.309784"}}
{"question": "How does AWS GuardDuty Malware Protection scan for malware?", "answer": "AWS GuardDuty Malware Protection scans by creating and scanning a replica of Amazon EBS volumes or scanning uploaded objects in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-11T15:39:06.310001"}}
{"question": "How does AWS GuardDuty Malware Protection for Amazon EBS compare to traditional security agents?", "answer": "AWS GuardDuty Malware Protection for Amazon EBS does not require you to install security agents. Instead, it creates and scans a replica of your EBS volumes for malware.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-17", "source_tokens": 393, "generated_at": "2026-02-11T15:39:06.310393"}}
{"question": "What is the duration of the free trial for Malware Protection in GuardDuty?", "answer": "Each new GuardDuty account in each Region receives a 30-day free trial of GuardDuty's Malware Protection feature. Existing accounts also receive a 30-day trial at no additional charge when enabling it for the first time.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-11T15:39:12.289551"}}
{"question": "How can an administrator enable Malware Protection for all member accounts in a multi-account setup?", "answer": "An administrator can enable Malware Protection across their entire organization in the GuardDuty administrator account's Malware Protection console page. This will enable monitoring for malware in all individual member accounts.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-11T15:39:12.289827"}}
{"question": "What are the differences between enabling Malware Protection for GuardDuty and S3?", "answer": "For GuardDuty, you can enable Malware Protection in the GuardDuty console or API, and it will monitor for malware in all member accounts in a multi-account setup. For S3, as an application owner, you need to set up the bucket protection configuration in the GuardDuty console or when creating a new bucket. GuardDuty sends scan metrics to your EventBridge events and allows you to set up alarms and define post-scan actions based on the scan result.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-18", "source_tokens": 446, "generated_at": "2026-02-11T15:39:12.289970"}}
{"question": "What is the default setting for Malware Protection when a new GuardDuty account is created using the console or API?", "answer": "Malware Protection is enabled by default for new GuardDuty accounts created using the console or API.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-11T15:39:17.981763"}}
{"question": "Why do you need to explicitly enable Malware Protection for new GuardDuty accounts created using the AWS Organizations auto-enable feature?", "answer": "You need to explicitly enable the auto-enable for Malware Protection option for new GuardDuty accounts created using the AWS Organizations auto-enable feature.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-11T15:39:17.982108"}}
{"question": "How does enabling and disabling Malware Protection impact the performance of your workloads in different AWS Regions?", "answer": "Enabling Malware Protection initiates a malware scan in response to relevant Amazon EC2 findings, which generates a volume snapshot for malware analysis. This snapshot can only be generated once in a 24-hour period, and GuardDuty Malware Protection retains the encrypted replicas and snapshots for a few minutes after it completes a scan. GuardDuty Malware Protection uses GuardDuty compute resources for malware scanning instead of customer compute resources, so it does not affect the performance of your workloads.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-19", "source_tokens": 487, "generated_at": "2026-02-11T15:39:17.982696"}}
{"question": "Which key does GuardDuty use to encrypt the replica EBS volume of an encrypted Amazon EBS volume?", "answer": "GuardDuty uses the AWS Key Management Service (KMS) key that is shared with it by the user.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-11T15:39:22.202538"}}
{"question": "How does GuardDuty handle encryption for replica EBS volumes of unencrypted Amazon EBS volumes?", "answer": "GuardDuty uses its own key to encrypt the replica EBS volume for unencrypted Amazon EBS volumes.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-11T15:39:22.202721"}}
{"question": "What's the difference in encryption key usage between encrypted and unencrypted Amazon EBS volumes in GuardDuty?", "answer": "Encrypted Amazon EBS volumes allow sharing of the AWS KMS key with GuardDuty, while unencrypted Amazon EBS volumes use GuardDuty's own key for encryption.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-20", "source_tokens": 167, "generated_at": "2026-02-11T15:39:22.202832"}}
{"question": "What is the length of the free trial for the Malware Protection feature in each new GuardDuty account in each Region?", "answer": "Each new GuardDuty account, in each Region, receives a 30-day free trial of GuardDuty, including the Malware Protection feature.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-11T15:39:27.453086"}}
{"question": "Why can you control the cost of malware scanning for EBS volumes by excluding or including certain instances?", "answer": "You can control the cost of malware scanning for EBS volumes by excluding or including certain instances using tags. This allows you to only scan instances that you want and avoid scanning instances that you don't need.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-11T15:39:27.453439"}}
{"question": "How does the pricing for malware scanning of EBS volumes and S3 buckets compare?", "answer": "The pricing for malware scanning of EBS volumes is based on the GB of data scanned in a volume. The pricing for malware scanning of storage objects in S3 buckets is based on the GB of data scanned and the number of files scanned in a designated S3 bucket.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-21", "source_tokens": 487, "generated_at": "2026-02-11T15:39:27.453560"}}
{"question": "How long does GuardDuty retain a replica Amazon EBS volume after scanning it?", "answer": "By default, GuardDuty retains each replica Amazon EBS volume for up to 24 hours. In case of service outages or connection problems, the retention period can be extended up to seven days.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-11T15:39:32.895317"}}
{"question": "Why might GuardDuty retain a replica Amazon EBS volume for longer than 24 hours?", "answer": "GuardDuty might retain a replica Amazon EBS volume for longer than 24 hours if a service outage or connection problem interferes with its malware scan. In such cases, GuardDuty will retain the replica volume to give the service time to triage and address the issue.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-11T15:39:32.895620"}}
{"question": "How does the retention period for replica Amazon EBS volumes in GuardDuty compare to the frequency of malware scans?", "answer": "By default, GuardDuty scans a replica Amazon EBS volume once every 24 hours. However, if GuardDuty generates a qualified finding after 24 hours from the last malware scan, it will retain the replica volume for up to seven days. Therefore, the retention period for replica volumes is longer than the frequency of malware scans.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-22", "source_tokens": 402, "generated_at": "2026-02-11T15:39:32.895742"}}
{"question": "What actions are required to turn on GuardDuty RDS Protection for an existing account?", "answer": "You can turn on GuardDuty RDS Protection for an existing account through the GuardDuty console on the RDS Protection page or through the API.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-11T15:39:37.607570"}}
{"question": "How does GuardDuty RDS Protection work to identify potential threats?", "answer": "GuardDuty RDS Protection uses tailored ML models to analyze and profile login attempts to Amazon Aurora databases. It identifies suspicious behaviors or attempts by known malicious actors and issues actionable security findings to the GuardDuty and Amazon RDS consoles, Security Hub, and Amazon EventBridge.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-11T15:39:37.608282"}}
{"question": "How does GuardDuty RDS Protection compare to GuardDuty Lambda Protection?", "answer": "GuardDuty RDS Protection monitors Amazon Aurora databases for potential threats, while GuardDuty Lambda Protection monitors network activity from serverless workloads.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-23", "source_tokens": 495, "generated_at": "2026-02-11T15:39:37.608471"}}
{"question": "What method can I use to activate GuardDuty Lambda Protection for my existing account?", "answer": "You can activate GuardDuty Lambda Protection for your existing account through the GuardDuty console on the Lambda Protection page or through the API.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-11T15:39:42.426554"}}
{"question": "How does GuardDuty's Extended Threat Detection benefit me in terms of threat detection and response?", "answer": "GuardDuty's Extended Threat Detection uses AI and ML techniques to automatically correlate disparate threat signals, providing faster threat detection and response, improved visibility into multi-resource and account attack sequences, and prescriptive remediation recommendations based on AWS best practices and MITRE ATT&CK tactic and technique mappings.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-11T15:39:42.426920"}}
{"question": "How does the cost and performance impact of GuardDuty Lambda Protection compare to not using it?", "answer": "GuardDuty Lambda Protection has no performance, availability, or cost implications to your Lambda workloads.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-24", "source_tokens": 496, "generated_at": "2026-02-11T15:39:42.427119"}}
{"question": "What protection plans do I need to enable for GuardDuty to identify data compromises related to ransomware events?", "answer": "You need to enable GuardDuty S3 Protection in addition to the foundational threat detection for GuardDuty to identify data compromises related to ransomware events.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T15:39:47.762614"}}
{"question": "In what ways does enabling GuardDuty S3 Protection enhance the Extended Threat Detection capabilities?", "answer": "Enabling GuardDuty S3 Protection allows GuardDuty to identify potential data exfiltration activities that may occur after S3 bucket access becomes more permissive, in addition to detecting IAM privilege discovery and S3 control plane alterations.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T15:39:47.762964"}}
{"question": "How does enabling GuardDuty S3 Protection compare to only having GuardDuty foundational threat detection enabled?", "answer": "With GuardDuty S3 Protection enabled, GuardDuty can identify potential data exfiltration activities and provide a more comprehensive view of potential threats targeting your S3 resources. Without S3 Protection, GuardDuty can only detect IAM privilege discovery and S3 control plane alterations.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T15:39:47.763424"}}
{"question": "What kind of attack sequences can GuardDuty detect with S3 Protection?", "answer": "GuardDuty can detect multi-stage attack sequences involving Amazon S3 resources, such as IAM privilege discovery activities followed by S3 bucket policy changes, or suspicious API calls to list or modify S3 buckets followed by anomalous data access or transfer activities.", "question_type": "factual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-11T15:39:54.418490"}}
{"question": "How does GuardDuty enhance the security of Amazon EKS clusters with the combination of EKS Protection and Runtime Monitoring?", "answer": "By correlating security signals from Amazon EKS audit logs, runtime behaviors, and AWS API activity, GuardDuty can detect sophisticated attack sequences that might go unnoticed by individual detections. This includes compromise of containers running vulnerable web applications, unauthorized access through misconfigured credentials, attempts to escalate privileges within the cluster, suspicious API requests to the Kubernetes API server, and attempts to access sensitive data or AWS resources through compromised pods.", "question_type": "conceptual", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-11T15:39:54.418860"}}
{"question": "How does S3 Protection in GuardDuty compare to EKS Protection in terms of detected threats?", "answer": "S3 Protection in GuardDuty monitors activities related to Amazon S3 resources and detects threats such as unauthorized access, privilege escalation, and data exfiltration. EKS Protection in GuardDuty, on the other hand, monitors control plane activities and container behaviors within Amazon EKS clusters and detects threats such as container compromise, privilege escalation, and unauthorized access to AWS resources.", "question_type": "comparison", "metadata": {"service": "GUARDDUTY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "guardduty-faq-26", "source_tokens": 448, "generated_at": "2026-02-11T15:39:54.419089"}}
{"question": "What format does AWS HealthLake use to store and organize health data?", "answer": "AWS HealthLake uses the Fast Healthcare Interoperability Resources (FHIR) industry standard format to store and organize health data.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-11T15:39:58.796429"}}
{"question": "How does AWS HealthLake enable healthcare organizations to analyze their data?", "answer": "AWS HealthLake enables healthcare organizations to analyze their data by using machine learning models that extract meaningful medical information from the raw data, such as medications, procedures, and diagnoses.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-11T15:39:58.796637"}}
{"question": "How does AWS HealthLake compare to other data storage solutions in terms of data interoperability?", "answer": "AWS HealthLake uses the FHIR industry standard format to provide interoperability between different healthcare systems and enables easy copying of health data from on-premises systems to a secure data lake in the cloud.", "question_type": "comparison", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-0", "source_tokens": 349, "generated_at": "2026-02-11T15:39:58.796762"}}
{"question": "What format does AWS HealthLake ingest healthcare data in?", "answer": "AWS HealthLake ingests healthcare data in FHIR R4 format.", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T15:40:02.834208"}}
{"question": "How can clinicians use machine learning models with AWS HealthLake?", "answer": "Clinicians can use web or mobile application dashboards to view the results of custom or pre-built machine learning models built using Amazon SageMaker with AWS HealthLake normalized data.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T15:40:02.834459"}}
{"question": "What are some AWS services that can be used with AWS HealthLake for machine learning and cognitive search applications?", "answer": "Amazon SageMaker, Amazon Neptune, and Amazon Kendra can be used with AWS HealthLake for machine learning and cognitive search applications.", "question_type": "comparison", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-1", "source_tokens": 459, "generated_at": "2026-02-11T15:40:02.834628"}}
{"question": "What encryption method is used for data at rest in AWS HealthLake?", "answer": "Customer data in AWS HealthLake is encrypted using Customer-Managed Keys (CMK).", "question_type": "factual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-11T15:40:07.062599"}}
{"question": "How is sensitive health data protected in AWS HealthLake?", "answer": "AWS HealthLake is a HIPAA-eligible service that ensures patientsâ€™ sensitive health data is protected and meets regulatory compliance. Data is encrypted at all times, in transit and at rest, and versioned when deleted.", "question_type": "conceptual", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-11T15:40:07.062976"}}
{"question": "How does AWS HealthLake compare to other services in handling data encryption?", "answer": "AWS HealthLake uses Customer-Managed Keys (CMK) for encrypting customer data at rest within its service boundary, ensuring security and HIPAA-eligible requirements.", "question_type": "comparison", "metadata": {"service": "HEALTHLAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "healthlake-faq-2", "source_tokens": 434, "generated_at": "2026-02-11T15:40:07.063196"}}
{"question": "What is the primary function of AWS Identity and Access Management (IAM)?", "answer": "AWS Identity and Access Management (IAM) is a service that provides fine-grained access control across all of AWS. It enables users to control access to services and resources under specific conditions using IAM policies.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T15:40:11.942881"}}
{"question": "How does AWS Identity and Access Management (IAM) ensure least privilege?", "answer": "AWS Identity and Access Management (IAM) ensures least privilege by allowing users to grant only the permissions required to perform a task. This is done by defining the actions that can be taken on specific resources under specific conditions.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T15:40:11.943254"}}
{"question": "What's the difference between an AWS managed policy and a customer managed policy in IAM?", "answer": "An AWS managed policy is a pre-built policy provided by AWS that helps users get started with IAM and is available in all AWS accounts. A customer managed policy is a policy created and managed by the user specifically for their unique use cases.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T15:40:11.943771"}}
{"question": "What are AWS IAM roles and how are they used for accessing AWS services?", "answer": "AWS IAM roles are a way to access AWS services by relying on temporary security credentials. Each role has a set of permissions for making AWS service requests and is not associated with a specific user or group. Authorized identities, such as identity providers or AWS services, assume roles to make AWS requests. To grant permissions to a role, attach an IAM policy to it.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-11T15:40:17.672136"}}
{"question": "What is the difference between an IAM role and an IAM user in terms of credentials?", "answer": "An IAM role uses temporary security credentials, while an IAM user has long-term access credentials. IAM roles are typically used for granting access to AWS services for entities, while IAM users are used for workforce users or scenarios where long-term access keys are required.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-11T15:40:17.672502"}}
{"question": "How do I grant access to an Amazon S3 bucket using IAM policies?", "answer": "You can attach IAM policies directly to an Amazon S3 bucket to grant direct, cross-account access. The permissions defined in the policy determine whether requests are allowed or denied when an IAM role makes a request to the bucket.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-1", "source_tokens": 431, "generated_at": "2026-02-11T15:40:17.673038"}}
{"question": "What type of document is used to define permissions in AWS IAM?", "answer": "A JavaScript Object Notation (JSON) document is used to define permissions in AWS IAM.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-11T15:40:21.494135"}}
{"question": "How do you create and assign permissions for specific use cases in AWS IAM?", "answer": "You can create customer managed policies and attach them to roles to grant permissions specific to your use cases in AWS IAM.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-11T15:40:21.494491"}}
{"question": "What's the difference between AWS managed policies and customer managed policies in AWS IAM?", "answer": "AWS managed policies are created and administered by AWS and cover common use cases, while customer managed policies are specific to your use cases and resources.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-2", "source_tokens": 507, "generated_at": "2026-02-11T15:40:21.494705"}}
{"question": "What resources can resource-based policies be attached to in AWS?", "answer": "Resource-based policies can be attached to Amazon S3 buckets, Amazon SQS queues, VPC endpoints, and AWS Key Management Service (AWS KMS) encryption keys.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-11T15:40:26.224122"}}
{"question": "How does AWS IAM implement Role-Based Access Control (RBAC)?", "answer": "AWS IAM implements RBAC by defining IAM roles with permissions that align with job functions. Individuals can then be granted access to assume these roles to perform specific job functions.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-11T15:40:26.224420"}}
{"question": "What is the difference between Resource-Based Access Control (RBAC) and Attribute-Based Access Control (ABAC) in AWS?", "answer": "RBAC is a method of access control that grants access based on a person's job function, while ABAC is a method that grants access based on attributes, such as tags, assigned to resources or IAM roles.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-3", "source_tokens": 457, "generated_at": "2026-02-11T15:40:26.224591"}}
{"question": "What steps should be taken to use ABAC for access control in AWS?", "answer": "1. Define tag keys and values for access control, 2. Ensure the IAM role has the appropriate tag keys and values, 3. Define session tag keys and values if needed, 4. Ensure resources have the appropriate tag keys and values, 5. Define a policy that grants access based on tag matches.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-11T15:40:30.776567"}}
{"question": "What is the effect of a Deny statement in an AWS IAM policy?", "answer": "A Deny statement in an AWS IAM policy denies access to specific actions and resource types, even if an Allow statement exists. It always prevails over an Allow statement.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-11T15:40:30.776912"}}
{"question": "How do SCPs differ from IAM policies in terms of access control?", "answer": "IAM policies grant permissions, while SCPs allow or deny access to AWS services for individual AWS accounts or groups within an organizational unit. SCPs affect all IAM users and roles in the member account.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-4", "source_tokens": 415, "generated_at": "2026-02-11T15:40:30.777485"}}
{"question": "What are AWS managed policies and how are they created and administered?", "answer": "AWS managed policies are pre-built policies created and administered by AWS. They include permissions for common use cases.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-11T15:40:35.077604"}}
{"question": "How does the process of refining permissions in AWS Identity and Access Management (IAM) progress?", "answer": "You can start with broader permissions for exploration and experimentation. As your use cases mature, AWS recommends refining permissions to grant only the required permissions, which is known as achieving least-privilege permissions. To help determine specific permissions, you can use AWS Identity and Access Management Access Analyzer, review CloudTrail logs, and inspect last accessed information. You can also use the IAM policy simulator for testing and troubleshooting.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-11T15:40:35.077887"}}
{"question": "What's the difference between AWS managed policies and customer managed policies?", "answer": "AWS managed policies are pre-built policies created and administered by AWS, while customer managed policies are specific permissions defined by the user.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-5", "source_tokens": 169, "generated_at": "2026-02-11T15:40:35.078050"}}
{"question": "What does IAM Access Analyzer do during the policy generation step?", "answer": "IAM Access Analyzer generates a fine-grained policy based on the access activity captured in logs after an application is built and run.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-11T15:40:39.242016"}}
{"question": "How can IAM Access Analyzer help me create secure policies?", "answer": "IAM Access Analyzer provides more than 100 policy checks to guide you in authoring and validating secure and functional policies.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-11T15:40:39.242347"}}
{"question": "What's the difference between internal and external findings in IAM Access Analyzer?", "answer": "Internal findings within IAM Access Analyzer identify access allowed by your resource policies within your AWS organization. External findings help you verify and refine access allowed by your resource policies from outside your AWS organization.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-6", "source_tokens": 372, "generated_at": "2026-02-11T15:40:39.242788"}}
{"question": "What information is available through the IAM console, APIs, and SDKs to help identify unused IAM users and roles?", "answer": "The last used information for IAM users and roles is available.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-11T15:40:45.293549"}}
{"question": "How can IAM Access Analyzer help me achieve least-privilege access in my AWS account?", "answer": "IAM Access Analyzer continuously analyzes your accounts to identify unused access and provides a centralized dashboard with findings. Security teams can use the dashboard to review findings and prioritize which accounts to review based on the volume of findings, which highlight unused roles, unused access keys for IAM users, and unused passwords for IAM users.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-11T15:40:45.293807"}}
{"question": "What is the difference between using the IAM console, APIs, and SDKs to identify unused IAM users and roles and using IAM Access Analyzer as a paid feature?", "answer": "The IAM console, APIs, and SDKs provide last used information for IAM users and roles, allowing you to manually identify and remove unused access. IAM Access Analyzer, as a paid feature, continuously analyzes your accounts to identify unused access and provides a centralized dashboard with findings. It also simplifies the inspection of unused access to guide you toward least privilege, whereas manual inspection requires more effort.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-7", "source_tokens": 359, "generated_at": "2026-02-11T15:40:45.293980"}}
{"question": "What is the function of IAM Access Analyzer's custom policy checks?", "answer": "IAM Access Analyzer's custom policy checks validate that your IAM policies adhere to your security standards using automated reasoning for proactive detection of nonconformant updates.", "question_type": "factual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-11T15:40:50.092793"}}
{"question": "How does IAM Access Analyzer help security teams manage IAM policies?", "answer": "IAM Access Analyzer helps security teams manage IAM policies by simplifying the inspection of unused access, guiding them towards least privilege, and providing visibility into unused roles, access keys, passwords, services, and actions.", "question_type": "conceptual", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-11T15:40:50.093146"}}
{"question": "What is the difference between IAM Access Analyzer's custom policy checks and its unused access analysis?", "answer": "IAM Access Analyzer's custom policy checks validate IAM policies adherence to security standards using automated reasoning. Unused access analysis helps security teams rightsize permissions by identifying and highlighting unused access across their AWS organization.", "question_type": "comparison", "metadata": {"service": "IAM", "doc_type": "Guide", "source_file": "aws-iam-faq.html", "chunk_id": "iam-aws-iam-faq-8", "source_tokens": 329, "generated_at": "2026-02-11T15:40:50.093321"}}
{"question": "What are the benefits of using Amazon Inspector for vulnerability management?", "answer": "Amazon Inspector provides automated discovery and continual scanning for software vulnerabilities and unintended network exposure in Amazon EC2, AWS Lambda functions, container images in Amazon ECR, and within CI/CD tools. It offers central management and configuration for all your organization's accounts, a highly contextualized risk score for each finding, and an intuitive dashboard for coverage metrics. Additionally, it maximizes vulnerability assessment coverage by seamlessly scanning EC2 instances, integrates with AWS Security Hub and Amazon EventBridge, and allows you to deactivate the old Amazon Inspector Classic.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-11T15:40:57.290409"}}
{"question": "What types of resources can Amazon Inspector scan for vulnerabilities?", "answer": "Amazon Inspector scans Amazon Elastic Compute Cloud (EC2) instances, AWS Lambda functions, container images in Amazon Elastic Container Registry (ECR), and resources within continuous integration and continuous delivery (CI/CD) tools for software vulnerabilities and unintended network exposure.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-11T15:40:57.290771"}}
{"question": "How does the new Amazon Inspector compare to the old Amazon Inspector Classic in terms of activation and deactivation?", "answer": "To activate the new Amazon Inspector, you can follow a few steps in the AWS Management Console or use the new Amazon Inspector APIs. In contrast, you can deactivate the old Amazon Inspector Classic by simply deleting all assessment templates in your account. However, to access findings for existing assessment runs of the old Amazon Inspector, you can download them as reports or export them using the Amazon Inspector API.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-0", "source_tokens": 470, "generated_at": "2026-02-11T15:40:57.291202"}}
{"question": "What new features does the rebuilt Amazon Inspector offer for container images and Lambda functions?", "answer": "The new Amazon Inspector scans container images residing in Amazon ECR and within CI/CD tools, and Lambda functions for software vulnerabilities. Container-related findings are also pushed to the Amazon ECR console.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T15:41:01.885261"}}
{"question": "How does the new Amazon Inspector prioritize its findings?", "answer": "The new Amazon Inspector calculates an Inspector risk score by correlating up-to-date CVE information with temporal and environmental factors such as network accessibility and exploitability information to add context and help prioritize your findings.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T15:41:01.885605"}}
{"question": "What are the differences in scanning between the new and old Amazon Inspector for EC2 instances?", "answer": "The new Amazon Inspector seamlessly scans EC2 instances and switches between agent-based and agentless scanning. In the old Amazon Inspector, you needed to install and maintain a standalone Amazon Inspector agent on all of your Amazon EC2 instances.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T15:41:01.886100"}}
{"question": "What code repositories can Amazon Inspector scan for security vulnerabilities and misconfigurations?", "answer": "Amazon Inspector scans GitHub and GitLab code repositories.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-11T15:41:05.561419"}}
{"question": "How does Amazon Inspector identify security vulnerabilities and misconfigurations in source-code?", "answer": "Amazon Inspector identifies security vulnerabilities and misconfigurations in source-code by rapidly scanning and prioritizing issues.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-11T15:41:05.561754"}}
{"question": "What's the difference between the old and new Amazon Inspector in terms of code repository integration?", "answer": "The new Amazon Inspector has native integration to GitHub and GitLab, whereas the old version may not have had this capability.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-2", "source_tokens": 62, "generated_at": "2026-02-11T15:41:05.561949"}}
{"question": "Can I use S3 and SNS together in the same AWS account?", "answer": "Yes", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-11T15:41:09.247153"}}
{"question": "How does using S3 and SNS together in an AWS account benefit me?", "answer": "Using S3 and SNS together in an AWS account allows you to store and manage your data in S3 and then send notifications or messages based on events in S3 using SNS.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-11T15:41:09.247505"}}
{"question": "What is the difference in functionality between S3 and SNS when used in the same account?", "answer": "S3 is a storage service where you can store and manage your data, while SNS is a messaging service that sends notifications or messages based on events in AWS services including S3.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-3", "source_tokens": 14, "generated_at": "2026-02-11T15:41:09.248027"}}
{"question": "Which AWS service offers continual container image scanning in Amazon ECR?", "answer": "Amazon Inspector", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-11T15:41:13.584199"}}
{"question": "What's the difference in vulnerability intelligence between Amazon Inspector and Amazon ECR native scanning?", "answer": "Amazon Inspector provides enhanced vulnerability intelligence such as CVE details, remediation guidance, EPSS scores, and malware information, while Amazon ECR only provides basic software vulnerability information.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-11T15:41:13.584525"}}
{"question": "How does Amazon Inspector's scanning engine differ from Amazon ECR's?", "answer": "Amazon Inspector supports enhanced scanning for various ecosystems, OS packages, and programming language packages, and offers both continual and on-push scanning, while Amazon ECR offers only basic scanning for OS packages and on-push scanning.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-4", "source_tokens": 501, "generated_at": "2026-02-11T15:41:13.584719"}}
{"question": "What is the duration of the free trial for Amazon Inspector?", "answer": "Amazon Inspector offers a 15-day free trial.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T15:41:17.617588"}}
{"question": "How does Amazon Inspector integrate with source code management platforms?", "answer": "To integrate Amazon Inspector with a source code management platform, you need to establish a secure connection. This allows Amazon Inspector to begin scanning your code repositories.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T15:41:17.617931"}}
{"question": "What are the differences between scanning types in Amazon Inspector, and which ones are activated by default?", "answer": "Amazon Inspector supports scanning for Amazon EC2 instances, Lambda functions, and Amazon ECR container images by default. Existing users can activate or deactivate these features across all accounts in their organization.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T15:41:17.618458"}}
{"question": "What is required for Amazon EC2 instances to be scanned for software vulnerabilities using AWS Systems Manager and the SSM Agent?", "answer": "Amazon EC2 instances managed by AWS Systems Manager and have the SSM Agent installed are recommended for agent-based vulnerability scanning using Amazon Inspector.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:41:22.219729"}}
{"question": "How does Amazon Inspector handle scanning of Amazon EC2 instances without the SSM Agent?", "answer": "Amazon Inspector offers agentless scanning as an alternative for instances without the SSM Agent installed.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:41:22.219975"}}
{"question": "What is the difference between agent-based and agentless scanning in Amazon Inspector for vulnerability assessment of Amazon EC2 instances?", "answer": "Agent-based scanning requires instances to be managed by AWS Systems Manager and have the SSM Agent installed. Agentless scanning does not require an agent and is suitable for instances that do not have the SSM Agent installed.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:41:22.220146"}}
{"question": "What is the default rescan duration for image last in use date in Amazon ECR?", "answer": "The default rescan duration for image last in use date in Amazon ECR is 14 days.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:41:45.980886"}}
{"question": "Why does Amazon Inspector scan images in Amazon ECR for different rescan durations based on image last in use date and push date?", "answer": "Amazon Inspector scans images in Amazon ECR for different rescan durities based on image last in use date and push date to ensure that images are monitored and rescanned when necessary. If an image has been last in use on a running container within the configured rescan duration or was pushed within the configured rescan duration, it will continue to be monitored and automated rescans will be started when a new CVE affecting the image is published.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:41:45.981229"}}
{"question": "How does the rescan duration configuration for image last in use date compare to the rescan duration configuration for image push date in Amazon ECR?", "answer": "The rescan duration configurations for image last in use date and image push date in Amazon ECR can be configured to be the same or different. When Amazon Inspector ECR scanning is activated, images pushed in the last 14 days are picked up for scanning by default. After activation, if the rescan duration for both push date and last in use date is configured to be 30 days, Amazon Inspector will continue to scan images if they were pushed in the last 30 days or have been last in use on running container at least once in the last 30 days. If an image hasn't been pushed or last in use on a running container in the last 30 days, Amazon Inspector will stop monitoring it.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:41:45.981748"}}
{"question": "What is the maximum rescan duration for image last in use date in Amazon Inspector ECR scanning?", "answer": "The maximum rescan duration for image last in use date in Amazon Inspector ECR scanning is 180 days.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-11T15:41:50.842151"}}
{"question": "How does Amazon Inspector determine which container images to continue scanning?", "answer": "Amazon Inspector determines which container images to continue scanning based on their last push or last in use date. If the image was pushed or last in use on a running container within the last 180 days, it will continue to be scanned.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-11T15:41:50.842494"}}
{"question": "What's the difference between the rescan duration for last push date and last in use date in Amazon Inspector ECR scanning?", "answer": "The rescan duration for last push date determines when to scan an image after it has been pushed to the registry, while the rescan duration for last in use date determines when to scan an image based on its last usage on a running container.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-9", "source_tokens": 255, "generated_at": "2026-02-11T15:41:50.842991"}}
{"question": "What tag should be used to exclude an EC2 instance from Amazon Inspector scanning?", "answer": "You can exclude an EC2 instance from Amazon Inspector scanning by adding a resource tag with the key â€˜InspectorEc2Exclusionâ€™.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-11T15:41:55.899681"}}
{"question": "How does the scanning process for container images in Amazon ECR differ from EC2 instances?", "answer": "While you can select which Amazon ECR repositories are configured for scanning, all images within a repository will be scanned. Unlike EC2 instances, you cannot exclude specific images from scanning.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-11T15:41:55.899984"}}
{"question": "What are the differences between Lambda standard scanning and Lambda code scanning?", "answer": "Lambda standard scanning provides fundamental security protection against vulnerable dependencies used in the application deployed as Lambda functions and association layers. Lambda code scanning, on the other hand, scans your custom proprietary application code within a Lambda function for code security vulnerabilities such as injection flaws, data leaks, weak cryptography, or embedded secrets.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-10", "source_tokens": 493, "generated_at": "2026-02-11T15:41:55.900475"}}
{"question": "What impact does increasing the default SSM inventory collection frequency have on the detection of application inventory changes and new findings in Amazon Inspector?", "answer": "Increasing the application inventory duration from the default of 30 minutes will delay the detection of changes to the application inventory and new findings in Amazon Inspector. This could potentially lead to a delay in addressing vulnerabilities and securing resources.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:42:02.019278"}}
{"question": "How does Amazon Inspector determine the risk score for a finding?", "answer": "Amazon Inspector calculates the risk score for a finding by correlating common vulnerabilities and exposures (CVE) information with network reachability results, exploitability data, and social media trends. The resulting score helps prioritize findings and focus on the most critical vulnerabilities and vulnerable resources.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:42:02.019618"}}
{"question": "How does the risk score of a finding in Amazon Inspector compare to the severity level assigned to it?", "answer": "The risk score in Amazon Inspector is a more fine-grained measure of the potential impact and likelihood of a vulnerability compared to the severity level, which is a broader categorization. The risk score ranges from Informational (0.2-3.9) to Critical (9.0-10.0), with severity level ranging from Low (0) to Critical (10).", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-11", "source_tokens": 442, "generated_at": "2026-02-11T15:42:02.020142"}}
{"question": "What are the steps to generate and export SBOMs for resources monitored with Amazon Inspector in multiple formats?", "answer": "You can generate and export SBOMs for all resources monitored with Amazon Inspector in multiple formats (CycloneDx or SPDX) through the Amazon Inspector console or APIs. You can download a full report with SBOM for all resources, or selectively generate and download SBOMs for a few select resources based on the set view filters.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-11T15:42:08.014363"}}
{"question": "How does Amazon Inspector determine which scan mode to use for assessing vulnerabilities?", "answer": "Amazon Inspector uses hybrid scan mode by default when you enable EC2 scanning. In this mode, Amazon Inspector relies on SSM Agents for application inventory collection to perform vulnerability assessments and automatically falls back on agentless scanning for instances that donâ€™t have SSM Agents installed or configured.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-11T15:42:08.014758"}}
{"question": "What's the difference between the scan behavior for agentless and SSM agent-based instances in Amazon Inspector?", "answer": "For instances marked for agentless scanning, Amazon Inspector automatically triggers a scan every 24 hours. For instances marked for SSM agent-based scans, there is no change to the continuous scanning behavior.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-12", "source_tokens": 489, "generated_at": "2026-02-11T15:42:08.015019"}}
{"question": "What role can application and platform teams play in setting up scan mode configuration in a multi-account setup?", "answer": "Application and platform teams cannot set up scan mode configuration for the complete organization in a multi-account setup. Only delegated admins have this permission.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-11T15:42:12.934927"}}
{"question": "How can teams integrate Amazon Inspector into their build pipelines?", "answer": "Teams can integrate Amazon Inspector into their build pipelines using purpose-built Amazon Inspector plugins designed for various CI/CD tools. Once the plugin is installed, teams can add a step in the pipeline to perform an assessment of the container image and take actions based on the assessment results.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-11T15:42:12.935298"}}
{"question": "What is the difference between setting up SSM Agent as an Amazon VPC endpoint and not setting it up as an endpoint?", "answer": "Setting up SSM Agent as an Amazon VPC endpoint allows teams to avoid sending information over the internet. If SSM Agent is not set up as an endpoint, information is sent over the internet.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-13", "source_tokens": 486, "generated_at": "2026-02-11T15:42:12.935745"}}
{"question": "What three features does Amazon Inspector provide for application security?", "answer": "Amazon Inspector provides Static Application Security Testing (SAST) for analyzing application source code, Software Composition Analysis (SCA) for evaluating third-party dependencies, and Infrastructure as code (IaC) scanning for validating infrastructure definitions.", "question_type": "factual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-11T15:42:18.307181"}}
{"question": "How does Amazon Inspector help developers incorporate security scanning?", "answer": "Amazon Inspector integrates with GitHub and GitLab, enabling teams to evaluate code security at multiple stages like pull request, merge request, or push code changes in repositories. This flexibility aligns with different development practices and makes security an integral part of the development lifecycle without disrupting team productivity.", "question_type": "conceptual", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-11T15:42:18.307558"}}
{"question": "What's the difference between default and general scan configurations in Amazon Inspector?", "answer": "A default scan configuration is automatically attached to new projects discovered and is embedded into the integration workflow when establishing the connection to the Source Code Management (SCM) platform. In contrast, a general scan configuration is applied to existing projects at the time of creating the scan configuration.", "question_type": "comparison", "metadata": {"service": "INSPECTOR", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "inspector-faq-14", "source_tokens": 495, "generated_at": "2026-02-11T15:42:18.307956"}}
{"question": "What type of search service is Amazon Kendra and what does it use for power?", "answer": "Amazon Kendra is a machine learning (ML) powered enterprise search service that allows developers to add search capabilities to their applications. It uses ML algorithms to understand the context and return the most relevant results.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-11T15:42:23.834383"}}
{"question": "How can Amazon Kendra be used to find information in various systems?", "answer": "Amazon Kendra allows developers to integrate highly accurate search into their applications, enabling end users to discover information from various systems like Amazon S3, Microsoft SharePoint, Salesforce, ServiceNow, RDS databases, or Microsoft OneDrive.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-11T15:42:23.834722"}}
{"question": "How does Amazon Kendra compare to other AWS AI services for searching unstructured data?", "answer": "Amazon Kendra is an ML-powered search service that offers easy integration with popular AWS repository types like Amazon S3 and Amazon RDS databases. Other AWS AI services, such as Amazon Comprehend, Amazon Transcribe, and Amazon Comprehend Medical, can be used to pre-process documents, generate searchable text, extract entities, and enrich metadata for more specialized search experiences.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-0", "source_tokens": 370, "generated_at": "2026-02-11T15:42:23.835151"}}
{"question": "What types of questions can Amazon Kendra handle according to the text passage?", "answer": "Amazon Kendra can handle factoid questions (who, what, when, where), descriptive questions, and keyword searches.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:42:28.492998"}}
{"question": "How does Amazon Kendra handle queries when the data doesn't contain a precise answer?", "answer": "When your data doesnâ€™t contain a precise answer to a question, Amazon Kendra returns a list of the most-relevant documents ranked by its deep learning models.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:42:28.493217"}}
{"question": "How does Amazon Kendra compare to other search engines when dealing with unstructured and semi-structured documents?", "answer": "Amazon Kendra provides easier ways to get started with unstructured and semi-structured documents such as FAQs stored in Amazon S3, and you can implement its API using a few lines of code for more-precise control.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-1", "source_tokens": 474, "generated_at": "2026-02-11T15:42:28.493576"}}
{"question": "What file formats can Amazon Kendra search?", "answer": "Amazon Kendra supports unstructured and semi-structured data in .html, MS Office (.doc, .ppt), PDF, and text formats. It also searches audio and video files with the MediaSearch solution.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T15:42:33.251500"}}
{"question": "How does Amazon Kendra handle index updates?", "answer": "Amazon Kendra offers two methods to keep the index updated: connectors with scheduling and the Amazon Kendra API. Connectors automatically sync data sources on a regular basis, while the API allows for data to be sent directly to Amazon Kendra.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T15:42:33.251840"}}
{"question": "What encryption options are available for data at rest in Amazon Kendra?", "answer": "Amazon Kendra offers three choices for data encryption at rest: AWS-owned KMS key, AWS-managed KMS key in your account, or a customer-managed KMS key.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T15:42:33.252399"}}
{"question": "What data sources can Kendra GenAI Index connect to?", "answer": "Kendra GenAI Index can connect to 40+ enterprise data sources.", "question_type": "factual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-11T15:42:37.962735"}}
{"question": "How does Kendra GenAI Index help in building digital assistants?", "answer": "Kendra GenAI Index helps in building digital assistants more efficiently and effectively by offering high retrieval accuracy, integrating with Bedrock Knowledge Bases and other Bedrock tools, and allowing the creation of RAG-powered chatbots.", "question_type": "conceptual", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-11T15:42:37.963074"}}
{"question": "How does Kendra GenAI Index compare to Bedrock Knowledge Bases when building generative AI solutions?", "answer": "Kendra GenAI Index can be used as a managed retriever with Bedrock Knowledge Bases to create generative AI solutions with greater configurability, or as a retriever in Q Business for a fully managed approach with a streamlined experience.", "question_type": "comparison", "metadata": {"service": "KENDRA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kendra-faq-3", "source_tokens": 430, "generated_at": "2026-02-11T15:42:37.963693"}}
{"question": "What is Amazon Keyspaces and how does it work?", "answer": "Amazon Keyspaces is a managed, serverless offering of Apache Cassandra-compatible database service. It allows users to run Cassandra workloads on AWS using the same CQL code, drivers, and tools. Amazon Keyspaces uses a modified version of Apache Cassandra and eliminates the need to manage servers or software. tables can scale automatically and users pay for only the resources they use.", "question_type": "conceptual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T15:42:44.847229"}}
{"question": "What are the main benefits of using Amazon Keyspaces over traditional Apache Cassandra?", "answer": "Amazon Keyspaces offers several benefits over traditional Apache Cassandra. It is a managed, serverless offering, meaning users do not have to manage servers or software. Tables can scale automatically and users pay for only the resources they use. Keyspaces also eliminates compaction strategies, tombstones, or garbage-collection settings and provides single-digit-millisecond performance.", "question_type": "factual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T15:42:44.847560"}}
{"question": "How does Amazon Keyspaces compare to other managed databases services like DynamoDB?", "answer": "Both Amazon Keyspaces and DynamoDB are managed database services offered by AWS, but they have some key differences. Amazon Keyspaces is Apache Cassandra-compatible and uses the CQL API, while DynamoDB is a NoSQL key-value store. Keyspaces provides single-digit-millisecond performance and supports Cassandra data-plane operations, while DynamoDB is known for its fast and predictable performance at any scale.", "question_type": "comparison", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T15:42:44.847764"}}
{"question": "What kind of performance does Amazon Keyspaces provide?", "answer": "Amazon Keyspaces offers consistent single-digit-millisecond, server-side read and write performance.", "question_type": "factual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-11T15:42:49.386734"}}
{"question": "How does Amazon Keyspaces help with application traffic and capacity requirements?", "answer": "Amazon Keyspaces offers both on-demand and provisioned capacity modes. With on-demand capacity mode, you pay for only the reads and writes that your application actually performs. Provisioned capacity mode helps you optimize the price of throughput if you have predictable application traffic and can forecast capacity requirements in advance.", "question_type": "conceptual", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-11T15:42:49.387087"}}
{"question": "What is the difference in pricing between on-demand and provisioned capacity mode in Amazon Keyspaces?", "answer": "With on-demand capacity mode, you pay for only the reads and writes that your application actually performs. Provisioned capacity mode requires forecasting capacity requirements in advance for optimal pricing.", "question_type": "comparison", "metadata": {"service": "KEYSPACES", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "keyspaces-faq-1", "source_tokens": 130, "generated_at": "2026-02-11T15:42:49.387646"}}
{"question": "What are some common data types that can be added to Kinesis Data Streams?", "answer": "Clickstreams, application logs, and social media are some common data types that can be added to Kinesis Data Streams.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-11T15:42:54.197123"}}
{"question": "How does Kinesis Data Streams manage and process data in real-time?", "answer": "Kinesis Data Streams manages and processes data in real-time by managing the infrastructure, storage, networking, and configuration needed to stream the data at the desired throughput. It also synchronously replicates data across three Availability Zones for high availability and data durability, and scales capacity automatically by default.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-11T15:42:54.197469"}}
{"question": "What are the differences between automatic scaling and provisioned mode in Kinesis Data Streams?", "answer": "With automatic scaling, Kinesis Data Streams scales capacity based on the data throughput. In contrast, with provisioned mode, you can provision and manage throughput on your own.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-0", "source_tokens": 399, "generated_at": "2026-02-11T15:42:54.197929"}}
{"question": "What are some typical scenarios for using Amazon Kinesis Data Streams?", "answer": "Amazon Kinesis Data Streams is useful for rapidly moving data off data producers and then continuously processing the data. Some typical scenarios include accelerated log and data feed intake, real-time metrics and reporting, real-time data analytics, log and event data collection, and powering event-driven applications.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-11T15:42:59.218343"}}
{"question": "How does Amazon Kinesis Data Streams help with real-time data processing?", "answer": "Amazon Kinesis Data Streams allows for continuous processing of data as soon as it is produced, enabling real-time metrics and analytics, reporting, and data transformations.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-11T15:42:59.218703"}}
{"question": "What's the difference between using Amazon Kinesis Data Streams for real-time analytics and log collection?", "answer": "Using Amazon Kinesis Data Streams for real-time analytics involves processing streaming data and generating insights in real time. Using it for log collection involves collecting logs and events from various sources and continuously processing them.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-1", "source_tokens": 400, "generated_at": "2026-02-11T15:42:59.219192"}}
{"question": "What is the maximum size of a data blob in an Amazon Kinesis data stream?", "answer": "The maximum size of a data blob in an Amazon Kinesis data stream is 1 megabyte (MB).", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-11T15:43:04.429136"}}
{"question": "How does a shard in Amazon Kinesis Data Streams support data processing?", "answer": "A shard in Amazon Kinesis Data Streams supports data processing by serving as a base throughput unit for writes and reads. It allows for parallel processing of data by consumers, and ensures predictable performance by limiting write and read throughput. Producers put data records into shards, and consumers get data records from shards.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-11T15:43:04.429490"}}
{"question": "What's the difference between the read and write throughput of a shard in Amazon Kinesis Data Streams?", "answer": "A shard in Amazon Kinesis Data Streams supports a read throughput of 2 MB/second and a write throughput of 1 MB/second for data. This means that more data can be read from a shard than written to it.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-2", "source_tokens": 432, "generated_at": "2026-02-11T15:43:04.429699"}}
{"question": "What partition key is used for adding records to which shard in a Kinesis data stream?", "answer": "Records with a specific partition key are added to a particular shard in a Kinesis data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-11T15:43:09.292516"}}
{"question": "How does Amazon Kinesis handle partition keys and sequence numbers in a data stream?", "answer": "Partition keys are used to isolate records and route them to specific shards in a data stream. Sequence numbers are unique identifiers assigned to each record and increase generally over time.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-11T15:43:09.292850"}}
{"question": "Which capacity mode of Kinesis Data Streams allows for automatic adjustment of shards based on usage and what mode requires specifying the number of shards?", "answer": "In on-demand mode, AWS manages the shards to provide the necessary throughput and you pay only for the actual throughput used. In provisioned mode, you specify the number of shards for the data stream and pay for the number of shards at an hourly rate.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-3", "source_tokens": 397, "generated_at": "2026-02-11T15:43:09.293349"}}
{"question": "What mode should I use for workloads with unpredictable and highly variable traffic patterns?", "answer": "You should use on-demand mode for workloads with unpredictable and highly variable traffic patterns.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-11T15:43:15.016245"}}
{"question": "How does switching from provisioned mode to on-demand mode affect the shard count of a Kinesis data stream?", "answer": "When you switch from provisioned mode to on-demand capacity mode, your data stream retains the shard count it had before the transition, but Kinesis Data Streams monitors your data traffic and scales the shard count up or down depending on traffic increase or decrease.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-11T15:43:15.016535"}}
{"question": "What are the differences between using PutRecord operation, PutRecords operation, KPL, and Amazon Kinesis Agent to add data to a Kinesis data stream?", "answer": "PutRecord operation allows a single data record within an API call, while PutRecords operation allows multiple data records within an API call. KPL is a library that helps put data into an Amazon Kinesis data stream with a simple and reliable interface, and Amazon Kinesis Agent is a prebuilt Java application that monitors certain files and continuously sends data to your data stream.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-4", "source_tokens": 459, "generated_at": "2026-02-11T15:43:15.016725"}}
{"question": "What are the required parameters for a PutRecord or PutRecords call in Amazon Kinesis?", "answer": "The required parameters for a PutRecord or PutRecords call in Amazon Kinesis are the data blob, partition key, and data stream name.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-11T15:43:21.685512"}}
{"question": "How do the different consumer types in Amazon Kinesis affect the read throughput and transactions per second?", "answer": "Shared fan-out consumers all share a shard's 2 MB/second of read throughput and five transactions per second limits and require the use of the GetRecords API. Enhanced fan-out consumers get their own 2 MB/second allotment of read throughput, allowing multiple consumers to read data from the same stream in parallel, without contending for read throughput with other consumers. To use enhanced fan-out consumers, you need to use the SubscribeToShard API.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-11T15:43:21.685854"}}
{"question": "How does using an enhanced fan-out consumer in Amazon Kinesis compare to using a shared fan-out consumer in terms of read throughput and transactions per second?", "answer": "Enhanced fan-out consumers get their own 2 MB/second allotment of read throughput, allowing multiple consumers to read data from the same stream in parallel without contending for read throughput with other consumers. Shared fan-out consumers all share a shardâ€™s 2 MB/second of read throughput and five transactions per second limits and require the use of the GetRecords API.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-5", "source_tokens": 504, "generated_at": "2026-02-11T15:43:21.686237"}}
{"question": "What is the typical delivery time for data using the SubscribeToShard API?", "answer": "Data is delivered to registered consumers within approximately 70 milliseconds using the SubscribeToShard API.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:43:25.835104"}}
{"question": "How does enhanced fan-out impact data delivery performance for consumers in a Kinesis Data Stream?", "answer": "Enhanced fan-out provides logical 2 MB/second throughput pipes between consumers and shards, allowing for fast delivery even when multiple consumers are reading from the same shard.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:43:25.835450"}}
{"question": "What is the difference in performance between the SubscribeToShard API and the GetRecords API for data delivery?", "answer": "The SubscribeToShard API offers approximately 65% faster data delivery compared to the GetRecords API.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-6", "source_tokens": 457, "generated_at": "2026-02-11T15:43:25.835654"}}
{"question": "What is the maximum write throughput that an on-demand Kinesis Data Stream can accommodate when it hits a new peak?", "answer": "An on-demand Kinesis Data Stream can accommodate double the previous peak write throughput it has observed in the last 30 days.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-11T15:43:30.842052"}}
{"question": "How does Kinesis Data Streams handle a data stream's write throughput in on-demand mode?", "answer": "Kinesis Data Streams automatically scales the capacity of on-demand data streams when the write throughput hits a new peak, ensuring there is enough capacity for double the peak throughput.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-11T15:43:30.842396"}}
{"question": "What's the difference in read throughput between on-demand and provisioned mode for Kinesis Data Streams?", "answer": "In on-demand mode, you get at least twice the write throughput to read data using the GetRecords API. In provisioned mode, the read throughput scales proportionally to the write throughput.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-7", "source_tokens": 452, "generated_at": "2026-02-11T15:43:30.842866"}}
{"question": "What formula is used to calculate the initial number of shards for a Kinesis data stream?", "answer": "The initial number of shards for a Kinesis data stream is calculated using the formula: number_of_shards = max (incoming_write_bandwidth_in_KB/1000, outgoing_read_bandwidth_in_KB/2000)", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T15:43:36.357035"}}
{"question": "How is the throughput of a Kinesis data stream determined?", "answer": "The throughput of a Kinesis data stream is determined by the number of shards within the data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T15:43:36.357327"}}
{"question": "What is the difference in shard quota between the default AWS Regions and all other regions for a Kinesis data stream?", "answer": "The default shard quota for a Kinesis data stream in US East (N. Virginia), US West (Oregon), and Europe (Ireland) is 20,000 shards per stream. For all other regions, the default shard quota is 1,000 or 6,000 shards per stream.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T15:43:36.357521"}}
{"question": "What determines the capacity limits in provisioned mode for a Kinesis data stream?", "answer": "The capacity limits of a Kinesis data stream in provisioned mode are defined by the number of shards within the data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-11T15:43:41.248097"}}
{"question": "Why would you increase the number of shards in a Kinesis data stream in provisioned mode?", "answer": "You should increase the number of shards within a Kinesis data stream in provisioned mode to provide enough capacity for the put or read data calls to consistently succeed when capacity limits are exceeded.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-11T15:43:41.248444"}}
{"question": "How does the retention period of a Kinesis data stream affect its usage?", "answer": "The retention period of a Kinesis data stream determines the length of time for which data is kept, allowing users to reprocess data for various use cases such as catch-up with real-time data, data loss resolution, algorithm back testing, data store backfills, and auditing.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-9", "source_tokens": 491, "generated_at": "2026-02-11T15:43:41.248910"}}
{"question": "What new feature allows applications to discover shards from a specific point in time and eliminate the need to start at the trim horizon?", "answer": "The TimeStamp filter is a new feature available in the ListShards API that enables applications to efficiently retrieve the shard map and discover shards from the desired point in time.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-11T15:43:47.188877"}}
{"question": "How does using the new filtering option and ChildShards field in Kinesis Data Streams APIs improve performance when reading old data?", "answer": "By using the TimeStamp filter and ChildShards field in GetRecords and SubscribeToShard APIs, applications can quickly discover and read data from the desired shards, making efficient use of their compute resources and reducing the need to traverse the shard map repeatedly.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-11T15:43:47.189212"}}
{"question": "What are the benefits of using the AWS Glue Schema Registry with Kinesis Data Streams compared to using it through the KPL or KCL?", "answer": "Both KPL and KCL and AWS Glue Schema Registry APIs in the AWS Java SDK allow clients to use the Schema Registry with Kinesis Data Streams. Using the Schema Registry through the AWS Glue Schema Registry APIs provides additional functionality and flexibility not available through the KPL and KCL.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-10", "source_tokens": 500, "generated_at": "2026-02-11T15:43:47.189695"}}
{"question": "What are the two methods to modify the throughput of an Amazon Kinesis data stream?", "answer": "You can change the throughput of your Amazon Kinesis data stream by using the UpdateShardCount API or the AWS Management Console to scale the number of shards, or you can reshard to adjust the number of shards within the data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-11T15:43:52.875915"}}
{"question": "How does adjusting the number of shards impact the performance metrics of an Amazon Kinesis data stream?", "answer": "Adjusting the number of shards within an Amazon Kinesis data stream affects the throughput of data input and output. The Kinesis Data Streams Management Console displays these metrics, and Kinesis Data Streams also integrates with Amazon CloudWatch for more detailed analysis.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-11T15:43:52.876285"}}
{"question": "What is the difference between using the UpdateShardCount API and resharding to change the throughput of an Amazon Kinesis data stream?", "answer": "Using the UpdateShardCount API involves scaling the number of shards in a data stream to change its throughput, while resharding involves changing the number of shards within a data stream. Both methods allow data input and output to continue during the scaling process.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-11", "source_tokens": 482, "generated_at": "2026-02-11T15:43:52.876473"}}
{"question": "Which AWS service records AWS API calls for your account and delivers log files?", "answer": "Amazon CloudTrail", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-11T15:43:57.732018"}}
{"question": "What are tags and how can they be used in Kinesis Data Streams?", "answer": "Tags are user-defined labels expressed as key-value pairs that help organize AWS resources. In Kinesis Data Streams, you can tag your Kinesis data streams and enhanced fan-out (EFO) consumers for easier resource and cost management, such as by cost centers.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-11T15:43:57.732369"}}
{"question": "How can you securely access Kinesis Data Streams APIs in your Amazon VPC?", "answer": "You can privately access Kinesis Data Streams APIs from your Amazon VPC by creating VPC Endpoints. VPC Endpoints use AWS PrivateLink technology, which enables private connectivity between AWS services and your VPCs using Elastic Network Interfaces (ENI) with private IPs.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-12", "source_tokens": 510, "generated_at": "2026-02-11T15:43:57.732902"}}
{"question": "What encryption method does server-side encryption for Kinesis Data Streams use?", "answer": "Server-side encryption for Kinesis Data Streams uses encryption and decryption processes managed by AWS KMS.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-11T15:44:02.023972"}}
{"question": "Why would you consider using server-side encryption over client-side encryption for Kinesis Data Streams?", "answer": "You might choose server-side encryption over client-side encryption due to easier key management, a second layer of security, or difficulty enforcing client-side encryption.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-11T15:44:02.024311"}}
{"question": "How does server-side encryption for Kinesis Data Streams compare to client-side encryption?", "answer": "Server-side encryption encrypts and decrypts data within the Kinesis Data Streams service, while client-side encryption requires producers and consumers to manage encryption and decryption processes.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-13", "source_tokens": 402, "generated_at": "2026-02-11T15:44:02.024766"}}
{"question": "What key alias is used for AWS-managed KMS key for Kinesis?", "answer": "aws/kinesis", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-11T15:44:06.850716"}}
{"question": "Why is it necessary to configure AWS KMS key policies for server-side encryption in Kinesis Data Streams?", "answer": "It is necessary to configure AWS KMS key policies to allow encryption and decryption of messages in Kinesis Data Streams to enable server-side encryption for your data stream.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-11T15:44:06.850972"}}
{"question": "What are the costs for using server-side encryption with Kinesis Data Streams using the AWS-managed KMS key compared to a custom KMS key?", "answer": "Using the AWS-managed KMS key for server-side encryption in Kinesis Data Streams is free, but if you use a custom KMS key, you are subject to KMS key costs. Each Kinesis Data Stream call to KMS for encryption and decryption results in an additional KMS API call cost.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-14", "source_tokens": 502, "generated_at": "2026-02-11T15:44:06.851135"}}
{"question": "What encryption algorithm does Kinesis Data Streams use for server-side encryption?", "answer": "Kinesis Data Streams uses an AES-GCM 256 algorithm for encryption.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-11T15:44:11.791282"}}
{"question": "How does Kinesis Data Streams' server-side encryption work conceptually?", "answer": "Kinesis Data Streams' server-side encryption encrypts the payload of the message along with the partition key, and it is a stream-specific feature.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-11T15:44:11.791645"}}
{"question": "How does Kinesis Data Streams' server-side encryption compare to other AWS services regarding availability and cost?", "answer": "Kinesis Data Streams' server-side encryption is a pay-as-you-go service and does not offer free usage under the AWS Free Tier. It provides an SLA with a Monthly Uptime Percentage of at least 99.9%. Compared to other AWS services, it is billed differently as it is a stream-specific feature.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-15", "source_tokens": 442, "generated_at": "2026-02-11T15:44:11.792168"}}
{"question": "What is the pricing model for Kinesis Data Streams in on-demand capacity mode?", "answer": "Pricing is based on the volume of data ingested and retrieved, as well as a per-hour charge for each data stream in your account.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-11T15:44:16.064781"}}
{"question": "How does on-demand capacity mode for Kinesis Data Streams handle read and write throughput?", "answer": "You donâ€™t need to specify how much read and write throughput you expect your application to perform. Instead, pricing is based on the actual volume of data ingested and retrieved.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-11T15:44:16.065124"}}
{"question": "What are the additional charges for using Kinesis Data Streams beyond the first 7 days?", "answer": "There are additional charges for Extended data retention (beyond the first 24 hours and within the first seven days), Long-Term data retention (beyond seven days and up to one year), and Enhanced Fan-Out.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-16", "source_tokens": 145, "generated_at": "2026-02-11T15:44:16.065569"}}
{"question": "What is the hourly cost of shards in Kinesis Data Streams provisioned mode?", "answer": "The hourly cost of shards in Kinesis Data Streams provisioned mode is determined by the number of shards within your data stream.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-11T15:44:20.671739"}}
{"question": "How does the cost of extended data retention in Kinesis Data Streams provisioned mode work?", "answer": "When extended data retention is enabled, you pay the extended retention rate for each shard in your stream.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-11T15:44:20.672084"}}
{"question": "What is the difference between the cost dimensions of Enhanced fan-out and Long-term data retention in Kinesis Data Streams provisioned mode?", "answer": "Enhanced fan-out has cost dimensions for consumer-shard hours and data retrievals, while Long-term data retention has cost dimensions for long-term data storage and long-term data retrieval.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-17", "source_tokens": 422, "generated_at": "2026-02-11T15:44:20.672496"}}
{"question": "What is the calculation for the cost of a consumer-shard hour in Kinesis Data Streams?", "answer": "The cost of a consumer-shard hour in Kinesis Data Streams is calculated by multiplying the number of registered stream consumers with the number of shards in the stream, and then multiplying that result by the cost per consumer-shard hour.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-11T15:44:26.100156"}}
{"question": "How does the cost of using enhanced fan-out in Kinesis Data Streams differ between single and multiple consumers?", "answer": "When using enhanced fan-out with a single consumer, the cost will be equal to the consumer-shard hour charge. With multiple consumers, the cost will be the sum of the consumer-shard hour charges for each consumer.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-11T15:44:26.100497"}}
{"question": "What are the advantages of using Amazon MSK over Kinesis Data Streams for my specific use case?", "answer": "If you have existing applications running on Apache Kafka, or if you have a preference for open-source technologies, Amazon MSK might be the better choice for you. MSK is fully compatible with Apache Kafka and Kafka Connect, respectively.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-18", "source_tokens": 419, "generated_at": "2026-02-11T15:44:26.101007"}}
{"question": "What service does Kinesis Data Streams provide for ordering of records?", "answer": "Kinesis Data Streams provides ordering of records for real-time processing of streaming big data.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-11T15:44:30.571841"}}
{"question": "How does Kinesis Data Streams simplify building applications reading from the same data stream?", "answer": "Kinesis Data Streams simplifies building applications reading from the same data stream by delivering all records for a given partition key to the same record processor, making it easier to perform counting, aggregation, and filtering.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-11T15:44:30.572191"}}
{"question": "What's the difference between Kinesis Data Streams and Amazon Simple Queue Service (SQS) in terms of processing data?", "answer": "Kinesis Data Streams enables real-time processing of streaming big data and provides ordering of records, while Amazon SQS lets messages be processed independently with message-level ack/fail semantics.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-19", "source_tokens": 182, "generated_at": "2026-02-11T15:44:30.572625"}}
{"question": "What are some use cases that make Kinesis Data Streams a good choice?", "answer": "Kinesis Data Streams is recommended for use cases that require routing related records to the same record processor for tasks like counting and aggregation, maintaining record order, and allowing multiple applications to consume the same stream concurrently. It also supports consuming records in the same order a few hours later.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-11T15:44:36.133261"}}
{"question": "How does Kinesis Data Streams compare to Amazon SQS in terms of use cases?", "answer": "Kinesis Data Streams is suitable for use cases that involve real-time processing of large data streams, maintaining order of records, and allowing multiple applications to consume the same stream concurrently. On the other hand, Amazon SQS is recommended for messaging semantics, individual message delay, and dynamically increasing concurrency at read time.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-11T15:44:36.133610"}}
{"question": "What are some benefits of using Kinesis Data Streams for data processing?", "answer": "Kinesis Data Streams offers benefits such as the ability to route related records to the same record processor for complex tasks like counting and aggregation, maintain record order, and support multiple applications consuming the same stream concurrently and independently. It also allows consuming records in the same order up to 365 days later.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-20", "source_tokens": 484, "generated_at": "2026-02-11T15:44:36.134110"}}
{"question": "What happens when the load changes on Amazon SQS and you have buffered requests?", "answer": "Amazon SQS can handle the load transparently by processing each buffered request independently.", "question_type": "factual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-11T15:44:40.167856"}}
{"question": "How does Amazon SQS handle load changes and what role do buffered requests play in this process?", "answer": "Amazon SQS buffers requests and processes them independently when the load changes, allowing for transparent scaling without provisioning instructions.", "question_type": "conceptual", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-11T15:44:40.168169"}}
{"question": "How does Amazon SQS's buffering and processing of requests compare to a system that requires provisioning instructions for scaling?", "answer": "Amazon SQS buffers requests and processes them independently, allowing for transparent scaling without provisioning instructions, whereas a system that requires provisioning instructions may experience delays or interruptions during scaling.", "question_type": "comparison", "metadata": {"service": "KINESIS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kinesis-faq-21", "source_tokens": 58, "generated_at": "2026-02-11T15:44:40.168343"}}
{"question": "What are some use cases for AWS Key Management Service (KMS) mentioned in the text?", "answer": "AWS Key Management Service (KMS) is mentioned to be used for centrally managing encryption keys that control access to data across AWS services by individuals responsible for data security. It is also suggested for developers who need to encrypt data in their applications using the AWS Encryption SDK or manage private keys for digital signatures or verification. For scalability, it's recommended for organizations looking to reduce licensing costs and operational burden.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-11T15:44:46.045270"}}
{"question": "What benefits does AWS Key Management Service provide for data security?", "answer": "The text states that AWS Key Management Service offers a highly available key generation, storage, management, and auditing solution for encryption or digital signature operations. It also aids in reducing licensing costs and operational burden, and is beneficial in proving data security for regulatory or compliance purposes.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-11T15:44:46.045523"}}
{"question": "How does AWS Key Management Service compare to other key management solutions for developers?", "answer": "The text mentions that AWS Key Management Service, when used with the AWS Encryption SDK, makes it easier for developers to generate, use, and protect symmetric encryption keys within their code. However, no other specific key management solutions are mentioned or compared in the context.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-0", "source_tokens": 421, "generated_at": "2026-02-11T15:44:46.045776"}}
{"question": "What services allow you to encrypt your data with AWS KMS using AWS owned root keys?", "answer": "AWS services that allow you to encrypt your data with AWS KMS using AWS owned root keys include those listed on the AWS Services home page, under Security, Identity and Compliance.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:44:51.197577"}}
{"question": "Why would you create your own AWS KMS customer managed keys instead of using AWS owned root keys?", "answer": "You would create your own AWS KMS customer managed keys if you want full control over the management of your keys, including the ability to share access to keys across accounts or services.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:44:51.197928"}}
{"question": "How does AWS KMS compare to using AWS Encryption SDK for indirect access to AWS KMS APIs?", "answer": "AWS KMS can be accessed directly through the AWS KMS Console, CLI, or SDK, while AWS Encryption SDK is used within your own applications to encrypt data for AWS KMS. Both methods use AWS KMS keys, but the former gives you more direct control and interaction with the KMS service.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:44:51.198140"}}
{"question": "What steps are required to start using AWS KMS?", "answer": "You can start using the service by requesting the creation of an AWS KMS key. Once you have created a KMS key, you can submit data directly to the service to be encrypted, decrypted, signed, verified, or to generate or verify an HMAC using this KMS key.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T15:44:58.750042"}}
{"question": "How does envelope encryption work with AWS KMS?", "answer": "Under this method, AWS KMS generates data keys that are used to encrypt data locally in the AWS service or your application. The data keys are themselves encrypted under an AWS KMS key you define. AWS services encrypt your data and store an encrypted copy of the data key along with the encrypted data. When a service needs to decrypt your data, it requests AWS KMS to decrypt the data key using your KMS key. If the user requesting data from the AWS service is authorized to decrypt under your KMS key, the AWS service will receive the decrypted data key from AWS KMS. The AWS service then decrypts your data and returns it in plaintext.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T15:44:58.750410"}}
{"question": "What are the differences between using AWS KMS APIs directly and having AWS services encrypt data using your KMS keys in the service?", "answer": "When you use AWS KMS APIs directly to encrypt and decrypt data using your KMS keys stored in the service, you interact with the service directly. On the other hand, when you have AWS services encrypt your data using your KMS keys stored in the service, data is encrypted using data keys that are protected by your KMS keys. The main difference lies in the level of interaction with the service.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-2", "source_tokens": 443, "generated_at": "2026-02-11T15:44:58.750936"}}
{"question": "What are the three types of AWS KMS keys mentioned in the text?", "answer": "The three types of AWS KMS keys mentioned in the text are customer managed keys, AWS managed keys, and AWS owned keys.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-11T15:45:03.683192"}}
{"question": "How does envelope encryption with AWS KMS benefit performance?", "answer": "Envelope encryption with AWS KMS reduces network load and performance issues by only transferring the data key over the network instead of the entire block of data. This avoids the need to send large data to AWS KMS and suffer network latency.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-11T15:45:03.683544"}}
{"question": "What is the difference between customer managed keys and AWS managed keys in AWS KMS?", "answer": "Customer managed keys are keys owned and managed by the user within their AWS account, allowing full control over access control and usage policy. AWS managed keys, on the other hand, are keys created in the user's account but managed by AWS. While the user can track usage and log it in CloudTrail, they have no direct control over the keys themselves.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-3", "source_tokens": 433, "generated_at": "2026-02-11T15:45:03.684066"}}
{"question": "What are the benefits of using customer managed keys created and stored in the KMS HSMs in AWS KMS?", "answer": "Customer managed keys created and stored in the KMS HSMs offer the most flexibility, policy control, lifecycle management (including automatic and on-demand rotation for symmetric encryption keys), and complete audibility. They also provide higher performance, lower latency, and a service level agreement for KMS cryptographic operations compared to keys in the custom key store (CloudHSM) or external key store (XKS).", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-11T15:45:11.859184"}}
{"question": "How does AWS KMS handle key rotation for keys stored in the KMS HSMs and for imported or custom key store keys?", "answer": "AWS KMS can automatically rotate KMS keys in a configurable range of days from 90 days to 2560 days (7 years), or use the RotateKeyOnDemand API to invoke immediate key rotation (lifetime limit of 10 on-demand rotations per key). For keys stored in the KMS HSMs, AWS KMS keeps previous versions of keys to use for decryption of data encrypted under an old version of a key. However, for imported or custom key store keys, you may need to re-encrypt your data depending on whether you decide to keep old versions of keys available.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-11T15:45:11.859564"}}
{"question": "What are the differences in performance and rotation capabilities between customer managed keys created and stored in the KMS HSMs and keys in the external key store (XKS) in AWS KMS?", "answer": "Customer managed keys created and stored in the KMS HSMs offer higher performance, lower latency, and automatic and on-demand rotation capabilities for symmetric encryption keys. In contrast, keys in the external key store (XKS) require you to manage all key lifecycle events including rotation for external keys in your key manager.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-4", "source_tokens": 479, "generated_at": "2026-02-11T15:45:11.860043"}}
{"question": "What is the waiting period for scheduling an AWS KMS key for deletion?", "answer": "The waiting period for scheduling an AWS KMS key for deletion ranges from 7 to 30 days.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-11T15:45:16.758603"}}
{"question": "Why is there a waiting period before an AWS KMS key can be deleted?", "answer": "The waiting period before an AWS KMS key can be deleted allows you to verify the impact of deleting the key on your applications and users. It helps ensure that the key is no longer in use.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-11T15:45:16.758977"}}
{"question": "Can I delete the imported key material for an AWS KMS key without deleting the key? And if so, how?", "answer": "Yes, you can delete the imported key material for an AWS KMS key without deleting the key. You can do this on demand without a waiting period or define an expiration time during the import process. If you need to use the key material again, you can re-import it into the AWS KMS key.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-5", "source_tokens": 477, "generated_at": "2026-02-11T15:45:16.759847"}}
{"question": "What part of a symmetric KMS key or an asymmetric KMS key in AWS KMS can be exported in plain text?", "answer": "Only the public portion of an asymmetric KMS key can be exported in plain text.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-11T15:45:21.777307"}}
{"question": "How is the symmetric data key or the private portion of the asymmetric data key encrypted in AWS KMS?", "answer": "The symmetric data key or the private portion of the asymmetric data key is encrypted under the symmetric KMS key you define when requesting AWS KMS to generate the data key.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-11T15:45:21.777668"}}
{"question": "What's the difference between exporting a symmetric data key and an asymmetric data key from AWS KMS?", "answer": "A symmetric data key can be exported using either the GenerateDataKey API or the GenerateDataKeyWithoutPlaintext API, whereas only the public portion of an asymmetric data key can be exported in plain text, and both the private and public portions can be exported using the GenerateDataKeyPair API or the GenerateDataKeyPairWithoutPlaintext API.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-6", "source_tokens": 171, "generated_at": "2026-02-11T15:45:21.778180"}}
{"question": "What is the primary function of AWS Private CA in the context of AWS services?", "answer": "AWS Private CA provides a public key infrastructure (PKI) to identify entities and secure network connections. It issues certificates to identify web and application servers, service meshes, VPN users, internal API endpoints, and AWS IoT Core devices, and establishes encrypted TLS/SSL communications channels.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:45:27.120990"}}
{"question": "How does AWS Private CA and AWS KMS differ in their functions and uses?", "answer": "AWS Private CA focuses on providing PKI infrastructure and issuing certificates for securing network connections and establishing encrypted communications channels. In contrast, AWS KMS offers asymmetric keys for digital signing and encryption operations that donâ€™t require certificates.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:45:27.121275"}}
{"question": "What are the main benefits of using AWS Private CA for certificates and PKI infrastructure?", "answer": "AWS Private CA offers benefits such as identity verification, distributed trust, key lifecycle management, and certificate status revocation. These functions add important processes and infrastructure to the underlying asymmetric cryptographic keys and algorithms provided by AWS KMS.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:45:27.121672"}}
{"question": "In what security level are the FIPS 140-3 validated HSMs used by AWS KMS?", "answer": "FIPS 140-3 Security Level 3", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-11T15:45:32.264207"}}
{"question": "How does AWS KMS ensure the confidentiality and integrity of your KMS keys?", "answer": "AWS KMS uses hardware security modules (HSMs) that have been validated under FIPS 140-3 or are in the process of being validated to protect the confidentiality and integrity of your keys. Your plaintext KMS keys never leave the HSMs, are never written to disk, and are only ever used in the volatile memory of the HSMs for the time needed to perform your requested cryptographic operation.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-11T15:45:32.264554"}}
{"question": "What's the difference between the FIPS 140-3 validated HSMs used by AWS KMS in different regions?", "answer": "In all other AWS Regions, AWS KMS uses FIPS 140-3 validated HSMs. However, in China Regions, AWS KMS uses China's Office of the State Commercial Cryptographic Administration (OSCCA) certified HSMs instead.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-8", "source_tokens": 432, "generated_at": "2026-02-11T15:45:32.265088"}}
{"question": "What security feature does AWS KMS FIPS 140-2 validated HTTPS endpoints use for encryption?", "answer": "AWS KMS FIPS 140-2 validated HTTPS endpoints use the OpenSSL FIPS Object Module for encryption.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-11T15:45:37.055229"}}
{"question": "How do you ensure the security of data keys returned by AWS KMS for use in your application?", "answer": "You encrypt data keys under a root key you define in AWS KMS and store the encrypted data key along with your encrypted data. Only users with permissions to use the original root key can decrypt your encrypted data key.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-11T15:45:37.055574"}}
{"question": "What's the difference between a single-Region and a multi-Region key in AWS KMS?", "answer": "A single-Region key is stored and used only in the Region in which it was created, while a multi-Region key can be replicated into multiple Regions within the same AWS partition.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-9", "source_tokens": 464, "generated_at": "2026-02-11T15:45:37.056095"}}
{"question": "What types of AWS KMS requests will be logged in CloudTrail?", "answer": "CloudTrail will log all AWS KMS API requests, including management requests and cryptographic requests.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T15:45:41.650002"}}
{"question": "How does interacting with keys in CloudHSM compare to AWS KMS?", "answer": "Interacting with keys in CloudHSM is similar to interacting with applications running in Amazon EC2, while interacting with AWS KMS involves using the AWS SDK or other AWS services integrated with AWS KMS, or using the AWS Encryption SDK.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T15:45:41.650338"}}
{"question": "What are some use cases for CloudHSM?", "answer": "CloudHSM can be used for a variety of use cases, such as Digital Rights Management (DRM), Public Key Infrastructure (PKI), document signing, and cryptographic functions using PKCS#11, Java JCE, or Microsoft CNG interfaces.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-10", "source_tokens": 496, "generated_at": "2026-02-11T15:45:41.650857"}}
{"question": "What is included in the AWS KMS Free Tier for creating and storing keys in all Regions?", "answer": "The AWS KMS Free Tier includes creating and storing AWS managed keys at no additional cost in all Regions.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-11T15:45:46.381422"}}
{"question": "Why would you import a key into AWS KMS instead of using an AWS managed key?", "answer": "You would import a key into AWS KMS to gain greater control over the creation, lifecycle management, and durability of your key. This can help meet compliance requirements related to maintaining a secure copy of the key and the ability to immediately delete the imported key.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-11T15:45:46.381696"}}
{"question": "How does importing an asymmetric key into AWS KMS differ from importing a symmetric key?", "answer": "Importing an asymmetric key into AWS KMS involves wrapping the key with an AWS KMS-provided public key using a supported wrapping algorithm. This step is not required when importing symmetric keys.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-11", "source_tokens": 378, "generated_at": "2026-02-11T15:45:46.382093"}}
{"question": "What is the difference between the expiration behavior of imported keys and keys generated by AWS KMS?", "answer": "Imported keys can be set with an expiration period, which AWS KMS will automatically delete the key material after. Keys generated by AWS KMS do not have an expiration time and cannot be deleted immediately, requiring a wait period before deletion.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-11T15:45:51.717979"}}
{"question": "Why is it important for me to maintain a copy of my imported key in my key management infrastructure?", "answer": "You are responsible for maintaining a copy of your imported keys for re-import at any time. AWS only retains the KMS key reference and associated metadata, not the key material itself.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-11T15:45:51.718189"}}
{"question": "How does the expiration handling differ between 256-bit keys imported to AWS KMS and keys generated by AWS KMS?", "answer": "Imported 256-bit keys can be set to expire and will be automatically deleted by AWS KMS. Generated 256-bit keys by AWS KMS do not have an expiration time and can only be manually deleted after a wait period.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-12", "source_tokens": 463, "generated_at": "2026-02-11T15:45:51.718545"}}
{"question": "What encryption algorithms can be used with RSA 2048, RSA 3072, and RSA 4096 key types in AWS KMS?", "answer": "AWS KMS supports the RSAES_OAEP_SHA_1 and RSAES_OAEP_SHA_256 encryption algorithms with RSA 2048, RSA 3072, and RSA 4096 key types.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T15:45:59.376409"}}
{"question": "How does AWS KMS handle digital signature verification or public key encryption with elliptic curve key types?", "answer": "AWS KMS supports the ECDH key agreement algorithms when using elliptic curve key types. For digital signature verification or public key encryption, you can call the â€˜Verifyâ€™ or â€˜Encryptâ€™ API respectively.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T15:45:59.376749"}}
{"question": "What's the difference between the signing algorithms supported by AWS KMS for RSA and elliptic curve key types?", "answer": "For RSA key types, AWS KMS supports RSASSA_PSS_SHA_1, RSASSA_PSS_SHA_256, RSASSA_PSS_SHA_384, RSASSA_PKCS1_V1_5_SHA_256, RSASSA_PKCS1_V1_5_SHA_384, and RSASSA_PKCS1_V1_5_SHA_512 signing algorithms. For elliptic curve key types, AWS KMS supports the ECDSA_SHA_256, ECDSA_SHA_384, and ECDSA_SHA_512 signing algorithms.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T15:45:59.377325"}}
{"question": "What is the maximum size limit for data to be digitally signed using AWS KMS?", "answer": "The maximum size limit for data to be digitally signed using AWS KMS is 4 KB. If data is larger than 4 KB, a message digest of the data must be created and sent to AWS KMS to sign the digest instead.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-11T15:46:04.201697"}}
{"question": "Why would you use an asymmetric key in AWS KMS for encryption instead of a symmetric key?", "answer": "You would use an asymmetric key in AWS KMS for encryption instead of a symmetric key because asymmetric encryption provides better security for your data as the encryption and decryption process uses both a public and a private key, ensuring that only the intended recipient can access the data.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-11T15:46:04.202085"}}
{"question": "What is the difference between an RSA key type and an elliptic curve key type in AWS KMS in terms of their usage?", "answer": "An RSA key type in AWS KMS can be used for both signing and encryption operations, while an elliptic curve key type can only be used for signing operations.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-14", "source_tokens": 473, "generated_at": "2026-02-11T15:46:04.202305"}}
{"question": "What are the benefits of using a custom key store in AWS KMS, as described in the text?", "answer": "The benefits of using a custom key store in AWS KMS include having control over keys in a single tenant HSM, the ability to independently manage key lifecycle, and the option to audit all use of keys independently of AWS KMS or CloudTrail.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T15:46:09.027117"}}
{"question": "What are the differences in managing keys between a custom key store backed by CloudHSM and the default AWS KMS key store?", "answer": "In a custom key store backed by CloudHSM, you cannot import key material and AWS KMS does not automatically rotate keys. In all other respects, keys are managed similarly.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T15:46:09.027489"}}
{"question": "What type of keys can be stored and managed in an AWS KMS custom key store backed by CloudHSM?", "answer": "Customer managed KMS keys can be stored and managed in an AWS KMS custom key store backed by CloudHSM.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T15:46:09.028043"}}
{"question": "What logging mechanisms are provided by the use of an AWS KMS custom key store?", "answer": "The use of an AWS KMS custom key store provides three additional auditing mechanisms beyond what is logged by AWS KMS to CloudTrail. CloudHSM logs all API activity to CloudTrail, each cluster captures its own local logs, and each CloudHSM instance copies the local user and key management activity logs to AWS CloudWatch.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-11T15:46:15.683063"}}
{"question": "Why would you use an AWS KMS custom key store instead of the default AWS KMS key store in terms of auditing?", "answer": "An AWS KMS custom key store provides additional auditing mechanisms beyond what is offered by the default AWS KMS key store. It logs all API activity to CloudTrail, each cluster captures its own local logs, and each CloudHSM instance copies the local user and key management activity logs to AWS CloudWatch.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-11T15:46:15.683398"}}
{"question": "How does the use of an AWS KMS custom key store backed by CloudHSM compare to the use of the default AWS KMS key store in terms of logging and availability?", "answer": "The use of an AWS KMS custom key store backed by CloudHSM provides additional logging mechanisms compared to the use of the default AWS KMS key store. It logs all API activity to CloudTrail, each cluster captures its own local logs, and each CloudHSM instance copies the local user and key management activity logs to AWS CloudWatch. However, the rate at which keys stored in the custom key store can be used through AWS KMS API calls is lower than for keys stored in the default AWS KMS key store.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-16", "source_tokens": 447, "generated_at": "2026-02-11T15:46:15.683896"}}
{"question": "What is required to use a custom key store in AWS KMS with an existing AWS CloudHSM cluster?", "answer": "Users need to set up an AWS CloudHSM cluster, add HSMs, manage HSM users, and potentially restore HSMs from backup.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-11T15:46:21.189797"}}
{"question": "How does using an external key store in AWS KMS differ from using a custom key store within AWS KMS?", "answer": "An external key store is a custom key store backed by an external key management infrastructure that you own and manage outside of AWS. All encryption or decryption operations are performed in your key manager with cryptographic keys and operations that are under your control and are physically inaccessible to AWS.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-11T15:46:21.190160"}}
{"question": "What are the differences between managing keys in an external key store and managing keys in an AWS KMS custom key store?", "answer": "In an external key store, users manage the HSM cluster, add HSMs, manage HSM users, and perform key rotation manually. In an AWS KMS custom key store, users cannot import their own key material, cannot migrate keys between key stores, and do not have the ability to automatically rotate keys.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-17", "source_tokens": 485, "generated_at": "2026-02-11T15:46:21.190595"}}
{"question": "What component in your network is responsible for forwarding AWS KMS requests to your key management infrastructure?", "answer": "An XKS Proxy", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T15:46:26.347498"}}
{"question": "How does the XKS Proxy facilitate the use of external keys for encryption and decryption in AWS services?", "answer": "The XKS Proxy acts as an intermediary between AWS services and an external key manager. AWS services call the AWS KMS GenerateDataKey API, which returns a plaintext data key and a double-encrypted data key. The plaintext data key is encrypted by a key stored in AWS KMS and then forwarded to the XKS Proxy implementation connected to the external key manager for a second encryption. The resulting double-encrypted data key is returned to the AWS service for use in encrypting data.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T15:46:26.347767"}}
{"question": "What services can you use XKS keys to encrypt data in?", "answer": "You can use XKS keys to encrypt data in any AWS service that integrates with AWS KMS using customer managed keys. The list of supported services is available here.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-18", "source_tokens": 414, "generated_at": "2026-02-11T15:46:26.348150"}}
{"question": "What encryption protocol is recommended for the network connection between AWS KMS, XKS Proxy, and an external key manager?", "answer": "A point-to-point encryption protocol like TLS is recommended.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T15:46:30.327523"}}
{"question": "Why is double encryption used in the process of transferring data between AWS KMS and an external key manager?", "answer": "Double encryption provides security controls such as ensuring that no ciphertext can be decrypted without the key material in the external key manager, and that the ciphertext leaving the AWS network is encrypted using FIPS 140 certified AWS KMS HSMs.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T15:46:30.327864"}}
{"question": "How does the pricing of XKS keys compare to other customer managed keys in AWS KMS?", "answer": "XKS keys are priced at $1 per month per key until they are deleted, which is the same price as other customer managed keys.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-19", "source_tokens": 490, "generated_at": "2026-02-11T15:46:30.328331"}}
{"question": "What happens when automatic key rotation is enabled for an XKS key?", "answer": "Automatic rotation for XKS keys occurs entirely in the external key manager. When a rotated XKS key is used to encrypt data, the current key material is used. When a rotated XKS key is used to decrypt ciphertext, the version of the key material that was used to encrypt it is used.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-11T15:46:36.379402"}}
{"question": "How does the process of using an XKS key with automatic rotation differ from a non-rotating XKS key?", "answer": "The main difference lies in the ability to successfully decrypt earlier ciphertexts using previous XKS keys. With automatic rotation, as long as the previous keys are still enabled in the external key manager, you can make successful Decrypt API requests under those versions of your XKS keys. For services that do not cache keys, the next API call using the rotated XKS key will fail.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-11T15:46:36.379686"}}
{"question": "How does the authentication process differ between an external key store proxy with automatic TLS and one without when using AWS KMS?", "answer": "An external key store proxy with automatic TLS uses mutual TLS for additional assurance that it only accepts requests from AWS KMS. Without mutual TLS, AWS KMS authenticates the proxy using server-side TLS certificates.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-20", "source_tokens": 362, "generated_at": "2026-02-11T15:46:36.380061"}}
{"question": "What metadata is included in requests from AWS KMS to the XKS Proxy for authorization purposes?", "answer": "The calling AWS user/role, the KMS key ARN, and the specific KMS API that was requested are included in requests from AWS KMS to the XKS Proxy for authorization purposes.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-11T15:46:41.912409"}}
{"question": "How can you apply fine-grained authorization policies on the use of keys in an external key manager beyond trusting requests from AWS KMS?", "answer": "By implementing a secondary layer of authorization controls based on the request metadata included with each request sent from AWS KMS to the XKS Proxy, you can apply fine-grained authorization policies on the use of keys in an external key manager.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-11T15:46:41.912744"}}
{"question": "What's the difference between the authorization controls applied by the XKS Proxy based on request metadata and those applied by AWS KMS?", "answer": "The XKS Proxy allows for fine-grained authorization policy on the use of a key in the external key manager beyond simply trusting any request from AWS KMS. AWS KMS applies authorization mechanisms such as IAM policies, AWS KMS key policies, and grants.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-21", "source_tokens": 277, "generated_at": "2026-02-11T15:46:41.913174"}}
{"question": "What is the responsibility of the user regarding the availability of the XKS Proxy and external key material in AWS KMS?", "answer": "The user is responsible for ensuring the high availability of the XKS Proxy and external key manager for AWS KMS to successfully connect and complete cryptographic operations using the keys.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-11T15:46:47.001048"}}
{"question": "How does the lack of availability of the XKS Proxy or external key manager impact the performance of AWS KMS?", "answer": "If the XKS Proxy or external key manager is unavailable, the EC2 instances will fail to launch as they are unable to decrypt the volume keys, leading to performance issues.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-11T15:46:47.001389"}}
{"question": "What's the difference between availability and durability risks in the context of external keys in AWS KMS?", "answer": "Availability risk refers to the impact of the XKS Proxy or external key manager being unavailable on the performance of AWS KMS, while durability risk relates to the permanent loss or deletion of the external key, making all ciphertext encrypted under it unrecoverable.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-22", "source_tokens": 328, "generated_at": "2026-02-11T15:46:47.001600"}}
{"question": "What is the elapsed time limit for a single XKS Proxy request from AWS KMS?", "answer": "The elapsed time limit for a single XKS Proxy request from AWS KMS is 500ms.", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-11T15:46:52.154763"}}
{"question": "How does the performance of the XKS Proxy impact the request rate from AWS KMS?", "answer": "The XKS Proxy's performance determines the request rate from AWS KMS, as every request using XKS keys requires a connection to the XKS Proxy. If the request rate from AWS KMS exceeds the request rate the XKS Proxy or external key manager can support, the XKS Proxy can become a bottleneck.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-11T15:46:52.155039"}}
{"question": "What is the difference in retry behavior between failed requests below and above 250ms in the XKS Proxy?", "answer": "AWS KMS will attempt a single retry for any request that takes 250ms or less, but if the retry request also takes more than 250ms, a 400 error will be returned to the calling client.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-23", "source_tokens": 238, "generated_at": "2026-02-11T15:46:52.155237"}}
{"question": "Which type of key store infrastructure is not covered by AWS KMS availability SLA?", "answer": "XKS (external key store infrastructure)", "question_type": "factual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-11T15:46:55.546885"}}
{"question": "Why isn't AWS KMS able to provide an availability SLA for XKS keys?", "answer": "AWS cannot control the end-to-end availability of the connection between AWS KMS and XKS.", "question_type": "conceptual", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-11T15:46:55.547142"}}
{"question": "How does the availability SLA for AWS services differ between XKS keys and AWS KMS keys?", "answer": "AWS KMS keys are covered by the availability SLA for any AWS service, while XKS keys are not.", "question_type": "comparison", "metadata": {"service": "KMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "kms-faq-24", "source_tokens": 80, "generated_at": "2026-02-11T15:46:55.547548"}}
{"question": "What are the three main features of AWS Lake Formation mentioned in the text?", "answer": "Centralized permissions management, Security management and governance, Data access monitoring and auditing", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-11T15:47:00.821540"}}
{"question": "How does AWS Lake Formation enable data sharing and access control?", "answer": "AWS Lake Formation makes it easier to centralize data security and governance using the AWS Glue Data Catalog, delivering fine-grained data access control and scaling permissions across users. It also facilitates sharing data internally and externally with no data movement, and provides comprehensive data access auditing.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-11T15:47:00.821834"}}
{"question": "What is the difference between AWS Lake Formation and AWS Glue in terms of their roles and integration with Amazon DataZone?", "answer": "AWS Lake Formation is a service for centralized data security, governance, data sharing, and data access monitoring. AWS Glue is a service for data integration and ETL. They share console controls and the AWS Glue Data Catalog, and Amazon DataZone uses Lake Formation to manage permissions and facilitate sharing of data products.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-0", "source_tokens": 512, "generated_at": "2026-02-11T15:47:00.822227"}}
{"question": "Which third-party tools integrate with AWS Lake Formation?", "answer": "Ahana, Dremio, Privacera, Collibra, and Starburst are third-party tools that integrate with AWS Lake Formation.", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T15:47:05.890203"}}
{"question": "How does Lake Formation's fine-grained access control benefit organizations?", "answer": "Lake Formation's fine-grained access control (FGAC) makes it easier to comply with increased business regulations, apply better data governance, and protect and manage consumersâ€™ sensitive data by managing permissions to the column, row, and cell level.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T15:47:05.890494"}}
{"question": "What is the difference between Lake Formation's tag-based access control and fine-grained access control?", "answer": "Lake Formation's tag-based access control (LF-TBAC) uses attributes of the data to help keep permissions up to date as data changes, while fine-grained access control (FGAC) manages permissions to the column, row, and cell level.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T15:47:05.890901"}}
{"question": "What service lets users share distributed data across AWS accounts with proper data governance?", "answer": "AWS Lake Formation", "question_type": "factual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T15:47:10.504873"}}
{"question": "How does AWS Lake Formation allow users to share data with external businesses without moving or copying it?", "answer": "AWS Lake Formation integrates with AWS Data Exchange, enabling users to share data with external businesses directly.", "question_type": "conceptual", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T15:47:10.505166"}}
{"question": "What AWS services can use AWS Lake Formation to access data in Amazon S3, and how does Lake Formation provide access?", "answer": "AWS services such as Amazon Athena, AWS Glue, Amazon Redshift Spectrum, Amazon EMR, Amazon QuickSight, and Amazon SageMaker Studio can use Lake Formation to access data in Amazon S3. Lake Formation provides access to data through temporary credentials and defines and manages FGAC permissions for the data in the AWS Glue Data Catalog.", "question_type": "comparison", "metadata": {"service": "LAKE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lake-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T15:47:10.505324"}}
{"question": "What programming languages does AWS Lambda support for writing functions?", "answer": "AWS Lambda supports writing functions in Java, Node.js, Python, C#, PowerShell, Go, and Ruby.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T15:47:14.287982"}}
{"question": "How does AWS Lambda simplify application development and deployment?", "answer": "AWS Lambda lets you run code without provisioning or managing servers. You only pay for the compute time you consume and can directly integrate your code with other AWS services or call it from web or mobile apps.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T15:47:14.288313"}}
{"question": "What is the difference between using AWS Lambda for processing AWS events and building applications?", "answer": "Using AWS Lambda for processing AWS events involves setting up your code to automatically respond to triggers from other AWS services. Building applications with AWS Lambda means calling your code directly from web or mobile apps.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-0", "source_tokens": 503, "generated_at": "2026-02-11T15:47:14.288482"}}
{"question": "What is the main component of AWS's serverless computing service?", "answer": "AWS Lambda", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T15:47:18.879482"}}
{"question": "How does AWS Lambda differ from other AWS compute services in terms of management responsibilities?", "answer": "Unlike Amazon EC2, Elastic Beanstalk, or Amazon EC2 Container Service, with AWS Lambda, all server management tasks, including capacity provisioning, monitoring fleet health and performance, security patches, and code deployment, are handled by AWS.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T15:47:18.879845"}}
{"question": "What are some common use cases for AWS Lambda?", "answer": "AWS Lambda is used for building mobile back-ends, handling data retrieval and transformation from Amazon DynamoDB, compressing or transforming objects as they are uploaded to Amazon S3, auditing and reporting of API calls made to any Amazon Web Service, and server-less processing of streaming data using Amazon Kinesis.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T15:47:18.880060"}}
{"question": "What programming languages does AWS Lambda support for authoring functions?", "answer": "AWS Lambda supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby for authoring functions. Additional languages can be used by providing a Runtime API.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-11T15:47:23.867085"}}
{"question": "What security measures does AWS Lambda take to ensure the security of the functions?", "answer": "AWS Lambda operates the compute infrastructure, performs health checks, and applies security patches. Each function runs in an isolated environment with its own resources and file system view. AWS Lambda stores code in Amazon S3 and encrypts it at rest, and performs additional integrity checks while the code is in use.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-11T15:47:23.867391"}}
{"question": "How does AWS Lambda compare the performance between reusing and creating a new function instance?", "answer": "AWS Lambda may choose to retain an instance of a function and reuse it to serve a subsequent request for improved performance. However, the code should not assume that this will always happen.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-2", "source_tokens": 415, "generated_at": "2026-02-11T15:47:23.867578"}}
{"question": "What is the minimum and maximum ephemeral storage size for a Lambda function?", "answer": "The minimum ephemeral storage size for a Lambda function is 512MB, and the maximum is 10,240MB, both in 1MB increments.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T15:47:30.004510"}}
{"question": "What is the difference between AWS Lambda ephemeral storage and Amazon EBS gp3 storage in terms of pricing and purpose?", "answer": "AWS Lambda ephemeral storage is priced at $0.0000000309 per GB-second, or $0.000111 per GB-hour and $0.08 per GB-month. It is ideal for storing data needed by code in a single function invocation. Amazon EBS gp3 storage, on the other hand, is priced at $0.08 per GB-month and is designed for durable, persistent storage.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T15:47:30.004766"}}
{"question": "Why would you use AWS Lambda ephemeral storage over other storage options for your application?", "answer": "AWS Lambda ephemeral storage can be used when your application requires storing data needed by code in a single function invocation. It is ideal for transient caching and is encrypted at rest by AWS.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T15:47:30.004944"}}
{"question": "What size range can you configure for a Lambda function's ephemeral storage?", "answer": "You can configure a Lambda function's ephemeral storage between 512MB and 10,240MB, in 1MB increments.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:47:35.051837"}}
{"question": "Why should you consider using Amazon EFS or Amazon S3 instead of ephemeral storage in Lambda?", "answer": "If your application requires persistent storage, consider using Amazon EFS or Amazon S3 instead of ephemeral storage in Lambda. Ephemeral storage may be affected by the initialization behavior of Provisioned Concurrency.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:47:35.052332"}}
{"question": "How does AWS Lambda's ephemeral storage compare to Amazon S3 in terms of storage capacity?", "answer": "AWS Lambda's ephemeral storage has a smaller capacity range, with options from 512MB to 10,240MB, while Amazon S3 offers virtually unlimited storage.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-4", "source_tokens": 512, "generated_at": "2026-02-11T15:47:35.052508"}}
{"question": "What methods can you use to upload your code for an AWS Lambda function?", "answer": "You can author the code directly in the AWS Lambda console using its code editor, or you can package it as a ZIP file and upload it using the AWS Lambda console, AWS CLI, or specify an Amazon S3 location.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T15:47:40.024332"}}
{"question": "How does the AWS Lambda console help in creating and managing Lambda functions?", "answer": "The AWS Lambda console provides an IDE-like environment to author and test your functions, view the results of function executions, and manage associated resources such as environment variables and layers.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T15:47:40.024623"}}
{"question": "What's the difference between uploading code to the AWS Lambda console directly vs. using a ZIP file?", "answer": "Directly authoring code in the AWS Lambda console allows you to write, test, and deploy your function in one place, whereas using a ZIP file involves packaging your code and any dependencies and uploading it to AWS Lambda.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-5", "source_tokens": 420, "generated_at": "2026-02-11T15:47:40.025015"}}
{"question": "What metrics does AWS Lambda automatically report through Amazon CloudWatch?", "answer": "AWS Lambda reports real-time metrics including total requests, account-level and function-level concurrency usage, latency, error rates, and throttled requests.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-11T15:47:44.046372"}}
{"question": "Why does AWS Lambda automatically integrate with Amazon CloudWatch logs?", "answer": "AWS Lambda automatically integrates with Amazon CloudWatch logs to provide application lifecycle event log entries, enabling users to easily insert additional logging statements into their code and call third-party logging APIs.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-11T15:47:44.046710"}}
{"question": "How does the resource allocation of memory affect the CPU power in AWS Lambda?", "answer": "Choosing 256MB of memory allocates approximately twice as much CPU power to your Lambda function as requesting 128MB of memory and half as much CPU power as choosing 512MB of memory.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-6", "source_tokens": 450, "generated_at": "2026-02-11T15:47:44.047039"}}
{"question": "What is the maximum execution time for an AWS Lambda function?", "answer": "The maximum execution time for an AWS Lambda function is 15 minutes.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-11T15:47:48.599447"}}
{"question": "Why are larger memory functions ideal for data and computationally intensive applications in AWS Lambda?", "answer": "Larger memory functions are ideal for data and computationally intensive applications like machine learning, batch and ETL jobs, financial modeling, genomics, HPC, and media processing in AWS Lambda because they help multithreaded applications run faster.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-11T15:47:48.599797"}}
{"question": "How does the pricing of AWS Lambda compare to Compute Savings Plans in terms of savings on Duration and Provisioned Concurrency?", "answer": "AWS Lambda is priced on a pay-per-use basis, while Compute Savings Plans offer up to 17% discount on Duration and Provisioned Concurrency.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-7", "source_tokens": 370, "generated_at": "2026-02-11T15:47:48.599956"}}
{"question": "What is the pricing structure for AWS Lambda's monthly on-demand function duration on x86 architecture in US East (Ohio) region?", "answer": "The pricing structure for AWS Lambda's monthly on-demand function duration on x86 architecture in US East (Ohio) region is as follows: $0.0000166667 for every GB-second for the first 6 billion GB-seconds per month, $0.0000150000 for every GB-second for the next 9 billion GB-seconds per month, and $0.0000133334 for every GB-second over 15 billion GB-seconds per month.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:47:56.260654"}}
{"question": "How does AWS Lambda's tiered pricing work for monthly on-demand function duration?", "answer": "AWS Lambda's tiered pricing for monthly on-demand function duration applies to aggregate monthly on-demand duration of functions running on the same architecture (x86 or Arm, respectively), in the same region, within the same account or across accounts in AWS Organizations.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:47:56.260955"}}
{"question": "What is the difference between pricing for monthly on-demand function duration and hourly savings plan commitment in AWS Lambda?", "answer": "Monthly on-demand function duration pricing is applied to the aggregate monthly duration of functions running on the same architecture, in the same region, within the account or across accounts in AWS Organizations. Hourly savings plan commitment pricing is billed at the applicable CSP rate and discount for the covered usage and the remaining usage not covered by the commitment is billed at the rate corresponding to the tier the monthly aggregate function duration falls in.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-8", "source_tokens": 506, "generated_at": "2026-02-11T15:47:56.261124"}}
{"question": "What is the process for associating an AWS Lambda function with an Amazon S3 bucket's notifications?", "answer": "You can associate an AWS Lambda function with an Amazon S3 bucket's notifications through the AWS Lambda console or the Amazon S3 console. This functionality is also available through the AWS SDK and CLI.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T15:48:01.854228"}}
{"question": "How does a Lambda function get triggered when an event occurs in an Amazon S3 bucket?", "answer": "You can associate an AWS Lambda function with an Amazon S3 bucket's notifications. When an event occurs in the bucket, such as an object being created or deleted, the event data is sent to the Lambda function as an event input parameter.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T15:48:01.854601"}}
{"question": "What's the difference between associating an AWS Lambda function with an Amazon S3 bucket's notifications and an Amazon DynamoDB Stream?", "answer": "When associating a Lambda function with an Amazon S3 bucket's notifications, the function is triggered by events in the S3 bucket. When associating a Lambda function with an Amazon DynamoDB Stream, the function is triggered by updates to a DynamoDB table.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T15:48:01.854996"}}
{"question": "What is the guarantee for processing order of records within the same shard in AWS Lambda?", "answer": "AWS Lambda guarantees that records put in the same shard will be processed in the order they were received.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-11T15:48:06.362457"}}
{"question": "How does AWS Kinesis Data Analytics (KDA) differ from AWS Lambda in terms of analytics capabilities?", "answer": "While AWS Lambda provides time-based aggregations over a 15-minute tumbling window for a single shard, KDA offers more complex analytics with various processing window options and exactly-once processing over an entire data stream across multiple logical partitions.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-11T15:48:06.362731"}}
{"question": "What are the different types of processing windows supported by AWS Kinesis Data Analytics (KDA)?", "answer": "AWS Kinesis Data Analytics supports tumbling window, stagger window, sliding window, and session window processing.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-10", "source_tokens": 486, "generated_at": "2026-02-11T15:48:06.362935"}}
{"question": "What information does AWS Lambda automatically gain access to when called through the AWS Mobile SDK?", "answer": "AWS Lambda automatically gains insight into the device and application that made the call through the â€˜contextâ€™ object.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-11T15:48:15.582622"}}
{"question": "How does AWS Lambda leverage Amazon Cognito identity for user authentication and access to user data?", "answer": "When user identity is presented to a Lambda function in the form of an Amazon Cognito id, the function can access user data from Amazon Cognito or use it as a key to store and retrieve data in Amazon DynamoDB or other web services.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-11T15:48:15.582947"}}
{"question": "What are the differences in error handling and retry logic between S3 bucket notifications and other ordered event sources in AWS Lambda?", "answer": "AWS Lambda will attempt execution of your function three times in the event of an error condition or exceeding a service or resource limit for S3 bucket notifications. For ordered event sources like Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution until the data expires.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-12", "source_tokens": 485, "generated_at": "2026-02-11T15:48:15.583309"}}
{"question": "What resource types does AWS CloudFormation support for serverless applications according to the context?", "answer": "The context mentions that AWS CloudFormation supports a set of resource types referred to as 'serverless resources'. However, the text does not provide specific names for these resource types.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:48:21.403697"}}
{"question": "How can you deploy and manage serverless applications using AWS SAM and AWS CloudFormation?", "answer": "You can deploy and manage serverless applications using AWS SAM, which is a specification prescribing the rules for expressing serverless applications on AWS. AWS SAM aligns with the syntax used by AWS CloudFormation and is supported natively within AWS CloudFormation as a set of resource types. AWS CloudFormation commands can be used to package and deploy the serverless application.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:48:21.403998"}}
{"question": "What is the role of AWS CodePipeline and AWS CodeDeploy in the serverless application release process?", "answer": "AWS CodePipeline is a continuous delivery service used to model, visualize and automate the steps required to release a serverless application. AWS CodeDeploy provides a deployment automation engine for Lambda-based applications and helps establish guardrails to ensure the safety, stability, and readiness of code before full production release.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:48:21.404420"}}
{"question": "What permissions do I need to add to my Lambda function execution role to enable tracing with AWS X-Ray?", "answer": "You need to add X-Ray permissions to your Lambda function execution role.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-11T15:48:26.004816"}}
{"question": "How does enabling X-Ray tracing for my Lambda function provide insights?", "answer": "Enabling X-Ray tracing for your Lambda function provides insights such as Lambda service overhead, function init time, and function execution time.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-11T15:48:26.005119"}}
{"question": "What is the difference between enabling X-Ray tracing in my Lambda function and using the X-Ray SDK?", "answer": "Enabling X-Ray tracing in your Lambda function emits tracing information to X-Ray regarding the Lambda service overhead. Using the X-Ray SDK allows you to create your own trace segments, annotate your traces, or view trace segments for downstream calls made from your Lambda function.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-14", "source_tokens": 424, "generated_at": "2026-02-11T15:48:26.005570"}}
{"question": "Which image formats are supported by AWS Lambda for container images?", "answer": "AWS Lambda supports Docker Image Manifest V2 Schema 2 and Open Container Initiative (OCI) Specifications (v1.0 and up) for container images.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-11T15:48:30.735463"}}
{"question": "What are the benefits of using custom Linux base images in AWS Lambda instead of the provided base images?", "answer": "Using custom Linux base images in AWS Lambda allows you to extend the provided base images and use your preferred images with a size of up to 10GB. This can provide more flexibility and compatibility for your specific use case.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-11T15:48:30.735789"}}
{"question": "How does using container images affect the use of Lambda layers in AWS Lambda?", "answer": "Once deployed, AWS Lambda treats an image as immutable. However, customers can use container layers during their build process to include dependencies. This allows for the use of Lambda layers in conjunction with container images.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-15", "source_tokens": 404, "generated_at": "2026-02-11T15:48:30.736202"}}
{"question": "What is the maximum size for functions created using ZIP archives in AWS Lambda?", "answer": "The maximum size for functions created using ZIP archives in AWS Lambda is 250 MB unzipped.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-11T15:48:36.204944"}}
{"question": "What are the differences between functions created using ZIP archives and container images in AWS Lambda in terms of management and patching?", "answer": "Functions created using ZIP archives are automatically patched for the latest runtime security and bug fixes, while functions defined as container images are immutable and customers are responsible for the components packaged in their function. AWS provides regularly updated base images for container images for security and bug fixes.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-11T15:48:36.205228"}}
{"question": "How does the use of container images for functions in AWS Lambda compare to ZIP archives in terms of image size and invocability?", "answer": "Functions created using container images have a maximum image size of 10 GB, while functions created using ZIP archives have a maximum code package size of 250 MB unzipped. A function defined as a container image may not be invocable when the underlying image is deleted from Amazon ECR.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-16", "source_tokens": 438, "generated_at": "2026-02-11T15:48:36.205398"}}
{"question": "What does the Lambda Runtime Interface Emulator do in local Lambda function testing?", "answer": "The Lambda Runtime Interface Emulator acts as a proxy for the Lambda Runtime API during local testing. It converts HTTP requests to JSON events and emulates the Lambda Runtime API, allowing you to test your Lambda function using familiar tools like cURL and the Docker CLI.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-11T15:48:41.886933"}}
{"question": "How does the Lambda Runtime Interface Emulator simplify local Lambda function testing?", "answer": "The Lambda Runtime Interface Emulator simplifies local testing by allowing you to use the docker run or docker-compose up command to test your Lambda application. It also enables you to add it as the entry point to the container image or package it as a sidecar so that the container image accepts HTTP requests instead of JSON events, making it easier to run on additional compute services.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-11T15:48:41.887183"}}
{"question": "What is the difference between the Lambda Runtime API and the Lambda Runtime Interface Emulator?", "answer": "The Lambda Runtime API in the running Lambda service accepts JSON events and returns responses. In contrast, the Lambda Runtime Interface Emulator emulates the Lambda Runtime API during local testing, allowing your Lambda function packaged as a container image to accept HTTP requests and surface them via the same interface locally to the function.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-17", "source_tokens": 471, "generated_at": "2026-02-11T15:48:41.887557"}}
{"question": "What are the requirements for deploying a containerized application to AWS Lambda?", "answer": "The container image must implement the Lambda Runtime API and be able to run on a read-only filesystem. The files required for the execution of function code must be readable by the default Lambda user, who is a Linux user with least-privileged permissions. The container image must be a Linux-based one.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-11T15:48:47.372469"}}
{"question": "How does AWS Lambda SnapStart work to improve startup performance?", "answer": "AWS Lambda SnapStart improves startup performance by snapshotting a function's initialized memory and disk state, and caching this snapshot for low-latency access. When the function is invoked again, Lambda resumes execution environments from the pre-initialized snapshot instead of initializing them from scratch.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-11T15:48:47.372721"}}
{"question": "What's the difference in startup performance between an AWS Lambda function without SnapStart and one with SnapStart enabled?", "answer": "An AWS Lambda function without SnapStart can take several seconds to start, while a function with SnapStart enabled can have a startup latency as low as sub-second.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-18", "source_tokens": 450, "generated_at": "2026-02-11T15:48:47.372860"}}
{"question": "What runtimes does Lambda SnapStart support?", "answer": "Lambda SnapStart supports Java 11 (and newer), Python 3.12 (and newer), and .NET 8 (and newer).", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-11T15:48:52.368793"}}
{"question": "How does enabling Lambda SnapStart impact my function's ability to access resources in a VPC?", "answer": "You can configure a Lambda SnapStart function to access resources in a virtual private cloud (VPC). For more information, see the Lambda documentation.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-11T15:48:52.369102"}}
{"question": "What are the differences between Lambda SnapStart and Provisioned Concurrency (PC) in terms of resource availability and performance?", "answer": "Lambda SnapStart is a performance optimization that reduces start-up times for functions, but does not eliminate cold starts. Provisioned Concurrency, on the other hand, maintains a warm pool of instances for your application, ensuring double-digit millisecond startup times. However, it may increase costs as you pay for the idle capacity.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-19", "source_tokens": 436, "generated_at": "2026-02-11T15:48:52.369258"}}
{"question": "What is the minimum duration for which I will be charged for caching a snapshot of my AWS Lambda function?", "answer": "The minimum duration for which you will be charged for caching a snapshot of your AWS Lambda function is 3 hours.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-11T15:48:58.474817"}}
{"question": "Why does AWS Lambda charge for SnapStart functionality and how does it differ for different managed runtimes?", "answer": "AWS Lambda charges for SnapStart functionality due to the cost of caching a snapshot of your function over a certain period, which is minimum of 3 hours. The duration for which snapshots remain active differs for different managed runtimes. For Python and .NET, snapshots remain active as long as the function is active. However, for Java, the snapshot associated with a published function expires if it remains inactive for more than 14 days.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-11T15:48:58.475056"}}
{"question": "How does the pricing for SnapStart in AWS Lambda compare to the pricing for supported Java managed runtimes?", "answer": "The main difference between SnapStart pricing in AWS Lambda and pricing for supported Java managed runtimes is the length of time for which snapshots remain active. SnapStart snapshots remain active as long as the function is active, whereas snapshots for supported Java managed runtimes can only cache a snapshot for up to 14 days.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-20", "source_tokens": 495, "generated_at": "2026-02-11T15:48:58.475431"}}
{"question": "What pricing model does Provisioned Concurrency follow?", "answer": "Provisioned Concurrency follows a pricing model where you pay for the amount of concurrency that you configure and for the period of time that you configure it.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T15:49:04.034822"}}
{"question": "Why is Provisioned Concurrency useful for building applications?", "answer": "Provisioned Concurrency is useful for building latency-sensitive applications because it allows you to easily configure the appropriate amount of concurrency based on your application's unique demand. This helps ensure consistent latency and scale characteristics for your functions.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T15:49:04.035100"}}
{"question": "How does Provisioned Concurrency on x86-based processors compare to Provisioned Concurrency on AWS Graviton2 processors?", "answer": "Both x86-based and AWS Graviton2 processors allow you to use Provisioned Concurrency and run your functions without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume. However, AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-21", "source_tokens": 430, "generated_at": "2026-02-11T15:49:04.035477"}}
{"question": "What is the price performance advantage of AWS Lambda functions using Graviton2 processors compared to x86 processors?", "answer": "AWS Lambda functions using Graviton2 processors offer up to 34% better price performance compared to functions running on x86 processors.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-11T15:49:08.778131"}}
{"question": "Why would you choose to use Graviton2 processors for your AWS Lambda functions?", "answer": "Graviton2 functions can deliver lower latency, higher performance, 20% lower cost, and the highest power-efficiency currently available at AWS, making them suitable for mission critical serverless applications.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-11T15:49:08.778428"}}
{"question": "How does the process of deploying a function to run on Graviton2 processors compare to x86-based processors?", "answer": "There is no difference in the process of deploying a function to run on Graviton2 processors compared to x86-based processors. You can configure existing and new functions to target the Graviton2 processor through various methods and AWS services.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-22", "source_tokens": 478, "generated_at": "2026-02-11T15:49:08.778855"}}
{"question": "What is the default architecture for AWS Lambda functions?", "answer": "The default architecture for AWS Lambda functions is â€˜x86_64'.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-11T15:49:12.541791"}}
{"question": "How does using Amazon Elastic File System (Amazon EFS) for AWS Lambda impact data processing?", "answer": "By using Amazon Elastic File System (Amazon EFS) for AWS Lambda, developers don't need to write code to download data to temporary storage. This enables them to process large volumes of data without the limitations of local temporary storage.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-11T15:49:12.542038"}}
{"question": "What is the cost difference between running AWS Lambda functions on x86 and Arm-based processors?", "answer": "AWS Lambda functions powered by Arm-based processors are 20% cheaper compared to x86-based Lambda functions.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-23", "source_tokens": 450, "generated_at": "2026-02-11T15:49:12.542443"}}
{"question": "What encryption method is used for data in transit between AWS Lambda and Amazon EFS?", "answer": "Data in transit between AWS Lambda functions and Amazon EFS is encrypted using industry-standard Transport Layer Security (TLS) 1.2.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:49:17.269381"}}
{"question": "Why would you use Amazon EFS for Lambda in a microservice architecture or Step Functions workflow?", "answer": "Amazon EFS for Lambda can be used in a stateful microservice architecture or Step Functions workflow to keep state between invocations.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:49:17.269682"}}
{"question": "How does the pricing model compare when using VPC peering for cross-account access between Lambda and EFS compared to not using it?", "answer": "When using VPC peering for cross-account access, customers will incur data transfer charges, while there is no additional charge for using EFS and Lambda in the same availability zone and not using VPC peering.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-24", "source_tokens": 508, "generated_at": "2026-02-11T15:49:17.270075"}}
{"question": "What is the default IAM authorization status for a Lambda function URL?", "answer": "Lambda function URLs are secured with IAM authorization by default.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T15:49:21.843835"}}
{"question": "How can I invoke a Lambda function using a custom domain name?", "answer": "You can use a custom domain with your function URL by creating an Amazon CloudFront distribution and mapping your custom domain to it. Then, map your CloudFront distribution domain name to be routed to your function URL as an origin.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T15:49:21.844185"}}
{"question": "What are the differences between using Lambda function URLs and Lambda@Edge?", "answer": "Lambda function URLs are used to invoke a Lambda function directly, whereas Lambda@Edge allows you to run code across AWS locations globally and respond to end-users at the lowest network latency. Lambda function URLs require no additional charge, whereas Lambda@Edge has its own pricing.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-25", "source_tokens": 488, "generated_at": "2026-02-11T15:49:21.844639"}}
{"question": "What CloudFront events can trigger a Lambda@Edge function?", "answer": "Lambda@Edge functions can be triggered by Viewer Request, Viewer Response, Origin Request, and Origin Response events.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-11T15:49:26.293169"}}
{"question": "Why would you use Lambda@Edge instead of API Gateway and AWS Lambda for global distribution of your application?", "answer": "You would use Lambda@Edge and Amazon CloudFront instead of API Gateway and AWS Lambda for global distribution if you want to execute logic across multiple AWS locations based on where your end viewers are located.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-11T15:49:26.293472"}}
{"question": "How does the triggering mechanism for Lambda@Edge differ from API Gateway and Lambda?", "answer": "In contrast to API Gateway and Lambda being regional services, Lambda@Edge and Amazon CloudFront allow you to execute logic across multiple AWS locations based on the location of your end viewers.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-26", "source_tokens": 466, "generated_at": "2026-02-11T15:49:26.293653"}}
{"question": "What is the default safety throttle limit for concurrent executions in an AWS Lambda account?", "answer": "The text passage does not provide the default safety throttle limit for concurrent executions in an AWS Lambda account.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-11T15:49:31.869467"}}
{"question": "How does AWS Lambda handle exceeding the maximum concurrent executions limit for synchronously and asynchronously invoked functions?", "answer": "AWS Lambda returns a throttling error (429 error code) for synchronously invoked functions when the maximum concurrent executions limit is exceeded. Asynchronously invoked functions can absorb reasonable bursts of traffic for approximately 15-30 minutes before incoming events are rejected as throttled.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-11T15:49:31.869832"}}
{"question": "What's the difference between the concurrency scaling limit for synchronously and asynchronously invoked AWS Lambda functions?", "answer": "Each synchronously invoked Lambda function can scale at a rate of up to 1000 concurrent executions every 10 seconds, while asynchronously invoked functions can absorb reasonable bursts of traffic for approximately 15-30 minutes before incoming events are rejected as throttled.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-27", "source_tokens": 490, "generated_at": "2026-02-11T15:49:31.870260"}}
{"question": "What happens when a Lambda function being invoked synchronously encounters a failure?", "answer": "The function responds with an exception.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-11T15:49:35.660931"}}
{"question": "Why is a dead letter queue (DLQ) used when the retry policy for asynchronous Lambda invocations is exceeded?", "answer": "The event is placed in the DLQ instead of being rejected.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-11T15:49:35.661227"}}
{"question": "How does access control for a Lambda function differ between using an IAM role and a resource policy on an Amazon SQS queue?", "answer": "Using an IAM role grants permissions to the Lambda function directly, while a resource policy on an Amazon SQS queue grants access to the queue itself.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-28", "source_tokens": 395, "generated_at": "2026-02-11T15:49:35.661648"}}
{"question": "What VPC resources can be specified for an AWS Lambda function to access?", "answer": "AWS Lambda functions can access VPC resources by specifying the subnet and security group as part of the function configuration.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-11T15:49:40.162367"}}
{"question": "How does AWS Signer help ensure the integrity of AWS Lambda code?", "answer": "AWS Signer is a fully-managed code signing service that enables you to digitally sign code artifacts and configure Lambda functions to verify the signatures at deployment, ensuring the integrity and trust of the code.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-11T15:49:40.162612"}}
{"question": "What are the differences between IPv4 and IPv6 for Lambda functions communicating with resources in a dual-stack VPC?", "answer": "By default, Lambda functions communicate with resources in a dual-stack VPC over IPv4. You can configure your functions to access resources over IPv6 as well.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-29", "source_tokens": 495, "generated_at": "2026-02-11T15:49:40.162970"}}
{"question": "What methods can be used to enable code signing for existing AWS Lambda functions?", "answer": "You can enable code signing for existing AWS Lambda functions using the AWS Lambda console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-11T15:49:45.737591"}}
{"question": "Why is it beneficial to use JSON structured logs for AWS Lambda functions?", "answer": "Using JSON structured logs for AWS Lambda functions simplifies the logging experience by making it easier to search, filter, and analyze large volumes of log entries. It also enables you to control the log level filtering without making any code changes and set which Amazon CloudWatch log group Lambda sends logs to.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-11T15:49:45.737896"}}
{"question": "How does using your own logging libraries for JSON structured logs in AWS Lambda compare to using Lambda's native logging controls?", "answer": "When using your own logging libraries for JSON structured logs in AWS Lambda, Lambda will not double-encode any logs generated by your function that are already JSON encoded. On the other hand, using Lambda's native logging controls simplifies the experience further by providing additional benefits like logging level filtering and setting the log group without making any code changes.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-30", "source_tokens": 469, "generated_at": "2026-02-11T15:49:45.738309"}}
{"question": "What is the cost for using advanced logging controls on AWS Lambda?", "answer": "There is no additional charge for using advanced logging controls on Lambda.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-11T15:49:50.915719"}}
{"question": "How does CloudWatch Application Signals help monitor the performance and health of AWS Lambda applications?", "answer": "CloudWatch Application Signals is an application performance monitoring solution that provides pre-built dashboards, service map, and more, to help developers and operators monitor the performance and health of serverless applications built with Lambda.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-11T15:49:50.922107"}}
{"question": "What's the difference between CloudWatch Application Signals and CloudWatch Logs Live Tail in terms of monitoring AWS Lambda applications?", "answer": "CloudWatch Application Signals is an application performance monitoring solution that provides pre-built dashboards, service map, and more, to monitor the performance and health of serverless applications built with Lambda, while CloudWatch Logs Live Tail is an interactive log streaming and analytics capability that provides real-time visibility into logs to help developers and operators detect and debug failures and critical errors in Lambda function code.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-31", "source_tokens": 453, "generated_at": "2026-02-11T15:49:50.922387"}}
{"question": "What tools can be used to compile a Lambda function written in Java?", "answer": "Standard tools like Maven or Gradle can be used to compile a Lambda function written in Java.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-11T15:49:55.325291"}}
{"question": "How can custom scripts be run in a Lambda function using Node.js?", "answer": "The child_process command in Node.js can be used to execute a binary that is included in the function or any executable from Amazon Linux that is visible to the function.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-11T15:49:55.325589"}}
{"question": "What are the different ways to deploy a Node.js Lambda function?", "answer": "A Node.js Lambda function can be deployed by packaging the JavaScript code and dependent libraries as a ZIP file, which can be uploaded from a local environment or specified as an Amazon S3 location. Alternatively, pip can be used to install any Python packages needed.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-32", "source_tokens": 481, "generated_at": "2026-02-11T15:49:55.325745"}}
{"question": "What type of file is used for deploying a PowerShell Lambda function?", "answer": "A PowerShell Lambda deployment package is a ZIP file.", "question_type": "factual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-11T15:49:59.895710"}}
{"question": "Why would you install the AWSLambdaPSCore PowerShell module for creating a PowerShell Lambda deployment package?", "answer": "You install the AWSLambdaPSCore PowerShell module from the PowerShell Gallery to help create your PowerShell Lambda deployment package.", "question_type": "conceptual", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-11T15:49:59.896113"}}
{"question": "How does deploying a PowerShell Lambda function using AWS Lambda compare to deploying a Go Lambda function?", "answer": "For PowerShell Lambda functions, you create a ZIP file containing your script, required modules, and assemblies, while for Go Lambda functions, you use AWS's native tools to build and package your code and upload it as a ZIP file.", "question_type": "comparison", "metadata": {"service": "LAMBDA", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lambda-faq-33", "source_tokens": 390, "generated_at": "2026-02-11T15:49:59.896566"}}
{"question": "What is Amazon Lex and what are its capabilities?", "answer": "Amazon Lex is a service for building conversational interfaces using voice and text. It provides high quality speech recognition and language understanding capabilities, enabling the addition of sophisticated 'chatbots' to new and existing applications. Lex reduces development effort by allowing easy publication to mobile devices and multiple chat services, and integrates with many other AWS services.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:50:05.418293"}}
{"question": "How does Amazon Lex help in building chatbots?", "answer": "Amazon Lex helps in building chatbots by offering high quality speech recognition and language understanding capabilities, reducing development effort by enabling easy publication to various platforms, and integrating with other AWS services like AWS Lambda, Amazon Cognito, and Amazon Polly.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:50:05.418787"}}
{"question": "What are the differences between self-service voice assistants and application/transactional bots in terms of Amazon Lex usage?", "answer": "Self-service voice assistants and chatbots built using Amazon Lex are used for call center automation, while informational bots answer questions. Application/transactional bots, on the other hand, are stand-alone agents like a pizza ordering agent or a travel bot.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:50:05.419052"}}
{"question": "Which AWS service is used for building conversational interfaces using voice and text?", "answer": "Amazon Lex", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:50:09.246484"}}
{"question": "How does a developer create actions for an Amazon Lex bot?", "answer": "A developer creates actions for an Amazon Lex bot by defining intents, adding sample utterances and slots, and providing business logic to execute the intended actions.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:50:09.246794"}}
{"question": "How does Amazon Lex compare to AWS Lambda when it comes to input validation?", "answer": "Amazon Lex provides the option of returning parsed intent and slots back to the client for business logic implementation, while AWS Lambda offers input validation through the initialization and validation codeHook, which gets executed at every turn of the conversation.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-1", "source_tokens": 499, "generated_at": "2026-02-11T15:50:09.246952"}}
{"question": "What information does Amazon Lex elicit from the user through slots?", "answer": "Amazon Lex elicits user information through slots. For example, it elicits show name and time for the make reservations intent.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-11T15:50:13.685150"}}
{"question": "How does Amazon Lex obtain user information for slot fulfillment?", "answer": "Amazon Lex obtains user information for slot fulfillment through the elicitation of prompts. For instance, it prompts the user to provide a show time for the reservation intent.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-11T15:50:13.685424"}}
{"question": "What's the difference between Amazon Lex bot's interaction with AWS Lambda for intent fulfillment versus returning parsed values to the client?", "answer": "Amazon Lex interacts with AWS Lambda for the execution of intent actions or business logic, whereas it returns parsed intent and slot values to the client for self-fulfilling intents.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-2", "source_tokens": 504, "generated_at": "2026-02-11T15:50:13.685790"}}
{"question": "Which locales are supported by Amazon Lex for automated chatbot design?", "answer": "English locales (US, UK, AU, IN, SA) are supported by Amazon Lex for automated chatbot design.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T15:50:19.188339"}}
{"question": "How does the process of creating and testing a new version of an Amazon Lex bot work?", "answer": "Creating a new version of an Amazon Lex bot triggers machine learning and creates the models for your bot. Once created, a version is immutable. You can test the bot via the test window on the console, including any business logic implemented in AWS Lambda. All supported browsers allow for testing text with your Amazon Lex bot, and voice can be tested from a Chrome browser.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T15:50:19.188624"}}
{"question": "Is it possible to deploy different versions of an Amazon Lex bot to different messaging services, and if so, how?", "answer": "Yes, you can deploy a specific version of your Amazon Lex bot to each messaging service. Each version has an ARN and can be associated with a different alias. You can use different aliases for deployment to different messaging services, and you can also have multiple bots deployed to the same messaging service.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-3", "source_tokens": 486, "generated_at": "2026-02-11T15:50:19.189011"}}
{"question": "Which languages are currently supported by Amazon Lex?", "answer": "Amazon Lex supports US English, Spanish, French, German, Italian, Japanese, Australian English, British English, Canadian French, Latin American Spanish, and US Spanish.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-11T15:50:23.779152"}}
{"question": "How does the conversation experience differ between request and response interaction and streaming conversation in Amazon Lex?", "answer": "In a request and response interaction, each user input is processed as a separate API call, while in a streaming conversation, all user inputs across multiple turns are processed in one streaming API call. With streaming conversation, the bot continuously listens and can be designed to respond proactively to user interruptions and pauses.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-11T15:50:23.779433"}}
{"question": "What is the difference in audio formats supported by Amazon Lex for input and output?", "answer": "Amazon Lex supports LPCM and Opus for input audio formats and MPEG, OGG, and PCM for output audio formats.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-4", "source_tokens": 483, "generated_at": "2026-02-11T15:50:23.779801"}}
{"question": "Which languages and regions does Amazon Lex V2 support?", "answer": "Amazon Lex V2 supports US English, Spanish, French, German, Italian, Japanese, Australian English, British English, Canadian French, Latin American Spanish, and US Spanish in the following regions: US, Europe (Frankfurt), Asia Pacific (Tokyo), Asia Pacific (Sydney), South America (SÃ£o Paulo), and Europe (Ireland).", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-11T15:50:28.958274"}}
{"question": "What are the advantages of using Amazon Lex V2 instead of V1?", "answer": "Amazon Lex V2 offers new features and improvements, such as access to the enhanced console experience and the V2 APIs. To migrate from V1 to V2, follow the provided migration guide.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-11T15:50:28.958703"}}
{"question": "How does Amazon Lex V2 compare to Alexa Skills Kit for building bots?", "answer": "Amazon Lex V2 is a bot service that supports both voice and text and can be deployed across mobile and messaging platforms. In contrast, Alexa Skills Kit (ASK) is used to build skills for the Alexa ecosystem and devices, which offers capabilities such as Smart Home and Flash Briefing APIs, streaming audio, and rich GUI experiences.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-5", "source_tokens": 422, "generated_at": "2026-02-11T15:50:28.959018"}}
{"question": "What information can be exported from Amazon Lex as a JSON file?", "answer": "Amazon Lex allows you to export your bot schema into a JSON file.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T15:50:33.308812"}}
{"question": "How can you use the exported Amazon Lex bot schema with Alexa?", "answer": "To use the exported Amazon Lex bot schema with Alexa, you need to log in to the Alexa developer portal, navigate to the â€˜Interaction Modelâ€™ tab, launch the Alexa Skill Builder, and paste the bot schema into the Code Editor of your Alexa Skill.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T15:50:33.309092"}}
{"question": "Can you use Amazon Lex with various Alexa-enabled devices?", "answer": "Yes, you can use Amazon Lex with the Amazon Echo, Amazon Dot, Amazon Look, Amazon Tap, Amazon Echo Show, and any third-party Alexa-enabled devices.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T15:50:33.309269"}}
{"question": "What encryption methods does Amazon Lex use for storing content at rest and in transit?", "answer": "Amazon Lex encrypts content at rest in the AWS region where it is being used and in transit as well.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-11T15:50:37.734739"}}
{"question": "How does Amazon Lex ensure the security and privacy of user content?", "answer": "Amazon Lex ensures user content security and privacy through encryption at rest and in transit, as well as appropriate and sophisticated technical and physical controls.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-11T15:50:37.735024"}}
{"question": "What is the difference between the storage of content processed by Amazon Lex in the same region versus another region?", "answer": "Content processed by Amazon Lex is encrypted and stored at rest in the same region where it is being used. However, some portion of it may also be stored in another AWS region solely for continuous improvement and development of Amazon Lex and other machine-learning/artificial-intelligence technologies.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-7", "source_tokens": 443, "generated_at": "2026-02-11T15:50:37.735396"}}
{"question": "What resource should I refer to for COPPA requirements and guidance?", "answer": "The United States Federal Trade Commission provides the necessary resources and guidance for COPPA requirements and determination of applicability for websites, programs, or applications.", "question_type": "factual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:50:42.001371"}}
{"question": "How can I build bots using Amazon Lex and which programming languages are supported?", "answer": "Amazon Lex supports building bots using Java, JavaScript, Python, CLI, .Net, Ruby, PHP, Go, and CPP for both text and speech input.", "question_type": "conceptual", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:50:42.001616"}}
{"question": "How does the billing work for Amazon Lex and what's the difference between text and speech requests?", "answer": "Every input to an Amazon Lex bot is considered a request. There are no differences in billing between text and speech requests, but each one is counted as an individual request.", "question_type": "comparison", "metadata": {"service": "LEX", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lex-faq-8", "source_tokens": 510, "generated_at": "2026-02-11T15:50:42.001808"}}
{"question": "What are managed entitlements in AWS License Manager?", "answer": "Managed entitlements is a feature in AWS License Manager that allows organizations to centrally manage software licenses.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-11T15:50:46.251708"}}
{"question": "How does managed entitlements work in AWS License Manager?", "answer": "Managed entitlements in AWS License Manager enable organizations to assign, manage, and retire software licenses for their users. This helps ensure compliance with software licensing agreements.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-11T15:50:46.252033"}}
{"question": "What is the difference between managed entitlements and user-based license subscriptions in AWS License Manager?", "answer": "Managed entitlements and user-based license subscriptions are two different licensing models in AWS License Manager. Managed entitlements allow organizations to centrally manage software licenses, while user-based license subscriptions allow users to access software licenses based on their specific subscription.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-0", "source_tokens": 81, "generated_at": "2026-02-11T15:50:46.252181"}}
{"question": "What is the first step in using AWS License Manager?", "answer": "The first step in using AWS License Manager is to define licensing rules.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-11T15:50:50.145236"}}
{"question": "How does License Manager help manage software usage?", "answer": "License Manager helps manage software usage by integrating with AWS Systems Manager to discover software installed on AWS resources and on-premises servers. Administrators can then apply licensing rules to the discovered software and track usage through the built-in dashboard.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-11T15:50:50.145605"}}
{"question": "How does the enforcing of licensing rules differ between EC2 instances and applications in the AWS Service Catalog?", "answer": "Licensing rules can be enforced on EC2 instances by attaching them to specific Amazon Machine Images (AMIs) or launch templates. For applications in the AWS ServiceCatalog, rules are attached at the portfolio or registration level.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-1", "source_tokens": 453, "generated_at": "2026-02-11T15:50:50.145765"}}
{"question": "What instances can you onboard to AWS License Manager for Linux subscriptions discovery?", "answer": "You can onboard instances with Red Hat Enterprise Linux (RHEL), SUSE Linux Enterprise Server (SLES), and Ubuntu Pro for subscriptions discovery using AWS License Manager.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-11T15:50:54.060365"}}
{"question": "How does AWS License Manager discover Linux subscriptions without requiring AWS Systems Manager?", "answer": "AWS License Manager discovers Linux subscriptions via instance metadata.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-11T15:50:54.060588"}}
{"question": "How does using AWS License Manager for Linux subscriptions with Red Hat Subscription Manager (RHSM) compare to using it without RHSM?", "answer": "With RHSM, you can get detailed information on RHEL use and see when an instance has more than one subscription defined.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-2", "source_tokens": 124, "generated_at": "2026-02-11T15:50:54.060947"}}
{"question": "What software can be tracked with AWS License Manager based on which resource?", "answer": "AWS License Manager can track software that is licensed based on virtual cores (vCPUs), physical cores, sockets, or number of instances.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-11T15:50:58.248327"}}
{"question": "How can AWS License Manager be used to manage licenses for Oracle databases?", "answer": "AWS License Manager can be used to track licenses and subscriptions for Oracle databases, including Oracle database engine editions, options, and packs, on Amazon RDS.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-11T15:50:58.248620"}}
{"question": "What is the difference between tracking licenses for IBM DB2 workloads on AWS RDS with and without AWS License Manager?", "answer": "Without AWS License Manager, you would need to manage and track licenses for IBM DB2 workloads on AWS RDS separately. With AWS License Manager, you can associate licensing rules to AWS Marketplace BYOL AMI products and benefit from centralized license management tracking and compliance.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-3", "source_tokens": 416, "generated_at": "2026-02-11T15:50:58.248819"}}
{"question": "What is the primary function of AWS License Manager?", "answer": "AWS License Manager reduces the risk of non-compliance by increasing transparency, enforcing and tracking licensing rules, and providing built-in dashboards for reporting and vendor audits.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-11T15:51:02.862218"}}
{"question": "How can you manage licenses for software purchased in AWS Marketplace?", "answer": "You can track and manage licenses for software purchased in AWS Marketplace using AWS License Manager's managed entitlements. You can also distribute licenses to different groups of users and integrate with other AWS services and IAM for access control.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-11T15:51:02.862441"}}
{"question": "How does using AWS License Manager impact license management for ISV software across multiple AWS accounts and on-premises environments?", "answer": "Using AWS License Manager, you can pay for and manage distribution and track entitlements for ISV software licenses across both AWS Cloud accounts and on-premises environments.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-4", "source_tokens": 410, "generated_at": "2026-02-11T15:51:02.862664"}}
{"question": "What is required to onboard directly through AWS License Manager?", "answer": "You can onboard directly through AWS License Manager by creating a public and private key pair and modifying your software to call the API operations. License information is signed with your private key and verified with the public key.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T15:51:07.712689"}}
{"question": "How does AWS License Manager help you manage licenses?", "answer": "AWS License Manager helps you manage licenses by enforcing license use, tracking usage across all customer identities, and allowing you to integrate with your sales order system to create and update licenses.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T15:51:07.713034"}}
{"question": "What's the difference between using a short-lived token for license activation and generating a license file for on-premises workloads?", "answer": "Customers can use a short-lived token for license activation by entering it to activate the license, while for on-premises workloads without an internet connection, you can generate a license file unique to the host for the customer to use.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T15:51:07.713516"}}
{"question": "What is required to get started with AWS License Manager for tag-based search and automation?", "answer": "To get started with AWS License Manager for tag-based search and automation, you need to follow these steps: Configure AWS Directory Service for Microsoft Active Directory, subscribe to a product in AWS Marketplace or the EC2 Console, launch an instance, associate users to an instance, and connect to a user-based subscription instance.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-11T15:51:12.941375"}}
{"question": "Why is having a tagging strategy important in AWS?", "answer": "Having a tagging strategy in AWS is important because it helps you organize your resources, allocate cost, automate processes, control access, and manage security risk.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-11T15:51:12.941712"}}
{"question": "How does AWS License Manager's automated discovery and tag-based search work together?", "answer": "AWS License Manager's automated discovery helps you track all instances running software that is specified in discovery rules, while tag-based search allows you to search for instances based on tags. Combining these features allows you to automate the process of tracking and managing license usage for specific software instances.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-6", "source_tokens": 431, "generated_at": "2026-02-11T15:51:12.942213"}}
{"question": "What is the billing structure for AWS services like Microsoft Office and Visual Studio?", "answer": "AWS bills you monthly based on the number of users associated with the license for Microsoft Office or Visual Studio instances.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-11T15:51:17.958885"}}
{"question": "How does AWS handle user billing for these services and why is it important to note the number of EC2 instances a user connects to?", "answer": "You are charged per user for Microsoft Office and Visual Studio, and a user is only counted once, regardless of the number of EC2 instances they connect to. However, it's essential to note this because Windows Server licenses are bundled with the EC2 instances and charged per vCPU alongside the instance charges.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-11T15:51:17.959246"}}
{"question": "What is the difference between how AWS bills for Microsoft Office, Visual Studio, and Windows Server licenses?", "answer": "Microsoft Office and Visual Studio are billed based on the number of users, while Windows Server licenses are bundled with the EC2 instances and charged per vCPU along with the instance charges.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-7", "source_tokens": 481, "generated_at": "2026-02-11T15:51:17.959716"}}
{"question": "What can you see about Linux subscriptions in the subscriptions view?", "answer": "You can see usage over time and create alarms based on thresholds in the subscriptions view.", "question_type": "factual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-11T15:51:22.510830"}}
{"question": "How do you convert the license type of Ubuntu LTS instances?", "answer": "You can use either the License Manager Console or the AWS CLI to convert the license type of eligible Ubuntu LTS instances. Instances must be stopped and associated by AWS Systems Manager Inventory.", "question_type": "conceptual", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-11T15:51:22.511219"}}
{"question": "What resources are included in the charges for using License Manager?", "answer": "You pay for only the resources created in your account, which can include Amazon Elastic Compute Cloud (EC2) instances, an Amazon Simple Storage Service (S3) bucket for storing software based on AWS Systems Manager, Amazon Athena queries, AWS Glue jobs, and Amazon Simple Notification Service (SNS) notifications.", "question_type": "comparison", "metadata": {"service": "LICENSE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "license-faq-8", "source_tokens": 241, "generated_at": "2026-02-11T15:51:22.511717"}}
{"question": "What does Amazon Lookout for Equipment do with the data from customers' sensors?", "answer": "Amazon Lookout for Equipment uses the data from customers' sensors to detect abnormal equipment behavior and alert to potential issues before machine failures occur.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:51:27.792569"}}
{"question": "How does Amazon Lookout for Equipment differ from previous methods of analyzing data from industrial equipment?", "answer": "Amazon Lookout for Equipment benefits customers by removing the complexities of data science, providing fast proof of concepts, and offering cost effectiveness, accuracy, and scale compared to previous methods of analyzing data from industrial equipment which often lead to too many alerts or an overgeneralized model that does not adapt to the unique operating conditions of each piece of equipment.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:51:27.792929"}}
{"question": "What are the key benefits of using Amazon Lookout for Equipment for machine learning on industrial equipment data?", "answer": "Amazon Lookout for Equipment offers ease of use, fast proof of concepts, cost effectiveness, accuracy, and scale for customers who have their own sensors generating data on industrial equipment and want to build custom models to detect abnormal behavior such as failure patterns or inefficient processes.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 458, "generated_at": "2026-02-11T15:51:27.793581"}}
{"question": "What type of data does Lookout for Equipment work with?", "answer": "Lookout for Equipment works with time series analog data, which can include temperature, flow rates, rpms from components including sensors and actuators.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-11T15:51:31.132213"}}
{"question": "How does Lookout for Equipment handle model training?", "answer": "Unlike other machine learning tools, Lookout for Equipment builds a custom model on every data set it is given, learning the normal operating behavior specific to the equipment and its unique operating environment.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-11T15:51:31.132584"}}
{"question": "How does the number of sensors affect Lookout for Equipment's performance?", "answer": "Lookout for Equipment can work with up to 300 sensors (tags) for one model.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 458, "generated_at": "2026-02-11T15:51:31.132969"}}
{"question": "What region(s) is Lookout for Equipment available in?", "answer": "Lookout for Equipment is available in US East (N. Virginia), EU (Ireland), and Asia Pacific (Seoul)", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-11T15:51:36.441227"}}
{"question": "What types of equipment is Lookout for Equipment designed for?", "answer": "Lookout for Equipment is designed for industrial process equipment that operate continuously and with low variability in operating conditions, such as compressors, pumps, motors, turbines, and boilers. It may not be effective on highly variable equipment like construction equipment, vehicles, robots, and CNC machines", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-11T15:51:36.441573"}}
{"question": "How does Lookout for Equipment compare in detecting issues between a compressor and a wind turbine?", "answer": "Both compressors and wind turbines can benefit from real-time abnormal state detection provided by Lookout for Equipment. However, since the operating conditions of a compressor in a pipeline and a wind turbine vary, the effectiveness and approach to detecting issues may differ. For a compressor, Lookout for Equipment can predict failure, while for a wind turbine, it can detect critical issues", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 276, "generated_at": "2026-02-11T15:51:36.441792"}}
{"question": "What type of data is required for Amazon Lookout for Equipment?", "answer": "Time series data generated from industrial assets such as pumps, compressors, motors, etc. Each asset should be generating data from sensors (tags) that are representative of the condition and operation of the asset.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-11T15:51:41.131178"}}
{"question": "Why is it important to choose the right input data for Amazon Lookout for Equipment?", "answer": "Choosing the right input data is crucial to the success of using Amazon Lookout for Equipment as it ensures the data is relevant to the equipment issues. too few inputs may result in missing critical information, while too many might have less of an impact on the detection.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-11T15:51:41.131553"}}
{"question": "How does the number of inputs affect the performance of Amazon Lookout for Equipment?", "answer": "Amazon Lookout for Equipment works with up to 300 inputs. Too few inputs may result in missing critical information, while too many might have less of an impact on the detection.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 251, "generated_at": "2026-02-11T15:51:41.131768"}}
{"question": "What region is the encrypted content, processed by Amazon Lookout for Equipment, stored at rest?", "answer": "The encrypted content, processed by Amazon Lookout for Equipment, is stored at rest in the AWS region where you are using Amazon Lookout for Equipment.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T15:51:46.356913"}}
{"question": "How does Amazon ensure the security of content used by Amazon Lookout for Equipment?", "answer": "Amazon implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that their use complies with their commitments to you.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T15:51:46.357272"}}
{"question": "Is there a difference in storage location for content processed by Amazon Lookout for Equipment between an opt-in and opt-out account?", "answer": "If you opt in to having your content used to improve and develop the quality of Amazon Lookout for Equipment and other Amazon machine-learning/artificial-intelligence technologies, some portion of your content may be stored in another AWS region. If you opt out, your content will not be stored in another AWS region.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 503, "generated_at": "2026-02-11T15:51:46.357757"}}
{"question": "What is required to access the Amazon Lookout for Equipment pricing?", "answer": "Visiting the Amazon Lookout for Equipment pricing page is necessary to access the information.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-11T15:51:49.499215"}}
{"question": "How can one start using Amazon Lookout for Equipment?", "answer": "By getting started in the AWS Management Console, users can begin building with Amazon Lookout for Equipment.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-11T15:51:49.499701"}}
{"question": "Is there a free tier available for Amazon Lookout for Equipment?", "answer": "Yes, instant access to the AWS Free Tier is provided when visiting the Amazon Lookout for Equipment pricing page.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 42, "generated_at": "2026-02-11T15:51:49.500004"}}
{"question": "What machine learning algorithm does Amazon Lookout for Metrics use for anomaly detection?", "answer": "Amazon Lookout for Metrics uses a collection of machine learning algorithms for anomaly detection. It inspects the data and applies the right ML algorithm to the right data to detect anomalies accurately.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T15:51:54.174222"}}
{"question": "How does Amazon Lookout for Metrics help customers get started with anomaly detection?", "answer": "Amazon Lookout for Metrics helps customers get started with anomaly detection by allowing them to provide historical data for training the models or learn as it goes if they donâ€™t have historical data.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T15:51:54.174579"}}
{"question": "How does Amazon Lookout for Metrics compare to other anomaly detection solutions in terms of requiring historical data?", "answer": "Amazon Lookout for Metrics can learn and detect anomalies even if customers donâ€™t have historical data. Some other anomaly detection solutions might require historical data for effective performance.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T15:51:54.174979"}}
{"question": "When does AWS stop providing access to Lookout for Vision for new customers?", "answer": "October 10, 2024", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-11T15:52:24.008264"}}
{"question": "Why can't cloud applications access Lookout for Vision after October 31, 2025?", "answer": "Because the Lookout for Vision cloud service will no longer be available.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-11T15:52:24.008648"}}
{"question": "What are some alternatives to Lookout for Vision that AWS offers?", "answer": "Amazon SageMaker and Amazon Bedrock are two options. Amazon SageMaker offers pre-trained models and Amazon Bedrock may support the use case.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-0", "source_tokens": 476, "generated_at": "2026-02-11T15:52:24.009168"}}
{"question": "What will happen to the images stored in S3 that are used with Lookout for Vision after the service is discontinued?", "answer": "The images stored in S3 for import into Lookout for Vision will not be impacted and will remain after the Lookout for Vision service is discontinued.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:52:28.463469"}}
{"question": "How does Amazon Lookout for Vision help in industrial quality control and operational cost reduction?", "answer": "Amazon Lookout for Vision is a machine learning service that helps increase industrial production quality and reduce operational costs by identifying visual defects in objects. It allows for automation of quality inspection processes in manufacturing lines.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:52:28.463947"}}
{"question": "How does Amazon Lookout for Vision compare to manual inspection for product defect detection?", "answer": "Amazon Lookout for Vision uses computer vision to automate quality inspection processes and spot product defects at scale, decreasing dependency on manual inspection.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-1", "source_tokens": 430, "generated_at": "2026-02-11T15:52:28.464273"}}
{"question": "How many images are required to train an anomaly detection model with Amazon Lookout for Vision?", "answer": "The number of images required to train an anomaly detection model with Amazon Lookout for Vision depends on the variability in the production line and the quality of the training data. Fewer images may be needed for simple use cases with constant lighting, zoom level, focus, and alignment, while more complex use cases may require hundreds of training examples with high quality annotations.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-11T15:52:35.005117"}}
{"question": "What are the benefits of using Amazon Lookout for Vision for anomaly detection instead of building a deep learning pipeline?", "answer": "Amazon Lookout for Vision is a fully managed service that comes with anomaly detection techniques for defect detection tasks, allowing you to focus on maximizing business value without investing time and resources on creating a deep learning pipeline. It continues to improve the accuracy of its models by building on the latest research and sourcing new training data.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-11T15:52:35.005355"}}
{"question": "How does the image quality and variability in production affect the number of images needed to train an anomaly detection model with Amazon Lookout for Vision?", "answer": "The image quality and variability in production can significantly impact the number of images needed to train an anomaly detection model with Amazon Lookout for Vision. Simple use cases with constant lighting, zoom level, focus, and alignment may only require a few dozen images, while more complex use cases with many variations may require hundreds of high-quality training examples.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-2", "source_tokens": 495, "generated_at": "2026-02-11T15:52:35.005747"}}
{"question": "What charges will I incur if my training fails in Amazon Lookout for Vision?", "answer": "You will not be charged for the compute resources if your training fails.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:52:38.654348"}}
{"question": "Why is it important to monitor the provisioning of Amazon Lookout for Vision model?", "answer": "Monitoring the frequency at which you need to provision your model and the number of images that need to be processed at a single time helps you schedule provisioning most efficiently.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:52:38.654758"}}
{"question": "How does the size of an image and complexity of the defect detection model impact the throughput of a single Amazon Lookout for Vision compute resource?", "answer": "The size of the images and the complexity of the defect detection model are factors that influence the throughput of a single Amazon Lookout for Vision compute resource.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-3", "source_tokens": 424, "generated_at": "2026-02-11T15:52:38.655445"}}
{"question": "Which hardware devices can you deploy Amazon Lookout for Vision models on using AWS IoT Greengrass?", "answer": "Amazon Lookout for Vision models can be deployed on any NVIDIA Jetson edge appliance or x86 compute platform running Linux with an NVIDIA GPU accelerator.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-11T15:52:43.674962"}}
{"question": "How does the pricing model for Amazon Lookout for Vision work?", "answer": "Amazon Lookout for Vision charges for the CreateModel API for training operation and for the elapsed minutes between the StartModel API and the StopModel API usage. The charges are based on the duration of training and inference minutes.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-11T15:52:43.675319"}}
{"question": "How does deploying Amazon Lookout for Vision models on a hardware device using AWS IoT Greengrass compare to running the models in the cloud?", "answer": "The main difference is that when deploying models on a hardware device, you will only be charged when the model is actively being used to detect anomalies, whereas in the cloud, you pay for both the training and inference minutes.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-4", "source_tokens": 456, "generated_at": "2026-02-11T15:52:43.675834"}}
{"question": "What region is the encrypted content processed by Amazon Lookout for Vision stored at rest?", "answer": "The encrypted content processed by Amazon Lookout for Vision is stored at rest in the AWS region where you are using Amazon Lookout for Vision.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:52:48.136527"}}
{"question": "Why is content processed by Amazon Lookout for Vision encrypted and stored?", "answer": "Content processed by Amazon Lookout for Vision is encrypted and stored to prevent unauthorized access to, or disclosure of, your content and ensure that Amazon's use complies with their commitments to you.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:52:48.136885"}}
{"question": "How does Amazon handle content stored in another AWS region when I opt out of content improvement?", "answer": "If you opt out of having your content used to develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies, your content will not be stored in another AWS region.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-5", "source_tokens": 508, "generated_at": "2026-02-11T15:52:48.137273"}}
{"question": "What is required to access the AWS Free Tier?", "answer": "No specific action is mentioned in the context for accessing the AWS Free Tier.", "question_type": "factual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-11T15:52:51.326065"}}
{"question": "How does one get started with Amazon Lookout for Vision in the AWS Management Console?", "answer": "The context states that one can get started with Amazon Lookout for Vision in the AWS Management Console.", "question_type": "conceptual", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-11T15:52:51.326556"}}
{"question": "How does the AWS Free Tier differ from getting started with Amazon Lookout for Vision in the AWS Management Console?", "answer": "The context does not provide enough information to make this comparison.", "question_type": "comparison", "metadata": {"service": "LOOKOUT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "lookout-faq-6", "source_tokens": 30, "generated_at": "2026-02-11T15:52:51.326724"}}
{"question": "What does Amazon Macie do for data security in AWS?", "answer": "Amazon Macie is a data security service that discovers sensitive data using machine learning and pattern matching, provides visibility into data security risks, and enables automated protection against those risks.", "question_type": "factual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:52:55.520726"}}
{"question": "How does Macie simplify the setup process for users?", "answer": "Macie's setup is simplified with one selection in the AWS Management Console or a single API call.", "question_type": "conceptual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:52:55.521087"}}
{"question": "What are the dimensions on which we are charged for Macie?", "answer": "We are charged based on three dimensions: the number of S3 buckets evaluated for bucket inventory and monitoring, the number of S3 objects monitored for automated data discovery, and the quantity of data inspected for automated and targeted sensitive data discovery.", "question_type": "comparison", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-0", "source_tokens": 482, "generated_at": "2026-02-11T15:52:55.521563"}}
{"question": "What is required to enable Macie in one account or across all accounts within AWS Organizations?", "answer": "Macie can be enabled with one selection in the AWS Management Console or a single API call. For multi-account support, Macie can be enabled across all accounts using AWS Organizations with a few selections.", "question_type": "factual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:52:59.953008"}}
{"question": "How can you customize Macie to discover specific sensitive data for your business?", "answer": "You can add custom-defined data types using regular expressions to help Macie discover proprietary or unique sensitive data for your business.", "question_type": "conceptual", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:52:59.953374"}}
{"question": "How does the Macie free trial period compare to the regular pricing?", "answer": "There is a 30-day free trial for all new and existing accounts to try automated sensitive data discovery. After the free trial, refer to the Macie pricing page for cost estimates.", "question_type": "comparison", "metadata": {"service": "MACIE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "macie-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:52:59.953791"}}
{"question": "What is Amazon Managed Grafana and how does it integrate with data sources?", "answer": "Amazon Managed Grafana is a fully managed multicloud, cross-project service that helps analyze, monitor, and alarm on metrics, logs, and traces across multiple data sources. It integrates with data sources by allowing users to create workspaces, which can then be used to query and visualize metrics from these data sources.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:53:05.236947"}}
{"question": "How does the pricing model for Amazon Managed Grafana differ from the open source Grafana project?", "answer": "Amazon Managed Grafana is a fully managed service with pricing, while the open source Grafana project is free. However, users are responsible for managing the underlying infrastructure and costs associated with the data sources they connect to in the open source project.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:53:05.237297"}}
{"question": "What is the difference between creating a new workspace and integrating a data source in Amazon Managed Grafana?", "answer": "Creating a new workspace involves setting up a logically isolated Grafana server, while integrating a data source allows the workspace to query and visualize metrics from that data source.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 413, "generated_at": "2026-02-11T15:53:05.237450"}}
{"question": "What AWS services does Amazon Managed Grafana integrate with for discovery and read-only access?", "answer": "Amazon Managed Grafana integrates with AWS Organizations, AWS CloudFormation StackSets, Amazon Managed Service for Prometheus, Amazon CloudWatch, and supports the installation of Grafana community plugins for other cloud providers and self-managed data sources.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-11T15:53:12.622938"}}
{"question": "How does Amazon Managed Grafana enable access to enterprise data sources?", "answer": "By upgrading a workspace to Amazon Managed Grafana Enterprise, you gain access to Enterprise plugins, enabling you to query and visualize data from AppDynamics, Atlassian Jira, Datadog, Dynatrace, Gitlab, Honeycomb, MongoDB, New Relic, Oracle Database, Salesforce, SAP HANA, ServiceNow, VMware Tanzu Observability by Wavefront, and Snowflake.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-11T15:53:12.623301"}}
{"question": "What's the difference between Amazon Managed Grafana and Amazon Managed Grafana Enterprise in terms of supported data sources?", "answer": "Amazon Managed Grafana comes with core plugins to connect to commonly used data sources and supports the installation of community plugins. Amazon Managed Grafana Enterprise, on the other hand, offers additional capabilities by providing access to enterprise data source plugins, enabling you to query and visualize data from various services such as AppDynamics, Atlassian Jira, Datadog, Dynatrace, Gitlab, Honeycomb, MongoDB, New Relic, Oracle Database, Salesforce, SAP HANA, ServiceNow, VMware Tanzu Observability by Wavefront, and Snowflake.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 406, "generated_at": "2026-02-11T15:53:12.623754"}}
{"question": "What AWS service can be used to manage Amazon Managed Grafana workspaces and configure SAML authentication settings?", "answer": "AWS CloudFormation", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T15:53:17.498949"}}
{"question": "How does one manage the permissions of different user types in Amazon Managed Grafana?", "answer": "Administrators have add, edit, and delete permissions to manage data sources, users, teams, folders, and dashboards. Editors have view, add, edit, and delete permissions to dashboards and alerts. Viewers can only view dashboards.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T15:53:17.499443"}}
{"question": "How does Amazon Managed Grafana in AWS compare to Grafana self-managed in terms of supported data sources?", "answer": "Amazon Managed Grafana in AWS supports native integrations for multiple AWS Services and also allows the installation of Grafana community plugins for other cloud providers and self-managed data sources. Self-managed Grafana supports a variety of data sources as well, but it does not come with the AWS native integrations.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T15:53:17.499671"}}
{"question": "What type of groups can be used in Amazon Managed Grafana for organizing users?", "answer": "Teams are used in Amazon Managed Grafana for organizing users.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-11T15:53:21.257479"}}
{"question": "How does Amazon Managed Grafana allow you to manage teams and user identities?", "answer": "Amazon Managed Grafana allows you to keep team membership and user identities in sync with your Identity Provider's user directories using Team Sync.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-11T15:53:21.257839"}}
{"question": "Can Amazon Managed Grafana connect to data sources from different accounts or regions?", "answer": "Yes, Amazon Managed Grafana can connect to data sources from different accounts or regions by using VPC peering or AWS Transit Gateway, and then connecting to the VPC endpoint in the same account and region as the Amazon Managed Grafana workspace.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 441, "generated_at": "2026-02-11T15:53:21.258064"}}
{"question": "What must requests to public data sources do when configuring a VPC connection in Amazon Managed Grafana?", "answer": "Requests to public data sources must traverse your VPC.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T15:53:26.398052"}}
{"question": "How does configuring a VPC connection in Amazon Managed Grafana impact previously connected data sources?", "answer": "If your workspace was previously connected to data sources prior to configuring a VPC endpoint, ensure that the VPC is able to reach the previously connected data sources as all traffic will now route through the VPC connection.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T15:53:26.398411"}}
{"question": "What are the differences between open access and restricted access modes for user and host access in Amazon Managed Grafana workspaces?", "answer": "The open access mode is the default access setting and allows users to access the workspace URL without VPC endpoint or managed prefix list restrictions. Users must still authenticate with the configured identity provider(s). The restricted access mode enables you to specify the inbound network traffic that is allowed to reach the workspace. You can configure prefix lists and create VPC endpoints to help restrict access.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 478, "generated_at": "2026-02-11T15:53:26.398812"}}
{"question": "How many plugins can be installed in an Amazon Managed Grafana workspace?", "answer": "Up to 50 data source, app, or visualization panel plugins can be installed in an Amazon Managed Grafana workspace, in addition to the core plugins.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-11T15:53:30.849246"}}
{"question": "What are the differences between API keys and Service accounts in Amazon Managed Grafana?", "answer": "API keys are strings that act as passwords for authentication, while Service accounts use generated random strings called Service Account Tokens. API keys are on the deprecation path and may be fully removed in future Grafana releases.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-11T15:53:30.849608"}}
{"question": "Why is there a difference in pricing between Editor and Viewer users in Amazon Managed Grafana?", "answer": "Editor users are assigned Administrator or Editor roles and are subject to a higher pricing tier than Viewer users, who are only assigned Viewer roles.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 501, "generated_at": "2026-02-11T15:53:30.850082"}}
{"question": "What type of API requests are free when working with an Amazon Managed Grafana workspace?", "answer": "Amazon Managed Grafana APIs that are used to create, edit, and delete workspaces are free.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T15:53:35.392295"}}
{"question": "How does billing work for multiple workspaces in Amazon Managed Grafana?", "answer": "Users are billed per workspace per month. If a user belongs to multiple workspaces, they will be billed separately for each workspace.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T15:53:35.392654"}}
{"question": "What is the difference between billed and unbilled API requests in Amazon Managed Grafana?", "answer": "Amazon Managed Grafana APIs for creating, editing, and deleting workspaces do not incur charges. Grafana HTTP API requests for managing workspace resources and Amazon Managed Grafana data queries made to other AWS Services or third-party ISVs do incur charges.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 498, "generated_at": "2026-02-11T15:53:35.393127"}}
{"question": "What allows manual control over Grafana workspace versioning?", "answer": "Manual control over Grafana workspace versioning is a feature that lets users validate their Grafana experience against new versions of Grafana before upgrading production workspaces.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-11T15:53:40.464239"}}
{"question": "Why is manual control over Grafana workspace versioning important?", "answer": "Manual control over Grafana workspace versioning is important because new versions of Grafana may introduce breaking changes that can impact visualizations or automation workflows. By allowing users to validate their experience against new versions before upgrading production workspaces, they can prevent potential issues.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-11T15:53:40.464601"}}
{"question": "How does manual control over Grafana workspace versioning compare to automatic upgrades?", "answer": "Manual control over Grafana workspace versioning allows users to validate their experience against new versions of Grafana before upgrading production workspaces, providing the ability to prevent potential issues caused by breaking changes. Automatic upgrades, on the other hand, do not offer this level of control and can result in the immediate implementation of new versions, potentially causing issues if there are breaking changes.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 55, "generated_at": "2026-02-11T15:53:40.465253"}}
{"question": "What is Amazon Managed Service for Apache Flink and how does it simplify building and managing Apache Flink applications?", "answer": "Amazon Managed Service for Apache Flink is a fully managed service offered by AWS that allows users to transform and analyze real-time streaming data using Apache Flink. It simplifies building and managing Apache Flink applications by taking care of everything required to continuously run streaming applications and automatically scaling resources to match incoming data volume and throughput. With Amazon Managed Service for Apache Flink, there are no servers to manage, no minimum fees or setup costs, and users only pay for the resources their applications consume.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-11T15:53:47.878209"}}
{"question": "What are some real-time data sources that Amazon Managed Service for Apache Flink can help companies ingest and analyze?", "answer": "Amazon Managed Service for Apache Flink can help companies ingest and analyze real-time data from various sources, including log data from mobile and web applications, purchase data from ecommerce platforms, and sensor data from IoT devices.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-11T15:53:47.878575"}}
{"question": "How does Amazon Managed Service for Apache Flink compare to traditional methods of handling real-time data processing and analysis?", "answer": "Amazon Managed Service for Apache Flink differs from traditional methods of handling real-time data processing and analysis in several ways. It is a fully managed service that simplifies the process of building, managing, and integrating Apache Flink applications with other AWS services. It also automatically scales resources to match the volume and throughput of incoming data, reducing the need for manual management. Additionally, using Amazon Managed Service for Apache Flink eliminates the need for servers, minimum fees, and setup costs, and users only pay for the resources consumed by their applications.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 343, "generated_at": "2026-02-11T15:53:47.878990"}}
{"question": "What is the primary use case for Amazon Managed Service for Apache Flink in the context of stream processing applications?", "answer": "Amazon Managed Service for Apache Flink is used for stream processing applications to get insights in seconds or minutes, reduce or eliminate batch ETL steps, and build end-to-end applications for various use cases such as log analytics, clickstream analytics, IoT, ad tech, gaming, and more.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-11T15:53:53.815307"}}
{"question": "How does Amazon Managed Service for Apache Flink support continuous metric generation?", "answer": "Amazon Managed Service for Apache Flink allows users to continuously generate time series analytics over time windows using Apache Flink code in Java, Scala, Python, or SQL. This information is then seamlessly integrated with reporting databases and monitoring services to serve applications and users in real time.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-11T15:53:53.815841"}}
{"question": "What is the difference between streaming ETL and continuous metric generation in the context of Amazon Managed Service for Apache Flink?", "answer": "Streaming ETL involves cleaning, enriching, organizing, and transforming raw data prior to loading a data lake or data warehouse in real time. Continuous metric generation, on the other hand, monitors and understands how data is trending over time by aggregating streaming data into critical information.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 428, "generated_at": "2026-02-11T15:53:53.816084"}}
{"question": "What service does an application send notifications to when certain metrics are reached in real-time analytics?", "answer": "Amazon Simple Notification Service (Amazon SNS)", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-11T15:53:59.348240"}}
{"question": "How can interactive analysis of data streams help in real-time analytics applications?", "answer": "Interactive analysis helps in real-time analytics applications by enabling stream data exploration in real time, inspecting streams from services like Amazon MSK and Amazon Kinesis Data Streams, and visualizing the data. It also supports iterative development of stream processing applications, with queries continuously updating as new data arrives.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-11T15:53:59.348597"}}
{"question": "What is the difference between using Amazon CloudWatch and Amazon Kinesis Data Streams for sending results of availability or success rate of a customer-facing API?", "answer": "Amazon CloudWatch is a monitoring service used to collect and track data, whereas Amazon Kinesis Data Streams is a service for real-time processing of streaming data. In the context, Amazon CloudWatch is used to send results of the availability or success rate of a customer-facing API over time, while Amazon Kinesis Data Streams is used to look for events that meet certain criteria and automatically notify the right customers.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 300, "generated_at": "2026-02-11T15:53:59.349060"}}
{"question": "What is required to create a new stream processing application on Amazon Managed Service for Apache Flink?", "answer": "Sign in to the Amazon Managed Service for Apache Flink console, create a new application, go to your preferred integrated development environment, connect to AWS, and install the open source Apache Flink libraries and AWS SDKs in your language of choice. Once built, upload your code to Amazon Managed Service for Apache Flink.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:54:05.795668"}}
{"question": "How can I write code for a new stream processing application on Amazon Managed Service for Apache Flink?", "answer": "Once you have created a new notebook in the Amazon Managed Service for Apache Flink console, you can open it in Apache Zeppelin to immediately write code in SQL, Python, or Scala. You can interactively develop applications using the notebook interface for Amazon Kinesis Data Streams, Amazon MSK, and Amazon S3 using built-in integrations and other Apache Flink-supported sources and destinations with custom connectors.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:54:05.796167"}}
{"question": "How does creating a new stream processing application on Amazon Managed Service for Apache Flink using Apache Zeppelin compare to using the console?", "answer": "Both methods allow you to create a new application and write code. However, using the console requires you to build and upload your code separately, while using Apache Zeppelin allows you to write and run your code directly in the notebook.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 451, "generated_at": "2026-02-11T15:54:05.796442"}}
{"question": "What is the role of AWS Glue Schema Registry in Amazon Managed Service for Apache Flink?", "answer": "AWS Glue Schema Registry is a serverless feature of AWS Glue that can be integrated with Amazon Managed Service for Apache Flink applications as a sink or a source. It allows the use of DataStream Connectors for sources like Apache Kafka, Amazon MSK, and Amazon Kinesis Data Streams.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T15:54:12.046578"}}
{"question": "How does the input component in an Amazon Managed Service for Apache Flink application function?", "answer": "The input component in an Amazon Managed Service for Apache Flink application is the streaming source for the application. Application users map streaming sources to data streams, and data flows from these sources into the data streams. Users process data from these data streams using application code, sending processed data to subsequent data streams or destinations.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T15:54:12.046959"}}
{"question": "What are the differences between input and output components in an Amazon Managed Service for Apache Flink application?", "answer": "Input components are the streaming sources for an Amazon Managed Service for Apache Flink application, and data flows from these sources into data streams. Output components are optional and can be configured to persist data to external destinations. Users add inputs inside application code for Amazon Managed Service for Apache Flink applications and Studio notebooks, and outputs can also be added in the same manner.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T15:54:12.047435"}}
{"question": "Which programming languages can be used to build applications on Amazon Managed Service for Apache Flink?", "answer": "Applications can be built using Java, Scala, and Python with the open source Apache Flink libraries and your own custom code. Java applications can also be built using the open source Apache Beam libraries and your own customer code.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T15:54:16.648799"}}
{"question": "How does Amazon Managed Service for Apache Flink Studio support code development?", "answer": "Amazon Managed Service for Apache Flink Studio supports code built using Apache Flinkâ€“compatible SQL, Python, and Scala.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T15:54:16.649312"}}
{"question": "What permissions does Amazon Managed Service for Apache Flink need to read from and write to specified destinations?", "answer": "Amazon Managed Service for Apache Flink needs permissions to read records from the streaming data sources you specify in your application and write your application output to specified destinations in your application output configuration.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 368, "generated_at": "2026-02-11T15:54:16.649583"}}
{"question": "How much memory does one KPU provide?", "answer": "One KPU provides 4 GB memory.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-11T15:54:20.439080"}}
{"question": "What is the purpose of checkpoints in Amazon Managed Service for Apache Flink?", "answer": "Checkpoints are up-to-date backups of a running application used to recover immediately from an application disruption.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-11T15:54:20.439453"}}
{"question": "How does the parallelism and parallelismPerKPU parameters in the Amazon Managed Service for Apache Flink API compare?", "answer": "Parallelism defines the number of concurrent instances of a task, while parallelismPerKPU defines the amount of the number of parallel tasks that can be scheduled per KPU.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 495, "generated_at": "2026-02-11T15:54:20.439666"}}
{"question": "What is the default internet access configuration for Amazon Managed Service for Apache Flink applications and notebooks in a VPC?", "answer": "By default, Amazon Managed Service for Apache Flink applications and notebooks do not have internet access in a VPC.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:54:25.294113"}}
{"question": "How does Amazon Managed Service for Apache Flink handle charging for using its services?", "answer": "Amazon Managed Service for Apache Flink charges users based on the number of Amazon KPUs used to run their applications and the associated running application storage. There are no upfront costs or resources to provision.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:54:25.294359"}}
{"question": "What is the difference in pricing between running Apache Flink applications and Apache Flink Studio notebooks on Amazon Managed Service for Apache Flink?", "answer": "Users are charged for a single additional KPU per application for application orchestration, running application storage, and interactive development for Apache Flink Studio. Additionally, there is no charge for durable application backups for Apache Flink Studio.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 483, "generated_at": "2026-02-11T15:54:25.294712"}}
{"question": "What is Amazon Managed Service for Apache Flink and how does it differ from the open source Apache Flink?", "answer": "Amazon Managed Service for Apache Flink is a fully managed stream processing solution provided by AWS, based on the open source Apache Flink project. It is a managed service, meaning it is independently billed and provides additional features such as fault tolerance and distributed computations over data streams. The open source Apache Flink, on the other hand, is a framework and engine for stream and batch data processing, which you can download and run yourself.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T15:54:32.317734"}}
{"question": "What are the benefits of using operators in Apache Flink applications?", "answer": "Operators are used in Apache Flink applications to define processing on data streams. They take an application data stream as input and send processed data to an application data stream as output. Operators can be connected in serial and parallel chains to build applications with multiple steps. They are beneficial because they don't require advanced knowledge of distributed systems to implement and operate.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T15:54:32.318092"}}
{"question": "How does using Amazon Managed Service for Apache Flink compare to using the open source Apache Flink for handling data streams?", "answer": "Using Amazon Managed Service for Apache Flink involves using a fully managed solution provided by AWS, which is independently billed and provides additional features such as fault tolerance and distributed computations over data streams. On the other hand, using the open source Apache Flink requires downloading and running the software yourself, which gives you full control but requires more setup and management.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 492, "generated_at": "2026-02-11T15:54:32.318584"}}
{"question": "What operators does Amazon Managed Service for Apache Flink support for processing data?", "answer": "Amazon Managed Service for Apache Flink supports operators for map, KeyBy, aggregations, windows, joins, and more.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-11T15:54:37.612351"}}
{"question": "How does the KeyBy operator in Amazon Managed Service for Apache Flink help in processing data?", "answer": "The KeyBy operator logically organizes data using a specified key so that similar data points can be processed together.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-11T15:54:37.612703"}}
{"question": "What are the differences between integrating Amazon Managed Service for Apache Flink with Amazon Kinesis Data Streams and Amazon Managed Streaming for Apache Kafka?", "answer": "Both Amazon Kinesis Data Streams and Amazon Managed Streaming for Apache Kafka are data sources for Amazon Managed Service for Apache Flink. However, they differ in their implementations and features. Amazon Kinesis Data Streams is a managed service for storing and processing real-time, streaming data, while Amazon Managed Streaming for Apache Kafka is a fully managed service that makes it easy to run and operate Apache Kafka.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 403, "generated_at": "2026-02-11T15:54:37.613121"}}
{"question": "What configurations are available for Apache Flink data sources and sinks?", "answer": "Apache Flink data sources and sinks come with configurations for reading and writing data continuously or once, asynchronously or synchronously, and much more.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-11T15:54:42.353042"}}
{"question": "How does exactly-once processing work in Amazon Managed Service for Apache Flink?", "answer": "Exactly-once processing in Amazon Managed Service for Apache Flink applications is achieved by building applications using idempotent operators, including sources and sinks, and using Apache Flinkâ€™s exactly-once semantics.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-11T15:54:42.353396"}}
{"question": "What is the difference between checkpoints and snapshots in Amazon Managed Service for Apache Flink?", "answer": "Checkpoints save the current application state and enable recovery to the application position in case of a failure. They use running application storage. Snapshots save a point-in-time recovery point for applications and use durable application backups.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 489, "generated_at": "2026-02-11T15:54:42.353818"}}
{"question": "What is the purpose of creating snapshots in Amazon Managed Service for Apache Flink?", "answer": "Creating snapshots in Amazon Managed Service for Apache Flink allows you to maintain previous application state and roll back your application to a specific point in time. You can also control how many snapshots you have at any given time.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-11T15:54:47.352533"}}
{"question": "What happens to the data in snapshots in Amazon Managed Service for Apache Flink?", "answer": "Data saved in snapshots in Amazon Managed Service for Apache Flink is encrypted by default and uses durable application backups. Amazon Managed Service for Apache Flink charges you based on the size of the snapshots.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-11T15:54:47.352872"}}
{"question": "How does Amazon Managed Service for Apache Flink compare to other services in terms of snapshot management?", "answer": "Amazon Managed Service for Apache Flink allows you to maintain previous application state by creating and restoring your application to a previous point in time using snapshots. It also encrypts data saved in snapshots by default and charges based on their size.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 275, "generated_at": "2026-02-11T15:54:47.353084"}}
{"question": "What console can I use to immediately query data streams and perform interactive data analytics using SQL, Python, or Scala?", "answer": "You can start from the Amazon Managed Service for Apache Flink Studio, Amazon Kinesis Data Streams, or Amazon MSK consoles to launch a serverless notebook and perform interactive data analytics using SQL, Python, or Scala.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-11T15:54:53.572165"}}
{"question": "How can I transition from writing code in a notebook for interactive data analytics to running a production stream processing application?", "answer": "Once your code is ready to run as a production application, you can build your code by clicking â€˜Deploy as stream processing applicationâ€™ in the notebook interface or issue a single command in the CLI. Studio takes care of all the infrastructure management necessary for you to run your stream processing application at scale, with auto scaling and durable state enabled.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-11T15:54:53.572526"}}
{"question": "What are the differences between writing interactive data analytics code in a notebook and running a production stream processing application?", "answer": "In a notebook, you can write code in SQL, Python, or Scala to interact with your streaming data with query response times in seconds and use built-in visualizations to explore the data. Once you're ready to promote your code to production, you can build your code and transition to a stream processing application that processes gigabytes of data per second, with Studio managing the infrastructure for you.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 407, "generated_at": "2026-02-11T15:54:53.573140"}}
{"question": "What SQL operations can be performed using Apache Flink's Table API?", "answer": "Apache Flink's Table API supports SQL operations including Scan and filter (SELECT, WHERE), Aggregations (GROUP BY, GROUP BY WINDOW, HAVING), Set (UNION, UNIONALL, INTERSECT, IN, EXISTS), Order (ORDER BY, LIMIT), Joins (INNER, OUTER, Timed Window â€“ BETWEEN, AND, Joining with Temporal Tables), and Top-N. Some of these queries, such as GROUP BY, OUTER JOIN, and Top-N, are result updating for streaming data.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:54:59.759469"}}
{"question": "How does Apache Flink's Table API support different programming languages?", "answer": "Apache Flinkâ€™s Table API supports Python and Scala through language integration using Python strings and Scala expressions. The operations supported are very similar to the SQL operations supported.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:54:59.759835"}}
{"question": "How does Apache Flink's Table API compare to using Amazon MSK as a sink for SQL queries?", "answer": "Apache Flink's Table API allows for more complex SQL operations, including real-time data processing and stream processing, while Amazon MSK is primarily a messaging service for handling real-time data ingestion.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 509, "generated_at": "2026-02-11T15:54:59.760294"}}
{"question": "What percentage of uptime is guaranteed by the SLA for Amazon Managed Service for Apache Flink?", "answer": "The SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Amazon Managed Service for Apache Flink.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-11T15:55:04.862549"}}
{"question": "How does Amazon determine if an SLA credit is eligible for Amazon Managed Service for Apache Flink?", "answer": "An SLA credit is eligible for Amazon Managed Service for Apache Flink if more than one Availability Zone in which you are running a task, within the same AWS Region, has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-11T15:55:04.862905"}}
{"question": "How does the uptime guarantee of Amazon Managed Service for Apache Flink compare to that of Amazon Elastic Container Service (ECS)?", "answer": "The text passage only mentions the uptime percentage for Amazon Managed Service for Apache Flink, it does not provide enough information to make a comparison with Amazon Elastic Container Service (ECS).", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 176, "generated_at": "2026-02-11T15:55:04.863566"}}
{"question": "What does Amazon Managed Service for Prometheus do?", "answer": "Amazon Managed Service for Prometheus is a fully managed AWS service that makes it easier for users to securely monitor and alert on metrics compatible with open source Prometheus, across various container environments.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-11T15:55:09.771235"}}
{"question": "How does Amazon Managed Service for Prometheus work?", "answer": "Amazon Managed Service for Prometheus is based on the open-source Prometheus project and is powered by Cortex. It reduces the heavy lifting required to monitor applications across various container services and integrates AWS security and compliance capabilities.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-11T15:55:09.771675"}}
{"question": "What's the difference between Amazon Managed Service for Prometheus and self-managed Prometheus?", "answer": "Amazon Managed Service for Prometheus is a fully managed AWS service, while self-managed Prometheus requires users to set up and maintain their own Prometheus instance. Amazon Managed Service for Prometheus automatically scales and integrates AWS security and compliance capabilities.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 311, "generated_at": "2026-02-11T15:55:09.772143"}}
{"question": "What are the benefits of using Amazon Managed Service for Prometheus instead of self-managed Prometheus for container monitoring?", "answer": "Amazon Managed Service for Prometheus offers a fully managed experience across AWS or multiple cloud providers, eliminating the need for manual deployment, management, and operation of Prometheus components. It also provides enhanced security, scalability, and availability. Additionally, it integrates seamlessly with the new Amazon Managed Grafana service for data visualization.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-11T15:55:16.347846"}}
{"question": "What kind of data model does Amazon Managed Service for Prometheus use for monitoring?", "answer": "Amazon Managed Service for Prometheus uses a data model that identifies each time series with a name and any number of key-value pairs called labels. Labels can be used to differentiate the characteristics of what is being measured, such as 'region=us-east-1', 'environment=production', and 'app=ecommerce'.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-11T15:55:16.348209"}}
{"question": "How does Amazon Managed Service for Prometheus compare to self-managed Prometheus in terms of integration with other AWS services?", "answer": "Amazon Managed Service for Prometheus is fully integrated with other AWS services, allowing for seamless data visualization with Amazon Managed Grafana, authorization using IAM and AWS Organizations, and logging of API calls to AWS CloudTrail. Self-managed Prometheus does not offer these integrations out of the box.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 491, "generated_at": "2026-02-11T15:55:16.348697"}}
{"question": "What open source projects does Amazon Managed Grafana support?", "answer": "Amazon Managed Grafana supports the open source Grafana project and is also compatible with other data sources such as Amazon CloudWatch, AWS X-Ray, Amazon Elasticsearch, and AWS Timestream.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:55:28.940846"}}
{"question": "What are the benefits of using Amazon Managed Grafana over the open source version?", "answer": "Amazon Managed Grafana offers alerting capabilities, simplifies querying, visualization, and alerting on data sources no matter where they are stored, and shares AWS security services such as access control and audit trails.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:55:28.941204"}}
{"question": "How does Amazon Managed Service for Prometheus differ from the open source Prometheus project?", "answer": "Amazon Managed Service for Prometheus is a fully managed service based on the popular open source Prometheus project and is powered by Cortex for scalability. It uses AWS Distro for OpenTelemetry as a collection agent for Prometheus metrics and offers an SLA with a Monthly Uptime Percentage of at least 99.9%.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 485, "generated_at": "2026-02-11T15:55:28.941606"}}
{"question": "What does the Amazon Managed Service for Prometheus collector do for Amazon EKS users?", "answer": "The Amazon Managed Service for Prometheus collector is an agentless scraper that automatically discovers and monitors Amazon EKS applications and infrastructure by removing the need to manage Prometheus agents for collecting Prometheus metrics.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:34.627389"}}
{"question": "How does Amazon Managed Service for Prometheus collector compare to AWS Distro for OpenTelemetry for collecting metrics?", "answer": "Amazon Managed Service for Prometheus collector is an agentless scraper that automatically discovers and monitors Prometheus metrics for Amazon EKS applications and infrastructure, while AWS Distro for OpenTelemetry requires customers to install, right-size, and manage it if they wish to utilize it for collecting metrics.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:34.627778"}}
{"question": "What are the benefits of using Amazon Managed Service for Prometheus collector over managing Prometheus collectors manually?", "answer": "Amazon Managed Service for Prometheus collector provides automatic, reliable, multi-AZ, secure, and scalable discovery and monitoring for Amazon EKS applications and infrastructure without the need to manage, patch, or secure Prometheus collectors manually.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:34.628164"}}
{"question": "What type of Apache Kafka services does Amazon MSK offer?", "answer": "Amazon MSK offers both Provisioned and Serverless Apache Kafka services.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-11T15:55:38.118551"}}
{"question": "What are the benefits of using Amazon MSK for Apache Kafka?", "answer": "Amazon MSK manages Apache Kafka infrastructure and operations, providing enterprise-grade security features, built-in AWS integrations, and ease of development for streaming data applications.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-11T15:55:38.119060"}}
{"question": "How does the pricing model for Amazon MSK compare to on-premises Apache Kafka?", "answer": "Amazon MSK operates on a pay-as-you-go model, while traditional on-premises Apache Kafka may require upfront investments and ongoing management costs.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 466, "generated_at": "2026-02-11T15:55:38.119351"}}
{"question": "What technology does Apache Kafka use to maintain cluster metadata?", "answer": "Apache Kafka uses Apache ZooKeeper or Apache Kafka Raft (KRaft) to maintain cluster metadata.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-11T15:55:42.818157"}}
{"question": "How does Apache Kafka enable data consumers to preserve the order of data production?", "answer": "Apache Kafka allows data consumers to process data from topics on a first-in-first-out basis, preserving the order data was produced.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-11T15:55:42.818421"}}
{"question": "What's the difference between Apache Kafka and Amazon MSK regarding data storage and order preservation?", "answer": "Both Apache Kafka and Amazon MSK store and process streaming data. However, Apache Kafka is an open-source framework that provides fault-tolerant storage and order preservation, while Amazon MSK is a managed service provided by AWS that offers similar capabilities but with additional features such as integration with other AWS services and automated scaling.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 498, "generated_at": "2026-02-11T15:55:42.818818"}}
{"question": "What is the benefit of using AWS Glue Schema Registry with Apache Kafka clients?", "answer": "AWS Glue Schema Registry is a serverless feature of AWS Glue that Apache Kafka clients can use at no additional charge. It allows you to manage and store schema information for your data streams.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-11T15:55:47.683712"}}
{"question": "What are the differences between provisioned and serverless clusters in Amazon MSK?", "answer": "Provisioned clusters contain both broker instances and abstracted metadata nodes, while serverless clusters are a resource in and of themselves, abstracting away all underlying resources.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-11T15:55:47.684071"}}
{"question": "How does Amazon MSK simplify the process of creating and managing an Apache Kafka cluster?", "answer": "Amazon MSK replaces unhealthy brokers, automatically replicates data for high availability, manages metadata nodes, automatically deploys hardware patches, manages integrations with AWS services, makes important metrics visible through the console, and supports Apache Kafka version upgrades.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-2", "source_tokens": 462, "generated_at": "2026-02-11T15:55:47.684556"}}
{"question": "What are the responsibilities of Apache Kafka brokers in a cluster?", "answer": "Apache Kafka brokers are the individual servers that make up the Apache Kafka cluster. They are responsible for storing and replicating data published to Kafka topics, managing partitions within those topics, handling client requests (producing and consuming messages), and coordinating with each other to maintain the overall state of the Kafka deployment.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:55:53.316271"}}
{"question": "How does Amazon MSK manage brokers for provisioned clusters?", "answer": "For provisioned clusters, you can choose EC2 T3.small instances or instances within the EC2 M7g and M5 instance families. Each broker you provision includes boot volume storage managed by the Amazon MSK service. For Standard brokers, you will provision storage and optionally enable provisioned storage throughput for storage volumes. For Express brokers, you do not need to provision or manage storage.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:55:53.316641"}}
{"question": "How does Amazon MSK manage brokers for serverless clusters compared to provisioned clusters?", "answer": "For serverless clusters, you just create a cluster as a resource. In contrast, for provisioned clusters, you need to provision broker instances with every cluster you create.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-3", "source_tokens": 357, "generated_at": "2026-02-11T15:55:53.317114"}}
{"question": "What replication strategy is used by Amazon MSK with Express brokers?", "answer": "Amazon MSK uses a three Availability Zone replication strategy with Express brokers.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:58.622809"}}
{"question": "How does Amazon MSK's custom replication strategy for Standard brokers differ from Express brokers in terms of configuration management?", "answer": "With Standard brokers, users have the option to use a custom replication strategy by topic. Amazon MSK fully manages the storage layer with Express brokers, offering a simpler experience by abstracting configurations related to storage. Express brokers also protect against suboptimal values that may affect availability and durability.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:58.623046"}}
{"question": "What's the difference in replication factor between a topic created with Amazon MSK's default settings and one created using the Apache Kafka API with Standard brokers?", "answer": "Amazon MSK creates a cluster of three brokers (one per Availability Zone) and sets the topic replication factor to three by default. When creating a topic using the Apache Kafka API with Standard brokers, the replication factor can be set to a different value.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-4", "source_tokens": 409, "generated_at": "2026-02-11T15:55:58.623231"}}
{"question": "What are the two deployment options for Amazon MSK's Apache Kafka clusters?", "answer": "Amazon MSK offers two deployment options for Apache Kafka clusters: Amazon MSK Provisioned and Amazon MSK Serverless.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-11T15:56:03.549269"}}
{"question": "How does Amazon MSK Provisioned compare to MSK Serverless in terms of cluster management?", "answer": "Amazon MSK Provisioned provides varying levels of control over your cluster while removing most operational overhead but requires you to scale in units of brokers and choose from standard or express broker types. In contrast, MSK Serverless fully abstracts cluster scaling and management, allowing you to run applications without having to provision, configure, or optimize clusters, and you pay for the data volume you stream and retain.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-11T15:56:03.549875"}}
{"question": "What are the ways to simplify connecting to Amazon MSK clusters?", "answer": "Amazon MSK offers multiple options to simplify connecting to your MSK clusters, including Amazon MSK Connect, Amazon MSK Replicator, and other native AWS integrations.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-5", "source_tokens": 191, "generated_at": "2026-02-11T15:56:03.550008"}}
{"question": "What are the instance types supported by MSK Provisioned for Standard brokers?", "answer": "The supported instances for MSK Provisioned Standard brokers are T3, M5, and M7g.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-11T15:56:08.445877"}}
{"question": "How does MSK Provisioned enable users to optimize their Kafka clusters for specific workload requirements?", "answer": "MSK Provisioned allows users to manually configure and scale their Apache Kafka clusters, providing flexibility to optimize the infrastructure for specific workload requirements, such as maximizing throughput, retention capacity, or other performance characteristics.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-11T15:56:08.446175"}}
{"question": "What is the difference in broker scaling between Standard and Express brokers in MSK Provisioned?", "answer": "Both Standard and Express brokers in MSK Provisioned support vertical and horizontal scaling, but Standard brokers offer more flexibility for customer managed storage management and instance selection, while Express brokers offer more elasticity and ease-of-use for running high performance streaming applications.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-6", "source_tokens": 508, "generated_at": "2026-02-11T15:56:08.446351"}}
{"question": "What is CloudWatch's open monitoring feature called?", "answer": "Open Monitoring", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-11T15:56:11.215226"}}
{"question": "How does CloudWatch's open monitoring work?", "answer": "The exact functioning of CloudWatch's open monitoring is not specified in the text.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-11T15:56:11.215417"}}
{"question": "What's the difference between CloudWatch and CloudWatch's open monitoring?", "answer": "CloudWatch is a service, while Open Monitoring is a feature of CloudWatch.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-7", "source_tokens": 15, "generated_at": "2026-02-11T15:56:11.215535"}}
{"question": "What instance sizes can Amazon MSK support for Graviton3-based M7g instances?", "answer": "Amazon MSK supports instance sizes from .large through .16xlarge for Graviton3-based M7g instances.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-11T15:56:15.734435"}}
{"question": "How does Express brokers for MSK Provisioned compare to Standard brokers in terms of throughput and recovery time?", "answer": "Express brokers provide up to 3x more throughput per broker and recover 90% quicker compared to Standard brokers.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-11T15:56:15.734649"}}
{"question": "What benefits does Amazon MSK's Express brokers offer for managing and running Apache Kafka at scale?", "answer": "Express brokers simplify Kafka management, make it more cost-effective, and increase elasticity with low latency by including pay-as-you-go storage, automatic scaling, and best practice defaults.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-8", "source_tokens": 370, "generated_at": "2026-02-11T15:56:15.734764"}}
{"question": "What are some benefits of using Express brokers in terms of storage management?", "answer": "Express brokers eliminate the need to provision or manage any storage resources. They offer elastic, virtually unlimited, pay-as-you-go, and fully managed storage. For high throughput use cases, they simplify cluster management and eliminate storage management operational overhead.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T15:56:20.920197"}}
{"question": "How does the use of Express brokers impact cluster scaling compared to Standard brokers?", "answer": "Express brokers allow for faster scaling of clusters. They enable scaling out to handle upcoming load spikes and scaling in to reduce costs. This is a crucial capability when dealing with changing demand.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T15:56:20.920518"}}
{"question": "What is the throughput difference between Express and Standard brokers?", "answer": "Express brokers offer up to 3x more throughput per broker than Standard brokers. For example, you can safely write data at up to 500 MBps with each m7g.16xlarge sized Express broker compared to 153.8 MBps on the equivalent Standard broker.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-9", "source_tokens": 509, "generated_at": "2026-02-11T15:56:20.920731"}}
{"question": "What encryption method does Amazon MSK use for Express brokers' data at rest?", "answer": "Amazon MSK encrypts data at rest in Express brokers using the AWS Key Management Service (AWS KMS) key that you specify or an AWS managed key.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-11T15:56:25.410380"}}
{"question": "How does Express broker configuration differ from standard brokers in MSK Provisioned?", "answer": "Express brokers have some default configurations optimized for availability and durability, but you can customize some configurations. The differences include storage management, instance type availability, and supported versions.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-11T15:56:25.410556"}}
{"question": "Which methods can be used to migrate data from a Standard broker Kafka cluster to a cluster with Express brokers?", "answer": "You can migrate the data to a new cluster using MirrorMaker 2 or Amazon MSK Replicator, which copies both data and metadata.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-10", "source_tokens": 482, "generated_at": "2026-02-11T15:56:25.410738"}}
{"question": "What is the write capacity of an MSK Serverless cluster?", "answer": "MSK Serverless provides up to 200 MBps of write capacity and 400 MBps of read capacity per cluster.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T15:56:30.278892"}}
{"question": "How does MSK Serverless manage partitions in a cluster?", "answer": "MSK Serverless fully manages partitions, including monitoring and moving them to even load across a cluster.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T15:56:30.279076"}}
{"question": "What's the difference between the write and read capacity of an MSK Serverless cluster and the instant write and read capacity per partition?", "answer": "MSK Serverless provides up to 200 MBps of write capacity and 400 MBps of read capacity per cluster. Additionally, to ensure sufficient throughput availability for all partitions in a cluster, MSK Serverless allocates up to 5 MBps of instant write capacity and 10 MBps of instant read capacity per partition.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-11", "source_tokens": 476, "generated_at": "2026-02-11T15:56:30.279185"}}
{"question": "What number of replicas does MSK Serverless create when you create a partition?", "answer": "MSK Serverless creates two replicas of a partition and places them in different Availability Zones.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-11T15:56:34.381705"}}
{"question": "How does MSK Serverless ensure high availability for Apache Kafka clusters?", "answer": "MSK Serverless automatically detects and recovers failed backend resources to maintain high availability for Apache Kafka clusters.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-11T15:56:34.382065"}}
{"question": "What's the difference in network access between in-VPC and internet-accessible MSK clusters?", "answer": "In-VPC MSK clusters are only accessible to clients within the VPC, while internet-accessible MSK clusters can be accessed by authorized clients from outside the VPC.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-12", "source_tokens": 465, "generated_at": "2026-02-11T15:56:34.382550"}}
{"question": "What IP addresses are allowed for public access if you enable public access for an MSK cluster?", "answer": "You should configure the cluster's security groups to have inbound TCP rules that allow public access from your trusted IP address.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:56:39.006598"}}
{"question": "How can you connect to an MSK cluster from different VPCs or AWS accounts?", "answer": "You can turn on multi-VPC private connectivity for MSK clusters running Apache Kafka 2.7.1 or later versions, and configure your clients to connect privately to the cluster using Amazon MSK managed VPC connections.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:56:39.006968"}}
{"question": "What encryption methods does Amazon MSK use for storage and in-transit data?", "answer": "Amazon MSK uses Amazon EBS server-side encryption and AWS KMS keys to encrypt storage volumes. For in-transit data, new clusters have in-transit encryption enabled through TLS by default.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-13", "source_tokens": 468, "generated_at": "2026-02-11T15:56:39.007367"}}
{"question": "What authentication and authorization options are available for serverless clusters and provisioned clusters in Amazon MSK?", "answer": "For serverless clusters, IAM access control is recommended for both authentication and authorization. For provisioned clusters, options include IAM access control, TLS certificate authentication for AuthN and access control lists for AuthZ, or SASL/SCRAM for AuthN and access control lists for AuthZ.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-11T15:56:44.109948"}}
{"question": "Why is IAM access control the recommended method for authentication and authorization in Amazon MSK?", "answer": "IAM access control is the easiest to use and most secure option in Amazon MSK. It defaults to least privilege access, making it a popular choice for managing access and authorization.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-11T15:56:44.110323"}}
{"question": "What is the difference between using IAM access control and TLS certificate authentication for authorization in Amazon MSK?", "answer": "With IAM access control, Amazon MSK uses the policies you write and its own authorizer to authorize actions. With TLS certificate authentication, you enable client authentication using TLS certificates and use the Dname of clientsâ€™ TLS certificates as the principal of the ACL to authorize client requests.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-14", "source_tokens": 480, "generated_at": "2026-02-11T15:56:44.110547"}}
{"question": "What component does Amazon MSK use for metadata management in Kafka clusters version 3.7 and below?", "answer": "Amazon MSK uses Apache ZooKeeper for metadata management in Kafka clusters version 3.7 and below.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-11T15:56:53.802580"}}
{"question": "How does Apache KRaft change the metadata management process in Kafka clusters compared to using Apache ZooKeeper?", "answer": "Apache KRaft shifts metadata management in Kafka clusters from external Apache ZooKeeper nodes to a group of controllers within Kafka. Metadata is stored and replicated as topics within Kafka brokers, resulting in faster propagation of metadata.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-11T15:56:53.802944"}}
{"question": "What is the difference in metadata management between KRaft- and ZooKeeper-based Amazon MSK clusters?", "answer": "The main difference is that in KRaft-based clusters, metadata is managed by KRaft controllers within Kafka, while in ZooKeeper-based clusters, metadata is managed by external Apache ZooKeeper nodes.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-16", "source_tokens": 385, "generated_at": "2026-02-11T15:56:53.803190"}}
{"question": "Which AWS services does Amazon MSK integrate with for delivering data to Amazon S3 in a no-code manner?", "answer": "Amazon S3 via Amazon S3's Firehose", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-11T15:56:58.626836"}}
{"question": "How does Amazon MSK facilitate network isolation and security?", "answer": "By integrating with Amazon VPC", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-11T15:56:58.627193"}}
{"question": "What's the difference between Amazon MSK and Amazon MSK Serverless when it comes to AWS services integration?", "answer": "Both integrate with Amazon S3, Amazon VPC, Amazon CloudWatch, IAM, AWS Glue Schema Registry, AWS CloudTrail, and AWS PrivateLink for similar purposes, but Amazon MSK also integrates with AWS KMS for storage volume encryption, AWS Lambda for event sourcing, AWS IoT Core for IoT event sourcing, Amazon Managed Service for Apache Flink for fully managed Flink applications, and AWS Secrets Manager for client credentials used for SASL/SCRAM authentication.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-17", "source_tokens": 364, "generated_at": "2026-02-11T15:56:58.627665"}}
{"question": "What regions can Amazon MSK Replicator be used for cross-Region replication?", "answer": "Amazon MSK Replicator can be used for cross-Region replication between MSK clusters in different AWS Regions.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-11T15:57:03.632912"}}
{"question": "In what ways can you use Amazon MSK Replicator for replicating Kafka clusters?", "answer": "Amazon MSK Replicator can be used for cross-Region replication to build highly available and fault-tolerant multi-Region streaming applications, provide lower latency access to consumers in different geographic regions, distribute data from one cluster to many clusters for sharing data with partners and teams, and aggregate data from multiple clusters into one for analytics.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-11T15:57:03.633295"}}
{"question": "How does Amazon MSK Replicator compare to manual cross-Region replication?", "answer": "Amazon MSK Replicator offers automated replication across MSK clusters without requiring users to write code or manage infrastructure, whereas manual cross-Region replication would involve creating and managing the infrastructure manually.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-18", "source_tokens": 491, "generated_at": "2026-02-11T15:57:03.633527"}}
{"question": "What metrics can I view for my Kafka topic and replicators in CloudWatch?", "answer": "You can view metrics for ReplicationLatency, MessageLag, and ReplicatorThroughput at a topic and aggregate level for each Replicator in CloudWatch. Metrics are visible under ReplicatorName in the AWS/Kafka namespace.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-11T15:57:08.768718"}}
{"question": "How does MSK Replicator handle cluster topologies to increase application resiliency?", "answer": "MSK Replicator allows you to set up active-active or active-passive cluster topologies. In an active-active setup, both MSK clusters are actively serving reads and writes. In contrast, in an active-passive setup, only one MSK cluster at a time is actively serving streaming data while the other cluster is on standby.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-11T15:57:08.769243"}}
{"question": "What is the difference in data replication between active-active and active-passive MSK cluster setups?", "answer": "In active-active setups, both MSK clusters are actively serving reads and writes, while in active-passive setups, only one MSK cluster at a time is actively serving streaming data, and the other cluster is on standby.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-19", "source_tokens": 369, "generated_at": "2026-02-11T15:57:08.769469"}}
{"question": "What prefix is added to the topic names when using MSK Replicator?", "answer": "MSK Replicator adds a prefix to the topic names in the target cluster. The prefix is the sourceKafkaClusterAlias.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-11T15:57:13.792687"}}
{"question": "How does MSK Replicator handle existing data in the source cluster?", "answer": "By default, MSK Replicator starts replicating data from the tip of the stream (latest offset) on the source cluster. However, you can configure it to start replicating from the earliest offset in the source cluster topic partitions.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-11T15:57:13.793045"}}
{"question": "How does the use of MSK Replicator impact the read capacity on the source cluster?", "answer": "MSK Replicator acts as a consumer for the source cluster and may throttle other consumers if the source cluster doesn't have enough read capacity or if the data throughput is high. To avoid this, it's recommended to provision identical capacity for source and target clusters and set Kafka quotas for the Replicator.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-20", "source_tokens": 421, "generated_at": "2026-02-11T15:57:13.793256"}}
{"question": "What storage options are available for provisioned MSK clusters running on Standard brokers?", "answer": "You can scale up storage in provisioned MSK clusters running on Standard brokers using the AWS Management Console or AWS CLI. Tiered storage allows you to virtually store unlimited data on your cluster without adding brokers for storage.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-11T15:57:20.176139"}}
{"question": "How does Apache Kafka manage stored data in different tiers?", "answer": "Apache Kafka stores data in log segments. Once a segment is complete based on size configured at cluster or topic level, it is copied to the low-cost storage tier. Data is held in performance-optimized storage for a specified retention time or size, and then itâ€™s deleted. There is a separate time and size limit setting for the low-cost storage, which is longer than the primary storage tier. If clients request data from segments stored in the low-cost tier, the broker will read the data from it and serve the data in the same way as if itâ€™s being served from the primary storage.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-11T15:57:20.176533"}}
{"question": "What's the difference between scaling storage in provisioned MSK clusters on Standard vs Express brokers?", "answer": "With Standard brokers, you can provision and manage storage, and you can also create an auto scaling storage policy. With Express brokers, you do not need to provision or manage storage, and you have access to virtually unlimited storage.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-21", "source_tokens": 461, "generated_at": "2026-02-11T15:57:20.177137"}}
{"question": "What are the data transfer charges for data transferred within a Region with provisioned MSK clusters?", "answer": "There are no additional charges for data transfer within the cluster in a Region, including data transfer between brokers and data transfer between brokers and metadata management nodes.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-11T15:57:25.004043"}}
{"question": "How does data transfer pricing differ between provisioned and serverless MSK clusters?", "answer": "With provisioned clusters, there are no additional charges for data transfer within the cluster in a Region. With serverless clusters, you will pay standard AWS data transfer charges for data transferred to or from another Region and for data transferred out to the public internet.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-11T15:57:25.004396"}}
{"question": "Why might you consider compliance with certain programs like HIPAA or PCI when using Amazon MSK?", "answer": "Amazon MSK is compliant with or eligible for various compliance programs, including HIPAA, PCI, ISO, and SOC 1, 2, and 3. These programs help ensure that AWS services meet specific security and compliance requirements.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-22", "source_tokens": 304, "generated_at": "2026-02-11T15:57:25.004605"}}
{"question": "What are the benefits of using Amazon MWAA for managing Apache Airflow workflows?", "answer": "Amazon MWAA eliminates the need for managing the Airflow infrastructure and environment, allowing data engineering and data science teams to spend more time building workflows and less time on managing the infrastructure. It provides a managed Airflow environment that is highly available, monitored, and automatically scalable.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T15:57:30.904725"}}
{"question": "What is Amazon MWAA and how does it differ from self-managed Apache Airflow?", "answer": "Amazon MWAA is a managed Apache Airflow service offered by AWS. It allows users to run their existing Airflow workflows and interact with the environment programmatically through the AWS console, API, and CLI. Unlike self-managed Apache Airflow, Amazon MWAA handles the setup, management, and scaling of the Airflow environment, freeing users from the need to manage the infrastructure and focus on building workflows.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T15:57:30.905074"}}
{"question": "What tasks can be performed using the AWS console, API, and CLI with Amazon MWAA?", "answer": "Users can interact with Amazon MWAA and manage their workflows using the AWS console, API, and command line interface (CLI).", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-0", "source_tokens": 479, "generated_at": "2026-02-11T15:57:30.905316"}}
{"question": "What sources can Amazon MWAA workflows retrieve input from?", "answer": "Amazon MWAA workflows can retrieve input from sources like S3 using Athena queries.", "question_type": "factual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-11T15:57:35.635021"}}
{"question": "How does Amazon MWAA handle plugin extensibility?", "answer": "Amazon MWAA supports all Airflow community plugins developed to date and allows users to create custom plugins. Plugins can be placed in an S3 bucket for easy integration.", "question_type": "conceptual", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-11T15:57:35.635393"}}
{"question": "How does Amazon MWAA compare to AWS Step Functions in terms of cost and performance?", "answer": "Amazon MWAA and AWS Step Functions cater to different use cases. Amazon MWAA prioritizes open source and portability, while Step Functions prioritize cost and performance. For example, Step Functions have higher performance at a lower cost when processing streaming data and transforming it through multiple steps before putting it in a DynamoDB database or S3.", "question_type": "comparison", "metadata": {"service": "MANAGED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "managed-faq-1", "source_tokens": 480, "generated_at": "2026-02-11T15:57:35.635561"}}
{"question": "What authentication methods are supported in the Console Mobile Application for logging in?", "answer": "The Console Mobile Application supports authentication methods including owner/root credentials, IAM user credentials, federated login via AWS Single Sign-On, Microsoft Active Directory, and third-party identity providers.", "question_type": "factual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-11T15:57:41.172924"}}
{"question": "Why is it recommended to use IAM user credentials or a federated role instead of the owner account for signing in to the Console Mobile Application?", "answer": "It is recommended to use IAM user credentials or a federated role to sign in to the Console Mobile Application for security reasons. If you lose your device, an IAM user can be deactivated to prevent unauthorized access. Root accounts cannot be deactivated.", "question_type": "conceptual", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-11T15:57:41.173185"}}
{"question": "How does the Console Mobile Application support authentication methods compared to the Management Console?", "answer": "The Console Mobile Application supports several authentication methods including owner/root credentials, IAM user credentials, federated login via AWS Single Sign-On, Microsoft Active Directory, third-party identity providers, biometrics authentication, and FIDO certified hardware authenticators for MFA. The Management Console only supports owner/root credentials and IAM user credentials.", "question_type": "comparison", "metadata": {"service": "MANAGEMENT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "management-faq-0", "source_tokens": 500, "generated_at": "2026-02-11T15:57:41.173372"}}
{"question": "What region options are available for Amazon MemoryDB Multi-Region?", "answer": "Amazon MemoryDB Multi-Region allows you to build applications in multiple Regions with up to 99.999% availability and microsecond read and single-digit millisecond write latency.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:57:50.574434"}}
{"question": "How does Amazon MemoryDB ensure both in-memory speed and data durability?", "answer": "Amazon MemoryDB achieves this by storing your entire dataset in memory and leveraging a distributed transactional log to provide both in-memory speed and data durability, consistency, and recoverability.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:57:50.574966"}}
{"question": "How does Amazon MemoryDB Multi-Region compare to a regular Amazon MemoryDB cluster in terms of availability and latency?", "answer": "Amazon MemoryDB Multi-Region enables you to build applications in multiple Regions with up to 99.999% availability and microsecond read and single-digit millisecond write latency, compared to a regular Amazon MemoryDB cluster which does not offer this level of multi-region availability and low latency.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T15:57:50.575268"}}
{"question": "What data types does MemoryDB support that are also available in Valkey and Redis OSS?", "answer": "MemoryDB supports data types such as strings, lists, sets, hashes, sorted sets, hyperloglogs, bitmaps, and streams, which are also available in Valkey and Redis OSS.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T15:57:55.587472"}}
{"question": "How does MemoryDB manage the compatibility with Valkey and Redis OSS data types and commands?", "answer": "MemoryDB maintains compatibility by supporting the same set of data types, parameters, and commands as Valkey and Redis OSS. This means that the application code, clients, and tools you use with Valkey and Redis OSS can be used with MemoryDB.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T15:57:55.587839"}}
{"question": "What is the difference between the primary node and replica nodes in a MemoryDB cluster?", "answer": "A primary node serves read and write requests, while a replica node only serves read requests. The primary node can failover to a replica node, promoting that replica to the new primary node for that shard.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-1", "source_tokens": 277, "generated_at": "2026-02-11T15:57:55.588061"}}
{"question": "What is MemoryDB and what type of workloads is it suitable for?", "answer": "MemoryDB is a durable, in-memory database designed for workloads that require ultra-fast performance with microsecond read and single-digit millisecond write latency. It is suitable for use cases where a durable database with Valkey or Redis OSS-compatible data structures and APIs is needed.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T15:58:02.316607"}}
{"question": "How does MemoryDB's multi-Region feature improve application availability and resiliency?", "answer": "MemoryDB's multi-Region feature improves application availability and resiliency by providing active-active replication and data redundancy across multiple AWS Regions. It allows serving reads and writes locally from the Regions closest to customers with microsecond read and single-digit millisecond write latency, and asynchronously replicates data between Regions with data typically propagated within a second.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T15:58:02.316977"}}
{"question": "What is the main difference between MemoryDB and ElastiCache?", "answer": "MemoryDB is a fully-managed, in-memory database designed for workloads requiring a durable primary database with ultra-fast performance, while ElastiCache is a service used to cache data from other databases and data stores using Valkey, Memcached, or Redis OSS. MemoryDB offers active-active, multi-Region replication for high availability, while ElastiCache is used to accelerate data access with existing primary databases or data stores.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-2", "source_tokens": 479, "generated_at": "2026-02-11T15:58:02.317321"}}
{"question": "What regions can I add to a MemoryDB Multi-Region cluster once I have created a regional cluster in one AWS Region?", "answer": "You can add up to four additional Regions to a MemoryDB Multi-Region cluster.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:58:07.092750"}}
{"question": "How does MemoryDB Multi-Region ensure data consistency across all regional clusters?", "answer": "MemoryDB Multi-Region ensures data consistency by automatically and asynchronously replicating data to all other regional clusters within one second. Conflict resolution is managed in the background without any impact to application availability.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:58:07.093138"}}
{"question": "How does MemoryDB Multi-Region compare to a single MemoryDB cluster in terms of regional expansion?", "answer": "MemoryDB Multi-Region allows you to add up to five regional clusters, whereas a single MemoryDB cluster can only exist in one region. When you write data to any regional cluster in a MemoryDB Multi-Region cluster, it is automatically replicated to all other regional clusters within the same cluster.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T15:58:07.093351"}}
{"question": "What data structure does MemoryDB Multi-Region use for reconciliation between concurrent updates?", "answer": "MemoryDB Multi-Region uses Conflict-free Replicated Data Type (CRDT) for reconciliation between concurrent updates.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-11T15:58:12.967917"}}
{"question": "How does MemoryDB Multi-Region handle conflicts in a Multi-Region setup?", "answer": "MemoryDB Multi-Region uses CRDT to merge write-writer conflicts independently on each replica with eventual consistency. It keeps track of any writes that have occurred in an isolated or degraded Region and propagates them to other Regions once the Region is back online.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-11T15:58:12.968282"}}
{"question": "How does the throughput and latency of MemoryDB compare when using different node types and payload sizes?", "answer": "MemoryDB's throughput and latency vary based on the node type, payload size, and number of client connections. MemoryDB delivers microsecond read latency, single-digit millisecond write latency, and read-after-write latency on the primary node for a cluster shard. It can support up to 390K read and 100K write requests per second and up to 1.3 GB/s read and 100 MB/s write throughput per node.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-4", "source_tokens": 481, "generated_at": "2026-02-11T15:58:12.968509"}}
{"question": "What is the benefit of enhanced IO multiplexing for MemoryDB version 7.0 and later?", "answer": "Enhanced IO multiplexing in MemoryDB version 7.0 and later delivers additional improvements to throughput and latency at scale, making it ideal for throughput-bound workloads with multiple client connections. Its benefits scale with the level of workload concurrency.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-11T15:58:24.564612"}}
{"question": "How does enhanced IO multiplexing in MemoryDB affect the performance of read and write operations?", "answer": "With enhanced IO multiplexing, each dedicated network IO thread pipelines commands from multiple clients into the MemoryDB engine, taking advantage of the engine's ability to efficiently process commands in batches. This results in up to 46% increased throughput (read and write operations per second) and up to 21% decreased P99 latency, as demonstrated in the example using r6g.4xlarge node and 5200 concurrent clients.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-11T15:58:24.564853"}}
{"question": "What is the difference between using MemoryDB version 6 and version 7.0 or later for Redis OSS in terms of throughput and latency?", "answer": "MemoryDB version 7.0 and later, with enhanced IO multiplexing, delivers up to 46% increased throughput (read and write operations per second) and up to 21% decreased P99 latency, compared to MemoryDB version 6 for Redis OSS.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-6", "source_tokens": 423, "generated_at": "2026-02-11T15:58:24.564998"}}
{"question": "What are the two ways to resize a MemoryDB cluster horizontally?", "answer": "You can resize a MemoryDB cluster horizontally by adding or removing nodes, and by adding or removing shards and replica nodes.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:58:28.698972"}}
{"question": "How does MemoryDB handle cluster resizing operations?", "answer": "MemoryDB allows you to resize your cluster both horizontally and vertically while keeping it online and serving read and write requests.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:58:28.699389"}}
{"question": "What is the difference between scaling a MemoryDB cluster horizontally and vertically?", "answer": "Scaling a MemoryDB cluster horizontally means adding or removing nodes and shards to distribute the workload and increase capacity. Scaling vertically means changing the node type to increase memory and CPU resources per node.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-7", "source_tokens": 498, "generated_at": "2026-02-11T15:58:28.699635"}}
{"question": "What is required to migrate data from ElastiCache to MemoryDB?", "answer": "To migrate data from ElastiCache to MemoryDB, create a snapshot of your ElastiCache cluster, export it to your S3 bucket, create a new MemoryDB cluster, and specify the backup to restore from.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-11T15:58:34.621390"}}
{"question": "How does MemoryDB handle data encryption?", "answer": "MemoryDB supports encryption of data both at-rest and in-transit. For encryption at rest, you can use AWS Key Management Service customer managed keys (CMK) or a MemoryDB provided key. With Graviton2 instances for your MemoryDB cluster, your data is encrypted in memory using always-on 256-bit DRAM encryption.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-11T15:58:34.621922"}}
{"question": "What are the differences between ElastiCache and MemoryDB in terms of data migration and encryption?", "answer": "ElastiCache requires creating a snapshot and exporting it to S3 for data migration, while MemoryDB allows restoring a new cluster from the backup. ElastiCache supports encryption at rest using AWS KMS or ElastiCache provided keys, but MemoryDB also encrypts data in memory using Graviton2 instances' 256-bit DRAM encryption.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-8", "source_tokens": 500, "generated_at": "2026-02-11T15:58:34.622141"}}
{"question": "What type of instances and storage should I use to enable data tiering in MemoryDB?", "answer": "Create a new MemoryDB cluster using memory-optimized instances with ARM-based AWS Graviton2 processors and NVMe SSDs (R6gd).", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-11T15:58:39.396529"}}
{"question": "How does MemoryDB's data tiering feature manage data placement and cost optimization?", "answer": "MemoryDB manages data placement using a least-recently used (LRU) policy, transparently moving items between memory and disk when memory is fully consumed. This optimizes cost by automatically detecting and moving least-recently used items to disk.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-11T15:58:39.396892"}}
{"question": "What are the storage cost savings I can expect when using R6gd nodes with data tiering compared to R6g nodes?", "answer": "You can achieve over 60% storage cost savings when running at maximum utilization, compared to R6g nodes (memory only).", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-9", "source_tokens": 473, "generated_at": "2026-02-11T15:58:39.397107"}}
{"question": "What size flexibility does MemoryDB reserved nodes offer within a node family and AWS Region?", "answer": "MemoryDB reserved nodes offer size flexibility within a node family and AWS Region, allowing the discounted reserved node rate to be automatically applied to usage of all sizes in the same node family.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-11T15:58:44.224286"}}
{"question": "How does the size flexibility capability of MemoryDB reserved nodes impact node management?", "answer": "The size flexibility capability of MemoryDB reserved nodes reduces the time spent managing reserved nodes as users are no longer tied to a specific database node size.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-11T15:58:44.224651"}}
{"question": "What is the difference between the size flexibility of MemoryDB R6g and R6gd nodes?", "answer": "Both R6g and R6gd MemoryDB nodes offer size flexibility within a node family and AWS Region, allowing the discounted reserved node rate to be automatically applied to usage of all sizes in the same node family. The difference between the two node types lies in the data tiering feature for R6gd nodes.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-10", "source_tokens": 324, "generated_at": "2026-02-11T15:58:44.224883"}}
{"question": "What type of applications is vector search for MemoryDB ideal for?", "answer": "Vector search for MemoryDB is ideal for high-speed AI/ML applications, particularly those focused on peak performance, such as Retrieval Augmented Generation (RAG), anomaly (fraud) detection, real-time recommendation engines, and document retrieval.", "question_type": "conceptual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-11T15:58:49.140155"}}
{"question": "What is the difference in performance between MemoryDB and other popular vector databases on AWS regarding vector search?", "answer": "As of June 26, 2024, MemoryDB delivers the fastest vector search performance at the highest recall rates among popular vector databases on AWS.", "question_type": "comparison", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-11T15:58:49.140586"}}
{"question": "How does MemoryDB store and index vector embeddings?", "answer": "MemoryDB stores vector embeddings as JSON or hash data types and builds the index with your vector embeddings. As you load new, update existing, or delete data, MemoryDB streams updates to the vector index within single-digit milliseconds.", "question_type": "factual", "metadata": {"service": "MEMORYDB", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "memorydb-faq-11", "source_tokens": 413, "generated_at": "2026-02-11T15:58:49.141023"}}
{"question": "What tools does AWS Migration Hub provide access to for collecting IT assets and analyzing dependencies?", "answer": "AWS Migration Hub provides access to tools like AWS Application Migration Service, AWS Server Migration Service, AWS Database Migration Service, and ATADATA ATAmotion for collecting and inventorying IT assets based on actual usage, analyzing application components and infrastructure dependencies, and grouping resources into applications.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:58:55.067531"}}
{"question": "How does AWS Migration Hub help in the cloud transformation journey?", "answer": "AWS Migration Hub simplifies the cloud transformation journey by providing the tools needed to collect and inventory IT assets, analyze application components and infrastructure dependencies, generate migration strategy and Amazon Elastic Compute Cloud (EC2) instance recommendations, track application migrations, and modernize applications currently running on AWS.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:58:55.067791"}}
{"question": "What is the difference between AWS Migration Hub and AWS Application Migration Service in terms of capabilities?", "answer": "AWS Migration Hub is a service that provides access to various tools and integrations for collecting IT assets, analyzing dependencies, generating strategy and instance recommendations, tracking migration status, and modernizing applications. AWS Application Migration Service is a specific tool within the AWS Migration Hub ecosystem, which focuses on assessing, migrating, and transforming applications to AWS.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-0", "source_tokens": 467, "generated_at": "2026-02-11T15:58:55.067932"}}
{"question": "What is the primary function of AWS Migration Hub?", "answer": "AWS Migration Hub helps you manage your IT environment and migration progress by providing visibility into the status of your migration projects using integrated migration tools.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:58:58.981787"}}
{"question": "How does AWS Migration Hub let you understand your IT environment?", "answer": "AWS Migration Hub uses information collected by AWS discovery tools and the Application Discovery Service repository to let you view technical specifications and performance information about discovered resources.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:58:58.982169"}}
{"question": "What are the differences in grouping servers in AWS Migration Hub between starting migration and discovery?", "answer": "You can group servers into applications once the migration has started or, you can discover and group your servers before you start the migration.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-1", "source_tokens": 451, "generated_at": "2026-02-11T15:58:58.982380"}}
{"question": "What region should be selected before using most features in Migration Hub?", "answer": "A Migration Hub home Region needs to be selected from the Migration Hub Settings page or by using the Migration Hub Config API before using most features in Migration Hub.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T15:59:02.800750"}}
{"question": "Why is it necessary to choose a Migration Hub home Region?", "answer": "The Migration Hub home Region acts as a single repository of discovery and migration planning information for the entire portfolio and provides a single view of migrations into multiple AWS Regions.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T15:59:02.801132"}}
{"question": "Can I change the Migration Hub home Region once it's set?", "answer": "Once set, the Migration Hub home Region cannot be changed.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-2", "source_tokens": 506, "generated_at": "2026-02-11T15:59:02.801344"}}
{"question": "Which data collection options are available for discovery in AWS Migration Hub?", "answer": "You have two options for data collection during discovery in AWS Migration Hub: the AWS Application Discovery Service agentless collector or the installation of agents on your servers.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T15:59:07.600654"}}
{"question": "Why would you use the agentless collector in AWS Migration Hub instead of installing agents?", "answer": "You might choose to use the AWS Application Discovery Service agentless collector during discovery in AWS Migration Hub if you have a VMware environment and prefer not to install an agent. However, if you need more detailed information, you should install agents on your servers.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T15:59:07.601027"}}
{"question": "How does the integration of migration tools in AWS Migration Hub affect the resources that appear in the Applications page?", "answer": "Resources that are migrated using integrated migration tools in AWS Migration Hub and then grouped as applications will appear on the Applications page in the Migrate section of the console.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T15:59:07.601246"}}
{"question": "What method can be used to import data into AWS Migration Hub?", "answer": "You can access the AWS Migration Hub import feature either from the Migration Hub console or by invoking the Application Discovery Service APIs.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-11T15:59:11.767986"}}
{"question": "How is imported data handled in AWS Migration Hub?", "answer": "The imported data is stored in the Application Discovery Service data repository in encrypted format.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-11T15:59:11.768346"}}
{"question": "How does importing data with mismatched keys affect the process in AWS Migration Hub?", "answer": "If the imported data contains records with mismatched keys, some records will not be imported. The import feature will flag those records as incorrect. If no matching key is provided, the import will use the values of 'IPAddress', 'HostName', 'MACAddress', or a combination of 'VMware.VCenterId' and 'VMware.MoRefId' to determine the uniqueness of a given server.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-4", "source_tokens": 495, "generated_at": "2026-02-11T15:59:11.768771"}}
{"question": "What information does AWS Migration Hub use to make EC2 instance recommendations?", "answer": "AWS Migration Hub uses server specification, CPU, and memory utilization data to make EC2 instance recommendations.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-11T15:59:15.816049"}}
{"question": "How does the EC2 instance recommendations feature determine the best instance type for a workload?", "answer": "The EC2 instance recommendations feature determines the best instance type for a workload by analyzing the required CPU and RAM resources, along with user preferences for AWS purchasing option, AWS Region, EC2 instance type exclusions, and CPU/Rram utilization metric.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-11T15:59:15.816364"}}
{"question": "What type of instances does the EC2 instance recommendations feature provide recommendations for?", "answer": "The EC2 instance recommendations feature provides recommendations for current generation instances.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-5", "source_tokens": 484, "generated_at": "2026-02-11T15:59:15.816582"}}
{"question": "What does AWS Migration Hub offer for understanding EC2 cost projections?", "answer": "AWS Migration Hub provides an EC2 instance recommendation feature through Migration Hub when users want an understanding of their projected EC2 costs.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-11T15:59:20.189793"}}
{"question": "How does AWS Migration Hub help you manage your application's resources during migration?", "answer": "AWS Migration Hub lets you view a diagram and a table with migration status details for each resource in an application. It also provides links to the resources created or running instances (depending on the tool) after migration completion.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-11T15:59:20.190025"}}
{"question": "What's the difference between tracking application migration status in Migration Hub versus automating the migration itself?", "answer": "AWS Migration Hub provides a single place for users to track the progress of applications they are migrating, whereas it does not automate the migration steps.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-6", "source_tokens": 416, "generated_at": "2026-02-11T15:59:20.190258"}}
{"question": "What must be true in AWS Migration Hub to view migration progress?", "answer": "The resources being migrated must be in the AWS Discovery repository and supported tools must be used for migration.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-11T15:59:24.230951"}}
{"question": "How does grouping resources in AWS Migration Hub impact migration tracking?", "answer": "Grouping resources into applications in AWS Migration Hub allows users to track the migration status of those resources in a single location.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-11T15:59:24.231321"}}
{"question": "What happens to the status of tools not integrated with AWS Migration Hub?", "answer": "The status of resources managed by tools not integrated with AWS Migration Hub will not be displayed in the AWS Migration Hub Management Console, but users can still view the status of their applications and update it via the CLI or APIs.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-7", "source_tokens": 474, "generated_at": "2026-02-11T15:59:24.231537"}}
{"question": "What applications can Strategy Recommendations analyze for migration and modernization?", "answer": "Strategy Recommendations supports analysis for applications running on Windows Server 2003 or above and various Linux distributions, including Ubuntu, RedHat, Oracle Linux, Debian, and Fedora. It also offers additional refactoring analysis for custom applications written in C# and Java, and licensed databases such as Microsoft SQL Server and Oracle.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-11T15:59:30.751131"}}
{"question": "How does Refactor Spaces simplify the application transformation process?", "answer": "Refactor Spaces helps you accelerate application refactoring and simplifies the app transformation process by making it easy to manage the refactoring process while operating in production. It reduces the business risk of evolving applications into microservices or extending legacy applications that canâ€™t be modified with new features written in microservices.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-11T15:59:30.751323"}}
{"question": "What are the main differences between Strategy Recommendations and Refactor Spaces in AWS?", "answer": "Strategy Recommendations helps you identify a tailored migration and modernization strategy and provides the tools and services to help you run the strategy. It identifies incompatibilities (anti-patterns) in the source code that need to be resolved to implement recommendations. Refactor Spaces, on the other hand, helps you accelerate application refactoring and simplifies the application transformation process by making it easy to manage the refactoring process while operating in production.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-8", "source_tokens": 429, "generated_at": "2026-02-11T15:59:30.751493"}}
{"question": "What AWS services does Refactor Spaces use to create refactoring environments?", "answer": "Refactor Spaces uses Transit Gateway, Resource Access Manager, and API Gateway to create refactoring environments.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T15:59:35.572139"}}
{"question": "How does Refactor Spaces help in operating evolving applications at scale?", "answer": "Refactor Spaces helps in operating evolving applications at scale by orchestrating other AWS services to create refactoring environments and stitch together existing applications and microservices into Refactor Spaces applications.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T15:59:35.572472"}}
{"question": "What's the difference between a Refactor Spaces Environment and a regular AWS VPC?", "answer": "A Refactor Spaces Environment is a container for your existing application and new microservices, while an AWS VPC is a virtual private cloud. The environment orchestrates Transit Gateway, Resource Access Manager, and VPCs to bridge networking across accounts, while a VPC is used to isolate resources within an AWS account.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T15:59:35.572662"}}
{"question": "What is the role of A Refactor Spaces Application in AWS?", "answer": "An A Refactor Spaces Application in AWS provides configurable request routing to existing applications and new microservices, and simplifies strangler fig refactoring through a proxy. It orchestrates API Gateway, Network Load Balancer (NLB), and AWS Lambda resource policies.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-11T15:59:40.662204"}}
{"question": "How does traffic routing work in A Refactor Spaces for services with different endpoints?", "answer": "For services with a Lambda endpoint, traffic is routed using API Gatewayâ€™s Lambda integration. For services with a URL endpoint, traffic is routed using an API Gateway VPC Link and NLB target group.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-11T15:59:40.662448"}}
{"question": "What's the difference in traffic routing for services with a Lambda endpoint versus a URL endpoint in A Refactor Spaces?", "answer": "Services with a Lambda endpoint use API Gatewayâ€™s Lambda integration for traffic routing, while services with a URL endpoint use an API Gateway VPC Link and NLB target group.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-10", "source_tokens": 230, "generated_at": "2026-02-11T15:59:40.662613"}}
{"question": "What are the ways to use Refactor Spaces in AWS?", "answer": "Refactor Spaces can be used through the AWS Management Console, AWS SDK/CLI, or CloudFormation.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-11T15:59:45.989243"}}
{"question": "How does one set up environment sharing in Refactor Spaces?", "answer": "First, create a Refactor Spaces Environment in the account chosen to be the environment owner and share it with other accounts. Once the other accounts accept the environment sharing invitation, Refactor Spaces automatically shares AWS resources contained in the environment with the other designated accounts.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-11T15:59:45.989782"}}
{"question": "How can I privately access Refactor Spaces APIs using VPC Endpoints?", "answer": "To privately access Refactor Spaces APIs from your VPC, you can create VPC Endpoints. With VPC Endpoints, the routing between the VPC and Refactor Spaces is handled by the AWS network without the need for an internet gateway, NAT gateway, or virtual private network (VPN) connection. The latest generation of VPC Endpoints used by Refactor Spaces is powered by AWS PrivateLink.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-11", "source_tokens": 474, "generated_at": "2026-02-11T15:59:45.990045"}}
{"question": "What is the role of AWS Migration Hub Orchestrator in application migrations to AWS?", "answer": "AWS Migration Hub Orchestrator is a tool designed to automate and simplify the migration of applications to AWS. It helps reduce migration costs and time by managing dependencies between different tools, providing visibility into migration progress, and offering predefined and customizable workflow templates.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-11T15:59:51.885710"}}
{"question": "How does AWS Migration Hub Orchestrator simplify the process of migrating applications to AWS?", "answer": "AWS Migration Hub Orchestrator simplifies the process of migrating applications to AWS by automating pre-migration tasks, migration workflows, and migration tasks across multiple tools. It also offers customizable workflow templates that can be adapted to address the needs of specific workloads and use cases.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-11T15:59:51.885935"}}
{"question": "What is the difference between accelerating migrations with AWS Migration Hub Orchestrator and customizing workflow templates?", "answer": "Accelerating migrations with AWS Migration Hub Orchestrator involves using predefined workflow templates based on thousands of applications with similar patterns to speed up the migration process. Customizing workflow templates, on the other hand, involves building on top of baseline recommendations and modifying the steps and dependencies to address the needs of specific workloads and use cases.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-12", "source_tokens": 326, "generated_at": "2026-02-11T15:59:51.886075"}}
{"question": "What is the purpose of using Orchestrator in application migrations to AWS?", "answer": "Orchestrator simplifies and accelerates the migration of applications to AWS by automating various tasks such as pre-migration checks, migration tasks in different tools, and post-migration tasks to reduce migration costs, time, and errors.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-11T15:59:56.546699"}}
{"question": "How does Orchestrator help in automating pre-migration tasks?", "answer": "Orchestrator allows the automation of tasks such as checking migration readiness, installing agents, or removing unnecessary log files in the source environments to save time, cost, and reduce errors.", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-11T15:59:56.547066"}}
{"question": "What are the benefits of using Orchestrator in migrations that involve multiple tools?", "answer": "Orchestrator helps to minimize the inputs required in each tool for the same migration workflow, manage dependencies between different tools, and provide visibility into migration progress in one place, thus reducing migration costs and time.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-13", "source_tokens": 401, "generated_at": "2026-02-11T15:59:56.547415"}}
{"question": "What are the five predefined workflow templates available in Orchestrator?", "answer": "The five predefined workflow templates available in Orchestrator are: 1) migrating SAP NetWeaver-based applications with HANA databases using AWS Launch Wizard and HANA System Replication, 2) accelerating the rehosting of any applications using AWS Application Migration Service (MGN), 3) replatforming SQL Server databases to Amazon RDS, 4) rehosting SQL Server databases to Amazon EC2 using native backup and restore, and 5) importing on-premises virtual machine (VM) images to AWS with a console-based experience for generating Amazon Machine Image (AMI)", "question_type": "factual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-11T16:00:04.465510"}}
{"question": "How does Orchestrator help in the migration process?", "answer": "Orchestrator helps in the migration process by enabling users to complete prerequisites like discovering or importing source servers, grouping the discovered servers into applications, and installing a plugin in the source environment. After defining a workflow using one of the predefined templates, users can run, pause, or delete the workflow and track the status of the workflow at step level and step group level.", "question_type": "conceptual", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-11T16:00:04.465876"}}
{"question": "What is the difference between the third and fourth predefined workflow templates in Orchestrator?", "answer": "The third and fourth predefined workflow templates in Orchestrator both help in database migration. However, the third template (replatforming SQL Server databases to Amazon RDS) involves migrating SQL Server databases to a managed database service (Amazon RDS), while the fourth template (rehosting SQL Server databases to Amazon EC2 using native backup and restore) involves rehosting SQL Server databases to Amazon EC2 instances using native backup and restore.", "question_type": "comparison", "metadata": {"service": "MIGRATION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "migration-faq-14", "source_tokens": 459, "generated_at": "2026-02-11T16:00:04.466097"}}
{"question": "What are the features of Amazon Neptune's Neptune Database?", "answer": "Amazon Neptune's Neptune Database is a fully managed graph database offering enterprise features such as high availability (up to 99.99%), multi-Region for disaster recovery, dynamic scaling with serverless, and native integrations with other AWS services. It automatically scales storage, is fault-tolerant and self-healing, and supports popular graph query languages like Apache TinkerPop Gremlin, SPARQL, and openCypher.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T16:00:10.370580"}}
{"question": "How does Neptune's graph database improve AI applications?", "answer": "Neptune's graph database captures context that improves accuracy and explainability of generative AI applications by modeling data as a graph. This enables faster development of AI applications and strategic insights from analyzing relationships across structured and unstructured data.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T16:00:10.371118"}}
{"question": "What is the difference between Neptune Database and Neptune Analytics?", "answer": "Neptune Database is a fully managed graph database with features like high availability, multi-Region, dynamic scaling, and native AWS service integrations. Neptune Analytics is not explicitly mentioned in the text, so no comparison can be made.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-0", "source_tokens": 497, "generated_at": "2026-02-11T16:00:10.371299"}}
{"question": "What type of data can Neptune Analytics load for graph analytics?", "answer": "Neptune Analytics can load graph data from Amazon S3 or an existing Neptune database.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-11T16:00:14.521020"}}
{"question": "How does Neptune Analytics handle new data for predictions in Neptune ML?", "answer": "Neptune Analytics supports real-time predictions on nodes, edges, and properties without the need to retrain ML models.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-11T16:00:14.521409"}}
{"question": "What is the difference between Neptune Analytics and Neptune ML in terms of data sources?", "answer": "Neptune Analytics processes graph data from Amazon S3 or an existing Neptune database for graph analytics. Neptune ML is an integration between Neptune Database and Amazon SageMaker for training and making predictions using graph data.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-1", "source_tokens": 237, "generated_at": "2026-02-11T16:00:14.521641"}}
{"question": "What query languages does Neptune Database support for property graph data model?", "answer": "Neptune Database supports two query languages for the property graph data model: Apache TinkerPop Gremlin and openCypher.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T16:00:19.637344"}}
{"question": "How can Neptune Analytics be used for building Retrieval Augmented Generation (RAG) applications?", "answer": "Neptune Analytics can be used for building RAG applications by performing vector similarity search and combining the search results with contextually aware data representations in graphs for providing rich contextual information related to relationships.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T16:00:19.637730"}}
{"question": "How does Neptune Analytics compare to Neptune ML for handling relationships and categorizations?", "answer": "Neptune Analytics can be used for deriving critical features from connected data using common algorithms such as clustering, centrality, and path finding. Neptune ML, on the other hand, is used for designing, building, optimizing, and predicting relationships and categorizations using state-of-the-art GNNs.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-2", "source_tokens": 456, "generated_at": "2026-02-11T16:00:19.638155"}}
{"question": "What query languages can be used to interact with property graph data in Amazon Neptune?", "answer": "You can interact with property graph data in Amazon Neptune using either Gremlin or openCypher query languages.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T16:00:24.275937"}}
{"question": "Why might you choose to use different query languages (Gremlin and openCypher) for the same property graph data in Amazon Neptune?", "answer": "You might find it more convenient to use Gremlin for some workloads and openCypher for others when working with property graph data in Amazon Neptune.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T16:00:24.276244"}}
{"question": "Can you execute a query for property graph data (Gremlin or openCypher) over RDF data in Amazon Neptune?", "answer": "No, you cannot execute a query for property graph data (Gremlin or openCypher) over RDF data or vice-versa in Amazon Neptune.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-3", "source_tokens": 476, "generated_at": "2026-02-11T16:00:24.276621"}}
{"question": "What management features does Neptune Database share with Amazon RDS?", "answer": "Neptune Database shares certain management features with Amazon RDS, including instance lifecycle management, encryption at rest with AWS KMS keys, and security groups management.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:00:29.158043"}}
{"question": "How does Neptune Database's architecture support high-performance graph queries?", "answer": "Neptune Database uses a scale-up, in-memory optimized architecture to allow for fast query evaluation over large graphs, making it well-suited for graph applications that require high throughput and low-latency queries.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:00:29.158356"}}
{"question": "How does the pricing for Neptune Database's replication compare to other databases?", "answer": "Unlike some other databases, Neptune Database's replication is bundled into the price, and you are charged based on the storage your database consumes at the database layer. This can help reduce costs by eliminating the need to pay for separate replication storage.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:00:29.158535"}}
{"question": "What is the minimum storage size for Amazon Neptune?", "answer": "The minimum storage size for Amazon Neptune is 10 GiB.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T16:00:33.233742"}}
{"question": "How does automatic scaling of database capacity work in Amazon Neptune?", "answer": "Amazon Neptune automatically scales database capacity based on workload requirements, determining and provisioning the necessary compute and memory resources to maintain consistent performance.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T16:00:33.234065"}}
{"question": "What's the difference between manually and automatically scaling database capacity in Amazon Neptune?", "answer": "Manual scaling involves choosing the desired DB instance class and applying changes during a specified maintenance window or using the Apply Immediately flag, while automatic scaling with Neptune Serverless allows for instant scaling and management of resources based on workload requirements.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-5", "source_tokens": 479, "generated_at": "2026-02-11T16:00:33.234247"}}
{"question": "What can you do with a database snapshot after deleting an AWS Neptune database instance?", "answer": "You can use the final database snapshot to restore the deleted database instance at a later date.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:00:36.939943"}}
{"question": "What are the benefits of sharing Neptune Database snapshots between different AWS accounts?", "answer": "Sharing Neptune Database snapshots allows you to easily share data between environments and keep backups of all your data secure in a separate account.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:00:36.940328"}}
{"question": "Can you share encrypted Neptune Database snapshots with other AWS accounts?", "answer": "Yes, you can share encrypted Neptune Database snapshots with other AWS accounts.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:00:36.940498"}}
{"question": "What number of subnets and Availability Zones are required to create a Neptune Database cluster?", "answer": "A Neptune Database cluster can only be created in an Amazon VPC that has at least two subnets in at least two Availability Zones.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-11T16:00:41.296567"}}
{"question": "Why does Neptune distribute database instances across multiple Availability Zones?", "answer": "Neptune distributes database instances across multiple Availability Zones to ensure availability in the unlikely event of an Availability Zone failure.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-11T16:00:41.296930"}}
{"question": "How does Neptune handle database crashes compared to other databases?", "answer": "Unlike other databases, Neptune does not require replaying the redo log from the last checkpoint during database crashes. This reduces database restart times to less than 60 seconds in most cases.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-7", "source_tokens": 491, "generated_at": "2026-02-11T16:00:41.297124"}}
{"question": "What happens if the higher priority replicas on a Neptune cluster are unavailable?", "answer": "Neptune will promote the lower priority replica to become the primary instance.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-11T16:00:45.500038"}}
{"question": "How does Neptune handle failover to ensure database operations resume quickly?", "answer": "Neptune flips the canonical name record (CNAME) for the primary endpoint to a healthy replica and promotes it to be the new primary, typically within 30 seconds.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-11T16:00:45.500350"}}
{"question": "How does the failover process for a Neptune Database with replicas compare to a single instance?", "answer": "Failover for a Neptune Database with replicas completes within 30 seconds, while failover for a single instance can take up to 15 minutes.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-8", "source_tokens": 489, "generated_at": "2026-02-11T16:00:45.500887"}}
{"question": "What is required for creating an Amazon Neptune Database instance?", "answer": "All Amazon Neptune Database instances must be created in a VPC.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-11T16:00:49.457757"}}
{"question": "Why do we need to create Neptune Database instances in a VPC?", "answer": "Creating Neptune Database instances in a VPC allows us to define a virtual network topology and have complete control over who can access the databases.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-11T16:00:49.458069"}}
{"question": "How does Neptune Analytics compare to other graph processing tools in terms of handling large graphs?", "answer": "Neptune Analytics is an in-memory engine and can load large graphs into memory to deliver a response in seconds, making it well-suited for handling large graphs.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-9", "source_tokens": 512, "generated_at": "2026-02-11T16:00:49.458458"}}
{"question": "What is Neptune Analytics' compliance with ACID and consistency?", "answer": "Neptune Analytics is ACID compliant with strong consistency.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:00:53.759085"}}
{"question": "How does Neptune Analytics handle vector search and indexing?", "answer": "Neptune Analytics supports a vector search index on embeddings (up to 65,000 dimensions) stored in your graph data. It uses Hierarchical Navigable Small Worlds (HNSW) for performing vector indexing and similarity search.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:00:53.759370"}}
{"question": "What is the difference between using a separate vector database and using Neptune Analytics for vector search?", "answer": "Using a separate vector database allows you to use different indexing and similarity search algorithms or multiple indices built on different properties, whereas Neptune Analytics provides efficient vector search that can be invoked directly from the openCypher query language and supports a single vector search index on embeddings.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:00:53.759725"}}
{"question": "Which machine learning techniques are supported by Neptune ML?", "answer": "Neptune ML supports node classification, multi-class classification, node regression, edge classification, single-class classification, edge regression, and link (edge) prediction.", "question_type": "factual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-11T16:00:57.292397"}}
{"question": "How does Neptune ML's machine learning capabilities benefit a user?", "answer": "Neptune ML offers various machine learning techniques to help users analyze and make predictions based on their graph data, enhancing their ability to gain insights and make informed decisions.", "question_type": "conceptual", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-11T16:00:57.292719"}}
{"question": "What is the difference between node regression and edge regression in Neptune ML?", "answer": "Node regression is used to predict a continuous target value for a node, while edge regression is used to predict a continuous target value for an edge in a graph.", "question_type": "comparison", "metadata": {"service": "NEPTUNE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "neptune-faq-11", "source_tokens": 90, "generated_at": "2026-02-11T16:00:57.293341"}}
{"question": "What is AWS Network Firewall and how does it work?", "answer": "AWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs). It can be set up with just a few clicks and scales automatically with your network traffic. The service lets you define firewall rules that give you fine-grained control over network traffic and works together with AWS Firewall Manager for centralized policy management.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-11T16:01:02.250636"}}
{"question": "What types of firewall rules can I create with AWS Network Firewall?", "answer": "AWS Network Firewall supports firewall rules based on domain, port, protocol, IP addresses, and pattern matching.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-11T16:01:02.250941"}}
{"question": "How does AWS Network Firewall compare to other firewall solutions in terms of rule management?", "answer": "AWS Network Firewall allows the use of custom firewall rules and works together with AWS Firewall Manager for centralized policy management. It supports thousands of rules.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-0", "source_tokens": 428, "generated_at": "2026-02-11T16:01:02.251343"}}
{"question": "What protocols can AWS Network Firewall identify based on traffic flows?", "answer": "AWS Network Firewall can identify various protocols based on traffic flows for enforcing policies.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-11T16:01:06.129631"}}
{"question": "How does AWS Network Firewall's web filtering feature work?", "answer": "AWS Network Firewall's web filtering feature stops traffic to known-bad URLs and monitors fully qualified domain names.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-11T16:01:06.130141"}}
{"question": "How does AWS Network Firewall compare to AWS Web Application Firewall for network security?", "answer": "AWS Network Firewall provides control and visibility to Layer 3-7 network traffic for your entire VPC, while AWS Web Application Firewall focuses on protecting web applications.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-1", "source_tokens": 507, "generated_at": "2026-02-11T16:01:06.130575"}}
{"question": "What is the regional availability information for AWS Network Firewall?", "answer": "The regional availability for AWS Network Firewall can be found on the AWS region table.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-11T16:01:10.926318"}}
{"question": "How can I deploy AWS Network Firewall for closer application security?", "answer": "AWS Network Firewall can be deployed within each Amazon VPC for distributed enforcement, which brings the firewall closer to the applications.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-11T16:01:10.927399"}}
{"question": "What are the two primary deployment types for AWS Network Firewall and how do they differ in terms of filtering capabilities?", "answer": "AWS Network Firewall offers two primary deployment types: centralized and distributed. With a centralized deployment, the firewall is attached to an AWS Transit Gateway, allowing filtering for a variety of traffic types to or from various gateways and subnets. In a distributed deployment, the firewall is deployed within each Amazon VPC for enforcement closer to the applications, and does not support the same level of filtering versatility.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-2", "source_tokens": 402, "generated_at": "2026-02-11T16:01:10.927578"}}
{"question": "What subnet size is required to deploy an AWS Network Firewall endpoint?", "answer": "AWS Network Firewall endpoint must be deployed in a dedicated subnet within your Amazon VPC, with a minimum size of /28.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-11T16:01:15.224971"}}
{"question": "How can you centrally manage AWS Network Firewall policies across multiple accounts?", "answer": "You may want to use AWS Firewall Manager to maintain policy and governance across multiple accounts.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-11T16:01:15.226470"}}
{"question": "What is the difference between stateless and stateful rules in AWS Network Firewall?", "answer": "Stateless rules consist of network access control lists (ACLs), which can be based on source and destination IP addresses, ports, or protocols. Stateful, or Layer-4, rules maintain and secure connections or sessions throughout the life of the connection or session.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-3", "source_tokens": 505, "generated_at": "2026-02-11T16:01:15.226777"}}
{"question": "What type of ENI is used for the AWS Network Firewall endpoint with AWS Gateway Load Balancer?", "answer": "The AWS Network Firewall endpoint with AWS Gateway Load Balancer uses a 'gateway_load_balancer_endpoint' type ENI.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T16:01:19.605844"}}
{"question": "Why is the hourly rate for secondary endpoints lower than the primary endpoint in AWS Network Firewall?", "answer": "The lower hourly rate for secondary endpoints in AWS Network Firewall is a cost reduction for associating multiple VPCs with one firewall.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T16:01:19.606177"}}
{"question": "How does pricing for AWS Network Firewall differ between primary and secondary endpoints?", "answer": "The primary firewall endpoint in an inspection VPC incurs the standard hourly rate per region and AZ, while secondary endpoints pay a reduced hourly rate per region and AZ.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-4", "source_tokens": 455, "generated_at": "2026-02-11T16:01:19.606353"}}
{"question": "What metrics are available for each VPC endpoint in AWS Network Firewall logs?", "answer": "The available metrics for each VPC endpoint in AWS Network Firewall logs are received packets, dropped packets, invalid dropped packets, other dropped packets, and passed packets.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T16:01:24.715432"}}
{"question": "How does the process of configuring AWS Network Firewall TLS inspection differ between the Amazon VPC Console and the Network Firewall API?", "answer": "The process of configuring AWS Network Firewall TLS inspection in the Amazon VPC Console and the Network Firewall API is the same, with three steps: 1) provision certificates and keys, 2) create a TLS inspection configuration, and 3) apply the configuration to a firewall policy.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T16:01:24.715743"}}
{"question": "How does active threat defense managed rule groups on AWS Network Firewall differ from existing Domain, IP and threat signature managed rule groups?", "answer": "Active threat defense managed rule groups on AWS Network Firewall differ from existing Domain, IP and threat signature managed rule groups in that they are based on Amazon threat intelligence. When an active threat is identified, AWS Network Firewall automatically applies managed rules to block the threat, offering an additional layer of protection.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-5", "source_tokens": 510, "generated_at": "2026-02-11T16:01:24.716130"}}
{"question": "What is the billing charge for traffic processed by AWS Network Firewall when active threat defense rule groups are enabled?", "answer": "You pay an additional charge for the amount of traffic processed by your firewall endpoint when active threat defense rule groups are enabled. This traffic is billed per gigabyte per region and Availability Zone.", "question_type": "factual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-11T16:01:29.775936"}}
{"question": "How does the use of active threat defense managed rule groups in AWS Network Firewall impact your security posture visibility?", "answer": "Through the Network Firewall console's active threat defense managed rule groups section, you gain enhanced visibility into your security posture, including details on indicator groups, indicator types, and specific threat names being mitigated.", "question_type": "conceptual", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-11T16:01:29.776189"}}
{"question": "How does the capacity of active threat defense managed rule groups in AWS Network Firewall compare to the default total limit of stateful rules?", "answer": "Active threat defense managed rule groups utilize a fixed rule capacity of 15,000, while the default total limit for stateful rules remains at 30,000 per firewall policy in a Region.", "question_type": "comparison", "metadata": {"service": "NETWORK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "network-faq-6", "source_tokens": 218, "generated_at": "2026-02-11T16:01:29.776562"}}
{"question": "What versions of OpenSearch and Elasticsearch are supported by Amazon OpenSearch Service?", "answer": "Amazon OpenSearch Service supports the latest versions of OpenSearch and several legacy versions of Elasticsearch up to version 7.10.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-11T16:01:34.152316"}}
{"question": "How can you create and manage Amazon OpenSearch Service domains?", "answer": "You can create and manage Amazon OpenSearch Service domains using the Amazon OpenSearch Service console, CLI, or API. Each domain is an OpenSearch or Elasticsearch cluster in the cloud with the resources you specify.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-11T16:01:34.152741"}}
{"question": "How does Amazon OpenSearch Service compare to self-managed Elasticsearch in terms of setup and configuration?", "answer": "Amazon OpenSearch Service makes it easier to set up and configure your OpenSearch or Elasticsearch clusters as it offers the latest versions, support for several legacy Elasticsearch versions, and visualization capabilities.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-0", "source_tokens": 432, "generated_at": "2026-02-11T16:01:34.152918"}}
{"question": "What administrative tasks does Amazon OpenSearch Service automate once a domain is running?", "answer": "Amazon OpenSearch Service automates common administrative tasks such as performing backups, monitoring instances, and patching software.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T16:01:38.309854"}}
{"question": "How does Amazon OpenSearch Service simplify the task of tailoring domains based on application needs?", "answer": "Amazon OpenSearch Service offers options to modify domain instance and storage settings to simplify the task of tailoring domains based on application needs.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T16:01:38.310166"}}
{"question": "What is the difference between running a single AZ and multiple AZs on Amazon OpenSearch Service for production workloads?", "answer": "Running production-grade workloads on a single AZ is not recommended. Customers should use two or three AZs to ensure higher availability and availability requirements.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-1", "source_tokens": 332, "generated_at": "2026-02-11T16:01:38.310617"}}
{"question": "What is Amazon OpenSearch Service and where does it currently run?", "answer": "Amazon OpenSearch Service is a fully managed service that lets users run and scale OpenSearch clusters without having to manage infrastructure or build expertise in operating OpenSearch clusters. It currently runs on AWS.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:01:43.421928"}}
{"question": "What are some use cases of OpenSearch and how does it help users analyze data?", "answer": "OpenSearch helps users more easily ingest, secure, search, aggregate, view, and analyze data for various use cases such as log analytics, application search, enterprise search, and more. It provides a highly scalable system for fast access and response to large volumes of data with an integrated visualization tool.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:01:43.422197"}}
{"question": "How does Amazon OpenSearch Service compare to running OpenSearch on premises or in other cloud platforms?", "answer": "Amazon OpenSearch Service is a fully managed service that lets users run and scale OpenSearch clusters without having to manage infrastructure or build expertise. OpenSearch can also be run on premises or in hybrid and multicloud environments on other cloud platforms.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:01:43.422457"}}
{"question": "What instance types can you specify when configuring a dedicated master node in Amazon OpenSearch Service?", "answer": "You can specify the instance type for a dedicated master node in Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:01:47.948310"}}
{"question": "Why would you choose to create multiple indices within the same Amazon OpenSearch Service domain?", "answer": "You might choose to create multiple indices within the same Amazon OpenSearch Service domain to make use of the automatic index distribution and management, reducing the need for manual administration.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:01:47.948675"}}
{"question": "What are the differences between using Amazon Kinesis Data Firehose and Logstash for data ingestion in Amazon OpenSearch Service?", "answer": "Amazon Kinesis Data Firehose is a fully managed service that automatically scales and requires no ongoing administration, while Logstash integration allows you to configure your Amazon OpenSearch Service domain as the data store for all logs arriving from your Logstash implementation.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:01:47.949177"}}
{"question": "What is the maximum storage capacity for a single Amazon OpenSearch Service domain with R6g.12xlarge instances and EBS gp3 storage?", "answer": "The maximum storage capacity for a single Amazon OpenSearch Service domain with R6g.12xlarge instances and EBS gp3 storage is 1920 TB.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:01:52.708827"}}
{"question": "Why is it recommended to deploy data instances across three AZs in Amazon OpenSearch Service?", "answer": "Deploying data instances across three AZs in Amazon OpenSearch Service offers better availability for production workloads.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:01:52.709870"}}
{"question": "What is the difference in storage capacity between enabling a three AZ deployment and a two AZ deployment in Amazon OpenSearch Service?", "answer": "Enabling a three AZ deployment in Amazon OpenSearch Service allows for more storage capacity compared to a two AZ deployment, but you will still only be charged for the number of instances in your domain.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:01:52.710390"}}
{"question": "How does Amazon OpenSearch Service handle unreachable instances in an Availability Zone (AZ)?", "answer": "Amazon OpenSearch Service automatically tries to bring up new instances in the same AZ to replace unreachable instances. If new instances cannot be brought up in the AZ, the service brings up new instances in other available AZs. Once the AZ issue resolves, the instances are rebalanced to be equally distributed across the AZs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-11T16:01:58.964091"}}
{"question": "Why is it recommended to configure three Availability Zones (AZs) for Amazon OpenSearch Service instead of two?", "answer": "In a three AZ domain, if an AZ is disrupted, the capacity loss is one-third of the total capacity. In contrast, in a two AZ domain, a disruption results in a capacity loss of half. Additionally, a three AZ domain allows for cross-AZ replication even when an AZ is disrupted.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-11T16:01:58.964532"}}
{"question": "How do I configure a specific number of Availability Zones (AZs) for my Amazon OpenSearch Service domain?", "answer": "The number of AZs your domain is deployed to corresponds to the number of subnets you have configured for your VPC domain. To enable three AZ deployment, you need to configure at least three subnets in your VPC domain.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-5", "source_tokens": 506, "generated_at": "2026-02-11T16:01:58.964727"}}
{"question": "What is the scaling process for Amazon OpenSearch Service domains like?", "answer": "Amazon OpenSearch Service allows you to control the scaling of your domains using the console, API, and CLI. You can add, remove, or modify instances and storage volumes as needed for your application. This process is an online operation with no downtime.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T16:02:03.887471"}}
{"question": "What metrics about Amazon OpenSearch Service domains can you find in Amazon CloudWatch?", "answer": "Amazon OpenSearch Service exposes several performance metrics through Amazon CloudWatch, including number of nodes, cluster health, searchable documents, EBS metrics (if applicable), CPU, memory, and disk utilization for data and master nodes.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T16:02:03.887714"}}
{"question": "How do snapshots of Amazon OpenSearch Service domains differ from automated hourly snapshots?", "answer": "A snapshot is a copy of an Amazon OpenSearch Service domain at a moment in time, while automated hourly snapshots are created by Amazon OpenSearch Service by default and retained for 14 days.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-6", "source_tokens": 490, "generated_at": "2026-02-11T16:02:03.887874"}}
{"question": "What are the daily snapshots in Amazon OpenSearch Service stored for?", "answer": "The daily snapshots in Amazon OpenSearch Service are stored for free in an Amazon OpenSearch Service S3 bucket for node recovery purposes.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-11T16:02:08.606589"}}
{"question": "Why would you create manual snapshots in Amazon OpenSearch Service?", "answer": "You would create manual snapshots in Amazon OpenSearch Service to store them in your S3 bucket and have them incur relevant Amazon S3 usage charges, in addition to the daily automated snapshots.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-11T16:02:08.606836"}}
{"question": "How does enabling slow logs for an index in Amazon OpenSearch Service impact performance and troubleshooting?", "answer": "Enabling slow logs for an index in Amazon OpenSearch Service allows you to fine-tune the index setup and performance by providing insights into the indexing process, and helps troubleshoot query and fetch performance issues by fine-tuning the performance of any kind of search operation on OpenSearch or Elasticsearch.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-7", "source_tokens": 454, "generated_at": "2026-02-11T16:02:08.607046"}}
{"question": "What happens when you enable slow logs in Amazon OpenSearch Service?", "answer": "When you enable slow logs in Amazon OpenSearch Service, it starts publishing the generated logs to CloudWatch Logs.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-11T16:02:12.515667"}}
{"question": "How can you control the logging granularity for slow logs in Amazon OpenSearch Service?", "answer": "You can control the logging granularity for slow logs in Amazon OpenSearch Service by setting the appropriate level in the configuration of your index.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-11T16:02:12.516016"}}
{"question": "What is the difference between slow logs and error logs in Amazon OpenSearch Service?", "answer": "Slow logs contain information about queries that take longer than a specified time limit to complete, while error logs contain information about errors that occur in OpenSearch Service.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-8", "source_tokens": 484, "generated_at": "2026-02-11T16:02:12.516190"}}
{"question": "What is the purpose of enabling slow logs in Amazon OpenSearch Service?", "answer": "Slow logs are used for troubleshooting indexes and fine-tuning performance in Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-11T16:02:16.171841"}}
{"question": "How can I process slow logs in real time with Amazon OpenSearch Service?", "answer": "You can process slow logs in real time using CloudWatch Logs and the AWS Lambda service.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-11T16:02:16.172105"}}
{"question": "What are the differences in logging settings for different versions of Elasticsearch in Amazon OpenSearch Service?", "answer": "Please refer to the Amazon OpenSearch Service documentation for details on the differences in logging settings for different versions of Elasticsearch.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-9", "source_tokens": 448, "generated_at": "2026-02-11T16:02:16.172298"}}
{"question": "What version of Elasticsearch is required for in-place version upgrades?", "answer": "In-place version upgrades are available for domains running Elasticsearch 5.x and above.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T16:02:20.202306"}}
{"question": "Why is a snapshot taken before an upgrade in Amazon OpenSearch Service?", "answer": "A snapshot is taken before an upgrade to ensure that the current state of the domain can be restored in case the upgrade fails.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T16:02:20.202579"}}
{"question": "How does the upgrade process in Amazon OpenSearch Service differ from a manual snapshot and upgrade?", "answer": "The upgrade process in Amazon OpenSearch Service automatically takes a snapshot, runs a set of tests, and starts the upgrade if the snapshot is successful. In contrast, a manual snapshot and upgrade require separate steps and more user intervention.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-10", "source_tokens": 485, "generated_at": "2026-02-11T16:02:20.202840"}}
{"question": "What happens during an in-place version upgrade in Amazon OpenSearch Service?", "answer": "During an in-place version upgrade, all the data in your cluster is also restored as part of the upgrade process.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-11T16:02:25.057814"}}
{"question": "Why would you choose to use Multi-AZ with Standby for your Amazon OpenSearch Service deployment?", "answer": "Multi-AZ with Standby is a deployment option for Amazon OpenSearch Service that ensures high-availability and consistent performance for business-critical workloads. It enables your cluster to be resilient to infrastructure failures and simplifies configuration and management.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-11T16:02:25.058054"}}
{"question": "How does the data setup differ between an in-place version upgrade and creating a new domain with a newer version in Amazon OpenSearch Service?", "answer": "During an in-place version upgrade, all the data in your cluster is restored as part of the upgrade process. Alternatively, you can create a new domain with the newer version and then restore your data to that domain.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-11", "source_tokens": 434, "generated_at": "2026-02-11T16:02:25.058211"}}
{"question": "What events does Multi-AZ with Standby automatically recover from in Amazon OpenSearch Service?", "answer": "Multi-AZ with Standby automatically recovers from loss of one active AZ or all nodes in an active AZ, loss of connectivity to one active AZ, instance hardware failure in the active AZ, or storage failure on a node in the active AZ.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T16:02:31.063362"}}
{"question": "How does the failure recovery process work with Multi-AZ with Standby in Amazon OpenSearch Service?", "answer": "With Multi-AZ with Standby, Amazon OpenSearch Service automatically fails over from active to standby nodes in under a minute when any of the specified events occur. The standby capacity acts as a failover target during AZ disruption or instance failure.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T16:02:31.063768"}}
{"question": "What is the difference between the capacity requirements for the 'Zone Awareness' option and Multi-AZ with Standby in Amazon OpenSearch Service?", "answer": "The primary difference is how redundant or additional capacity is handled to maintain availability. In Multi-AZ with Standby, you need to have at least one copy of data in each AZ to explicitly reserve capacity in one AZ as standby. In the existing model, you must maintain an optimal level of resources to serve your workload.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-12", "source_tokens": 454, "generated_at": "2026-02-11T16:02:31.063989"}}
{"question": "What is the cost model for using Multi-AZ with Standby on Amazon OpenSearch Service?", "answer": "You continue to pay for the resources deployed on the cluster to serve your workload. There is no extra cost for the Multi-AZ with Standby feature itself, but if your cluster is undersized or does not have enough redundant capacity, you will need to add capacity to use it.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-11T16:02:36.604242"}}
{"question": "How does using Multi-AZ with Standby enhance the performance and availability of my Amazon OpenSearch Service cluster?", "answer": "Multi-AZ with Standby provides enhanced availability and performance by maintaining a standby cluster that takes over if the primary cluster fails or becomes overloaded. It is important to ensure that your cluster is sized appropriately to avoid the need to add capacity.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-11T16:02:36.604498"}}
{"question": "What are the requirements for performing cross-cluster search between Amazon OpenSearch Service clusters?", "answer": "Both participating clusters must be on OpenSearch or Elasticsearch version 6.8 and above, have encryption in transit enabled, have Fine Grained Access Control (FGAC) enabled, and adhere to the same rules for rolling version upgrades.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-13", "source_tokens": 491, "generated_at": "2026-02-11T16:02:36.604652"}}
{"question": "Which instance families support cross-cluster search in Amazon OpenSearch Service?", "answer": "The i2, i3, r3, r4, r5, m4, m5, c4, c5, and Graviton families support cross-cluster search in Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-11T16:02:40.000202"}}
{"question": "Why are t2 and m3 families not supported for cross-cluster search in Amazon OpenSearch Service?", "answer": "This is due to technical limitations.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-11T16:02:40.000556"}}
{"question": "Can domains in two different AWS Regions participate in cross-cluster replication?", "answer": "Yes.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-14", "source_tokens": 307, "generated_at": "2026-02-11T16:02:40.001057"}}
{"question": "What version of OpenSearch was launched on July 12, 2021?", "answer": "OpenSearch version 1.0 was launched on July 12, 2021.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-11T16:02:43.855703"}}
{"question": "Why did AWS invest in OpenSearch and how does it benefit users?", "answer": "AWS invested in OpenSearch to ensure users continue to have a secure, high-quality, fully open source search and analytics suite with a rich roadmap of new and innovative functionality.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-11T16:02:43.855934"}}
{"question": "What is the difference between the old and new SDKs in terms of new functionality?", "answer": "The new SDK is required for implementing any new functionality that requires new configuration APIs.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-15", "source_tokens": 479, "generated_at": "2026-02-11T16:02:43.856172"}}
{"question": "What changes are there to pricing for upgrading to OpenSearch 1.x?", "answer": "There are no changes to pricing.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:02:48.171835"}}
{"question": "What features does OpenSearch 1.x offer compared to earlier versions?", "answer": "OpenSearch 1.x offers features such as enterprise-grade security, alerting, data-lifecycle management, observability, ML-based anomaly detection, and more.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:02:48.172196"}}
{"question": "What is the process for upgrading to OpenSearch 1.x?", "answer": "The process involves adding new nodes to the OpenSearch Service cluster, migrating data from the old nodes, and dropping the old nodes once the data migration is complete. Search and indexing APIs are available and function normally during this process, but some changes may cause dashboards to be unavailable.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:02:48.172711"}}
{"question": "What version of Elasticsearch is OpenSearch 1.x compatible with?", "answer": "OpenSearch 1.x is compatible with Elasticsearch version 7.10.2.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-11T16:02:52.506535"}}
{"question": "Why do you need to upgrade and enable compatibility mode when migrating to OpenSearch Service?", "answer": "You need to upgrade to Elasticsearch 7.10 and enable compatibility mode to ensure your existing clients can interoperate with OpenSearch Service, as some clients or tools perform version checks or leverage functionality targeted to older versions of Elasticsearch.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-11T16:02:52.509081"}}
{"question": "What is the difference between using Elasticsearch 5.x indices and OpenSearch 1.x indices?", "answer": "Elasticsearch 5.x indices are not compatible with OpenSearch 1.x. You must create new indices and load data from your source.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-17", "source_tokens": 506, "generated_at": "2026-02-11T16:02:52.509463"}}
{"question": "What version of Elasticsearch is OpenSearch 1.0 based on?", "answer": "OpenSearch 1.0 is based on Elasticsearch 7.10.2.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:02:56.261241"}}
{"question": "Why is compatibility mode important when transitioning from Elasticsearch to OpenSearch?", "answer": "Compatibility mode allows Elasticsearch clients to work with OpenSearch 1.0, making the transition process smoother.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:02:56.261601"}}
{"question": "How does the support structure differ between Elasticsearch and OpenSearch?", "answer": "OpenSearch provides Standard Support with regular bug fixes and security updates, followed by an Extended Support period. Elasticsearch offers only standard support for each engine version.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:02:56.262224"}}
{"question": "What is the additional charge for Extended Support in terms of Normalized Instance Hours (NIH) and size normalization factor?", "answer": "The additional charge for Extended Support is computed as a flat fee per NIH, which is $0.0065. The NIH is computed as the instance size factor (e.g., 2 for medium-sized instances) multiplied by the number of instance hours.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-11T16:03:02.040097"}}
{"question": "Why do you need to pay an additional fee for Extended Support in OpenSearch Service?", "answer": "You need to pay an additional fee for Extended Support because your domain is running a version that is no longer covered under Standard Support. This fee covers the costs associated with providing extended support for your domain.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-11T16:03:02.040355"}}
{"question": "How does the cost of Extended Support compare to the cost of Standard Support in OpenSearch Service?", "answer": "The cost of Extended Support includes both the standard instance usage cost (excluding storage) and the Extended Support cost. For example, if the standard instance cost is $1.632 and the Extended Support cost is $0.312 for 24 hours, the total cost would be $1.944.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-19", "source_tokens": 485, "generated_at": "2026-02-11T16:03:02.040737"}}
{"question": "What happens when Extended Support ends for a version of Amazon OpenSearch Service?", "answer": "Domains running the specific version will no longer receive bug fixes or security updates. They will be isolated and data preserved for at least 30 days, after which they can no longer be accessed.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-11T16:03:06.451020"}}
{"question": "Why is it recommended to upgrade Amazon OpenSearch Service to a supported version before Extended Support ends?", "answer": "To ensure that you continue to receive bug fixes and security updates, which are essential for maintaining the security and reliability of your domain.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-11T16:03:06.451349"}}
{"question": "How does the zero-ETL integration with Amazon DynamoDB compare to traditional data pipelines for keeping Amazon OpenSearch Service and Amazon DynamoDB in sync?", "answer": "The zero-ETL integration offers a fully managed solution for making operational data from Amazon DynamoDB available in Amazon OpenSearch Service within seconds. It abstracts away the operational complexity and intermittent errors commonly associated with traditional data pipelines.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-20", "source_tokens": 439, "generated_at": "2026-02-11T16:03:06.451749"}}
{"question": "What AWS services are involved in the zero-ETL integration between Amazon DynamoDB and Amazon OpenSearch Service?", "answer": "The zero-ETL integration uses Amazon DynamoDB, Amazon OpenSearch Service, Amazon OpenSearch Ingestion, and IAM.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-11T16:03:11.429963"}}
{"question": "How does the zero-ETL integration of Amazon DynamoDB and Amazon OpenSearch Service facilitate data transformation?", "answer": "The integration leverages the native data transformational capabilities of Amazon OpenSearch Ingestion pipelines to aggregate, filter, and even write custom logic for data transformation.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-11T16:03:11.430231"}}
{"question": "What is the difference between setting up a custom Amazon OpenSearch Ingestion pipeline and using out-of-the-box blueprints for data integration?", "answer": "Custom pipelines allow users to drop fields, create new fields based on aggregations, and write custom logic for transformations. On the other hand, out-of-the-box blueprints enable users to perform integrations with just a few button clicks.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-21", "source_tokens": 466, "generated_at": "2026-02-11T16:03:11.430414"}}
{"question": "What metrics can be viewed related to a zero-ETL integration with Amazon DynamoDB on Amazon OpenSearch Ingestion dashboards?", "answer": "All metrics related to a zero-ETL integration with Amazon DynamoDB can be viewed on the dashboards provided by Amazon OpenSearch Ingestion.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-11T16:03:16.304854"}}
{"question": "Why is it beneficial for customers to use the new integration's built-in query acceleration capabilities in OpenSearch Service?", "answer": "Customers can boost the performance of their queries and build fast-loading dashboards using the new integration's built-in query acceleration capabilities in OpenSearch Service.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-11T16:03:16.305214"}}
{"question": "How does OpenSearch Service querying data in Amazon S3 compare to querying data from DynamoDB using the new integration?", "answer": "OpenSearch Service queries data directly from Amazon S3 without duplicating data, offering performance benefits and the ability to build custom alerting and dashboards based on user-defined thresholds.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-22", "source_tokens": 399, "generated_at": "2026-02-11T16:03:16.305777"}}
{"question": "What units are used to measure compute capacity in OpenSearch Service?", "answer": "OpenSearch Compute Units (OCUs) are used to measure compute capacity in OpenSearch Service.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-11T16:03:21.669768"}}
{"question": "How does the integration between OpenSearch Service and Security Lake work conceptually?", "answer": "Integration between OpenSearch Service and Security Lake can be done through query-access or data-access. With query-access, analysts can run direct queries on Security Lake data using OpenSearch Dashboards. With data-access, OpenSearch ingestion service provides a preconfigured blueprint for ingesting OCSF parquet files from Security Lake. The zero-ETL integration is only available on collections with OpenSearch UI.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-11T16:03:21.670131"}}
{"question": "How does the billing for OpenSearch Service and Security Lake compare?", "answer": "OpenSearch Service charges for compute capacity used to query external data and maintain optional indexes, while costs for Amazon S3 and AWS Glue Data Catalog are billed separately. Security Lake is integrated with OpenSearch Service through query-access or data-access, but the billing for these two services remains separate.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-23", "source_tokens": 394, "generated_at": "2026-02-11T16:03:21.670712"}}
{"question": "What is required to enable the integration between AWS Security Lake and Amazon OpenSearch Service?", "answer": "To enable the integration between AWS Security Lake and Amazon OpenSearch Service, you need an existing Security Lake setup in your AWS environment, and you need to configure the necessary permissions and access controls to allow OpenSearch Service to securely access and query the data in your Security Lake.", "question_type": "factual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-11T16:03:27.544642"}}
{"question": "How does the integration between AWS Security Lake and Amazon OpenSearch Service work conceptually?", "answer": "The integration between AWS Security Lake and Amazon OpenSearch Service allows you to use the pre-built queries and integrations available through OCSF to perform common security analytics use cases. You also have the option to configure on-demand indexing of specific data sets from your Security Lake into OpenSearch Service for advanced analytics and visualization needs.", "question_type": "conceptual", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-11T16:03:27.544919"}}
{"question": "What is the difference between using pre-built queries and integrations in OCSF and configuring on-demand indexing in terms of advanced analytics needs?", "answer": "Using pre-built queries and integrations in OCSF allows you to quickly get started with common security analytics use cases. Configuring on-demand indexing of specific data sets from your Security Lake into OpenSearch Service is an option for advanced analytics and visualization needs, providing more customized and detailed analysis.", "question_type": "comparison", "metadata": {"service": "OPENSEARCH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "opensearch-faq-24", "source_tokens": 152, "generated_at": "2026-02-11T16:03:27.545341"}}
{"question": "What are the capabilities of AWS Organizations for managing AWS accounts and resources?", "answer": "AWS Organizations enables automating AWS account creation and management, maintaining a secure environment with policies and management of AWS security services, governing access to AWS services, resources, and regions, centrally managing policies across multiple AWS accounts, auditing environments for compliance, viewing and managing costs with consolidated billing, and configuring AWS services across multiple accounts.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T16:03:34.378552"}}
{"question": "How does AWS Organizations help in managing and governing a large number of AWS accounts?", "answer": "AWS Organizations helps in managing and governing a large number of AWS accounts by providing capabilities to programmatically create new accounts, allocate resources, simplify billing, create groups of accounts to organize workflows, and apply policies for governance. It also integrates with other AWS services to define central configurations, security mechanisms, and resource sharing across accounts.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T16:03:34.378914"}}
{"question": "What are the differences between AWS Organizations and AWS Control Tower in managing AWS environments?", "answer": "AWS Organizations is a service that helps you centrally govern your AWS environment by enabling automating AWS account creation and management, maintaining a secure environment, governing access to AWS services and resources, centrally managing policies, auditing environments, and managing costs. AWS Control Tower, on the other hand, is a service that helps create and manage a multi-account AWS environment with built-in best practices. It automates setup, provides prescriptive guidance, and offers flexible controls to simplify multi-account management.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-0", "source_tokens": 463, "generated_at": "2026-02-11T16:03:34.379473"}}
{"question": "What is the role of a management account in an AWS organization?", "answer": "A management account is the AWS account used to create and manage an AWS organization. It provides administrative capabilities for access and billing, and serves as the ultimate owner of the organization with final control over security, infrastructure, and finance policies.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T16:03:39.186116"}}
{"question": "Why is using multiple AWS accounts a best practice in an AWS organization?", "answer": "Using multiple AWS accounts in an AWS organization provides a natural billing boundary for costs, isolates resources for security, and offers flexibility for individuals and teams. It is also adaptable for new business processes.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T16:03:39.186469"}}
{"question": "What is the difference between a management account and a member account in an AWS organization?", "answer": "A management account is the AWS account used to create and manage the organization, providing administrative capabilities and serving as the ultimate owner. A member account is an AWS account that is part of an organization, which can be created and managed by the management account and subject to policies.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-1", "source_tokens": 373, "generated_at": "2026-02-11T16:03:39.186682"}}
{"question": " What type of policies can I use in AWS Organizations to control permissions for IAM users and roles?", "answer": " You can use Service control policies (SCPs) for this purpose.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-11T16:03:43.752296"}}
{"question": " How do OUs and policies work together in AWS Organizations?", "answer": " OUs are used to group AWS accounts and apply the same controls to a subset of accounts. Policies, such as SCPs and RCPs, are used to centrally control permissions for IAM users, IAM roles, and resources in an organization.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-11T16:03:43.752675"}}
{"question": " What's the difference between a declarative policy and a resource control policy in AWS Organizations?", "answer": " Declarative policies help enforce durable intent for a given AWS service with a few clicks or commands, preventing non-compliant actions. Resource control policies offer central control over the maximum available permissions for resources in an organization.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-2", "source_tokens": 447, "generated_at": "2026-02-11T16:03:43.753025"}}
{"question": "What method allows you to add an existing AWS account to your organization?", "answer": "You can add an existing AWS account to your organization by inviting it to join. This involves providing the email address or AWS account ID of the account and allowing the account's administrator to accept or reject the invitation.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:03:48.990174"}}
{"question": "How can you add a new AWS account to your organization and what happens after the addition?", "answer": "You can add a new AWS account to your organization by either inviting an existing one or creating a new one. When you add a new account, it will automatically inherit the policies attached to the organizational unit (OU) it is moved to.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:03:48.990548"}}
{"question": "What's the difference between inviting an existing AWS account and creating a new one in your organization?", "answer": "The difference lies in the creation process. When you invite an existing account, you provide its email address or AWS account ID and let its administrator accept or reject the invitation. When you create a new account, you provide a name and email address and it is automatically added to your organization.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:03:48.990969"}}
{"question": "What permissions does AWS Organizations grant to an IAM role in a new account during creation?", "answer": "AWS Organizations grants full administrative permissions to an IAM role in a new account.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T16:03:53.102871"}}
{"question": "Why do you need to update information when making an account standalone in AWS Organizations?", "answer": "You need to update the contact information, provide a valid payment method, and choose a support plan option when making an account standalone in AWS Organizations.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T16:03:53.103229"}}
{"question": "How does the process of removing a member account from an organization differ between the master account and the member account?", "answer": "In the master account, you can directly remove the member account from the Organizations console. In contrast, the member account must choose to leave the organization from its side.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-4", "source_tokens": 499, "generated_at": "2026-02-11T16:03:53.103457"}}
{"question": "What steps are required to create an Organizational Unit (OU) in AWS?", "answer": "To create an OU, sign in as an administrator of the management account, navigate to the AWS Organizations console, choose the Organize accounts tab, navigate to where you want to create the OU, choose Create organizational unit, and provide a unique name for your OU.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-11T16:03:57.812064"}}
{"question": "How can you manage an AWS account's membership in an Organizational Unit (OU)?", "answer": "You can move an AWS account to an OU in the AWS Organizations console or use the AWS CLI and APIs.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-11T16:03:57.812437"}}
{"question": "What's the difference between adding an AWS account to an OU versus moving an account to an OU?", "answer": "Adding an AWS account to an OU means granting the account membership, while moving an account to an OU transfers the account's root account permissions.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-5", "source_tokens": 373, "generated_at": "2026-02-11T16:03:57.812892"}}
{"question": "Which ways can I attach a policy in AWS Organizations?", "answer": "You can attach a policy in AWS Organizations by navigating to the desired location (root, OU, or account) and choosing 'Attach Policy'. Alternatively, you can use the 'Policies' tab, choose 'Attach Policy' from the 'Actions' drop-down list, and select the target location.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-11T16:04:03.077280"}}
{"question": "What are the different types of policies available in AWS Organizations?", "answer": "AWS Organizations supports the following types of policies: Service control policies (SCPs), resource control policies (RCPs), declarative policies, backup policies, tag policies, chatbot policies, and AI services opt-out policies.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-11T16:04:03.077637"}}
{"question": "What is the difference between attaching a policy through 'Attach Policy' and creating a new policy?", "answer": "Attaching a policy involves selecting an existing policy and applying it to a specific location (root, OU, or account). Creating a new policy involves defining a policy from scratch and attaching it to a location during the policy creation workflow.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-6", "source_tokens": 427, "generated_at": "2026-02-11T16:04:03.078133"}}
{"question": "What actions are allowed by an SCP for EC2 services?", "answer": "An SCP can allow or deny specific AWS service actions for EC2 in an account.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:04:06.826054"}}
{"question": "Why is an SCP necessary even if IAM policies are in place?", "answer": "An SCP determines the overall access control for a principal in an account, as the effective permissions are the intersection of what is allowed by the SCP and the IAM policies.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:04:06.826420"}}
{"question": "What happens if an SCP allows different actions than an IAM policy for the same principal?", "answer": "The resultant permission for the principal is the intersection of the allowed actions by the SCP and the IAM policy. If the SCP allows different actions than the IAM policy, the principal can only perform the actions allowed by the SCP.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:04:06.826946"}}
{"question": "What is the role of the IAM policy simulator regarding SCPs?", "answer": "The IAM policy simulator can include the effects of SCPs. It allows an administrator in a member account to understand the impact on individual principals in that account.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-11T16:04:10.963862"}}
{"question": "How does using RCPs help in an organization?", "answer": "RCPs enable centralized setting of maximum permissions for AWS resources in your organization. They help restrict access to resources to only identities within your organization or specify conditions for external identities to access.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-11T16:04:10.964118"}}
{"question": "What's the difference between SCPs and declarative policies?", "answer": "SCPs define and enforce preventative controls on AWS resources, while declarative policies help enforce durable intent for a given AWS service with a baseline configuration.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-8", "source_tokens": 360, "generated_at": "2026-02-11T16:04:10.964274"}}
{"question": "What is the purpose of declarative policies in AWS IAM?", "answer": "Declarative policies in AWS IAM offer a simpler way to define the configuration, provide end users with visibility into why their actions failed, and maintain the configuration once set. They do not require updating with new APIs to protect the configuration objective.", "question_type": "conceptual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-11T16:04:15.594045"}}
{"question": "What is the difference between SCPs and declarative policies in AWS IAM?", "answer": "SCPs offer central control over the maximum available permissions for IAM users and IAM roles in an organization, while declarative policies provide a simpler way to define and maintain the configuration, with visibility into why actions failed.", "question_type": "comparison", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-11T16:04:15.594253"}}
{"question": "Which AWS services can be integrated with AWS Organizations for centralized management and configuration?", "answer": "AWS services that can be integrated with AWS Organizations include, but are not limited to, Amazon S3, IAM, CloudFormation, and Config.", "question_type": "factual", "metadata": {"service": "ORGANIZATIONS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "organizations-faq-9", "source_tokens": 420, "generated_at": "2026-02-11T16:04:15.594385"}}
{"question": "What are some common use cases for AWS Outposts racks?", "answer": "AWS Outposts racks can be used to support applications with low latency or local data processing requirements. These applications may need to generate near real-time responses to end user applications or communicate with other on-premises systems or control on-site equipment. Use cases include manufacturing automated operations, real-time patient diagnosis and medical imaging, and content and media streaming. Outposts racks can also be used to securely store and process customer data that needs to remain on-premises or in countries where there is no AWS Region.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-11T16:04:20.882339"}}
{"question": "Why would you use Outposts racks for processing data locally instead of transmitting it to AWS Regions?", "answer": "Transmitting data to AWS Regions can be expensive and wasteful, especially for data-intensive workloads. Outposts racks allow you to process data locally, providing better control on data analysis, backup and restore.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-11T16:04:20.882651"}}
{"question": "What AWS services can you run on Outposts racks?", "answer": "You can run 9 AWS services on Outposts racks.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-0", "source_tokens": 242, "generated_at": "2026-02-11T16:04:20.883018"}}
{"question": "Which AWS Regions support first-generation Outposts?", "answer": "The following AWS Regions support first-generation Outposts: US East (N. Virginia) (us-east-1), US East (Ohio) (us-east-2), US West (N. California) (us-west-1), US West (Oregon) (us-west-2), Canada (Central) (ca-central-1), South America (SÃ£o Paulo) (sa-east-1), EU (Frankfurt) (eu-central-1), EU (Stockholm) (eu-north-1), EU (Ireland) (eu-west-1), EU (London) (eu-west-2), EU (Paris) (eu-west-3), EU (Milan) (eu-south-1), EU (Spain) (eu-south-2), Middle East (Bahrain) (me-south-1), Middle East (UAE) (me-central-1), Israel (Tel Aviv) (il-central-1), Africa (Cape Town) (af-south-1), Asia Pacific (Singapore) (ap-southeast-1), Asia Pacific (Sydney) (ap-southeast-2), Asia Pacific (Jakarta) (ap-southeast-3), Asia Pacific (Tokyo) (ap-northeast-1), Asia Pacific (Seoul) (ap-northeast-2), Asia Pacific (Osaka) (ap-northeast-3), Asia Pacific (Mumbai) (ap-south-1), AWS GovCloud (US-West) (us-gov-west-1), AWS GovCloud (US-East) (us-gov-east-1).", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T16:04:38.559067"}}
{"question": "What's the difference between first-generation and second-generation Outposts in terms of supported AWS Regions?", "answer": "First-generation Outposts are supported in the following AWS Regions: US East (N. Virginia) (us-east-1), US East (Ohio) (us-east-2), US West (N. California) (us-west-1), US West (Oregon) (us-west-2), Canada (Central) (ca-central-1), South America (SÃ£o Paulo) (sa-east-1), EU (Frankfurt) (eu-central-1), EU (Stockholm) (eu-north-1), EU (Ireland) (eu-west-1), EU (London) (eu-west-2), EU (Paris) (eu-west-3), EU (Milan) (eu-south-1), EU (Spain) (eu-south-2), Middle East (Bahrain) (me-south-1), Middle East (UAE) (me-central-1), Israel (Tel Aviv) (il-central-1), Africa (Cape Town) (af-south-1), Asia Pacific (Singapore) (ap-southeast-1), Asia Pacific (Sydney) (ap-southeast-2), Asia Pacific (Jakarta) (ap-southeast-3), Asia Pacific (Tokyo) (ap-northeast-1), Asia Pacific (Seoul) (ap-northeast-2), Asia Pacific (Osaka) (ap-northeast-3), Asia Pacific (Mumbai) (ap-south-1), AWS GovCloud (US-West) (us-gov-west-1), AWS GovCloud (US-East) (us-gov-east-1). Second-generation Outposts are also supported in the same AWS Regions.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T16:04:38.559418"}}
{"question": "Why would you use first-generation Outposts instead of second-generation Outposts?", "answer": "First-generation Outposts can be used instead of second-generation Outposts if the specific use case requires the support of the AWS Regions in which first-generation Outposts are available and not the ones in which second-generation Outposts are available. However, it's important to note that second-generation Outposts offer improved functionality and performance compared to first-generation Outposts. Therefore, if the use case allows, it's usually recommended to use second-generation Outposts instead.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-1", "source_tokens": 512, "generated_at": "2026-02-11T16:04:38.559659"}}
{"question": "Which AWS Regions are currently supported in Europe and Canada?", "answer": "[ca-central-1, eu-west-2, eu-west-3]", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-11T16:04:42.078582"}}
{"question": "Why is it essential to consult with an AWS sales representative or APN partner when choosing a home Region?", "answer": "They can help evaluate available options in your geography, provide recommendations on service link bandwidth and latency requirements for your workloads.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-11T16:04:42.078949"}}
{"question": "How does the latency and bandwidth requirement vary between the eu-west-2 and eu-west-3 Regions?", "answer": "The text does not provide enough information for a comparison question.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-2", "source_tokens": 110, "generated_at": "2026-02-11T16:04:42.079408"}}
{"question": "Which countries and territories can first-generation Outposts racks be shipped to and installed in?", "answer": "First-generation Outposts racks can be shipped to and installed in the following countries and territories: NA - US, Canada, Mexico; EMEA - All EU countries, United Kingdom (UK), Switzerland, Norway, Bahrain, the United Arab Emirates (UAE), Israel, South Africa, Gibraltar, Morocco, Nigeria, Kenya, Oman, Kazakhstan, Serbia, Qatar, Egypt, Iceland, Turkey, the Kingdom of Saudi Arabia, Senegal, Jordan, Kuwait; APAC - Australia, New Zealand, Japan, South Korea, Taiwan, Singapore, Indonesia, Malaysia, Thailand, the Philippines, Brunei, India, Vietnam, Bangladesh; SA - Brazil, Colombia, Argentina, Chile, Peru, Ecuador, Trinidad and Tobago, Uruguay, CA - Puerto Rico, Costa Rica, Panama, Guatemala.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-11T16:04:51.848501"}}
{"question": "Why is an AWS Outpost reliant on connectivity to the parent AWS Region?", "answer": "An AWS Outpost is reliant on connectivity to the parent AWS Region as Outposts racks are not designed for disconnected operations or environments with limited to no connectivity. Customers are recommended to have highly available networking connections back to their AWS Region.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-11T16:04:51.848886"}}
{"question": "How does the availability of first-generation Outposts racks compare between EMEA and APAC regions?", "answer": "First-generation Outposts racks can be shipped to and installed in the following EMEA countries and territories: All EU countries, United Kingdom (UK), Bahrain, the United Arab Emirates (UAE), Israel, Kenya, Egypt, Iceland, Turkey, the Kingdom of Saudi Arabia, Jordan, Kuwait. They can also be shipped to and installed in the following APAC countries and territories: Australia, New Zealand, Japan, South Korea, Taiwan, Singapore, Indonesia, Malaysia, Thailand, the Philippines, Brunei, Vietnam. The list of countries for both regions is quite similar, but there are some differences. For example, EMEA includes Morocco, Nigeria, and Senegal, while APAC includes India and Bangladesh.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-3", "source_tokens": 496, "generated_at": "2026-02-11T16:04:51.849127"}}
{"question": "What type of infrastructure does AWS Outposts racks use?", "answer": "AWS Outposts racks use AWS-designed infrastructure.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-11T16:04:55.836910"}}
{"question": "How does the management of AWS Outposts racks differ from other AWS services?", "answer": "AWS Outposts racks are a fully managed service, providing native access to AWS services with no additional effort or configuration required on-site.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-11T16:04:55.837278"}}
{"question": "How does the compute and storage infrastructure of AWS Outposts racks compare to that of first-generation Outposts racks?", "answer": "AWS Outposts racks offer a range of options for compute and storage infrastructure, allowing you to order as much as needed. S3 on Outposts is currently available on first-generation Outposts racks only.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-4", "source_tokens": 217, "generated_at": "2026-02-11T16:04:55.837813"}}
{"question": "What are the primary benefits of second-generation Outposts racks regarding scaling and resiliency?", "answer": "Second-generation Outposts racks offer simplified scaling and built-in resiliency. The introduction of the network rack enables seamless deployment of AWS Outpost racks in on-premises or co-location spaces, decoupling of compute and networking, and eliminating the need for multiple uplinks between compute racks and on-premises customer managed switches. The network rack also comes with built-in resiliency to handle switch failures.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T16:05:04.033394"}}
{"question": "How do second-generation Outposts racks support running the latest in-Region EC2 instance types differently than the previous generation?", "answer": "Second-generation Outposts racks support the latest in-Region EC2 instance types, enabling customers to run a broader range of on-premises workloads with even better performance. Newly supported instance types include M7i, C7i, and R7i, which deliver 2x the vCPU, memory, and network bandwidth and up to 40% better performance compared to C5, M5, and R5 instances on first-generation Outposts racks.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T16:05:04.033755"}}
{"question": "How do second-generation Outposts racks differ in terms of instance types and networking compared to first-generation Outposts racks?", "answer": "Second-generation Outposts racks introduce a new category of Outposts-specific Amazon EC2 instances, e.g., Bmn-sf2e and Bmn-cx2. These new instances have accelerated networking, designed for ultra-low latency and throughput-intensive workloads. Additionally, second-generation Outposts racks support the latest in-Region EC2 instance types, which deliver better performance compared to the previous generation.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-5", "source_tokens": 502, "generated_at": "2026-02-11T16:05:04.034226"}}
{"question": "What type of EBS volumes can be used when launching EC2 instances on second-generation Outposts racks?", "answer": "EC2 instances can be launched using the AMIs backed with EBS gp2 or gp3 volume types on second-generation Outposts racks.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:05:09.611328"}}
{"question": "How does storing EBS snapshots locally on an Outpost impact data residency?", "answer": "Setting resource-level IAM policies and permissions on your Outpost for EBS Local Snapshots allows you to enforce data residency and block the creation or copy of local snapshots and images outside the specified Outposts rack ARN. All operations are logged in CloudTrail audit logs.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:05:09.611593"}}
{"question": "What are the benefits of using S3 on Outposts for customers with data residency requirements?", "answer": "S3 on Outposts, available on first-generation Outposts racks, is ideal for customers with data residency requirements or those in regulated industries. It allows them to securely store and process customer data on premises, run data-intensive workloads locally, and communicate with other on-premises systems or control on-site equipment.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:05:09.611754"}}
{"question": "What are the three ways to establish a VPN connection from an Outposts rack service to the parent AWS Region?", "answer": "You can establish a VPN connection to the parent AWS Region via an AWS Direct Connect private connection, a public virtual interface, or the public Internet.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T16:05:15.283317"}}
{"question": "How can I run managed databases on Outposts racks for low latency workloads?", "answer": "You can run managed Microsoft SQL Server, MySQL, and PostgreSQL databases on premises for low latency workloads using Amazon RDS on Outposts. This allows you to manage the databases both in the cloud and on-premises using the same AWS Management Console, APIs, and CLI.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T16:05:15.283620"}}
{"question": "What is the difference between storing data on S3 on Outposts versus replicating it to AWS Regions?", "answer": "S3 on Outposts stores data on your Outpost by default, while you may choose to replicate some or all of your data to AWS Regions based on your specific data residency requirements. The main difference is that data stored on S3 on Outposts remains on the Outposts rack, while replicated data is stored in the AWS Region.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-7", "source_tokens": 476, "generated_at": "2026-02-11T16:05:15.283817"}}
{"question": "Which AWS resources can be shared using AWS Resource Access Manager (RAM)?", "answer": "AWS resources that can be shared using AWS Resource Access Manager (RAM) include EC2 instances, EBS volumes, subnets, and local gateways (LGWs).", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:05:20.556313"}}
{"question": "How does using Route 53 Resolver on AWS Outposts improve the performance of on-premises applications?", "answer": "Using Route 53 Resolver on AWS Outposts improves the performance of on-premises applications by serving DNS responses locally and enabling low-latency DNS resolution.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:05:20.556582"}}
{"question": "What is the difference between using Route 53 Resolver on AWS Outposts and in the parent AWS Region for DNS resolution?", "answer": "The main difference is that when you enable Route 53 Resolver on Outposts, Route 53 automatically stores DNS responses on Outposts racks and provides continued DNS resolution for your applications during unexpected network disconnects to the parent AWS Region. This improves the availability and performance of on-premises applications.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:05:20.556739"}}
{"question": "What are the power requirements for a first-generation Outposts rack?", "answer": "A first-generation Outposts rack needs 5-15 kVA.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:05:24.346602"}}
{"question": "How does the power requirement differ between first- and second-generation Outposts racks?", "answer": "A first-generation Outposts rack needs 5-15 kVA and a second-generation Outposts rack needs 10-30 kVA.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:05:24.346971"}}
{"question": "What are the networking uplink options for Outposts racks?", "answer": "Outposts racks support 1/10/40/100 Gbps uplinks.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:05:24.347184"}}
{"question": "What security measure ensures customer data is destroyed when an AWS Outposts rack is returned?", "answer": "The Nitro Security Key, which wraps customer data, is removed before the Outposts rack hardware is returned to ensure the data is crypto shredded.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-11T16:05:28.877361"}}
{"question": "What is the role of customers in ensuring GxP compliance in relation to AWS Outposts?", "answer": "Customers are responsible for designing and verifying their GxP compliance when using AWS Outposts, while AWS provides services and controls to help with data encryption and security.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-11T16:05:28.877724"}}
{"question": "Which AWS services follow the updated Shared Responsibility Model for managing network accelerator cards and switches?", "answer": "Bmn-sf2 and Bmn-cx2 instances have an updated Shared Responsibility Model where customers manage the network accelerator cards inside the servers and the associated bare metal network switches.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-10", "source_tokens": 481, "generated_at": "2026-02-11T16:05:28.877945"}}
{"question": "What information is sent back to the parent AWS Region from an Outpost regarding instances?", "answer": "Information about instance health, instance activity (launched, stopped), and the underlying hypervisor system is sent back to the parent AWS Region from an Outpost.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T16:05:33.899391"}}
{"question": "Why does AWS monitor an Outpost's instance health and capacity?", "answer": "AWS monitors an Outpost's instance health and capacity to provide alerting on instance health and capacity, and to apply patches and updates to the Outpost.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T16:05:33.899645"}}
{"question": "How does data management and telemetry data handling differ between EC2 instances and S3 on Outposts during disconnected periods?", "answer": "For EC2 instances, information about instance health, instance activity (launched, stopped), and underlying hypervisor system is sent back to the parent AWS Region, enabling alerting on instance health and capacity and applying patches and updates to the Outpost. For S3 on Outposts, certain data management and telemetry data, such as bucket names and metrics, may be stored in the AWS Region for reporting and management. However, during disconnected periods, this information cannot be sent back to the parent Region.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-11", "source_tokens": 502, "generated_at": "2026-02-11T16:05:33.899810"}}
{"question": "What are the two ways to expand the compute and storage capacity of an AWS Outposts rack?", "answer": "You can increase capacity by adding additional Outposts racks or by upgrading the configuration of existing racks.", "question_type": "factual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-11T16:05:37.832827"}}
{"question": "How can you expand the capacity of an existing AWS Outposts rack?", "answer": "If your existing racks have available power and positions within the rack, you can upgrade from a â€˜smallâ€™ to a â€˜mediumâ€™ or â€˜largeâ€™ configuration.", "question_type": "conceptual", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-11T16:05:37.833185"}}
{"question": "What's the difference between expanding an AWS Outposts rack by adding more racks and upgrading its configuration?", "answer": "Adding more racks increases the overall capacity, while upgrading the configuration of an existing rack increases the capacity of that specific rack.", "question_type": "comparison", "metadata": {"service": "OUTPOSTS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "outposts-faq-12", "source_tokens": 118, "generated_at": "2026-02-11T16:05:37.833426"}}
{"question": "What is Amazon Personalize and how does it work?", "answer": "Amazon Personalize is a fully managed machine learning service that uses customer data (age, location, device type, interactions with items) to generate personalized product, content, and service recommendations. It uses algorithms to analyze customer behavior and train custom models that can be surfaced via an API.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-11T16:05:42.895325"}}
{"question": "What types of data does Amazon Personalize require to generate recommendations?", "answer": "Amazon Personalize requires data about end-users (age, location, device type), items in the catalog (genre, price), and interactions between users and items (clicks, purchases).", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-11T16:05:42.895586"}}
{"question": "How does Amazon Personalize compare to other recommendation services that don't use real-time data insights?", "answer": "Amazon Personalize uses real-time data insights to deliver recommendations that are personalized instantaneously depending on the userâ€™s behavior. This contrasts with other recommendation services that may not use real-time data and therefore may not be able to provide personalized recommendations as frequently.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-0", "source_tokens": 310, "generated_at": "2026-02-11T16:05:42.895731"}}
{"question": "What benefit can businesses derive from Amazon Personalize in terms of user engagement and conversion rates?", "answer": "Businesses can improve user engagement and conversion rates by offering personalized recommendations that are tailored to their users' preferences.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-11T16:05:47.168553"}}
{"question": "How can Amazon Personalize help businesses enhance their customer experience?", "answer": "Amazon Personalize enables businesses to surface products and services that are more relevant to their users' needs and interests, resulting in a better customer experience.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-11T16:05:47.168910"}}
{"question": "In what ways does Amazon Personalize differ from other solutions for scaling personalization in a cost-effective manner?", "answer": "Amazon Personalize is a cloud-based, machine learning service that can handle massive volumes of user data and produce tailored recommendations for millions of users. This sets it apart from other solutions that may be more time-consuming or resource-intensive.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-1", "source_tokens": 208, "generated_at": "2026-02-11T16:05:47.169143"}}
{"question": "What are some digital channels where Amazon Personalize can be used for personalizing the end-user experience?", "answer": "Amazon Personalize can be used for personalizing the end-user experience over any digital channel, such as product recommendations for e-commerce, news articles, publications, media and social networks, hotel recommendations for travel websites, credit card recommendations for banks, and match recommendations for dating sites.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-11T16:05:52.815049"}}
{"question": "How can Amazon Personalize be used to create a more personalized experience for users in a meal delivery company?", "answer": "Amazon Personalize can be used by a meal delivery company to personalize weekly meals for users in a subscription plan.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-11T16:05:52.815434"}}
{"question": "How does Amazon Personalize compare in terms of functionality between personalizing a video streaming app and creating personalized emails?", "answer": "Amazon Personalize can be used to add multiple types of personalized video recommendations to a streaming app, such as 'Top picks for you', 'More like X', and 'Most popular' video recommendations. In contrast, it can also be used to generate batch recommendations for all users on an email list, which can then be sent to users through an AWS service or third-party service, recommending items in the catalog.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-2", "source_tokens": 391, "generated_at": "2026-02-11T16:05:52.815977"}}
{"question": "What are the three steps to use Amazon Personalize?", "answer": "The three steps to use Amazon Personalize are: first, point Amazon Personalize to your user interaction data in Amazon S3 and optionally provide an items or users dataset; second, train a custom private recommendation model; third, retrieve personalized recommendations.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-11T16:05:57.226894"}}
{"question": "How can you prepare and import your data to Amazon Personalize?", "answer": "You can prepare and import your data to Amazon Personalize using Amazon S3 or by using SageMaker Data Wrangler.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-11T16:05:57.227229"}}
{"question": "What's the difference between training a personalization model manually and letting Amazon Personalize choose the right algorithm automatically?", "answer": "Training a personalization model manually involves manually choosing one of the several algorithm options available, while letting Amazon Personalize choose the right algorithm for your dataset with AutoML is an automated process.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-3", "source_tokens": 356, "generated_at": "2026-02-11T16:05:57.227621"}}
{"question": "What type of user activity data should be provided to Amazon Personalize?", "answer": "Users should provide Amazon Personalize with a historical log of usersâ€™ interactions on the website/application in the form of events. This includes key events such as click, buy, watch, add-to-shopping cart, like, etc.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T16:06:01.626617"}}
{"question": "Why is catalog data important for Amazon Personalize?", "answer": "Catalog data, which includes item ids and metadata associated with each item, is important for Amazon Personalize as it helps the service understand the characteristics of the items and provide relevant recommendations.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T16:06:01.626891"}}
{"question": "What's the difference between providing user activity data and catalog data to Amazon Personalize?", "answer": "User activity data is a historical log of usersâ€™ interactions on the website/application in the form of events, while catalog data consists of item ids and metadata associated with each item.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-4", "source_tokens": 314, "generated_at": "2026-02-11T16:06:01.627269"}}
{"question": "What data sources can you import data from when preparing data for Amazon Personalize using SageMaker Data Wrangler?", "answer": "You can import data from 40+ supported data sources when preparing data for Amazon Personalize using SageMaker Data Wrangler.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-11T16:06:07.011512"}}
{"question": "How does Amazon Personalize help users discover new items?", "answer": "Amazon Personalize helps users discover new items by allowing you to specify a â€˜new item exploration weightâ€™. This input is used to strike a balance between exposing new content to users and offering the most relevant recommendations. Amazon Personalize also considers data about which items users have been exposed to but chose not to interact with.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-11T16:06:07.011785"}}
{"question": "How does using Amazon SageMaker Data Wrangler for data preparation compare to traditional data preparation methods?", "answer": "Using Amazon SageMaker Data Wrangler for data preparation allows you to perform end-to-end data preparation in a single user interface using little to no code. It also provides analysis on your data to make getting started easy and offers suggestions to improve your data preparation. However, it incurs additional charges as per usage.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-5", "source_tokens": 412, "generated_at": "2026-02-11T16:06:07.011946"}}
{"question": "What integration has Amazon Personalize launched with OpenSearch for personalized search results?", "answer": "Amazon Personalize has integrated with self-managed OpenSearch to enable personalized search results and predict search needs.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:06:11.399825"}}
{"question": "How does the Amazon Personalize Search Ranking plugin help in OpenSearch?", "answer": "The Amazon Personalize Search Ranking plugin in OpenSearch allows users to apply personalized re-ranking to search results using the deep learning capabilities offered by Amazon Personalize, without requiring ML expertise.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:06:11.400233"}}
{"question": "What is the difference between using Amazon Personalize Search Ranking plugin in Amazon OpenSearch and self-managed OpenSearch?", "answer": "The main difference lies in the setup process. In Amazon OpenSearch, users can simply associate and configure the plugin, while in self-managed OpenSearch, users need to install and configure the plugin.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:06:11.400735"}}
{"question": "What is the role of Amazon Personalize Recipes in model training and configuration?", "answer": "Amazon Personalize Recipes are algorithms provided by Amazon Personalize for specific personalization use cases, including product or content recommendations, personalized ranking, and user segmentation. These algorithms are used in model training and configuration.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-11T16:06:16.955389"}}
{"question": "How does Amazon Personalize Next Best Action (NBA) help increase loyalty and conversion?", "answer": "Amazon Personalize NBA helps increase loyalty and conversion by recommending the best action for individual users in real-time. These actions may increase loyalty and conversion by providing relevant and timely offers or suggestions.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-11T16:06:16.955763"}}
{"question": "What's the difference between the getRecommendations and getPersonalizedRanking APIs in Amazon Personalize?", "answer": "The getRecommendations API returns a list of recommended itemIDs for a user, while the getPersonalizedRanking API returns a reranked list of items for a user. The itemIDs can be used to generate the end-user experience through steps such as fetching image and description, rendering a display, and integrating with AWS services or third-party email delivery services.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-7", "source_tokens": 496, "generated_at": "2026-02-11T16:06:16.955999"}}
{"question": "What tool should be used for A/B testing in Amazon Personalize?", "answer": "Amazon CloudWatch Evidently", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T16:06:21.097822"}}
{"question": "How can offline metrics in Amazon Personalize help in optimizing for high quality recommendations?", "answer": "Offline metrics in Amazon Personalize allow you to measure the accuracy of predictions from the model against historical data, and can provide a directional sense of the quality of a solution version against other versions.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T16:06:21.098199"}}
{"question": "What is the difference between online and offline metrics in Amazon Personalize?", "answer": "Online metrics are empirical results observed in users' interactions with real-time recommendations in a live environment, while offline metrics are calculated against historical data and are used to provide a directional sense of the quality of a solution version.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-8", "source_tokens": 467, "generated_at": "2026-02-11T16:06:21.098688"}}
{"question": "What ensures that Amazon Personalize models are unique to each customer's data set?", "answer": "Amazon Personalize models are unique because they are not shared across other AWS accounts or with Amazon Retail, Amazon Prime, or any other business unit. Each customer's model inputs and outputs are entirely owned by their account.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T16:06:26.042270"}}
{"question": "How does Amazon Personalize protect user data?", "answer": "Amazon Personalize protects user data through encryption, both at rest and in transit in the AWS Region where the service is being used. Users can also encrypt their data with customer keys through AWS Key Management Service.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T16:06:26.042658"}}
{"question": "How does Amazon Personalize compare to other use cases like user segmentation for marketing?", "answer": "Amazon Personalize and user segmentation both aim to improve user experience by providing targeted content. However, while Amazon Personalize focuses on personalizing recommendations based on user behavior and preferences, user segmentation is used for targeted messaging and notifications based on user interests and demographics.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-9", "source_tokens": 451, "generated_at": "2026-02-11T16:06:26.043093"}}
{"question": "What are some features of Amazon Personalize beyond basic ML practices?", "answer": "Amazon Personalize offers several features such as user segmentation, domain optimized recommenders, new item recommendations, real-time or batch recommendations, action recommendations, personalized search, unstructured text support, contextual recommendations, business rules, and trending recommendations.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-11T16:06:30.307620"}}
{"question": "How does contextual information impact Amazon Personalize recommendations?", "answer": "Contextual information such as user segment, device type, location, or time of day is used to improve the recommendations generated by Amazon Personalize.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-11T16:06:30.307875"}}
{"question": "What's the difference between real-time and batch recommendations in Amazon Personalize?", "answer": "Real-time recommendations respond to changing user intent in real-time, while batch recommendations are fed to batch-oriented workflows.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-10", "source_tokens": 429, "generated_at": "2026-02-11T16:06:30.308031"}}
{"question": "What are the cost benefits of using Amazon Personalize?", "answer": "Amazon Personalize is a pay-as-you-go service with no minimum fees and no upfront commitments.", "question_type": "factual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-11T16:06:34.341037"}}
{"question": "How can I manage costs with Amazon Personalize?", "answer": "You can manage costs with Amazon Personalize by caching results based on your needs for real-time updates, re-training based on business requirements, heavily relying on auto-scaling, and considering using batch recommendations for downstream batch processes.", "question_type": "conceptual", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-11T16:06:34.341404"}}
{"question": "What's the difference between real-time and batch recommendations in terms of cost in Amazon Personalize?", "answer": "Real-time recommendations require a campaign and run in real-time, while batch recommendations do not require a campaign and run against a solution version.", "question_type": "comparison", "metadata": {"service": "PERSONALIZE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "personalize-faq-11", "source_tokens": 181, "generated_at": "2026-02-11T16:06:34.341840"}}
{"question": "What is the end of support date for Amazon Pinpoint?", "answer": "October 30, 2026", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-11T16:06:38.737630"}}
{"question": "How does Amazon Pinpoint help developers?", "answer": "Amazon Pinpoint is a self-service solution that allows developers to set up a project without the need for sales involvement, RFPs, or consultants. It also offers Journeys for automating multi-step campaigns.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-11T16:06:38.737982"}}
{"question": "How does the functionality of Amazon Pinpoint for Journeys compare to that of a traditional manual marketing process?", "answer": "Amazon Pinpoint for Journeys automates multi-step campaigns with activities such as sending emails, time-based waits, and splitting journey segments based on customer actions or enforcing holds. In contrast, a traditional manual marketing process would require more manual steps and potentially more time and resources.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-0", "source_tokens": 452, "generated_at": "2026-02-11T16:06:38.738468"}}
{"question": "What is the maximum duration for which a journey can run continuously?", "answer": "Each journey can run continuously for up to 18 months.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-11T16:06:42.572896"}}
{"question": "How does the review process in Journeys work?", "answer": "The review process in Journeys checks for show-stopping errors and provides recommendations and best practices before launching each journey.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-11T16:06:42.573274"}}
{"question": "What are the key features of Amazon Pinpoint for campaign management?", "answer": "Amazon Pinpoint enables defining user targeting, determining messages to send, scheduling delivery, tracking results, and measuring messaging effectiveness for multi-channel campaigns. It also supports personalization and can be scaled to handle billions of events and messages.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-1", "source_tokens": 455, "generated_at": "2026-02-11T16:06:42.573683"}}
{"question": "What are the components of a standard campaign in Amazon Pinpoint?", "answer": "A standard campaign in Amazon Pinpoint includes a targeted segment (either static or dynamic), a message, and a schedule for sending the message.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T16:06:48.041373"}}
{"question": "How do A/B campaigns differ from standard campaigns in Amazon Pinpoint?", "answer": "A/B campaigns in Amazon Pinpoint are campaigns with more than one treatment. Each treatment differs from the other based on the message or the sending schedule. Response rates for each treatment can be compared to determine which one had a bigger impact on customers.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T16:06:48.041689"}}
{"question": "Which options do you have when setting up a campaign in Amazon Pinpoint in terms of scheduling?", "answer": "When setting up a campaign in Amazon Pinpoint, you have two options for scheduling: sending the campaign at a specific time or sending it when an event occurs. Time-based campaigns can be scheduled to run one time immediately, or at a time you designate in the future, and can be set to recur hourly, daily, weekly, or monthly. Event-based campaigns trigger messages to be sent based on specific events, attributes, and metric values.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-2", "source_tokens": 499, "generated_at": "2026-02-11T16:06:48.042189"}}
{"question": "What limit can be set for the number of messages an endpoint can receive for an Amazon Pinpoint campaign?", "answer": "The maximum number of messages that an endpoint can receive for an Amazon Pinpoint campaign can be configured on the General Settings page or in the campaign settings.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-11T16:06:53.460670"}}
{"question": "Why is it important to set a limit on the number of messages an endpoint can receive in Amazon Pinpoint?", "answer": "Setting a limit on the number of messages an endpoint can receive in Amazon Pinpoint ensures that endpoints only receive a message once, which is useful when creating campaigns that automatically send messages to new customers.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-11T16:06:53.460918"}}
{"question": "How does the limit for the number of messages an endpoint can receive in Amazon Pinpoint compare to the number of messages actually delivered to an endpoint?", "answer": "The limit for the number of messages an endpoint can receive in Amazon Pinpoint is based on the number of messages targeted to an endpoint, not the number of messages actually delivered. If an endpoint is unable to receive a message, it is still counted towards the limit. Once the limit is reached, the endpoint is removed from subsequent runs of the campaign until they are outside the limit period.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-3", "source_tokens": 449, "generated_at": "2026-02-11T16:06:53.461302"}}
{"question": "What channels can developers extend with Amazon Pinpoint?", "answer": "Developers can extend the communication channels through which their applications engage users using Amazon Pinpoint. These channels include email, SMS text messaging, and push notifications, voice messages, and custom channels.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T16:06:57.673390"}}
{"question": "How does Amazon Pinpoint help developers address different messaging use cases?", "answer": "Amazon Pinpoint helps developers address multiple messaging use cases such as direct or transactional messaging, targeted, or campaign messaging and event-based messaging.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T16:06:57.673764"}}
{"question": "What's the difference between time-based and event-based campaigns in Amazon Pinpoint?", "answer": "Time-based campaigns allow developers to send messages at a specific time, while event-based campaigns send messages when specific events occur in the application.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-4", "source_tokens": 429, "generated_at": "2026-02-11T16:06:57.674198"}}
{"question": "What are custom events in AWS Pinpoint and what purpose do they serve?", "answer": "Custom events are event metrics defined by users in AWS Pinpoint. They help track user actions specific to applications or games, and the Amazon Pinpoint event charts provide a view of how often custom events occur. Custom events can be filtered based on attributes and their associated values.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-11T16:07:03.509750"}}
{"question": "How do you create and define custom events in AWS Pinpoint?", "answer": "You create custom events by naming them and then adding context by specifying attributes (for qualitative measures) and metrics (for quantitative measures). For example, if you want to track purchases of items from within the app, you can use 'Item Bought' as a custom event, 'Item XYZ' as an attribute, and 'Item Price' as the metric.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-11T16:07:03.510062"}}
{"question": "What's the difference between using 'Item Price' as a metric and 'Item XYZ' as an attribute in AWS Pinpoint for custom events?", "answer": "Using 'Item Price' as a metric allows you to measure and analyze the quantitative aspect of the data related to individual items' prices. Using 'Item XYZ' as an attribute, on the other hand, enables you to filter and search for specific items based on their names.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-5", "source_tokens": 238, "generated_at": "2026-02-11T16:07:03.510475"}}
{"question": "What information can be recorded as a custom event in AWS Pinpoint?", "answer": "Custom events in AWS Pinpoint can be recorded as an event with a name and attribute values. For example, a 'level_complete' event can be recorded with the name of the level and the player's health as attribute values.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-11T16:07:08.280335"}}
{"question": "How can custom events be used in AWS Pinpoint?", "answer": "Custom events can be used in AWS Pinpoint to understand user behavior and improve app engagement by identifying trends or issues. They can also be used to trigger event-based campaigns, sending messages when specific actions are taken within the application.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-11T16:07:08.280562"}}
{"question": "What is the difference between an endpoint and a user in AWS Pinpoint?", "answer": "An endpoint is a destination for sending messages, such as a user's mobile device or email address. A user is an individual with a unique user ID, which can be associated with up to 10 endpoints.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-6", "source_tokens": 507, "generated_at": "2026-02-11T16:07:08.280719"}}
{"question": "What metrics can be tracked for standard campaigns in Amazon Pinpoint?", "answer": "For standard campaigns, you can track messages sent, messages delivered, delivery rate, open rate, and campaign sessions by time of day.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T16:07:13.408947"}}
{"question": "How can you gain insights into your application's performance using Amazon Pinpoint?", "answer": "Amazon Pinpoint offers several types of standard analytics that provide insight into your application's performance, including metrics for active users, user activities and demographics, sessions, user retention, campaign efficacy, and transactional messages.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T16:07:13.409222"}}
{"question": "What is the difference between the sticky factor and daily retention in Amazon Pinpoint?", "answer": "The sticky factor represents the number of monthly users who used the app on a particular day, calculated by dividing daily active users by monthly active users. Daily retention, on the other hand, is measured by determining the number of users that first used your app on a specific day and came back and used your app in the next 7, 14, or 30 days.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-7", "source_tokens": 385, "generated_at": "2026-02-11T16:07:13.409390"}}
{"question": "How long does Amazon Pinpoint store analytics data by default?", "answer": "Amazon Pinpoint stores analytics data for 90 days by default.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-11T16:07:18.021938"}}
{"question": "What is the purpose of exporting or streaming Amazon Pinpoint data to Amazon Kinesis?", "answer": "Exporting or streaming Amazon Pinpoint data to Amazon Kinesis allows for data to be kept for longer than 90 days and processed in real-time by other AWS services.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-11T16:07:18.022301"}}
{"question": "What are the differences between using unregistered US long codes and 10DLC numbers for SMS messaging in Amazon Pinpoint?", "answer": "After June 1, 2021, unregistered US long codes can only be used for voice messages. To send SMS messages to recipients in the US, you must use either a short code, a 10DLC phone number, or a toll-free number.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-8", "source_tokens": 410, "generated_at": "2026-02-11T16:07:18.022765"}}
{"question": "What happens if I don't register an unregistered long code for text messaging?", "answer": "You'll continue to pay $1 per month for each unregistered long code. However, you wonâ€™t be able to use unregistered US long codes to send text messages.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:07:22.809900"}}
{"question": "Can I keep unregistered long codes for voice messaging?", "answer": "Yes, you can keep unregistered long codes for using them to send voice messages to your customers. Or, you can convert them to 10DLC numbers for text messaging.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:07:22.810289"}}
{"question": "What's the difference between completing the 10DLC conversion process before or after June 1, 2021?", "answer": "If you complete the process before June 1, 2021, you wonâ€™t experience any downtime. If you begin the process after this date, you may experience several days of downtime.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-9", "source_tokens": 493, "generated_at": "2026-02-11T16:07:22.810786"}}
{"question": "How long does it take to associate a new phone number with a 10DLC campaign?", "answer": "It takes up to 14 business days to associate a new phone number with a 10DLC campaign.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-11T16:07:27.226541"}}
{"question": "Can you explain the benefits of using multiple phone numbers in a single 10DLC campaign?", "answer": "Using multiple phone numbers for the same 10DLC campaign doesnâ€™t provide any added benefit in terms of throughput.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-11T16:07:27.226854"}}
{"question": "How does the process of associating a phone number with a 10DLC campaign compare to purchasing a phone number for the campaign?", "answer": "The process of associating a phone number with a 10DLC campaign takes up to 14 business days, while purchasing a phone number can be done through the Amazon Pinpoint console immediately.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-10", "source_tokens": 510, "generated_at": "2026-02-11T16:07:27.227035"}}
{"question": "What is the default limit for number of SMS messages you can send per second in Amazon Pinpoint?", "answer": "The default limit for number of SMS messages you can send per second in Amazon Pinpoint is 20.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-11T16:07:32.315908"}}
{"question": "Why is having an obvious brand name important when using a custom URL shortener with 10DLC?", "answer": "Having an obvious brand name when using a custom URL shortener with 10DLC is important because during the 10DLC campaign registration process, you need to provide examples of your shortened URLs along with your message templates.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-11T16:07:32.316216"}}
{"question": "How does the limit for sending SMS messages in Amazon Pinpoint compare to the limit for 10DLC carriers?", "answer": "The limit for sending SMS messages in Amazon Pinpoint is 20 messages per second by default. However, the limits for sending messages from a 10DLC campaign through a particular carrier can vary and are determined by the carrier's trust score for the sender.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-11", "source_tokens": 512, "generated_at": "2026-02-11T16:07:32.316606"}}
{"question": "What data does Amazon Pinpoint store for use cases?", "answer": "Amazon Pinpoint stores user, endpoint, and event data.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T16:07:36.422082"}}
{"question": "How does Amazon Pinpoint enhance customer engagement?", "answer": "Amazon Pinpoint enhances customer engagement by allowing the creation of message templates, delivery schedules, highly-targeted segments, and full campaigns. It also offers voice messages over the phone and call metrics for optimization.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T16:07:36.422421"}}
{"question": "How does Amazon Pinpoint compare to Amazon Connect in terms of communication channels?", "answer": "Amazon Pinpoint and Amazon Connect both offer engagement through push notifications, email, and voice calls. However, Amazon Pinpoint focuses on managing message audience, content, and delivery schedule, while Amazon Connect is an omnichannel cloud contact center.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-12", "source_tokens": 429, "generated_at": "2026-02-11T16:07:36.422638"}}
{"question": "What happens to the data in your Amazon Pinpoint account after account closure?", "answer": "After account closure, any content that was not deleted is permanently deleted, and any AWS services that were not stopped are also stopped.", "question_type": "factual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T16:07:40.088680"}}
{"question": "Why should you report email abuse to Amazon?", "answer": "Reporting email abuse to Amazon helps ensure that the issue is handled as quickly and effectively as possible.", "question_type": "conceptual", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T16:07:40.089775"}}
{"question": "What's the difference between AWS and mobile carrier fees when sending SMS messages?", "answer": "AWS fees cover the charges assessed by mobile carriers for sending A2P SMS messages, and these fees are subject to change.", "question_type": "comparison", "metadata": {"service": "PINPOINT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "pinpoint-faq-13", "source_tokens": 472, "generated_at": "2026-02-11T16:07:40.089959"}}
{"question": "What is Amazon Polly and what does it do?", "answer": "Amazon Polly is a machine learning service that turns text into lifelike speech. It enables existing applications to speak as a first-class feature and creates opportunities for new speech-enabled products. Amazon Polly includes dozens of lifelike voices and support for multiple languages.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T16:07:44.828575"}}
{"question": "How can I use Amazon Polly to enhance my application?", "answer": "You can use Amazon Polly to power your application with high-quality spoken output. It has very low response times and is available for virtually any use case, with no restrictions on storing and reusing generated speech.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T16:07:44.828947"}}
{"question": "How does Amazon Polly's pricing compare to other speech synthesis services?", "answer": "Amazon Polly's pay-as-you-go pricing and lack of restrictions on storage and reuse of voice output make it a cost-effective way to enable speech synthesis compared to other services.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-0", "source_tokens": 373, "generated_at": "2026-02-11T16:07:44.829413"}}
{"question": "What elements does Amazon Polly use to generate Speech Marks?", "answer": "Amazon Polly uses the Sentence, Word, Viseme, and SSML elements to generate Speech Marks.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T16:07:49.100196"}}
{"question": "How does using Speech Marks enhance the visual experience of the synthesized speech?", "answer": "Using Speech Marks with the synthesized speech allows developers to provide their applications with an enhanced visual experience, such as speech-synchronized animation or karaoke-style highlighting.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T16:07:49.100560"}}
{"question": "What is the difference between the 'Word' and 'Viseme' elements in generating Speech Marks?", "answer": "The 'Word' element indicates a word in the text, while the 'Viseme' element describes the shape of the lips that corresponds to the sound being spoken.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-1", "source_tokens": 413, "generated_at": "2026-02-11T16:07:49.100774"}}
{"question": "What devices can leverage Amazon Polly for providing audio output?", "answer": "A wide range of devices such as set-top boxes, smart watches, tablets, smartphones, and IoT devices can leverage Amazon Polly for providing audio output.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T16:07:54.293958"}}
{"question": "What are the benefits of using cloud-based text-to-speech solutions like Amazon Polly?", "answer": "Cloud-based text-to-speech solutions like Amazon Polly reduce local resource requirements, making it possible to support all available languages and voices at the highest quality, provide speech corrections and enhancements to all end-users instantly, and minimize development time and effort since it is platform independent.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T16:07:54.294332"}}
{"question": "How does using cloud-based text-to-speech solutions like Amazon Polly compare to on-device text-to-speech solutions in terms of resource requirements?", "answer": "Cloud-based text-to-speech solutions like Amazon Polly dramatically reduce local resource requirements compared to on-device text-to-speech solutions, which can result in lower development costs and power consumption.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-2", "source_tokens": 485, "generated_at": "2026-02-11T16:07:54.294747"}}
{"question": "Which regions support Amazon Polly's Neural voices?", "answer": "Neural voices are supported in the following regions: US East (N. Virginia), US West (Oregon), Canada (Central), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Africa (Cape Town), EU (London), EU (Frankfurt), EU (Ireland), and AWS GovCloud (US-West).", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T16:07:58.789957"}}
{"question": "How can I implement my own access layer with Amazon Polly?", "answer": "Amazon Polly provides an HTTP API that you can use to implement your own access layer.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T16:07:58.790317"}}
{"question": "How does Amazon Polly's support for different audio formats compare?", "answer": "Amazon Polly supports MP3, Vorbis, and raw PCM audio stream formats.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-3", "source_tokens": 510, "generated_at": "2026-02-11T16:07:58.790544"}}
{"question": "What are the charges for using Amazon Polly for requesting speech or Speech Marks?", "answer": "You will be charged for every request for speech or Speech Marks based on the number of characters you send to the service.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-11T16:08:03.685334"}}
{"question": "How can I get started with Amazon Polly for free?", "answer": "As part of the AWS Free Usage Tier, new Amazon Polly customers can synthesize millions of characters for free each month for the first 12 months. New AWS customers also receive up to $200 in AWS Free Tier credits, which can be applied towards eligible AWS services, including Amazon Polly.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-11T16:08:03.685697"}}
{"question": "How does the pricing for Amazon Polly compare to the free usage tier?", "answer": "After the free usage tier, you will be charged for every request for speech or Speech Marks based on the number of characters you send to the service. The exact cost depends on the pricing information available on the Amazon Polly Pricing Page.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-4", "source_tokens": 398, "generated_at": "2026-02-11T16:08:03.686198"}}
{"question": "What does Amazon Polly do with the text inputs it receives?", "answer": "Amazon Polly may store and use text inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Polly and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-11T16:08:08.491425"}}
{"question": "How does Amazon Polly protect the privacy and security of user content?", "answer": "Amazon Polly implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, user content and ensure that its use complies with its commitments to users.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-11T16:08:08.491677"}}
{"question": "What is the difference in data handling between Amazon Polly and other AWS services?", "answer": "Amazon Polly may store and use text inputs solely for providing and maintaining the service and improving its technologies, while other AWS services may have different data handling practices. Users should refer to the specific service's documentation for details.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-5", "source_tokens": 385, "generated_at": "2026-02-11T16:08:08.491818"}}
{"question": "In which AWS regions is the content processed by Amazon Polly encrypted and stored at rest?", "answer": "The content processed by Amazon Polly is encrypted and stored at rest in the AWS region where you are using Amazon Polly.", "question_type": "factual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:08:13.896337"}}
{"question": "How does Amazon ensure the security of the content stored in connection with the continuous improvement of Amazon Polly and other Amazon machine-learning/artificial-intelligence technologies?", "answer": "Amazon implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, the content and ensure compliance with commitments.", "question_type": "conceptual", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:08:13.896730"}}
{"question": "Is there a difference in the storage location for content processed by Amazon Polly based on whether or not it is used for improving other Amazon machine-learning/artificial-intelligence technologies?", "answer": "Yes, some portion of content processed by Amazon Polly may be stored in another AWS region solely in connection with the continuous improvement and development of Amazon Polly and other Amazon machine-learning/artificial-intelligence technologies. However, users can opt out of having their content used for this purpose.", "question_type": "comparison", "metadata": {"service": "POLLY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "polly-faq-6", "source_tokens": 466, "generated_at": "2026-02-11T16:08:13.897199"}}
{"question": "What is the function of a CA certificate in a public key infrastructure (PKI)?", "answer": "A CA certificate is a cryptographic building block in a PKI that allows other certificates to be issued.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T16:08:18.171789"}}
{"question": "How does the Online Certificate Status Protocol (OCSP) work in relation to certificate status checks?", "answer": "The Online Certificate Status Protocol (OCSP) is a service used by resources to check the status of a certificate presented by another entity.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T16:08:18.172184"}}
{"question": "What's the difference between a CA certificate and a set of runtime services for certificate revocation (OCSP and CRL)?", "answer": "A CA certificate is a cryptographic building block used to issue certificates, while OCSP and CRL are runtime services used to maintain and check revocation information for those certificates.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-0", "source_tokens": 451, "generated_at": "2026-02-11T16:08:18.172626"}}
{"question": "What information can be included in a private certificate that cannot be in a public certificate?", "answer": "Private certificates can include information such as Wiki.internal, IP address 168.1.1, fire-sensor-123, and user123, which cannot be included in public certificates since they are strictly limited to identifying resources with public DNS names.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-11T16:08:23.831088"}}
{"question": "Why would you use a private CA and private certificates instead of public ones?", "answer": "Private CAs and private certificates offer flexibility and customizability, allowing administrators to make their own rules for issuing certificates and identify nearly anything within an organizationâ€™s private network without disclosing the name publicly. They also have fewer configuration constraints than publicly trusted certificates.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-11T16:08:23.831367"}}
{"question": "How does the use of a private CA and private certificates compare to a public CA and public certificates?", "answer": "Private CAs and private certificates allow more flexibility and customizability in issuing certificates and can include identity information that is not allowed in public certificates. However, to be trusted, an administrator must add the private CA to the list of trusted CAs in browsers and other network applications.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-1", "source_tokens": 385, "generated_at": "2026-02-11T16:08:23.831762"}}
{"question": "What are the limitations of self-signed certificates?", "answer": "Self-signed certificates have several limitations. They cannot verify identity and cannot be revoked. It can also be difficult to track their expiration dates, which may lead to outages caused by certificate expirations.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T16:08:29.502726"}}
{"question": "How does a CA hierarchy work in an organization?", "answer": "A CA hierarchy is a structure used by organizations to control access and distribute management of CAs. It provides strong security and restrictive access controls for the root CA at the top of the trust chain, while allowing more permissive access and bulk certificate issuance for subordinate CAs. This helps organizations manage their CAs efficiently and securely.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T16:08:29.503099"}}
{"question": "How does a CA hierarchy compare to self-signed certificates?", "answer": "A CA hierarchy provides stronger security and access control compared to using self-signed certificates. While self-signed certificates are easy to generate and don't require any infrastructure, they lack the ability to verify identity, cannot be revoked, and it can be difficult to track their expiration dates. A CA hierarchy, on the other hand, enables organizations to manage their certificates more effectively and securely.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-2", "source_tokens": 478, "generated_at": "2026-02-11T16:08:29.503598"}}
{"question": "What is the role of a subordinate CA in a CA hierarchy?", "answer": "A subordinate CA can be configured to directly issue certificates, act as an intermediate CA, act as an issuing CA, or act as both an intermediate and issuing CA.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-11T16:08:33.328320"}}
{"question": "Why do root CAs have longer lifetimes than subordinate CAs?", "answer": "Root CAs are typically more trusted due to their isolation and control policies, and their longer lifetimes reflect this higher level of security.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-11T16:08:33.328651"}}
{"question": "What's the difference between a root CA and a subordinate CA in terms of certificate issuance?", "answer": "A root CA can issue certificates directly, while a subordinate CA signs other subordinate CAs to create a hierarchy and can also issue end-entity certificates.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-3", "source_tokens": 399, "generated_at": "2026-02-11T16:08:33.328828"}}
{"question": "What type of certificates should be used for temporary workloads or authorizations?", "answer": "Short-lived certificates are best practice for temporary workloads and authorizations since they expire quickly and do not need to be revoked.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-11T16:08:38.464686"}}
{"question": "How does the security of short-lived certificates work?", "answer": "The security of short-lived certificates is based on their frequent re-issuance to reaffirm their health, which forces the subject to frequently demonstrate compliance with the certificate policy.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-11T16:08:38.464935"}}
{"question": "How does AWS Identity and Access Management (IAM) Roles Anywhere compare to short-lived certificates for obtaining temporary security credentials?", "answer": "Both short-lived certificates and IAM Roles Anywhere are used to obtain temporary security credentials, but short-lived certificates are self-managed and require trust between your PKI and IAM Roles Anywhere, while IAM Roles Anywhere are managed by AWS and use X.509 certificates issued by your CA.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-4", "source_tokens": 424, "generated_at": "2026-02-11T16:08:38.465074"}}
{"question": "What is the role of a trust anchor in establishing trust between IAM Roles Anywhere and a CA?", "answer": "A trust anchor is a reference to either an AWS Private CA or another CA certificate that is used to establish trust between IAM Roles Anywhere and the CA. Your workloads outside of AWS authenticate with the trust anchor using certificates issued by the trusted CA in exchange for temporary AWS credentials.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-11T16:08:44.661243"}}
{"question": "How does Matter ensure security and interoperability of smart home devices?", "answer": "Matter enforces device certification and authenticity checks before smart home devices can join a Matter smart home network (also known as fabric) and communicate with other Matter devices. Matter uses X.509 digital certificates to identify devices and to secure communication between devices.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-11T16:08:44.661561"}}
{"question": "What is the difference between Device Attestation Certificates (DACs) and Node Operational Certificates (NOCs) in Matter?", "answer": "Device Attestation Certificates (DACs) are provisioned by device makers to identify the device vendor and product type, and they are validated by Matter fabric administrator devices during device commissioning. Node Operational Certificates (NOCs) are issued by Matter administrators during commissioning and are used by devices for communicating with other Matter devices on the fabric.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-5", "source_tokens": 366, "generated_at": "2026-02-11T16:08:44.661948"}}
{"question": "What can AWS Private CA be used for in the context of Matter products?", "answer": "AWS Private CA can be used to establish and operate a Product Attestation Authority (PAA) and Product Attestation Intermediates to issue Device Attestation Certificates (DACs) for Matter products.", "question_type": "factual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T16:08:49.902332"}}
{"question": "How can you set up a Device Attestation CA in AWS Private CA?", "answer": "You can use the sample AWS Cloud Development Kit (CDK) scripts and AWS CloudFormation stack templates to help you create your device attestation CA. Once created, you can use the AWS SDKs and CLI, or the Java APIs to issue DACs.", "question_type": "conceptual", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T16:08:49.902698"}}
{"question": "How does setting up a non-VID-scoped Device Attestation CA differ from a VID-scoped one in AWS Private CA?", "answer": "A non-VID-scoped Device Attestation CA is used to issue DACs for your own company, while a VID-scoped one is used to issue DACs for other companies as well.", "question_type": "comparison", "metadata": {"service": "PRIVATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "private-faq-6", "source_tokens": 319, "generated_at": "2026-02-11T16:08:49.903227"}}
{"question": "What are VPC endpoints for in the context of AWS PrivateLink?", "answer": "VPC endpoints are used to access services and resources hosted on AWS through AWS PrivateLink. They appear as elastic network interfaces with private IPs in your VPCs. Once these endpoints are created, any traffic destined to these IPs will get privately routed to the corresponding services or resources.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-11T16:08:55.137332"}}
{"question": "How does a service owner make their service available through AWS PrivateLink?", "answer": "A service owner can make their service available through AWS PrivateLink by establishing a Network Load Balancer to front their service and creating a PrivateLink service to register with the Network Load Balancer.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-11T16:08:55.137610"}}
{"question": "How does AWS PrivateLink for content delivery compare to using VPC endpoints for a non-AWS service?", "answer": "AWS PrivateLink lets users access services and resources hosted on AWS in a highly available and scalable manner while keeping all network traffic within the AWS network. VPC endpoints for a non-AWS service would require the service owner to set up and manage the endpoints themselves.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-0", "source_tokens": 323, "generated_at": "2026-02-11T16:08:55.137767"}}
{"question": "Which types of VPC endpoints are powered by AWS PrivateLink?", "answer": "All VPC endpoint types except gateway endpoint are powered by PrivateLink.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T16:08:59.704761"}}
{"question": "How does interface endpoints differ from gateway endpoints in terms of features and functionality?", "answer": "Interface endpoints provide private connectivity to services powered by PrivateLink and support connectivity over AWS Direct Connect and VPN. Gateway endpoints, on the other hand, are available only for specific AWS services, donâ€™t enable PrivateLink, and add an entry to the route table you select.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T16:08:59.705153"}}
{"question": "What are the benefits of using resource endpoints over gateway endpoints?", "answer": "Resource endpoints provide private connectivity to VPC resources such as databases, clusters, domain-name targets, and IP addresses that donâ€™t require load balancing. They also support connectivity over AWS Direct Connect and VPN.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-1", "source_tokens": 379, "generated_at": "2026-02-11T16:08:59.705645"}}
{"question": "What service or resource can be accessed directly via VPC endpoints without requiring an internet gateway, NAT gateway, VPN connection, or VPC peering connection?", "answer": "VPC endpoints allow secure access to specific services or resources within Amazon's private network, without the need for additional gateways.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-11T16:09:04.118949"}}
{"question": "How does using VPC endpoints help reduce the risk of exposing traffic to the internet?", "answer": "By keeping traffic within Amazon's private network, VPC endpoints reduce the risk of exposing traffic to the internet.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-11T16:09:04.119212"}}
{"question": "What is the difference between resource endpoints and service network endpoints in the context of VPC endpoints?", "answer": "Resource endpoints provide private connectivity to VPC resources, while service network endpoints allow access to services and resources within a VPC Lattice service network.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-2", "source_tokens": 463, "generated_at": "2026-02-11T16:09:04.119356"}}
{"question": "What are the charges for creating a VPC endpoint with Gateway Load Balancer in each Availability Zone?", "answer": "You are charged for each hour that your VPC endpoint is provisioned in each Availability Zone.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T16:09:10.001568"}}
{"question": "How does the charging mechanism differ between creating a VPC endpoint with an interface or Gateway Load Balancer and a resource VPC endpoint?", "answer": "For a VPC endpoint with an interface or Gateway Load Balancer, you are charged for each hour that your VPC endpoint is provisioned in each Availability Zone. For a resource VPC endpoint, you are charged for each hour regardless of the number of Availability Zones your VPC endpoint is provisioned in.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T16:09:10.001936"}}
{"question": "What are the benefits of using AWS PrivateLink compared to VPC peering in terms of scalability and VPC endpoint creation?", "answer": "AWS PrivateLink has virtually unlimited scale and allows you to add as many VPC endpoints as needed, while VPC peering is limited to 125 VPC connections. Each VPC endpoint in AWS PrivateLink can support 10 Gbps continuous bandwidth per Availability Zone, with additional capacity added automatically up to 100 Gbps.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-3", "source_tokens": 501, "generated_at": "2026-02-11T16:09:10.002361"}}
{"question": "What types of VPC endpoints have CloudWatch metrics available?", "answer": "VPC endpoints of type â€˜interfaceâ€™ and â€˜gateway load balancerâ€™ have CloudWatch metrics available.", "question_type": "factual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-11T16:09:14.814657"}}
{"question": "How does the security of AWS PrivateLink work?,", "answer": "The security of AWS PrivateLink relies on the path, policies, and mode of communication. The path between a VPC endpoint and a service stays within AWS, and endpoint policies restrict access to requests. However, PrivateLink does not provide encryption for data in transit.", "question_type": "conceptual", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-11T16:09:14.815036"}}
{"question": "What is the difference between managing VPC endpoints with the AWS Management Console versus old CLI/SDK versions?", "answer": "With the latest version of AWS CLI/SDK, VPC endpoints are automatically discovered and used by default. However, with old CLI/SDK versions, you need to specify the DNS name as the endpoint parameter and can discover it by querying the EC2 metadata service.", "question_type": "comparison", "metadata": {"service": "PRIVATELINK", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "privatelink-faq-4", "source_tokens": 446, "generated_at": "2026-02-11T16:09:14.815473"}}
{"question": "What does AWS Proton enable platform teams to do for application developers?", "answer": "AWS Proton enables platform teams to define their infrastructure and deployment tools, while providing developers with a self-service experience to get infrastructure and deploy code. Platform teams can provision shared resources and define application stacks, including CI/CD pipelines and observability tools, and manage which infrastructure and deployment features are available for developers.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-11T16:09:21.134641"}}
{"question": "How does AWS Proton benefit application developers in terms of infrastructure management?", "answer": "AWS Proton allows application developers to self-serve from infrastructure templates to provision the infrastructure they need for their application code. They can select Service templates that meet their needs and easily trigger deployment through a supported CI/CD pipeline without having to write Infrastructure as Code templates. Application developers can also customize templates to meet specific application needs.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-11T16:09:21.134920"}}
{"question": "What is the main difference between AWS Proton and AWS Service Catalog in terms of infrastructure management?", "answer": "AWS Proton is a deployment workflow tool for managing Infrastructure as Code (IaC) templates built using tools like CloudFormation or Terraform. By comparison, AWS Service Catalog is a catalog of AWS resources that enables customers to store, share, and govern IaC templates and create individual stacks. Some AWS customers have used AWS Proton to manage architectures that include Service Catalog product components.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-0", "source_tokens": 473, "generated_at": "2026-02-11T16:09:21.135071"}}
{"question": "In which AWS Regions is AWS Proton currently supported for creating resources?", "answer": "AWS Proton is currently supported in the following AWS Regions: US East (Ohio) - us-east-2, US East (N. Virginia) - us-east-1, US West (Oregon) - us-west-2, Canada (Central) - ca-central-1, EU (Frankfurt) - eu-central-1, EU (Ireland) - eu-west-1, EU (London) - eu-west-2, Asia Pacific (Sydney) - ap-southeast-2, Asia Pacific (Tokyo) - ap-northeast-1, Asia Pacific (Seoul) - ap-northeast-2, Asia Pacific (Singapore) - ap-southeast-1.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-11T16:09:30.780749"}}
{"question": "What is the role of AWS Proton for platform teams and developers in deploying infrastructure?", "answer": "AWS Proton is a service that makes it easy for platform teams to create and manage reusable infrastructure templates, which are presented as version-controlled â€˜stacksâ€™ to developers. Platform teams define these stacks using infrastructure as code in a simple, declarative style that includes compute, networking, code pipeline, security, and monitoring resources. Developers can then select an application stack, enter required parameters, and deploy the infrastructure. This process helps ensure consistency across deployments and makes it easy for platform teams to identify and update outdated infrastructure when templates are updated.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-11T16:09:30.781025"}}
{"question": "How does the infrastructure deployment process differ between platform teams and developers using AWS Proton?", "answer": "Platform teams are responsible for creating and managing the infrastructure templates, which are presented as reusable application stacks to developers. They define these stacks using infrastructure as code with all the necessary resources like compute, networking, code pipeline, security, and monitoring. The platform team manages the creation of templates for environments and services and can use the â€˜bring your own environmentâ€™ feature to onboard existing environments. Developers, on the other hand, select an application stack, enter required parameters, and deploy the infrastructure using the provided templates. This separation of responsibilities helps ensure consistency across deployments and makes it easier for platform teams to manage and update infrastructure.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-1", "source_tokens": 445, "generated_at": "2026-02-11T16:09:30.781195"}}
{"question": "What is the process for saving a new template in AWS Proton?", "answer": "When you define a new template in AWS Proton, you can save it in an Amazon Simple Storage Service (Amazon S3) bucket and register it in AWS Proton. AWS Proton reads the template from the bucket and registers it in the console.", "question_type": "factual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-11T16:09:36.438744"}}
{"question": "How does AWS Proton enable developers to deploy projects without interacting with underlying resources?", "answer": "AWS Proton provides developers with a self-service interface to provision infrastructure and deploy their projects without interacting with the underlying resources. It offers visibility into the general status of your application, including stacks in use and stack health status, as well as access to the CI/CD pipeline, observability tools, and source control.", "question_type": "conceptual", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-11T16:09:36.438972"}}
{"question": "What's the difference between saving a new template in an Amazon S3 bucket and registering it in AWS Proton?", "answer": "Saving a new template in an Amazon S3 bucket involves storing the template file, while registering it in AWS Proton allows the console to access and manage the template. AWS Proton reads the template from the bucket and registers it, making it available for testing, publishing, and updating as needed.", "question_type": "comparison", "metadata": {"service": "PROTON", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "proton-faq-2", "source_tokens": 283, "generated_at": "2026-02-11T16:09:36.439142"}}
{"question": "What are the three specialized capabilities of Amazon Q for different types of employees?", "answer": "Amazon Q has specialized capabilities for software developers, business intelligence analysts, and contact center employees. It helps software developers with managing data and AI/ML, business intelligence analysts with getting insights on their data and solving problems, and contact center employees with generating content and taking actions on their behalf.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:09:42.558031"}}
{"question": "How does Amazon Q Business help organizations by using generative AI?", "answer": "Amazon Q Business uses generative AI to make it easier for organizations to get fast, relevant answers to pressing questions, solve problems, generate content, and take actions on their behalf. It connects securely to commonly used systems and tools to synthesize information and provide tailored assistance, empowering teams to be more data-driven, creative, and productive.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:09:42.558410"}}
{"question": "What is the difference between Amazon Q Business and Amazon Q Developer in terms of their capabilities?", "answer": "Amazon Q Business is designed for every employee in an organization and helps with getting insights on data, solving problems, generating content, and taking actions. Amazon Q Developer is more focused on software development and IT professionals, providing advanced capabilities for managing data and AI/ML, troubleshooting, performing security scanning, modernizing applications, optimizing AWS resources, and creating data engineering pipelines.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:09:42.558849"}}
{"question": "What service in AWS does Amazon Q's generative AI technology enhance?", "answer": "Amazon QuickSight, AWS unified business intelligence service", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-11T16:09:46.361512"}}
{"question": "How does Amazon Q's AI technology benefit business analysts in QuickSight?", "answer": "It helps business analysts build BI dashboards, visualizations, and complex calculations in minutes using natural language.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-11T16:09:46.361755"}}
{"question": "How does the generative AI capability of Amazon Q differ between Amazon QuickSight and AWS Supply Chain?", "answer": "In QuickSight, it's used to generate BI assistant features, while in AWS Supply Chain, it analyzes data and provides operational and financial insights", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-1", "source_tokens": 477, "generated_at": "2026-02-11T16:09:46.361952"}}
{"question": "What business tools can Amazon Q connect to?", "answer": "Amazon Q can connect to over 50 commonly used business tools, such as wikis, intranets, Atlassian, Gmail, Microsoft Exchange, Salesforce, ServiceNow, Slack, and Amazon Simple Storage Service (Amazon S3)", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T16:09:51.573569"}}
{"question": "How can businesses use Amazon Q to increase productivity?", "answer": "Amazon Q can be used as an intelligent virtual assistant across all business functions and by employees of all levels and capabilities. It can help business analysts create dashboards, developers generate code, and customer service agents find the best solutions. Teams can even make generative AI apps to automate business functions and enhance efficiency where it's needed most.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T16:09:51.573916"}}
{"question": "How does Amazon Q compare to other generative AI applications built on Amazon Bedrock?", "answer": "Amazon Q uses multiple Foundational Models from Amazon and leading AI companies to complete its tasks and uses logic to route tasks to the Foundational Model that is the best fit for the job.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-2", "source_tokens": 471, "generated_at": "2026-02-11T16:09:51.574089"}}
{"question": "What security features does Amazon Q inherit from Amazon Bedrock?", "answer": "Amazon Q inherits security controls from Amazon Bedrock to enforce safety, security, and responsible use of AI.", "question_type": "factual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-11T16:09:55.193800"}}
{"question": "How does Amazon Q's integration with Amazon Bedrock impact security?", "answer": "Amazon Q's integration with Amazon Bedrock allows users to inherit the controls implemented in Amazon Bedrock for safety, security, and responsible use of AI.", "question_type": "conceptual", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-11T16:09:55.194181"}}
{"question": "What is the difference between the free trial and monthly fee for Amazon Q functionality?", "answer": "Some Amazon Q functionality is available for free trial for a short time, while most functionality incurs a monthly fee.", "question_type": "comparison", "metadata": {"service": "Q", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "q-faq-3", "source_tokens": 127, "generated_at": "2026-02-11T16:09:55.213768"}}
{"question": "What are the different ways to access Amazon QuickSight for visualization and analysis?", "answer": "Amazon QuickSight can be accessed through interactive dashboards, paginated reports, natural language queries, and embedded analytics on any device.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-11T16:09:59.456836"}}
{"question": "What are the file formats that can be uploaded to Amazon QuickSight for analysis?", "answer": "CSV and Excel files can be uploaded to Amazon QuickSight for analysis.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-11T16:09:59.457081"}}
{"question": "How does Amazon QuickSight's mobile and web access compare to its visualization and analysis capabilities?", "answer": "Amazon QuickSight's mobile and web access allows users to access their visualizations and perform analysis from anywhere, while its visualization and analysis capabilities enable users to build modern interactive dashboards, paginated reports, natural language queries, and embedded analytics.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-0", "source_tokens": 339, "generated_at": "2026-02-11T16:09:59.457426"}}
{"question": "What IAM permissions does a QuickSight Author need to make SageMaker API calls on behalf of another account?", "answer": "The QuickSight Author needs to be granted QuickSight IAM permissions to make SageMaker API calls on behalf of another account.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T16:10:11.430059"}}
{"question": "What are the differences between QuickSight Author and Author Pro, and QuickSight Reader and Reader Pro?", "answer": "QuickSight Authors can connect to data sources, create visuals and analyze data, create interactive dashboards with advanced capabilities, and publish dashboards. QuickSight Author Pro includes all Author capabilities and adds Amazon Q Generative BI capabilities. QuickSight Readers can only consume interactive dashboards, view shared dashboards, filter data, drill down to details, and export data as a CSV file. QuickSight Reader Pro includes all Reader capabilities plus Amazon Q Generative BI capabilities. QuickSight Readers and Reader Pro are only available in Amazon QuickSight Enterprise Edition.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T16:10:11.430449"}}
{"question": "Why would a QuickSight user choose to use Amazon Q Generative BI capabilities?", "answer": "Amazon Q Generative BI capabilities allow users to build dashboards with natural language, create Q Topics, and build and share generative data stories.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-2", "source_tokens": 451, "generated_at": "2026-02-11T16:10:11.430876"}}
{"question": "What are the capabilities of a QuickSight Admin user?", "answer": "A QuickSight Admin is a user who can manage QuickSight users and account-level preferences, purchase SPICE capacity and annual subscriptions, and has all QuickSight authoring capabilities.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:10:16.564675"}}
{"question": "What's the difference in capabilities between QuickSight Admins, Authors, and Readers?", "answer": "QuickSight Admins can manage users and account-level preferences, purchase capacity and subscriptions, and have all authoring capabilities. QuickSight Authors can create, edit, and publish analyses, dashboards, and data sets. QuickSight Readers can only view and share analyses, dashboards, and data sets.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:10:16.565050"}}
{"question": "How can you access QuickSight on mobile devices?", "answer": "QuickSight offers mobile apps for iOS and Android, and a web interface accessible on any mobile device. Users can browse, search, and interact with dashboards, add favorites, drill down, filter, and explore data.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-3", "source_tokens": 508, "generated_at": "2026-02-11T16:10:16.565514"}}
{"question": "Which AWS services does QuickSight support for data connection?", "answer": "QuickSight supports various AWS data sources that are available in your account with your approval. You can also explicitly connect to other AWS data sources that are not in your account or in a different region by providing connection details for those sources.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:10:21.570953"}}
{"question": "How can you prepare data in QuickSight for visualization?", "answer": "You can prepare data in QuickSight for visualization by selecting the â€˜Edit/Preview Dataâ€™ button in the connection dialog. QuickSight supports various functions to format and transform your data, including aliasing data fields, changing data types, subsetting your data using built-in filters, performing database join operations using drag and drop, and creating calculated fields using mathematical operations and built-in functions.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:10:21.571198"}}
{"question": "How does QuickSight's data handling differ between data in your account and external data?", "answer": "QuickSight seamlessly discovers your AWS data sources that are available in your account with your approval. For external data, you need to provide connection details. QuickSight also lets you prepare data that is not ready for visualization for both types of data.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:10:21.571372"}}
{"question": "What types of visualizations can QuickSight create from a given dataset?", "answer": "QuickSight supports various visualizations, including comparison and distribution Bar charts, changes over time Line graphs, area line charts, correlation Scatter plots, Heat maps, aggregation Pie graphs, Tree maps, and Tabular Pivot tables.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-11T16:10:26.502121"}}
{"question": "How does QuickSight help users in creating visualizations?", "answer": "QuickSight uses an innovative technology called AutoGraph to select the most appropriate visualizations based on the properties of the data, such as cardinality and data type. It also comes with a built-in suggestion engine that provides users with suggested visualizations based on the underlying datasets.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-11T16:10:26.502383"}}
{"question": "How does a Bar chart comparison look like in QuickSight compared to a Line graph?", "answer": "I'm unable to answer this question directly from the context as the text doesn't provide enough information about the visual differences between Bar chart and Line graph comparisons in QuickSight.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-5", "source_tokens": 460, "generated_at": "2026-02-11T16:10:26.502577"}}
{"question": "What is the purpose of using stories in QuickSight?", "answer": "Stories are used in QuickSight to convey key points, a thought process, or the evolution of an analysis for collaboration. They serve as guided tours through specific views of an analysis.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T16:10:31.473604"}}
{"question": "What functions can be performed in QuickSight for data analysis?", "answer": "You can perform typical arithmetic and comparison functions, conditional functions such as if,then, and date, numeric, and string calculations in QuickSight.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T16:10:31.473817"}}
{"question": "How does the integration of Billing and Cost Management with QuickSight impact the use of the Cloud Intelligence Dashboards (CID)?", "answer": "The integration of Billing and Cost Management with QuickSight automates the creation of the Cost and Usage Dashboard, bringing the benefits of CID to the Billing and Cost Management console as an AWS supported feature. It removes the need for maintaining underlying infrastructure like Amazon Athena views or AWS Glue crawlers.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-6", "source_tokens": 474, "generated_at": "2026-02-11T16:10:31.474183"}}
{"question": "What IP address range should be added to the security group rules of a VPC with public connectivity to enable traffic flow into the VPC and database instances for QuickSight?", "answer": "The IP address range of QuickSight should be added to the security group rules of the VPC.", "question_type": "factual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T16:10:37.643092"}}
{"question": "How does row-level security (RLS) simplify managing access to data in QuickSight?", "answer": "Row-level security enables dataset owners in QuickSight to control access to data at row granularity based on permissions associated with the user interacting with the data. All associated dashboards and analyses will enforce these rules, allowing users to manage a single set of data and simplifying dataset management.", "question_type": "conceptual", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T16:10:37.643360"}}
{"question": "What are the differences between Amazon QuickSight Standard and Enterprise Edition regarding data source connectivity and security features?", "answer": "Standard Edition supports public connectivity to data sources in AWS and on-premises, while Enterprise Edition offers secure, private communication with data sources in a VPC using an Elastic Network Interface (ENI) and AWS Direct Connect. Enterprise Edition also includes row-level security, hourly refresh of SPICE data, AD connectivity, and group-based management of assets for AD accounts. Downgrading from Enterprise Edition to Standard Edition is not supported due to the differences in feature sets.", "question_type": "comparison", "metadata": {"service": "QUICKSIGHT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "quicksight-faq-7", "source_tokens": 477, "generated_at": "2026-02-11T16:10:37.643754"}}
{"question": "How many billing-related FAQs are there in Amazon RDS?", "answer": "There are 8 billing FAQs in Amazon RDS.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-11T16:10:42.265114"}}
{"question": "What are some of the features that Amazon RDS offers for database configuration?", "answer": "Amazon RDS offers features like Multi-AZ Deployments, Read Replicas, Monitoring and metrics, Amazon RDS Proxy, Trusted Language Extensions for PostgreSQL, Amazon RDS Blue/Green Deployments, and Amazon RDS Optimized Writes and Reads for database configuration.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-11T16:10:42.265471"}}
{"question": "What is the difference between Amazon RDS Optimized Writes and Amazon RDS Optimized Reads?", "answer": "Amazon RDS Optimized Writes and Amazon RDS Optimized Reads are features offered by Amazon RDS. Optimized Writes help to improve write performance, while Optimized Reads help to improve read performance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-0", "source_tokens": 276, "generated_at": "2026-02-11T16:10:42.265996"}}
{"question": "What databases can I use with Amazon RDS?", "answer": "Amazon RDS supports RDS for PostgreSQL, RDS for MySQL,RDS for MariaDB, RDS for SQL Server, RDS for Oracle, and RDS for Db2.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-11T16:10:46.524502"}}
{"question": "How does Amazon RDS help in managing database administration tasks?", "answer": "Amazon RDS offloads database administration by automatically backing up databases, keeping software up to date, and providing flexibility to scale compute resources or storage capacity.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-11T16:10:46.524897"}}
{"question": "What's the difference between using Amazon RDS and managing my own database on Amazon EC2?", "answer": "Amazon RDS is a fully managed service that offloads database administration, while using Amazon EC2 allows you to manage your own relational database in the cloud.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-1", "source_tokens": 465, "generated_at": "2026-02-11T16:10:46.525140"}}
{"question": "What can you create and manage using AWS in relation to a DB instance?", "answer": "You can create and manage DB instances, define or refine infrastructure attributes, control access and security, and run one or more DB instances that can support one or more databases or database schemas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-11T16:10:59.264055"}}
{"question": "How can you modify the backup retention policy and preferred backup window for a DB instance?", "answer": "You can modify the backup retention policy and preferred backup window for a DB instance using the AWS Management Console, Amazon RDS APIs, or AWS Command Line Interface.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-11T16:10:59.264311"}}
{"question": "How does the process of creating a DB instance using the AWS Management Console differ from using the CreateDBInstance API or create-db-instances command?", "answer": "The process of creating a DB instance using the AWS Management Console involves clicking 'RDS' and then the â€˜Launch DB Instanceâ€™ button, specifying the parameters for your DB instance, and retrieving the endpoint via the DB instance description. Using the CreateDBInstance API or create-db-instances command involves making an API call or running a command with the required parameters, and retrieving the endpoint via the API response or command output.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-3", "source_tokens": 376, "generated_at": "2026-02-11T16:10:59.264509"}}
{"question": "How many databases can be created on an RDS for SQL Server instance by default?", "answer": "Up to 100 databases can be created on an RDS for SQL Server instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-11T16:11:04.794447"}}
{"question": "What are the different ways to import data into RDS for MySQL, Oracle, SQL Server, PostgreSQL, and Db2?", "answer": "RDS for MySQL supports mysqldump and mysqlimport utilities for data import. RDS for Oracle can use Data Pump, import/export, or SQL Loader. RDS for SQL Server provides an Import/Export Wizard, full backup files (.bak), or Bulk Copy Program (BCP). RDS for PostgreSQL supports pg_dump. RDS for Db2 allows up to 1 database import per instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-11T16:11:04.794811"}}
{"question": "How does data import and export work in RDS for Oracle compared to other supported database engines?", "answer": "RDS for Oracle supports import and export via Data Pump, import/export, or SQL Loader. These methods allow moving data between Oracle databases and RDS for Oracle.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-4", "source_tokens": 443, "generated_at": "2026-02-11T16:11:04.795284"}}
{"question": "What is the purpose of the maintenance window in Amazon RDS?", "answer": "The maintenance window in Amazon RDS allows users to control when DB instance modifications, database engine version upgrades, and software patching occurs.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-11T16:11:09.305467"}}
{"question": "How does modifying the maintenance window in Amazon RDS benefit users?", "answer": "Modifying the maintenance window in Amazon RDS allows users to choose when maintenance events, such as database engine version upgrades and software patching, occur. This can help minimize the impact on production workloads.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-11T16:11:09.305837"}}
{"question": "What are the types of maintenance events that can take a DB instance offline in Amazon RDS? And how often do they occur?", "answer": "Maintenance events that can take a DB instance offline in Amazon RDS include scale compute operations, database engine version upgrades, and required software patching. Required software patching occurs infrequently, typically once every few months.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-5", "source_tokens": 297, "generated_at": "2026-02-11T16:11:09.306300"}}
{"question": "What metrics does Enhanced Monitoring provide for production databases in RDS?", "answer": "Enhanced Monitoring in RDS provides access to over 50 CPU, memory, file system, and disk I/O metrics.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-11T16:11:14.211885"}}
{"question": "Why would enabling Enhanced Monitoring help improve query performance in RDS?", "answer": "Enhancing Monitoring in RDS can help improve query performance by allowing users to identify and address high levels of CPU utilization, which can reduce query performance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-11T16:11:14.212248"}}
{"question": "What is the difference between accessing slow query logs in RDS for MySQL and MariaDB compared to RDS for Oracle and SQL Server?", "answer": "In RDS for MySQL and MariaDB, users can access the slow query logs to determine if there are slow-running SQL queries and review their performance characteristics. In contrast, for RDS for Oracle and SQL Server, users can use client side traces or server side trace file data, respectively, to identify slow queries.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-6", "source_tokens": 460, "generated_at": "2026-02-11T16:11:14.212635"}}
{"question": "What is the general timeframe for Amazon RDS to support new major and minor database engine versions?", "answer": "Amazon RDS aims to support new engine versions within 5 months of their general availability.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-11T16:11:18.206938"}}
{"question": "How does Amazon RDS determine which new database engine versions to support?", "answer": "Amazon RDS evaluates new engine versions based on releases and patches from the engineâ€™s vendor or development organization, and the outcome of a thorough vetting process by their database engineering team.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-11T16:11:18.207244"}}
{"question": "What is the difference between the way Amazon RDS supports MySQL and PostgreSQL new versions?", "answer": "The text passage does not provide enough information to make a comparison between the ways Amazon RDS supports MySQL and PostgreSQL new versions.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-7", "source_tokens": 147, "generated_at": "2026-02-11T16:11:18.207640"}}
{"question": "What version of the database engine will Amazon RDS automatically upgrade my instance to once it's available?", "answer": "Amazon RDS will automatically upgrade your instance to the latest available minor version that contains significant bug fixes, if you have the Auto Minor Version Upgrade setting enabled.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-11T16:11:22.780282"}}
{"question": "Why should I keep my database instance upgraded in Amazon RDS?", "answer": "You should keep your database instance upgraded in Amazon RDS to ensure you have the latest security and functionality fixes, which are only available in the most current minor versions.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-11T16:11:22.780645"}}
{"question": "What happens when a new minor version of a database engine is made available in Amazon RDS?", "answer": "A new minor version of a database engine is thoroughly tested by Amazon RDS before it's made available. Once available, it becomes the preferred minor version for new DB instances, and older instances can be manually or automatically upgraded.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-8", "source_tokens": 466, "generated_at": "2026-02-11T16:11:22.781104"}}
{"question": "What action is required to upgrade a DB instance to a new major engine version?", "answer": "The upgrade must be initiated by the user.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-11T16:11:26.046247"}}
{"question": "Why does Amazon RDS not perform major version upgrades automatically?", "answer": "Major version upgrades involve compatibility risk and must be initiated manually to allow users to prepare and minimize potential issues.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-11T16:11:26.046612"}}
{"question": "How does the manual upgrade process for major version changes in Amazon RDS compare to automatic updates?", "answer": "Manual upgrades allow users to prepare and minimize potential issues, while automatic updates perform the updates without user intervention.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-9", "source_tokens": 68, "generated_at": "2026-02-11T16:11:26.047115"}}
{"question": "What is the process for upgrading a DB instance to a new major version using Amazon RDS?", "answer": "To upgrade a DB instance to a new major version using Amazon RDS, create a DB snapshot of your existing DB instance, restore from the DB snapshot to create a new DB instance, and then initiate a version upgrade for the new DB instance. You can experiment on the upgraded copy before deciding whether or not to upgrade your original DB instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:11:32.741284"}}
{"question": "Why would you create a new DB instance and upgrade it before upgrading your current one when performing a major version upgrade in Amazon RDS?", "answer": "Creating a new DB instance and upgrading it before upgrading your current one allows you to experiment with the new version safely and assess any potential issues or changes before applying them to your production database.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:11:32.741650"}}
{"question": "How does the process for upgrading a minor version of a database engine in Amazon RDS compare to upgrading a major version?", "answer": "When a minor version is deprecated in Amazon RDS, there is a three-month period before automatic upgrades begin, and instances still running the deprecated minor version will be upgraded to the latest supported minor version during their scheduled maintenance windows. On the other hand, when a major version is deprecated, there is a six-month period before automatic upgrades begin, and instances still running the deprecated version will be upgraded to the next major version during their scheduled maintenance windows.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:11:32.742131"}}
{"question": "What events trigger a billing charge for a DB instance?", "answer": "Billing commences for a DB instance as soon as the DB instance is available and continues until the DB instance terminates, which would occur upon deletion or in the event of an instance failure.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-11T16:11:37.761170"}}
{"question": "Why might Amazon RDS deprecate certain database versions without notice?", "answer": "Amazon RDS may deprecate specific major or minor versions without prior notice when they do not meet Amazon RDS's high quality, performance, or security bar.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-11T16:11:37.761480"}}
{"question": "How does pricing for Amazon RDS vary between different storage types?", "answer": "Amazon RDS charges for storage based on the capacity you have provisioned, with a pro-rated bill if you scale your storage within the month. There is an additional charge for I/O requests per month for Amazon RDS Magnetic Storage and Amazon Aurora, whereas there is a provisioned IOPS rate for Amazon RDS Provisioned IOPS (SSD) Storage.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-11", "source_tokens": 470, "generated_at": "2026-02-11T16:11:37.761976"}}
{"question": "What are DB instance hours billed for in AWS?", "answer": "DB instance hours are billed for each hour your DB instance is running in an available state.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-11T16:11:41.044829"}}
{"question": "Why don't we get charged for DB instance hours when the instance is stopped?", "answer": "We don't get charged for DB instance hours when the instance is stopped because the instance is not running in an available state.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-11T16:11:41.045203"}}
{"question": "What are we charged for when the DB instance is stopped?", "answer": "We are charged for provisioned storage and backup storage when the DB instance is stopped.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-12", "source_tokens": 146, "generated_at": "2026-02-11T16:11:41.045650"}}
{"question": "What is the amount of free backup storage provided in this account and region based on the provisioned database storage?", "answer": "Free backup storage is provided up to the account's total provisioned database storage across the entire region.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-11T16:11:45.687650"}}
{"question": "How does the backup storage work in relation to the provisioned database storage in AWS RDS?", "answer": "Each day, your account's total provisioned database storage in the region is compared against your total backup storage in the region. Backup storage beyond the free allocation is charged daily, based on the excess backup storage.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-11T16:11:45.687935"}}
{"question": "How does the backup storage capacity compare between a DB instance and its associated backups in AWS RDS?", "answer": "The size of the DB instance's backups is directly proportional to the amount of data on the instance. However, the free backup storage is not displayed in the RDS Console or DescribeDBSnapshots API response.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-13", "source_tokens": 498, "generated_at": "2026-02-11T16:11:45.688120"}}
{"question": "What is the billing structure for Multi-AZ DB instance hours in Amazon RDS?", "answer": "Multi-Aqua DB instance hours are billed based on the class of the DB instance consumed.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-11T16:11:49.726992"}}
{"question": "How does Multi-AZ deployment impact I/O requests in Amazon RDS?", "answer": "Multi-AZ deployments consume a larger volume of I/O requests than standard DB instance deployments due to synchronous replication.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-11T16:11:49.727368"}}
{"question": "What is the difference in I/O charges between standard and Multi-AZ DB instances in Amazon RDS?", "answer": "Write I/O usage associated with database updates is doubled for Multi-AZ deployments, but read I/O usage remains the same.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-14", "source_tokens": 464, "generated_at": "2026-02-11T16:11:49.727766"}}
{"question": "What free database instance hours does AWS Free Tier offer for Amazon RDS per month?", "answer": "AWS Free Tier offers 750 hours of free instance usage for Amazon RDS Single-AZ Micro DB instances per month.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T16:11:54.725448"}}
{"question": "How does the usage of multiple Single-AZ Micro DB instances affect the AWS Free Tier for Amazon RDS?", "answer": "You can run multiple Single-AZ Micro DB instances and still be eligible for usage counted under the AWS Free Tier for Amazon RDS, but any usage beyond 750 hours, across all Amazon RDS Single-AZ Micro DB instances and across all eligible database engines and regions, will be billed at standard Amazon RDS prices.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T16:11:54.725741"}}
{"question": "How does the pricing of Amazon RDS reserved instances compare to the on-demand instance pricing?", "answer": "Amazon RDS reserved instances offer significant discounts compared to on-demand instance pricing for a DB instance in exchange for a one or three year term.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-15", "source_tokens": 483, "generated_at": "2026-02-11T16:11:54.726123"}}
{"question": "What is the difference in billing between a Reserved Instance and an On-Demand DB instance in Amazon RDS?", "answer": "With a Reserved Instance, you purchase a one- or three-year reservation and receive a lower effective hourly usage rate compared to On-Demand DB instances for the duration of the term. On-Demand DB instances are billed at hourly rates.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-11T16:11:58.994974"}}
{"question": "Why would you use a Reserved Instance instead of an On-Demand DB instance in Amazon RDS?", "answer": "You would use a Reserved Instance if you want to secure a lower hourly usage rate for your DB instance for a specific term and region. This can help with budget planning and cost savings.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-11T16:11:58.995343"}}
{"question": "Can I use a Reserved Instance in a specific Availability Zone instead of a Region?", "answer": "No, Amazon RDS reserved instances are purchased for a Region rather than for a specific Availability Zone. They are not capacity reservations.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-16", "source_tokens": 439, "generated_at": "2026-02-11T16:11:58.995840"}}
{"question": "What happens to the pricing of a reserved instance once the request is received?", "answer": "The pricing changes for a reserved instance are activated once the request is received.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-11T16:12:02.699773"}}
{"question": "How can I monitor the status of my reserved DB instance's pricing?", "answer": "You can follow the status of your reservation on the AWS Account Activity page or use the DescribeReservedDBInstances API or the describe-reserved-db-instances command.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-11T16:12:02.700176"}}
{"question": "What happens to the pricing of a reserved DB instance when the payment authorization fails?", "answer": "If the one-time payment cannot be successfully authorized by the next billing period, the discounted price will not take effect.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-17", "source_tokens": 188, "generated_at": "2026-02-11T16:12:02.700430"}}
{"question": "What attributes are associated with each reservation in AWS RDS?", "answer": "Each reservation is associated with the following set of attributes: DB engine, DB instance class, Multi-AZ deployment option, license model, and Region.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-11T16:12:06.943597"}}
{"question": "What happens if I scale up a DB instance that is associated with a size-flexible reservation?", "answer": "If you scale up a DB instance that is associated with a size-flexible reservation, the discounted rate of the RI will cover 1/2 of the usage of the larger DB instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-11T16:12:06.943958"}}
{"question": "Can I apply a DB instance reservation to a read replica?", "answer": "Yes, a DB instance reservation can be applied to a read replica, provided the DB instance class and Region are the same.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-18", "source_tokens": 509, "generated_at": "2026-02-11T16:12:06.944177"}}
{"question": "What happens if I cancel a Reserved DB instance with an upfront payment?", "answer": "You cannot cancel a Reserved DB instance and the one-time payment is not refundable. You will continue to pay for every hour during the Reserved DB instance term regardless of your usage.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-11T16:12:12.166626"}}
{"question": "Why can't you cancel a Reserved DB instance with an upfront payment and what are the billing implications?", "answer": "You cannot cancel a Reserved DB instance and once paid, the one-time payment is non-refundable. You will continue to be billed for every hour during the Reserved DB instance term, regardless of your usage.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-11T16:12:12.166923"}}
{"question": "How does the billing for a Reserved DB instance with an upfront payment compare to one with a no upfront payment?", "answer": "For a Reserved DB instance with an upfront payment, the entire payment for the term is paid in one upfront payment. For a Reserved DB instance with no upfront payment, the entire value is spread across every hour in the term and you are billed for every hour in the term, regardless of usage.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-19", "source_tokens": 411, "generated_at": "2026-02-11T16:12:12.167366"}}
{"question": "What type of storage does Amazon RDS use for database and log storage?", "answer": "Amazon RDS uses EBS volumes for database and log storage.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-11T16:12:17.405115"}}
{"question": "How does Amazon RDS enhance IOPS performance for larger storage requests?", "answer": "Amazon RDS automatically stripes across multiple EBS volumes to enhance IOPS performance for larger storage requests.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-11T16:12:17.405465"}}
{"question": "What are the differences between Amazon RDS General Purpose (SSD) Storage and Amazon RDS Provisioned IOPS (SSD) Storage?", "answer": "Amazon RDS General Purpose (SSD) Storage is suitable for a broad range of database workloads with moderate I/O requirements and provides a baseline of 3 IOPS/GB and ability to burst up to 3,000 IOPS. Amazon RDS Provisioned IOPS (SSD) Storage is an SSD-backed storage option designed to deliver fast, predictable, and consistent I/O performance and allows users to specify an IOPS rate when creating a DB instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-20", "source_tokens": 488, "generated_at": "2026-02-11T16:12:17.405953"}}
{"question": "What type of Amazon RDS storage is recommended for small database workloads with less frequent data access?", "answer": "Amazon RDS magnetic storage", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-11T16:12:21.186121"}}
{"question": "Why isn't magnetic storage recommended for production database instances on Amazon RDS?", "answer": "Magnetic storage is not recommended for production database instances on Amazon RDS due to its lower performance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-11T16:12:21.186484"}}
{"question": "How does Amazon RDS Provisioned IOPS (SSD) Storage compare to magnetic storage for database workloads?", "answer": "Amazon RDS Provisioned IOPS (SSD) Storage is recommended for high-performance OLTP workloads, while magnetic storage is suitable for small database workloads with less frequent data access.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-21", "source_tokens": 127, "generated_at": "2026-02-11T16:12:21.186972"}}
{"question": "What is the default retention period for automated backups in Amazon RDS?", "answer": "The default retention period for automated backups in Amazon RDS is 7 days.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T16:12:25.728797"}}
{"question": "How does Amazon RDS allow for restoring a DB instance to a specific time?", "answer": "Amazon RDS allows for restoring a DB instance to a specific time by applying transaction logs to the most appropriate daily backup during the retention period. This process is initiated through point-in-time recovery.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T16:12:25.729083"}}
{"question": "What is the difference between automated backups and DB snapshots in Amazon RDS in terms of retention and initiation?", "answer": "Automated backups are initiated by Amazon RDS and are retained for a user-specified retention period (default 7 days, up to 35 days). DB snapshots are user-initiated and are kept until explicitly deleted. Automated backups enable point-in-time recovery, while DB snapshots allow for restoring to a specific state at any time.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-22", "source_tokens": 485, "generated_at": "2026-02-11T16:12:25.729241"}}
{"question": "What happens when you create a DB Instance from a point in time or from a DB Snapshot?", "answer": "A new DB Instance is created with a new endpoint. The old DB Instance can be deleted if desired.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-11T16:12:29.912473"}}
{"question": "Why is a new DB Instance created when restoring from a DB Snapshot or a specific point in time?", "answer": "This is done to allow the creation of multiple DB Instances from a single snapshot or point in time.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-11T16:12:29.912840"}}
{"question": "How does creating a DB Instance from a snapshot or a specific point in time differ from creating a new DB Instance from scratch?", "answer": "The main difference is that when creating from a snapshot or point in time, a new DB Instance is created with the same data at that specific state, while creating a new DB Instance from scratch results in an empty database.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-23", "source_tokens": 68, "generated_at": "2026-02-11T16:12:29.913315"}}
{"question": "What is the default backup retention period for Amazon RDS?", "answer": "Amazon RDS enables automated backups of your DB instance with a 7-day retention period by default.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-11T16:12:34.578502"}}
{"question": "How can I modify the backup retention period for my Amazon RDS instance and what are the restrictions?", "answer": "You can modify the backup retention period for your Amazon RDS instance using the RDS Console, the CreateDBInstance API, or the ModifyDBInstance API. The value can be any number from 0 to the desired number of days, up to 35. However, if the DB instance is a source to Read Replicas, the value cannot be set to 0.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-11T16:12:34.578788"}}
{"question": "Where are Amazon RDS DB snapshots and automated backups stored?", "answer": "Amazon RDS DB snapshots and automated backups are stored in S3.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-24", "source_tokens": 480, "generated_at": "2026-02-11T16:12:34.579177"}}
{"question": "How many automated DB snapshots are normally created for a given retention period?", "answer": "One or two more automated DB snapshots than the number of days in the retention period are normally created.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-11T16:12:38.481297"}}
{"question": "Why are extra automated DB snapshots created?", "answer": "Extra automated DB snapshots are created to ensure the ability to perform a point in time restore to any time during the retention period.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-11T16:12:38.481549"}}
{"question": "How does Amazon VPC enable running public-facing web applications with private backend servers?", "answer": "Amazon VPC allows creating a public-facing subnet for webservers with Internet access and a private-facing subnet for backend Amazon RDS DB Instances with no Internet access.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-25", "source_tokens": 426, "generated_at": "2026-02-11T16:12:38.481933"}}
{"question": "What type of environment can I use to deploy Amazon RDS if my account was created before 2013-12-04?", "answer": "You may be able to run Amazon RDS in an Amazon Elastic Compute Cloud (EC2)-Classic environment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-11T16:12:46.523205"}}
{"question": "Why should I create a DB Subnet Group when deploying Amazon RDS in a VPC?", "answer": "A DB Subnet Group is a collection of subnets that you may want to designate for your Amazon RDS DB Instances in a VPC. Each DB Subnet Group should have at least one subnet for every Availability Zone in a given Region. When creating a DB Instance in VPC, you will need to select a DB Subnet Group. Amazon RDS then uses that DB Subnet Group and your preferred Availability Zone to select a subnet and an IP address within that subnet. This is important for managing access to your DB Instances and ensuring high availability.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-11T16:12:46.523569"}}
{"question": "What's the difference between using a DB Subnet Group in EC2-Classic and EC2-VPC for Amazon RDS?", "answer": "In EC2-Classic, you don't need a DB Subnet Group when deploying Amazon RDS. However, in EC2-VPC, a DB Subnet Group is a collection of subnets that you may want to designate for your Amazon RDS DB Instances. Each DB Subnet Group should have at least one subnet for every Availability Zone in a given Region. When creating a DB Instance in VPC, you will need to select a DB Subnet Group. Amazon RDS then uses that DB Subnet Group and your preferred Availability Zone to select a subnet and an IP address within that subnet. This helps in managing access to your DB Instances and ensuring high availability.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-26", "source_tokens": 446, "generated_at": "2026-02-11T16:12:46.524050"}}
{"question": "What is required to access a DB Instance deployed within a VPC from EC2 Instances outside the VPC?", "answer": "To access a DB Instance deployed within a VPC from EC2 Instances outside the VPC, you can use a VPN Gateway or launch a bastion host in the public subnet and set up public access for the DB Instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-11T16:12:52.128870"}}
{"question": "How do I allow access to a DB Instance deployed within a VPC from EC2 Instances outside the VPC?", "answer": "You can allow access to a DB Instance deployed within a VPC from EC2 Instances outside the VPC by setting up a VPN Gateway or launching a bastion host in the public subnet and configuring public access for the DB Instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-11T16:12:52.129234"}}
{"question": "What is the difference between setting up a VPN and launching a bastion host to access a DB Instance in a VPC from EC2 Instances outside the VPC?", "answer": "Setting up a VPN Gateway extends your corporate network into your VPC and allows access to the Amazon RDS DB instance in that VPC, while launching a bastion host involves setting up a public subnet with an EC2 instance that acts as an SSH Bastion and then forwarding requests to the private IP address of the Amazon RDS DB instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-27", "source_tokens": 498, "generated_at": "2026-02-11T16:12:52.129677"}}
{"question": "What actions are required to ensure DB instance reachability from client instances in a VPC?", "answer": "Modifying routing tables and networking ACLs in your VPC is necessary to ensure that your DB instance is reachable from your client instances.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-11T16:12:56.376376"}}
{"question": "Why is it essential to configure networking ACLs for Multi-AZ deployments after a failover?", "answer": "Configuring networking ACLs to allow cross-AZ communication is necessary after a failover, as the client EC2 instance and Amazon RDS DB Instance may be in different Availability Zones.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-11T16:12:56.376849"}}
{"question": "How does updating a DB Subnet Group impact the availability of running instances?", "answer": "Removing subnets from an existing DB Subnet Group can cause unavailability for instances running in the removed Availability Zone.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-28", "source_tokens": 359, "generated_at": "2026-02-11T16:12:56.377079"}}
{"question": "What are the default privileges for the primary user in MySQL?", "answer": "The primary user in MySQL has default privileges for: create, drop, references, event, alter, delete, index, insert, select, update, create temporary tables, lock tables, trigger, create view, show view, alter routine, create routine, execute, trigger, create user, process, show databases, and grant option.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T16:13:02.534101"}}
{"question": "What role is the primary user granted in Oracle's Amazon RDS? How does this impact their privileges?", "answer": "The primary user in Oracle's Amazon RDS is granted the 'dba' role, which grants them most of the privileges associated with the role. Users should refer to the Amazon RDS User Guide for the list of restricted privileges and the corresponding alternatives to perform administrative tasks.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T16:13:02.534497"}}
{"question": "What is the difference in default privileges between the primary user in MySQL and Oracle's Amazon RDS?", "answer": "The primary user in MySQL has a long list of privileges, while the primary user in Oracle's Amazon RDS is granted the 'dba' role, which grants them most of the privileges associated with the role. Users should refer to the Amazon RDS User Guide for the list of restricted privileges and the corresponding alternatives for Oracle.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-29", "source_tokens": 504, "generated_at": "2026-02-11T16:13:02.534973"}}
{"question": "What encryption method does Amazon RDS use at rest for all database engines?", "answer": "Amazon RDS uses encryption at rest for all database engines using keys managed through AWS Key Management Service (KMS).", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-11T16:13:08.167304"}}
{"question": "How does encryption work for Amazon RDS users when dealing with data at rest?", "answer": "Amazon RDS users can encrypt data at rest on their database instances using AWS KMS keys. This encryption applies to the underlying storage, automated backups, read replicas, and snapshots. Encryption and decryption are handled transparently.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-11T16:13:08.167663"}}
{"question": "What are the differences between encryption at rest using AWS KMS and Transparent Data Encryption (TDE) for Oracle and SQL Server engines in Amazon RDS?", "answer": "AWS KMS encrypts data at rest for all database engines in Amazon RDS, while Transparent Data Encryption (TDE) is specific to Oracle and SQL Server engines. AWS KMS uses keys managed by AWS, whereas TDE is an engine-level feature that encrypts data before it is written to the database. For more information, consult the Amazon RDS User's Guide for Oracle and SQL Server.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-30", "source_tokens": 474, "generated_at": "2026-02-11T16:13:08.168151"}}
{"question": "What Amazon RDS database engines are HIPAA-eligible?", "answer": "All Amazon RDS database engines are HIPAA-eligible.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-11T16:13:12.339400"}}
{"question": "Why can you create a new DB Parameter Group to modify engine configuration values for a DB Instance?", "answer": "You can create a new DB Parameter Group to modify engine configuration values for a DB Instance if you want your DB Instance to run with your custom-specified engine configuration values.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-11T16:13:12.339768"}}
{"question": "How does using AWS Config affect configuration changes to Amazon RDS resources?", "answer": "Using AWS Config allows you to continuously record configuration changes to Amazon RDS DB Instances and receive notifications of changes through Amazon Simple Notification Service. You can also create AWS Config Rules to evaluate whether these Amazon RDS resources have the desired configurations.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-31", "source_tokens": 496, "generated_at": "2026-02-11T16:13:12.340222"}}
{"question": "What role does the standby DB instance play in a Multi-AZ deployment?", "answer": "The standby DB instance is an up-to-date replica of the primary DB instance in a Multi-AZ deployment. It is used as the primary instance in failover scenarios. Before failover, the standby is not used for database operations.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-11T16:13:17.383758"}}
{"question": "How does Amazon RDS maintain data synchronization between the primary and standby DB instances in a Multi-AZ deployment?", "answer": "Amazon RDS synchronously replicates updates to the primary DB instance across Availability Zones to the standby, keeping both instances in sync.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-11T16:13:17.384059"}}
{"question": "What are the main differences between the primary and standby DB instances in a Multi-AZ deployment?", "answer": "The primary DB instance serves database writes and reads. The standby is a replica of the primary that is promoted to become the primary in failover scenarios. Users do not interact with the standby prior to promotion.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-32", "source_tokens": 485, "generated_at": "2026-02-11T16:13:17.384469"}}
{"question": "What are the two main benefits of using a Multi-AZ DB instance deployment in Amazon RDS?", "answer": "The two main benefits of using a Multi-AZ DB instance deployment in Amazon RDS are enhanced database durability and availability.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-11T16:13:23.426204"}}
{"question": "Why is a Multi-AZ DB instance deployment important for production environments in Amazon RDS?", "answer": "A Multi-AZ DB instance deployment in Amazon RDS provides enhanced database availability and fault tolerance, making it a natural fit for production environments. In case of DB instance component failure or loss of availability in one Availability Zone, Amazon RDS automatically initiates a failover to the standby, ensuring data integrity and minimizing downtime.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-11T16:13:23.426514"}}
{"question": "How does the availability impact of a DB instance failure compare between a standard DB instance deployment in a single Availability Zone and a Multi-AZ DB instance deployment in Amazon RDS?", "answer": "In a standard DB instance deployment in a single Availability Zone, a user-initiated restore operation is required in case of a DB instance failure, and updates that occurred after the latest restorable time (typically within the last five minutes) may not be available. In contrast, a Multi-AZ DB instance deployment in Amazon RDS limits the availability impact to the time required for automatic failover to complete.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-33", "source_tokens": 444, "generated_at": "2026-02-11T16:13:23.426904"}}
{"question": "What is the role of the standby instance in a Multi-AZ DB instance deployment?", "answer": "The standby instance in a Multi-AZ DB instance deployment is used for enhanced database availability and durability through synchronous replication with the primary instance. It cannot be used for read or write operations.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-11T16:13:28.418226"}}
{"question": "Why can't the standby instance in a Multi-AZ DB instance deployment be used for read requests?", "answer": "The standby instance is designed for enhanced database availability and durability through synchronous replication with the primary instance. It cannot be used for read or write operations as it is constantly in sync with the primary.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-11T16:13:28.418511"}}
{"question": "How does converting a single-AZ RDS instance to a Multi-AZ instance impact read performance?", "answer": "Converting a single-AZ RDS instance to a Multi-AZ instance does not cause any downtime but might result in increased latency while the data on the standby is caught up to match the primary.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-34", "source_tokens": 419, "generated_at": "2026-02-11T16:13:28.418907"}}
{"question": "What are the common failure scenarios that trigger an automatic failover in Amazon RDS for Multi-AZ deployments?", "answer": "Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, or Storage failure on primary.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-11T16:13:33.569050"}}
{"question": "How does Amazon RDS handle failover in Multi-AZ deployments and what is the typical recovery time?", "answer": "Amazon RDS handles failover by flipping the canonical name record (CNAME) for the DB instance to point at the standby, which is then promoted to become the new primary. Failovers typically complete within one to two minutes.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-11T16:13:33.569422"}}
{"question": "What's the difference between failover time in case of a compute unit failure and a storage failure in Amazon RDS Multi-AZ deployments?", "answer": "The text passage does not provide enough information for a comparison between failover time in case of a compute unit failure and a storage failure.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-35", "source_tokens": 460, "generated_at": "2026-02-11T16:13:33.569934"}}
{"question": "What option does Amazon RDS provide for initiating a failover when rebooting your instance?", "answer": "You can initiate a failover when rebooting your instance via the AWS Management Console or when using the RebootDBInstance API call.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-11T16:13:39.520038"}}
{"question": "How does Multi-AZ deployment work in Amazon RDS?", "answer": "With Multi-AZ deployments in Amazon RDS, you set the â€˜Multi-AZâ€™ parameter to true, and Amazon RDS handles the creation of the standby, synchronous replication, and failover automatically. You cannot select the Availability Zone for the standby or alter the number of standbys. The standby is also not configured to accept database read activity.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-11T16:13:39.520351"}}
{"question": "How does Multi-AZ deployment in Amazon RDS compare to having redundancy across multiple Availability Zones for the entire application?", "answer": "Multi-AZ deployments in Amazon RDS and having redundancy across multiple Availability Zones for the entire application serve similar purposes but focus on different aspects. Multi-AZ deployments specifically address the database tier and are handled automatically by Amazon RDS, while having redundancy across multiple Availability Zones for the entire application requires architecting your application and other AWS resources with this redundancy.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-36", "source_tokens": 321, "generated_at": "2026-02-11T16:13:39.520763"}}
{"question": "What happens to automated backups and DB Snapshots in a Multi-AZ deployment?", "answer": "Automated backups and DB Snapshots in a Multi-AZ deployment are taken from the standby instance to avoid I/O suspension on the primary instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-11T16:13:44.616027"}}
{"question": "Why is creating read replicas beneficial for read-heavy workloads in AWS RDS?", "answer": "Creating read replicas allows users to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads by taking advantage of supported engines' built-in replication functionality.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-11T16:13:44.616298"}}
{"question": "How does initiating a restore operation differ between Single-AZ and Multi-AZ deployments?", "answer": "The process of initiating a restore operation (point-in-time restore or restore from DB Snapshot) is the same for Single-AZ and Multi-AZ deployments. However, in a Multi-AZ deployment, the new DB instance deployments can also be Multi-AZ.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-37", "source_tokens": 445, "generated_at": "2026-02-11T16:13:44.616435"}}
{"question": "What reasons are there for creating read replicas of a DB instance?", "answer": "Read replicas can be used for scaling beyond the capacity of a single DB instance for read-heavy workloads, serving read traffic during source DB instance unavailability, business reporting or data warehousing, and disaster recovery in the same or different AWS Regions.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-11T16:13:48.923668"}}
{"question": "Why is it important to enable automatic backups on the source DB instance before creating read replicas?", "answer": "Automatic backups must remain enabled for read replicas to function.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-11T16:13:48.924044"}}
{"question": "How does using a read replica for business reporting compare to using the primary DB instance?", "answer": "Running business reporting queries against a read replica instead of the primary DB instance allows for read traffic to be offloaded from the production DB instance.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-38", "source_tokens": 274, "generated_at": "2026-02-11T16:13:48.924511"}}
{"question": "Which databases support read replicas in Amazon RDS for MySQL?", "answer": "All DB instances in Amazon RDS for MySQL support creation of read replicas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-11T16:13:53.248337"}}
{"question": "Why is automatic backup enabled for read replica creation in Amazon RDS for MySQL?", "answer": "Automatic backups must be and remain enabled on the source DB instance for read replica operations.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-11T16:13:53.248604"}}
{"question": "How does Amazon RDS for MySQL and Amazon RDS for PostgreSQL compare in terms of read replica support for different versions?", "answer": "Amazon RDS for MySQL supports automatic backups for read replicas running MySQL 5.6 and later. Amazon RDS for PostgreSQL requires upgrading existing PostgreSQL instances to version 9.3.5 or newer to create read replicas.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-39", "source_tokens": 318, "generated_at": "2026-02-11T16:13:53.248741"}}
{"question": "What is required to identify a read replica when creating one?", "answer": "You need to specify a SourceDBInstanceIdentifier, which is the DB Instance Identifier of the source DB Instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T16:13:57.727694"}}
{"question": "How does the creation of multiple read replicas within a short timeframe impact the source DB instance?", "answer": "Amazon RDS is currently working on an optimization to minimize I/O impact by ensuring all read replicas created within a 30-minute window use the same source snapshot.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T16:13:57.728063"}}
{"question": "How does the number of read replicas allowed vary between different database engines in Amazon RDS?", "answer": "Amazon RDS for MySQL, MariaDB, and PostgreSQL allow up to 15 read replicas, while Amazon RDS for Oracle and SQL Server allow up to 5.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-40", "source_tokens": 507, "generated_at": "2026-02-11T16:13:57.728546"}}
{"question": "What type of replication is used in Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server read replicas?", "answer": "Amazon RDS read replicas use their engines' native asynchronous replication.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-11T16:14:02.674215"}}
{"question": "How does Multi-AZ deployment's replication compare to read replica's replication in terms of write availability and data protection?", "answer": "Multi-AZ deployment's replication is synchronous, protecting the latest database updates, while read replica's replication is asynchronous and can vary significantly in replication lag.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-11T16:14:02.674566"}}
{"question": "What are the benefits of using Multi-AZ deployments and read replicas together in a production environment?", "answer": "Multi-AZ deployments provide enhanced write availability and data durability, while read replicas improve read traffic scalability. When using Multi-AZ deployments, associated read replicas automatically resume replication post-failover.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-41", "source_tokens": 449, "generated_at": "2026-02-11T16:14:02.675058"}}
{"question": "Which databases support second-tier and third-tier read replicas?", "answer": "Amazon Aurora, Amazon RDS for MySQL, and MariaDB support second-tier and third-tier read replicas.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-11T16:14:07.224604"}}
{"question": "Why would you create a third-tier read replica?", "answer": "You might create a third-tier read replica to further distribute replication load from the primary database instance to the secondary and tertiary read replicas based on your application needs.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-11T16:14:07.224882"}}
{"question": "How does the latency differ between a primary database and a third-tier read replica?", "answer": "The primary database has the least latency, while a third-tier read replica may have greater latency due to the additional replication lag between the primary, first-tier, and second-tier read replicas.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-42", "source_tokens": 385, "generated_at": "2026-02-11T16:14:07.225035"}}
{"question": "What reasons can cause a read replica to fall behind its source DB instance?", "answer": "A read replica can fall behind its source DB instance due to write I/O volume to the source DB instance exceeding the application rate to the read replica, complex or long-running transactions to the source DB Instance holding up replication to the read replica, or network partitions or latency between the source DB instance and a read replica.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-11T16:14:12.183386"}}
{"question": "How does replication technology impact the consistency between a read replica and its source DB instance?", "answer": "Replication technology, specifically the asynchronous replication used with supported engines, can result in a lag or inconsistency between a read replica and its source DB Instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-11T16:14:12.183785"}}
{"question": "How does the performance of a read replica compare to the source DB instance in terms of handling write workloads?", "answer": "The performance of a read replica in handling write workloads can be less than the source DB instance, depending on the compute capacity of the read replica.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-43", "source_tokens": 203, "generated_at": "2026-02-11T16:14:12.184246"}}
{"question": "What metric provides information about the lag between a read replica and its source DB instance in Amazon RDS?", "answer": "The 'Replica Lag' metric is published via the AWS Management Console or Amazon CloudWatch APIs to indicate the number of seconds that a read replica is behind its source DB instance.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-11T16:14:17.582373"}}
{"question": "How can you identify and resolve replication issues in Amazon RDS for MySQL and PostgreSQL?", "answer": "You can review the Replication State and the Replication Error field in the AWS Management Console to identify replication issues. For MySQL engines, you can learn more about troubleshooting these issues in the User Guide for Amazon RDS for MySQL. For PostgreSQL engines, you can use the pg_stat_replication view on the source DB instance to explore replication metrics.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-11T16:14:17.582747"}}
{"question": "What are the recommended resources for read replicas to ensure effective replication and to prevent lag in Amazon RDS?", "answer": "To prevent lag or ensure effective replication, read replicas in Amazon RDS should have as much or more compute and storage resources as their respective source DB instances.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-44", "source_tokens": 406, "generated_at": "2026-02-11T16:14:17.583228"}}
{"question": "What happens to an Amazon Aurora replica when its source DB Instance is deleted?", "answer": "An Amazon Aurora replica will remain active and continue accepting read traffic even after its corresponding source DB Instance has been deleted. One of the replicas in the cluster will be promoted as the new primary and will start accepting write traffic.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-11T16:14:22.841509"}}
{"question": "How does deleting a read replica for Amazon RDS for MySQL or MariaDB differ from deleting an Aurora read replica?", "answer": "When deleting a read replica for Amazon RDS for MySQL or MariaDB, you must also explicitly delete the source DB instance using the DeleteDBInstance API or AWS Management Console if you don't want to delete it. For an Aurora read replica, the replica will be promoted as the new primary and will continue accepting write traffic when the source DB Instance is deleted.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-11T16:14:22.841785"}}
{"question": "What monitoring and metrics solution simplifies database troubleshooting by automating telemetry collection and providing a unified view of database performance and health?", "answer": "CloudWatch Database Insights", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-45", "source_tokens": 483, "generated_at": "2026-02-11T16:14:22.842182"}}
{"question": "What metrics does Enhanced Monitoring collect for Amazon RDS instances?", "answer": "Enhanced Monitoring for Amazon RDS collects vital operating system metrics and process information at the defined granularity. The complete list of metrics can be found in the documentation.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-11T16:14:27.017032"}}
{"question": "How does CloudWatch Database Insights differ from Enhanced Monitoring for Amazon RDS?", "answer": "CloudWatch Database Insights provides pre-built dashboards, alarms, and insights for monitoring and optimizing database performance, while Enhanced Monitoring collects system level metrics and process information for Amazon RDS instances.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-11T16:14:27.017408"}}
{"question": "Which Amazon RDS database engines support Enhanced Monitoring?", "answer": "Enhanced Monitoring supports all Amazon RDS database engines.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-46", "source_tokens": 480, "generated_at": "2026-02-11T16:14:27.017869"}}
{"question": "What metrics and process information can I view for my Amazon RDS DB Instances on the console?", "answer": "You can view all the system metrics and process information for your Amazon RDS DB Instances in a graphical format on the console.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-11T16:14:31.645440"}}
{"question": "Why would I use CloudWatch to monitor my Amazon RDS instances instead of the console?", "answer": "You should use CloudWatch if you want to view historical data beyond what is available on the Amazon RDS console dashboard.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-11T16:14:31.645723"}}
{"question": "How do I consume the metrics from Amazon RDS Enhanced Monitoring using a third-party dashboard or application?", "answer": "There are two ways to consume the metrics: you can use CloudWatch Logs Subscriptions to set up a near real-time feed for the metrics, or you can use filters in CloudWatch Logs to bridge metrics across to CloudWatch and integrate your application with CloudWatch.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-47", "source_tokens": 505, "generated_at": "2026-02-11T16:14:31.646151"}}
{"question": "What is the default retention period for Enhanced Monitoring in CloudWatch Logs?", "answer": "The default retention period for Enhanced Monitoring in CloudWatch Logs is 30 days.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-11T16:14:36.151082"}}
{"question": "How does the retention period for Enhanced Monitoring in CloudWatch Logs compare to that of other CloudWatch Logs streams?", "answer": "The default retention period for Enhenced Monitoring in CloudWatch Logs is 30 days, while the retention period for other CloudWatch Logs streams can be controlled similarly.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-11T16:14:36.151350"}}
{"question": "What are the capabilities of CloudWatch Database Insights compared to Amazon RDS Performance Insights?", "answer": "CloudWatch Database Insights inherits all the capabilities of Amazon RDS Performance Insights and adds fleet-level monitoring, integration with application performance monitoring, and correlation of database metrics with logs and events.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-48", "source_tokens": 412, "generated_at": "2026-02-11T16:14:36.151845"}}
{"question": "What are the three main benefits of using Amazon RDS Proxy?", "answer": "Amazon RDS Proxy improves scalability by pooling and sharing database connections, improves availability by reducing database failover times by up to 66% and preserving application connections during failovers, and improves security by optionally enforcing AWS IAM authentication to databases and securely storing credentials in AWS Secrets Manager.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-11T16:14:41.233334"}}
{"question": "How does Amazon RDS Proxy enhance application availability?", "answer": "Amazon RDS Proxy enhances application availability by reducing database failover times by up to 66% and preserving application connections during failovers.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-11T16:14:41.233597"}}
{"question": "What's the difference between Amazon RDS Proxy and traditional database connection pooling?", "answer": "Both Amazon RDS Proxy and traditional database connection pooling aim to improve application performance by reusing database connections. However, Amazon RDS Proxy offers additional benefits such as high availability and security, as it fully manages and automatically handles database connections and enforces IAM authentication and credentials management.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-49", "source_tokens": 107, "generated_at": "2026-02-11T16:14:41.233994"}}
{"question": "What are three use cases for Amazon RDS Proxy in terms of scalability, availability, and security?", "answer": "Amazon RDS Proxy addresses use cases related to scalability, availability, and security of applications. It handles applications with unpredictable workloads by allowing efficient reuse of database connections, maintaining predictable database performance, and removing requests that cannot be served. It also helps applications that frequently open and close database connections by maintaining a pool of database connections to avoid unnecessary stress on database compute and memory. Additionally, it supports applications that keep connections open but idle by holding idling connections while only establishing database connections as required. ", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-11T16:14:47.937081"}}
{"question": "How does Amazon RDS Proxy improve handling of applications with unpredictable workloads?", "answer": "Amazon RDS Proxy improves handling of applications with unpredictable workloads by allowing efficient reuse of database connections through enabling multiple application connections to share a database connection, maintaining predictable database performance by regulating the number of database connections that are opened, and removing requests that cannot be served to preserve the overall performance and availability of the application.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-11T16:14:47.937373"}}
{"question": "What is the difference between how Amazon RDS Proxy handles applications with frequent database connections and applications with idle connections?", "answer": "Amazon RDS Proxy maintains a pool of database connections to avoid unnecessary stress on database compute and memory for applications that frequently open and close database connections. It holds idling connections while only establishing database connections as required for applications that keep connections open but idle.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-50", "source_tokens": 495, "generated_at": "2026-02-11T16:14:47.937787"}}
{"question": "How much network latency does Amazon RDS Proxy add on average?", "answer": "Amazon RDS Proxy adds an average of 5 milliseconds of network latency to query or transaction response time.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-11T16:14:54.102523"}}
{"question": "What benefits does Amazon RDS Proxy provide for building serverless applications with relational databases?", "answer": "Amazon RDS Proxy enables efficient scaling by pooling and reusing database connections, eliminates the need to handle database credentials in Lambda code, and requires no new infrastructure or code to utilize the full potential of serverless applications backed by relational databases.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-11T16:14:54.102906"}}
{"question": "How does Amazon RDS Proxy for MariaDB compare to Amazon RDS Proxy for MySQL in terms of supported database engines?", "answer": "Both Amazon RDS Proxy for MariaDB and Amazon RDS Proxy for MySQL are supported by Amazon RDS Proxy. They both allow you to efficiently scale, eliminate the need to handle database credentials in Lambda code, and require no new infrastructure or code to utilize the full potential of serverless applications backed by relational databases. The main difference is the specific relational database engine they are compatible with â€“ Amazon RDS Proxy for MariaDB is compatible with Amazon RDS for MariaDB, while Amazon RDS Proxy for MySQL is compatible with Amazon RDS for MySQL.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-51", "source_tokens": 407, "generated_at": "2026-02-11T16:14:54.103409"}}
{"question": "What is required to create an Amazon RDS Proxy?", "answer": "You can create an Amazon RDS Proxy by using the AWS CLI command 'aws rds create-db-proxy' with specified parameters such as 'db-proxy-name', 'engine-family', 'auth', 'role-arn', 'subnet-ids', 'require-tls', and 'tags'.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-11T16:14:58.551932"}}
{"question": "How does Trusted Language Extensions (TLE) benefit database administrators?", "answer": "Trusted Language Extensions (TLE) allows developers to build and safely run high-performance PostgreSQL extensions on Amazon Aurora and Amazon RDS, reducing the burden on database administrators to certify custom and third-party code for production use and improving time to market.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-11T16:14:58.552205"}}
{"question": "What databases can Trusted Language Extensions (TLE) be used with on Amazon RDS?", "answer": "Trusted Language Extensions (TLE) can be used with PostgreSQL databases on Amazon RDS.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-52", "source_tokens": 292, "generated_at": "2026-02-11T16:14:58.552383"}}
{"question": "What role can determine who is permitted to install specific extensions in TLE for PostgreSQL?", "answer": "The rds_superuser role can determine who is permitted to install specific extensions in TLE for PostgreSQL.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-11T16:15:02.834176"}}
{"question": "How does TLE for PostgreSQL limit the impact of an extension defect?", "answer": "TLE for PostgreSQL limits the impact of an extension defect to a single database connection.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-11T16:15:02.834480"}}
{"question": "What are the differences between the availability of TLE for PostgreSQL on Amazon Aurora and Amazon RDS?", "answer": "TLE for PostgreSQL is available on both Amazon Aurora PostgreSQL-Compatible Edition and Amazon RDS on PostgreSQL, starting from versions 14.5 and higher.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-53", "source_tokens": 413, "generated_at": "2026-02-11T16:15:02.834866"}}
{"question": "Which PostgreSQL extensions does Aurora and Amazon RDS support?", "answer": "Aurora and Amazon RDS support over 85 PostgreSQL extensions.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-11T16:15:07.590126"}}
{"question": "How does one implement and deploy TLE extensions in PostgreSQL?", "answer": "Once the rds_superuser role activates TLE for PostgreSQL, you can deploy TLE extensions using the SQL CREATE EXTENSION command from any PostgreSQL client. You can control which users have permission to deploy and use specific extensions.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-11T16:15:07.590490"}}
{"question": "What's the difference between deploying TLE extensions in Aurora and Amazon RDS?", "answer": "Both Aurora and Amazon RDS support TLE extensions and the deployment process is similar using the SQL CREATE EXTENSION command. The main difference is the specific edition of RDS being used (MySQL-Compatible, PostgreSQL-Compatible, or other compatible editions).", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-54", "source_tokens": 418, "generated_at": "2026-02-11T16:15:07.590959"}}
{"question": "Which RDS services support Amazon RDS Blue/Green Deployments and from which versions?", "answer": "Amazon RDS Blue/Green Deployments are available for Amazon Aurora MySQL-Compatible Edition versions 5.6 and higher, RDS for MySQL versions 5.7 and higher, and RDS for MariaDB versions 10.2 and higher. They are also supported for Amazon Aurora PostgreSQL-Compatible Edition and Amazon RDS for PostgreSQL for versions 11.21 and higher, 12.16 and higher, 13.12 and higher, 14.9 and higher, and 15.4 and higher.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-11T16:15:15.758107"}}
{"question": "How does Amazon RDS Blue/Green Deployments simplify and speed up database changes?", "answer": "Amazon RDS Blue/Green Deployments allow you to make safer, simpler, and faster database changes. They are ideal for use cases such as major or minor version database engine upgrades, operating system updates, schema changes on green environments that do not break logical replication, or database parameter setting changes. Using Blue/Green Deployments, you can make multiple database updates at the same time using a single switchover, allowing you to stay current on security patches, improve database performance, and access newer database features with short, predictable downtime.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-11T16:15:15.758522"}}
{"question": "What is the difference between Amazon RDS Blue/Green Deployments for MariaDB and MySQL?", "answer": "Both Amazon RDS Blue/Green Deployments for MariaDB and MySQL allow you to make safer, simpler, and faster database changes. However, they are available from different RDS service versions. Blue/Green Deployments for MariaDB are supported from versions 10.2 and higher, while for MySQL they are supported from versions 5.7 and higher.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-55", "source_tokens": 321, "generated_at": "2026-02-11T16:15:15.758979"}}
{"question": "What is the cost difference between running workloads on blue and green instances using Amazon RDS Blue/Green Deployments?", "answer": "The cost of running on blue and green instances using Amazon RDS Blue/Green Deployments is approximately 2x the cost of running workloads on db.instances for the lifespan of the deployment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-11T16:15:21.391187"}}
{"question": "How does Amazon RDS Blue/Green Deployments facilitate database changes?", "answer": "Amazon RDS Blue/Green Deployments enable safer, simpler, and faster database changes such as major or minor version upgrades, schema changes, instance scaling, engine parameter changes, and maintenance updates.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-11T16:15:21.391636"}}
{"question": "What is the cost comparison between running an RDS for MySQL 5.7 database on two r5.2xlarge db.instances and using Amazon RDS Blue/Green Deployments for 15 days?", "answer": "Running an RDS for MySQL 5.7 database on two r5.2xlarge db.instances for 15 days costs $1,387, while using Amazon RDS Blue/Green Deployments for the same period costs $2,774.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-56", "source_tokens": 435, "generated_at": "2026-02-11T16:15:21.391929"}}
{"question": "What happens during a Blue/Green Deployment switchover in terms of write access?", "answer": "Writes are blocked on both the blue and green environments during the switchover process. Once the switchover is complete, writes can be enabled on the green environment.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-11T16:15:26.550184"}}
{"question": "How does a Blue/Green Deployment ensure data consistency between environments?", "answer": "During a switchover, the staging environment, or green environment, catches up with the production system to ensure data consistency. Once the environments are in sync, the switchover promotes the staging environment as the production environment.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-11T16:15:26.550596"}}
{"question": "What is the difference in handling a self-managed logical replica as a subscriber versus a publisher during a Blue/Green Deployment?", "answer": "If the blue environment is a subscriber, Amazon RDS will block switchover and you should stop replication before proceeding. If the blue environment is a publisher, you can continue with the switchover but will need to update the self-managed replica to replicate from the green environment post switchover.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-57", "source_tokens": 495, "generated_at": "2026-02-11T16:15:26.551130"}}
{"question": "What is the benefit of Amazon RDS Optimized Writes for MySQL users?", "answer": "Amazon RDS Optimized Writes help MySQL users achieve up to 2x improved write transaction throughput by writing 16KiB data pages reliably and durably in one step using the Torn Write Prevention feature of the AWS Nitro System.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-11T16:15:32.463837"}}
{"question": "Can Amazon RDS Optimized Writes be used for rolling back changes in Blue/Green Deployments?", "answer": "No, at this time Amazon RDS Optimized Writes cannot be used for rolling back changes in Blue/Green Deployments.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-11T16:15:32.464198"}}
{"question": "How does Amazon RDS Optimized Writes compare to the doublewrite buffer in MySQL?", "answer": "Amazon RDS Optimized Writes write 16KiB data pages directly to data files reliably and durably in one step using the Torn Write Prevention feature of the AWS Nitro System, while MySQL uses a doublewrite buffer to protect users from data loss. Amazon Aurora MySQL-Compatible Edition avoids the use of the doublewrite buffer and instead replicates data six ways across three Availability Zones and uses a quorum-based approach for data durability.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-58", "source_tokens": 474, "generated_at": "2026-02-11T16:15:32.464685"}}
{"question": "Which MySQL and MariaDB versions support Amazon RDS Optimized Reads?", "answer": "Amazon RDS Optimized Reads are available on MySQL versions 8.0.28 and higher, and on MariaDB versions 10.4.25, 10.5.16, 10.6.7 and higher.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-11T16:15:38.170885"}}
{"question": "In what scenarios should customers use Amazon RDS Optimized Reads?", "answer": "Customers should use Amazon RDS Optimized Reads when they have workloads that require complex queries, general purpose analytics, intricate groups, sorts, hash aggregations, high-load joins, or Common Table Expressions (CTEs), resulting in the creation of temporary tables to speed up query processing.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-11T16:15:38.171233"}}
{"question": "How does Amazon RDS Optimized Reads compare to non-Optimized Reads instances?", "answer": "Amazon RDS Optimized Reads allow for faster query processing by creating temporary tables when complex queries, general purpose analytics, intricate groups, sorts, hash aggregations, high-load joins, or Common Table Expressions (CTEs) are used, resulting in improved query performance for workloads with these characteristics.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-59", "source_tokens": 476, "generated_at": "2026-02-11T16:15:38.171725"}}
{"question": "What resources does one need to pay for when using Amazon RDS zero-ETL integration with Amazon Redshift or Amazon SageMaker?", "answer": "You need to pay for Amazon RDS and zero-ETL target resources, including Amazon RDS snapshot export costs, change data capture data transfer costs, and regular RDS I/O and storage. For Amazon Redshift, you also need to consider storage and compute costs for the replicated data. For SageMaker, you need to consider AWS Glue storage and SageMaker compute on the target.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-11T16:15:44.531512"}}
{"question": "Why should you use an Amazon RDS Read Replica as the source Amazon RDS instance for a zero-ETL integration?", "answer": "You should use an Amazon RDS Read Replica as the source Amazon RDS instance for a zero-ETL integration to reduce resource consumption on the primary instance.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-11T16:15:44.531809"}}
{"question": "How does the cost of using Amazon RDS zero-ETL integration with Amazon Redshift compare to using it with Amazon SageMaker?", "answer": "Both Amazon RDS zero-ETL integrations incur costs for Amazon RDS and zero-ETL target resources. However, for Amazon Redshift, you also need to consider storage and compute costs for the replicated data, whereas for Amazon SageMaker, you need to consider AWS Glue storage and SageMaker compute on the target.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-60", "source_tokens": 339, "generated_at": "2026-02-11T16:15:44.532008"}}
{"question": "What transactions are replicated in Amazon RDS zero-ETL integrations?", "answer": "Only committed transactions in Amazon RDS are replicated to Amazon Redshift or the lakehouse in Amazon SageMaker.", "question_type": "factual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-11T16:15:49.768483"}}
{"question": "How does the transactional consistency work between Amazon RDS and Amazon Redshift/SageMaker in the context of zero-ETL integrations?", "answer": "The atomicity of transactions is maintained between the source Amazon RDS database and the target Amazon Redshift cluster or lakehouse in Amazon SageMaker. This means after replication, the data for a given transaction will be consistent in Amazon RDS and the target.", "question_type": "conceptual", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-11T16:15:49.768811"}}
{"question": "How does the handling of schema changes in Amazon RDS zero-ETL integrations compare to the handling of transactions?", "answer": "Both transactions and schema changes are atomically applied in Amazon RDS zero-ETL integrations to ensure data consistency between the source and target. However, while only committed transactions are replicated, schema changes like DDL statements and DML changes are automatically replicated and synced with minimal lag.", "question_type": "comparison", "metadata": {"service": "RDS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rds-faq-61", "source_tokens": 385, "generated_at": "2026-02-11T16:15:49.769035"}}
{"question": "What is Amazon Redshift's integration with Amazon SageMaker SQL analytics?", "answer": "Amazon Redshift is integrated with Amazon SageMaker SQL analytics, allowing users to access, combine, and share data with minimal movement or copying.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-11T16:15:55.086103"}}
{"question": "How does Amazon Redshift help in performing SQL analytics in the cloud?", "answer": "Amazon Redshift helps in performing SQL analytics in the cloud by securely accessing, combining, and sharing data with minimal movement or copying. It is deeply integrated with AWS database, analytics, and machine learning services to employ Zero-ETL approaches or help users access data in place for near real-time analytics and machine learning model building.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-11T16:15:55.086364"}}
{"question": "What is the difference between Amazon Redshift and other cloud data warehouses in terms of performance?", "answer": "Amazon Redshift delivers up to 5x better price performance than other cloud data warehouses due to its Massively Parallel Processing (MPP) engine and architecture that separates compute and storage for efficient scaling, and machine learning driven performance innovations like Automated Materialized Views.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-0", "source_tokens": 394, "generated_at": "2026-02-11T16:15:55.086562"}}
{"question": "What services does Amazon Redshift integrate well with for analytics?", "answer": "Amazon Redshift integrates well with database and machine learning services.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T16:15:58.959205"}}
{"question": "How does Amazon Redshift optimize performance and keep costs low?", "answer": "Amazon Redshift optimizes real-world customer workload performance based on fleet performance telemetry and delivers performance that scales linearly to the workload while keeping costs low.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T16:15:58.959569"}}
{"question": "What is the difference between Amazon Redshift and other data warehouses in terms of performance and cost?", "answer": "Amazon Redshift offers leading price performance for diverse analytics workloads and delivers high performance for demanding and unpredictable workloads at a lower cost than other data warehouses.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-1", "source_tokens": 296, "generated_at": "2026-02-11T16:15:58.960027"}}
{"question": "What tasks does AWS manage for Amazon Redshift data warehouses?", "answer": "AWS manages tasks such as hardware provisioning, software patching, setup, configuration, monitoring nodes and drives to recover from failures, backups, setting up, operating, and scaling the data warehouse.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-11T16:16:03.300316"}}
{"question": "How does Amazon Redshift Serverless handle data warehouse capacity?", "answer": "Amazon Redshift Serverless automatically provisions and scales the data warehouse capacity to deliver high performance for demanding and unpredictable workloads, and you pay only for the resources you use.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-11T16:16:03.300687"}}
{"question": "What is the difference between Amazon Redshift Serverless and provisioned options in terms of resource management?", "answer": "Amazon Redshift Serverless automatically provisions and scales the data warehouse capacity, while the provisioned option allows you to predictably manage resources for steady workloads.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-2", "source_tokens": 427, "generated_at": "2026-02-11T16:16:03.301187"}}
{"question": "What type of storage does Amazon Redshift Serverless use by default?", "answer": "Amazon Redshift Serverless uses Redshift-managed storage to store data.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-11T16:16:07.700644"}}
{"question": "Why is Amazon Redshift Serverless a good choice for short query workloads?", "answer": "Amazon Redshift Serverless offers up to 7x better price performance on high concurrency, low latency workloads that run in less than 1 second.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-11T16:16:07.701072"}}
{"question": "How does the storage scaling work for Amazon Redshift Serverless and RA3 instances?", "answer": "Amazon Redshift managed storage is available for both Amazon Redshift Serverless and RA3 instances. It lets you scale and pay for compute and storage independently. The storage automatically uses high-performance SSD-based local storage as tier-1 cache and scales to Amazon S3 when needed.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-3", "source_tokens": 477, "generated_at": "2026-02-11T16:16:07.701324"}}
{"question": "What role does Amazon Redshift Spectrum play in processing SQL queries against data in Amazon S3?", "answer": "Amazon Redshift Spectrum is a feature of Amazon Redshift that allows SQL queries to be run against data in Amazon S3 without requiring data loading or ETL. When an SQL query is issued, it goes to the Amazon Redshift endpoint, which generates and optimizes a query plan, determines what data is local and what is in S3, and requests Amazon Redshift Spectrum workers to read and process data from S3.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-11T16:16:14.634512"}}
{"question": "How does Amazon Redshift Spectrum enable cost-effective analysis of large data volumes?", "answer": "Amazon Redshift Spectrum allows users to process SQL queries against their data lake in Amazon S3 without the need for data loading or ETL. This feature gives users the flexibility to size their cluster based on their performance needs and only pay for the managed storage they use, making it a cost-effective solution for analyzing large data volumes.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-11T16:16:14.634807"}}
{"question": "How does the use of Amazon Redshift RA3 instances with managed storage compare to traditional Amazon Redshift instances in terms of sizing and cost structure?", "answer": "Amazon Redshift RA3 instances with managed storage allow users to choose the number of nodes based on their performance requirements and pay only for the managed storage they use. This gives users the flexibility to size their cluster based on the amount of data they process daily without increasing their storage costs. In contrast, traditional Amazon Redshift instances require users to size their cluster based on their total data volume, leading to higher storage costs.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-4", "source_tokens": 350, "generated_at": "2026-02-11T16:16:14.634964"}}
{"question": "When was Amazon Redshift's native spatial data processing support launched?", "answer": "November 2019", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-11T16:16:18.017705"}}
{"question": "How does Amazon Redshift's spatial feature provide insights into data?", "answer": "Amazon Redshift's spatial feature integrates spatial and business data to provide analytics for decision making.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-11T16:16:18.018065"}}
{"question": "What spatial data types and standards does Amazon Redshift support?", "answer": "Amazon Redshift supports Shapefiles, GeoJSON, WKT, WKB, eWKT, and eWKB", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-5", "source_tokens": 162, "generated_at": "2026-02-11T16:16:18.018553"}}
{"question": "What is the architecture of Amazon Redshift that makes it suitable for complex BI and analytics workloads?", "answer": "Amazon Redshift utilizes a Massively Parallel Processing (MPP) architecture that separates storage and compute, and offers machine learning led automatic optimization capabilities.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:16:22.958286"}}
{"question": "How does Amazon Athena differ from Amazon Redshift in terms of functionality?", "answer": "Amazon Athena is designed for interactive analytics and data exploration, and is built on open-source engines like Spark, Presto, and Apache Iceberg. In contrast, Amazon Redshift is a data warehouse optimized for complex BI and analytics workloads.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:16:22.958653"}}
{"question": "What are the integration capabilities of Amazon Redshift that make it a central data architecture component?", "answer": "Amazon Redshift supports accessing data stored in Amazon S3, operational databases like Aurora and RDS, third party data warehouses through Data Exchange, and data stored within the Amazon Redshift data warehouse itself.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:16:22.959166"}}
{"question": "What sources can you directly query data from in Amazon SageMaker for SQL analytics?", "answer": "You can directly query data from Amazon S3 (AWS Glue Data Catalog and Amazon S3 table buckets), Amazon Redshift (serverless and provisioned), and 13 additional federated data sources.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-11T16:16:28.326397"}}
{"question": "How does Amazon SageMaker make SQL analytics more accessible for data users?", "answer": "Amazon SageMaker offers a user-friendly notebook-style interface in Unified Studio, where you can write and run SQL code in separate cells, create charts and visualizations, and explore unified data from different sources. It also provides helpful features like auto-complete and syntax checking, and generative AI functionality with Amazon Q.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-11T16:16:28.326767"}}
{"question": "How does running queries directly on Amazon S3 data in SageMaker compare to uploading data into your data warehouse?", "answer": "Running queries directly on Amazon S3 data allows you to analyze data without the need to move it first, which saves time and effort. In contrast, uploading data into your data warehouse requires additional steps and resources.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-7", "source_tokens": 447, "generated_at": "2026-02-11T16:16:28.327254"}}
{"question": "What resources can be stored in a SageMaker Project?", "answer": "A SageMaker Project is a collaborative digital workspace where team members can store SQL queries, data models, code, and other resources in one secure location.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-11T16:16:33.647704"}}
{"question": "How does the use of SageMaker Projects facilitate team collaboration?", "answer": "By creating a Project, you establish a centralized environment where team members can be invited, given specific access permissions, and work together on SQL analytics projects. Within this space, you can distribute query books, grant access to data sources and computing resources, and implement version control through Git integration.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-11T16:16:33.648073"}}
{"question": "What are the differences between Amazon Redshift and Amazon Redshift Serverless?", "answer": "Both Amazon Redshift and Amazon Redshift Serverless are SQL analytics services offered by AWS. Amazon Redshift requires users to set up and manage data warehouse infrastructure, while Amazon Redshift Serverless is a serverless option that makes running and scaling analytics more efficient. With Redshift Serverless, users can get insights from data by loading and querying data in the data warehouse without the need to manage infrastructure.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-8", "source_tokens": 373, "generated_at": "2026-02-11T16:16:33.648622"}}
{"question": "What datasets can be used in Amazon Redshift Serverless?", "answer": "Preloaded sample datasets such as weather data, census data, and benchmark datasets are available in Amazon Redshift Serverless. You can also load data from Amazon S3, Amazon Redshift data shares, or restore from an existing Redshift provisioned cluster snapshot.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-11T16:16:39.213722"}}
{"question": "How does Amazon Redshift Serverless make data analytics more cost-effective?", "answer": "Amazon Redshift Serverless offers automatic scaling and the ability to pay for use, making it more cost-effective for running development and test environments, ad-hoc business analytics, workloads with varying and unpredictable compute needs, and intermittent or sporadic workloads.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-11T16:16:39.214082"}}
{"question": "What's the difference between Amazon Redshift Serverless and a provisioned Redshift cluster in terms of control?", "answer": "Amazon Redshift Serverless allows users to focus on deriving meaningful insights from their data and delivering on core business outcomes without worrying about setting up, configuring, managing clusters, or tuning the warehouse. In contrast, a provisioned Redshift cluster provides fine-grained control over the data warehouse.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-9", "source_tokens": 507, "generated_at": "2026-02-11T16:16:39.214599"}}
{"question": "What data sources can be used to load data into Amazon Redshift?", "answer": "Data can be loaded into Amazon Redshift from Amazon S3, Amazon RDS, Amazon DynamoDB, Amazon EMR, AWS Glue, AWS Data Pipeline, and any SSH-enabled host on Amazon EC2 or on-premises.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-11T16:16:44.125157"}}
{"question": "How does Redshift auto-copy automate the file ingestion process?", "answer": "Redshift auto-copy automates the file ingestion process by tracking specified Amazon S3 paths for new files and initiating user-defined copy statements to automatically copy new files into the target table.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-11T16:16:44.125515"}}
{"question": "How does loading data from Amazon S3 compare to using SQL insert statements in Amazon Redshift?", "answer": "Loading data from Amazon S3 is faster than using SQL insert statements in Amazon Redshift since data is loaded in parallel to each compute node in the case of Amazon S3, while SQL insert statements are processed through the single leader node.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-10", "source_tokens": 428, "generated_at": "2026-02-11T16:16:44.126021"}}
{"question": "What are some use cases for using Apache Spark with Amazon Redshift?", "answer": "Customers use Amazon EMR and AWS Glue to run Apache Spark jobs that access and load data into Amazon Redshift for data ingestion and transformation (batch and streaming). They also use Amazon SageMaker for machine learning and access data from Amazon Redshift for feature engineering and transformation. Amazon Athena customers perform interactive analysis on data in Amazon Redshift using Apache Spark.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-11T16:16:49.249855"}}
{"question": "Why is it beneficial to use Apache Spark with Amazon Redshift?", "answer": "It allows for easy use and getting started, minimally configured setup and maintenance, and improved performance for running Apache Spark applications on Amazon Redshift.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-11T16:16:49.250170"}}
{"question": "How does using Amazon Redshift with Apache Spark from AWS services compare to manually setting up and maintaining uncertified versions of Spark?", "answer": "Using Amazon Redshift with Apache Spark from AWS services offers convenience with minimal configuration and setup, eliminating the need to worry about manual steps and maintenance of uncertified versions.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-11", "source_tokens": 212, "generated_at": "2026-02-11T16:16:49.250604"}}
{"question": "What service does Amazon Aurora Zero-ETL allow data to be replicated from into Amazon Redshift?", "answer": "Amazon Aurora", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-11T16:16:53.731176"}}
{"question": "How does Amazon Aurora Zero-ETL to Amazon Redshift enable customers to improve their applications?", "answer": "It reduces the need for customers to build and manage complex data pipelines, enabling them to focus on improving their applications.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-11T16:16:53.731539"}}
{"question": "What are the main differences between working with stream data and traditional database tables in Amazon Redshift?", "answer": "Stream data are time-varying relations that evolve over time, while traditional database tables capture a point-in-time snapshot. Amazon Redshift's customers typically perform downstream processing on tables using a batch model. Amazon Redshift provides Materialized Views to materialize a point-in-time view of stream data for ELT workflows.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-12", "source_tokens": 497, "generated_at": "2026-02-11T16:16:53.732021"}}
{"question": "Which use cases can benefit from having multiple BI/analytics clusters in AWS Redshift?", "answer": "Use cases that involve providing read workload isolation and optional charge-ability for multiple BI/analytics clusters, such as a central ETL cluster sharing data with many BI/analytics clusters or a data provider sharing data to external consumers.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-11T16:16:58.637892"}}
{"question": "Why is cross-database queries functionality beneficial in AWS Redshift?", "answer": "Cross-database queries allow you to seamlessly query and join data from any Redshift database that you have access to, regardless of which database you are connected to. This flexibility enables you to organize data as separate databases to support multi-tenant configurations.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-11T16:16:58.638185"}}
{"question": "How does AWS Data Exchange simplify data exchange and usage in AWS compared to traditional methods?", "answer": "AWS Data Exchange makes it more efficient for AWS customers to securely exchange and use third-party data in AWS by providing a centralized platform for accessing data from multiple providers with consistent delivery methods.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-13", "source_tokens": 357, "generated_at": "2026-02-11T16:16:58.638581"}}
{"question": "How long is the cluster unavailable during Elastic Resize?", "answer": "The cluster is unavailable for four to eight minutes during Elastic Resize.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-11T16:17:03.264685"}}
{"question": "In what ways does Amazon Redshift Serverless differ from manually scaled Redshift when handling query performance and resource utilization?", "answer": "Amazon Redshift Serverless automatically adds cluster capacity in seconds to maintain high performance and simplified operations, while manually scaled Redshift requires users to increase the number of nodes through Elastic Resize, which results in a temporary unavailability of the cluster for resize.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-11T16:17:03.265058"}}
{"question": "What's the purpose of Concurrency Scaling and Elastic Resize in Amazon Redshift?", "answer": "Concurrency Scaling automatically adds cluster resources to increase the overall query concurrency, while Elastic Resize adds or removes nodes from a single Redshift cluster within minutes to manage its query throughput.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-14", "source_tokens": 509, "generated_at": "2026-02-11T16:17:03.265583"}}
{"question": "What security features does Amazon Redshift offer at no additional cost?", "answer": "Amazon Redshift offers built-in identity management and federation for single sign-on (SSO), multi-factor authentication, column-level access control, row-level security, role-based access control, and Amazon Virtual Private Cloud (Amazon VPC). Your data is encrypted in transit and at rest. AWS supports more security standards and compliance certifications than any other provider, including ISO 27001, SOC, HIPAA/HITECH, and FedRAMP.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-11T16:17:09.572424"}}
{"question": "How can you implement role-based access control in Amazon Redshift?", "answer": "You can assign one or more roles to a user, and assign system and object permissions by role. Amazon Redshift offers out-of-the-box system rolesâ€“root user, dba, operator, and security admins, or you can create your own roles.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-11T16:17:09.572793"}}
{"question": "What is the difference between AWS Lambda user-defined functions (UDFs) and Redshift Dynamic Data Masking?", "answer": "AWS Lambda UDFs enable you to write custom extensions for your SQL query to achieve tighter integration with other services or third-party products. Redshift Dynamic Data Masking allows you to protect sensitive data and control granular access by managing Data Masking policies.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-15", "source_tokens": 511, "generated_at": "2026-02-11T16:17:09.573218"}}
{"question": "What identity providers can be used for single sign-on with Amazon Redshift?", "answer": "Microsoft Azure Active Directory, Active Directory Federation Services, Okta, Ping Federate, and other SAML compliant identity providers can be used for single sign-on with Amazon Redshift.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-11T16:17:15.367616"}}
{"question": "Why would you use single sign-on with Amazon Redshift and your corporate identity provider?", "answer": "Using single sign-on with Amazon Redshift and your corporate identity provider allows you to sign on to the data warehouse without duplicating the identities in Redshift, enhancing security and simplifying the authentication process.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-11T16:17:15.367985"}}
{"question": "How does Amazon Redshift handle node replacement in Dense Compute and Dense Storage clusters compared to RA3 and Redshift serverless?", "answer": "In Dense Compute and Dense Storage clusters, Amazon Redshift automatically detects and replaces a failed node, refreshing the data from the mirror copy on the other node. RA3 clusters and Redshift serverless have data stored in Amazon S3, and the local drive is used as a data cache. In the event of a node replacement, the data warehouse cluster is unavailable until a replacement node is provisioned and added to the DB.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-16", "source_tokens": 413, "generated_at": "2026-02-11T16:17:15.368472"}}
{"question": "What data formats are supported by Amazon Redshift Spectrum?", "answer": "Amazon Redshift Spectrum currently supports many open-source data formats, including Avro, CSV, Grok, Amazon Ion, JSON, ORC, Parquet, RCFile, RegexSerDe, Sequence, Text, and TSV.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-11T16:17:26.440577"}}
{"question": "How can I use the same query syntax to access external tables in Amazon Redshift Spectrum?", "answer": "You can use exactly the same query syntax and have the same query capabilities to access tables in Redshift Spectrum as you have for tables in the local storage of your Redshift cluster. You can reference external tables using the schema name defined in the CREATE EXTERNAL SCHEMA command.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-11T16:17:26.441359"}}
{"question": "How does Amazon Redshift Spectrum compare to Amazon Redshift in terms of data formats?", "answer": "Amazon Redshift and Amazon Redshift Spectrum both support many open-source data formats. The main difference is that Amazon Redshift Spectrum allows you to query data directly from S3 without loading it into the cluster first. Currently, Amazon Redshift Spectrum supports Avro, CSV, Grok, Amazon Ion, JSON, ORC, Parquet, RCFile, RegexSerDe, Sequence, Text, and TSV data formats.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-18", "source_tokens": 392, "generated_at": "2026-02-11T16:17:26.441631"}}
{"question": "What SQL commands can be used to create, train, and deploy machine learning models in Amazon Redshift?", "answer": "Amazon Redshift allows SQL users to create, train, and deploy machine learning models using familiar SQL commands.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-11T16:17:31.130875"}}
{"question": "How does Amazon Redshift make it easy to access data from Amazon Redshift using web services?", "answer": "Amazon Redshift provides a Data API that simplifies access to Amazon Redshift. It allows you to run SQL commands to an Amazon Redshift cluster by calling a secured API endpoint, and takes care of managing database connections and buffering data.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-11T16:17:31.131241"}}
{"question": "What are the differences between accessing data from Amazon Redshift using the Data API versus AWS CLI?", "answer": "Accessing data from Amazon Redshift using the Data API involves calling a secured API endpoint and using SQL commands, while accessing data using AWS CLI involves using the aws redshift-data command line option.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-19", "source_tokens": 409, "generated_at": "2026-02-11T16:17:31.131725"}}
{"question": "What are the benefits of using Zero-ETL integrations instead of traditional ETL processes for data movement?", "answer": "Zero-ETL integrations simplify data architecture, reduce data-engineering efforts, and increase agility by allowing for the inclusion of new data sources without the need to reprocess large amounts of data. They also reduce costs by using cloud-native and scalable data integration technologies, optimize costs based on actual usage, and decrease maintenance overheads. Additionally, Zero-ETL provides near real-time data access, which results in faster time to insights for analytics, AI/ML, and reporting.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-11T16:17:37.336129"}}
{"question": "How does Zero-ETL compare to traditional ETL processes in terms of complexity and time to insights?", "answer": "Zero-ETL simplifies data architecture and reduces data-engineering efforts compared to traditional ETL processes. It also provides near real-time data access, which results in faster time to insights for analytics, AI/ML, and reporting, while traditional ETL processes often involve periodic batch updates resulting in delayed data availability.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-11T16:17:37.336505"}}
{"question": "Which operational sources and applications can Zero-ETL make data available in Amazon Redshift and SageMaker from?", "answer": "Zero-ETL makes data available in Amazon Redshift and SageMaker from multiple operational sources, transactional sources, and enterprise applications.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-20", "source_tokens": 505, "generated_at": "2026-02-11T16:17:37.337031"}}
{"question": "What databases support zero-ETL integrations with Amazon Redshift according to the text?", "answer": "Amazon SageMaker Lakehouse, Amazon Redshift, Amazon DynamoDB, Amazon Aurora MySQL, Amazon Aurora PostgreSQL, Amazon Relational Database Service (Amazon RDS) for MySQL, Amazon DocumentDB, and Amazon OpenSearch Service.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-11T16:17:43.853262"}}
{"question": "How does zero-ETL integration with Amazon Redshift handle schema changes?", "answer": "Zero-ETL integration automatically replicates DDL statements from the source database to Amazon Redshift and makes necessary adjustments in Amazon Redshift tables for schema changes. It maintains schema consistency in real time with minimal lag between source and target databases.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-11T16:17:43.853627"}}
{"question": "What is the difference between zero-ETL integration with Amazon Redshift and Amazon SageMaker Lakehouse versus zero-ETL integration with Amazon OpenSearch Service?", "answer": "Zero-ETL integration with Amazon Redshift involves replicating schema changes and data from databases like Amazon SageMaker Lakehouse, Amazon Aurora MySQL, Amazon Aurora PostgreSQL, Amazon Relational Database Service (Amazon RDS) for MySQL, Amazon DocumentDB, and Amazon DynamoDB. Zero-ETL integration with Amazon OpenSearch Service involves replicating data from sources like Amazon CloudWatch Logs and Amazon Simple Storage Service (Amazon S3) into OpenSearch Service.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-21", "source_tokens": 434, "generated_at": "2026-02-11T16:17:43.854016"}}
{"question": "What type of storage does Amazon Redshift RA3 and Serverless use for data?", "answer": "Amazon Redshift RA3 clusters and Serverless use Redshift Managed Storage, which always has the latest copy of the data available.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-11T16:17:48.635021"}}
{"question": "How does Amazon Redshift ensure data availability in the event of a failure on a DS2 or DC2 cluster?", "answer": "Amazon Redshift DS2 and DC2 clusters mirror the data on the cluster to ensure the latest copy is available in the event of a failure.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-11T16:17:48.635393"}}
{"question": "What is the difference in backup storage for Amazon Redshift between DS2/DC2 and RA3/Serverless clusters?", "answer": "Amazon Redshift DS2 and DC2 clusters provide free backup storage limited to the total size of storage on the nodes in the data warehouse cluster, while RA3 and Serverless clusters use Redshift Managed Storage which always has the latest copy of the data available.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-22", "source_tokens": 494, "generated_at": "2026-02-11T16:17:48.635836"}}
{"question": "What parameter should I modify in the AWS Management Console or API to manage the retention period for automated backups?", "answer": "You should modify the RetentionPeriod parameter.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:17:54.070838"}}
{"question": "How does managing the retention period for automated backups using the AWS Management Console or API impact the availability of deleted data warehouse clusters?", "answer": "Setting a retention period to 0 does not recommend turning off automated backups altogether. When you delete a data warehouse cluster, you have the option to create a final snapshot for potential restoration at a later date. Previously created manual snapshots of your data warehouse cluster will be retained and billed at standard Amazon S3 rates.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:17:54.071102"}}
{"question": "What are the differences between managing backups for Amazon Redshift clusters and Serverless data warehouses using the AWS Backup console versus the API or CLI?", "answer": "Both methods allow you to automate backup and restore for Amazon Redshift clusters and Serverless data warehouses. Using the AWS Backup console, you can centrally create and manage immutable backups across all your accounts, while the API and CLI provide programmatic access for managing backups.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:17:54.071474"}}
{"question": "What tools can be used to access metrics for compute utilization, storage utilization, and read/write traffic in Amazon Redshift?", "answer": "Metrics for compute utilization, storage utilization, and read/write traffic to an Amazon Redshift data warehouse cluster can be accessed through the AWS Management Console or Amazon CloudWatch APIs.", "question_type": "factual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-11T16:17:58.782557"}}
{"question": "How can the AWS Management Console help you diagnose performance issues in Amazon Redshift?", "answer": "The AWS Management Console provides a monitoring dashboard that enables you to see which users and queries are consuming the most system resources in Amazon Redshift. You can also view query plans and execution statistics to diagnose performance issues.", "question_type": "conceptual", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-11T16:17:58.782805"}}
{"question": "How often does Amazon Redshift perform maintenance and how does it affect cluster availability?", "answer": "Amazon Redshift performs maintenance periodically to apply fixes, enhancements, and new features to your cluster. During these maintenance windows, your Amazon Redshift cluster is not available for normal operations.", "question_type": "comparison", "metadata": {"service": "REDSHIFT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "redshift-faq-24", "source_tokens": 266, "generated_at": "2026-02-11T16:17:58.783202"}}
{"question": "What features does Amazon Rekognition Image offer for image analysis?", "answer": "Amazon Rekognition Image offers features for object detection, scene and activity recognition, landmark recognition, face recognition, dominant color extraction, image quality analysis, text recognition, celebrity recognition, and inappropriate content detection.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-11T16:18:05.583121"}}
{"question": "How does Amazon Rekognition Video analyze videos?", "answer": "Amazon Rekognition Video analyzes videos by detecting activities, understanding the movement of people in frame, and recognizing objects, celebrities, and inappropriate content. It also tracks persons and indexes metadata like objects, activities, scene, landmarks, celebrities, and faces for easy video search.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-11T16:18:05.583484"}}
{"question": "What is the difference between Amazon Rekognition Image and Amazon Rekognition Video?", "answer": "Amazon Rekognition Image is an image recognition service that analyzes images for object detection, scene and activity recognition, landmark recognition, face recognition, dominant color extraction, image quality analysis, text recognition, celebrity recognition, and inappropriate content detection. Amazon Rekognition Video is a video recognition service that extracts motion-based context from stored or live stream videos, analyzes them for activities, understands the movement of people in frame, and recognizes objects, celebrities, and inappropriate content. Rekognition Image allows you to search and compare faces, while Rekognition Video tracks persons and indexes metadata for easy video search.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-0", "source_tokens": 511, "generated_at": "2026-02-11T16:18:05.583994"}}
{"question": "What is Deep Learning and how does it differ from Machine Learning?", "answer": "Deep Learning is a sub-field of Machine Learning and a significant branch of Artificial Intelligence. It aims to infer high-level abstractions from raw data by using a deep graph with multiple processing layers composed of multiple linear and non-linear transformations. Deep Learning is loosely based on models of information processing and communication in the brain and replaces handcrafted features with ones learned from very large amounts of annotated data. Machine Learning, on the other hand, is a method of data analysis that automates the building of analytical models.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T16:18:13.099307"}}
{"question": "Why is Amazon Rekognition a better option than building a deep learning pipeline for image and video recognition tasks?", "answer": "Amazon Rekognition is a fully managed service that comes pre-trained for image and video recognition tasks. It allows users to focus on high-value application design and development without investing time and resources on creating a deep learning pipeline. Deep learning systems need to be tuned properly and trained with massive amounts of labeled ground truth data, which is a time-consuming and expensive task. Training a deep neural network is also computationally expensive and often requires custom hardware built using Graphics Processing Units (GPU).", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T16:18:13.099562"}}
{"question": "What are some common use-cases for Amazon Rekognition with Image and Video?", "answer": "The most common use-cases for Rekognition Image include: a searchable image library, face-based user verification, sentiment analysis, and facial recognition. The most common use-cases for Rekognition Video include: a search index for video archives and easy filtering of video for explicit and suggestive content.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-1", "source_tokens": 496, "generated_at": "2026-02-11T16:18:13.099741"}}
{"question": "Which image formats does Amazon Rekognition Image support?", "answer": "Amazon Rekognition Image currently supports JPEG and PNG image formats.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-11T16:18:17.417103"}}
{"question": "How does Amazon Rekognition handle video formats and codecs?", "answer": "Amazon Rekognition Video supports MPEG-4 and MOV video formats that are encoded with the H.264 codec.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-11T16:18:17.417368"}}
{"question": "What are the size limitations for submitting images and videos to Amazon Rekognition?", "answer": "Amazon Rekognition supports images up to 15MB when passed as an S3 object and up to 5MB when submitted as an image byte array. For videos, it accepts up to 10GB files and up to 6 hour videos when passed through as an S3 file.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-2", "source_tokens": 492, "generated_at": "2026-02-11T16:18:17.417709"}}
{"question": "What is the minimum size requirement for an object or face in an image to be recognized by Amazon Rekognition, based on the text passage?", "answer": "The minimum size for an object or face to be recognized by Amazon Rekognition is at least 5% of the shorter image dimension. For example, in a 1600x900 image, the smallest face or object should be at least 45 pixels in either dimension.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-11T16:18:24.030506"}}
{"question": "How does Amazon Rekognition ensure accurate recognition of faces in images with varying resolutions, according to the text passage?", "answer": "Amazon Rekognition is trained to recognize faces larger than 32 pixels (on the shortest dimension), which corresponds to a minimum size for a face to be recognized that varies from approximately 1/7 of the screen smaller dimension at QVGA resolution to 1/30 at HD 1080p resolution.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-11T16:18:24.030777"}}
{"question": "What are the differences between using a confidence threshold and random sampling percentage for human review in Amazon Rekognition, based on the text passage?", "answer": "When using Amazon Rekognition with Amazon A2I for human review, you can specify either a confidence threshold or a random sampling percentage for routing predictions to reviewers. Confidence threshold sets a minimum confidence level for the predictions to be sent to reviewers, while random sampling sends a random sample of predictions for review regardless of their confidence level.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-3", "source_tokens": 506, "generated_at": "2026-02-11T16:18:24.031172"}}
{"question": "In which regions is Amazon Rekognition available?", "answer": "Amazon Rekognition is available in the regions listed in the AWS Region table.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T16:18:28.510615"}}
{"question": "What labels can Amazon Rekognition detect in an image, and how are they categorized?", "answer": "Amazon Rekognition can detect labels such as 'Person', 'Water', 'Sand', 'Palm Tree', 'Swimwear' (objects), 'Beach' (scene), and 'Outdoors' (concept) in an image. Confidence scores are provided for each label.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T16:18:28.510922"}}
{"question": "How does the confidence score for a label in Amazon Rekognition impact the detection result?", "answer": "A higher confidence score indicates a higher probability that the label is correct. Applications that require high accuracy may discard results associated with confidence scores below a certain threshold.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-4", "source_tokens": 453, "generated_at": "2026-02-11T16:18:28.511134"}}
{"question": "What information does Amazon Rekognition return for each identified label, besides the label itself?", "answer": "Amazon Rekognition returns the parent label (if it exists), the alias (if it exists), and the category (if it exists) for each identified label.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-11T16:18:33.916196"}}
{"question": "Can you explain how parents, aliases, and categories are related to labels in Amazon Rekognition?", "answer": "Parent labels are returned in the 'parents' field in hierarchical order, with the first parent being the immediate parent and following parents being parents of parents. Aliases are labels with the same meaning as the primary labels and are returned in the 'aliases' field. Categories group labels based on common themes and are returned in the 'categories' field.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-11T16:18:33.916462"}}
{"question": "What's the difference between the 'parents' and 'aliases' fields in Amazon Rekognition's label response?", "answer": "The 'parents' field contains the parent labels in hierarchical order, with the first parent being the immediate parent and following parents being parents of parents. The 'aliases' field contains labels with the same meaning as the primary labels.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-5", "source_tokens": 257, "generated_at": "2026-02-11T16:18:33.916884"}}
{"question": "What categories does AWS Rekognition support for labeling in images?", "answer": "AWS Rekognition supports categories including People and Events, Food and Drink, Nature and Outdoors, Animals and Pets, Home and Garden, Sports and Leisure, Plants and Flowers, Art and Entertainment, Transportation and Vehicles, Electronics, and Landmarks.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T16:18:39.068181"}}
{"question": "How does Rekognition Video identify complex activities in videos?", "answer": "Rekognition Video identifies complex activities in videos by relying on motion and time context in the video to accurately identify activities such as 'blowing a candle' or 'extinguishing fire'.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T16:18:39.068553"}}
{"question": "What is the difference between Rekognition for image labeling and Rekognition Video for video analysis?", "answer": "Rekognition for image labeling analyzes static images and returns labels for objects and scenes, while Rekognition Video analyzes videos and returns labels for objects, activities, and provides timestamps and confidence scores.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-6", "source_tokens": 509, "generated_at": "2026-02-11T16:18:39.068991"}}
{"question": "What formats does Image Properties return dominant colors in?", "answer": "Image Properties returns dominant colors in four formats: RGB, hexcode, CSS color, and simplified colors.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-11T16:18:43.104556"}}
{"question": "How does Image Properties in Amazon Rekognition determine dominant colors?", "answer": "Image Properties first identifies the dominant colors based on pixel percentage and then maps these colors to the 140 CSS color palette, RGB, hex code, and 12 simplified colors.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-11T16:18:43.104841"}}
{"question": "What's the difference between the brightness score and sharpness score provided by Image Properties?", "answer": "The brightness score measures the overall lightness or darkness of an image, while the sharpness score indicates how clear and focused the edges are in an image.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-7", "source_tokens": 374, "generated_at": "2026-02-11T16:18:43.105027"}}
{"question": "How does Custom Labels work for detecting unsafe image content?", "answer": "Custom Labels detects unsafe image content based on the labels you train it with. You can train it to detect use case-specific unsafe content, and it will identify instances of that content in new images.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-11T16:18:48.327356"}}
{"question": "What is the minimum number of images required to train a Custom Labels model?", "answer": "The minimum number of images required to train a Custom Labels model depends on the variability of the custom labels and the quality of the training data. A simple logo can be detected with 1-2 training images, while a more subtle logo may need in the order of tens to hundreds of training examples.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-11T16:18:48.327628"}}
{"question": "What's the difference in usage between Custom Labels and face analysis APIs in Rekognition?", "answer": "Custom Labels is used for finding objects and scenes in images, while face analysis APIs are used for analyzing faces. Custom Labels can be trained for specific unsafe image content, while face analysis APIs handle face recognition and other face-related features.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-8", "source_tokens": 472, "generated_at": "2026-02-11T16:18:48.327996"}}
{"question": "What happens if my image processing fails? Will I be charged?", "answer": "No, you will not be charged for the compute resources if your image processing fails.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-11T16:18:51.964954"}}
{"question": "Why is it necessary to stop provisioning my custom model when I'm not processing images?", "answer": "You should stop provisioning your custom model when you're not processing images to avoid being charged.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-11T16:18:51.965250"}}
{"question": "How does the charging structure for Amazon Rekognition's custom model provisioning differ from processing images?", "answer": "You are charged for the compute resources while your custom model is provisioned, even if you're not processing images. However, there is no charge for failed training.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-9", "source_tokens": 102, "generated_at": "2026-02-11T16:18:51.965659"}}
{"question": "What specific sub-categories of inappropriate content does Amazon Rekognition detect and provide as labels?", "answer": "Amazon Rekognition detects and provides labels for explicit nudity, graphic male and female nudity, violent content, weapons, visually disturbing content, drugs, alcohol, tobacco, hate symbols, gambling, and rude gestures. These labels indicate specific sub-categories of the type of content detected, allowing developers to filter and manage user generated content with more granular control.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T16:18:58.731268"}}
{"question": "What information does Amazon Rekognition return beyond flagging an image or video based on presence of inappropriate content?", "answer": "Amazon Rekognition returns a hierarchical list of labels with confidence scores for each detected label. For instance, given an inappropriate image, Rekognition may return 'Explicit Nudity' with a confidence score as a top-level label, and 'Graphic Male Nudity' with its own confidence score as a second level label. Developers can use this metadata to build more complex filtering logic to serve different geographies and demographics.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T16:18:58.731532"}}
{"question": "How does the detection and labeling of inappropriate content in Amazon Rekognition compare between different models or versions?", "answer": "The text passage does not provide enough information to make a comparison between different models or versions of Amazon Rekognition's Content Moderation API in terms of their detection and labeling of inappropriate content.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-10", "source_tokens": 475, "generated_at": "2026-02-11T16:18:58.731905"}}
{"question": "What field should I use to keep track of Amazon Rekognition's model version?", "answer": "You can use the 'ModerationModelVersion' field in the API response.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-11T16:19:03.604987"}}
{"question": "How can I adjust Amazon Rekognition's Content Moderation API to prioritize recall over precision or vice versa?", "answer": "You can use the â€˜MinConfidenceâ€™ parameter in your API requests to balance detection of content (recall) vs the accuracy of detection (precision). Reducing 'MinConfidence' increases recall but may also pick up non-inappropriate content. Increasing 'MinConfidence' ensures all detected content is truly inappropriate but some content may not be tagged.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-11T16:19:03.605321"}}
{"question": "How does providing feedback to Amazon Rekognition's Content Moderation APIs impact its ability to detect inappropriate content?", "answer": "Amazon Rekognition continuously expands the types of inappropriate content detected based on customer feedback.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-11", "source_tokens": 286, "generated_at": "2026-02-11T16:19:03.605692"}}
{"question": "What facial attributes does Amazon Rekognition return for each face detected, aside from a bounding box and confidence score?", "answer": "Amazon Rekognition returns facial attributes including face pose, face quality, and face landmarks for each face detected.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-11T16:19:07.836945"}}
{"question": "How can face pose in Amazon Rekognition be utilized?", "answer": "Face pose in Amazon Rekognition can be used to find the orientation of the face bounding polygon, measure deformation, and track faces accurately.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-11T16:19:07.837215"}}
{"question": "What is the difference between face landmarks and face pose in Amazon Rekognition?", "answer": "Face landmarks are a set of salient points on key facial components, and face pose refers to the rotation of a detected face on the pitch, roll, and yaw axes.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-12", "source_tokens": 395, "generated_at": "2026-02-11T16:19:07.837612"}}
{"question": "What information does Rekognition Video return for each detected face in a video?", "answer": "Rekognition Video returns the detected faces with timestamps, position, and a bounding box along with landmark points such as left eye, right eye, nose, left corner of the mouth, and right corner of the mouth.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-11T16:19:12.386905"}}
{"question": "How can Rekognition Video be used for sentiment analysis?", "answer": "Rekognition Video can be used for sentiment analysis by tracking user sentiment over time using the position and time information of detected faces.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-11T16:19:12.387154"}}
{"question": "What's the difference between Face Comparison and Face Search in Amazon Rekognition?", "answer": "Face Comparison is the process of comparing one face to one or more faces to measure similarity, while Face Search is the process of using an input face to search for similar matches in a collection of stored faces.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-13", "source_tokens": 445, "generated_at": "2026-02-11T16:19:12.387309"}}
{"question": "What API do I use to add a face to a face collection in AWS Rekognition?", "answer": "The IndexFaces API is used to add a face to an existing face collection in AWS Rekognition.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T16:19:17.967755"}}
{"question": "How does the process of deleting a face from a face collection in AWS Rekognition differ from deleting a user?", "answer": "To delete a face from a face collection, you can use the DeleteFaces API. However, if the FaceID is associated with a user vector, you'll first need to use the DisassociateFaces API to remove it from the user vector. Alternatively, you can delete the user vector from the collection using the DeleteUser API.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T16:19:17.968042"}}
{"question": "What's the difference between searching for faces within a collection using an image and using a FaceId in AWS Rekognition?", "answer": "When searching for faces within a collection, you can use either the SearchFaceByImage API, which takes an input image, or the SearchFaces API, which takes a FaceId. Both APIs return a set of faces that match, ordered by similarity score with the highest similarity first.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-14", "source_tokens": 476, "generated_at": "2026-02-11T16:19:17.968438"}}
{"question": "What improves the performance of Amazon Rekognition's face collections search besides video resolution?", "answer": "The quality and representative faces, using multiple face instances per person with variations like beard, glasses, poses (profile and frontal), significantly improve the performance.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T16:19:22.743014"}}
{"question": "How does Amazon Rekognition's Celebrity Recognition feature benefit users?", "answer": "It allows users to index and search their digital image libraries for celebrities based on their particular interest, ideal for various categories such as politics, sports, business, entertainment, and media.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T16:19:22.743312"}}
{"question": "What additional information does the Rekognition Video API provide when detecting and recognizing celebrities in a video?", "answer": "Besides the name and unique id of the celebrity, bounding box coordinates, confidence score, the API also returns URLs pointing to related content for the celebrity, such as the celebrity's IMDB link.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-15", "source_tokens": 477, "generated_at": "2026-02-11T16:19:22.743491"}}
{"question": "What are some factors that can affect the quality of Amazon Rekognition's Video APIs for text detection?", "answer": "Moving celebrities and blurred videos can affect the quality of Amazon Rekognition's Video APIs for text detection. In addition, heavy makeup and camouflage common for actors/actresses can also impact the quality.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:19:29.393475"}}
{"question": "How does text detection in Amazon Rekognition work and what can it be used for?", "answer": "Text detection in Amazon Rekognition is a capability that allows the service to detect and recognize text within an image or a video. It can be used for various applications such as indexing images based on text labels, identifying vehicles based on license plate numbers from traffic cameras, and creating text metadata for search in media and entertainment applications. It supports text in most Latin scripts and numbers embedded in a large variety of layouts, fonts, and styles, and overlaid on background objects at various orientations.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:19:29.393775"}}
{"question": "How does text detection in Amazon Rekognition compare to document text detection?", "answer": "Text detection in Amazon Rekognition is specifically built to work with real-world images and videos rather than document images. It can detect text and get confidence scores and timestamps for each detection, and supports text rotated by up to -90 to +90 degrees from the horizontal axis. However, it does not explicitly mention any support for document text detection.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-16", "source_tokens": 503, "generated_at": "2026-02-11T16:19:29.393988"}}
{"question": "What types of protective equipment can Amazon Rekognition 'DetectProtectiveEquipment' API identify?", "answer": "Amazon Rekognition 'DetectProtectiveEquipment' API can identify common types of face covers, hand covers, and head covers.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-11T16:19:34.287498"}}
{"question": "How does Amazon Rekognition Custom Labels help in detecting specific PPE for businesses?", "answer": "Amazon Rekognition Custom Labels can help detect PPE unique to a business, such as high-visibility vests, safety goggles, and other specific PPE.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-11T16:19:34.287793"}}
{"question": "What information does Amazon Rekognition 'DetectProtectiveEquipment' API provide about the protective equipment's location on a person?", "answer": "Amazon Rekognition 'DetectProtectiveEquipment' API provides the coordinates of the bounding box rectangle and a confidence score for each detected item of protective equipment on a person.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-17", "source_tokens": 503, "generated_at": "2026-02-11T16:19:34.288198"}}
{"question": "What labels can Amazon Rekognition Streaming Video Events detect for object detection?", "answer": "Amazon Rekognition Streaming Video Events can detect people, pets (specifically dogs and cats), and packages.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:19:39.820978"}}
{"question": "How does the process of detecting objects using Amazon Rekognition Streaming Video Events work?", "answer": "When motion is detected on a connected camera, a notification is sent to Amazon Rekognition to start processing the corresponding video stream. Amazon Rekognition then looks for the desired objects (people, pets, or packages) in the video post-motion detection. As soon as a desired object is detected, Amazon Rekognition sends a notification to the user with the object's bounding box, a zoomed-in image of the object, and the time stamp.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:19:39.821240"}}
{"question": "What is the difference in detection accuracy between Amazon Rekognition for detecting packages and small objects like bubble mailers?", "answer": "Amazon Rekognition Streaming Video Event APIs have high accuracy for detecting medium and large cardboard boxes but may miss smaller objects like bubble mailers and folders occasionally.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-18", "source_tokens": 506, "generated_at": "2026-02-11T16:19:39.821633"}}
{"question": "What resolution and fps are required for label detection in Amazon Rekognition Streaming Video Events?", "answer": "Amazon Rekognition Streaming Video Events supports 1080p or lower resolution video streams and processes the video stream at 5 fps.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-11T16:19:43.860295"}}
{"question": "Why can you choose to opt into specific labels for Amazon Rekognition Streaming Video Events?", "answer": "You can opt into specific labels (pet, package) or choose to opt in to all three labels (people, pet, package) based on your use case.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-11T16:19:43.860664"}}
{"question": "How does the processing time and cost of Amazon Rekognition Streaming Video Events compare between different resolutions?", "answer": "Amazon Rekognition Streaming Video Events processes lower resolution videos (1080p or lower) to keep costs and latency low.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-19", "source_tokens": 509, "generated_at": "2026-02-11T16:19:43.861059"}}
{"question": "How many concurrent video streams can Amazon Rekognition process?", "answer": "Amazon Rekognition Streaming Video Events can support 600 concurrent sessions per AWS customer.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-11T16:19:46.898792"}}
{"question": "What is the concept behind Amazon Rekognition's limit on concurrent video streams?", "answer": "Amazon Rekognition sets a limit of 600 concurrent sessions for streaming video events to manage resource utilization effectively.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-11T16:19:46.899064"}}
{"question": "How does the concurrent video stream limit of Amazon Rekognition compare to other similar services?", "answer": "Without explicit context regarding other similar services, a comparison question cannot be answered accurately.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-20", "source_tokens": 59, "generated_at": "2026-02-11T16:19:46.899236"}}
{"question": "What is the definition of a video segment in Amazon Rekognition Video?", "answer": "A video segment is defined by a start timestamp, an end timestamp, and a duration.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T16:19:51.453298"}}
{"question": "How does Amazon Rekognition Video identify and return label results when they span multiple consecutive frames?", "answer": "Amazon Rekognition Video returns a single label entry for each detected label, with the start timestamp, end timestamp, and duration representing the frames in which the label was detected.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T16:19:51.453602"}}
{"question": "How does the label detection and segment definition process in Amazon Rekognition Video compare to other labeling solutions that return results per frame?", "answer": "In Amazon Rekognition Video, label results are organized by video segments, while other solutions may return results per frame. This difference allows Amazon Rekognition Video to provide more context around label detections, as each segment represents a continuous occurrence of the label across multiple frames.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-21", "source_tokens": 132, "generated_at": "2026-02-11T16:19:51.453978"}}
{"question": "What types of segments or entities can Amazon Rekognition Video detect in media analysis?", "answer": "Amazon Rekognition Video can detect black frames, credits, shots, and color bars.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:19:55.464533"}}
{"question": "How does Amazon Rekognition Video help with identifying credits in videos?", "answer": "Amazon Rekognition Video can identify the exact frames where opening and closing credits start and end for a movie or TV show, allowing the generation of 'binge markers' or interactive viewer prompts.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:19:55.464861"}}
{"question": "How does detecting color bars with Amazon Rekognition Video differ from detecting shots?", "answer": "Detecting color bars involves identifying sections of video that display SMPTE or EBU color bars, while detecting shots involves detecting the start, end, and duration of a continuous series of pictures taken by a single camera.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:19:55.465240"}}
{"question": "What types of metadata does Amazon Rekognition identify in video slates?", "answer": "Amazon Rekognition can identify text metadata about the episode, studio, video format, and audio channels in video slates.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:19:59.768945"}}
{"question": "How does Amazon Rekognition help with reviewing studio logos in videos?", "answer": "Amazon Rekognition can identify sequences that contain studio logos or emblems in videos, making it easy for operators to review them for identifying studios.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:19:59.769216"}}
{"question": "What are the differences between content and non-content segments in videos, according to the text?", "answer": "Content refers to the portions of the TV show or movie that contain the program or related elements, while non-content segments include black frames, credits, color bars, slates, and studio logos. Once all the content segments are detected with Amazon Rekognition Video, you can apply specific domain knowledge to further categorize each segment.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-23", "source_tokens": 347, "generated_at": "2026-02-11T16:19:59.769668"}}
{"question": "What format do frame accurate timecodes use in the given text passage?", "answer": "Frame accurate timecodes are provided in the SMPTE (Society of Motion Picture and Television Engineers) format hours:minutes:seconds:frame number.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-11T16:20:04.283921"}}
{"question": "How does Amazon Rekognition Video segment detection handle different frame rates when generating timecodes?", "answer": "Amazon Rekognition Video segment detection handles integer, fractional, and drop frame standards for frame rates between 15 and 60fps and generates frame accurate timecodes accordingly.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-11T16:20:04.284199"}}
{"question": "What is the difference between the timecodes provided by Amazon Rekognition Video segment detection and those using the SMPTE format?", "answer": "Amazon Rekognition Video segment detection provides both frame accurate SMPTE timecodes and millisecond timestamps for the start and end of each detection.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-24", "source_tokens": 382, "generated_at": "2026-02-11T16:20:04.284597"}}
{"question": "What is the unit of image processing for DetectLabels, DetectModerationLabels, DetectText, DetectFaces, IndexFaces, RecognizeCelebrities, SearchFaceByImage, and Image Properties APIs?", "answer": "The unit of image processing for DetectLabels, DetectModerationLabels, DetectText, DetectFaces, IndexFaces, RecognizeCelebrities, SearchFaceByImage, and Image Properties APIs is an 'image'.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-11T16:20:11.464779"}}
{"question": "How does Amazon Rekognition handle image processing for videos reclaimed from tape archives compared to modern digital videos?", "answer": "Amazon Rekognition allows users to account for varied video quality and formats when detecting black frames by specifying filters such as minimum confidence score, maximum pixel luminance for black pixels, and percentage of pixels meeting the black pixel luminance criteria.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-11T16:20:11.465074"}}
{"question": "How does Amazon Rekognition charge for image processing and video processing, respectively?", "answer": "Amazon Rekognition charges for image processing based on the number of images processed (DetectLabels, DetectModerationLabels, DetectText, DetectFaces, IndexFaces, RecognizeCelebrities, SearchFaceByImage, CompareFaces, SearchFaces, and Image Properties APIs), while charges for video processing are based on the duration of the video in minutes (StartLabelDetection, StartFaceDetection, StartTextDetection, StartContentModeration, StartPersonTracking, StartCelebrityRecognition, StartFaceSearch, and StartStreamProcessor APIs).", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-25", "source_tokens": 492, "generated_at": "2026-02-11T16:20:11.465437"}}
{"question": "What is the cost of Amazon Rekognition per 1,000 face vectors per month?", "answer": "The cost of Amazon Rekognition per 1,000 face vectors per month is $0.01.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-11T16:20:15.542992"}}
{"question": "How does Amazon Rekognition allow us to analyze images stored in Amazon S3?", "answer": "Amazon Rekognition allows us to analyze images stored in Amazon S3 without moving the data by pointing the Amazon Rekognition API to the S3 bucket.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-11T16:20:15.543390"}}
{"question": "What are the differences in regions between Amazon Rekognition API endpoint and Amazon S3 bucket?", "answer": "The Amazon Rekognition API endpoint and Amazon S3 bucket must be in the same region for image analysis.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-26", "source_tokens": 336, "generated_at": "2026-02-11T16:20:15.543675"}}
{"question": "What does Amazon Rekognition use processed image and video inputs for?", "answer": "Amazon Rekognition uses processed image and video inputs solely to provide and maintain the service, and to improve and develop the quality of Amazon Rekognition and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-11T16:20:21.458353"}}
{"question": "How does Amazon Rekognition ensure the security and privacy of user content?", "answer": "Amazon Rekognition ensures the security and privacy of user content by implementing appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, user content and ensure that the service complies with its commitments to users.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-11T16:20:21.458626"}}
{"question": "What is the difference between how Amazon Rekognition uses and handles user content compared to other AWS services?", "answer": "Amazon Rekognition uses and handles user content solely to provide and maintain the service and to improve and develop the quality of Amazon Rekognition and other Amazon machine-learning/artificial-intelligence technologies. Access to user content is restricted to authorized employees, and user content is encrypted at rest and in transit. In contrast, users can opt out of having their image and video inputs used for these purposes.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-27", "source_tokens": 477, "generated_at": "2026-02-11T16:20:21.458824"}}
{"question": "What is the role of AWS IAM in granting access to Amazon Rekognition APIs?", "answer": "AWS IAM is used to ensure that only authorized users have access to Amazon Rekognition APIs. IAM policies can be created to grant or deny access to specific APIs or actions.", "question_type": "factual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-11T16:20:27.712515"}}
{"question": "Why is it important to understand and comply with biometrics laws when using Amazon Rekognition?", "answer": "Biometrics laws apply to the collection, processing, and use of biometric data, such as facial geometry. They may require providing notice to and obtaining consent from end users, and complying with deletion requests. Compliance is part of the shared responsibility model and helps ensure responsible use of Amazon Rekognition.", "question_type": "conceptual", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-11T16:20:27.712790"}}
{"question": "How does the process of providing notice and obtaining consent for biometrics data usage with Amazon Rekognation compare to other AWS services?", "answer": "For AWS generally, there are resources and tools provided for building and using AI systems responsibly. For Amazon Rekognition specifically, there are AI Service Cards that explain the intended use cases, how the service uses machine learning, and key considerations for responsible design and use. Biometrics data, however, requires additional attention due to specific legal requirements, including providing notice and obtaining consent from end users and complying with deletion requests.", "question_type": "comparison", "metadata": {"service": "REKOGNITION", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "rekognition-faq-28", "source_tokens": 485, "generated_at": "2026-02-11T16:20:27.712960"}}
{"question": "What resource types can be shared using AWS Resource Access Manager (AWS RAM)?", "answer": "AWS RAM supports sharing various resource types. For a complete list, refer to the 'shareable AWS resources' in the AWS Resource Access Manager User Guide.", "question_type": "factual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T16:20:32.812746"}}
{"question": "How does AWS Resource Access Manager (AWS RAM) help in managing resource access across multiple AWS accounts?", "answer": "AWS Resource Access Manager (AWS RAM) allows you to securely share resources across AWS accounts, eliminating the need to provision and manage resources in every account. When a resource is shared, the receiving account gains access to it, and their policies and permissions apply to the shared resource.", "question_type": "conceptual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T16:20:32.813035"}}
{"question": "Can I share resources with IAM users using AWS Resource Access Manager (AWS RAM)?", "answer": "Yes, you can share resources with IAM users using AWS Resource Access Manager (AWS RAM). When you share a resource with IAM users, they receive an invitation to join the resource share, which they must accept before they can start using the shared resources.", "question_type": "comparison", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-0", "source_tokens": 510, "generated_at": "2026-02-11T16:20:32.813278"}}
{"question": "What type of permissions can be specified for resource access in AWS RAM?", "answer": "IAM policies can be specified to control access to resources shared with you in AWS Resource Access Manager (RAM).", "question_type": "factual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T16:20:36.252939"}}
{"question": "What happens when you stop sharing a resource in AWS RAM?", "answer": "You can stop sharing a resource by removing it from the resource share or by deleting the resource share.", "question_type": "conceptual", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T16:20:36.253220"}}
{"question": "How does the use of AWS managed permissions compare to customer managed permissions in AWS RAM?", "answer": "AWS managed permissions are created and maintained by AWS, while customer managed permissions are permissions that you author and maintain. AWS managed permissions grant permissions for common customer scenarios, while customer managed permissions allow for tailoring permissions to specific needs.", "question_type": "comparison", "metadata": {"service": "RESOURCE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "resource-faq-1", "source_tokens": 433, "generated_at": "2026-02-11T16:20:36.253371"}}
{"question": "What role does DNS play in translating domain names into IP addresses?", "answer": "DNS is a globally distributed service that translates human readable names like www.example.com into the numeric IP addresses that computers use to connect to each other.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T16:20:42.040026"}}
{"question": "How does DNS function in terms of managing the mapping between domain names and IP addresses?", "answer": "DNS works like a phone book, managing the mapping between names and numbers. When a user types a domain name into their web browser, a query is sent to DNS servers to translate the domain name into the corresponding IP address, controlling which server the end user will reach.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T16:20:42.040417"}}
{"question": "What's the difference between Route 53 and a traditional DNS service regarding DNS Routing Policies and Health Checks?", "answer": "Both Route 53 and traditional DNS services manage the translation of domain names into IP addresses. However, Route 53 offers additional features like DNS Routing Policies and Health Checks. DNS Routing Policies help in routing traffic based on different conditions like latency or geolocation. Health Checks and DNS Failover help in monitoring the health of your resources and automatically failover to a healthy resource if needed.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-0", "source_tokens": 324, "generated_at": "2026-02-11T16:20:42.040658"}}
{"question": "What services does Amazon Route 53 provide for domain name system (DNS) and registration?", "answer": "Amazon Route 53 provides highly available and scalable DNS, domain name registration, and health-checking web services.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-11T16:20:47.510266"}}
{"question": "How can you use Amazon Route 53 to manage DNS records for a domain name like example.com?", "answer": "Amazon Route 53 lets you manage the IP addresses listed for your domain names in the Internetâ€™s DNS phone book, create DNS records for a new domain or transfer DNS records for an existing domain, and answer requests to translate specific domain names like example.com into their corresponding IP addresses like 192.0.2.1.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-11T16:20:47.510553"}}
{"question": "What is the difference between managing DNS records using Amazon Route 53 and a traditional phone book?", "answer": "Amazon Route 53 is a cloud-based DNS service that allows you to manage the IP addresses listed for your domain names and answer requests to translate specific domain names into their corresponding IP addresses, while a traditional phone book is a physical directory that lists phone numbers and their corresponding names.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-1", "source_tokens": 380, "generated_at": "2026-02-11T16:20:47.510708"}}
{"question": "What steps do I take to create a hosted zone for an existing domain name in Amazon Route 53?", "answer": "You can create a hosted zone for an existing domain name in Amazon Route 53 using the AWS Management Console or the CreateHostedZone API. Upon creating the hosted zone, you will receive four Route 53 name servers across four different Top-Level Domains (TLDs) to help ensure a high level of availability.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-11T16:20:54.849483"}}
{"question": "How does the process of managing domain name servers differ between an existing domain name and a new one when using Amazon Route 53?", "answer": "For an existing domain name, you create a hosted zone using the AWS Management Console or the CreateHostedZone API, and then inform your domain registrar to update the name servers for your domain to the ones associated with your hosted zone. For a new domain name, you can register the domain name and create the hosted zone using the AWS Management Console or the API, and Route 53 automatically associates the domain name with the name servers hosting your zone.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-11T16:20:54.849909"}}
{"question": "What happens when I create a hosted zone for my domain in Amazon Route 53?", "answer": "When you create a hosted zone for your domain in Amazon Route 53, you receive four Route 53 name servers across four different Top-Level Domains (TLDs) to help ensure a high level of availability. Your hosted zone will be initially populated with a basic set of DNS records, including four virtual name servers that will answer queries for your domain. You can add, delete or change records in this set by using the AWS Management Console or by calling the ChangeResourceRecordSet API.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-2", "source_tokens": 407, "generated_at": "2026-02-11T16:20:54.850375"}}
{"question": "What is the infrastructure that Route 53 is built upon?", "answer": "Route 53 is built using AWSâ€™s highly available and reliable infrastructure.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-11T16:20:59.451482"}}
{"question": "How does Route 53 ensure consistent routing for end users?", "answer": "Route 53 uses a global anycast network of DNS servers around the world to automatically answer queries from the optimal location, resulting in low query latency for end users.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-11T16:20:59.451802"}}
{"question": "What is the difference between a domain and a hosted zone in the context of Route 53?", "answer": "A domain is a general DNS concept and a domain name is an easily recognizable name for numerically addressed Internet resources, such as amazon.com. A hosted zone is an Amazon Route 53 concept and represents a collection of records that can be managed together, belonging to a single parent domain name, like the amazon.com hosted zone.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-3", "source_tokens": 466, "generated_at": "2026-02-11T16:20:59.452294"}}
{"question": "What is the billing process for Amazon Route 53 hosted zones?", "answer": "Amazon Route 53 hosts charge fees when hosted zones are created and then on the first day of each month.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:21:03.576221"}}
{"question": "How does AWS IAM help with controlling access to Amazon Route 53?", "answer": "AWS IAM allows creating multiple users and managing their permissions for modifying DNS records within an AWS Account.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:21:03.576587"}}
{"question": "What is the difference in billing between creating a new Amazon Route 53 hosted zone and creating it on the last day of the month?", "answer": "A new hosted zone fee is charged upon creation, while a hosted zone fee for creating a zone on the last day of the month appears on the subsequent month's invoice.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:21:03.577019"}}
{"question": "What is the role of Amazon Route 53's Anycast technology in DNS queries?", "answer": "Amazon Route 53's Anycast technology helps end users' DNS queries get answered from the optimal location for improved performance and high availability.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-11T16:21:08.504484"}}
{"question": "How does creating multiple hosted zones benefit a user in Route 53?", "answer": "Creating multiple hosted zones allows users to test DNS settings in a 'test' environment and then replicate those settings on a 'production' hosted zone for different name servers, resulting in different answers for DNS queries based on the hosted zone.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-11T16:21:08.504697"}}
{"question": "In what ways does creating multiple hosted zones differ in terms of resource limitations?", "answer": "Each Amazon Route 53 account is limited to a maximum of 500 hosted zones and 10,000 resource record sets per hosted zone. Creating multiple hosted zones allows users to manage separate DNS settings for different environments, but they each come with the same resource limitations.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-5", "source_tokens": 389, "generated_at": "2026-02-11T16:21:08.505059"}}
{"question": "Which DNS record types does Amazon Route 53 currently support?", "answer": "Amazon Route 53 currently supports the following DNS record types: A, AAAA, CNAME, CAA, MX, NAPTR, NS, PTR, SOA, SPF, SRV, TXT, and alias records.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-11T16:21:16.434986"}}
{"question": "How does alias record in Amazon Route 53 work?", "answer": "Alias records in Amazon Route 53 are an Amazon Route 53-specific extension to DNS. They allow you to route traffic to selected AWS resources, including Amazon Elastic Load Balancing load balancers, Amazon CloudFront distributions, AWS Elastic Beanstalk environments, API Gateways, VPC interface endpoints, and Amazon S3 buckets that are configured as websites. Alias records typically have a type of A or AAAA, but they work like a CNAME record. Using an alias record, you can map your record name (example.com) to the DNS name for an AWS resource (elb1234.elb.amazonaws.com). Resolvers see the A or AAAA record and the IP address of the AWS resource.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-11T16:21:16.435254"}}
{"question": "What is the difference between using an alias record and a CNAME record in Amazon Route 53?", "answer": "Both alias records and CNAME records allow you to redirect traffic to different resources. However, CNAME records can only be used to redirect traffic to other DNS records, while alias records in Amazon Route 53 allow you to redirect traffic to various types of AWS resources, including Amazon Elastic Load Balancing load balancers, Amazon CloudFront distributions, AWS Elastic Beanstalk environments, API Gateways, VPC interface endpoints, and Amazon S3 buckets that are configured as websites.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-6", "source_tokens": 429, "generated_at": "2026-02-11T16:21:16.435433"}}
{"question": "What type of record in Amazon Route 53 supports wildcard entries, excluding NS records?", "answer": "All record types in Amazon Route 53, except NS records, support wildcard entries.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:21:21.136424"}}
{"question": "How does setting a TTL for a record in Amazon Route 53 impact DNS resolver caching?", "answer": "Setting a TTL for a record instructs DNS resolvers how long to cache the response. Amazon Route 53 does not have a default TTL and requires a specific TTL to be set for each record.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:21:21.136726"}}
{"question": "How does Amazon Route 53's support for Alias records and multiple IP addresses for an A record compare?", "answer": "Both Alias records and multiple IP addresses for an A record help in managing DNS settings for subdomains and geographically-distributed web servers. However, Alias records map sub-domains to load balancers, CloudFront distributions, or S3 website buckets, while multiple IP addresses for an A record lists multiple IP addresses for the same domain.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:21:21.137128"}}
{"question": "How long does it take for Amazon Route 53 to propagate DNS record updates worldwide?", "answer": "Amazon Route 53 propagates updates to its DNS records worldwide within 60 seconds under normal conditions.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-11T16:21:25.512135"}}
{"question": "What happens when DNS record updates are successfully propagated through Amazon Route 53?", "answer": "When an API call returns an INSYNC status listing, it indicates that the DNS record updates have been successfully propagated world-wide through Amazon Route 53.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-11T16:21:25.512421"}}
{"question": "Can Amazon CloudTrail be used to roll back changes to hosted zones? And if not, what are its alternative uses?", "answer": "No, Amazon CloudTrail logs cannot be used to roll back changes to hosted zones. Instead, they can be used for security analysis, resource change tracking, and compliance auditing.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-8", "source_tokens": 384, "generated_at": "2026-02-11T16:21:25.512808"}}
{"question": "What type of record does Amazon Route 53 offer that lets you map a zone apex to an ELB load balancer's DNS name?", "answer": "Alias record", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-11T16:21:30.264366"}}
{"question": "How does mapping a zone apex to an ELB load balancer's DNS name with an Alias record in Amazon Route 53 benefit users?", "answer": "It allows Route 53 to respond with one or more IP addresses for the load balancer, accommodating for potential IP address changes due to scaling or software updates.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-11T16:21:30.264651"}}
{"question": "What's the difference between mapping a zone apex to an ELB load balancer and an Amazon S3 website bucket with an Alias record in Amazon Route 53?", "answer": "The main difference lies in the DNS name for the service - an ELB load balancer's DNS name vs an Amazon S3 website bucket's DNS name.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-9", "source_tokens": 390, "generated_at": "2026-02-11T16:21:30.264809"}}
{"question": "What type of record in Amazon Route 53 maps a zone apex DNS name to an Amazon CloudFront distribution?", "answer": "Alias record", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-11T16:21:36.185586"}}
{"question": "How does mapping a zone apex DNS name to an Amazon CloudFront distribution using an Alias record in Amazon Route 53 benefit users?", "answer": "Amazon Route 53 responds to each request for an Alias record with the IP address(es) for the CloudFront distribution, which helps direct the end user to the nearest CloudFront edge location. IP addresses associated with CloudFront endpoints can change due to scaling and software updates, but Route 53 ensures users are always directed to the correct IP address.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-11T16:21:36.185877"}}
{"question": "What is the difference in IP address stability when using an Alias record in Amazon Route 53 to map a zone apex DNS name to an Amazon CloudFront distribution compared to an AWS Elastic Beanstalk environment?", "answer": "IP addresses associated with Amazon CloudFront endpoints can change based on the end user's location and due to scaling and software updates, while IP addresses associated with AWS Elastic Beanstack environments can also change due to scaling and software updates. However, when using an Alias record for a CloudFront distribution, Amazon Route 53 handles the IP address changes and ensures users are always directed to the correct IP address. No such handling is provided for AWS Elastic Beanstalk environments.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-10", "source_tokens": 350, "generated_at": "2026-02-11T16:21:36.186326"}}
{"question": "What type of record in Amazon Route 53 allows mapping a zone apex DNS name to an Amazon API Gateway DNS name?", "answer": "Alias record", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-11T16:21:41.614494"}}
{"question": "How does mapping a zone apex DNS name to an Amazon API Gateway DNS name using an Alias record in Amazon Route 53 work?", "answer": "When a user makes a DNS query for the zone apex name (example.com), Route 53 responds with one or more IP addresses for the API Gateway. This allows the API Gateway IP addresses, which can change at any time, to be automatically updated in the DNS.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-11T16:21:41.614764"}}
{"question": "What's the difference between mapping a zone apex DNS name to an Amazon API Gateway DNS name and an Amazon VPC Endpoint DNS name using Alias records in Amazon Route 53?", "answer": "The primary difference is that the IP addresses associated with Amazon API Gateway can change at any time due to scaling or software updates, while the IP addresses associated with Amazon VPC Endpoints can also change but typically remain consistent within a VPC.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-11", "source_tokens": 357, "generated_at": "2026-02-11T16:21:41.614933"}}
{"question": "What type of record should I create for my S3 bucket if it's configured to host static websites?", "answer": "You should create an 'Alias' record for your domain that maps to your S3 website bucket.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-11T16:21:47.304442"}}
{"question": "What are the advantages of using an Alias record over a CNAME record for a CloudFront distribution or an S3 bucket?", "answer": "An Alias record has two advantages: first, you can create an Alias record for your zone apex, and second, queries to Alias records are free of charge.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-11T16:21:47.304715"}}
{"question": "How long does it take for Amazon Route 53 to propagate updates to my DNS records after I've made changes?", "answer": "After you make changes to your resource record sets in Amazon Route 53, the service propagates updates to its world-wide network of authoritative DNS servers. However, if you test the record before propagation is complete, you might see an old value when you use dig or nslookup utilities. DNS resolvers on the internet also cache your resource record sets according to their time to live (TTL), so a dig/nslookup command might return a cached value.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-12", "source_tokens": 398, "generated_at": "2026-02-11T16:21:47.305199"}}
{"question": "What percentage of the time will Route 53 return a record set with weight 3 compared to a record set with weight 1 in a Weighted Round Robin setup?", "answer": "75% of the time for the record set with weight 3 and 25% of the time for the record set with weight 1.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-11T16:21:52.605194"}}
{"question": "How does Amazon Route 53's Latency Based Routing (LBR) feature improve application performance for a global audience?", "answer": "Amazon Route 53's LBR feature determines the best AWS endpoint for each request based on the location of the end user and routes them accordingly to minimize latency.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-11T16:21:52.605538"}}
{"question": "What is the difference between Weighted Round Robin and Latency Based Routing in terms of how Amazon Route 53 determines which record set to return to the end user?", "answer": "Weighted Round Robin allows you to specify the frequency of different responses based on weights assigned to record sets, while Latency Based Routing determines the best AWS endpoint for each request based on the location of the end user to minimize latency.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-13", "source_tokens": 440, "generated_at": "2026-02-11T16:21:52.605723"}}
{"question": "What geographic levels does Amazon Route 53's Geo DNS support?", "answer": "Amazon Route 53's Geo DNS provides three levels of geographic granularity: continent, country, and state.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-11T16:21:57.112653"}}
{"question": "How does using a global record with Amazon Route 53's Geo DNS benefit me?", "answer": "Using a global record with Amazon Route 53's Geo DNS ensures that Route 53 can provide a response to DNS queries from all possible locations, even if you have created specific records for certain geographies.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-11T16:21:57.112989"}}
{"question": "What happens when an end user's location doesn't match any specific Geo DNS records I have created?", "answer": "In such cases, Amazon Route 53 will return the value contained in the global record.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-14", "source_tokens": 485, "generated_at": "2026-02-11T16:21:57.113189"}}
{"question": "What geographic regions can you have Geo DNS records for in Route 53?", "answer": "You can have Geo DNS records for continents, countries, and states within countries.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-11T16:22:01.501083"}}
{"question": "How does Route 53 determine which Geo DNS record to return for a given user location?", "answer": "Route 53 returns the most specific Geo DNS record that includes the given user location. It first checks for a state record, then a country record, and finally a continent record.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-11T16:22:01.501366"}}
{"question": "What's the difference between Geo DNS and Latency Based Routing in Route 53?", "answer": "Geo DNS bases routing decisions on the geographic location of the requests, while Latency Based Routing utilizes latency measurements between viewer networks and AWS datacenters.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-15", "source_tokens": 474, "generated_at": "2026-02-11T16:22:01.501803"}}
{"question": "What is the purpose of a traffic policy in Amazon Route 53 Traffic Flow?", "answer": "A traffic policy in Amazon Route 53 Traffic Flow is a set of rules that define how end usersâ€™ requests are routed to one of your applicationâ€™s endpoints.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-11T16:22:06.803014"}}
{"question": "How can you create a traffic policy in Amazon Route 53 Traffic Flow?", "answer": "You can create a traffic policy using the visual policy builder in the Amazon Route 53 Traffic Flow section of the Amazon Route 53 console or by creating JSON-formatted text files and uploading them using the Route 53 API, the AWS CLI, or the various AWS SDKs.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-11T16:22:06.803297"}}
{"question": "What's the difference between a traffic policy and a policy record in Amazon Route 53 Traffic Flow?", "answer": "A traffic policy is a set of rules that define how end usersâ€™ requests are routed to one of your applicationâ€™s endpoints, while a policy record associates the traffic policy with the appropriate DNS name within an Amazon Route 53 hosted zone.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-16", "source_tokens": 467, "generated_at": "2026-02-11T16:22:06.803707"}}
{"question": "How many ways can I manage multiple DNS names with a single traffic policy in Amazon Route 53?", "answer": "You can manage multiple DNS names with a single traffic policy in Amazon Route 53 using two methods: creating additional policy records or creating standard CNAME records.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-11T16:22:11.687034"}}
{"question": "What is the cost difference between managing multiple DNS names under a single traffic policy using policy records and CNAME records in Amazon Route 53?", "answer": "Managing multiple DNS names under a single traffic policy using policy records incurs additional charges because you are billed for each policy record you create. On the other hand, managing multiple DNS names using CNAME records does not incur additional charges.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-11T16:22:11.687351"}}
{"question": "Can I create an Alias record pointing to a DNS name managed by a traffic policy in Amazon Route 53?", "answer": "Yes, you can create an Alias record pointing to a DNS name managed by a traffic policy in Amazon Route 53.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-17", "source_tokens": 452, "generated_at": "2026-02-11T16:22:11.687528"}}
{"question": "What regions can you specify when creating a traffic flow policy in AWS?", "answer": "You can specify either an AWS region or the latitude and longitude for each endpoint when creating a traffic flow policy in AWS.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-11T16:22:16.716059"}}
{"question": "How does changing the geoproximity bias value impact traffic routing in Route 53?", "answer": "Changing the geoproximity bias value on an endpoint expands or shrinks the area from which Route 53 routes traffic to a resource, but it can't accurately predict the load factor.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-11T16:22:16.716364"}}
{"question": "What's the difference between managing private IP addresses within VPCs using Route 53's Public DNS and Private DNS?", "answer": "With Route 53 Public DNS, your DNS records, including the name of the resource and its IP address(es), are exposed to the Internet. In contrast, with Route 53 Private DNS, your DNS records are only returned when queried from within the associated VPCs.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-18", "source_tokens": 468, "generated_at": "2026-02-11T16:22:16.716728"}}
{"question": "What internet connectivity is needed to update the configuration for a Private DNS hosted zone on Route 53?", "answer": "Internet connectivity is required to access the Route 53 API endpoint, which is outside of VPC.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-11T16:22:20.503335"}}
{"question": "How does Route 53 Private DNS use VPC for DNS resolution for private hosted zones?", "answer": "Route 53 Private DNS uses VPC to manage visibility and provide DNS resolution for private DNS hosted zones.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-11T16:22:20.503608"}}
{"question": "What are the differences between creating standard health checks and metric-based health checks for endpoints in a Private DNS hosted zone?", "answer": "Standard health checks can be created against public IP addresses of endpoints, while metric-based health checks use existing Amazon CloudWatch metrics as the source of endpoint health information.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-19", "source_tokens": 505, "generated_at": "2026-02-11T16:22:20.504064"}}
{"question": "What are the two main components of DNS Failover?", "answer": "DNS Failover consists of two components: health checks and failover.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-11T16:22:26.175698"}}
{"question": "How does DNS Failover work for Elastic Load Balancers?", "answer": "To enable DNS Failover for an Elastic Load Balancer (ELB) endpoint, create an Alias record pointing to the ELB and set the â€˜Evaluate Target Healthâ€™ parameter to true. Route 53 creates and manages the health checks for your ELB automatically, inheriting the health of your backend instances behind that ELB.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-11T16:22:26.175998"}}
{"question": "What is the difference between using DNS Failover for an Elastic Load Balancer and a static site?", "answer": "DNS Failover for an Elastic Load Balancer involves creating an Alias record pointing to the ELB and setting the â€˜Evaluate Target Healthâ€™ parameter to true, allowing Route 53 to manage the health checks and health status of the load balancer. In contrast, using DNS Failover for a static site (such as an Amazon S3 website bucket) involves setting up health checks for the static site and configuring Route 53 to route traffic to the healthy site.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-20", "source_tokens": 416, "generated_at": "2026-02-11T16:22:26.176188"}}
{"question": "What is the default threshold for consecutive failed health checks before Route 53 considers an endpoint failed?", "answer": "The default threshold is three consecutive health check observations.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-11T16:22:31.093518"}}
{"question": "How does Route 53 determine which endpoint to route traffic to when one endpoint fails health checks?", "answer": "Route 53 does not make routing decisions based on the load or available traffic capacity of your endpoints. You will need to ensure that you have available capacity at your other endpoints, or the ability to scale at those endpoints, to handle the traffic from the failed endpoint.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-11T16:22:31.093789"}}
{"question": "What is the difference between setting up health checks for endpoints running within AWS versus outside AWS when using Route 53?", "answer": "For endpoints within AWS, Route 53 automatically creates and manages health checks on your behalf. For endpoints running outside AWS, you need to set up health checks yourself, and Route 53 can fail over to the endpoint within AWS if the health checks fail.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-21", "source_tokens": 480, "generated_at": "2026-02-11T16:22:31.093956"}}
{"question": "What is the default interval for Route 53 health checks?", "answer": "The default interval for Route 53 health checks is 30 seconds.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-11T16:22:35.157888"}}
{"question": "Why do fast interval health checks in Route 53 check endpoints more frequently?", "answer": "Fast interval health checks check endpoints every 10 seconds instead of the default 30 seconds. This enables faster DNS failover and confirmation of endpoint failure but results in more traffic to the endpoint.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-11T16:22:35.158181"}}
{"question": "How often does an endpoint receive requests on average for fast interval health checks compared to standard interval health checks?", "answer": "An endpoint receives approximately one or more requests per second for fast interval health checks and one request every 2-3 seconds on average for standard interval health checks.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-22", "source_tokens": 411, "generated_at": "2026-02-11T16:22:35.158577"}}
{"question": "What happens to the resource records when a health check fails and failover occurs in Route 53?", "answer": "The resource records for the failed endpoint are disabled and no longer served, causing traffic to be routed to the healthy endpoints instead.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-11T16:22:39.478003"}}
{"question": "How does the TTL setting impact the use of DNS Failover in Route 53?", "answer": "A lower TTL value is recommended for DNS Failover to minimize the time it takes for traffic to stop being routed to a failed endpoint. For ELB and S3 Website endpoints, you need to use Alias records with a fixed TTL of 60 seconds.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-11T16:22:39.478275"}}
{"question": "In what ways does Route 53's health check differ when using HTTPS compared to HTTP or TCP?", "answer": "Route 53's HTTPS health checks test connectivity over SSL and check for a valid HTTP response code, but they do not validate the SSL certificate returned by the endpoint.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-23", "source_tokens": 419, "generated_at": "2026-02-11T16:22:39.478673"}}
{"question": "What is the purpose of the 'Enable String Matching' option in Route 53 health checks?", "answer": "The 'Enable String Matching' option in Route 53 health checks allows users to check for the presence of a designated string in a server response.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-11T16:22:44.193559"}}
{"question": "How can Route 53 health checks be used to check the internal health of a server?", "answer": "Users can create a dedicated status page and use it to check the health of the server from an internal or operational perspective with Route 53 health checks.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-11T16:22:44.193917"}}
{"question": "What metrics are published for Route 53 health checks and how can they be used?", "answer": "Amazon Route 53 publishes health and latency metrics for each health check as Amazon CloudWatch metrics. These metrics can be used to view the current and historical status of the health check, as well as create CloudWatch alarms to send notifications if the status changes.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-24", "source_tokens": 444, "generated_at": "2026-02-11T16:22:44.194299"}}
{"question": "What metric in CloudWatch is generated by each Route 53 health check?", "answer": "Each Route 53 health check publishes its results as a CloudWatch metric.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-11T16:22:49.006812"}}
{"question": "Why would you use the 'Evaluate Target Health' option for setting up DNS Failover with ELB endpoints?", "answer": "The 'Evaluate Target Health' option allows you to use Alias records with Route 53 and automatically enables DNS Failover for ELB endpoints without creating your own health checks.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-11T16:22:49.007073"}}
{"question": "How can you re-send the confirmation email for an SNS topic associated with a Route 53 alarm?", "answer": "You can re-send the confirmation email for an SNS topic associated with a Route 53 alarm by opening the 'Create Subscription' box within the SNS console, selecting Email for protocol, and entering the desired email address. Clicking 'Subscribe' will re-send the confirmation email.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-25", "source_tokens": 499, "generated_at": "2026-02-11T16:22:49.007439"}}
{"question": "What metrics does Amazon Route 53 use for metric-based health checks?", "answer": "Amazon Route 53 uses metrics available within Amazon CloudWatch, including AWS-provided metrics and custom metrics from your own application.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-11T16:22:53.421740"}}
{"question": "How does Amazon Route 53 handle health checks for Amazon S3 Website buckets?", "answer": "Amazon Route 53 takes into account the health of the Amazon S3 service itself in the AWS region where your bucket is located. It does not check whether a specific bucket exists or contains valid website content.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-11T16:22:53.422147"}}
{"question": "What's the difference between standard and metric-based health checks in Amazon Route 53?", "answer": "Standard health checks make requests against an endpoint from a network of checkers around the world, while metric-based health checks rely on metrics within Amazon CloudWatch to determine health.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-26", "source_tokens": 468, "generated_at": "2026-02-11T16:22:53.422541"}}
{"question": "What type of IP address does Amazon Route 53 use for health checks when a domain name is specified as the endpoint?", "answer": "Amazon Route 53 uses IPv4 address for health checks when a domain name is specified as the endpoint.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-11T16:22:57.827888"}}
{"question": "Why won't Amazon Route 53 use IPv6 addresses for health checks when a domain name is used as the endpoint?", "answer": "Amazon Route 53 does not attempt to look up IPv6 addresses for endpoints that are specified by domain name.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-11T16:22:57.828216"}}
{"question": "How does the use of a domain name as an endpoint in Amazon Route 53 health checks compare to using an IP address directly?", "answer": "When using a domain name as an endpoint, Amazon Route 53 only uses IPv4 address for health checks, whereas selecting an IP address directly allows for IPv6 address to be used.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-27", "source_tokens": 124, "generated_at": "2026-02-11T16:22:57.828604"}}
{"question": "What service field values should I search for in the 'ip-ranges.json' file to find IP ranges for Route 53 DNS servers and health checkers?", "answer": "Search for 'ROUTE53' to find IP ranges for Route 53 DNS servers and search for 'ROUTE53_HEALTHCHECKS' to find IP ranges for Route 53 health checkers.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-11T16:23:03.963125"}}
{"question": "How can I obtain the current IP address ranges for AWS services, specifically for Route 53 DNS servers and health checkers?", "answer": "You can obtain the current IP address ranges by downloading the 'ip-ranges.json' file from AWS, then searching for the designated service field values: 'ROUTE53' for DNS servers and 'ROUTE53_HEALTHCHECKS' for health checkers.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-11T16:23:03.963445"}}
{"question": "What is the difference between the IP ranges for Route 53 DNS servers and health checkers in the 'ip-ranges.json' file?", "answer": "According to the provided context, there is no explicit difference mentioned between the IP ranges for Route 53 DNS servers and health checkers. The text only indicates that they have distinct service field values to search for in the 'ip-ranges.json' file.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-28", "source_tokens": 495, "generated_at": "2026-02-11T16:23:03.963835"}}
{"question": "What information must be provided to register a domain with Route 53?", "answer": "To register a domain with Route 53, you need to provide contact information for the registrant of the domain, including name, address, phone number, and email address. If the administrative and technical contacts are different, you need to provide that contact information as well.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-11T16:23:23.982211"}}
{"question": "Why does ICANN require contact information for domain registrations and how does Route 53 provide privacy protection?", "answer": "ICANN, the governing body for domain registration, requires that registrars provide contact information, including name, address, and phone number, for every domain name registration and make this information publicly available via a Whois database. For domain names that are registered as individuals, Route 53 provides privacy protection, which hides the personal phone number, email address, and physical address, free of charge, and instead, the Whois contains the registrarâ€™s name and mailing address, along with a registrar-generated forwarding email address that third parties may use if they wish to contact the registrant.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-11T16:23:23.982489"}}
{"question": "How does the registration process and timeframe vary between gTLDs and ccTLDs in Route 53?", "answer": "The registration process and timeframe for gTLDs and ccTLDs in Route 53 can vary. For gTLDs, registration can take from a few minutes to complete, while for ccTLDs, registration can take several hours. The initial registration period is typically one year, but some TLD registries have longer registration periods. Once a domain is successfully registered, it will show up in your account.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-30", "source_tokens": 501, "generated_at": "2026-02-11T16:23:23.982661"}}
{"question": "What information does Route 53 hide with privacy protection?", "answer": "Route 53 hides your phone number, email address, and physical address with privacy protection. Your first and last name will also be hidden if the TLD registry and registrar allow it.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-11T16:23:28.685604"}}
{"question": "How does privacy protection in Route 53 work?", "answer": "When you enable privacy protection in Route 53, a Whois query for the domain will display the registrarâ€™s mailing address and name (if allowed) instead of your personal information.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-11T16:23:28.685888"}}
{"question": "What's the difference between a reusable delegation set and a new delegation set in Route 53?", "answer": "A new delegation set is automatically assigned to each hosted zone, while a reusable delegation set can be applied to multiple hosted zones. This feature simplifies the migration to Route 53 for customers with large numbers of domain names.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-31", "source_tokens": 468, "generated_at": "2026-02-11T16:23:28.686065"}}
{"question": "What charges apply to a Route 53 hosted zone?", "answer": "You will be charged for the hosted zone that Route 53 creates for your domain name, as well as for the DNS queries against this hosted zone.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-11T16:23:33.128132"}}
{"question": "Why is it important to verify contact information during initial domain registration with Gandi?", "answer": "Gandi is required by ICANN to contact the registrant to verify their contact information at the time of initial registration. Failure to do so within the first 15 days may result in domain suspension.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-11T16:23:33.128460"}}
{"question": "How does the underlying registrar for a Route 53 domain differ between Amazon Registrar and Gandi?", "answer": "Most domains are registered through Amazon Registrar, but some may be registered through Gandi. Amazon dynamically chooses which registrar to use based on the domain.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-32", "source_tokens": 478, "generated_at": "2026-02-11T16:23:33.128941"}}
{"question": "What steps do I need to take before initiating a domain transfer to Route 53?", "answer": "You need to ensure your domain name is unlocked at your current registrar, disable privacy protection (if applicable), and obtain the valid Authorization Code or â€˜authcodeâ€™.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-11T16:23:39.090536"}}
{"question": "How does the process of transferring a domain name to Route 53 work?", "answer": "You first need to get a list of DNS record data for your domain name and use Route 53â€™s Management Console or simple web-services interface to create a hosted zone. Then, you contact your current registrar to update the name servers for your domain name to the ones associated with your hosted zone. Once the registrar propagates the new name server delegations, DNS queries from end users will start to get answered by Route 53 DNS servers.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-11T16:23:39.090861"}}
{"question": "What is the difference between transferring a domain name to and away from Route 53?", "answer": "To transfer a domain name to Route 53, you need to initiate a transfer request and follow the steps provided by Route 53 and your current registrar. To move a domain name away from Route 53, you need to initiate a transfer request with your new registrar.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-33", "source_tokens": 511, "generated_at": "2026-02-11T16:23:39.091238"}}
{"question": "What is the role of Route 53 Resolver in DNS queries?", "answer": "Route 53 Resolver is a recursive DNS service that finds the correct authoritative answer for any DNS query and returns it to the client.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-11T16:23:44.114021"}}
{"question": "How does Route 53 Resolver handle DNS queries?", "answer": "Route 53 Resolver may be configured to automatically forward queries directly to a specific recursive DNS server or recursively search for the answer. Once an answer is found, it may be cached for faster responses to subsequent queries.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-11T16:23:44.114391"}}
{"question": "What's the difference between conditional forwarding rules and DNS endpoints in Route 53 Resolver?", "answer": "Conditional forwarding rules allow Resolver to forward queries for specified domains to a specific IP address (typically an on-premises DNS resolver), while DNS endpoints include one or more elastic network interfaces that serve as forwarding targets for on-premises DNS servers.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-34", "source_tokens": 495, "generated_at": "2026-02-11T16:23:44.114765"}}
{"question": "What regions has Route 53 Resolver been launched in?", "answer": "You can visit the AWS Region Table to see which regions Route 53 Resolver has launched in.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-11T16:23:49.490278"}}
{"question": "How does integrating Route 53 Resolver with RAM simplify the process of sharing rules across accounts?", "answer": "Integrating Route 53 Resolver with RAM allows you to create rules in one primary account and then share them across multiple accounts. Once shared, the rules still need to be applied to VPCs in those accounts before they can take effect.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-11T16:23:49.490548"}}
{"question": "How does using Route 53 Resolver on Outposts racks compare to using it in the parent AWS Region?", "answer": "Using Route 53 Resolver on Outposts racks enables low-latency DNS resolution and improvement in performance for on-premises applications as DNS responses are served locally. However, it also requires connecting Route 53 Resolver endpoints with DNS servers in your on-premises data centers for resolution of queries between the Outposts racks and your other on-premises resources.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-35", "source_tokens": 470, "generated_at": "2026-02-11T16:23:49.490893"}}
{"question": "What types of lists can you create with Route 53 Resolver DNS Firewall for filtering domain names?", "answer": "You can create 'allowlists' and 'denylists' with Route 53 Resolver DNS Firewall for filtering domain names.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-11T16:23:55.236717"}}
{"question": "How can you configure DNS security using Route 53 Resolver DNS Firewall?", "answer": "You can configure DNS security using Route 53 Resolver DNS Firewall by either creating a 'walled-garden' approach to DNS security by denying all outbound DNS queries for domains that arenâ€™t on your lists of approved domains, or by allowing all outbound DNS lookups within your accounts by default and only requiring the ability to block DNS requests for known malicious domains.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-11T16:23:55.237047"}}
{"question": "What is the difference between AWS Managed Domain Lists and custom denylists in Route 53 Resolver DNS Firewall?", "answer": "AWS Managed Domain Lists help you protect against suspicious domains and Command-and-Control (C&C) bots, while custom denylists are lists of malicious domain names created by your organization.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-36", "source_tokens": 495, "generated_at": "2026-02-11T16:23:55.237287"}}
{"question": "What is the regional feature that secures Route 53 Resolver DNS network traffic at an organization and account level?", "answer": "Route 53 Resolver DNS Firewall", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-11T16:24:00.403862"}}
{"question": "Why is it recommended to use AWS Firewall Manager for maintaining policy and governance across multiple accounts with Route 53 Resolver DNS Firewall?", "answer": "AWS Firewall Manager helps maintain policy and governance across multiple accounts by managing firewall rules at the organization level.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-11T16:24:00.404231"}}
{"question": "How does Route 53 Resolver DNS Firewall and AWS Network Firewall differ in terms of offering protection against outbound DNS query threats?", "answer": "Route 53 Resolver DNS Firewall is designed to offer protection by blocking DNS requests to malicious or compromised domains when using Amazon Route 53 Resolver for DNS resolution. AWS Network Firewall offers similar capabilities by filtering/blocking outbound DNS queries to known malicious domains when using an external DNS service to resolve DNS requests.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-37", "source_tokens": 484, "generated_at": "2026-02-11T16:24:00.404431"}}
{"question": "What can you associate with a VPC in Route 53 Profiles?", "answer": "You can associate one Profile per VPC at a time.", "question_type": "factual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-11T16:24:04.600320"}}
{"question": "What features does Route 53 Profiles support for VPC configurations?", "answer": "Route 53 Profiles support private hosted zones and their settings, Route 53 Resolver rules (forwarding and system), DNS Firewall rule groups, reverse DNS lookup configuration for Resolver Rules, DNS Firewall failure mode configuration, and DNSSEC validation configuration.", "question_type": "conceptual", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-11T16:24:04.600603"}}
{"question": "How does sharing of a Route 53 Profile across AWS Regions differ from the association of a Profile with a VPC?", "answer": "You cannot share a Route 53 Profile across AWS Regions, but you can associate only one Profile per VPC at a time.", "question_type": "comparison", "metadata": {"service": "ROUTE53", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "route53-faq-38", "source_tokens": 126, "generated_at": "2026-02-11T16:24:04.600961"}}
{"question": "How many durability and data protection options does Amazon S3 offer?", "answer": "Amazon S3 offers three durability and data protection options: Amazon S3 Standard, Amazon S3 Standard-Infrequent Access (S3 Standard-IA), and Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). There's also Amazon S3 Glacier with three storage classes: Amazon S3 Glacier Instant Retrieval, Amazon S3 Glacier Flexible Retrieval, and Amazon S3 Glacier Deep Archive.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T16:24:11.434701"}}
{"question": "What are the main differences between Amazon S3 Standard and S3 Standard-IA?", "answer": "Amazon S3 Standard is the default storage class for new buckets, designed for frequently accessed data. In contrast, Amazon S3 Standard-IA is optimized for infrequent access. The main difference is the cost, with S3 Standard-IA being less expensive due to its lower access frequency. However, retrieval times for S3 Standard-IA objects are longer than those for S3 Standard objects.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T16:24:11.435000"}}
{"question": "What are the benefits of using Amazon S3 for data storage and retrieval?", "answer": "Amazon S3 is an object storage service that offers several benefits, including industry-leading durability, availability, performance, security, and virtually unlimited scalability at very low costs. It's designed to store and retrieve any amount of data from anywhere, and its simple, web services interface makes it easy to use.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-0", "source_tokens": 475, "generated_at": "2026-02-11T16:24:11.435507"}}
{"question": "What is the minimum and maximum size for individual Amazon S3 objects?", "answer": "The minimum size for an Amazon S3 object is 0 bytes, and the maximum size is 5 TB.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-11T16:24:15.605428"}}
{"question": "How does Amazon S3 allow developers to focus on innovation instead of storage?", "answer": "Amazon S3 provides a simple web service interface for storing and retrieving data, allowing developers to focus on innovation without worrying about the underlying storage infrastructure.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-11T16:24:15.605754"}}
{"question": "How does the multipart upload capability in Amazon S3 compare to storing single large objects?", "answer": "For objects larger than 100 MB, the multipart upload capability in Amazon S3 allows you to upload the object in smaller parts, which can be beneficial for handling larger files and improving upload performance.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-1", "source_tokens": 443, "generated_at": "2026-02-11T16:24:15.606093"}}
{"question": "What storage classes can be used in a general purpose bucket?", "answer": "A general purpose bucket can contain objects stored across all storage classes except S3 Express One Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-11T16:24:19.750425"}}
{"question": "What are the recommended use cases for general purpose buckets and S3 directory buckets?", "answer": "General purpose buckets are recommended for most use cases and access patterns, while S3 directory buckets are recommended for low-latency use cases.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-11T16:24:19.750710"}}
{"question": "How does a vector bucket differ from a general purpose bucket in terms of data processing and querying?", "answer": "In a vector bucket, you use dedicated vector APIs instead of the S3 object APIs to write vector data and query it based on semantic meaning and similarity. All writes to a vector bucket are strongly consistent.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-2", "source_tokens": 469, "generated_at": "2026-02-11T16:24:19.750871"}}
{"question": "What type of objects can be stored in a general purpose bucket?", "answer": "A general purpose bucket can contain objects stored across all storage classes except S3 Express One Zone.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-11T16:24:24.219528"}}
{"question": "How does S3 table buckets differ from general purpose buckets in terms of data processing and recommendations?", "answer": "S3 table buckets are purpose-built for storing tabular data and interacting with it using analytics capabilities. They are recommended for low-latency use cases and performing continual table maintenance to optimize query efficiency.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-11T16:24:24.219814"}}
{"question": "What are the key features and benefits of using an S3 vector bucket?", "answer": "An S3 vector bucket is purpose-built for storing and querying vectors using dedicated vector APIs. It automatically optimizes the vector data stored in it and allows controlling access to vector data using existing access control mechanisms in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-3", "source_tokens": 480, "generated_at": "2026-02-11T16:24:24.220270"}}
{"question": "What type of object store is Amazon S3?", "answer": "Amazon S3 is a simple key-based object store.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-11T16:24:27.414104"}}
{"question": "How can you organize data in Amazon S3 besides using object keys?", "answer": "You can use S3 Object Tagging to organize your data across all of your S3 buckets and/or prefixes.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-11T16:24:27.414365"}}
{"question": "How does the availability differ between S3 Standard and S3 Standard-IA storage classes?", "answer": "The S3 Standard storage class is designed for 99.99% availability, while the S3 Standard-IA storage class is designed for 99.9% availability.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-4", "source_tokens": 442, "generated_at": "2026-02-11T16:24:27.414792"}}
{"question": "What consistency level does Amazon S3 provide for read requests after a write?", "answer": "Amazon S3 provides strong read-after-write consistency for read requests after a write.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-11T16:24:31.895402"}}
{"question": "Why is strong read-after-write consistency important for applications using Amazon S3?", "answer": "Strong read-after-write consistency in Amazon S3 is important for applications that need to immediately read an object after a write, or when performing list operations. It helps ensure that the latest version of the object is read consistently across all reads.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-11T16:24:31.895667"}}
{"question": "How does strong read-after-write consistency compare to weak consistency in Amazon S3?", "answer": "Strong read-after-write consistency in Amazon S3 ensures that the latest version of the object is immediately readable after a write, while weak consistency may not reflect the latest version. Strong consistency also eliminates the need for additional infrastructure to provide consistency.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-5", "source_tokens": 216, "generated_at": "2026-02-11T16:24:31.896048"}}
{"question": "Which S3 storage classes store objects across multiple Availability Zones (AZs) in an AWS Region?", "answer": "S3 Standard, S3 Standard-IA, S3 Intelligent-Tiering, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive storage classes store objects across multiple Availability Zones (AZs) in an AWS Region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T16:24:37.939965"}}
{"question": "Why might you choose to use S3 storage classes for AWS Dedicated Local Zones instead of other S3 storage classes?", "answer": "You might choose to use S3 storage classes for AWS Dedicated Local Zones if you have sensitive data and applications that need to run on physically separate infrastructure that is dedicated to your exclusive use and placed within a specified regulatory jurisdiction to address security and compliance requirements.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T16:24:37.940241"}}
{"question": "How does the storage location differ between S3 storage classes for AWS Dedicated Local Zones and S3 Standard storage classes?", "answer": "S3 storage classes for AWS Dedicated Local Zones keep your objects within the Dedicated Local Zone, while S3 Standard storage classes store objects across multiple devices spanning a minimum of three Availability Zones (AZs) in an AWS Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-6", "source_tokens": 428, "generated_at": "2026-02-11T16:24:37.940615"}}
{"question": "In which geographic area does an AWS Region consist of at least three Availability Zones?", "answer": "Each AWS Region consists of a minimum of three, isolated, and physically separate Availability Zones within a geographic area.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:24:43.222381"}}
{"question": "Why do AWS Regions have multiple Availability Zones instead of a single data center?", "answer": "Multiple Availability Zones within an AWS Region offer customers advantages such as higher availability, fault tolerance, and scalability, as each AZ has independent power, cooling, and physical security and is connected via redundant, ultra-low-latency networks.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:24:43.222674"}}
{"question": "What is the difference in data replication between S3 Standard storage classes and S3 One Zone-IA?", "answer": "S3 Standard storage classes (Standard, Standard-Infrequent Access, Intelligent-Tiering, Glacier Instant Retrieval, Glacier Flexible Retrieval, and Glacier Deep Archive) replicate data across a minimum of three Availability Zones, while S3 One Zone-IA replicates data within a single Availability Zone. The data in S3 One Zone-IA is not resilient to the physical loss of an Availability Zone.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-7", "source_tokens": 428, "generated_at": "2026-02-11T16:24:43.222823"}}
{"question": "In which AWS Regions is Amazon S3 available?", "answer": "Amazon S3 is available in AWS Regions worldwide. Refer to the AWS regional services list for a list of AWS Regions in which S3 is available.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:24:48.402178"}}
{"question": "Why should I consider storing my data in a specific AWS Region for my application?", "answer": "You may want to store your data in a Region that is near your customers, data centers, or other AWS resources to reduce data access latencies. Alternatively, you may choose a remote Region for geographic redundancy and disaster recovery purposes. Legal and regulatory requirements and storage costs are other factors to consider.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:24:48.402622"}}
{"question": "What is the difference in data transfer costs when transferring data between Amazon EC2 and Amazon S3 within the same vs. different AWS Regions?", "answer": "There is no Data Transfer charge for data transferred between Amazon EC2 and Amazon S3 within the same Region. However, data transfer between Amazon EC2 and Amazon S3 across different Regions is charged at rates specified on the Amazon S3 pricing page.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:24:48.402998"}}
{"question": "What is required to begin using Amazon S3 without incurring any setup charges or commitments?", "answer": "There are no setup charges or commitments to begin using Amazon S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-11T16:24:52.516534"}}
{"question": "How long can new customers take advantage of the free plan with Amazon S3 before upgrading to a paid plan?", "answer": "New customers can use the free plan with Amazon S3 for 6 months after account creation.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-11T16:24:52.516895"}}
{"question": "How do Amazon S3 costs vary between different AWS regions? Give an example of a region where costs are lower.", "answer": "AWS charges less for Amazon S3 where its costs are less. For example, costs are lower in the US East (Northern Virginia) Region compared to the US West (Northern California) Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-9", "source_tokens": 415, "generated_at": "2026-02-11T16:24:52.517261"}}
{"question": "What is the total byte-hour usage for storing the objects in the given scenario?", "answer": "5,257,039,970,304 Byte-Hours", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-11T16:24:56.897966"}}
{"question": "How does Amazon S3 Versioning impact storage costs?", "answer": "Amazon S3 Versioning allows you to preserve all versions of an object, which results in increased storage costs as each version adds to the total byte-hour usage.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-11T16:24:56.898243"}}
{"question": "How does the storage cost for storing a 4GB object and a 5GB object with Amazon S3 Versioning compare?", "answer": "The cost for storing a 4GB object and a 5GB object with Amazon S3 Versioning is higher than the cost for storing a single version of each object due to the additional storage required for each version.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-10", "source_tokens": 466, "generated_at": "2026-02-11T16:24:56.898736"}}
{"question": "What pricing applies when another AWS Account accesses your Amazon S3 storage?", "answer": "Normal Amazon S3 pricing applies.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-11T16:25:00.626183"}}
{"question": "How can you configure your Amazon S3 bucket so that the requester pays for requests and downloads?", "answer": "You can configure your bucket as a Requester Pays bucket.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-11T16:25:00.626551"}}
{"question": "What is the difference between the standard pricing for Amazon S3 and the pricing when a Requester Pays bucket is used?", "answer": "Under standard pricing, you pay for the cost of accessing your Amazon S3 storage by another AWS Account. However, when you configure your bucket as a Requester Pays bucket, the requester pays for the cost of requests and downloads.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-11", "source_tokens": 169, "generated_at": "2026-02-11T16:25:00.626928"}}
{"question": "What is the first step if I have a dedicated AWS account team?", "answer": "Contact your AWS account team and inform them of your plans.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-11T16:25:04.011048"}}
{"question": "What should I do if I have a negotiated commitment with AWS?", "answer": "Discuss your options with your AWS account team.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-11T16:25:04.011414"}}
{"question": "How does contacting AWS Customer Support compare to contacting the dedicated AWS account team?", "answer": "Contacting the dedicated AWS account team allows for potential negotiations and customized solutions based on a pre-existing relationship, while contacting AWS Customer Support provides general support and may not offer the same level of customization.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-12", "source_tokens": 78, "generated_at": "2026-02-11T16:25:04.011922"}}
{"question": "What information does AWS require when I request free data transfer off their platform?", "answer": "AWS Customer Support will ask for your plans and evaluate if you qualify for free data transfer out based on the volume of data stored across AWS services at the time of their calculation.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:25:08.924000"}}
{"question": "How does AWS determine if a user is eligible for free data transfer out?", "answer": "AWS evaluates a user's eligibility for free data transfer out based on their active AWS account standing, volume of data stored, and compliance with the company's move-off requirements.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:25:08.924361"}}
{"question": "What's the difference between free data transfer out for moving off AWS and data transfer out from specialized services?", "answer": "Free data transfer out for moving off AWS is provided to users when they move all their data off the platform, while data transfer out from specialized services, like Amazon CloudFront, AWS Direct Connect, AWS Snowball, and AWS Global Accelerator, are not included in the free transfer program.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:25:08.924839"}}
{"question": "What are the steps to create a vector index in Amazon S3?", "answer": "To create a vector index in Amazon S3, you first create a vector bucket, then create a vector index within the bucket, specifying the distance metric and dimensions. You can also add metadata fields during index creation, some of which can be made non-filterable.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-11T16:25:14.206187"}}
{"question": "How does the process of creating a vector index in Amazon S3 work?", "answer": "When creating a vector index in Amazon S3, you first create a vector bucket and then create an index within it, specifying the distance metric and dimensions. An index can have optional metadata fields, some of which can be made non-filterable during queries.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-11T16:25:14.206588"}}
{"question": "What's the difference between creating a vector index and a regular S3 index in AWS?", "answer": "A regular S3 index is used for traditional data indexing, while a vector index in Amazon S3 is specifically used for vector data indexing and similarity queries. When creating a vector index, you specify the distance metric and dimensions, and can optionally add metadata fields.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-14", "source_tokens": 427, "generated_at": "2026-02-11T16:25:14.207056"}}
{"question": "What API is used to add vectors to a vector index in AWS?", "answer": "The PutVectors API is used to add vectors to a vector index in AWS.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T16:25:19.738531"}}
{"question": "How can metadata be used in a similarity query in AWS?", "answer": "Metadata can be used as filters in a similarity query in AWS to search for vectors that match the filter. By default, all metadata fields can be used as filters unless specified as non-filterable metadata at the time of vector index creation.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T16:25:19.738922"}}
{"question": "What are the main differences between S3 Vectors and other vector storage solutions in terms of durability, availability, and query latency?", "answer": "S3 Vectors is designed to deliver highly durable and available vector storage, with data written to S3 that is designed for 11 9s of data durability and 99.99% availability with an availability SLA of 99.9%. S3 Vectors delivers sub-second query latency times and uses the elastic throughput of Amazon S3 to handle searches across millions of vectors, making it ideal for infrequent query workloads.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-15", "source_tokens": 486, "generated_at": "2026-02-11T16:25:19.739404"}}
{"question": "What measurement does S3 Vectors provide for query result quality?", "answer": "Average recall", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-11T16:25:23.119352"}}
{"question": "How does the ListVectors API help users in the context of S3 Vectors?", "answer": "The ListVectors API allows users to view a list of vectors in a vector index, export vector data, and check for truncation. It is also strongly consistent.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-11T16:25:23.119716"}}
{"question": "How does using an existing S3 vector index in Bedrock compare to letting Bedrock create and manage one?", "answer": "Using an existing S3 vector index in Bedrock saves on vector storage costs for RAG use cases, while letting Bedrock create and manage one allows for easier setup and management.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-16", "source_tokens": 403, "generated_at": "2026-02-11T16:25:23.120216"}}
{"question": "How can S3 customers export vectors from an S3 vector index to OpenSearch Serverless?", "answer": "S3 customers can export all vectors from an S3 vector index to OpenSearch Serverless as a new serverless collection using either the S3 or OpenSearch console.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T16:25:28.350110"}}
{"question": "Why would you use OpenSearch with S3 Vectors instead of building natively on S3?", "answer": "You can benefit from being able to use OpenSearch Serverless selectively for workloads with real-time query needs. This allows you to keep the cost benefits of S3 Vectors and make no changes to your applications.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T16:25:28.350488"}}
{"question": "What are the benefits of using IPv6 with Amazon S3 instead of IPv4?", "answer": "Using IPv6 support for Amazon S3 allows applications to connect to Amazon S3 without the need for any IPv6 to IPv4 translation software or systems. It also enables the use of existing source address filtering features in IAM policies and bucket policies with IPv6 addresses, expanding options to secure applications interacting with Amazon S3.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-17", "source_tokens": 380, "generated_at": "2026-02-11T16:25:28.350712"}}
{"question": "What endpoints support IPv4 and IPv6 in Amazon S3?", "answer": "Amazon S3â€™s â€˜dual-stackâ€™ endpoint supports access over both IPv4 and IPv6.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-11T16:25:32.890575"}}
{"question": "How do Amazon S3 Event Notifications work conceptually?", "answer": "Amazon S3 Event Notifications allow users to receive notifications when certain events occur in their S3 bucket, and to perform actions in response, such as transcoding media files or processing data files.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-11T16:25:32.890933"}}
{"question": "What are the differences between using IPv4 and IPv6 in terms of Amazon S3 event notifications and performance?", "answer": "There is no difference in performance when using IPv4 or IPv6 with Amazon S3. Both support event notifications and the same features, such as notifications for PUT, POST, COPY, and DELETE events.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-18", "source_tokens": 484, "generated_at": "2026-02-11T16:25:32.891420"}}
{"question": "What are the charges for using Amazon S3 for event notifications?", "answer": "There are no additional charges for using Amazon S3 for event notifications.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-11T16:25:37.949105"}}
{"question": "How does Amazon S3 Transfer Acceleration improve data transfer?", "answer": "Amazon S3 Transfer Acceleration improves data transfer by leveraging Amazon CloudFrontâ€™s globally distributed AWS Edge locations and routing data to your Amazon S3 bucket over an optimized network path.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-11T16:25:37.949466"}}
{"question": "What's the difference between using .s3-accelerate.amazonaws.com and .s3-accelerate.dualstack.amazonaws.com for data transfer with S3 Transfer Acceleration?", "answer": "Both types of endpoints, .s3-accelerate.amazonaws.com and .s3-accelerate.dualstack.amazonaws.com, are used for faster data transfer with S3 Transfer Acceleration. The difference lies in the dual-stack endpoint providing additional support for IPv6.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-19", "source_tokens": 366, "generated_at": "2026-02-11T16:25:37.949903"}}
{"question": "What factors influence the amount of acceleration provided by S3 Transfer Acceleration?", "answer": "The amount of acceleration primarily depends on the available bandwidth, the distance between the source and destination, and packet loss rates on the network path.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-11T16:25:43.016398"}}
{"question": "How does S3 Transfer Acceleration improve data transfer performance?", "answer": "S3 Transfer Acceleration helps minimize the effect of distance on throughput and ensures consistently fast data transfer to Amazon S3 by optimizing transfer speeds from across the world into S3 buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-11T16:25:43.016762"}}
{"question": "How does the performance of S3 Transfer Acceleration compare when uploading to a bucket in the US East (N. Virginia) Region versus a bucket in the Asia Pacific (Sydney) Region?", "answer": "One customer observed a 50% reduction in their average time to ingest 300 MB files from a global user base to a bucket in the Asia Pacific (Sydney) Region, while another customer saw performance improvements in excess of 500% for users in South East Asia and Australia uploading 250 MB files to a bucket in the US East (N. Virginia) Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-20", "source_tokens": 512, "generated_at": "2026-02-11T16:25:43.017189"}}
{"question": "What feature of S3 Transfer Acceleration supports multipart uploads?", "answer": "S3 Transfer Acceleration supports all bucket level features including multipart uploads.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-11T16:25:47.269470"}}
{"question": "Why would you choose S3 Transfer Acceleration over AWS Direct Connect for submitting data to S3?", "answer": "S3 Transfer Acceleration is best for submitting data from distributed client locations over the public internet, or where variable network conditions make throughput poor.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-11T16:25:47.269857"}}
{"question": "How does S3 Transfer Acceleration compare to AWS Direct Connect for data transfer?", "answer": "AWS Direct Connect is a good choice for customers who have a private networking requirement or who have access to AWS Direct Connect exchanges. S3 Transfer Acceleration is best for submitting data from distributed client locations over the public internet.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-21", "source_tokens": 383, "generated_at": "2026-02-11T16:25:47.270250"}}
{"question": "What security feature does Amazon S3 enable by default for newly created buckets?", "answer": "Amazon S3 Block Public Access is enabled by default for newly created buckets.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-11T16:25:52.905892"}}
{"question": "How can customers control access to Amazon S3 resources?", "answer": "Customers can use various mechanisms for controlling access to Amazon S3 resources, such as AWS Identity and Access Management (IAM) policies, bucket policies, access point policies, access control lists (ACLs), Query String Authentication, Amazon Virtual Private Cloud (Amazon VPC) endpoint policies, service control policies (SCPs) in AWS Organizations, and Amazon S3 Block Public Access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-11T16:25:52.906220"}}
{"question": "What is the difference between enabling Amazon S3 Block Public Access and using AWS CloudTrail Data Events for access logging?", "answer": "Amazon S3 Block Public Access is a security feature that prevents public access to your Amazon S3 bucket, while AWS CloudTrail Data Events allow you to capture log records for all requests made against your bucket. With Amazon S3 Block Public Access, you control who has access to your bucket, while with AWS CloudTrail Data Events, you can capture log records for audit purposes with details about the request.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-22", "source_tokens": 464, "generated_at": "2026-02-11T16:25:52.906413"}}
{"question": "What encryption method does Amazon S3 apply by default to new data uploads?", "answer": "Amazon S3 applies S3-managed server-side encryption (SSE-S3) to all new data uploads.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-11T16:25:57.478120"}}
{"question": "Why might you choose to use SSE-C instead of SSE-S3 for encryption in Amazon S3?", "answer": "You might choose to use SSE-C if you want to maintain your own encryption keys and don't want to implement or leverage a client-side encryption library.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-11T16:25:57.478460"}}
{"question": "How does the use of SSE-C for encryption in Amazon S3 compare to the use of SSE-S3?", "answer": "With SSE-C, you don't need to implement or use a client-side library to perform the encryption and decryption of objects in Amazon S3, but you do need to manage the keys that you send to Amazon S3 to encrypt and decrypt objects. With SSE-S3, Amazon handles key management and key protection using multiple layers of security.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-23", "source_tokens": 297, "generated_at": "2026-02-11T16:25:57.478680"}}
{"question": "What type of documentation does the text discuss?", "answer": "Protecting data using encryption documentation.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-11T16:26:07.950598"}}
{"question": "How does encryption help protect data?", "answer": "Encryption is a method of converting data into a coded language that can only be deciphered with a specific key. By using encryption, data is protected from unauthorized access even if it is intercepted.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-11T16:26:07.950889"}}
{"question": "How does encryption compare to data masking as a data protection method?", "answer": "Encryption and data masking are both methods of data protection. Encryption converts data into a coded language using a key, while data masking replaces sensitive data with non-sensitive substitutes. The main difference between the two is that encryption is reversible - the data can be decrypted back to its original form using the correct key, while data masking is irreversible - the masked data cannot be recovered.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-25", "source_tokens": 9, "generated_at": "2026-02-11T16:26:07.951043"}}
{"question": "Which AWS Regions can customers use to store their data in Europe according to the text?", "answer": "Customers can use the Europe (Frankfurt), Europe (Ireland), Europe (Paris), Europe (Stockholm), Europe (Milan), Europe (Spain), Europe (London), or Europe (Zurich) Region to store their data in Europe.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-11T16:26:12.482830"}}
{"question": "Why is it important for users to ensure compliance with European privacy laws when using AWS?", "answer": "It is the user's responsibility to ensure compliance with European privacy laws when using AWS, as stated in the text.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-11T16:26:12.483080"}}
{"question": "What happens to object metadata when using S3 storage classes for AWS Dedicated Local Zones?", "answer": "By default, object metadata stays within the single Dedicated Local Zone, but bucket management and telemetry data are stored back in the parent AWS Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-26", "source_tokens": 464, "generated_at": "2026-02-11T16:26:12.483271"}}
{"question": "What condition can be used in S3 bucket policies to restrict access from specific VPC endpoints?", "answer": "The condition 'aws:sourceVpce' can be used in S3 bucket policies to restrict access from specific VPC endpoints.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-11T16:26:18.168839"}}
{"question": "How does AWS PrivateLink for S3 allow access to S3 from on-premises without using public IPs or changing firewall rules?", "answer": "AWS PrivateLink for S3 provides private connectivity between Amazon S3 and on-premises by allowing you to create interface VPC endpoints in your VPC to connect your on-premises applications directly to S3 over AWS Direct Connect or AWS VPN.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-11T16:26:18.169165"}}
{"question": "What's the difference between using a gateway VPC endpoint and an interface VPC endpoint to access S3 from a VPC in the same AWS Region?", "answer": "A gateway VPC endpoint is recommended for resources accessing S3 from a VPC in the same AWS Region as S3 and is not billed, while an interface VPC endpoint is recommended for accessing S3 from on-premises or from a VPC in another AWS Region and requires provisioning.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-27", "source_tokens": 506, "generated_at": "2026-02-11T16:26:18.169630"}}
{"question": "What does Amazon Macie do to help prevent data loss in S3?", "answer": "Amazon Macie is an AI-powered security service that automatically discovers, classifies, and protects sensitive data in Amazon S3. It uses machine learning to recognize PII or intellectual property, assigns a business value, and monitors data access activity for anomalies.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-11T16:26:22.652090"}}
{"question": "How does Amazon Macie help in detecting and preventing unauthorized data access?", "answer": "Amazon Macie continually monitors data access activity for anomalies and delivers alerts when it detects a risk of unauthorized access or inadvertent data leaks.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-11T16:26:22.652363"}}
{"question": "What options does Amazon Macie provide for incident response upon alert generation?", "answer": "Upon alert generation, you can use Amazon Macie for incident response by using Amazon CloudWatch Events to take swift action and protect your data.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-28", "source_tokens": 247, "generated_at": "2026-02-11T16:26:22.652748"}}
{"question": "What does Access Analyzer for S3 do in terms of permissions management for S3 buckets?", "answer": "Access Analyzer for S3 is a feature that helps simplify permissions management for S3 buckets and access points by verifying and refining policies, monitoring existing access policies, and alerting the user when there is unrequired access. It evaluates bucket access policies and assists in discovering and making changes to buckets with inappropriate access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-11T16:26:29.917445"}}
{"question": "What are the benefits of using Access Analyzer for S3 for managing public access to S3 buckets?", "answer": "Access Analyzer for S3 proactively alerts users when they have a bucket that is configured to allow public access or is shared with other AWS accounts. It provides findings about the source and level of public or shared access and enables the user to block public access with a single click in the S3 console. The console also allows the user to drill down into bucket-level permissions settings to configure granular levels of access.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-11T16:26:29.917814"}}
{"question": "How does Access Analyzer for S3 compare to S3 Access Grants for managing S3 access?", "answer": "Access Analyzer for S3 is a feature that monitors and verifies S3 access policies to ensure the required access is provided. On the other hand, S3 Access Grants map identities to datasets in S3 and automatically grant S3 access to end-users based on their corporate identity. Access Analyzer for S3 focuses on managing and refining existing access policies, while S3 Access Grants focus on managing data permissions at scale by automating access granting.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-29", "source_tokens": 483, "generated_at": "2026-02-11T16:26:29.918282"}}
{"question": "What is the first step to use S3 Access Grants with corporate directory identities?", "answer": "Configure an S3 Access Grants instance and enable AWS Identity Center, then connect S3 Access Grants to your Identity Center instance.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-11T16:26:34.149374"}}
{"question": "How does S3 Access Grants handle identity management for enterprise users and groups?", "answer": "S3 Access Grants supports enterprise user or group identities from AWS Identity Center, and also supports permission rules for AWS IAM principals including IAM users and roles.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-11T16:26:34.149742"}}
{"question": "What are the differences between the three access levels offered by S3 Access Grants?", "answer": "READ allows you to view and retrieve objects from S3, WRITE allows you to write to and delete from S3, and READWRITE allows you to do both.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-30", "source_tokens": 512, "generated_at": "2026-02-11T16:26:34.150217"}}
{"question": "How many locations can be created per S3 Access Grants instance?", "answer": "Up to 1,000 locations can be created per S3 Access Grants instance.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-11T16:26:39.717392"}}
{"question": "What is the role of AWS IAM Identity Center in using S3 Access Grants for directory identities?", "answer": "AWS IAM Identity Center is required to be set up first if you intend to use S3 Access Grants for directory identities. It helps you create or connect your workforce identities, and S3 Access Grants relies on Identity Center to retrieve user attributes such as group membership to evaluate requests and make authorization decisions.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-11T16:26:39.717756"}}
{"question": "How does the process of using S3 Access Grants differ from using IAM credentials for S3 requests?", "answer": "Instead of initializing the S3 client with IAM credentials associated with your application, you will need to obtain S3 Access Grants credentials first before initializing the S3 client. These S3 Access Grants credentials will be specific to the authenticated user in your application, and once the S3 client is initialized with these credentials, it can make requests for S3 data as usual.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-31", "source_tokens": 472, "generated_at": "2026-02-11T16:26:39.718217"}}
{"question": "What is the charging mechanism for S3 Access Grants?", "answer": "S3 Access Grants is charged based on the number of requests to S3 Access Grants.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-11T16:26:43.600779"}}
{"question": "How does S3 Access Grants integrate with IAM for managing encrypted objects?", "answer": "S3 Access Grants utilizes an IAM role granted to it by the bucket owner during the location registration process to access KMS-encrypted objects in the buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-11T16:26:43.601147"}}
{"question": "What are the main differences between AWS Lake Formation and S3 Access Grants?", "answer": "AWS Lake Formation is used for managing access for tabular data and enforcing row- and column-level access, while S3 Access Grants is used for managing access for direct S3 permissions such as unstructured data including videos, images, logs, etc.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-32", "source_tokens": 462, "generated_at": "2026-02-11T16:26:43.601671"}}
{"question": "What is the role of Amazon S3 Access Points in managing data access?", "answer": "Amazon S3 Access Points are endpoints that simplify managing data access for applications or AWS services that work with Amazon S3. They provide customized paths into S3 buckets with unique hostnames and access policies, allowing for easier management and control of data access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:26:49.648360"}}
{"question": "How does using S3 Access Points with S3 buckets simplify data access management?", "answer": "Using S3 Access Points with S3 buckets eliminates the need to manage a single, complex bucket policy with hundreds of permission rules. Instead, you can create hundreds of access points per bucket, each with a unique access policy. This simplifies managing data access and allows you to focus on building the right access policy for each application.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:26:49.648705"}}
{"question": "What are the benefits of using S3 Access Points with Amazon FSx for OpenZFS?", "answer": "Using S3 Access Points with Amazon FSx for OpenZFS allows you to access your FSx data using the S3 API, making it accessible for use with a broad range of AI, machine learning, and analytics services and applications. Your file data in FSx for OpenZFS remains on the file system, but can be accessed as if it were in S3.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:26:49.649140"}}
{"question": "What can you do with an S3 Access Point attached to an FSx for OpenZFS file system?", "answer": "You can use an S3 Access Point attached to an FSx for OpenZFS file system to access your file data in Amazon FSx for OpenZFS using S3 APIs. This allows you to work with your data using various services and applications that are designed for S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-11T16:26:55.134313"}}
{"question": "How does attaching an S3 Access Point to an FSx for OpenZFS file system differ from attaching it to an S3 bucket?", "answer": "The main difference is that with FSx for OpenZFS, the data remains in the file system, while with S3 buckets, the data is moved to S3. However, access to the data is controlled by access policies with both methods.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-11T16:26:55.134591"}}
{"question": "Which services can you use to access FSx for OpenZFS data using an S3 Access Point?", "answer": "You can use various services and applications that work with S3, such as generative AI, machine learning, and analytics services, to access your FSx for OpenZFS data using an S3 Access Point.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-34", "source_tokens": 161, "generated_at": "2026-02-11T16:26:55.134750"}}
{"question": "What is the maximum number of S3 Access Points that can be created in a region per account by default?", "answer": "10,000", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-11T16:26:59.588774"}}
{"question": "What are the benefits of using Access Points in S3 for managing access to shared buckets?", "answer": "Access Points allow you to grant access to specific users or applications for a bucket without sharing the entire bucket. You can also control access using network origins and Block Public Access. Aliases for access points can be used instead of bucket names for data access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-11T16:26:59.589139"}}
{"question": "How does creating an access point for a bucket with a network origin control differ from creating one without?", "answer": "Creating an access point for a bucket with a network origin control allows access only from the specified virtual private cloud. Creating an access point without a network origin control allows access based on the access point policy.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-35", "source_tokens": 463, "generated_at": "2026-02-11T16:26:59.589689"}}
{"question": "What is the role of an S3 access point policy in managing access to S3 data?", "answer": "An S3 access point policy is used to grant or restrict access to S3 data requested through the access point. Access point policies are written using the access point ARN and can be managed similarly to bucket policies.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:27:05.326140"}}
{"question": "Why would you use access points instead of bucket policies to manage S3 access?", "answer": "Access points provide an easier and more auditable way to lock down all or a subset of data in a shared dataset to VPC-only traffic for all applications in an organization. They allow you to enforce a 'No internet data access' policy by setting the 'network origin control' API parameter value to 'vpc' using an AWS SCP.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:27:05.326379"}}
{"question": "How does using access points for S3 access compare to using bucket policies?", "answer": "Access points and bucket policies serve similar purposes in managing S3 access, but access points provide an easier and more auditable way to limit access to VPC-only traffic for all applications in an organization. Bucket policies can also be used to limit bucket access to specified VPCs, but access points offer finer-grained control and additional security features.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:27:05.326728"}}
{"question": "What happens when you remove an access point from an S3 bucket?", "answer": "The removal of an access point does not disrupt access to the associated bucket through other access points or the bucket hostname.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-11T16:27:09.870075"}}
{"question": "How does Amazon S3 ensure data durability?", "answer": "Amazon S3 designs for durability by having end-to-end integrity checking on every object upload, and storing data redundantly across a minimum of 3 Availability Zones. S3 also continuously monitors data durability and the redundancy of your data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-11T16:27:09.870434"}}
{"question": "How does the durability of Amazon S3 compare to other cloud storage services?", "answer": "Amazon S3 provides 99.999999999% (11 nines) data durability and stores data redundantly across a minimum of 3 Availability Zones by default.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-37", "source_tokens": 418, "generated_at": "2026-02-11T16:27:09.870863"}}
{"question": "What type of events can result in data loss for One Zone storage class in AWS S3?", "answer": "Data loss for One Zone storage class in AWS S3 can occur due to events like fire and water damage.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-11T16:27:14.225949"}}
{"question": "Why doesn't Amazon S3's durability system protect against accidental or malicious deletes?", "answer": "Amazon S3 does not protect against accidental or malicious deletes because it relies on customers to decide what data they want to keep and how to protect against deletes.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-11T16:27:14.226308"}}
{"question": "How does Amazon S3 Object Versioning, Replication, and Object Lock compare to S3's automatic durability in protecting data?", "answer": "Amazon S3 Object Versioning, Replication, and Object Lock are optional features that add additional data protection beyond the durability that S3 automatically provides.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-38", "source_tokens": 355, "generated_at": "2026-02-11T16:27:14.226787"}}
{"question": "Which algorithms does Amazon S3 support for data integrity checking?", "answer": "Amazon S3 supports five checksum algorithms: SHA-1, SHA-256, CRC32, CRC32C, and CRC64NVME.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-11T16:27:19.852171"}}
{"question": "How does Amazon S3 ensure data integrity during object storage and retrieval?", "answer": "Amazon S3 uses a combination of Content-MD5 checksums, secure hash algorithms (SHAs), and cyclic redundancy checks (CRCs) to ensure data integrity. It calculates and verifies checksums on data at rest and repairs any disparities using redundant data. The latest AWS SDKs automatically calculate efficient CRC-based checksums for all uploads.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-11T16:27:19.852476"}}
{"question": "How does versioning in Amazon S3 compare to data integrity checking?", "answer": "Versioning in Amazon S3 allows you to preserve, retrieve, and restore every version of every object stored in a bucket. It keeps existing objects when you perform PUT, POST, COPY, or DELETE operations. Data integrity checking, on the other hand, ensures the integrity of the data during storage and retrieval using checksums.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-39", "source_tokens": 463, "generated_at": "2026-02-11T16:27:19.852891"}}
{"question": "What happens when a user deletes an object with versioning enabled in Amazon S3?", "answer": "When a user performs a DELETE operation on an object with versioning enabled in Amazon S3, subsequent simple requests will no longer retrieve the object. However, all versions of that object will continue to be preserved in the bucket and can be retrieved or restored. Only the owner of the bucket can permanently delete a version.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-11T16:27:26.221647"}}
{"question": "Why is versioning useful in Amazon S3 beyond data recovery?", "answer": "Versioning in Amazon S3 is not only useful for data recovery from accidental overwrites or deletions, but also for data retention and archiving. It allows you to set lifecycle rules to manage the lifetime and cost of storing multiple versions of your objects and implement a rollback window for your S3 objects.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-11T16:27:26.222085"}}
{"question": "How does Amazon S3 Versioning and Lifecycle rules help in cost optimization?", "answer": "Amazon S3 Versioning and Lifecycle rules help in cost optimization by allowing you to retain additional versions of your objects when needed and saving costs by transitioning or removing older versions after a period of time. For example, you can set a rule to archive all previous versions to the lower-cost S3 Glacier Flexible Retrieval storage class and delete them after a certain number of days or when there are at least two newer versions of the object.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-40", "source_tokens": 400, "generated_at": "2026-02-11T16:27:26.222344"}}
{"question": "What is required to permanently delete a version of an object when Versioning and MFA Delete are enabled on an Amazon S3 bucket?", "answer": "Two forms of authentication are required: your AWS account credentials and a valid six-digit code and serial number from an authentication device in your physical possession.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-11T16:27:31.263470"}}
{"question": "How does enabling Versioning with MFA Delete add to the security of an Amazon S3 bucket?", "answer": "It requires two forms of authentication - your AWS account credentials and a valid six-digit code from an authentication device - to permanently delete a version of an object, providing an additional layer of security.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-11T16:27:31.263831"}}
{"question": "What's the difference in authentication requirements between an Amazon S3 bucket with Versioning and one with Versioning and MFA Delete enabled?", "answer": "With Versioning, only AWS account credentials are required to make requests to the bucket. With Versioning and MFA Delete, two forms of authentication are required to permanently delete a version of an object - your AWS account credentials and a valid six-digit code and serial number from an authentication device.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-41", "source_tokens": 135, "generated_at": "2026-02-11T16:27:31.264289"}}
{"question": "What is the total byte-hour usage for the given scenario in the text passage?", "answer": "5,257,039,970,304 Byte-Hours", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-11T16:27:36.549045"}}
{"question": "How does versioning in Amazon S3 impact the storage costs in the given scenario?", "answer": "With versioning enabled, every version of an object is preserved in the bucket and incurs storage costs. In the given scenario, the 4 GB object from Day 1 and the 5 GB object from Day 16 are both preserved, resulting in a higher total byte-hour usage and thus higher costs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-11T16:27:36.549346"}}
{"question": "How does the storage cost of a 4 GB object compare to a 5 GB object in the given scenario when using Amazon S3 Versioning?", "answer": "The cost for storing a 4 GB object is different from the cost for storing a 5 GB object in the given scenario when using Amazon S3 Versioning. The cost is calculated based on the byte-hour usage for each object, which is the product of the object size, the number of days, and the hours in a day.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-42", "source_tokens": 411, "generated_at": "2026-02-11T16:27:36.549741"}}
{"question": "What is the purpose of Amazon S3 Object Lock feature?", "answer": "Amazon S3 Object Lock is a feature that helps prevent an object version from being deleted or overwritten for a fixed amount of time or indefinitely to enforce retention policies and add an additional layer of data protection.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-11T16:27:41.063094"}}
{"question": "How does Amazon S3 Object Lock help meet regulatory requirements?", "answer": "Amazon S3 Object Lock helps meet regulatory requirements by preventing object version deletions prior to pre-defined Retain Until Dates or indefinitely (Legal Hold Dates) and maintaining the protection regardless of the storage class.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-11T16:27:41.063484"}}
{"question": "What's the difference between S3 Object Lock and traditional WORM systems?", "answer": "S3 Object Lock and traditional WORM systems both serve the purpose of preventing data deletion, but S3 Object Lock also allows for object version protection and lifecycle transitions between storage classes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-43", "source_tokens": 252, "generated_at": "2026-02-11T16:27:41.063980"}}
{"question": "What is the effect of assigning a Retain Until Date to an S3 object version?", "answer": "Assigning a Retain Until Date to an S3 object version prevents the modification and deletion of the object version until the Retain Until Date has passed.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-11T16:27:45.520813"}}
{"question": "How can I ensure that an S3 object version remains immutable indefinitely?", "answer": "By applying a Legal Hold to an S3 object version, you can ensure that it remains immutable and cannot be modified or deleted indefinitely until the Legal Hold is removed.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-11T16:27:45.521224"}}
{"question": "What's the difference between Governance Mode and Compliance Mode in S3 Object Lock?", "answer": "In Governance Mode, specific IAM users can remove WORM protection from an object version. In Compliance Mode, WORM protection cannot be removed by any user, including the root account.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-44", "source_tokens": 411, "generated_at": "2026-02-11T16:27:45.521675"}}
{"question": "Which S3 storage classes are purpose-built for different access patterns and what are their ideal use cases?", "answer": "Amazon S3 offers various storage classes, each designed for specific access patterns and use cases. These include storage classes for data with demanding performance needs, data residency requirements, unknown or changing access patterns, and archival storage.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-11T16:27:57.790508"}}
{"question": "What factors should you consider when deciding which S3 storage class to use for your workload?", "answer": "To optimize for the lowest total cost over the lifetime of your data in Amazon S3, consider the access patterns and retention time of your data.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-11T16:27:57.790810"}}
{"question": "How does the cost of the S3 Standard-Infrequent Access storage class compare to the S3 Intelligent-Tiering storage class?", "answer": "The context does not provide enough information to make a comparison between the cost of S3 Standard-Infrequent Access and S3 Intelligent-Tiering storage classes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-46", "source_tokens": 144, "generated_at": "2026-02-11T16:27:57.791182"}}
{"question": "Which S3 storage class is best for frequently accessed data?", "answer": "S3 Standard storage class", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-11T16:28:01.518434"}}
{"question": "Why would you use S3 Intelligent-Tiering for your workload?", "answer": "S3 Intelligent-Tiering automatically saves on storage costs for workloads with changing, unpredictable, or unknown access patterns", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-11T16:28:01.518786"}}
{"question": "How does the retrieval time and cost differ between S3 Glacier Instant Retrieval and S3 Glacier Flexible Retrieval?", "answer": "S3 Glacier Instant Retrieval provides milliseconds retrieval at a lower cost than S3 Glacier Flexible Retrieval, which retrieves data in minutes or offers free bulk retrievals in 5â€”12 hours", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-47", "source_tokens": 434, "generated_at": "2026-02-11T16:28:01.519289"}}
{"question": "What type of S3 storage class can be used to reduce costs for data with lower resiliency requirement?", "answer": "S3 One Zone-Infrequent Access", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-11T16:28:05.586730"}}
{"question": "Why would you consider using S3 storage classes for AWS Dedicated Local Zones or S3 on Outposts?", "answer": "For data residency or isolation requirements that can't be met by existing AWS Regions", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-11T16:28:05.587023"}}
{"question": "How does the cost and resiliency compare between S3 One Zone-Infrequent Access and S3 storage classes for AWS Dedicated Local Zones or S3 on Outposts?", "answer": "S3 One Zone-Infrequent Access has lower costs but lower resiliency than S3 storage classes for AWS Dedicated Local Zones or S3 on Outposts", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-48", "source_tokens": 92, "generated_at": "2026-02-11T16:28:05.587199"}}
{"question": "What access tiers does S3 Intelligent-Tiering offer for data storage?", "answer": "S3 Intelligent-Tiering offers Frequent, Infrequent, and Archive Instant Access tiers for data storage.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-11T16:28:09.495762"}}
{"question": "How does S3 Intelligent-Tiering reduce storage costs?", "answer": "S3 Intelligent-Tiering reduces costs by automatically moving data to the most cost-effective access tier based on access frequency, without performance impact or retrieval fees.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-11T16:28:09.496148"}}
{"question": "How does S3 Intelligent-Tiering compare to traditional storage solutions for data access?", "answer": "S3 Intelligent-Tiering delivers milliseconds latency and high throughput performance for frequently, infrequently, and rarely accessed data, while reducing storage costs through automatic tiering and eliminating retrieval charges.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-49", "source_tokens": 219, "generated_at": "2026-02-11T16:28:09.496663"}}
{"question": "What access tier does S3 Intelligent-Tiering move objects to after 30 days of no access?", "answer": "The Infrequent Access tier", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-11T16:28:13.425492"}}
{"question": "How does S3 Intelligent-Tiering determine which objects to move to a lower access tier?", "answer": "S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for a specific period to a lower access tier to save on storage costs", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-11T16:28:13.425867"}}
{"question": "Which access tier does S3 Intelligent-Tiering move objects to after 180 days of no access when the optional Deep Archive Access tier is enabled?", "answer": "The Deep Archive Access tier", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-50", "source_tokens": 413, "generated_at": "2026-02-11T16:28:13.426106"}}
{"question": "What is the minimum object size for S3 Intelligent-Tiering that is eligible for auto-tiering?", "answer": "Objects must be larger than 128KB to be eligible for auto-tiering in S3 Intelligent-Tiering.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-11T16:28:19.300299"}}
{"question": "How does S3 Intelligent-Tiering impact the performance of smaller objects in S3?", "answer": "S3 Intelligent-Tiering stores smaller objects (less than 128KB) and charges them at the Frequent Access tier rates without the monitoring and automation charge. However, these objects do not benefit from the auto-tiering feature and always have the same low latency and high throughput performance as S3 Standard.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-11T16:28:19.300616"}}
{"question": "What are the differences in storage costs and performance between S3 Intelligent-Tiering for larger objects and S3 Standard for smaller objects?", "answer": "S3 Intelligent-Tiering offers the same low latency and high throughput performance as S3 Standard for larger objects and automatically tiers them to lower costs when they are infrequently accessed. For smaller objects (less than 128KB), S3 Intelligent-Tiering stores them but charges them at the Frequent Access tier rates without the monitoring and automation charge. These smaller objects do not benefit from the auto-tiering feature.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-51", "source_tokens": 212, "generated_at": "2026-02-11T16:28:19.300955"}}
{"question": "What is the recommended storage class for data with unknown or changing access patterns according to the text passage?", "answer": "S3 Intelligent-Tiering", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-11T16:28:24.152779"}}
{"question": "How does S3 Intelligent-Tiering reduce storage costs for data with unknown or changing access patterns?", "answer": "S3 Intelligent-Tiering automatically moves data to the most cost-effective access tier based on access frequency without performance impact, retrieval fees, or operational overhead.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-11T16:28:24.153027"}}
{"question": "What is the difference between the performance of S3 Intelligent-Tiering's Archive Access and Deep Archive Access tiers compared to S3 Glacier's Flexible Retrieval and Deep Archive storage classes?", "answer": "The Archive Access tier has the same performance as S3 Glacier Flexible Retrieval, and the Deep Archive Access tier has the same performance as S3 Glacier Deep Archive storage class.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-52", "source_tokens": 496, "generated_at": "2026-02-11T16:28:24.153395"}}
{"question": "What availability level does S3 Intelligent-Tiering provide according to the text?", "answer": "S3 Intelligent-Tiering provides a 99.9% availability level, as stated in the text.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-11T16:28:29.372407"}}
{"question": "How does S3 Intelligent-Tiering ensure data durability, according to the text?", "answer": "S3 Intelligent-Tiering ensures the same 99.999999999% durability as the S3 Standard storage class, as mentioned in the text.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-11T16:28:29.372813"}}
{"question": "What are the two methods to transfer data into S3 Intelligent-Tiering as mentioned in the text?", "answer": "The two methods to transfer data into S3 Intelligent-Tiering are directly PUTting into S3 Intelligent-Tiering by specifying INTELLIGENT_TIERING in the x-amz-storage-class header, and setting lifecycle policies to transition objects from S3 Standard or S3 Standard-IA to S3 INTELLIGENT_TIERING.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-53", "source_tokens": 173, "generated_at": "2026-02-11T16:28:29.373048"}}
{"question": "What are the three access tiers in S3 Intelligent-Tiering and what are their corresponding pricing models?", "answer": "S3 Intelligent-Tiering has three access tiers: Frequent Access tier, priced at S3 Standard storage rates; Infrequent Access tier, priced at S3 Standard-Infrequent Access storage rates; and Archive Instant Access tier, priced at S3 Glacier Instant Retrieval storage rates.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-11T16:28:35.907164"}}
{"question": "How does S3 Intelligent-Tiering determine which access tier an object belongs to?", "answer": "S3 Intelligent-Tiering monitors access patterns and moves objects through low latency and high throughput access tiers based on their usage. Objects in the Infrequent Access, Archive Instant Access, or asynchronous archive tiers are automatically moved to the Frequent Access tier when accessed.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-11T16:28:35.907512"}}
{"question": "What are the differences between the Frequent Access tier and the Archive Access tier in S3 Intelligent-Tiering in terms of pricing and access latency?", "answer": "The Frequent Access tier is priced at S3 Standard storage rates and offers low latency and high throughput access. The Archive Access tier is priced at S3 Glacier Flexible Retrieval storage rates and offers asynchronous access with higher retrieval latency.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-54", "source_tokens": 512, "generated_at": "2026-02-11T16:28:35.907992"}}
{"question": "How long does it take for an object in the Archive Access Tier to be moved back to the Frequent Access Tier?", "answer": "It takes 3-5 hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-11T16:28:40.308370"}}
{"question": "How does the process of accessing an object in the S3 Intelligent-Tiering storage work?", "answer": "To access an object, you need to issue a Restore request, which moves the object back to the Frequent Access Tier. Once the object is in the Frequent Access Tier, you can issue a GET request to retrieve it.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-11T16:28:40.308631"}}
{"question": "What is the difference in time it takes for an object in the Archive Access Tier and the Deep Archive Access Tier to be moved back to the Frequent Access Tier?", "answer": "Objects in the Archive Access Tier are moved back to the Frequent Access Tier in 3-5 hours, while objects in the Deep Archive Access Tier take 12 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-55", "source_tokens": 393, "generated_at": "2026-02-11T16:28:40.308991"}}
{"question": "What is the minimum billable object size for S3 Intelligent-Tiering's auto-tiering?", "answer": "Objects smaller than 128KB are not eligible for auto-tiering.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-11T16:28:45.755480"}}
{"question": "How does S3 Intelligent-Tiering handle smaller objects when it comes to auto-tiering?", "answer": "Smaller objects, specifically those under 128KB, are not eligible for auto-tiering and will always be charged at Frequent Access tier rates. Their metadata is stored and billed separately at S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive storage rates.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-11T16:28:45.755840"}}
{"question": "What's the difference in storage and throughput performance between S3 Standard and S3 Intelligent-Tiering for frequently accessed data?", "answer": "S3 Standard delivers millisecond access latency and high throughput performance for frequently accessed data, while S3 Intelligent-Tiering has no minimum billable object size but has specific requirements for auto-tiering.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-56", "source_tokens": 423, "generated_at": "2026-02-11T16:28:45.756366"}}
{"question": "What storage class is Amazon S3 Express One Zone?", "answer": "Amazon S3 Express One Zone is a high-performance, single-Availability Zone Amazon S3 storage class.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-11T16:28:49.736566"}}
{"question": "Why is Amazon S3 Express One Zone ideal for latency-sensitive applications?", "answer": "Amazon S3 Express One Zone is ideal for latency-sensitive applications because it offers consistent single-digit millisecond data access and up to 10x faster data access speed than Amazon S3 Standard.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-11T16:28:49.736870"}}
{"question": "How does importing data into S3 Express One Zone differ from copying data?", "answer": "Importing data into S3 Express One Zone simplifies the process by letting you choose a prefix or bucket to import data from without having to specify all objects individually. On the other hand, copying data involves specifying each object to be copied.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-57", "source_tokens": 485, "generated_at": "2026-02-11T16:28:49.737285"}}
{"question": "What Availability Zone is used for storing S3 Express One Zone objects?", "answer": "S3 Express One Zone objects are stored in a single AWS Availability Zone (AZ) that the user chooses.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-11T16:28:54.698712"}}
{"question": "How does S3 Express One Zone improve performance compared to other S3 storage classes?", "answer": "S3 Express One Zone provides consistent single-digit millisecond first-byte read and write latency request latencies, which is up to 10x faster than existing S3 storage classes.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-11T16:28:54.699072"}}
{"question": "What's the difference in throughput capabilities between a regular S3 directory bucket and an S3 Express One Zone directory bucket?", "answer": "Each S3 Express One Zone directory bucket can support up to 2 million reads and up to 200,000 writes per second, while a regular S3 directory bucket supports up to 200,000 reads and up to 100,000 writes per second by default.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-58", "source_tokens": 457, "generated_at": "2026-02-11T16:28:54.699589"}}
{"question": "What happens to an S3 directory bucket when it has no request activity for at least 3 months?", "answer": "The bucket transitions to an inactive state, making it temporarily inaccessible for reads and writes. Despite this, it retains all storage, object metadata, and bucket metadata, and existing storage charges still apply.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-11T16:28:59.568521"}}
{"question": "Why is S3 Express One Zone an attractive choice for machine learning model training applications?", "answer": "S3 Express One Zone is designed to handle high throughput and burst requests, which benefits machine learning model training applications that deal with large amounts of data. It also allows for maximum accessible bandwidth by spreading requests over separate connections.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-11T16:28:59.568924"}}
{"question": "How does S3 Express One Zone's session-based mechanism for authentication and authorization compare to traditional methods?", "answer": "S3 Express One Zone's session-based mechanism through S3 CreateSession provides lower latency and is optimized for high-performance access to an S3 directory bucket.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-59", "source_tokens": 446, "generated_at": "2026-02-11T16:28:59.569355"}}
{"question": "What is the storage cost for storing 10 GB of data in S3 Express One Zone for 30 days?", "answer": "$1.10", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-11T16:29:04.391567"}}
{"question": "How does S3 Express One Zone charging work for storage and requests?", "answer": "S3 Express One Zone charges for storage based on total byte-hour usage, and for requests based on the number and type of requests. The storage cost is $0.11 per GB-Month, and the per request fees vary for different request types.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-11T16:29:04.391946"}}
{"question": "How do the data upload and retrieval charges compare to the storage and request charges in S3 Express One Zone?", "answer": "Data upload and retrieval charges are additional fees on top of the storage and request charges. The data upload charge is $0.03 per million 10 KB requests, and the data retrieval charge is $0.05 per million 10 KB requests.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-60", "source_tokens": 496, "generated_at": "2026-02-11T16:29:04.392411"}}
{"question": "What is the total cost for the given usage in the text passage?", "answer": "$2,581.32", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-11T16:29:07.770870"}}
{"question": "How does the cost for storage charges compare to the cost for request charges in this example?", "answer": "The storage charges are significantly higher than the request charges, with a difference of approximately $3,587.71.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-11T16:29:07.771240"}}
{"question": "What factors contribute to the storage charges in this text passage?", "answer": "The storage charges are based on the total byte-hour usage and the cost per GB-month.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-61", "source_tokens": 488, "generated_at": "2026-02-11T16:29:07.771654"}}
{"question": "What is the total amount charged in the text passage?", "answer": "$1,902.26", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-11T16:29:10.522577"}}
{"question": "How does AWS calculate the total charges?", "answer": "They add up the individual charges.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-11T16:29:10.523016"}}
{"question": "What is the difference between the largest and smallest individual charges mentioned in the text?", "answer": "The largest charge is $983.04 and the smallest charge is $9.44.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-62", "source_tokens": 55, "generated_at": "2026-02-11T16:29:10.523517"}}
{"question": "What are the costs for transferring data between Amazon EC2 and S3 Express One Zone within the same Region?", "answer": "There is no additional charge for transferring data between Amazon EC2 and S3 Express One Zone within the same Region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T16:29:16.558831"}}
{"question": "How does Amazon S3 Standard-Infrequent Access (S3 Standard-IA) differ from Amazon S3 One Zone-IA in terms of usage and storage class transition?", "answer": "S3 Standard-IA is a storage class for data that is accessed less frequently but requires rapid access when needed. It offers the same high durability, throughput, and low latency as S3 Standard, but with a lower per-GB storage price and per-GB retrieval charge. S3 Standard-IA allows you to use S3 Lifecycle policies to transition objects between storage classes without requiring any application changes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T16:29:16.559204"}}
{"question": "Why is Amazon S3 Standard-Infrequent Access (S3 Standard-IA) ideal for long-term storage and backups?", "answer": "Amazon S3 Standard-IA is ideal for long-term storage, backups, and as a data store for disaster recovery due to its low cost and high performance. It offers the same milliseconds latency and high throughput performance as the S3 Standard storage class.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-63", "source_tokens": 496, "generated_at": "2026-02-11T16:29:16.559648"}}
{"question": "What is the minimum object size charge for S3 Standard-IA?", "answer": "The minimum object size charge for S3 Standard-IA is 128KB.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-11T16:29:22.104941"}}
{"question": "Why is a smaller object in S3 Standard-IA charged as if it were 128KB?", "answer": "S3 Standard-IA has a minimum object storage charge of 128KB. Objects smaller than 128KB in size will incur storage charges as if the object were 128KB.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-11T16:29:22.105301"}}
{"question": "How does the pricing and storage class comparison between S3 Standard-IA and S3 Glacier (all tiers) differ?", "answer": "S3 Standard-IA is designed for long-lived, infrequently accessed data retained for months or years, with charges for the entire storage period, and a minimum object size charge of 128KB. S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive offer different retrieval speeds and costs, with varying retrieval fees and longer retrieval times.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-64", "source_tokens": 294, "generated_at": "2026-02-11T16:29:22.105717"}}
{"question": "What storage class in S3 offers 20% less cost than geographically redundant S3 Standard-IA storage?", "answer": "S3 One Zone-IA storage class", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-11T16:29:26.568358"}}
{"question": "Why would you choose to use S3 One Zone-IA storage over S3 Standard-IA?", "answer": "S3 One Zone-IA is designed for infrequently-accessed storage and offers a lower cost due to its single availability zone redundancy.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-11T16:29:26.568704"}}
{"question": "How does S3 One Zone-IA storage class compare to S3 Standard storage class in terms of durability and availability?", "answer": "S3 One Zone-IA is designed for 99.999999999% of durability within an availability zone, while S3 Standard is designed to withstand loss of availability and the destruction of an availability zone.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-65", "source_tokens": 484, "generated_at": "2026-02-11T16:29:26.569211"}}
{"question": "What type of AWS Availability Zone does the Amazon S3 One Zone-IA storage class use?", "answer": "The Amazon S3 One Zone-IA storage class uses an individual AWS Availability Zone within the Region.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-11T16:29:32.581240"}}
{"question": "How does S3 One Zone-IA differ from S3 Standard and S3 Standard-IA in terms of durability and availability?", "answer": "S3 One Zone-IA offers protection against equipment failure within an Availability Zone, but it is not resilient to the physical loss of the Availability Zone due to disasters. S3 Standard and S3 Standard-IA, on the other hand, store data redundantly in multiple Availability Zones and offer higher durability and availability.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-11T16:29:32.581600"}}
{"question": "How does S3 Glacier Instant Retrieval compare to S3 One Zone-IA in terms of durability and availability?", "answer": "S3 Glacier Instant Retrieval is designed for 99.999999999% (11 9s) of data durability and 99.9% availability by redundantly storing data across a minimum of three physically separated AWS Availability Zones, while S3 One Zone-IA only offers protection against equipment failure within an Availability Zone.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-66", "source_tokens": 447, "generated_at": "2026-02-11T16:29:32.582054"}}
{"question": "What is the durability level of S3 Glacier Instant Retrieval?", "answer": "S3 Glacier Instant Retrieval provides 11 9s of durability.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-11T16:29:37.320351"}}
{"question": "How does the access process differ between S3 Glacier Instant Retrieval and other S3 storage classes?", "answer": "Unlike the S3 Glacier Flexible Retrieval and S3 Glacier Deep Archive storage classes, which require a Restore request before accessing an object, you do not need to do this for S3 Glacier Instant Retrieval.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-11T16:29:37.320631"}}
{"question": "How does the cost structure of S3 Glacier Instant Retrieval compare to S3 Standard-IA when dealing with data that is not retained for 90 days?", "answer": "For objects in S3 Glacier Instant Retrieval that are not retained for 90 days, there is a pro-rated charge equal to the storage charge for the remaining days. In contrast, S3 Standard-IA does not have this charge.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-67", "source_tokens": 387, "generated_at": "2026-02-11T16:29:37.321011"}}
{"question": "What is the minimum object size for S3 Glacier Instant Retrieval?", "answer": "The minimum object size for S3 Glacier Instant Retrieval is 128KB.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-11T16:29:41.795991"}}
{"question": "Why does S3 Glacier Instant Retrieval charge for objects smaller than 128KB?", "answer": "S3 Glacier Instant Retrieval charges for objects smaller than 128KB as if they were 128KB due to a minimum object size requirement.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-11T16:29:41.796324"}}
{"question": "How does the pricing of S3 Glacier Instant Retrieval for small objects compare to larger objects?", "answer": "For small objects under 128KB in size, S3 Glacier Instant Retrieval charges the equivalent price of 128KB in addition to the actual object size price.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-68", "source_tokens": 260, "generated_at": "2026-02-11T16:29:41.796551"}}
{"question": "What is the cost advantage of S3 Glacier Flexible Retrieval compared to S3 Glacier Instant Retrieval?", "answer": "S3 Glacier Flexible Retrieval offers up to 10% lower cost compared to S3 Glacier Instant Retrieval.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-11T16:29:47.049907"}}
{"question": "For what types of data and use cases is S3 Glacier Flexible Retrieval best suited?", "answer": "S3 Glacier Flexible Retrieval is ideal for archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-11T16:29:47.050265"}}
{"question": "How does the retrieval speed and cost compare between S3 Glacier Flexible Retrieval and S3 Glacier Instant Retrieval?", "answer": "S3 Glacier Flexible Retrieval offers access times ranging from minutes to hours and free bulk retrievals, while S3 Glacier Instant Retrieval offers faster retrieval times but at a higher cost.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-69", "source_tokens": 400, "generated_at": "2026-02-11T16:29:47.050724"}}
{"question": "How can I put data directly into S3 Glacier Flexible Retrieval?", "answer": "You can put data directly into S3 Glacier Flexible Retrieval by specifying GLACIER in the x-amz-storage-class header.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-11T16:29:52.826489"}}
{"question": "Can you explain how to transition objects into Amazon S3 Glacier Flexible Retrieval using S3 Lifecycle rules?", "answer": "Yes, you can use S3 Lifecycle rules to transition objects from any of the S3 storage classes for active data to Amazon S3 Glacier Flexible Retrieval based on object age.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-11T16:29:52.826846"}}
{"question": "What's the difference between putting data directly into Amazon S3 Glacier Flexible Retrieval vs using S3 Lifecycle rules for archival?", "answer": "Putting data directly into Amazon S3 Glacier Flexible Retrieval requires specifying GLACIER in the x-amz-storage-class header during the PUT request. On the other hand, using S3 Lifecycle rules for archival allows you to transition objects from any S3 storage class to Amazon S3 Glacier Flexible Retrieval based on object age.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-70", "source_tokens": 274, "generated_at": "2026-02-11T16:29:52.827295"}}
{"question": "How long is the temporary copy of data stored in Amazon S3 after retrieval from S3 Glacier Flexible Retrieval?", "answer": "You can specify the amount of time in days for which the temporary copy is stored in Amazon S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-11T16:30:00.267987"}}
{"question": "What happens when you retrieve data from S3 Glacier Flexible Retrieval and how does it differ from Reduced Redundancy Storage?", "answer": "When you retrieve data from S3 Glacier Flexible Retrieval, a temporary copy is created in the S3 Standard storage class. This temporary copy is billed as Reduced Redundancy Storage in AWS Regions where it's a lower price than S3 Standard. However, the Reduced Redundancy billing storage class doesnâ€™t reflect how the data is actually stored. With retrieve notifications, you can be notified when the object has successfully restored from S3 Glacier Flexible Retrieval and the temporary copy is made available to you.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-11T16:30:00.268356"}}
{"question": "What are the differences between using SQS and SNS for retrieve notifications from S3 Glacier Flexible Retrieval?", "answer": "With retrieve notifications, you can arrange for notifications to be issued to SQS or SNS. Both services allow you to process and act upon the notifications. However, SQS is a message queue service that lets you decouple and scale microservices, applications, and components. It's ideal for workloads where you need to process multiple messages concurrently. SNS, on the other hand, is a fully managed pub/sub messaging service ideal for sending messages to multiple subscribers in real-time.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-71", "source_tokens": 325, "generated_at": "2026-02-11T16:30:00.268791"}}
{"question": "What is the typical time frame for data retrieval using Expedited, Standard, and Bulk retrievals in Amazon S3?", "answer": "Data retrieved using Expedited retrievals are typically made available within 1-5 minutes. Objects retrieved using Standard retrievals typically complete between 3-5 hours. Bulk retrievals typically complete within 5-12 hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-11T16:30:05.570840"}}
{"question": "Why would someone choose to use provisioned retrieval capacity for data retrievals in Amazon S3?", "answer": "Provisioned retrieval capacity is useful for workloads that require highly reliable and predictable access to a subset of data in minutes. Without provisioned capacity, expedited retrievals might not be accepted during periods of high demand.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-11T16:30:05.571220"}}
{"question": "How does the retrieval time and cost compare between Expedited and Standard retrievals in Amazon S3 with provisioned capacity?", "answer": "Expedited retrievals using provisioned capacity are typically available within 1-5 minutes and cost more. Standard retrievals using provisioned capacity typically complete between 3-5 hours and cost less.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-72", "source_tokens": 486, "generated_at": "2026-02-11T16:30:05.571697"}}
{"question": "What is the additional storage required for each object in Amazon S3 Glacier Flexible Retrieval for S3 Glacier's index and metadata?", "answer": "An additional 32 KB of data per object is required for S3 Glacierâ€™s index and metadata.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-11T16:30:10.292525"}}
{"question": "Why does Amazon S3 Glacier Flexible Retrieval require extra storage for each object compared to standard storage?", "answer": "Amazon S3 Glacier Flexible Retrieval requires extra storage for each object due to the additional data required for S3 Glacierâ€™s index and metadata.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-11T16:30:10.292781"}}
{"question": "How does the storage required for Amazon S3 Glacier Flexible Retrieval compare to standard storage for each object?", "answer": "For each object in Amazon S3 Glacier Flexible Retrieval, an additional 32 KB of data is required compared to standard storage.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-73", "source_tokens": 386, "generated_at": "2026-02-11T16:30:10.293151"}}
{"question": "What is the minimum storage duration for objects in S3 Glacier Flexible Retrieval?", "answer": "The minimum storage duration for objects in S3 Glacier Flexible Retrieval is 90 days.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-11T16:30:15.695429"}}
{"question": "Why is there an additional metadata charge for objects in S3 Glacier Flexible Retrieval?", "answer": "An additional metadata charge for objects in S3 Glacier Flexible Retrieval is due to the 8 KB data that is charged at the S3 Standard rate and the 32 KB metadata charged at the S3 Glacier Flexible Retrieval rate, necessary to maintain the user-defined name and metadata for archived objects.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-11T16:30:15.695661"}}
{"question": "What is the difference in retrieval fees between Expedited and Standard Retrievals compared to Bulk Retrievals in S3 Glacier Flexible Retrieval?", "answer": "Expedited and Standard Retrievals from S3 Glacier Flexible Retrieval have per-GB retrieval fees and per-request fees, while Bulk Retrievals are free.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-74", "source_tokens": 344, "generated_at": "2026-02-11T16:30:15.696097"}}
{"question": "What is the storage class in S3 Glacier designed for long-term archiving with the lowest cost?", "answer": "S3 Glacier Deep Archive", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-11T16:30:20.570915"}}
{"question": "How does AWS manage to provide the lowest cost for the S3 Glacier Deep Archive storage class?", "answer": "AWS optimizes the sequence of inputs and outputs to maximize efficiency accessing the underlying storage", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-11T16:30:20.571272"}}
{"question": "How does S3 Glacier Deep Archive compare to S3 Glacier Instant Retrieval and Flexible Retrieval in terms of retrieval time and cost?", "answer": "S3 Glacier Deep Archive offers the lowest cost storage, but retrieval takes 12 hours. S3 Glacier Instant Retrieval delivers the lowest cost storage with milliseconds retrieval, while S3 Glacier Flexible Retrieval offers retrieval in minutes or free bulk retrievals in 5-12 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-75", "source_tokens": 462, "generated_at": "2026-02-11T16:30:20.571752"}}
{"question": "What industries commonly use S3 Glacier Deep Archive for data storage?", "answer": "S3 Glacier Deep Archive is commonly used in highly regulated industries such as Financial Services, Healthcare, Oil & Gas, and Public Sectors. Media and entertainment companies also use it for keeping a backup copy of core intellectual property.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-11T16:30:26.806756"}}
{"question": "Why is S3 Glacier Deep Archive an attractive choice for organizations?", "answer": "S3 Glacier Deep Archive is an attractive choice for organizations as it provides offline protection for important data assets and long-term data retention for corporate policy, contractual, or regulatory compliance requirements. It can also help organizations reduce or discontinue the use of on-premises magnetic tape libraries and off-premises tape archival services.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-11T16:30:26.806956"}}
{"question": "How does the cost and retrieval time differ between S3 Glacier Deep Archive and S3 Glacier Flexible Retrieval?", "answer": "S3 Glacier Deep Archive is up to 75% less expensive than S3 Glacier Flexible Retrieval and provides retrieval within 12 hours using the Standard retrieval tier. Retrievals with S3 Glacier Flexible Retrieval are typically free and take minutes or are bulk retrievals taking 5-12 hours.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-76", "source_tokens": 442, "generated_at": "2026-02-11T16:30:26.807163"}}
{"question": "What storage class should I use to upload data directly to S3 Glacier Deep Archive?", "answer": "You should specify 'S3 Glacier Deep Archive' as the storage class when uploading data directly to S3 Glacier Deep Archive using the S3 API.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-11T16:30:32.140388"}}
{"question": "How can I use S3 Lifecycle to migrate data to S3 Glacier Deep Archive?", "answer": "You can set policies to migrate objects to S3 Glacier Deep Archive based on the age of the object, and these policies can be set for an S3 bucket or for specific prefixes. Lifecycle transitions are billed at the S3 Glacier Deep Archive Upload price.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-11T16:30:32.140761"}}
{"question": "How does using Tape Gateway with S3 Glacier Deep Archive impact the cost of storing virtual tape-based backups and archives?", "answer": "By enabling you to store your virtual tape-based backups and archives in S3 Glacier Deep Archive, Tape Gateway provides the lowest cost storage for this data in the cloud.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-77", "source_tokens": 328, "generated_at": "2026-02-11T16:30:32.141241"}}
{"question": "How can I migrate data from tape archives to S3 Glacier Deep Archive using AWS?", "answer": "You can use the AWS Tape Gateway with a virtual tape library (VTL) interface, AWS Snowball, or AWS Direct Connect.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-11T16:30:36.504604"}}
{"question": "What are the benefits of using AWS Snowball for migrating data to S3 Glacier Deep Archive?", "answer": "It helps eliminate challenges with large-scale data transfers including high network costs, long transfer times, and security concerns.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-11T16:30:36.504977"}}
{"question": "What is the difference between using AWS Tape Gateway and AWS Snowball for migrating data to S3 Glacier Deep Archive?", "answer": "AWS Tape Gateway allows for immediate use of virtual tapes with existing backup applications, while AWS Snowball uses physical storage devices for data transfer.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-78", "source_tokens": 445, "generated_at": "2026-02-11T16:30:36.505486"}}
{"question": "What is the pricing structure for S3 Glacier Deep Archive in terms of data storage and requests?", "answer": "S3 Glacier Deep Archive pricing is based on the amount of data stored in GBs, the number of PUT/lifecycle transition requests, retrievals in GBs, and number of restore requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-11T16:30:42.177547"}}
{"question": "How does the metadata pricing work for objects stored in S3 Glacier Deep Archive?", "answer": "Objects in S3 Glacier Deep Archive require 40 KB of additional metadata for each archived object. This includes 32 KB of metadata charged at the S3 Glacier Deep Archive rate and an additional 8 KB charged at the S3 Standard rate.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-11T16:30:42.177910"}}
{"question": "What is the difference in metadata pricing between S3 Glacier Deep Archive and regular S3 storage?", "answer": "For S3 Glacier Deep Archive, 32 KB of metadata are charged at the S3 Glacier Deep Archive rate, and an additional 8 KB are charged at the S3 Standard rate. For regular S3 storage, only the metadata charged at the S3 Standard rate applies.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-79", "source_tokens": 398, "generated_at": "2026-02-11T16:30:42.178444"}}
{"question": "What Amazon S3 features does S3 Glacier Deep Archive support?", "answer": "S3 Glacier Deep Archive supports S3 Object Tagging, S3 Lifecycle policies, S3 Object Lock, and S3 Replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-11T16:30:48.215684"}}
{"question": "How does integrating S3 Glacier Deep Archive with Amazon S3 features benefit storage administrators?", "answer": "Integrating S3 Glacier Deep Archive with Amazon S3 features allows storage administrators to make decisions based on the nature of the data and data access patterns. They can use S3 Lifecycle policies to automatically migrate data to lower-cost storage classes as the data ages, or use S3 Cross-Region Replication or Same-Region Replication policies to replicate data to the same or a different region.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-11T16:30:48.216039"}}
{"question": "How does AWS Storage Gateway with Tape Gateway help in reducing the cost of storing long-term data using S3 Glacier Deep Archive?", "answer": "AWS Storage Gateway service integrates Tape Gateway with S3 Glacier Deep Archive storage class, allowing you to store virtual tapes in the lowest-cost Amazon S3 storage class. This reduces the monthly cost to store your long-term data in the cloud by 75%.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-80", "source_tokens": 362, "generated_at": "2026-02-11T16:30:48.216463"}}
{"question": "What are S3 object tags and how are they used in S3 on Outposts?", "answer": "S3 object tags are key-value pairs applied to S3 objects in S3 on Outposts. They can be used to create IAM policies, set up Lifecycle policies, and customize storage metrics. Object tags can manage transitions between storage classes and expire objects in the background. Up to ten tags can be added to each S3 object, and they can be added using various AWS tools.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-11T16:30:54.462331"}}
{"question": "What are the benefits of adding object tags to S3 objects in S3 on Outposts?", "answer": "Adding object tags to S3 objects in S3 on Outposts allows you to create IAM policies, set up Lifecycle policies, and customize storage metrics. Object tags can manage transitions between storage classes and expire objects in the background.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-11T16:30:54.462697"}}
{"question": "How does using S3 object tags in S3 on Outposts compare to using them in regular AWS S3?", "answer": "Both S3 on Outposts and regular S3 allow you to add object tags to manage and customize S3 objects. However, S3 on Outposts allows you to securely process and store customer data on-premises before moving it to an AWS Region, and also allows you to store data for companies in regulated industries or those with data residency requirements.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-81", "source_tokens": 330, "generated_at": "2026-02-11T16:30:54.463144"}}
{"question": "What are Object tags used for in S3?", "answer": "Object tags are used in Amazon S3 for simple management of your S3 storage. They allow you to control access to objects, secure confidential data, label objects for specific projects or business units, and can be used with S3 Lifecycle policies or S3 Replication to manage storage class transitions or data replication between regions.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-11T16:30:59.072235"}}
{"question": "How do I change Object tags in Amazon S3?", "answer": "You can change Object tags in Amazon S3 using the AWS Management Console, REST API, AWS CLI, or AWS SDKs. When adding a new tag, you need to include the original tag set in the request.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-11T16:30:59.072608"}}
{"question": "What is the difference between updating and adding Object tags in terms of pricing?", "answer": "The pricing for adding and updating Object tags in Amazon S3 is the same.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-82", "source_tokens": 438, "generated_at": "2026-02-11T16:30:59.073079"}}
{"question": "What metadata tables are used to store and query tabular data within Amazon S3, and where are they stored?", "answer": "Amazon S3 Metadata tables are stored in an AWS managed table bucket named 'aws-s3'. They are built on Apache Iceberg and provide a managed way to store and query tabular data within S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-11T16:31:04.702142"}}
{"question": "How does S3 Metadata make object metadata queryable, and what types of metadata does it manage?", "answer": "S3 Metadata makes object metadata queryable by storing it in Amazon S3 Tables, which are built on Apache Iceberg. It manages system-level metadata such as object size, custom metadata such as tags and user-defined metadata during object upload, and event metadata such as the IP address that sent the request.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-11T16:31:04.702526"}}
{"question": "How does S3 Metadata compare to other methods for querying S3 object metadata?", "answer": "S3 Metadata allows you to query S3 object metadata using SQL and various AWS analytics services and open source tools that are Iceberg-compatible. This provides more flexibility and functionality compared to other methods such as using the AWS CLI or Amazon S3 Select to query metadata.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-83", "source_tokens": 441, "generated_at": "2026-02-11T16:31:04.702955"}}
{"question": "What tables does S3 Metadata use to store metadata in an AWS account?", "answer": "S3 Metadata stores metadata in two managed tables in your account: journal tables and live inventory tables.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-11T16:31:08.834121"}}
{"question": "How does the S3 Metadata journal table help users?", "answer": "The S3 Metadata journal table provides a view of changes made within your bucket, allowing users to write SQL queries for identifying objects based on various filters such as objects added in the last 30 days, objects added by active requesters, or objects with metadata changes across the last week.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-11T16:31:08.834512"}}
{"question": "How does the frequency of updates differ between S3 Metadata journal tables and live inventory tables?", "answer": "Journal table updates are near real-time, while live inventory tables are updated hourly.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-84", "source_tokens": 381, "generated_at": "2026-02-11T16:31:08.834956"}}
{"question": "What output formats are available for the S3 Inventory report?", "answer": "The S3 Inventory report can be configured to provide a CSV, ORC, or Parquet file output.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-11T16:31:13.422246"}}
{"question": "How can the S3 Inventory report be used in business workflows and big data jobs?", "answer": "The S3 Inventory report can be used as a direct input into business workflows and big data jobs to simplify and speed up processes. It can also be queried using Standard SQL language with various tools like Amazon Athena, Amazon Redshift Spectrum, Presto, Hive, and Spark.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-11T16:31:13.422545"}}
{"question": "What is the difference between configuring S3 Inventory for a bucket and a prefix?", "answer": "Configuring S3 Inventory for a bucket includes all objects within that bucket, while configuring it for a prefix only includes objects under the specified shared prefix.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-85", "source_tokens": 394, "generated_at": "2026-02-11T16:31:13.422936"}}
{"question": "What type of data is S3 Tables optimized for?", "answer": "S3 Tables are optimized for analytics workloads.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-11T16:31:17.549681"}}
{"question": "How can I use S3 Tables to interact with my data?", "answer": "You can use S3 Tables to store tabular data in Amazon S3 and then interact with that data using analytics capabilities such as row-level transactions, queryable table snapshots, and more.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-11T16:31:17.550036"}}
{"question": "How does S3 Tables compare to other AWS services for querying data in S3?", "answer": "S3 Tables allow you to store and query tabular data in Amazon S3 using standard SQL statements, while services like Amazon Athena and Redshift also enable querying data in S3 but may require additional setup and configuration.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-86", "source_tokens": 321, "generated_at": "2026-02-11T16:31:17.550542"}}
{"question": "What formats can S3 Tables store for structured data?", "answer": "S3 Tables support storing structured data in the Apache Parquet, Avro, and ORC formats.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-11T16:31:21.696035"}}
{"question": "How does S3 optimize data in tables for improved query performance?", "answer": "S3 optimizes data on tables by automatically rewriting, or compacting, your objects over time to improve query performance.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-11T16:31:21.696398"}}
{"question": "What is the difference between creating a table using the CreateTable API and using a query engine?", "answer": "Both methods allow creating a table in an S3 table bucket. However, the CreateTable API is used in the S3 Management Console or through the S3 CreateTableBucket API, while a query engine can be used directly within the application.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-87", "source_tokens": 505, "generated_at": "2026-02-11T16:31:21.696808"}}
{"question": "What type of SQL can be used to query tables in S3 Table Buckets?", "answer": "Standard SQL can be used to query tables in S3 Table Buckets.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-11T16:31:25.912824"}}
{"question": "How does using table buckets instead of general purpose S3 buckets for storing Iceberg tables benefit query performance and transactions per second?", "answer": "Using table buckets instead of general purpose S3 buckets for storing Iceber tables can result in up to 3x faster query performance and up to 10x higher transactions per second due to automatic data compaction and purpose-built storage.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-11T16:31:25.913190"}}
{"question": "What are the maintenance operations offered by S3 Table Buckets?", "answer": "S3 Table Buckets offer three maintenance operations: compaction, snapshot management, and unreferenced file removal.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-88", "source_tokens": 474, "generated_at": "2026-02-11T16:31:25.913608"}}
{"question": "What is the default encryption method for data in S3 Tables?", "answer": "Data in S3 Tables is encrypted by default using server-side encryption.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-11T16:31:29.892371"}}
{"question": "Why would you use AWS KMS with S3 Tables for encryption and key management?", "answer": "AWS KMS allows you to encrypt your data in S3 Tables using your own encryption keys, adds an extra layer of control and protection against unauthorized access, and generates a detailed audit trail.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-11T16:31:29.892734"}}
{"question": "How does the cost structure for S3 Tables compare to general purpose S3 buckets?", "answer": "S3 Tables incur additional fees for table maintenance along with the regular storage, requests, and object monitoring fees.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-89", "source_tokens": 423, "generated_at": "2026-02-11T16:31:29.893225"}}
{"question": "What is the default retention period for table snapshots based on the given context?", "answer": "The default retention period for table snapshots is 120 hours.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-11T16:31:34.537762"}}
{"question": "How does snapshot management for S3 tables determine the number of active snapshots?", "answer": "Snapshot management for S3 tables determines the number of active snapshots based on the MinimumSnapshots (1 by default) and MaximumSnapshotAge (120 hours by default).", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-11T16:31:34.538161"}}
{"question": "What happens when a table snapshot expires and an object is no longer referenced?", "answer": "When a table snapshot expires, Amazon S3 creates delete markers for the data and metadata files uniquely referenced by that snapshot. These files are marked as noncurrent and are deleted after the number of days specified by the NoncurrentDays property in the unreferenced file removal policy. For any object not referenced by your table and older than the ExpireDays property, S3 permanently deletes the objects after the number of days specified by the NoncurrentDays property.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-90", "source_tokens": 359, "generated_at": "2026-02-11T16:31:34.538416"}}
{"question": "What automation feature does S3 offer for executing a single operation across multiple objects?", "answer": "S3 Batch Operations", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-11T16:31:39.446136"}}
{"question": "How does S3 Batch Operations simplify managing storage operations across many objects?", "answer": "S3 Batch Operations automates the execution of a single operation, such as copying an object or executing an AWS Lambda function, across a large number of objects. It also manages retries, displays progress, delivers notifications, provides a completion report, and sends events to AWS CloudTrail.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-11T16:31:39.446419"}}
{"question": "What are the main differences between using S3 Batch Operations from the console versus the AWS CLI or SDK?", "answer": "Using S3 Batch Operations from the console and through the AWS CLI or SDK both allow users to make changes to billions of objects without the need for custom application code or running compute clusters, but the console provides a few clicks interface and visual progress display, while the CLI and SDK offer more programmatic control.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-91", "source_tokens": 195, "generated_at": "2026-02-11T16:31:39.446814"}}
{"question": "What types of operations can be performed using S3 Batch Operations?", "answer": "S3 Batch Operations supports a variety of operations, including replacing tag sets, changing ACLs, copying storage, and initiating restores from S3 Glacier Flexible Retrieval to S3 Standard storage class.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-11T16:31:45.153809"}}
{"question": "How does S3 Batch Operations process a job?", "answer": "After creating an S3 Batch Operations job, S3 Batch Operations processes the list of objects and sends the job to the â€˜awaiting confirmationâ€™ state. Once the job details are confirmed, S3 Batch Operations begins executing the specified operation. Users can view the jobâ€™s progress through the S3 console or programmatically and receive notifications upon completion.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-11T16:31:45.154205"}}
{"question": "How does S3 Object Lock differ from S3 Batch Operations?", "answer": "While S3 Batch Operations is used to perform various operations on S3 objects, S3 Object Lock is a feature specifically designed for financial services industry customers to retain records in a non-erasable and non-rewritable format to meet regulatory requirements. S3 Object Lock allows users to designate the retention time frame and place legal holds.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-92", "source_tokens": 488, "generated_at": "2026-02-11T16:31:45.154646"}}
{"question": "What is required to use Amazon S3 for electronic storage and notify the regulatory body?", "answer": "A notification to your regulator or Designated Examining Authority (DEA) of your choice is required, along with a copy of the Cohasset Assessment. AWS is not a designated third party (D3P), so it's essential to select one and include this information in your notification.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-11T16:31:50.996398"}}
{"question": "How can you enable CloudWatch request metrics for an S3 bucket and configure filters?", "answer": "You can use the AWS Management Console to enable one-minute CloudWatch request metrics for your S3 bucket and configure filters using a prefix or object tag, or access point. Alternatively, you can call the S3 PUT Bucket Metrics API to enable and configure publication of S3 storage metrics.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-11T16:31:50.996759"}}
{"question": "What are the differences between CloudWatch storage metrics and request metrics, and how are they priced?", "answer": "CloudWatch storage metrics are enabled by default for all buckets and reported once per day, while CloudWatch request metrics are available within 15 minutes after they are enabled and are priced as custom metrics for Amazon CloudWatch. CloudWatch storage metrics are provided free, while CloudWatch request metrics incur additional charges.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-93", "source_tokens": 485, "generated_at": "2026-02-11T16:31:50.997267"}}
{"question": "At what levels can you set up and manage Lifecycle policies in AWS?", "answer": "You can set up and manage Lifecycle policies in the AWS Management Console, S3 REST API, AWS SDKs, or AWS Command Line Interface (CLI).", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-11T16:31:55.070334"}}
{"question": "How does managing Lifecycle policies work at different levels in AWS S3?", "answer": "You can specify the policy at the prefix or at the bucket level.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-11T16:31:55.070602"}}
{"question": "What's the difference between setting up a Lifecycle policy at the prefix level and the bucket level in AWS S3?", "answer": "Setting up a Lifecycle policy at the prefix level applies to the specified prefix and all its sub-prefixes, while setting it up at the bucket level applies to all the objects in the bucket.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-94", "source_tokens": 53, "generated_at": "2026-02-11T16:31:55.071001"}}
{"question": "What storage classes can you transition objects to using an S3 Lifecycle policy?", "answer": "You can transition objects to S3 Standard-IA, S3 One Zone-IA, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, or S3 Glacier Deep Archive storage classes using an S3 Lifecycle policy.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-11T16:32:00.194986"}}
{"question": "How can you use S3 Lifecycle policies to save time and reduce storage costs?", "answer": "S3 Lifecycle policies allow you to automate the process of moving and archiving objects based on specific rules, reducing the need for manual data review and migration and helping to save time and reduce storage costs.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-11T16:32:00.195337"}}
{"question": "How does an S3 Lifecycle policy differ in its application to individual objects versus sets of objects?", "answer": "An S3 Lifecycle policy can be applied to individual objects by specifying the key name, or to sets of objects by specifying their common prefix (e.g. â€˜logs/â€™).", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-95", "source_tokens": 470, "generated_at": "2026-02-11T16:32:00.195558"}}
{"question": "What is the cost for setting up and applying S3 Lifecycle policies?", "answer": "There is no additional cost to set up and apply S3 Lifecycle policies.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-11T16:32:04.198213"}}
{"question": "How can S3 Lifecycle policies help in saving costs?", "answer": "S3 Lifecycle policies can help save costs by automatically removing incomplete multipart uploads and the associated storage after a predefined number of days.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-11T16:32:04.198656"}}
{"question": "What's the difference between S3 Event Notifications and S3 Inventory?", "answer": "S3 Event Notifications notify you when S3 Lifecycle transitions or expires objects. S3 Inventory provides a report of your objects and their corresponding metadata on a daily or weekly basis.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-96", "source_tokens": 403, "generated_at": "2026-02-11T16:32:04.198859"}}
{"question": "What metrics are included in the free version of S3 Storage Lens?", "answer": "The free version of S3 Storage Lens includes metrics like bytes, object counts, and requests, as well as metrics detailing S3 feature utilization, such as encrypted object counts and S3 Lifecycle rule counts.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-11T16:32:08.883843"}}
{"question": "How does S3 Storage Lens help users optimize storage costs and apply best practices on data protection?", "answer": "S3 Storage Lens provides contextual recommendations to help users reduce storage costs and apply best practices on data protection across tens or hundreds of accounts and buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-11T16:32:08.884229"}}
{"question": "What is the difference between the free and advanced versions of S3 Storage Lens in terms of available metrics and recommendations?", "answer": "The free version of S3 Storage Lens includes a limited set of metrics and recommendations, while the advanced version offers 35 additional metrics and prefix-level aggregations for an additional cost.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-97", "source_tokens": 425, "generated_at": "2026-02-11T16:32:08.884465"}}
{"question": "What types of questions can be answered using the S3 Storage Lens dashboard with the Summary filter?", "answer": "The Summary filter allows exploring top-level questions related to overall storage usage and activity trends, such as 'How rapidly is my overall byte count and request count increasing over time?'", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-11T16:32:13.006199"}}
{"question": "How does the S3 Storage Lens dashboard help in understanding cost optimization?", "answer": "The dashboard allows exploring questions related to storage cost reduction, like 'Is it possible for me to save money by retaining fewer non-current versions?'", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-11T16:32:13.006520"}}
{"question": "What is the difference between free metrics and advanced metrics in S3 Storage Lens?", "answer": "Free metrics include usage analysis metrics, organized into categories like cost optimization, data protection, access management, performance, and events. Advanced metrics, available for an additional cost, provide deeper insights with metrics related to activity, cost optimization, data protection, and detailed status codes", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-98", "source_tokens": 371, "generated_at": "2026-02-11T16:32:13.006708"}}
{"question": "What historical data does the default S3 Storage Lens dashboard provide for free metrics?", "answer": "The default S3 Storage Lens dashboard provides 14 days of historical data for free metrics.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-11T16:32:17.423523"}}
{"question": "How does S3 Storage Lens advanced metrics differ from free metrics in terms of data retention?", "answer": "S3 Storage Lens advanced metrics offer 15 months of historical data compared to the 14 days provided by free metrics.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-11T16:32:17.423889"}}
{"question": "What are the advantages of using S3 Storage Lens advanced metrics and recommendations over free metrics?", "answer": "S3 Storage Lens advanced metrics and recommendations offer 35 additional metrics, prefix-level aggregation, CloudWatch metrics support, custom object metadata filtering with S3 Storage Lens groups, and provide 15 months of historical data in the dashboard.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-99", "source_tokens": 502, "generated_at": "2026-02-11T16:32:17.424318"}}
{"question": "What storage classes does S3 Storage Class Analysis recommend based on object access patterns?", "answer": "S3 Storage Class Analysis recommends optimal storage classes based on object-level access patterns within an individual bucket/prefix/tag for the previous 30-90 days.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-11T16:32:23.040199"}}
{"question": "How can you use S3 Storage Lens to improve cost efficiency and data protection best practices?", "answer": "S3 Storage Lens provides daily organization level recommendations on ways to improve cost efficiency and apply data protection best practices, with additional granular recommendations by account, region, storage class, bucket, S3 Storage Lens group, or prefix.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-11T16:32:23.040465"}}
{"question": "How does S3 Storage Class Analysis compare to S3 Storage Lens in terms of recommendations and filtering capabilities?", "answer": "S3 Storage Class Analysis provides recommendations based on object-level access patterns within a bucket/prefix/tag for the previous 30-90 days to determine the optimal storage class for your storage. S3 Storage Lens, on the other hand, offers daily organization level recommendations and allows for custom filters with S3 Storage Lens groups to visualize your storage based on object age and inform your storage archival strategy.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-100", "source_tokens": 416, "generated_at": "2026-02-11T16:32:23.040857"}}
{"question": "What is Amazon Athena and how does it work?", "answer": "Amazon Athena is an interactive query service that allows you to analyze data in Amazon S3 using standard SQL queries. It is serverless, so there is no infrastructure to set up or manage. You can start analyzing data immediately without the need to load your data into Athena. Athena works directly with data stored in any S3 storage class and supports a variety of standard data formats, including CSV, JSON, ORC, Apache Parquet, and Avro. It uses Presto with full standard SQL support and can handle complex analysis, including large joins, window functions, and arrays.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-11T16:32:30.645054"}}
{"question": "What is the difference between using client-side filtering and Amazon Athena for querying data in Amazon S3?", "answer": "Client-side filtering involves downloading an Amazon S3 object to your AWS compute and filtering the contents using data analysis libraries on your client application. This method requires additional setup and management compared to Amazon Athena. Amazon Athena, on the other hand, is a serverless query service that allows you to work directly with data stored in any S3 storage class and supports a variety of standard data formats. It also handles complex queries and integrates with Amazon QuickSight for easy visualization.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-11T16:32:30.645421"}}
{"question": "How do I download an Amazon S3 object and filter its contents using Pandas library in Python?", "answer": "You can download an Amazon S3 object using the Amazon S3 GET API and filter the contents using the Pandas library in Python. First, download the object using the `boto3` library. Then, load the data into a Pandas DataFrame and apply filters or transformations using Pandas functions.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-101", "source_tokens": 390, "generated_at": "2026-02-11T16:32:30.645899"}}
{"question": "What data does Amazon Redshift Spectrum let you query without loading or ETL?", "answer": "Amazon Redshift Spectrum lets you query exabytes of unstructured data in Amazon S3 without loading or Extract, Transform, Load (ETL) requirement.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-11T16:32:35.955889"}}
{"question": "How does Amazon Redshift Spectrum process queries against data in Amazon S3?", "answer": "Amazon Redshift Spectrum processes queries against data in Amazon S3 by generating and optimizing a query plan, determining what data is local and what is in Amazon S3, minimizing the amount of Amazon S3 data that needs to be read, and requesting Redshift Spectrum workers to read and process data from Amazon S3.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-11T16:32:35.956257"}}
{"question": "How does Amazon Redshift Spectrum compare to Amazon S3 Replication in terms of data access and processing?", "answer": "Amazon Redshift Spectrum allows you to query data directly from Amazon S3 without the need for replication, while Amazon S3 Replication enables automatic, asynchronous copying of objects across Amazon S3 buckets for disaster recovery and data availability purposes.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-102", "source_tokens": 413, "generated_at": "2026-02-11T16:32:35.956683"}}
{"question": "What region does CRR replicate data between?", "answer": "CRR replicates data between buckets across different AWS Regions.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-11T16:32:39.154729"}}
{"question": "Why is CRR useful for data access and compliance requirements?", "answer": "CRR can provide lower-latency data access in different geographic regions and help meet compliance requirements by storing copies of data hundreds of miles apart.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-11T16:32:39.155090"}}
{"question": "How does CRR compare to SRR in terms of region and ownership change?", "answer": "CRR replicates data between regions and allows changing account ownership for the replicated objects. SRR replicates data within the same region and also allows changing account ownership.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-103", "source_tokens": 424, "generated_at": "2026-02-11T16:32:39.155517"}}
{"question": "What storage classes can you copy objects to using S3 Replication?", "answer": "You can copy objects to various storage classes such as S3 Standard, S3 Standard-IA, S3 One Zone-IA, and S3 Glacier using S3 Replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-11T16:32:43.806732"}}
{"question": "Why would you disable lifecycle rules during an S3 Batch Replication job?", "answer": "You should disable lifecycle rules during an S3 Batch Replication job to maintain parity between noncurrent and current versions of objects in the source and destination buckets.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-11T16:32:43.807093"}}
{"question": "How does S3 Replication compare to setting up lifecycle rules independently for each bucket?", "answer": "S3 Replication allows you to establish replication rules to make copies of objects into another storage class within the same or different region. In contrast, setting up lifecycle rules independently for each bucket enables you to apply different lifecycle configurations to each bucket.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-104", "source_tokens": 460, "generated_at": "2026-02-11T16:32:43.807603"}}
{"question": "What are the region limitations for S3 Replication?", "answer": "S3 Replication allows customers to replicate their data to multiple destination buckets in the same or different AWS Regions. However, it's not available between AWS China Regions and AWS Regions outside of China.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-11T16:32:49.632821"}}
{"question": "Can I use S3 Replication to set up two-way replication between S3 buckets with different ownership?", "answer": "Yes, for Cross-Region Replication (CRR) and Server-Side Copy (SRC) replication, you can set up replication across AWS accounts and maintain a distinct ownership stack between source and destination. You can grant destination account ownership to the replicated storage using Ownership Overwrite in your replication configuration.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-11T16:32:49.633185"}}
{"question": "How does S3 Replication handle delete markers between buckets?", "answer": "Yes, you can replicate delete markers from source to destination if you have delete marker replication enabled in your replication configuration. When you replicate delete markers, Amazon S3 will behave as if the object was deleted in both buckets. You can apply delete marker replication to the entire bucket or to Amazon S3 objects that have a specific prefix, using prefix-based replication rules.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-105", "source_tokens": 485, "generated_at": "2026-02-11T16:32:49.633679"}}
{"question": "What types of encryption does S3 Replication support according to the text?", "answer": "S3 Replication supports all encryption types that S3 offers, including server-side encryption with Amazon S3-managed keys (SSE-S3), server-side encryption with KMS keys stored in AWS Key Management Service (SSE-KMS), and server-side encryption with customer-provided keys (SSE-C).", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-11T16:32:55.123160"}}
{"question": "How can you ensure the security of data being replicated using S3?,", "answer": "You can ensure the security of data being replicated using S3 by using server-side encryption, which the text states S3 offers in three different ways: SSE-S3, SSE-KMS, and SSE-C.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-11T16:32:55.123537"}}
{"question": "What's the difference between SSE-S3 and SSE-C in terms of encryption management?", "answer": "SSE-S3 is when S3 requests Amazon to encrypt the objects for you, while SSE-C is when you encrypt data on the client-side before uploading it to S3. Both are server-side encryption types, but the encryption management is different.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-106", "source_tokens": 191, "generated_at": "2026-02-11T16:32:55.123864"}}
{"question": "What charges does the source account incur for cross account S3 Replication?", "answer": "The source account pays for all data transfer charges (S3 RTC and S3 CRR) and the destination account pays for the replication PUT requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-11T16:33:01.492926"}}
{"question": "How does Amazon S3 Replication Time Control ensure predictable replication performance?", "answer": "Amazon S3 Replication Time Control is designed to replicate most objects in seconds, and 99.99% of objects within 15 minutes. It is backed by a Service Level Agreement (SLA) commitment that 99.9% of objects will be replicated in 15 minutes for each replication region pair during any billing month.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-11T16:33:01.493289"}}
{"question": "What are the differences in charges between using Amazon S3 Replication and Amazon S3 Batch Replication for cross account replication?", "answer": "For Amazon S3 Replication, the source account pays for all data transfer charges (S3 RTC and S3 CRR), and the destination account pays for the replication PUT requests. For Amazon S3 Batch Replication, you incur S3 Batch Operations charges, which include the Job and Object charges, as well as a manifest charge based on the number of objects in the source bucket. Replication PUT requests and Data Transfer OUT charges also apply to Amazon S3 Batch Replication.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-107", "source_tokens": 475, "generated_at": "2026-02-11T16:33:01.493767"}}
{"question": "What metrics does Amazon S3 Replication provide in the console and CloudWatch?", "answer": "Amazon S3 Replication provides four metrics: operations pending, bytes pending, replication latency, and operations failed replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-11T16:33:06.755474"}}
{"question": "How does enabling Amazon S3 Replication Time Control impact events and metrics?", "answer": "When S3 Replication Time Control is enabled, you will receive S3 Event Notifications when an object takes more than 15 minutes to replicate and when that object replicates successfully to the destination.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-11T16:33:06.755731"}}
{"question": "What's the difference between monitoring Amazon S3 Replication metrics and receiving S3 Event Notifications?", "answer": "Monitoring S3 Replication metrics provides information about the total number of operations and size of objects that are pending to replicate, the replication latency between source and destination buckets, and the number of operations that did not replicate successfully for each replication rule. Receiving S3 Event Notifications provides more detailed information about objects that failed to replicate and the reason behind the failures.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-108", "source_tokens": 496, "generated_at": "2026-02-11T16:33:06.755929"}}
{"question": "What metrics can't be used to track S3 Batch Replication progress?", "answer": "Metrics like bytes pending, operations pending, and replication latency can't be used to track S3 Batch Replication progress.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-11T16:33:11.658804"}}
{"question": "How can you monitor objects that don't replicate successfully with S3 Batch Replication?", "answer": "You can use the operations failed replication metric to monitor existing objects that do not replicate successfully with S3 Batch Replication, or you can use S3 Batch Operations completion reports to keep track of objects replicating with S3 Batch Replication.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-11T16:33:11.659113"}}
{"question": "What is the difference between S3 Replication Time Control and metrics like bytes pending and operations pending for tracking replication progress?", "answer": "S3 Replication Time Control is a service that aims to replicate 99.99% of your objects within 15 minutes, while metrics like bytes pending and operations pending cannot be used to track S3 Batch Replication progress.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-109", "source_tokens": 263, "generated_at": "2026-02-11T16:33:11.659550"}}
{"question": "What are the charges for S3 Replication, specifically for inter-region data transfer?", "answer": "For inter-region data transfer from S3 to your destination region during S3 Replication, you pay $0.020 per GB transferred.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-11T16:33:17.068291"}}
{"question": "How does S3 Multi-Region Access Points improve performance when accessing data replicated across multiple regions?", "answer": "S3 Multi-Region Access Points use AWS Global Accelerator to dynamically route requests over the AWS network to the lowest latency copy of the data, improving performance by up to 60%.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-11T16:33:17.068653"}}
{"question": "When comparing S3 Replication and S3 Multi-Region Access Points, what are the main differences in their usage and associated costs?", "answer": "S3 Replication involves replicating objects from one region to another, incurring charges for storage in the destination region, replication requests, and inter-region data transfer. S3 Multi-Region Access Points, on the other hand, improve performance by automatically routing requests to the lowest latency copy of the data across multiple regions, without incurring additional replication costs.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-110", "source_tokens": 461, "generated_at": "2026-02-11T16:33:17.069094"}}
{"question": "What does S3 Multi- Region Access Points do to improve application performance?", "answer": "S3 Multi-Region Access Points reduce request latency, allowing applications to run up to 60% faster by dynamically routing S3 requests to replicated data sets.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-11T16:33:21.747932"}}
{"question": "How does S3 Multi-Region Access Points help in building resilient applications?", "answer": "S3 Multi-Region Access Points help build resilient, multi-region and multi-account applications by providing protection against accidental or unauthorized data deletion.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-11T16:33:21.748260"}}
{"question": "What's the difference between S3 Multi-Region Access Points and regular S3 buckets in terms of performance and data protection?", "answer": "S3 Multi-Region Access Points dynamically route requests to replicated data sets to reduce request latency and allow applications to run up to 60% faster. They also help build resilient applications by providing protection against accidental or unauthorized data deletion.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-111", "source_tokens": 133, "generated_at": "2026-02-11T16:33:21.748477"}}
{"question": "What regions can I configure a Multi-Region Access Point to route requests across?", "answer": "You can configure a Multi-Region Access Point to route requests across up to 17 AWS Regions.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-11T16:33:25.880445"}}
{"question": "How does an active-active configuration of S3 Multi-Region Access Points improve performance?", "answer": "An active-active configuration of S3 Multi-Region Access Points considers factors like network congestion and the location of the requesting application to dynamically route requests over the AWS network to the closest copy of your data. This improves performance by reducing network latency and jitter.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-11T16:33:25.880799"}}
{"question": "What is the difference between S3 Multi-Region Access Points and S3 CRR in terms of data management?", "answer": "S3 Multi-Region Access Points help manage requests across AWS Regions, while S3 CRR allows you to move data across AWS Regions to create isolated replicas.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-112", "source_tokens": 497, "generated_at": "2026-02-11T16:33:25.881263"}}
{"question": "What is the charge for routing requests through an S3 Multi-Region Access Point within AWS?", "answer": "A low per-GB data routing charge is paid for each GB processed, in addition to standard charges for S3 requests, storage, data transfer, and replication.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-11T16:33:30.305716"}}
{"question": "How does using an S3 Multi-Region Access Point improve performance for requests made over the internet?", "answer": "It automatically routes requests through an AWS edge location to the closest copy of the data based on access latency, increasing performance and reducing latency.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-11T16:33:30.305963"}}
{"question": "When is the data routing charge applied when using an S3 Multi-Region Access Point for internet acceleration?", "answer": "It is applied in addition to standard S3 data transfer pricing and varies based on whether the source client is in the same or in a different location as the destination AWS Region.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-113", "source_tokens": 386, "generated_at": "2026-02-11T16:33:30.306327"}}
{"question": "What are the benefits of using S3 Transfer Acceleration and S3 Multi-Region Access Points?", "answer": "S3 Transfer Acceleration and S3 Multi-Region Access Points both provide performance benefits by using the AWS global network to speed up content transfers to and from Amazon S3. S3 Transfer Acceleration helps accelerate long-distance transfers of larger objects to and from a single S3 bucket, while S3 Multi-Region Access Points enable similar accelerated transfers across many S3 buckets in multiple AWS Regions for internet-based, VPC-based, and on-premises requests.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-11T16:33:38.923064"}}
{"question": "How does S3 Multi-Region Access Points work and what are its advantages over S3 Transfer Acceleration?", "answer": "S3 Multi-Region Access Points is a feature that enables performing accelerated transfers using the AWS global network not only for a single S3 bucket but also for multiple S3 buckets in different AWS Regions. With S3 Multi-Region Access Points, you can dynamically route your requests to the lowest latency copy of your data for applications from clients in multiple locations. This advantage is not available with S3 Transfer Acceleration, which is limited to a single S3 bucket.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-11T16:33:38.923434"}}
{"question": "What's the difference between S3 Transfer Acceleration and S3 Multi-Region Access Points in terms of supported regions and data replication?", "answer": "S3 Transfer Acceleration is a feature that can help speed up content transfers to and from a single Amazon S3 bucket using the AWS global network. S3 Multi-Region Access Points, on the other hand, allow performing similar accelerated transfers across many S3 buckets in different AWS Regions. Additionally, when you combine S3 Multi-Region Access Points with S3 Cross Replication, you provide the capability for S3 Multi-Region Access Points to dynamically route your requests to the lowest latency copy of your data between the Regions and/or accounts.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-114", "source_tokens": 493, "generated_at": "2026-02-11T16:33:38.923998"}}
{"question": "What is the use of S3 Object Lambda for modifying data returned by S3 GET requests?", "answer": "S3 Object Lambda allows users to add custom code to modify and process data as it is returned by S3 GET requests. This can be used for filtering rows, dynamically resizing images, redacting confidential data, and other data format requirements without the need to build and operate additional infrastructure.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-11T16:33:44.777379"}}
{"question": "How does S3 Object Lambda help simplify data transformation for applications?", "answer": "S3 Object Lambda enables the automatic processing of the output of standard S3 GET, LIST, or HEAD requests using AWS Lambda functions. This eliminates the need for building and managing additional infrastructure like a proxy layer or maintaining multiple derivative copies of data.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-11T16:33:44.777743"}}
{"question": "What's the difference between using S3 Object Lambda for modifying S3 GET and LIST requests?", "answer": "S3 Object Lambda is used to modify and process data as it is returned by S3 GET requests. It can filter rows, dynamically resize images, redact confidential data, and more. On the other hand, S3 Object Lambda can also modify the output of S3 LIST requests to create a custom view of objects in a bucket.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-115", "source_tokens": 369, "generated_at": "2026-02-11T16:33:44.777962"}}
{"question": "What action triggers an S3 Object Lambda function?", "answer": "An S3 Object Lambda function is triggered by GET, LIST, and HEAD requests made through an S3 Object Lambda Access Point.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-11T16:33:49.622773"}}
{"question": "How does S3 Object Lambda enhance object lists?", "answer": "S3 Object Lambda can enrich object lists by querying an external index that contains additional object metadata. It can also filter and mask object lists to include only objects with a specific object tag, or add a file extension to all object names in the object lists.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-11T16:33:49.622989"}}
{"question": "What is the difference between using an S3 Object Lambda Access Point and a regular S3 Access Point?", "answer": "An S3 Object Lambda Access Point invokes a Lambda function when handling GET, LIST, and HEAD requests, while a regular S3 Access Point does not. The Lambda function can then process the S3 object and stream the processed object back to the calling client.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-116", "source_tokens": 402, "generated_at": "2026-02-11T16:33:49.623330"}}
{"question": "What steps are required to set up an S3 Object Lambda Access Point in the S3 console?", "answer": "To set up an S3 Object Lambda Access Point in the S3 console, you need to create an S3 Object Lambda Access Point, a Lambda function, and a supporting S3 Access Point. Grant permissions to all resources to interact with Object Lambda, and update your SDK and application to use the new S3 Object Lambda Access Point.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-11T16:33:55.769861"}}
{"question": "How does using an S3 Object Lambda Access Point alias impact my requests?", "answer": "An alias for an S3 Object Lambda Access Point is automatically generated and is interchangeable with S3 bucket names for data accessed through S3 Object Lambda. This means you can make requests using the alias instead of the actual S3 Object Lambda Access Point name.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-11T16:33:55.770062"}}
{"question": "What is the difference between processing requests with S3 Object Lambda and regular S3 API calls?", "answer": "With S3 Object Lambda, you supply your own Lambda function to run custom computations against GET, LIST, and HEAD requests. This gives you the flexibility to process data according to the needs of your application. In contrast, any other S3 API calls made to an S3 Object Lambda Access Point will return the standard S3 API response.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-117", "source_tokens": 472, "generated_at": "2026-02-11T16:33:55.770219"}}
{"question": "What information does AWS provide when an S3 Object Lambda function fails?", "answer": "AWS provides a request response detailing the failure.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-11T16:33:59.314909"}}
{"question": "Why does AWS automatically log requests processed by S3 Object Lambda?", "answer": "AWS logs requests processed by S3 Object Lambda to help users troubleshoot failures.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-11T16:33:59.315275"}}
{"question": "How does the pricing model for using S3 Object Lambda differ between GET, LIST, and HEAD requests?", "answer": "S3 Object Lambda charges for requests based on the request type, with different rates for GET, LIST, and HEAD requests.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-118", "source_tokens": 359, "generated_at": "2026-02-11T16:33:59.315716"}}
{"question": "What operating systems does Mountpoint for Amazon S3 support?", "answer": "Mountpoint for Amazon S3 works with the Linux operating system.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-11T16:34:04.330285"}}
{"question": "Why is Mountpoint for Amazon S3 suitable for read-heavy data lake workloads?", "answer": "Mountpoint for Amazon S3 is ideal for read-heavy data lake workloads because it achieves high single-instance throughput, is backed by AWS Support, and supports efficient use of network bandwidth and scalability to thousands of compute instances.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-11T16:34:04.330644"}}
{"question": "How does Mountpoint for Amazon S3 compare to Amazon FSx for Lustre for data lake applications?", "answer": "Mountpoint for Amazon S3 does not support modifying existing files or deleting existing directories, making it less suitable for applications that need collaboration and coordination across multiple compute instances or users. Amazon FSx for Lustre, on the other hand, provides POSIX semantics and shared file system features like appending to existing files and file locking.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-119", "source_tokens": 512, "generated_at": "2026-02-11T16:34:04.331085"}}
{"question": "What operations does Mountpoint for Amazon S3 support for S3 objects?", "answer": "Mountpoint for Amazon S3 supports sequential and random read operations for existing Amazon S3 objects, and sequential writes for new objects.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-11T16:34:09.460351"}}
{"question": "Why is Mountpoint for Amazon S3 performance comparable to AWS SDKs?", "answer": "Mountpoint for Amazon S3 delivers the same performance as the AWS SDKs because it translates file system operations like read and write into object API requests made to your S3 bucket, allowing data lake applications to efficiently utilize the available network bandwidth on their Amazon EC2 instance.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-11T16:34:09.460747"}}
{"question": "How does controlling access to data differ between AWS SDKs and Mountpoint for Amazon S3?", "answer": "When using Mountpoint for Amazon S3, access control to your data is managed using Amazon S3â€™s existing access control mechanisms, including bucket policies and IAM policies. In contrast, AWS SDKs do not have built-in access control mechanisms and rely on the developer to implement access control in their application logic.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-120", "source_tokens": 457, "generated_at": "2026-02-11T16:34:09.460965"}}
{"question": "What metadata does Mountpoint for Amazon S3 not support?", "answer": "Mountpoint for Amazon S3 does not support reading or writing POSIX-style metadata, such as user ID, group ID, and permission fields.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-11T16:34:14.864985"}}
{"question": "Why would you use Amazon FSx for Lustre or AWS DataSync for storing POSIX-style metadata for S3 objects?", "answer": "You would use Amazon FSx for Lustre or AWS DataSync to store POSIX-style metadata for S3 objects because Mountpoint for Amazon S3 does not support reading or writing this type of metadata.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-11T16:34:14.865307"}}
{"question": "How does accessing Amazon S3 from Amazon EKS using the Mountpoint for Amazon S3 CSI driver compare to using gateway VPC endpoints?", "answer": "Accessing Amazon S3 from Amazon EKS using the Mountpoint for Amazon S3 CSI driver allows for high levels of aggregate throughput without changing application code or permission model. In contrast, using gateway VPC endpoints for resources in the same AWS Region as the S3 bucket is not billed.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-121", "source_tokens": 458, "generated_at": "2026-02-11T16:34:14.865490"}}
{"question": "What is the purpose of using Storage Browser for Amazon S3 in web applications?", "answer": "Storage Browser for Amazon S3 is used to provide a simple interface for data stored in S3 for authorized end users to browse, download, upload, copy, and delete data in S3 directly from applications without having to write custom code.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-11T16:34:20.344681"}}
{"question": "How does one add Storage Browser to their application in three steps?", "answer": "First, import the NPM package of Storage Browser and add the necessary code to your application. Second, set up authorization by configuring Storage Browser to work with IAM Identity Center, Amazon Cognito, or your own custom authorization service. Third, configure cross-origin resource sharing rules and content security policies on the buckets you want to present to users within Storage Browser.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-11T16:34:20.344922"}}
{"question": "What are the benefits of using Storage Browser for S3 compared to developing custom code from scratch?", "answer": "Storage Browser for S3 allows for easier implementation in three steps, as it makes API calls to S3 on your behalf and allows for customization of the interface to match your applicationâ€™s design and branding.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-122", "source_tokens": 346, "generated_at": "2026-02-11T16:34:20.345100"}}
{"question": "What steps are required to use AWS managed authorization with S3 Access Grants and Storage Browser?", "answer": "First, you configure an IAM Identity Center and set up permission grants for your users and groups in S3 Access Grants. Then, you connect your application to Identity Center and configure it to exchange an identity token from your external Identity Provider with one from Identity Center. Next, you configure your application to provide the Identity Center token to Storage Browser. As an alternative, you can use Amazon Cognito to provide access credentials to Storage Browser. To do this, you set up an identity store in Cognito, associate it with an auth resource in Amplify, deploy the resource in Amplify, and connect your application code to your auth resource. Once you add Storage Browser to your application, it will authorize end-usersâ€™ data access on your behalf based on the authorization method you chose.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-11T16:34:29.773271"}}
{"question": "How does custom authorization work with Storage Browser and S3?", "answer": "To apply custom authorization, you configure your application to provide Storage Browser with STS tokens authorizing the user to work with S3 datasets they are permitted to access. In the session policy for each STS token, you must include the end-userâ€™s access levels for each S3 dataset they are authorized to access.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-11T16:34:29.773636"}}
{"question": "What are the main differences between using AWS Identity Center and Amazon Cognito for authorization with Storage Browser and S3?", "answer": "Both methods allow end-users to browse buckets and prefixes, sort by object metadata, and search for prefixes and objects by name. End-users can also upload, download, copy, and delete objects in S3. However, when using AWS Identity Center, you configure your application to exchange an identity token from your external Identity Provider with one from Identity Center, and then provide the Identity Center token to Storage Browser. With Amazon Cognito, you set up an identity store in Cognito, associate it with an auth resource in Amplify, deploy the resource in Amplify, and then connect your application code to your auth resource. The main difference is the way the authorization tokens are obtained and provided to Storage Browser.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-123", "source_tokens": 478, "generated_at": "2026-02-11T16:34:29.774095"}}
{"question": "What are the three steps to add Storage Browser to an application?", "answer": "First, import the NPM package of Storage Browser and add the required code in your application. Second, set up authorization by configuring Storage Browser to work with IAM Identity Center, Amazon Cognito, or your own custom authorization service. Third, configure cross-origin resource sharing rules and content security policies on the buckets to be presented to users within Storage Browser.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-11T16:34:35.854747"}}
{"question": "Why would you use Storage Browser for Amazon S3 in your applications?", "answer": "Storage Browser is a component that provides a simple UI for browsing, downloading, and uploading data in S3 without having to write custom code for this user experience. It can be customized to match an existing application's design and branding, and it makes API calls to S3 on behalf of the application.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-11T16:34:35.855124"}}
{"question": "How does the customization process for Storage Browser compare to implementing custom code for browsing S3 data?", "answer": "Customizing Storage Browser for your application involves importing the NPM package, setting up authorization, and configuring cross-origin resource sharing rules and content security policies. In contrast, implementing custom code for browsing S3 data from scratch requires writing and managing your own code for this user experience.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-124", "source_tokens": 410, "generated_at": "2026-02-11T16:34:35.855565"}}
{"question": "What steps are required to use AWS managed authorization with Storage Browser and S3?", "answer": "First, configure an IAM Identity Center and set up permission grants for users and groups in S3 Access Grants. Then, connect your application to Identity Center, configure it to provide Identity Center tokens to Storage Browser, and set up Cognito as an alternative. To apply custom authorization, configure your application to provide STS tokens with end-usersâ€™ access levels for each S3 dataset. Log any access to your data made through Storage Browser using AWS CloudTrail logs, which can be enabled for buckets used by Storage Browser.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-11T16:34:42.784283"}}
{"question": "What's the difference between using IAM Identity Center and Amazon Cognito for authorization in Storage Browser?", "answer": "Using IAM Identity Center involves configuring an Identity Center, setting up permission grants for users and groups in S3 Access Grants, connecting your application, and providing Identity Center tokens to Storage Browser. With Amazon Cognito, you set up an identity store, associate it with an auth resource in Amplify, deploy the resource, and connect your application code to the auth resource. Once you add Storage Browser to your application, it will authorize end-usersâ€™ data access on your behalf based on the method you chose.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-11T16:34:42.784649"}}
{"question": "What actions can end users perform with Storage Browser in S3?", "answer": "End users can browse buckets and prefixes, sort by object metadata, search for prefixes and objects by name, upload, download, copy, and delete objects in S3.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-125", "source_tokens": 478, "generated_at": "2026-02-11T16:34:42.785130"}}
{"question": "What aspects of the Storage Browser interface can be customized?", "answer": "The Storage Browser interface can be customized with a custom logo, primary colors, padding, alignment, language, and other elements. For a full list of customizable elements, refer to the AWS Amplify User Guide.", "question_type": "factual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-11T16:34:47.104760"}}
{"question": "How can you customize the look and feel of the Storage Browser interface?", "answer": "You can customize the look and feel of the Storage Browser interface by adding a custom logo and customizing primary colors, padding, alignment, language, and other aspects. Visit the AWS Amplify User Guide for details on how to do this.", "question_type": "conceptual", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-11T16:34:47.105167"}}
{"question": "How does customizing the Storage Browser interface compare to using the default settings?", "answer": "Customizing the Storage Browser interface allows you to match the interface to your application's design and branding, while using the default settings provides a standard look and feel. You can customize various aspects such as the logo, colors, padding, alignment, and language.", "question_type": "comparison", "metadata": {"service": "S3", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "s3-faq-126", "source_tokens": 64, "generated_at": "2026-02-11T16:34:47.105426"}}
{"question": "What is the new name of Amazon SageMaker as of December 03, 2024?", "answer": "Amazon SageMaker AI", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-11T16:34:52.234813"}}
{"question": "How does the renaming of Amazon SageMaker to Amazon SageMaker AI impact the existing features?", "answer": "The renaming does not apply to any of the existing Amazon SageMaker features. The sagemaker API namespaces and related namespaces remain unchanged for backward compatibility.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-11T16:34:52.235170"}}
{"question": "What are some of the key features of Amazon SageMaker AI for machine learning?", "answer": "Amazon SageMaker AI is a fully managed machine learning service that allows data scientists and developers to quickly and confidently build, train, and deploy ML models into a production-ready hosted environment. It provides managed ML algorithms to run efficiently against large data in a distributed environment and supports bring-your-own-algorithms and frameworks for flexible distributed training. Within a few steps, you can deploy a model into a secure and scalable environment.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-0", "source_tokens": 469, "generated_at": "2026-02-11T16:34:52.235660"}}
{"question": "What capabilities does the next generation of Amazon SageMaker include in regards to machine learning and analytics?", "answer": "The next generation of Amazon SageMaker includes the following capabilities: Amazon SageMaker AI for machine learning and foundation models with fully managed infrastructure, tools, and workflows; Amazon SageMaker Lakehouse for unified data access across various data sources; Amazon SageMaker Data and AI Governance for secure data and AI discovery, governance, and collaboration; SQL Analytics for price-performance SQL insights with Amazon Redshift; Amazon SageMaker Data Processing for data analysis, preparation, and integration using open-source frameworks on Amazon Athena, Amazon EMR, and AWS Glue; Amazon SageMaker Unified Studio for analytics and AI development in a single environment; and Amazon Bedrock for building and scaling generative AI applications.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-11T16:35:00.243932"}}
{"question": "What are the differences between the capabilities Amazon SageMaker and Amazon SageMaker Lakehouse?", "answer": "Amazon SageMaker is a capability for building, training, and deploying machine learning and foundation models with fully managed infrastructure, tools, and workflows. Amazon SageMaker Lakehouse is a capability for unified data access across Amazon S3 data lakes, Amazon Redshift, and other data sources.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-11T16:35:00.244196"}}
{"question": "In which service endpoints and resources can I find the 'sagemaker' prefix in the context of the next generation of Amazon SageMaker?", "answer": "The 'sagemaker' prefix can be found in the following service endpoints: Managed policies containing AmazonSageMaker prefixes, Service endpoints containing sagemaker, and Console URLs containing sagemaker. Additionally, it can be found in AWS CloudFormation resources containing AWS::SageMaker prefixes.", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-1", "source_tokens": 507, "generated_at": "2026-02-11T16:35:00.244356"}}
{"question": "What is Amazon SageMaker AI used for?", "answer": "Amazon SageMaker AI is used for building, training, and deploying machine learning and foundation models with fully managed infrastructure, tools, and workflows.", "question_type": "factual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-11T16:35:04.630287"}}
{"question": "How does Amazon SageMaker Lakehouse help with data access?", "answer": "Amazon SageMaker Lakehouse unifies data access across Amazon S3 data lakes, Amazon Redshift, and other data sources.", "question_type": "conceptual", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-11T16:35:04.630654"}}
{"question": "What's the difference between Amazon SageMaker and Amazon SageMaker Lakehouse?", "answer": "Amazon SageMaker is used for building, training, and deploying machine learning and foundation models. Amazon SageMaker Lakehouse is used for unifying data access across data lakes, Amazon Redshift, and other data sources.", "question_type": "comparison", "metadata": {"service": "SAGEMAKER", "doc_type": "Guide", "source_file": "whatis.html", "chunk_id": "sagemaker-whatis-2", "source_tokens": 291, "generated_at": "2026-02-11T16:35:04.631174"}}
{"question": "What type of secrets can AWS Secrets Manager help manage and protect?", "answer": "AWS Secrets Manager helps manage and protect access to applications, services, and IT resources by securely storing and retrieving database credentials, API keys, and other secrets.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-11T16:35:09.320907"}}
{"question": "Why would you use AWS Secrets Manager for managing secrets?", "answer": "AWS Secrets Manager is useful for IT administrators seeking a secure and scalable method to store and manage secrets. It also enables security administrators to monitor and rotate secrets to meet regulatory and compliance requirements, and allows developers to retrieve secrets programmatically for their applications.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-11T16:35:09.321307"}}
{"question": "How does AWS Secrets Manager compare to managing secrets manually?", "answer": "AWS Secrets Manager offers several advantages over managing secrets manually. It reduces the need for upfront investment and ongoing maintenance costs, enables secure and centralized storage, and facilitates easier access control, secret rotation, and monitoring.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-0", "source_tokens": 462, "generated_at": "2026-02-11T16:35:09.321796"}}
{"question": "What type of secrets can be managed using AWS Secrets Manager?", "answer": "AWS Secrets Manager can be used to manage secrets such as database credentials, on-premises resource credentials, SaaS application credentials, third-party API keys, and Secure Shell (SSH) keys.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T16:35:15.715442"}}
{"question": "How does the process of using AWS Secrets Manager work?", "answer": "To use AWS Secrets Manager, you first identify your secrets and locate where they are used in your applications. Then, you sign in to the AWS Management Console and navigate to the Secrets Manager console. Use the console to upload the secret, or use the AWS SDK or AWS CLI. If the secret is not in use yet, follow the instructions on the console to configure automatic rotation. If applications are using the secret, complete steps for uploading and configuring before rotation. If other users or applications need to retrieve the secret, write an IAM policy to grant permissions.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T16:35:15.715693"}}
{"question": "How does AWS Secrets Manager compare to managing secrets in plain text?", "answer": "Managing secrets in plain text involves storing them directly in source code or configuration files, which can pose a security risk. In contrast, AWS Secrets Manager provides a more secure way to manage secrets by encrypting them at rest and in transit. With Secrets Manager, you can also easily rotate credentials and control access to secrets through IAM policies.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-1", "source_tokens": 439, "generated_at": "2026-02-11T16:35:15.716097"}}
{"question": "What encryption method does AWS Secrets Manager use for encrypting secrets at rest?", "answer": "AWS Secrets Manager uses encryption keys that are owned by you and stored in AWS Key Management Service (KMS) to encrypt secrets at rest.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-11T16:35:20.228464"}}
{"question": "How does AWS Secrets Manager handle database credential authentication during rotation?", "answer": "AWS Secrets Manager does not re-authenticate open database connections during rotation. It creates a clone user with the same privileges and communicates the clone user information to databases and applications.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-11T16:35:20.228753"}}
{"question": "What is the difference between how AWS Secrets Manager handles access control for database credentials and IAM policies?", "answer": "AWS Secrets Manager uses encryption keys in AWS KMS to encrypt secrets at rest and transmits decrypted secrets over TLS to your local environment, while IAM policies control access to retrieve or manage specific secrets.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-2", "source_tokens": 353, "generated_at": "2026-02-11T16:35:20.228926"}}
{"question": "What encryption algorithm does AWS Secrets Manager use for envelope encryption?", "answer": "AWS Secrets Manager uses the AES-256 encryption algorithm for envelope encryption.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-11T16:35:24.304742"}}
{"question": "How does AWS Secrets Manager handle encryption keys when you first use the service?", "answer": "When you first use AWS Secrets Manager, you can specify the AWS KMS keys to encrypt secrets. If you do not provide a KMS key, Secrets Manager creates AWS KMS default keys for your account automatically.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-11T16:35:24.305117"}}
{"question": "How does AWS Secrets Manager compare data handling and storage to other encryption services?", "answer": "AWS Secrets Manager does not write or cache the plaintext secret to persistent storage. The data key is stored encrypted and is never written to disk in plaintext.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-3", "source_tokens": 305, "generated_at": "2026-02-11T16:35:24.305587"}}
{"question": "When does the 30-day free trial for AWS Secrets Manager start?", "answer": "The free trial starts when you store your first secret.", "question_type": "factual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-11T16:35:28.629422"}}
{"question": "What benefits can new AWS customers receive for Secrets Manager under the Free Tier program?", "answer": "New AWS customers can receive up to $200 in AWS Free Tier credits which can be applied towards Secrets Manager starting July 15, 2025. The free trial enables you to rotate, manage, and retrieve secrets for 6 months.", "question_type": "conceptual", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-11T16:35:28.629787"}}
{"question": "How does the Free Tier for Secrets Manager compare to the free plan?", "answer": "The primary difference is that under the Free Tier, new AWS customers receive $200 in credits which can be used for Secrets Manager, while the free plan is available for 6 months after account creation.", "question_type": "comparison", "metadata": {"service": "SECRETS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "secrets-faq-4", "source_tokens": 213, "generated_at": "2026-02-11T16:35:28.630317"}}
{"question": "What is the main function of AWS Security Hub CSPM?", "answer": "AWS Security Hub CSPM is a capability of AWS Security Hub that offers automated security best practice checks to help users understand their overall security posture across their AWS accounts.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-11T16:35:33.200800"}}
{"question": "How does AWS Security Hub CSPM help security teams?", "answer": "AWS Security Hub CSPM helps security teams by delivering essential security posture signals that work together with other security capabilities to prioritize security issues and help teams respond at scale.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-11T16:35:33.201167"}}
{"question": "What's the difference between AWS Security Hub and Security Hub CSPM in terms of functionality?", "answer": "AWS Security Hub is a unified cloud security solution that prioritizes critical security issues and helps respond at scale, while Security Hub CSPM is a capability of Security Hub that offers automated security best practice checks to help users understand their overall security posture.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-0", "source_tokens": 303, "generated_at": "2026-02-11T16:35:33.201574"}}
{"question": "What are the new capabilities of Security Hub beyond security findings aggregation and posture management?", "answer": "Security Hub now automatically correlates security signals across multiple capabilities including vulnerability management (Amazon Inspector), threat detection (Amazon GuardDuty), posture management (AWS Security Hub), and sensitive data discovery (Amazon Macie). This enhanced correlation helps identify critical security risks that might be missed when viewing findings in isolation.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T16:35:38.627562"}}
{"question": "How does the enhanced Security Hub solution help in making informed decisions about critical security issues?", "answer": "The enhanced Security Hub solution provides automatic correlation and enhanced risk context, enabling informed decisions about critical security issues.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T16:35:38.627940"}}
{"question": "How does Security Hub's threat detection capability (Amazon GuardDuty) compare to its vulnerability management capability (Amazon Inspector)?", "answer": "Security Hub's threat detection capability (Amazon GuardDuty) and vulnerability management capability (Amazon Inspector) are different security capabilities within the enhanced Security Hub solution. Threat detection helps identify and respond to unauthorized behavior, while vulnerability management helps identify and prioritize vulnerabilities for remediation.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-1", "source_tokens": 504, "generated_at": "2026-02-11T16:35:38.628347"}}
{"question": "What is the primary use case of AWS Security Hub?", "answer": "The primary use case of AWS Security Hub is to provide a unified cloud security solution to prioritize and help users respond to critical security issues, including security posture management.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-11T16:35:42.519208"}}
{"question": "How does AWS Security Hub help in security posture management?", "answer": "AWS Security Hub achieves security posture management through automated best practice checks and correlation across multiple security signals.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-11T16:35:42.519615"}}
{"question": "What are the differences between Security Hub and Security Hub CSPM in terms of data formats?", "answer": "Security Hub utilizes OCSF (Open Cybersecurity Schema Framework) and ASFF (AWS Security Finding Format) for data format.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-2", "source_tokens": 365, "generated_at": "2026-02-11T16:35:42.520054"}}
{"question": "What are the core capabilities of the Unified security solution in AWS Security Hub?", "answer": "The core capabilities of the Unified security solution in AWS Security Hub are Security Hub CSPM for posture management and Amazon Inspector for vulnerability management, which includes EC2 scanning, ECR container scanning, and AWS Lambda standard scanning.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:35:48.488511"}}
{"question": "How does managing security findings differ between the Unified and Individual approaches in AWS Security Hub?", "answer": "With the Unified approach, security findings are automatically correlated and prioritized, while with the Individual approach, you'll need to manually correlate findings to identify and prioritize critical security risks.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:35:48.488880"}}
{"question": "What are the differences in costs and capabilities between the Unified and Individual approaches in AWS Security Hub during the public preview period?", "answer": "During the public preview period, the enhanced AWS Security Hub capabilities are free of charge, but customers will still incur costs for the integrated capabilities like Amazon GuardDuty, Amazon Inspector, Amazon Macie, and AWS Security Hub CSPM. However, new customers can take advantage of the free trial period available for these underlying security capabilities. The Unified approach provides automated correlation and enhanced context across security signals, while the Individual approach allows for targeted use cases but requires manual correlation of findings.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-3", "source_tokens": 411, "generated_at": "2026-02-11T16:35:48.489307"}}
{"question": "Which regions does Security Hub support during its public preview period?", "answer": "Security Hub is available in the following regions during its public preview period: US East (N.Virginia), US East (Ohio), US West (N. California), US West (Oregon), Africa (Cape Town), Asia Pacific (Hong Kong), Asia Pacific (Jakarta), Asia Pacific (Mumbai), Asia Pacific (Osaka), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Milan), Europe (Paris), Europe (Paris), Europe (Stockholm), Middle East (Bahrain), and South America (SÃ£o Paolo).", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T16:35:55.010814"}}
{"question": "What are the benefits of enabling Amazon GuardDuty, Amazon Macie, and other Amazon Inspector capabilities in Security Hub?", "answer": "Enabling Amazon GuardDuty, Amazon Macie, and other Amazon Inspector capabilities in Security Hub provides comprehensive security coverage and allows you to fully benefit from Security Hub's automated correlation capabilities.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T16:35:55.011180"}}
{"question": "How does Security Hub CSPM compare to AWS Config?", "answer": "Security Hub CSPM, a core capability of Security Hub, requires AWS Config to be enabled and configured to record resource configuration changes, while the enhanced Security Hub does not require AWS Config. The primary difference is that Security Hub CSPM uses AWS Config data to identify potential misconfigurations in your resources.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-4", "source_tokens": 444, "generated_at": "2026-02-11T16:35:55.011689"}}
{"question": "What are the mechanisms Security Hub uses to help prioritize findings?", "answer": "Security Hub uses insights and security standards to help prioritize findings.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-11T16:35:58.933523"}}
{"question": "How does Security Hub help users identify priority security issues?", "answer": "Security Hub helps users identify priority security issues by analyzing resource relationships and signals from various AWS services and automatically generating exposure findings. These findings help users understand complex security scenarios and prioritize their response to critical issues.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-11T16:35:58.933888"}}
{"question": "What is the difference between insights and security standards in Security Hub?", "answer": "Insights are grouped or correlated findings that help users identify higher-priority findings faster, while security standards are sets of controls based on regulatory requirements or best practices that Security Hub uses for specific security checks.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-5", "source_tokens": 381, "generated_at": "2026-02-11T16:35:58.934373"}}
{"question": "What factors does Security Hub consider when calculating exposure finding severity?", "answer": "Security Hub considers multiple security traits, including ease of discovery, ease of exploit, likelihood of exploit, awareness, and impact to calculate the severity of exposure findings.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-11T16:36:03.303503"}}
{"question": "How does Security Hub determine the potential impact of an exposure?", "answer": "Security Hub assesses the potential harm if an exploit is carried out, considering loss of confidentiality, integrity, availability, or accountability.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-11T16:36:03.303870"}}
{"question": "What's the difference between the ease of discovery and the ease of exploit in Security Hub?", "answer": "Ease of discovery refers to the availability of automated tools to discover the resource at risk, while ease of exploit refers to how easily a threat actor can exploit the risk based on open network paths or misconfigured metadata.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-6", "source_tokens": 484, "generated_at": "2026-02-11T16:36:03.304387"}}
{"question": "What sources does Security Hub and Security Hub CSPM receive findings from?", "answer": "Security Hub receives findings from Security Hub CSPM, Amazon GuardDuty, Amazon Inspector, and Amazon Macie during the preview period. Security Hub CSPM receives findings from several AWS services such as AWS Config, AWS WAF, Amazon GuardDuty, Amazon Inspector, third-party Partner tools, and custom findings.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T16:36:08.397736"}}
{"question": "How does the format of findings differ between Security Hub and Security Hub CSPM?", "answer": "Security Hub uses the OCSF (Open Cybersecurity Schema Framework) format, while Security Hub CSPM uses the ASFF (AWS Security Finding Format).", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T16:36:08.398037"}}
{"question": "What is the difference in event delivery between Security Hub and Security Hub CSPM findings?", "answer": "Security Hub findings come through EventBridge with a detail type of 'Findings Imported V2'. Security Hub CSPM findings come through EventBridge with a detail type of 'Security Hub Findings â€“ Imported'.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-7", "source_tokens": 405, "generated_at": "2026-02-11T16:36:08.398215"}}
{"question": "Which resource types are available in the Security Hub resource list?", "answer": "The Security Hub resource list includes resource types that can be evaluated by Security Hub's security capabilities: Security Hub CSPM, Amazon Inspector, GuardDuty, and Macie.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:36:14.395813"}}
{"question": "Why is it beneficial to use a targeted view in Security Hub?", "answer": "The targeted view in Security Hub helps you identify and prioritize critical resources by displaying all publicly exposed assets across your cloud environment.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:36:14.396225"}}
{"question": "What are the differences in Delegated Administrator account management between Security Hub and Security Hub CSPM?", "answer": "If Security Hub CSPM defines the Delegated Administrator account as the organization management account, Security Hub can set the Delegated Administrator to an account of your choosing. If Security Hub CSPM does not have a Delegated Administrator account defined, Security Hub can also set the Delegated Administrator to an account of your choosing. However, if Security Hub CSPM defines the Delegated Administrator account as an account other than the organization management account, Security Hub will automatically set the Delegated Administrator account to the same account as Security Hub CSPM. Any changes to the Delegated Administrator account for either service will apply to both services.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:36:14.398028"}}
{"question": "What applies only to findings within Security Hub and what to these automation rules do?", "answer": "Automation rules in Security Hub apply only to findings within Security Hub. These rules can make updates to findings and automatically create tickets in Jira or ServiceNow.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T16:36:20.207059"}}
{"question": "How does Security Hub CSPM help maintain cloud security posture and what role does Security Hub play in this?", "answer": "Security Hub CSPM is a practice by which to identify misconfiguration issues and compliance risks across workloads, accounts, and resources to maintain cloud security posture. Security Hub is the AWS service for CSPM that performs security best practice checks, aggregates alerts, and helps enable automated remediation across AWS accounts, workloads, and resources.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T16:36:20.207430"}}
{"question": "What's the difference between Security Hub CSPM and Security Hub in terms of automation rules and managed insights?", "answer": "Security Hub CSPM and Security Hub each have their own automation rules. The automation rules in Security Hub CSPM apply only to findings within Security Hub CSPM, while those in Security Hub apply only to findings within Security Hub. Security Hub CSPM also offers managed insights, which are collections of related findings that help identify security issues.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-9", "source_tokens": 511, "generated_at": "2026-02-11T16:36:20.207609"}}
{"question": "What is the AWS Foundational Security Best Practices standard and how does it help users?", "answer": "The AWS Foundational Security Best Practices standard is a set of controls developed by AWS Security in collaboration with relevant service teams to detect when AWS accounts and resources deviate from security best practices. It lets users continuously evaluate all of their AWS accounts and workloads to quickly identify areas of deviation and provides actionable and prescriptive guidance about how to improve and maintain their organizationâ€™s security posture.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T16:36:27.046829"}}
{"question": "How does Security Hub CSPM differ from AWS Config conformance packs in terms of managing AWS Config rules?", "answer": "Security Hub CSPM is a core capability of AWS Security Hub that uses AWS Config and AWS Config rules to evaluate the configuration of AWS resources, while AWS Config conformance packs are suggested templates that package a group of AWS Config rules and associated remediation actions into a single entity to simplify deployment and reporting across an organization.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T16:36:27.047194"}}
{"question": "Why would you use Security Hub CSPM or AWS Config conformance packs for managing security and compliance in AWS?", "answer": "Security Hub CSPM is the easiest way to operationalize compliance standards that are already present in Security Hub CSPM, allowing users to investigate findings via Amazon Detective and build automated or semi-automated remediation actions using EventBridge. AWS Config conformance packs, on the other hand, enable users to assemble their own compliance or security standards, which may include security, operational, or cost optimization checks.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-10", "source_tokens": 508, "generated_at": "2026-02-11T16:36:27.047650"}}
{"question": "What is the role of Audit Manager in relation to Security Hub CSPM?", "answer": "Audit Manager is used to automatically collect and combine findings generated by Security Hub CSPM's automated security checks with other evidence, such as AWS CloudTrail logs, to help customers generate assessment reports.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-11T16:36:31.214206"}}
{"question": "Which AWS services are used for the automated evidence collection in Audit Manager?", "answer": "Audit Manager automatically collects the findings generated by Security Hub CSPM's security checks as a form of evidence.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-11T16:36:31.214477"}}
{"question": "What types of controls does Security Hub CSPM cover through its automated security checks in Audit Manager?", "answer": "Security Hub CSPM covers a subset of controls in each supported framework in Audit Manager and focuses on generating automated evidence via its security checks for these controls.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-11", "source_tokens": 234, "generated_at": "2026-02-11T16:36:31.214883"}}
{"question": "What are AWS Systems Manager's main components used for?", "answer": "AWS Systems Manager consists of Systems Manager OpsCenter, which helps IT operators and DevOps engineers diagnose and resolve operational issues related to AWS resources, and Systems Manager Explorer, an operations dashboard that provides a view of operations data across AWS accounts and Regions. ", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-11T16:36:35.818709"}}
{"question": "How does consolidating security and operational issues in Systems Manager benefit engineers?", "answer": "When the same engineers work on both security and operational issues, consolidating them in Systems Manager can help streamline the process by allowing engineers to investigate and remediate both types of issues in a single location.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-11T16:36:35.819047"}}
{"question": "What are the main differences between the use cases of Systems Manager and Security Hub?", "answer": "Systems Manager is used for managing operational issues related to AWS resources, while Security Hub is used for understanding, managing, and remedying security issues in AWS accounts and resources.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-12", "source_tokens": 299, "generated_at": "2026-02-11T16:36:35.819275"}}
{"question": "What services does Security Hub CSPM analyze security findings from?", "answer": "Security Hub CSPM analyzes security findings from services such as AWS Config, Amazon GuardDuty, AWS Health, Amazon Inspector, AWS Firewall Manager, AWS IAM Access Analyzer, AWS IoT Device Defender, and Amazon Macie.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-11T16:36:42.349845"}}
{"question": "How do Security Hub CSPM and AWS Control Tower work together?", "answer": "Security Hub CSPM and AWS Control Tower are complementary services that work together to help ensure the security of AWS accounts and resources. Security Hub CSPM performs security best practice checks against AWS Foundational Security Best Practices and other industry and regulatory standards, while AWS Control Tower sets up and governs a secure AWS environment based on AWS best practices and applies mandatory guardrails. They are fully integrated, allowing customers to enable over 170 Security Hub CSPM detective controls directly from AWS Control Tower.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-11T16:36:42.350211"}}
{"question": "How does Security Hub CSPM's capability to analyze findings from various AWS services compare to AWS Control Tower's preventative guardrails?", "answer": "Security Hub CSPM's capability to analyze findings from multiple AWS services allows for continuous monitoring and improvement of the security posture of AWS accounts and resources, while AWS Control Tower's preventative guardrails help enforce policies and detect policy violations. They are mutually reinforcing and help ensure that accounts and resources are in a secure state.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-13", "source_tokens": 388, "generated_at": "2026-02-11T16:36:42.350706"}}
{"question": "What capabilities need to be enabled separately during the preview period for the enhanced Security Hub?", "answer": "Security Hub CSPM, Amazon Inspector, Amazon GuardDuty, and Amazon Macie.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T16:36:46.725385"}}
{"question": "How does the enhanced Security Hub help prioritize and respond to critical security issues at scale?", "answer": "The enhanced Security Hub automatically correlates and enriches security signals across multiple capabilities, transforms them into actionable insights, and provides automated response workflows.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T16:36:46.725744"}}
{"question": "What is the main difference between Security Hub CSPM and the enhanced Security Hub in terms of capabilities?", "answer": "Security Hub CSPM focuses on automated security checks and creating scores against security standards, while the enhanced Security Hub provides additional capabilities like correlating and enricing security signals and providing automated response workflows.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-14", "source_tokens": 469, "generated_at": "2026-02-11T16:36:46.726244"}}
{"question": "What CIS AWS Foundations Benchmark versions does Security Hub CSPM support?", "answer": "Security Hub CSPM supports CIS AWS Foundations Benchmark v1.2.0 and v1.4.0.", "question_type": "factual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-11T16:36:50.874186"}}
{"question": "How does Security Hub CSPM relate to the CIS AWS Foundations Benchmark and NIST SP 800-53?", "answer": "Security Hub CSPM supports select CIS AWS Foundations Benchmark requirements and some NIST SP 800-53 requirements through automated security checks.", "question_type": "conceptual", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-11T16:36:50.874553"}}
{"question": "How does Security Hub CSPM's PCI DSS support compare between version 3.2.1 and version 4.0.1?", "answer": "No comparison information is provided in the context.", "question_type": "comparison", "metadata": {"service": "SECURITY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "security-faq-15", "source_tokens": 287, "generated_at": "2026-02-11T16:36:50.875045"}}
{"question": "What is AWS SAM and how does it work?", "answer": "AWS SAM is an open source framework for building serverless applications using shorthand syntax. During deployment, AWS SAM transforms the SAM syntax into AWS CloudFormation syntax, which provisions your resources. You define the application with just a few lines per resource using YAML. There is no additional charge to use AWS SAM; you pay for the AWS resources created in the same manner as if you created them manually.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-11T16:36:55.992879"}}
{"question": "Which runtimes can be used with AWS SAM?", "answer": "AWS SAM can be used to build serverless applications that use any runtime supported by AWS Lambda.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-11T16:36:55.993191"}}
{"question": "How does the AWS SAM CLI compare to local debugging in AWS Lambda?", "answer": "The AWS SAM CLI provides a Lambda-like execution environment locally, allowing you to locally build, test, and debug serverless applications defined by AWS SAM templates. This helps catch issues upfront before deploying to AWS Lambda.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 459, "generated_at": "2026-02-11T16:36:55.993585"}}
{"question": "What is an AWS SAM template file?", "answer": "An AWS SAM template file is a YAML configuration that declares all AWS resources for a serverless application.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-11T16:37:00.213047"}}
{"question": "How does the AWS SAM CLI support developing serverless applications?", "answer": "The AWS SAM CLI offers several commands, including local invocation and testing, package creation, deployment, and log retrieval, to help developers build, test, and deploy serverless applications.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-11T16:37:00.213418"}}
{"question": "What's the difference between the AWS SAM CLI 'sam init' and 'sam local' commands?", "answer": "The 'sam init' command generates a pre-configured AWS SAM template and sample application code, while the 'sam local' command supports local invocation and testing of functions and APIs.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 389, "generated_at": "2026-02-11T16:37:00.213890"}}
{"question": "What regions does the AWS Serverless Application Repository currently support?", "answer": "The AWS Serverless Application Repository is currently available in US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), and South America (SÃ£o Paulo).", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T16:37:06.252463"}}
{"question": "How does the AWS Serverless Application Repository help in using serverless applications?", "answer": "The AWS Serverless Application Repository makes it easy to find and deploy serverless applications for common use cases like web and mobile back-ends, stream processing, machine learning, and more. This helps users quickly get started with the AWS Serverless platform without having to build the applications from scratch.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T16:37:06.252835"}}
{"question": "How does the AWS Serverless Application Repository compare to self-developed serverless applications?", "answer": "Using applications from the AWS Serverless Application Repository allows users to quickly get started with common use cases without having to build the applications from scratch. However, self-developed applications offer the flexibility to customize functionality and integration with existing systems.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-0", "source_tokens": 465, "generated_at": "2026-02-11T16:37:06.253284"}}
{"question": "What open source licenses does AWS use for its applications?", "answer": "AWS uses the MIT open source license for its applications.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-11T16:37:10.244932"}}
{"question": "Why is it important to review the licensing details of third-party applications on the AWS website?", "answer": "It's important to review the licensing details of third-party applications to ensure you know which resources can be modified or accessed by the application.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-11T16:37:10.245329"}}
{"question": "How does the AWS Serverless Application Repository simplify the process of publishing and deploying serverless applications?", "answer": "The AWS Serverless Application Repository makes it easier to publish and deploy serverless applications by enabling developers to publish applications developed in a GitHub repository and managing them as AWS CloudFormation stacks.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-1", "source_tokens": 489, "generated_at": "2026-02-11T16:37:10.245772"}}
{"question": "What should be done to charge a fee for a serverless application and sell it as a SaaS product through AWS Marketplace?", "answer": "Integrate AWS Lambda behind Amazon API Gateway, list the API on AWS Marketplace, and monetize the API using API Gateway.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:37:15.443619"}}
{"question": "How can you manage and deploy nested applications in a serverless architecture?", "answer": "Use AWS CloudFormation nested stacks to deploy nested applications as part of new or existing application templates. Use the SAM CLI to package and publish the nested application to the Serverless Application Repository, and use the SAM CLI to deploy the application immediately.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:37:15.443900"}}
{"question": "What's the difference between deploying a single serverless application and deploying a serverless application with nested applications?", "answer": "A single serverless application is deployed as a single AWS CloudFormation stack, while a serverless application with nested applications is deployed as a hierarchy of AWS CloudFormation nested stacks. The top-level application can have a maximum of 199 nested applications.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-2", "source_tokens": 490, "generated_at": "2026-02-11T16:37:15.444308"}}
{"question": "What command can be used to ensure that nested applications are still available before deploying an application?", "answer": "The 'sam package' command can be used to ensure that nested applications are still available before deploying an application.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:37:19.848100"}}
{"question": "Why is it necessary to update an application when deploying it with dependencies that no longer exist?", "answer": "It is necessary to update an application when deploying it with dependencies that no longer exist because the application will not be able to function correctly without those dependencies.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:37:19.848349"}}
{"question": "Can you share a serverless application with all accounts in an AWS Organization? How about outside the organization?", "answer": "Yes, you can share a serverless application with all accounts that belong to an AWS Organization using AWS IAM resource-based policies. No, you cannot share a serverless application with accounts outside the organization in the same way.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:37:19.848503"}}
{"question": "What methods can be used to share applications within an AWS organizational unit?", "answer": "Sharing of applications within an organizational unit isnâ€™t supported. You can use policies to keep your app private, grant cross-account access, grant organization access or make it available publicly.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-11T16:37:24.100283"}}
{"question": "How can I grant access to my application to certain accounts within my AWS organizational unit?", "answer": "To provide access to your application for certain accounts in an organization, simply update the resource-based policy to include AWS accounts along with the AWS organization ID with whom you would like to share the application.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-11T16:37:24.100689"}}
{"question": "Can I set restrictions on the type of operations someone can take on a shared application?", "answer": "Yes. You can set actions on your resource-based policy which can restrict the type of operations someone can take on an application that you have shared.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-4", "source_tokens": 161, "generated_at": "2026-02-11T16:37:24.101127"}}
{"question": "What form can AWS customers submit their serverless applications to the Repository for private or specified AWS accounts?", "answer": "AWS customers can submit their serverless applications to the Repository in binary or source code form for private or specified AWS accounts.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T16:37:28.686560"}}
{"question": "Why is it necessary for publishers to submit the terms of their AWS Serverless Application's license when submitting to the Repository?", "answer": "Publishers must submit the terms of their AWS Serverless Application's license to the Repository to enable AWS customers to access the source code if it is made available to all AWS customers.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T16:37:28.686866"}}
{"question": "What rights does AWS gain when a publisher submits their serverless application to the Repository?", "answer": "AWS is granted the rights to reproduce, distribute, display publicly or within specified AWS accounts, perform, transmit, use and otherwise digitally make available the submitted AWS Serverless Application.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-5", "source_tokens": 475, "generated_at": "2026-02-11T16:37:28.687043"}}
{"question": "What is the legal status of AWS in relation to Publishers' licenses?", "answer": "AWS is not a party to Publishers' licenses and has no liability or obligations under them.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-11T16:37:32.218961"}}
{"question": "Why is AWS not responsible for ensuring compliance with licensing requirements in the Repository?", "answer": "According to the text, AWS has no liability or obligations to ensure Publishers or customers comply with licensing requirements.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-11T16:37:32.219327"}}
{"question": "How does AWS's liability for Repository Content compare to Publishers' liability?", "answer": "Both Publishers and AWS have disclaimed any warranties and liability for the Repository Content.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-6", "source_tokens": 278, "generated_at": "2026-02-11T16:37:32.219831"}}
{"question": "What is the request for in the text passage?", "answer": "The text passage is asking for feedback to improve the quality of the content on their pages.", "question_type": "factual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-11T16:37:35.295298"}}
{"question": "Why is feedback important for content quality?", "answer": "Feedback is important for identifying areas of improvement and ensuring that the content meets the needs and expectations of its audience.", "question_type": "conceptual", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-11T16:37:35.295651"}}
{"question": "How does feedback compare to content creation?", "answer": "Feedback is a critical step in the content creation process, as it allows for ongoing improvement and refinement based on user input.", "question_type": "comparison", "metadata": {"service": "SERVERLESS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "serverless-faq-7", "source_tokens": 17, "generated_at": "2026-02-11T16:37:35.296064"}}
{"question": "What is AWS Service Catalog and what does it allow IT administrators to do?", "answer": "AWS Service Catalog is a service that enables IT administrators to create, manage, and distribute catalogs of approved products to end users. They can also control user access to each product and enforce organizational business policies.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:37:41.072199"}}
{"question": "How can AWS Service Catalog help organizations and IT teams?", "answer": "AWS Service Catalog provides a standard method for organizations, IT teams, and managed service providers (MSPs) to centralize policies and centrally provision cloud resources for large numbers of users. It allows for increased agility and reduced costs by enabling end users to find and launch only the approved products they need from a catalog that is controlled by IT administrators.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:37:41.072566"}}
{"question": "What is the difference between AWS Service Catalog for IT administrators and end users?", "answer": "IT administrators use AWS Service Catalog to create, manage, and distribute catalogs of approved products to end users. They can also control user access to each product and enforce organizational business policies. End users, on the other hand, have a simple portal to discover and launch the products that administrators have created for them, ensuring they comply with organizational policies and budget constraints.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:37:41.072979"}}
{"question": "What regions can I create and manage portfolios and products in AWS Service Catalog?", "answer": "Portfolios and products in AWS Service Catalog are regional constructs that need to be created per region and are only visible/usable on the regions in which they were created.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-11T16:37:46.311314"}}
{"question": "How can I access AWS Service Catalog APIs from my Amazon Virtual Private Cloud (VPC)?", "answer": "You can privately access AWS Service Catalog APIs from your VPC by creating VPC Endpoints. VPC Endpoints allow the routing between the VPC and AWS Service Catalog to be handled by the AWS network without the need for an Internet gateway, NAT gateway, or VPN connection.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-11T16:37:46.311570"}}
{"question": "What are the benefits of using portfolios, sharing, and constraints in AWS Service Catalog?", "answer": "Using portfolios, sharing, and constraints in AWS Service Catalog allows administrators to ensure that users are launching products that are configured properly for the organizationâ€™s needs. This helps maintain security, compliance, and consistency across the organization.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-1", "source_tokens": 485, "generated_at": "2026-02-11T16:37:46.311954"}}
{"question": "What information should you provide when creating a portfolio in the AWS Service Catalog console?", "answer": "You should provide a name, description, and owner for each portfolio.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-11T16:37:50.543128"}}
{"question": "How are AWS Service Catalog products related to infrastructure-as-code (IaC) templates?", "answer": "Each AWS Service Catalog product is based on an IaC template. You can use CloudFormation templates or Terraform configurations to create a product.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-11T16:37:50.543529"}}
{"question": "What is the difference between adding tags to a portfolio and adding IAM users to a portfolio?", "answer": "Adding tags to a portfolio results in the tags being applied to all instances of resources provisioned from products in the portfolio. Adding IAM users to a portfolio allows them to browse and launch any of the products in the portfolio.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-2", "source_tokens": 400, "generated_at": "2026-02-11T16:37:50.544036"}}
{"question": "What account ID do I need to share my portfolio with?", "answer": "You specify the account ID of the account you want to share your portfolio with.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-11T16:37:54.874379"}}
{"question": "How does sharing a portfolio work and what rights does the recipient have?", "answer": "When you share your portfolio with another AWS account, you retain ownership and control, but the recipient can create a link and assign IAM users to it. They can see the products in the portfolio, but only you can make changes or unshare it.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-11T16:37:54.874626"}}
{"question": "What's the difference between sharing a portfolio and creating a product in AWS Service Catalog?", "answer": "Sharing a portfolio allows another AWS account to access and use the products in the portfolio, while creating a product in AWS Service Catalog creates a new product that can be made available to all users in your AWS account.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-3", "source_tokens": 432, "generated_at": "2026-02-11T16:37:54.875015"}}
{"question": "What type of role is used by AWS Service Catalog to provision resources?", "answer": "A specific IAM role is used by AWS Service Catalog to provision resources.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-11T16:37:58.915975"}}
{"question": "How do template constraints in AWS Service Catalog affect the provisioning of products?", "answer": "AWS Service Catalog applies the most restrictive template constraint among all constraints applied to the portfolio and the product when provisioning a new product or updating an existing one.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-11T16:37:58.916212"}}
{"question": "What are the language options for AWS Service Catalog templates and how does AWS Service Catalog handle conflicting constraints?", "answer": "AWS Service Catalog supports both JSON and YAML language templates. If there are conflicting template constraints, AWS Service Catalog applies the most restrictive one.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-4", "source_tokens": 306, "generated_at": "2026-02-11T16:37:58.916567"}}
{"question": "Which AWS regions support the use of the AWS Service Management Connector for ServiceNow and Jira Service Desk?", "answer": "The AWS Service Management Connector for ServiceNow and Jira Service Desk is available in all AWS regions where AWS Service Catalog is available.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-11T16:38:04.088252"}}
{"question": "How does the AWS Service Management Connector simplify cloud provisioning and resource management for ServiceNow and Jira Service Desk administrators?", "answer": "The AWS Service Management Connector simplifies cloud provisioning and resource management for ServiceNow and Jira Service Desk administrators by allowing them to configure the connector to work with existing or new AWS accounts and roles, and enabling ServiceNow and Jira Service Desk users to browse and request approved AWS products.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-11T16:38:04.088664"}}
{"question": "What information can be viewed on the Product details page for an AWS product in the AWS Service Catalog?", "answer": "The Product details page for an AWS product in the AWS Service Catalog displays information about the product, including the version, whether a newer version is available, a description, support information, and tags associated with the product. It also indicates whether the product will be provisioned using the user's access permissions or an administrator-specified role.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-5", "source_tokens": 461, "generated_at": "2026-02-11T16:38:04.088908"}}
{"question": "What happens after you choose 'Launch' for a product in the AWS Service Catalog portal?", "answer": "After choosing 'Launch', you will be guided through a series of questions about your business needs and infrastructure requirements. Once you have provided the required information, the product will be provisioned and you will see it in the AWS Service Catalog console with the status 'in progress'. After provisioning is complete, the status will change to 'complete' and you will see information such as endpoints or ARNs that you can use to access the product.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:38:10.692793"}}
{"question": "What is the purpose of the 'Update Stack' command in the context of using new versions of a product in AWS Service Catalog?", "answer": "The 'Update Stack' command allows you to use a new version of a product that has been published. If you are currently using a product for which there is an update, it will continue to run until you close it. At that point, you can choose to use the new version.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:38:10.693196"}}
{"question": "What are the main features of AWS Service Catalog that make it helpful for central IT teams using Terraform?", "answer": "AWS Service Catalog enables central IT teams to provide self-service provisioning with governance to their end users in AWS. It offers features such as cataloging of standardized and pre-approved templates, access control, least privileges during provisioning, versioning, sharing to thousands of AWS accounts, and tagging.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-6", "source_tokens": 496, "generated_at": "2026-02-11T16:38:10.693625"}}
{"question": "What setup is required to use AWS Service Catalog with Terraform open source?", "answer": "You need to create a Terraform open source engine in one of your accounts using the AWS provided Terraform Reference Engine. After the one-time setup, you can start creating Terraform open source type products in AWS Service Catalog.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-11T16:38:16.298022"}}
{"question": "How does using AWS Service Catalog with Terraform benefit teams using a mix of CloudFormation and Terraform configurations?", "answer": "AWS Service Catalog allows teams to catalog and share both CloudFormation and Terraform configurations as products. For end users, it provides a common interface to view and provision resources regardless of the IaC technology.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-11T16:38:16.298380"}}
{"question": "What's the difference between setting up AWS Service Catalog for Terraform open source and Terraform Cloud?", "answer": "For Terraform open source, you create a Terraform open source engine in your account and install it using the AWS provided Terraform Reference Engine. For Terraform Cloud, you use the Terraform Reference Engine for Terraform Cloud. In both cases, you can then create products and share them with other accounts.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-7", "source_tokens": 471, "generated_at": "2026-02-11T16:38:16.298860"}}
{"question": "What file format and compression is required for template files in AWS Service Catalog when syncing with GitHub, GitHub Enterprise, or Bitbucket?", "answer": "The template file format is required to be a single file archived in Tar and compressed in Gzip.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-11T16:38:22.161053"}}
{"question": "How does AWS Service Catalog AppRegistry help organizations manage their applications within their AWS environment?", "answer": "AWS Service Catalog AppRegistry allows organizations to define their applications, including a name, description, associated CloudFormation stacks, and application metadata represented by Attribute Groups. It provides a single, up-to-date definition of applications within the AWS environment.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-11T16:38:22.161427"}}
{"question": "What's the difference between AWS Service Catalog and AWS Service Catalog AppRegistry in terms of functionality?", "answer": "AWS Service Catalog is a service that enables organizations to create and manage catalogs of IT services that are approved for use. It allows you to centrally manage the discovery, delivery, and access to approved IT services. AWS Service Catalog AppRegistry, on the other hand, is a repository for the information that describes the applications and associated resources within your enterprise. It enables you to define your application, including a name, description, associated CloudFormation stacks, and application metadata.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-8", "source_tokens": 427, "generated_at": "2026-02-11T16:38:22.161862"}}
{"question": "What type of metadata can be included in an attribute group?", "answer": "An attribute group can include metadata such as application security classification, organizational ownership, application type, cost center, and support information.", "question_type": "factual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-11T16:38:26.163181"}}
{"question": "How does updating an attribute group affect associated applications?", "answer": "Updating an attribute group results in the updates being automatically reflected in all applications associated to the attribute group.", "question_type": "conceptual", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-11T16:38:26.163449"}}
{"question": "How does an attribute group compare to other methods of storing application metadata?", "answer": "An attribute group is a way to store and manage application metadata in a centralized and flexible manner. It includes an open JSON schema, allowing for the capture of complex enterprise metadata. Compared to other methods, such as manually managing metadata within each application, using attribute groups can save time and reduce errors.", "question_type": "comparison", "metadata": {"service": "SERVICECATALOG", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "servicecatalog-faq-9", "source_tokens": 125, "generated_at": "2026-02-11T16:38:26.163606"}}
{"question": "What is the main function of AWS Shield's Application layer (L7) DDoS protection?", "answer": "AWS Shield's Application layer (L7) DDoS protection defends applications against active web exploitation and distributed denial of service (DDoS) events.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-11T16:38:32.430800"}}
{"question": "How does the AWS Shield network security director help users?", "answer": "The AWS Shield network security director performs network security analysis to identify configuration issues and provides actionable remediation recommendations. It identifies and analyzes network resources, connections, and configurations against AWS best practices and threat intelligence to build a complete network topology, and aggregates findings into a comprehensive dashboard.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-11T16:38:32.431068"}}
{"question": "What are the differences between AWS Shield Standard and AWS Shield Advanced in terms of DDoS protection?", "answer": "AWS Shield Standard provides protection against common infrastructure (layer 3 and 4) events like SYN/UDP floods, reflection events, and others for all AWS customers to support high availability of applications on AWS. AWS Shield Advanced, on the other hand, offers always-on automatic mitigation of sophisticated DDoS events to minimize application downtime and latency. It also allows users to customize their DDoS protection strategy using application-specific security controls and provides expert guidance from the Shield Response Team during active DDoS incidents.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-0", "source_tokens": 434, "generated_at": "2026-02-11T16:38:32.431465"}}
{"question": "What resources does AWS Shield Advanced protect against DDoS attacks?", "answer": "AWS Shield Advanced protects Amazon EC2, Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator, and Route 53 resources against DDoS attacks.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T16:38:38.239341"}}
{"question": "How does AWS Shield Advanced help against large and sophisticated DDoS attacks?", "answer": "AWS Shield Advanced provides enhanced protections for applications running on protected Amazon EC2, Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator, and Route 53 resources against more sophisticated and larger attacks. It uses advanced attack mitigation and routing techniques for automatically mitigating attacks and provides always-on, flow-based monitoring of network traffic and active application monitoring to provide near real-time notifications of suspected DDoS incidents.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T16:38:38.239707"}}
{"question": "What is the difference between AWS Shield and AWS Shield Advanced in terms of network security?", "answer": "AWS Shield provides DDoS defense, while AWS Shield Advanced expands network security beyond DDoS defense and includes the AWS Shield network security director in preview which analyzes your network resources to provide comprehensive security solutions.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-1", "source_tokens": 476, "generated_at": "2026-02-11T16:38:38.240110"}}
{"question": "What resources can AWS Shield analyze for network security issues during a manual analysis?", "answer": "AWS Shield can analyze Amazon CloudFront distributions, Amazon Application Load Balancers, Amazon API Gateways, Amazon Virtual Private Clouds (VPCs), VPC Elastic Network Interfaces, VPC subnets, and Amazon EC2 instances in a single account during a manual analysis.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-11T16:38:43.592852"}}
{"question": "How does AWS Shield help users understand their network security and receive recommendations?", "answer": "AWS Shield helps users understand their network security by providing natural language analysis results and recommendations through Amazon Q Developer. It also allows users to initiate manual network security analyses and receive findings and remediation recommendations for 90 days after each analysis completes.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-11T16:38:43.593115"}}
{"question": "What is the difference between continuously monitored network security analysis and the manual analysis offered by AWS Shield?", "answer": "The main difference between continuously monitored network security analysis and the manual analysis offered by AWS Shield is that continuous analysis is not currently available in preview, and each manual analysis captures a snapshot of current resources and their configurations.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-2", "source_tokens": 510, "generated_at": "2026-02-11T16:38:43.593500"}}
{"question": "What network security issues can Amazon Q Developer help identify in an AWS account?", "answer": "Amazon Q Developer can help identify network security configuration issues in an AWS account, including issues related to WAF, security groups, and network ACLs.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:38:48.068449"}}
{"question": "How does AWS Shield supplement the definitions of network security controls?", "answer": "AWS Shield supplements the definitions of network security controls by recommending when and how certain network security services should be enabled based on a resource's network context.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:38:48.068882"}}
{"question": "How does AWS Shield compare in terms of DDoS protection between its standard and advanced versions?", "answer": "AWS Shield includes DDoS cost protection as a standard feature, while AWS Shield Advanced provides additional safeguards from scaling charges due to DDoS attacks and supports more protected resources.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:38:48.069279"}}
{"question": "Which AWS Regions offer the AWS Shield network security director for free during the preview period?", "answer": "US East (N. Virginia) and Europe (Stockholm)", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-11T16:38:55.317249"}}
{"question": "How does AWS Shield Advanced differ from AWS Shield Standard in terms of availability and protection?", "answer": "AWS Shield Standard is available on all AWS services in every AWS Region and AWS edge location worldwide, and it automatically provides protection against common infrastructure layer attacks. AWS Shield Advanced is available globally on all Amazon CloudFront, AWS Global Accelerator, and Amazon Route 53 edge locations worldwide, and it allows customers to protect web applications hosted anywhere in the world by deploying Amazon CloudFront in front of their application. Customers can also enable AWS Shield Advanced directly on Elastic Load Balancing or Amazon EC2 in certain AWS Regions. AWS Shield Standard provides protection against UDP floods, TCP SYN floods, and allows customers to use AWS WAF for application layer attack protection. AWS Shield Advanced provides additional protection and global availability.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-11T16:38:55.317494"}}
{"question": "Why would I choose to use AWS Shield Standard over AWS Shield Advanced, considering their differences in availability and protection?", "answer": "Your decision to use AWS Shield Standard over AWS Shield Advanced would depend on your specific use case and requirements. If you prefer to have your web applications protected against the most common infrastructure layer attacks and you are using services available in all AWS Regions, then AWS Shield Standard may be suitable for you. If you have web applications hosted anywhere in the world and you require additional protection and global availability, then AWS Shield Advanced may be the better choice.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-4", "source_tokens": 510, "generated_at": "2026-02-11T16:38:55.317874"}}
{"question": "What is the maximum number of AWS resources you can enable for AWS Shield Advanced protection for each supported resource type?", "answer": "You can enable up to 1000 AWS resources of each supported resource type for AWS Shield Advanced protection.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-11T16:38:59.788508"}}
{"question": "How does AWS Shield Advanced help in protecting application layer events?", "answer": "AWS Shield Advanced utilizes an AWS Managed Rule group and application layer (L7) DDoS protection to automatically detect and mitigate DDoS events within seconds.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-11T16:38:59.788905"}}
{"question": "What is the difference in DDoS protection between AWS Shield Standard and AWS Shield Advanced for application layer events?", "answer": "AWS Shield Standard automatically protects against common DDoS events, while AWS Shield Advanced includes enhanced application layer DDoS protection in addition to the standard protection.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-5", "source_tokens": 399, "generated_at": "2026-02-11T16:38:59.789363"}}
{"question": "What features does AWS Shield Advanced include for DDoS protection?", "answer": "AWS Shield Advanced includes DDoS protection for layers 3, 4, and 7, 24/7 support from the Shield Response Team (SRT), and cost protection against events spikes.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-11T16:39:04.144431"}}
{"question": "How can you engage the AWS Shield Response Team (SRT) during a DDoS incident?", "answer": "You can engage the AWS Shield Response Team (SRT) via regular AWS support or contact AWS Support.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-11T16:39:04.144865"}}
{"question": "How does pricing for AWS Shield Advanced DDoS protection beyond the included 50 billion requests per month differ?", "answer": "If an AWS Shield Advanced customer exceeds the included 50 billion AWS WAF requests per month, there will be an additional charge.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-6", "source_tokens": 491, "generated_at": "2026-02-11T16:39:04.145101"}}
{"question": "How long does it take for AWS Shield Advanced to notify customers of an event after detection?", "answer": "AWS Shield Advanced provides notification of an event within a few minutes of event detection.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-11T16:39:08.755860"}}
{"question": "What information does the Global threat environment dashboard in AWS Shield Advanced provide?", "answer": "The Global threat environment dashboard gives an anonymized and sampled view of all DDoS events seen on AWS within the last 2 weeks.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-11T16:39:08.756227"}}
{"question": "How does the AWS WAF application layer (L7) DDoS protection in AWS Shield Advanced compare to the one-minute metrics in CloudWatch?", "answer": "The AWS WAF application layer (L7) DDoS protection is a managed rule group that automatically detects and mitigates DDoS events, while one-minute metrics in CloudWatch provide real-time monitoring of AWS WAF usage.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-7", "source_tokens": 455, "generated_at": "2026-02-11T16:39:08.756688"}}
{"question": "What does AWS Shield Advanced do in response to DDoS events?", "answer": "AWS Shield Advanced responds to DDoS events by creating, evaluating, and deploying custom AWS WAF rules for protected resources.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T16:39:14.450531"}}
{"question": "How does application layer (L7) DDoS protection with AWS Shield Advanced differ from custom AWS WAF rules?", "answer": "Application layer (L7) DDoS protection is an additional feature included in AWS Shield Advanced, which can be used in conjunction with custom AWS WAF rules. It challenges suspicious traffic to verify its legitimacy, while custom AWS WAF rules are used for application protection based on specific rules set by the user.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T16:39:14.450926"}}
{"question": "What are the differences in pricing between AWS Shield Standard and AWS Shield Advanced for application layer (L7) DDoS protection?", "answer": "AWS Shield Standard does not require any additional purchase for application layer (L7) DDoS protection, as it is built into their existing services. AWS Shield Advanced customers, however, pay an additional monthly fee of $3,000 per month per organization and are limited to 50B AWS WAF requests per month.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-8", "source_tokens": 496, "generated_at": "2026-02-11T16:39:14.451379"}}
{"question": "What resources does AWS Shield Advanced allow you to protect and charge for?", "answer": "AWS Shield Advanced allows you to protect and charge for the resources that you choose to protect.", "question_type": "factual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-11T16:39:18.381065"}}
{"question": "How can multiple AWS accounts be subscribed to AWS Shield Advanced?", "answer": "Multiple AWS accounts can be subscribed to AWS Shield Advanced by individually enabling it on each account using the AWS Management Console or API.", "question_type": "conceptual", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-11T16:39:18.381427"}}
{"question": "How is the monthly fee for AWS Shield Advanced charged when there are multiple AWS accounts under a single consolidated billing?", "answer": "The monthly fee for AWS Shield Advanced is charged once when all the AWS accounts and resources in those accounts are owned by the same organization and are under a single consolidated billing.", "question_type": "comparison", "metadata": {"service": "SHIELD", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "shield-faq-9", "source_tokens": 115, "generated_at": "2026-02-11T16:39:18.381641"}}
{"question": "What is the main purpose of using AWS Snowball for data migration?", "answer": "AWS Snowball is used for accelerating the offline data or remote storage migration to the cloud, allowing users to move petabytes of data without storage capacity or compute power limits, and to run compute workloads with little or no connectivity.", "question_type": "conceptual", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T16:39:23.034747"}}
{"question": "What are the two types of AWS Snowball devices that can be selected in the console?", "answer": "The two types of AWS Snowball devices that can be selected in the console are AWS Snowball Edge Compute Optimized and AWS Snowball Edge Storage Optimized.", "question_type": "factual", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T16:39:23.035079"}}
{"question": "How does AWS Snowball compare to traditional data transfer methods for moving large datasets to the cloud?", "answer": "AWS Snowball allows for accelerating the offline data migration to the cloud without limitations in storage capacity or compute power, compared to traditional methods that might be limited by network conditions or storage capacity.", "question_type": "comparison", "metadata": {"service": "SNOW", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "snow-faq-0", "source_tokens": 447, "generated_at": "2026-02-11T16:39:23.035634"}}
{"question": "What is Amazon SNS and how does it work?", "answer": "Amazon SNS is a web service that enables developers to set up, operate, and send notifications from the cloud using the publish-subscribe (pub-sub) messaging paradigm. It follows a push mechanism to deliver notifications to clients, eliminating the need to poll for new information. Its features include simplicity, scalability, flexibility, cost-effectiveness, and easy integration with applications through simple APIs and pay-as-you-go pricing.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-11T16:39:29.150337"}}
{"question": "What are the key features of Amazon SNS related to quota and restrictions?", "answer": "Amazon SNS has features such as quotas and restrictions to ensure efficient usage. These features include managing message retention, limits on the number of topics and subscriptions, and allowing you to set up filters to control the delivery of messages.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-11T16:39:29.150721"}}
{"question": "How does Amazon SNS compare to other messaging services in terms of raw message delivery?", "answer": "Amazon SNS offers raw message delivery as a feature, enabling developers to receive messages without any additional processing. This can be useful when integrating with other systems that require raw data. However, it's essential to consider the specific use case and requirements when comparing Amazon SNS to other messaging services, as each may have unique features and advantages.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-0", "source_tokens": 415, "generated_at": "2026-02-11T16:39:29.151149"}}
{"question": "What protocols can Amazon SNS support for message delivery?", "answer": "Amazon SNS supports various protocols for message delivery including HTTP/HTTPS, email, and SMS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-11T16:39:33.653519"}}
{"question": "How does Amazon SNS help in building distributed applications?", "answer": "Amazon SNS helps in building distributed applications by offering instantaneous, push-based delivery, simple APIs, flexible message delivery, an inexpensive pay-as-you-go model, and a web-based management console.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-11T16:39:33.653741"}}
{"question": "How does Amazon SNS compare to other messaging services for asynchronous message delivery?", "answer": "Amazon SNS and Amazon SQS work together to provide reliable, asynchronous message delivery to one or many system components. While Amazon SNS is responsible for message publishing and delivery, Amazon SQS handles message queuing and consumer retrieval.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-1", "source_tokens": 506, "generated_at": "2026-02-11T16:39:33.653890"}}
{"question": "What is the difference between Amazon SQS and Amazon SNS in terms of message delivery mechanism?", "answer": "Amazon SQS is a message queue service that uses a polling model for message delivery, while Amazon SNS is a messaging service that uses a push mechanism.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T16:39:38.742631"}}
{"question": "What are the benefits of using Amazon SQS for message exchange between components in distributed applications?", "answer": "Amazon SQS allows distributed components of applications to send and receive messages without requiring each component to be concurrently available. It provides flexibility and decouples sending and receiving components.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T16:39:38.742997"}}
{"question": "How can I sign up for Amazon SNS and what prerequisites do I need to meet?", "answer": "To sign up for Amazon SNS, you need to have an Amazon Web Services account. You can sign up by clicking the â€˜Sign up for Amazon SNSâ€™ button on the Amazon SNS detail page. After signing up, please refer to the Amazon SNS documentation and Getting Started Guide to begin using Amazon SNS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-2", "source_tokens": 488, "generated_at": "2026-02-11T16:39:38.743513"}}
{"question": "What can you do in the AWS Management Console regarding Amazon SNS?", "answer": "You can create topics, add subscribers, send notifications, publish messages to your endpoint of choice, and edit topic policies to control access in the AWS Management Console.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-11T16:39:42.941115"}}
{"question": "How does using the AWS Management Console benefit you when working with Amazon SNS?", "answer": "Using the AWS Management Console for Amazon SNS allows you to access and manage your topics, add and remove subscribers, and send notifications, all from your browser.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-11T16:39:42.941479"}}
{"question": "What services can you publish messages to using Amazon SNS in the AWS Management Console?", "answer": "You can publish messages to HTTP, SQS, Lambda, mobile push, email, or SMS endpoints using Amazon SNS in the AWS Management Console.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-3", "source_tokens": 334, "generated_at": "2026-02-11T16:39:42.941967"}}
{"question": "What is the cost per million Amazon SNS requests?", "answer": "$0.50", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-11T16:39:46.689460"}}
{"question": "How does the pricing model for Amazon SNS work?", "answer": "Users pay based on the number of Amazon SNS requests and notifications delivered over HTTP, email, and SMS, with different charges for each delivery method. The service includes a Free Tier with certain usage limits.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-11T16:39:46.689817"}}
{"question": "What is the difference in cost between email and HTTP notification deliveries with Amazon SNS?", "answer": "$1.94 per 100,000 (email) vs. $0.06 per 100,000 (HTTP)", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-4", "source_tokens": 369, "generated_at": "2026-02-11T16:39:46.690026"}}
{"question": "What are the allowed characters for a topic name in AWS SNS?", "answer": "Topic names in AWS SNS are limited to 256 characters. Alphanumeric characters, hyphens (-), and underscores (_) are allowed.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-11T16:39:51.127505"}}
{"question": "How does Amazon SNS assign a unique ARN to a topic?", "answer": "Amazon SNS assigns a unique ARN (Amazon Resource Name) to a topic upon creation, which includes the service name (SNS), region, AWS ID of the user, and the topic name.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-11T16:39:51.127861"}}
{"question": "What's the difference between the ARN of a topic and its name?", "answer": "The ARN (Amazon Resource Name) is a unique identifier assigned by AWS SNS when a topic is created, while the topic name is the user-defined name given to the topic.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-5", "source_tokens": 512, "generated_at": "2026-02-11T16:39:51.128351"}}
{"question": "What API does a topic owner use to see the list of all subscribers to a specific topic?", "answer": "The ListSubscriptionsByTopic API", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-11T16:39:56.754301"}}
{"question": "How does a topic owner differ from a subscriber in terms of accessing the list of subscribers to an Amazon SNS topic?", "answer": "A topic owner can use the ListSubscriptionsByTopic API to see the list of all subscribers actively registered to a topic, while a subscriber uses the ListSubscriptions API to get a list of all their active subscriptions to one or more topics.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-11T16:39:56.754668"}}
{"question": "What are the differences between an SQS and an HTTPS endpoint for Amazon SNS notifications?", "answer": "With an SQS endpoint, users specify an Amazon Simple Queue Service (SQS) standard or FIFO queue as the endpoint. Amazon SNS enqueues a notification message to the specified queue, which subscribers can then process using SQS APIs like ReceiveMessage or DeleteMessage. In contrast, with an HTTP or HTTPS endpoint, subscribers specify a URL as part of the subscription registration. Notifications are delivered through an HTTP POST to the specified URL.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-6", "source_tokens": 370, "generated_at": "2026-02-11T16:39:56.755081"}}
{"question": "What is the purpose of message filtering in Amazon SNS?", "answer": "Message filtering in Amazon SNS allows subscribers to receive only a subset of messages they are interested in, instead of receiving all messages published to a topic.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-11T16:40:02.084432"}}
{"question": "How does an order processing workflow system use Amazon SNS with other AWS services?", "answer": "An order processing workflow system uses Amazon SNS to send notifications between application components whenever a transaction occurs or an order advances through the order processing pipeline. It integrates Amazon SNS with services like Amazon EC2, Amazon SQS, and SimpleDB to create a system where notifications can update all subscribers instantly and be persisted in a queue for future processing.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-11T16:40:02.084688"}}
{"question": "How does Amazon SNS message delivery compare to Amazon SQS message delivery?", "answer": "Amazon SNS is a pub/sub messaging service where messages are fan-out delivered to multiple subscribers, whereas Amazon SQS is a message queuing service where messages are stored and processed in a first-in-first-out (FIFO) manner.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-7", "source_tokens": 482, "generated_at": "2026-02-11T16:40:02.085058"}}
{"question": "How long does it take for a deleted SNS topic name to be available for reuse?", "answer": "The availability for reuse of a deleted SNS topic name typically ranges from 30-60 seconds, but the exact time depends on the number of subscriptions which were active on the topic.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:40:07.788016"}}
{"question": "What are the main differences between SNS FIFO topics and Kinesis Streams in terms of ordered, many-to-many messaging?", "answer": "Both SNS FIFO topics and Kinesis Streams enable the building of applications requiring strictly ordered, many-to-many messaging. However, SNS FIFO topics can further unlock application integration use cases with large ordered fan-out, up to 100 subscribers, while Kinesis Streams supports ordered fan-out up to 5 subscribers and is often used for analytics and anomaly detection use cases.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:40:07.788319"}}
{"question": "What are some example use cases for SNS FIFO topics with ordered message delivery?", "answer": "Example use cases for SNS FIFO topics include bank transaction logs, stock tickers, flight trackers, price updates, news broadcasting, and inventory management.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-8", "source_tokens": 398, "generated_at": "2026-02-11T16:40:07.788475"}}
{"question": "What email address should a subscriber provide for receiving notifications via Amazon SNS?", "answer": "A subscriber should provide a valid email address as the end-point when specifying â€˜Emailâ€™ or â€˜Email-JSONâ€™ as the protocol.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-11T16:40:13.013606"}}
{"question": "What are the two email transports provided by Amazon SNS and for what types of users are they intended?", "answer": "Amazon SNS provides two email transports: â€˜Emailâ€™ and â€˜Email-JSONâ€™. â€˜Emailâ€™ is meant for end-users/consumers and notifications are regular, text-based messages, while â€˜Email-JSONâ€™ is for applications to process emails as a JSON object.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-11T16:40:13.014005"}}
{"question": "How does the setting of the Subject field and Display name for topics in Amazon SNS differ?", "answer": "The Subject field for emails can be set as a parameter passed in to the Publish API call and can be different for every message published. The Display name for topics, on the other hand, can be set using the SetTopicAttributes API, and this name applies to all emails sent from this topic.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-9", "source_tokens": 496, "generated_at": "2026-02-11T16:40:13.014556"}}
{"question": "What is the process for subscribing an SQS queue to an Amazon SNS topic?", "answer": "To subscribe an SQS queue to an Amazon SNS topic, first create the SNS topic using Amazon SNS. Then, create and subscribe the SQS queue to the topic. Any message published to the topic will then be delivered to the specified SQS queue.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-11T16:40:18.332036"}}
{"question": "What happens when a user who owns an SNS topic also owns the SQS queue receiving the notifications?", "answer": "When a user who owns both the Amazon SNS topic and the SQS queue receives a message, the message will automatically be delivered to the specified SQS queue.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-11T16:40:18.332398"}}
{"question": "How does the delivery process differ between an SQS queue owned by the topic owner and an SQS queue owned by a different user?", "answer": "If the SQS queue owner is the same as the Amazon SNS topic owner, the message will be delivered automatically. If the SQS queue owner is different, Amazon SNS will require an explicit confirmation to the subscription request before delivering the message.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-10", "source_tokens": 299, "generated_at": "2026-02-11T16:40:18.332909"}}
{"question": "What information does a notification message sent by Amazon SNS include?", "answer": "A notification message sent by Amazon SNS includes a MessageId, Timestamp, TopicArn, Type, UnsubscribeURL, Message, Subject (if present), Signature, SignatureVersion, and the payload (body) of the message as received from the publisher.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-11T16:40:22.955255"}}
{"question": "How does the signature of a notification message from Amazon SNS get generated?", "answer": "The signature of a notification message from Amazon SNS is Base64-encoded â€˜SHA1withRSAâ€™ signature of the Message, MessageId, Subject (if present), Type, Timestamp, and TopicArn values.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-11T16:40:22.955613"}}
{"question": "What's the difference between creating a topic via the AWS Management Console and the CreateTopic API?", "answer": "Both the AWS Management Console and the CreateTopic API allow creating a topic. However, the AWS Management Console provides a graphical user interface and may be easier for users, while the CreateTopic API is a programmatic way to create topics.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-11", "source_tokens": 507, "generated_at": "2026-02-11T16:40:22.956019"}}
{"question": "What methods are there for users to receive notifications from Amazon SNS?", "answer": "Users can receive notifications from Amazon SNS in two ways: (1) users with AWS IDs can subscribe directly to a topic, and (2) topic owners can subscribe and register end-points on behalf of users without AWS IDs.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-11T16:40:27.724844"}}
{"question": "How does Amazon SNS handle user authentication for subscriptions?", "answer": "Amazon SNS validates the authenticity of all API calls by requiring requests to be signed with the secret key of the AWS ID account and verifying the signature included in the requests.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-11T16:40:27.725216"}}
{"question": "What's the difference between the subscription process for users with AWS IDs and users without AWS IDs?", "answer": "Users with AWS IDs can subscribe directly to a topic, while topic owners subscribe and register end-points on behalf of users without AWS IDs. In both cases, the owner of the subscription endpoint needs to confirm the subscription.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-12", "source_tokens": 224, "generated_at": "2026-02-11T16:40:27.725435"}}
{"question": "What is the timeframe for validity of tokens included in Amazon SNS confirmation messages?", "answer": "Tokens included in Amazon SNS confirmation messages are valid for 2 days.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-11T16:40:32.601990"}}
{"question": "How does the confirmation process work for email notifications in Amazon SNS?", "answer": "For email and Email-JSON notifications, Amazon SNS sends an email to the specified address containing an embedded link. The user needs to click on the embedded link to confirm the subscription request.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-11T16:40:32.602362"}}
{"question": "What's the difference in the confirmation process between HTTP/HTTPS and Email notifications in Amazon SNS?", "answer": "For HTTP/HTTPS notifications, Amazon SNS sends a confirmation message containing a token to the specified URL. The application monitoring the URL needs to call the ConfirmSubscription API with the token. For Email and Email-JSON notifications, Amazon SNS sends an email to the specified address containing an embedded link, and the user needs to click on the link to confirm the subscription request.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-13", "source_tokens": 419, "generated_at": "2026-02-11T16:40:32.602881"}}
{"question": "What cryptographic mechanism does Amazon SNS use to ensure the authenticity of notifications?", "answer": "Amazon SNS uses a cryptographically secure, asymmetric mechanism (private-public key pair based on certificates) to sign all notification deliveries.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T16:40:39.280467"}}
{"question": "How does the process of confirming subscriptions work in Amazon SNS?", "answer": "Amazon SNS requires publishers to sign messages with their secret AWS key, and subscribers can register SSL-enabled end-points to securely receive notifications. The owner of the end-point receiving the notifications has to grant permissions for Amazon SNS to send messages to that end-point. Subscriptions can be unsubscribed by the topic owner, the subscription owner, or others depending on the subscription confirmation method. Subscriptions confirmed with the AuthenticateOnUnsubscribe flag set to True can only be unsubscribed by the topic owner or the subscription owner, while anonymous subscriptions can be anonymously unsubscribed.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T16:40:39.280728"}}
{"question": "How does the security of messages compare between HTTP and HTTPS in Amazon SNS?", "answer": "In Amazon SNS, publishers can connect to Amazon SNS over HTTPS and publish messages over the SSL channel. Subscribers should register an SSL-enabled end-point as part of the subscription registration, and notifications will be delivered over a SSL channel to that end-point. This provides an additional layer of security compared to HTTP, where messages are not encrypted during transit.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-14", "source_tokens": 462, "generated_at": "2026-02-11T16:40:39.281119"}}
{"question": "What AWS service can be used to build HIPAA-compliant applications with an executed Business Associate Agreement (BAA) with AWS?", "answer": "Amazon SNS", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-11T16:40:43.779728"}}
{"question": "How does Amazon SNS ensure message durability even if there's a failure in one Availability Zone?", "answer": "Amazon SNS stores multiple copies of messages across multiple Availability Zones before acknowledging receipt of the publish request.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-11T16:40:43.780087"}}
{"question": "What is the difference between the message delivery experience when using a single Availability Zone versus multiple Availability Zones with Amazon SNS?", "answer": "Using a single Availability Zone ensures in-order message delivery at the publisher end but may not ensure message durability in case of a failure. Using multiple Availability Zones ensures message durability but may result in out-of-order message delivery at the subscriber end.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-15", "source_tokens": 468, "generated_at": "2026-02-11T16:40:43.780564"}}
{"question": "What happens when Amazon SNS cannot deliver a message to a subscribed endpoint?", "answer": "Amazon SNS discards the message if the endpoint is unreachable due to client-side or server-side errors, unless a dead-letter queue is attached to the subscription.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-11T16:40:48.356214"}}
{"question": "Why is it important to mark messages as Transactional or Promotional when sending SMS messages using Amazon SNS?", "answer": "Marking messages appropriately based on their content and intent helps ensure compliance with regulations and best practices in various destination countries.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-11T16:40:48.356573"}}
{"question": "How does the message delivery retry policy work in Amazon SNS compared to a dead-letter queue?", "answer": "The message delivery retry policy includes four phases: retries with no delay, minimum delay, back-off model, and maximum delay. A dead-letter queue (DLQ) is used when the message delivery retry policy is exhausted.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-16", "source_tokens": 499, "generated_at": "2026-02-11T16:40:48.357057"}}
{"question": "What types of Origination IDs are supported by AWS for SMS messaging?", "answer": "AWS supports various types of Origination IDs including short codes, long codes, 10DLC, and Sender IDs.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T16:40:54.329005"}}
{"question": "How does the process of managing Origination IDs for SMS messaging work in AWS?", "answer": "To manage Origination IDs for SMS messaging in AWS, you can visit 'Request a Phone Number' in the AWS End User Messaging usage guide to request and purchase origination IDs. These IDs are managed by AWS End User Messaging and can be used with Amazon SNS to send SMS. You can also see the list of origination IDs available in your account by visiting the AWS End User Messaging console.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T16:40:54.329367"}}
{"question": "How does the spend quota apply to sending SMS messages using AWS?", "answer": "Spend quotas can be specified for an AWS account and for individual messages when sending SMS messages using AWS. The quotas apply only to the cost of sending SMS messages. Once the spend quota for an account or an individual message is exceeded, Amazon SNS stops delivering messages until the quota is increased or a new calendar month begins.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-17", "source_tokens": 473, "generated_at": "2026-02-11T16:40:54.329852"}}
{"question": "What type of numbers can I reserve for two-way SMS messaging in Amazon SNS?", "answer": "You can reserve dedicated short codes, long codes, and other origination ID types for two-way SMS messaging in Amazon SNS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-11T16:40:58.478892"}}
{"question": "Why should I reserve a dedicated number for SMS messaging in Amazon SNS?", "answer": "Reserving a dedicated number for SMS messaging in Amazon SNS makes it easier for your audience to recognize that your organization is the source of your messages.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-11T16:40:58.479131"}}
{"question": "What type of numbers does Amazon SNS use for SMS messaging by default?", "answer": "Amazon SNS uses dedicated short codes, dedicated long codes, or a shared set of numbers depending on what's available in your account.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-18", "source_tokens": 493, "generated_at": "2026-02-11T16:40:58.479508"}}
{"question": "What information can be obtained about each message through Amazon SNS's Delivery Status feature?", "answer": "The Delivery Status feature provides information on the MessageID, Time Sent, Destination Phone Number, Disposition, Disposition Reason (if applicable), Price, and Dwell Time for each message.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-11T16:41:03.480440"}}
{"question": "Why does AWS recommend using E.164 number formatting for phone numbers in Amazon SNS?", "answer": "AWS recommends using E.164 number formatting for phone numbers in Amazon SNS to ensure compatibility with a comprehensive list of supported countries.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-11T16:41:03.480703"}}
{"question": "How does the process of receiving an opt-out message and handling it differ from the process of delivering an SMS message through Amazon SNS?", "answer": "When a recipient opts out of receiving messages from Amazon SNS, they no longer receive SMS messages from the account unless the phone number is opted in again. However, the phone number remains subscribed to the topic and no re-subscription is needed.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-19", "source_tokens": 497, "generated_at": "2026-02-11T16:41:03.481091"}}
{"question": "What is the charge for sending SMS messages via Amazon SNS API?", "answer": "$0.5 per million requests made to SNS", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-11T16:41:07.294712"}}
{"question": "How does Amazon SNS handle the sending of SMS messages with more than 140 bytes?", "answer": "Amazon SNS automatically splits long messages into multiple messages and charges for each individual message", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-11T16:41:07.295017"}}
{"question": "What's the difference in character limit between UCS-2 and GSM-7 encoding when sending SMS messages via Amazon SNS?", "answer": "UCS-2 encoding supports up to 70 characters per message, while GSM-7 encoding supports up to 160 characters", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-20", "source_tokens": 464, "generated_at": "2026-02-11T16:41:07.295188"}}
{"question": "What is the maximum size of a single Amazon SNS message that can be published?", "answer": "A single Amazon SNS message that can be published can contain up to 256 KB of text data.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-11T16:41:11.227082"}}
{"question": "Why does Amazon SNS split SMS messages that exceed the size limit?", "answer": "Amazon SNS splits SMS messages that exceed the size limit into smaller messages to ensure that each message fits within the size limit of 1600 bytes for a single publish action.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-11T16:41:11.227396"}}
{"question": "How does the message delivery format differ between raw and JSON format in Amazon SNS?", "answer": "By default, messages in Amazon SNS are delivered in JSON format, which provides metadata about the message and topic. However, you can opt-in to get messages delivered in raw form, which means exactly as you published them.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-21", "source_tokens": 492, "generated_at": "2026-02-11T16:41:11.227803"}}
{"question": "What endpoints support raw message delivery in SQS and HTTP(S) with AWS?", "answer": "SQS and HTTP(S) endpoints support raw message delivery in AWS.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:41:15.553681"}}
{"question": "How does SNS Mobile Push deliver notifications to users?", "answer": "SNS Mobile Push delivers notifications by popping a message on the user's device, which can launch the app to display more information.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:41:15.553955"}}
{"question": "Which push notification services are supported by SNS for different devices?", "answer": "SNS supports Amazon Device Messaging (ADM), Apple Push Notification Service (APNS), Firebase Cloud Messaging (FCM), Windows Push Notification Service (WNS), Microsoft Push Notification Service (MPNS), and Baidu Cloud Push for different devices.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:41:15.554126"}}
{"question": "What does SNS do when an end-user opts in to receive push notifications?", "answer": "SNS delivers push notifications to the end-user when they first run an app.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-11T16:41:19.135821"}}
{"question": "Why is SNS more flexible than Baidu Cloud Push when it comes to adding components to client code?", "answer": "SNS does not require any modifications to client app code to work properly, while Baidu Cloud Push does.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-11T16:41:19.136195"}}
{"question": "How does SNS compare to Baidu Cloud Push in terms of endpoint customization?", "answer": "SNS allows identical messages to be sent to all subscribers of a topic, while SNS also supports customized messages for different push notification platforms using platform-specific payloads.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-23", "source_tokens": 502, "generated_at": "2026-02-11T16:41:19.136676"}}
{"question": "Which mobile push endpoints support direct addressing in AWS SNS?", "answer": "Direct addressing is supported for mobile push endpoints including APNS, FCM, ADM, WNS, MPNS, and Baidu.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-11T16:41:24.014268"}}
{"question": "Why does SNS automatically update FCM tokens and how does it notify you?", "answer": "SNS automatically updates FCM tokens when a token is reported as invalid by FCM, and it notifies you of this change via an event. FCM also provides the new token associated with the application endpoint in its response to SNS.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-11T16:41:24.014465"}}
{"question": "How does the process of updating GCM tokens with SNS compare to updating FCM tokens?", "answer": "Both GCM and FCM device tokens can be used to send notifications with SNS. While SNS automatically updates FCM tokens when they are reported as invalid and provides the new token, there is no explicit mention of an automatic update process for GCM tokens in the given context.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-24", "source_tokens": 511, "generated_at": "2026-02-11T16:41:24.014584"}}
{"question": "What is the time limit for a message sent through SNS before it gets deleted?", "answer": "The time limit for a message sent through SNS before it gets deleted can be specified in seconds using the Time to Live (TTL) value.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-11T16:41:29.097925"}}
{"question": "How does SNS handle messages that are relevant or valuable for a limited time?", "answer": "SNS allows you to set a Time to Live (TTL) value for each message. When the TTL expires for a given message that was not delivered and read by an end user, the message is deleted.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-11T16:41:29.098250"}}
{"question": "What's the difference between the TTL handling for SQS and mobile push endpoints in SNS?", "answer": "For SQS endpoints, you can specify up to 10 name-type-value triples per message, including a TTL value in seconds. For mobile push endpoints, you can take advantage of specific message attributes that each mobile platform supports, but there is no mention of a TTL value in the context.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-25", "source_tokens": 505, "generated_at": "2026-02-11T16:41:29.098645"}}
{"question": "What is the default Time to Live (TTL) for SNS messages on mobile platforms?", "answer": "The default TTL for SNS messages on mobile platforms is 4 weeks.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-11T16:41:34.038954"}}
{"question": "How does specifying a TTL within the message payload affect SNS delivery?", "answer": "If you specify a TTL within the message payload and also within a message attribute, SNS will follow the message attribute. Some mobile platforms, like Apple (APNS) and Google (FCM), treat TTL = 0 as a special case and attempt to deliver the message immediately. In such cases, SNS will relay your message with TTL = 0 to take advantage of this special case.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-11T16:41:34.039235"}}
{"question": "Which mobile push endpoints support the use of TTL with Amazon SNS?", "answer": "The mobile push endpoints that support the use of TTL with Amazon SNS are APNS, APNS_Sandbox, FCM, ADM, Baidu, and WNS.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-26", "source_tokens": 456, "generated_at": "2026-02-11T16:41:34.039604"}}
{"question": "What is the cost of using Amazon SNS Delivery Status feature with CloudWatch?", "answer": "The cost of using Amazon SNS Delivery Status feature with CloudWatch depends on your usage of CloudWatch. For more information, you can refer to the pricing page on Amazon's website.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-11T16:41:40.173313"}}
{"question": "Why is it necessary to define a Log Metrics Filter in Amazon CloudWatch after activating the Delivery Status feature in Amazon SNS?", "answer": "Defining a Log Metrics Filter in Amazon CloudWatch after activating the Delivery Status feature in Amazon SNS allows you to extract and store information that you're interested in, such as failure rate and dwell time. This information can then be used to set alarms or send notifications based on defined thresholds.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-11T16:41:40.173728"}}
{"question": "How does Amazon SNS handle the invocation of AWS Lambda functions compared to delivering notifications to supported Amazon SNS destinations?", "answer": "Amazon SNS uses HTTP/2 with p12 certificates to invoke AWS Lambda functions by publishing messages to Amazon SNS topics that have AWS Lambda functions subscribed to them. Unlike delivering notifications to supported Amazon SNS destinations such as mobile push, HTTP endpoints, SQS, email and SMS, invoking AWS Lambda functions does not require any change in the application.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-27", "source_tokens": 471, "generated_at": "2026-02-11T16:41:40.174117"}}
{"question": "What is the cost of publishing a message with Amazon SNS to an AWS Lambda function?", "answer": "There are no additional fees for delivering a message to an AWS Lambda function aside from charges incurred in using AWS services.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-11T16:41:46.140728"}}
{"question": "What are the benefits of using an AWS Lambda function for custom message handling in Amazon SNS?", "answer": "You can invoke an AWS Lambda function to modify messages and filter and route them to other topics and endpoints. Apps and services that already send Amazon SNS notifications can take advantage of AWS Lambda without having to provision or manage infrastructure for custom message handling. You can also use delivery to an AWS Lambda function as a way to publish to other AWS services like Amazon Kinesis or Amazon S3.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-11T16:41:46.141079"}}
{"question": "What's the difference in delivery methods between publishing a message to an AWS Lambda function and another destination in Amazon SNS?", "answer": "When you publish a message to an AWS Lambda function via Amazon SNS, it creates an instance of the Lambda function and invokes it with your message as input. This delivery method is different from delivering messages to other destinations subscribed to the same topic, which may receive the message as a message payload or use it to trigger an event in their respective services.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-28", "source_tokens": 497, "generated_at": "2026-02-11T16:41:46.141292"}}
{"question": "What AWS services can't the account owner subscribe to each other's resources directly?", "answer": "AWS account owners cannot subscribe an AWS Lambda function that belongs to another account.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-11T16:41:50.193840"}}
{"question": "Why can't an AWS account owner directly subscribe another account's AWS Lambda function?", "answer": "This restriction is a security measure to prevent unintended access and ensure proper resource ownership.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-11T16:41:50.194134"}}
{"question": "What is the difference in subscription capabilities between an AWS account owner's AWS Lambda functions and those of another account?", "answer": "An account owner can subscribe their own AWS Lambda functions to their own or another account's Amazon SNS topics, but they cannot subscribe to another account's AWS Lambda functions.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-29", "source_tokens": 460, "generated_at": "2026-02-11T16:41:50.194526"}}
{"question": "What type of notifications does an iOS VoIP app register for in iOS 8 and later?", "answer": "An iOS VoIP app registers for VoIP remote notifications such that iOS can launch or wake the app, as appropriate, when an incoming VoIP call arrives for the user.", "question_type": "factual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-11T16:41:55.292127"}}
{"question": "How does the process for registering for VoIP notifications on iOS differ from regular push notifications?", "answer": "To register for VoIP notifications on iOS, you need to obtain the VoIP push notification certificate from Apple in addition to the regular push notification certificate and create a new Platform Application in Amazon SNS and choose Apple VoIP Push as the platform type.", "question_type": "conceptual", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-11T16:41:55.292407"}}
{"question": "What are the differences between registering for VoIP push notifications and regular push notifications on iOS?", "answer": "Both types of push notifications require registering with Amazon SNS, but for VoIP push notifications, you also need to obtain a VoIP push notification certificate from Apple and create a new Platform Application in Amazon SNS with Apple VoIP Push as the platform type.", "question_type": "comparison", "metadata": {"service": "SNS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sns-faq-30", "source_tokens": 213, "generated_at": "2026-02-11T16:41:55.292756"}}
{"question": "What type of messaging service does Amazon SQS provide and how does it compare to Amazon SNS?", "answer": "Amazon SQS is a message queue service used by distributed applications to exchange messages through a polling model. In contrast, Amazon SNS allows applications to send time-critical messages to multiple subscribers through a 'push' mechanism, eliminating the need to periodically check or 'poll' for updates.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:42:00.786489"}}
{"question": "What advantages does Amazon SQS have over building your own message queue software or using commercial/open-source message queuing systems?", "answer": "Amazon SQS requires no administrative overhead and little configuration. It works on a massive scale, processing billions of messages per day. The service provides extremely high message durability and allows scaling traffic up or down without any configuration.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:42:00.786781"}}
{"question": "How does the security and reliability of Amazon SQS compare to other solutions?", "answer": "Amazon SQS offers advantages over other solutions in terms of security and reliability, providing no administrative overhead and little configuration. It also offers extremely high message durability and can be used on a massive scale.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-0", "source_tokens": 384, "generated_at": "2026-02-11T16:42:00.787182"}}
{"question": "What is the cost structure for using Amazon SQS?", "answer": "The cost of Amazon SQS is calculated per request, plus data transfer charges for data transferred out of Amazon SQS. For detailed pricing breakdowns per queue type and region, see Amazon SQS Pricing.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T16:42:11.521354"}}
{"question": "How does Amazon Kinesis Streams differ from Amazon SQS in terms of data processing?", "answer": "Amazon SQS offers a reliable, highly-scalable hosted queue for storing messages between applications or microservices and helps decouple components. Amazon Kinesis Streams, on the other hand, allows real-time processing of streaming big data and the ability to read and replay records to multiple applications for easier development of multiple applications that read from the same stream.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T16:42:11.522318"}}
{"question": "What are the main differences between using Amazon SQS for message processing and Amazon Kinesis Streams for real-time data processing?", "answer": "Amazon SQS offers message queuing and decoupling functionality, while Amazon Kinesis Streams provides real-time processing capabilities and the ability to read and replay records to multiple applications.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-2", "source_tokens": 476, "generated_at": "2026-02-11T16:42:11.522505"}}
{"question": "What is the cost of using batch operations in Amazon SQS?", "answer": "The cost of using batch operations (SendMessageBatch, DeleteMessageBatch, ChangeMessageVisibilityBatch) in Amazon SQS is the same as other Amazon SQS requests.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T16:42:16.172710"}}
{"question": "Why can tagging and tracking queues in Amazon SQS be beneficial?", "answer": "Tagging and tracking queues in Amazon SQS can be beneficial for resource and cost management as you can categorize and track your costs based on these cost centers.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T16:42:16.172978"}}
{"question": "How does using Amazon SQS with compute services like EC2 and ECS differ from using it with storage and database services like S3 and DynamoDB?", "answer": "Using Amazon SQS with compute services like EC2 and ECS allows for more flexibility and scalability compared to using it with storage and database services like S3 and DynamoDB.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-3", "source_tokens": 492, "generated_at": "2026-02-11T16:42:16.173331"}}
{"question": "What is required to perform operations on an Amazon SQS message queue?", "answer": "Only an AWS account owner or an AWS account with delegated rights can perform operations on an Amazon SQS message queue.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:42:20.352137"}}
{"question": "How can developers implement JMS on Amazon SQS?", "answer": "Developers can use the Amazon SQS Java Messaging Library, which implements the JMS 1.1 specification and uses Amazon SQS as the JMS provider.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:42:20.352392"}}
{"question": "What happens to messages in a dead letter queue in Amazon SQS?", "answer": "Dead letter queues in Amazon SQS receive messages after a maximum number of processing attempts cannot be completed. They can be used to isolate messages that can't be processed for later analysis.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-4", "source_tokens": 468, "generated_at": "2026-02-11T16:42:20.352547"}}
{"question": "What is the maximum number of metadata attributes an Amazon SQS message can contain?", "answer": "An Amazon SQS message can contain up to 10 metadata attributes.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-11T16:42:24.437504"}}
{"question": "How do message attributes help in processing Amazon SQS messages?", "answer": "Message attributes help process and store Amazon SQS messages with greater speed and efficiency by allowing applications to understand the metadata of a message without having to inspect the entire message.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-11T16:42:24.437798"}}
{"question": "What is the difference between long polling and short polling in Amazon SQS?", "answer": "Short polling returns immediately, even if the message queue being polled is empty. Long polling doesnâ€™t return a response until a message arrives in the message queue, or the long poll times out. Long polling can reduce the cost of using SQS by reducing the number of empty receives, but it is billed the same as short polling.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-5", "source_tokens": 414, "generated_at": "2026-02-11T16:42:24.438189"}}
{"question": "What is the advantage of using long polling over short polling in Amazon SQS?", "answer": "Long polling lets consumers receive messages as soon as they arrive in the queue while reducing the number of empty ReceiveMessageResponse instances returned.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-11T16:42:28.968397"}}
{"question": "How does using long polling instead of short polling affect application performance in Amazon SQS?", "answer": "Long polling results in higher performance and reduced cost in most Amazon SQS use cases by letting consumers receive messages as soon as they arrive and reducing the number of empty responses.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-11T16:42:28.968668"}}
{"question": "What's the difference between long polling and short polling in terms of timeout values in Amazon SQS?", "answer": "Long polling has a longer timeout (up to 20 seconds by default) than short polling, which reduces the number of empty responses but may not be suitable for applications that expect an immediate response.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-6", "source_tokens": 385, "generated_at": "2026-02-11T16:42:28.969061"}}
{"question": "What features does the AmazonSQSBufferedAsyncClient for Java provide that are not available in the AmazonSQSAsyncClient?", "answer": "The AmazonSQSBufferedAsyncClient for Java provides automatic batching and prefetching of messages, which are not available in the AmazonSQSAsyncClient.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T16:42:33.478382"}}
{"question": "How does the use of the AmazonSQSBufferedAsyncClient for Java impact the throughput and latency of an application?", "answer": "The use of the AmazonSQSBufferedAsyncClient for Java increases the throughput and reduces the latency of an application by automatically batching and prefetching messages.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T16:42:33.478723"}}
{"question": "What action can be used to delete all messages in an Amazon SQS message queue?", "answer": "The PurgeQueue action can be used to delete all messages in an Amazon SQS message queue.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-7", "source_tokens": 487, "generated_at": "2026-02-11T16:42:33.479133"}}
{"question": "In which AWS regions are FIFO queues available?", "answer": "FIFO queues are available in all AWS regions where Amazon SQS is available.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-11T16:42:37.922094"}}
{"question": "Why do FIFO queues prevent duplicate messages?", "answer": "FIFO queues prevent duplicate messages by providing deduplication functionality through the SQS APIs. Any duplicates introduced by the message producer are removed within a 5-minute deduplication interval.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-11T16:42:37.922393"}}
{"question": "How does the functionality of FIFO queues compare to standard queues?", "answer": "Both FIFO and standard queues have different uses. FIFO queues provide ordering guarantees and prevent duplicate messages, whereas standard queues provide the highest scalability and throughput but might deliver duplicate messages. Applications using standard queues must be idempotent to handle duplicate messages.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-8", "source_tokens": 454, "generated_at": "2026-02-11T16:42:37.922747"}}
{"question": "Which AWS services are not compatible with FIFO queues in Amazon SQS?", "answer": "Auto Scaling Lifecycle Hooks, AWS IoT Rule Actions, and AWS Lambda Dead Letter Queues", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-11T16:42:42.219304"}}
{"question": "How does Amazon SQS handle messages with the same message group ID when using FIFO queues?", "answer": "Amazon SQS delivers the messages in the order in which they arrive for processing, ensuring that the order in which messages are sent and received is preserved", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-11T16:42:42.219585"}}
{"question": "How does the compatibility of FIFO queues with the Amazon SQS Extended Client Library for Java and JMS client compare to their incompatibility with the Buffered Asynchronous Client?", "answer": "FIFO queues are compatible with the Amazon SQS Extended Client Library for Java and the Amazon SQS Java Message Service (JMS) client, but not with the Buffered Asynchronous Client", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-9", "source_tokens": 481, "generated_at": "2026-02-11T16:42:42.219982"}}
{"question": "What suffix indicates that a SQS queue is a FIFO queue?", "answer": ".fifo", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T16:42:46.466974"}}
{"question": "How does Amazon SQS ensure fairness among tenants in FIFO queues?", "answer": "Fair queues in Amazon SQS FIFO queues maintain consistent time between sending and receiving messages across all tenants, ensuring other tenants' messages maintain low dwell time and preserving quality of service for all.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T16:42:46.467249"}}
{"question": "What is the difference in message throughput between a standard FIFO queue and a high throughput FIFO queue?", "answer": "By default, FIFO queues support up to 3,000 messages per second with batching or up to 300 messages per second without batching. In contrast, high throughput FIFO queues support up to 70,000 messages per second without batching and even higher with batching.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-10", "source_tokens": 477, "generated_at": "2026-02-11T16:42:46.467640"}}
{"question": "What is the purpose of using fair queues in a multi-tenant Amazon SQS queue?", "answer": "Fair queues are used in a multi-tenant Amazon SQS queue when consistent, low message dwell time is critical for all tenants. They help maintain consistent dwell times across tenants by reordering messages when a single tenant causes a queue backlog.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-11T16:42:52.498173"}}
{"question": "How does enabling fair queues impact the throughput capability of an Amazon SQS standard queue?", "answer": "Enabling fair queues on an Amazon SQS standard queue maintains the same high throughput capabilities as standard queues. Fair queues only reorder messages to help maintain consistent dwell time across tenants, without imposing throughput limitations.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-11T16:42:52.498482"}}
{"question": "What is the difference between fair queues and FIFO queues in terms of tenant resource allocation and message processing?", "answer": "Fair queues and FIFO queues have different approaches to resource allocation and message processing for tenants. Fair queues allow multiple consumers to process messages from the same tenant concurrently and prioritize messages from tenants that are not causing backlogs. FIFO queues maintain strict ordering and limit the number of in-flight messages from each tenant to prevent noisy neighbors but limit throughput for each tenant.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-11", "source_tokens": 445, "generated_at": "2026-02-11T16:42:52.498882"}}
{"question": "What metrics does AWS CloudWatch provide for fair queues?", "answer": "AWS CloudWatch provides several metrics specific to fair queues, including the number of noisy neighbors detected, message count for quiet tenants, and dwell time statistics.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-11T16:42:57.170411"}}
{"question": "How can you use message group IDs with fair queues to optimize costs?", "answer": "By selectively applying message group IDs, messages without a message group ID can be treated as belonging to unique tenants, allowing you to mitigate noisy neighbor impact and optimize costs.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-11T16:42:57.170769"}}
{"question": "What security features does Amazon SQS provide for message queues?", "answer": "Amazon SQS provides several security features, including its own resource-based permissions system, support for HTTP over SSL (HTTPS) and Transport Layer Security (TLS) protocols, and the ability to build applications to encrypt messages before they are placed in a message queue.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-12", "source_tokens": 506, "generated_at": "2026-02-11T16:42:57.171168"}}
{"question": "What happens to a message in Amazon SQS once it's returned to the sender?", "answer": "The message stays in the message queue whether or not the sender actually receives it. The sender is responsible for deleting the message.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-11T16:43:01.719822"}}
{"question": "Why might you receive a previously-deleted message a second time in standard Amazon SQS queues?", "answer": "Under rare circumstances, you might receive a previously-deleted message a second time.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-11T16:43:01.720123"}}
{"question": "How does server-side encryption (SSE) in Amazon SQS compare to encryption in other AWS services like Amazon S3?", "answer": "Both SSE in Amazon SQS and encryption in Amazon S3 encrypt data using keys managed in AWS KMS. However, SSE in Amazon SQS encrypts messages as soon as they're received, while encryption in Amazon S3 is applied when data is being written.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-13", "source_tokens": 389, "generated_at": "2026-02-11T16:43:01.720528"}}
{"question": "What attribute should be set to enable SSE for a new or existing Amazon SQS queue using the API?", "answer": "The KmsMasterKeyId attribute should be set with the ID of the customer master key (CMK) for Amazon SQS.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-11T16:43:05.912695"}}
{"question": "Why is it necessary to configure AWS KMS key policies for SSE in Amazon SQS?", "answer": "It is necessary to configure AWS KMS key policies to allow encryption of queues and encryption and decryption of messages to enable SSE in Amazon SQS.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-11T16:43:05.913041"}}
{"question": "What permissions are required for a producer to send messages to an encrypted Amazon SQS queue?", "answer": "The producer must have the kms:GenerateDataKey and kms:Decrypt permissions for the CMK.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-14", "source_tokens": 472, "generated_at": "2026-02-11T16:43:05.913211"}}
{"question": "What components does SSE encrypt in an Amazon SQS queue?", "answer": "SSE encrypts the body of a message in an Amazon SQS queue.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-11T16:43:09.059211"}}
{"question": "How does SSE encryption impact the queue metadata?", "answer": "SSE doesn't encrypt the queue metadata (queue name and attributes).", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-11T16:43:09.059520"}}
{"question": "What are the differences between the encryption of message bodies and queue metadata in Amazon SQS using SSE?", "answer": "SSE encrypts the message body using the AES-GCM 256 algorithm, while queue metadata (queue name and attributes) is not encrypted.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-15", "source_tokens": 420, "generated_at": "2026-02-11T16:43:09.059700"}}
{"question": "What is the formula to calculate the number of API requests per queue in Amazon SQS?", "answer": "The number of API requests per queue (R) can be calculated using the formula: R = B / D * (2 * P + C)", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-11T16:43:13.626895"}}
{"question": "How does the data key reuse period affect the cost of using Amazon SQS?", "answer": "The data key reuse period in Amazon SQS affects the cost by influencing the number of API requests. A shorter reuse period results in more requests and higher cost, while a longer reuse period reduces the number of requests and lowers the cost. Producers incur double the cost of consumers.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-11T16:43:13.627208"}}
{"question": "How does the cost of using Amazon SQS with separate IAM users for producers and consumers compare to using the same IAM user?", "answer": "Using separate IAM users for producers and consumers in Amazon SQS results in higher costs compared to using the same IAM user. This is because the producing principals incur double the cost of consuming principals.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-16", "source_tokens": 297, "generated_at": "2026-02-11T16:43:13.627437"}}
{"question": "What is the minimum message retention period for Amazon SQS?", "answer": "The minimum message retention period for Amazon SQS is 1 minute.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-11T16:43:17.626821"}}
{"question": "Why can we use Amazon SQS to build HIPAA-compliant applications?", "answer": "We can use Amazon SQS to build HIPAA-compliant applications because it is now a HIPAA Eligible Service and we have an executed Business Associate Agreement (BAA) with AWS.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-11T16:43:17.627172"}}
{"question": "How does the message retention period in Amazon SQS compare to the default?", "answer": "The message retention period in Amazon SQS can be configured from 1 minute (default) to 14 days.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-17", "source_tokens": 440, "generated_at": "2026-02-11T16:43:17.627340"}}
{"question": "What is the maximum size of a single message in an Amazon SQS queue in bytes?", "answer": "1 MiB (1,048,576 bytes)", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-11T16:43:22.124630"}}
{"question": "How does one configure the maximum message size for an Amazon SQS queue?", "answer": "You can configure the maximum message size for an Amazon SQS queue using the console or the SetQueueAttributes method to set the MaximumMessageSize attribute in the console or the AWS SDK.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-11T16:43:22.124922"}}
{"question": "What is the difference in message size limits between standard and FIFO Amazon SQS queues?", "answer": "Both standard and FIFO Amazon SQS queues have a maximum message size of 1 MiB (1,048,576 bytes) for the text data within the message. However, the Extended Client Library for Java and Python allows sending messages with references to message payloads in Amazon S3 that can be as large as 2 GiB for both types of queues.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-18", "source_tokens": 447, "generated_at": "2026-02-11T16:43:22.125329"}}
{"question": "What API operations does Amazon SQS provide for managing access policy statements?", "answer": "Amazon SQS provides the following API operations for managing access policy statements: AddPermission, RemovePermission, SetQueueAttributes, GetQueueAttributes.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-11T16:43:26.169590"}}
{"question": "How does one go about sharing a message queue with another AWS user?", "answer": "To share a message queue with another AWS user, provide the full URL of the message queue you want to share. The CreateQueue and ListQueues operations return this URL in their responses.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-11T16:43:26.169859"}}
{"question": "How does the pricing and access structure of Amazon SQS in China (Beijing) differ from other regions?", "answer": "Amazon SQS pricing is the same for all regions, except China (Beijing).", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-19", "source_tokens": 404, "generated_at": "2026-02-11T16:43:26.170245"}}
{"question": "What is the purpose of a dead-letter queue in Amazon SQS?", "answer": "A dead-letter queue is an Amazon SQS queue to which a source queue can send messages if the source queueâ€™s consumer application is unable to consume the messages successfully. It makes it easier to handle message consumption failures and manage the life cycle of unconsumed messages.", "question_type": "factual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-11T16:43:32.430017"}}
{"question": "Describe the process of handling message consumption failures with a dead-letter queue in Amazon SQS.", "answer": "When a consumer application fails to consume messages successfully from a source queue in Amazon SQS, the messages are moved to a dead-letter queue. You can investigate the messages in the dead-letter queue, diagnose the consumer application issues, and once the issue is resolved, the messages can be redriven back to the source queue.", "question_type": "conceptual", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-11T16:43:32.430298"}}
{"question": "How does the handling of messages between a source queue and a dead-letter queue differ for FIFO queues compared to standard queues in Amazon SQS?", "answer": "For FIFO queues in Amazon SQS, you must use a FIFO dead-letter queue with a FIFO queue. Similarly, you can use only a standard dead-letter queue with a standard queue. There is no difference in the handling process itself, but the requirement for using specific queue types when implementing a redrive policy applies.", "question_type": "comparison", "metadata": {"service": "SQS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "sqs-faq-20", "source_tokens": 503, "generated_at": "2026-02-11T16:43:32.430694"}}
{"question": "What is AWS Step Functions and what does it help in managing?", "answer": "AWS Step Functions is a fully managed service that makes it easier to coordinate the components of distributed applications and microservices using visual workflows. It helps in managing execution dependencies, scheduling, and concurrency of service components, as well as handling failures.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-11T16:43:38.031836"}}
{"question": "How does AWS Step Functions help in building and running multi-step applications?", "answer": "AWS Step Functions provides a graphical console to arrange and visualize the components of a multi-step application as a series of steps. It automatically triggers and tracks each step, retries when there are errors, logs the state of each step, and allows changing and adding steps without writing code, making it easier to build and run multi-step applications.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-11T16:43:38.032212"}}
{"question": "What's the difference between AWS Step Functions and other orchestration tools in handling failures?", "answer": "While both AWS Step Functions and other orchestration tools help in managing service components and handling failures, AWS Step Functions automatically retries when there are errors and logs the state of each step. Other orchestration tools might require manual intervention or different approaches to handle failures.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-0", "source_tokens": 347, "generated_at": "2026-02-11T16:43:38.032689"}}
{"question": "What are some common use cases for AWS Step Functions?", "answer": "AWS Step Functions is useful for data processing, building serverless generative AI applications, DevOps and IT automation, and e-commerce. It helps consolidate data from multiple databases, create end-to-end workflows, automate business processes, and implement robust user registration processes.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T16:43:44.351232"}}
{"question": "In what way does AWS Step Functions help in creating complex workflows?", "answer": "AWS Step Functions helps create complex workflows by allowing you to define state machines that describe your workflow as a series of steps, their relationships, and their inputs and outputs. States can perform work, make choices, pass parameters, initiate parallel execution, manage timeouts, or terminate the workflow.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T16:43:44.351569"}}
{"question": "How does AWS Step Functions compare to other AWS services for workflow orchestration?", "answer": "AWS Step Functions is a workflow orchestration service provided by AWS, and it can be compared to other AWS services like Amazon SWF (Simple Workflow Service) or AWS Lambda. While Amazon SWF is designed for long-running and steamlined applications, Step Functions is more suited for coordinating multi-step workflows with all the added features like visual console, detailed history, and the ability to perform work, make choices, and manage timeouts.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-1", "source_tokens": 416, "generated_at": "2026-02-11T16:43:44.351802"}}
{"question": "What is the role of service integrations in AWS Step Functions?", "answer": "Service integrations help construct calls to AWS services and include the response in the workflow, allowing users to invoke one of over 9,000 AWS API actions directly from their workflow.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-11T16:43:49.503157"}}
{"question": "How do Activity Tasks differ from service integrations in AWS Step Functions?", "answer": "Service integrations are used to invoke AWS services directly from the workflow, whereas Activity Tasks incorporate integration with activity workers that run the work in a location of the user's choice, such as EC2, ECS, or on-premises servers.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-11T16:43:49.503370"}}
{"question": "Why would you use a combination of service integrations and Activity Tasks in an AWS Step Functions state machine?", "answer": "A Step Functions state machine can contain combinations of service integrations and Activity Tasks, allowing users to utilize the strengths of both approaches. Service integrations can be used for AWS services, while Activity Tasks can be used for custom application components or workers that run behind a firewall.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-2", "source_tokens": 392, "generated_at": "2026-02-11T16:43:49.503505"}}
{"question": "What language is required to define AWS Step Functions state machines?", "answer": "AWS Step Functions state machines are defined in JSON using the Amazon States Language.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-11T16:43:55.777394"}}
{"question": "How can you create an activity worker in AWS Step Functions?", "answer": "To create an activity worker in AWS Step Functions, you can use any programming language as long as you can communicate with Step Functions using web service APIs. Conveniently, AWS SDKs are available in various languages including Node.js (JavaScript), Python, Golang (Go), and C#.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-11T16:43:55.777754"}}
{"question": "What are the two ways to compose Express Workflows with Standard Workflows in AWS Step Functions?", "answer": "You can compose Express Workflows with Standard Workflows in AWS Step Functions by running Express Workflows as a child workflow of Standard Workflows or by calling Express Workflows from within an Express Workflow. When using the first approach, the Express Workflow is invoked from a Task state in the parent orchestration workflow and succeeds or fails as a whole from the parent's perspective, subject to the parent's retry policy for that Task. When using the second approach, you might choose to factor your workflows this way if your use case has a combination of long-running or exactly-once, and short-lived high-rate steps.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-3", "source_tokens": 287, "generated_at": "2026-02-11T16:43:55.777970"}}
{"question": "What is the maximum concurrency for a Map state in Inline mode?", "answer": "The maximum concurrency for a Map state in Inline mode is 40 parallel branches.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-11T16:44:00.240316"}}
{"question": "How does the Distributed Map state in Step Functions help with processing large amounts of data?", "answer": "The Distributed Map state in Step Functions helps with processing large amounts of data by splitting the iterations into parallel executions, allowing you to overcome payload and execution history limits.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-11T16:44:00.240686"}}
{"question": "What are the differences between using variables and directly passing data through states in Step Functions?", "answer": "Using variables allows you to assign a value in one state and then reference it in a later state without having to directly pass the data through all intervening states. However, if the state that needs the data is an earlier state, you have to directly pass the data without using variables.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-4", "source_tokens": 397, "generated_at": "2026-02-11T16:44:00.241178"}}
{"question": "What query language should be used to write JSONata expressions in Step Functions?", "answer": "To write a JSONata expression using the declared query language 'JSONata' in Step Functions, surround it with {% %} like this: '{% JSONata expression %}'.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:44:05.835842"}}
{"question": "How does JSONata simplify data manipulation in Step Functions compared to JSONPath?", "answer": "JSONata simplifies data manipulation in Step Functions by replacing the five primary fields (InputPath, Parameters, ResultSelector, ResultPath, and OutputPath) with two new fields (Arguments and Output). Both fields accept JSONata for data manipulation.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:44:05.836205"}}
{"question": "What are the benefits of using Variables and JSONata in Step Functions?", "answer": "Variables and JSONata in Step Functions provide an easier learning path for new customers as they onboard to Step Functions. They enable the use of 'QueryLanguage':'JSONata' in existing workflows, allowing for simplified data manipulation using the new Arguments and Output fields. Both fields accept JSONata for data manipulation, and the new Condition field can be used to write Choice state conditions on a single line.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:44:05.836687"}}
{"question": "What service should you use when you need a reliable, hosted queue for sending, storing, and receiving messages between services?", "answer": "Amazon Simple Queue Service (SQS)", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-11T16:44:10.301680"}}
{"question": "How does Step Functions compare to SQS in terms of application development features and functionality?", "answer": "Step Functions offers features like passing data between tasks and flexibility in distributing tasks, while SQS requires you to implement application-level functionality and has limited functionality.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-11T16:44:10.301945"}}
{"question": "Why would you choose Amazon Simple Workflow Service (SWF) over Step Functions for coordinating application components?", "answer": "You would choose SWF when you need to write state machines in a programming language or use the Flow framework for asynchronous interaction structure, and when you require external signals to intervene in your processes or launch child processes that return a result to a parent.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-6", "source_tokens": 401, "generated_at": "2026-02-11T16:44:10.302100"}}
{"question": "What services can be used together to build applications with Amazon EventBridge and AWS Step Functions?", "answer": "Amazon EventBridge and AWS Step Functions can be used together to build highly scalable and robust distributed applications.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-11T16:44:14.456025"}}
{"question": "How does Amazon EventBridge's API Destinations feature enable decoupling of event producers and consumers?", "answer": "API Destinations is a feature of EventBridge that enables you to create rules to forward events to third-party endpoints, allowing event producers and consumers to be decoupled.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-11T16:44:14.456341"}}
{"question": "How does the integration of HTTPS endpoints in AWS Step Functions compare to EventBridge's focus on routing events?", "answer": "While Amazon EventBridge focuses on routing events, AWS Step Functions, with its HTTPS endpoints integration, enables direct integration with and orchestration of HTTP-based services, including SaaS applications.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-7", "source_tokens": 485, "generated_at": "2026-02-11T16:44:14.456535"}}
{"question": "What is the purpose of using the TestState API in AWS Step Functions?", "answer": "The TestState API allows users to test a single step of their workflow in AWS Step Functions, enabling faster feedback cycles to accelerate development. It enables calling services and endpoints directly, modifying input, and reviewing responses, all without the need to deploy the workflow.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-11T16:44:21.537435"}}
{"question": "What are the benefits of using a Distributed Map state in S3 mode in AWS Step Functions?", "answer": "A Distributed Map state in S3 mode in AWS Step Functions can be used for large-scale data processing tasks such as logs, media files, sales transactions, or IoT sensor data. It allows for iterating through the items and starting up parallel workflow executions instantly, making it easy to build on-demand data processing at scale. It is optimized to work with S3 and accepts an S3 bucket with filter criteria, a manifest file, or a JSON/CSV file stored in S3 as inputs for the workflow.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-11T16:44:21.537768"}}
{"question": "How does testing with the TestState API compare to analyzing workflow executions through CloudWatch Logs, X-Ray, and the Step Functions console?", "answer": "The TestState API allows for testing a single step of a workflow in AWS Step Functions, providing faster feedback cycles and enabling modifications to the input and review of responses. In contrast, analyzing workflow executions through Amazon CloudWatch Logs, AWS X-Ray, and directly in the Step Functions console allows for identifying problem areas after the workflow has run.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-8", "source_tokens": 425, "generated_at": "2026-02-11T16:44:21.538380"}}
{"question": "What is the role of Step Functions in orchestrating distributed services?", "answer": "Step Functions is an AWS orchestration service that coordinates the interaction and order in which services are invoked. It achieves more tightly controlled communication between services.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T16:44:26.098870"}}
{"question": "How does choreography differ from orchestration in terms of service communication in AWS?", "answer": "In choreography, communication is not tightly controlled and services interact with each other through events flowing between them. In contrast, in orchestration, Step Functions coordinates the interaction and order of service invocations.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T16:44:26.099238"}}
{"question": "How does Step Functions compare to EventBridge in the context of AWS services?", "answer": "Step Functions is an orchestration service that coordinates the interaction and order of service invocations, while EventBridge is an event bus service that allows services to interact through events without centralized coordination.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-9", "source_tokens": 380, "generated_at": "2026-02-11T16:44:26.099724"}}
{"question": "What metrics does AWS Step Functions send to Amazon CloudWatch and AWS CloudTrail?", "answer": "AWS Step Functions sends metrics to Amazon CloudWatch and AWS CloudTrail for application monitoring. CloudWatch collects and tracks metrics, sets alarms, and automatically reacts to changes in AWS Step Functions. CloudTrail captures all API calls for Step Functions as events, including calls from the Step Functions console and from code calls to the Step Functions APIs.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:44:32.688182"}}
{"question": "How does Step Functions integrate with Amazon Bedrock for data processing and AI capabilities?", "answer": "Step Functions integrates with Amazon Bedrock by allowing users to invoke Bedrockâ€™s Foundation Models directly from their Step Functionsâ€™ workflow using natural language. This integration enables users to enrich data processed by Step Functions with generative AI capabilities, retrieve information from databases, generate embeddings, and use Step Function workflows for prompt chaining.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:44:32.688554"}}
{"question": "What are the differences between CloudWatch and CloudTrail in terms of monitoring AWS Step Functions?", "answer": "CloudWatch collects and tracks metrics, sets alarms, and automatically reacts to changes in AWS Step Functions. It also supports CloudWatch Events managed rules for each integrated service in your workflow. CloudTrail captures all API calls for Step Functions as events, including calls from the Step Functions console and from code calls to the Step Functions APIs.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-10", "source_tokens": 506, "generated_at": "2026-02-11T16:44:32.689022"}}
{"question": "What is AWS PrivateLink used for in Step Functions?", "answer": "AWS PrivateLink is used to support VPC Endpoints (VPCE) in Step Functions, allowing access without traversing the public internet.", "question_type": "factual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-11T16:44:36.624528"}}
{"question": "How does using VPC Endpoints impact the access to Step Functions?", "answer": "Using VPC Endpoints with Step Functions allows you to access it from VPC-enabled AWS Lambda functions and other AWS services without going through the public internet.", "question_type": "conceptual", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-11T16:44:36.624894"}}
{"question": "What are the main differences between accessing Step Functions via VPC Endpoints and through the public internet?", "answer": "Accessing Step Functions via VPC Endpoints allows you to access it from within your own VPC without traversing the public internet.", "question_type": "comparison", "metadata": {"service": "STEP", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "step-faq-11", "source_tokens": 126, "generated_at": "2026-02-11T16:44:36.625390"}}
{"question": "Which AWS Storage Gateway services support iSCSI, SMB, and NFS protocols?", "answer": "Amazon S3 File Gateway, Amazon FSx File Gateway, and Volume Gateway are the AWS Storage Gateway services that support iSCSI, SMB, and NFS protocols.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T16:44:42.206937"}}
{"question": "How does AWS Storage Gateway reduce on-premises storage footprint and costs?", "answer": "AWS Storage Gateway reduces on-premises storage footprint and associated costs by leveraging AWS storage services to store data securely and durably in the cloud, while caching frequently accessed data on-premises for low-latency performance.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T16:44:42.207307"}}
{"question": "What are the key hybrid cloud use cases for AWS Storage Gateway?", "answer": "AWS Storage Gateway supports four key hybrid cloud use cases: (1) move backups and archives to the cloud, (2) reduce on-premises storage with cloud-backed file shares, (3) provide on-premises applications low-latency access to data stored in AWS, and (4) data lake access for pre and post processing workflows.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-0", "source_tokens": 480, "generated_at": "2026-02-11T16:44:42.207836"}}
{"question": "What type of storage interface does Amazon S3 File Gateway use for file access?", "answer": "Amazon S3 File Gateway uses file protocols such as Network File System (NFS) and Server Message Block (SMB) for file access.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-11T16:44:48.246346"}}
{"question": "How does using Amazon FSx File Gateway differ from using Amazon S3 File Gateway for storing and retrieving files?", "answer": "Amazon FSx File Gateway uses the SMB protocol to enable storing and retrieving files in Amazon FSx for Windows File Server, whereas Amazon S3 File Gateway uses NFS and SMB protocols to enable storing and retrieving objects in Amazon S3.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-11T16:44:48.246719"}}
{"question": "What are the key differences between using the Volume Gateway and the Tape Gateway for storing data on AWS?", "answer": "The Volume Gateway provides block storage to on-premises applications using iSCSI connectivity, with data stored in Amazon S3 and the ability to take point-in-time copies and manage retention using AWS Backup. The Tape Gateway provides an iSCSI virtual tape library (VTL) interface and stores virtual tapes in Amazon S3, with the ability to archive them to Amazon S3 Glacier or Amazon S3 Glacier Deep Archive.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-1", "source_tokens": 333, "generated_at": "2026-02-11T16:44:48.247139"}}
{"question": "What tool do you use to download the gateway virtual appliance or launch it as an EC2 instance?", "answer": "The AWS Management Console is used to download the gateway virtual appliance or launch it as an EC2 instance.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-11T16:44:52.893192"}}
{"question": "How does the AWS Storage Gateway help in providing access to AWS storage?", "answer": "The AWS Storage Gateway helps in providing access to AWS storage by connecting your applications to AWS storage using standard storage interfaces, and providing transparent caching, efficient data transfer, and integration with AWS monitoring and security services.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-11T16:44:52.893558"}}
{"question": "What are the differences between deploying the Storage Gateway as a virtual machine versus a hardware appliance?", "answer": "You can deploy the Storage Gateway as a virtual machine on VMware ESXi, Microsoft Hyper-V, or Linux KVM, or as a hardware appliance. The choice between these two options depends on your specific requirements and infrastructure.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-2", "source_tokens": 421, "generated_at": "2026-02-11T16:44:52.893993"}}
{"question": "What protocols does Amazon S3 File Gateway support for accessing S3 objects?", "answer": "Amazon S3 File Gateway allows your applications or devices to use standard file storage protocols, such as Network File System (NFS) and Server Message Block (SMB), to interact with S3 objects.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-11T16:44:58.084719"}}
{"question": "How does Amazon S3 File Gateway improve access to S3 objects?", "answer": "Amazon S3 File Gateway provides a file-based interface to Amazon S3 and allows your existing applications or devices to access S3 objects through NFS or SMB file shares. It also caches your most recently used data on the gateway for low-latency access.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-11T16:44:58.085086"}}
{"question": "How does Amazon S3 File Gateway compare to Amazon FSx File Gateway in terms of supported file systems?", "answer": "Amazon S3 File Gateway allows access to Amazon S3 through NFS and SMB file shares, whereas Amazon FSx File Gateway optimizes on-premises access to Windows file shares on Amazon FSx.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-3", "source_tokens": 415, "generated_at": "2026-02-11T16:44:58.085605"}}
{"question": "What does AWS Tape Gateway offer and how does it interface with backup applications?", "answer": "AWS Tape Gateway is a cloud-based Virtual Tape Library (VTL) that presents your backup application with a VTL interface consisting of a media changer and tape drives. Your backup application can read data from or write data to virtual tapes by mounting them to virtual tape drives using the virtual media changer. Virtual tapes are discovered by your backup application using its standard media inventory procedure. They are available for immediate access and are backed by Amazon S3. You can also archive tapes, which are stored in Amazon S3 Glacier or Amazon S3 Glacier Deep Archive.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-11T16:45:07.679842"}}
{"question": "How does AWS Tape Gateway handle data and what are the benefits of archiving tapes?", "answer": "AWS Tape Gateway creates virtual tapes in your virtual tape library using the AWS Management Console. Your backup application can read data from or write data to virtual tapes. Virtual tapes are backed by Amazon S3 and can be archived. Archived tapes are stored in Amazon S3 Glacier or Amazon S3 Glacier Deep Archive for long-term retention. The benefits of archiving tapes include cost savings, compliance, and disaster recovery.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-11T16:45:07.680253"}}
{"question": "What's the difference between AWS Tape Gateway and Volume Gateway in terms of data storage and access?", "answer": "AWS Tape Gateway is a cloud-based Virtual Tape Library (VTL) that presents your backup application with a VTL interface. It offers virtual tapes that are available for immediate access and are backed by Amazon S3. Virtual tapes can be archived and stored in Amazon S3 Glacier or Amazon S3 Glacier Deep Archive. AWS Volume Gateway, on the other hand, provides an iSCSI target and offers block storage volumes that can be mounted as iSCSI devices from on-premises or EC2 application servers. In the cached mode, your primary data is written to S3, while retaining your frequently accessed data locally in a cache for low-latency access. In the stored mode, your primary data is stored locally and your entire dataset is available for low-latency access while asynchronously backed up to AWS.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-4", "source_tokens": 328, "generated_at": "2026-02-11T16:45:07.680636"}}
{"question": "What is the maximum size of the local cache for a gateway running on a virtual machine?", "answer": "The maximum size of the local cache for a gateway running on a virtual machine is 64 TiB.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-11T16:45:12.282914"}}
{"question": "How does AWS Storage Gateway allow you to use your existing applications without modifications?", "answer": "AWS Storage Gateway provides a standard set of protocols such as iSCSI, SMB and NFS that allow you to use your existing applications without any changes.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-11T16:45:12.283299"}}
{"question": "How does Amazon S3 File Gateway compare to the regular AWS Storage Gateway?", "answer": "Amazon S3 File Gateway provides a file interface to store files as objects in Amazon S3 and access them using industry standard file protocols, while the regular AWS Storage Gateway provides a set of features to effectively leverage AWS storage within your existing applications and workflows through various protocols.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-5", "source_tokens": 485, "generated_at": "2026-02-11T16:45:12.283810"}}
{"question": "What storage classes does Amazon S3 File Gateway support for storing files and metadata?", "answer": "Amazon S3 File Gateway supports Amazon S3 Standard, S3 Intelligent-Tiering, S3 Standard-IA, and S3 One Zone-IA for storing files and metadata.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-11T16:45:18.011018"}}
{"question": "How can administrators configure access to an NFS file share on Amazon S3 File Gateway?", "answer": "Administrators can configure access to an NFS file share on Amazon S3 File Gateway by limiting access to specific NFS clients or networks, enabling user permission squashing, and setting read-only or read-write permissions.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-11T16:45:18.011384"}}
{"question": "What is the difference between configuring access to an NFS file share and an SMB file share on Amazon S3 File Gateway?", "answer": "The main difference lies in the authentication methods used. NFS file shares can be configured with administrative controls for access, while SMB file shares can be accessed by Active Directory (AD) users only or provided with authenticated guest access. Access permissions such as read-only or read-write, or limiting access to specific AD users and groups can also be configured for SMB file shares.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-6", "source_tokens": 506, "generated_at": "2026-02-11T16:45:18.011819"}}
{"question": "What IAM role is used by Amazon S3 File Gateway to access S3 buckets?", "answer": "Amazon S3 File Gateway uses an IAM role to access S3 buckets. You can set up the IAM role yourself or have it automatically set up by the AWS Storage Gateway Management Console.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-11T16:45:22.423773"}}
{"question": "Why would you create an S3 prefix when setting up a file share with Amazon S3 File Gateway?", "answer": "Creating an S3 prefix when setting up a file share with Amazon S3 File Gateway ties the file share to the specified prefix within the S3 bucket.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-11T16:45:22.424081"}}
{"question": "How does the name of the file share differ from the name of the S3 bucket or prefix?", "answer": "The file share name does not have to be the same as the name of the S3 bucket or S3 prefix.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-7", "source_tokens": 379, "generated_at": "2026-02-11T16:45:22.424611"}}
{"question": "What is the relationship between files and objects in Amazon S3 File Gateway?", "answer": "There is a one-to-one relationship between files and objects in Amazon S3 File Gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T16:45:26.310095"}}
{"question": "How does the object key for a file in Amazon S3 File Gateway get determined?", "answer": "The object key for a file in Amazon S3 File Gateway is derived from the file path within the file system.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T16:45:26.310433"}}
{"question": "What happens when a user attempts to create a symbolic link or hard link in Amazon S3 File Gateway?", "answer": "Attempting to create a symbolic link or hard link in Amazon S3 File Gateway will result in an error.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-8", "source_tokens": 474, "generated_at": "2026-02-11T16:45:26.310864"}}
{"question": "What metadata does S3 store for each file that can be accessed via an NFS or SMB file share?", "answer": "S3 stores POSIX-style metadata including ownership, permissions, and timestamps for each file.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T16:45:31.339277"}}
{"question": "Why and how can you enable MIME type guessing for objects in an S3 bucket used with Amazon S3 File Gateway?", "answer": "You can enable MIME type guessing for objects in an S3 bucket used with Amazon S3 File Gateway by using the filename extension to determine the MIME type for the file and set the S3 objects Content-Type accordingly. This can be enabled upon creation or later.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T16:45:31.339651"}}
{"question": "How does managing objects using Amazon S3 File Gateway compare to managing them directly in S3 without using a file share?", "answer": "When you manage objects using Amazon S3 File Gateway, only the changed data in your files is uploaded to S3, while all objects are downloaded when accessing them without using a file share.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-9", "source_tokens": 497, "generated_at": "2026-02-11T16:45:31.340221"}}
{"question": "What event triggers a notification when an individual file upload completes using Amazon S3 File Gateway?", "answer": "AWS CloudWatch Events", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-11T16:45:51.334891"}}
{"question": "How does the File Upload Notification differ from the S3 event notifications when it comes to notifying file upload completion?", "answer": "The File Upload Notification provides a notification for each individual file that is uploaded to Amazon S3 through S3 File Gateway, while S3 event notifications provide notifications that include partial file uploads.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-11T16:45:51.335259"}}
{"question": "What can you use S3 File Gateway notifications for, conceptually?", "answer": "S3 File Gateway notifications can be used to trigger additional workflows, such as invoking an AWS Lambda function or Amazon EC2 Systems Manager Automation, based on the availability of data in the S3 bucket.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-11", "source_tokens": 499, "generated_at": "2026-02-11T16:45:51.335734"}}
{"question": "What is the maximum number of file shares you can create for a single S3 bucket in a single gateway?", "answer": "You can create up to 50 file shares for a single S3 bucket in a single gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-11T16:45:56.118905"}}
{"question": "Why might you recommend having a single writer to an S3 bucket when using AWS Storage Gateway?", "answer": "It is recommended to have a single writer to an S3 bucket, either an Amazon S3 File Gateway or a client accessing S3 directly, to ensure the bucket policies for lifecycle management, cross-region replication, and S3 event notification apply directly to objects stored in the bucket.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-11T16:45:56.119261"}}
{"question": "How does the size limit of an individual file share compare to the size limit of an individual object in S3?", "answer": "The maximum size of an individual file in a file share is the same as the maximum size of an individual object in S3, which is 5 TB.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-12", "source_tokens": 438, "generated_at": "2026-02-11T16:45:56.119482"}}
{"question": "What versions of SMB and NFS does Amazon S3 File Gateway support?", "answer": "Amazon S3 File Gateway supports SMB versions 2 and 3 as well as NFS versions 3, 4.0, and 4.1.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T16:46:01.104128"}}
{"question": "How does the local cache in Amazon S3 File Gateway improve performance?", "answer": "The local cache in Amazon S3 File Gateway stores recently accessed data for low-latency read access and reduces the frequency with which data is requested from S3, improving read performance. It also allows for efficient data transfer by using a write-back mechanism where data is first persisted to disk and then asynchronously uploaded to S3.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T16:46:01.104542"}}
{"question": "How does the performance of Amazon S3 File Gateway with a small cache compare to using the S3 API?", "answer": "A smaller cache in Amazon S3 File Gateway can result in poor performance and potential failures during writes due to lack of free cache space to store data locally while pending upload to S3. In contrast, the S3 API does not require file system operations and allows data transfer to be managed directly.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-13", "source_tokens": 510, "generated_at": "2026-02-11T16:46:01.104947"}}
{"question": "What happens to data in the cache when more space is needed?", "answer": "Data written to the cache from applications or retrieved from Amazon S3 is evicted only when space is needed to store more recently accessed data.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-11T16:46:06.270932"}}
{"question": "How does Amazon S3 File Gateway reduce data transfer?", "answer": "Amazon S3 File Gateway uses multipart uploads and copy put, so only changed data is uploaded to S3, reducing data transfer.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-11T16:46:06.271278"}}
{"question": "How does Amazon FSx File Gateway compare to Amazon S3 File Gateway in terms of data transfer?", "answer": "Amazon FSx File Gateway optimizes on-premises access to Windows file shares on Amazon FSx, synchronizing changed data to FSx for Windows File Server in the background. In contrast, Amazon S3 File Gateway uses multipart uploads and copy put, uploading only changed data to Amazon S3, but it does not reduce data transfer traffic as effectively as Amazon FSx File Gateway does.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-14", "source_tokens": 461, "generated_at": "2026-02-11T16:46:06.271661"}}
{"question": "What does Amazon FSx File Gateway provide to help with latency-sensitive on-premises desktop applications in AWS?", "answer": "Amazon FSx File Gateway provides an SMB file protocol server for clients to connect to and an on-premises cache of frequently used data for low latency access. File system operations are performed against the local cache, and changed data is synchronized to Amazon FSx for Windows File Server in the background.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-11T16:46:12.981521"}}
{"question": "How does Amazon FSx File Gateway help address congestion on shared bandwidth resources when using AWS for latency-sensitive on-premises desktop applications?", "answer": "Amazon FSx File Gateway minimizes the amount of data transfer and optimizes the usage of network bandwidth to AWS by providing a local cache for frequently used data and performing file system operations against it. This helps minimize the impact on shared bandwidth resources such as AWS Direct Connect links.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-11T16:46:12.982070"}}
{"question": "How does Amazon FSx File Gateway compare to AWS Direct Connect links in terms of handling latency-sensitive on-premises desktop applications?", "answer": "Amazon FSx File Gateway provides a local cache for frequently used data and performs file system operations against it, which helps minimize the amount of data transfer and optimize the usage of network bandwidth to AWS. This can help reduce the impact on shared bandwidth resources such as AWS Direct Connect links and provide lower latency access to data for on-premises desktop applications.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-15", "source_tokens": 255, "generated_at": "2026-02-11T16:46:12.983148"}}
{"question": "What protocols are supported by Amazon FSx File Gateway for accessing Windows file systems?", "answer": "Amazon FSx File Gateway supports versions 2.x and 3.x of the Server Message Block (SMB) protocol.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T16:46:19.117401"}}
{"question": "How does Amazon FSx File Gateway allow users to access Windows file systems on-premises and in AWS?", "answer": "Amazon FSx File Gateway maps local file shares and their contents to file shares stored remotely in Amazon FSx for Windows File Server. Users can then access the mapped file shares both on-premises and in AWS. The AWS Management Console guides users through the steps to make file shares accessible on-premises.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T16:46:19.117765"}}
{"question": "How does Amazon FSx File Gateway compare to directly accessing Amazon FSx for Windows File Server?", "answer": "Both Amazon FSx File Gateway and directly accessing Amazon FSx for Windows File Server allow users to access Windows file systems in AWS. However, when using Amazon FSx File Gateway, local file shares are mapped to remote file shares, enabling users to access the shares both on-premises and in AWS. When writes are made from both locations, Amazon FSx File Gateway does not prevent conflicts in this release.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-16", "source_tokens": 504, "generated_at": "2026-02-11T16:46:19.118185"}}
{"question": "What encryption specification does Amazon FSx File Gateway support for SMB?", "answer": "Amazon FSx File Gateway supports SMB encryption up to the latest SMB v3.1.1 specification, including AES 128 CCM and AES 128 GCM.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-11T16:46:24.698680"}}
{"question": "How does Amazon FSx File Gateway handle access control when joined to an Active Directory domain?", "answer": "Amazon FSx File Gateway, once a member of an Active Directory domain, has access to all users and policies set in that domain for enforcing security. It then behaves identically to any Windows Server and enforces all applicable file access policies based on what is configured in Active Directory.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-11T16:46:24.699053"}}
{"question": "What are the differences between deploying Amazon FSx File Gateway as a virtual machine and deploying it as a hardware appliance?", "answer": "Amazon FSx File Gateway can be deployed on VMware ESXi, Microsoft Hyper-V, or Linux KVM as a virtual machine, or as a hardware appliance. The choice between these options depends on your specific requirements.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-17", "source_tokens": 470, "generated_at": "2026-02-11T16:46:24.699543"}}
{"question": "What type of failures does Amazon FSx File Gateway recover from with VMware HA enabled?", "answer": "Amazon FSx File Gateway recovers from hardware failures, hypervisor failures, network failures, and software issues that lead to connection timeouts or file-share unavailability.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-11T16:46:29.748178"}}
{"question": "How does Amazon FSx File Gateway ensure high availability on VMware?", "answer": "Amazon FSx File Gateway achieves high availability on VMware by running continuous health checks, which trigger a gateway restart on a new host or the existing host if it's still operational during a failure. Users and applications experience up to 60 seconds of downtime during a restart.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-11T16:46:29.748638"}}
{"question": "How does Amazon FSx File Gateway compare to Amazon S3 File Gateway in terms of supported shares and active client sessions?", "answer": "Amazon FSx File Gateway supports up to 50 shares and 500 active client sessions connected to Amazon FSx File Gateway instances in a single instance configuration.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-18", "source_tokens": 249, "generated_at": "2026-02-11T16:46:29.748876"}}
{"question": "What are the data durability and encryption benefits when using S3 Glacier Deep Archive with Tape Gateway compared to offsite warehousing of physical tapes?", "answer": "When using S3 Glacier Deep Archive with Tape Gateway, your data is replicated and stored across at least three geographically-dispersed Availability Zones, ensuring 11 9s of durability. Data is also protected by S3 Server Side Encryption using default keys or your KMS keys. This contrasts with offsite warehousing of physical tapes, where there is a risk of receiving an incorrect or broken tape during restore.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-11T16:46:36.984959"}}
{"question": "How does AWS ensure the data integrity and availability when storing virtual tapes in S3 Glacier Deep Archive using Tape Gateway?", "answer": "AWS performs fixity checks on a regular basis to confirm the data can be read and no errors have been introduced, and all virtual tapes stored in S3 Glacier Deep Archive are replicated and stored across at least three geographically-dispersed Availability Zones, ensuring 11 9s of durability and data availability.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-11T16:46:36.985332"}}
{"question": "What are the minimum and maximum size limitations for a virtual tape on a Tape Gateway, and how much do you pay for?", "answer": "The minimum size for a virtual tape on a Tape Gateway is 100 GiB, and the maximum size is 15 TiB. You only pay for the amount of data stored on each tape, and not for the size of the tape itself.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-19", "source_tokens": 511, "generated_at": "2026-02-11T16:46:36.985749"}}
{"question": "What is the typical retrieval time for a virtual tape archived in S3 Glacier?", "answer": "The typical retrieval time for a virtual tape archived in S3 Glacier is within 3-5 hours.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-11T16:46:42.907588"}}
{"question": "How does the process of accessing a virtual tape archived in S3 Glacier or S3 Glacier Deep Archive differ?", "answer": "To access a virtual tape archived in S3 Glacier, you first select the virtual tape and then choose the virtual tape library into which you want the virtual tape to be loaded. The retrieval time is typically within 3-5 hours. For a virtual tape archived in S3 Glacier Deep Archive, the retrieval time is typically within 12 hours, but the process is otherwise similar.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-11T16:46:42.907957"}}
{"question": "How does the retrieval time for a virtual tape archived in S3 Glacier compare to that of a virtual tape archived in S3 Glacier Deep Archive?", "answer": "The retrieval time for a virtual tape archived in S3 Glacier is typically within 3-5 hours, while the retrieval time for a virtual tape archived in S3 Glacier Deep Archive is typically within 12 hours.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-20", "source_tokens": 403, "generated_at": "2026-02-11T16:46:42.908397"}}
{"question": "What charge is incurred when moving a tape from S3 Glacier to S3 Glacier Deep Archive?", "answer": "A tape move charge is incurred for moving a tape from S3 Glacier to S3 Glacier Deep Archive.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-11T16:46:47.999700"}}
{"question": "Why can't you move a tape from S3 Glacier Deep Archive to S3 Glacier?", "answer": "It's not possible to move a tape from S3 Glacier Deep Archive to S3 Glacier.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-11T16:46:48.000061"}}
{"question": "How does encryption work for data transferred between the gateway and AWS storage using Tape Gateway?", "answer": "All data transferred between the gateway and AWS storage is encrypted using SSL and by default, all data stored by Tape Gateway in S3 is encrypted server-side with Amazon S3-Managed Encryption Keys (SSE-S3). Optionally, encryption on tapes can be configured using AWS KMS-Managed Keys via the Storage Gateway API.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-21", "source_tokens": 416, "generated_at": "2026-02-11T16:46:48.000570"}}
{"question": "What is the maximum data capacity for a single Volume Gateway in cached mode?", "answer": "A single Volume Gateway in cached mode can support up to 1 PB of data.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:46:52.384461"}}
{"question": "How does data compression work in the context of AWS Volume Gateways?", "answer": "AWS Volume Gateways compress data before transferring it to AWS and while it is stored in AWS. This compression can reduce both data transfer and storage charges.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:46:52.384826"}}
{"question": "What is the maximum data capacity for a single Volume Gateway in stored mode? How does it compare to cached mode?", "answer": "A single Volume Gateway in stored mode can support up to 512 TB of data. In comparison, each volume in cached mode can support up to 32 TB for a maximum of 1 PB of data per gateway.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-22", "source_tokens": 504, "generated_at": "2026-02-11T16:46:52.385307"}}
{"question": "Which key can be used to encrypt an EBS volume created from a KMS-encrypted snapshot?", "answer": "You can use the same key that was used to encrypt the EBS snapshot, or specify a different encryption key for encrypting the volume.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-11T16:46:57.059517"}}
{"question": "How can taking snapshots of Volume Gateway volumes benefit an application running on EC2?", "answer": "Taking snapshots of Volume Gateway volumes allows you to easily supply data from your on-premises applications to your applications running on EC2 if you require additional on-demand compute capacity or replacement capacity for disaster recovery purposes.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-11T16:46:57.059879"}}
{"question": "What is the difference between how snapshots are used for cached volumes and stored volumes in Volume Gateway?", "answer": "For cached volumes, snapshots provide versioning and data preservation. When taking a new snapshot, only the data that has changed since the last snapshot is stored. For stored volumes, snapshots provide durable, off-site backups in Amazon S3. A new volume can be created from a snapshot for both cached and stored volumes.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-23", "source_tokens": 404, "generated_at": "2026-02-11T16:46:57.060340"}}
{"question": "What is the status of a Snapshot after it is created?", "answer": "Initially, a Snapshot is in a PENDING status, but when all data written to the volume prior to the snapshot request has been uploaded from the gateway and into EBS, the status changes to AVAILABLE.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-11T16:47:02.336978"}}
{"question": "How does creating a new volume from a snapshot impact the data in Amazon S3?", "answer": "When creating a new volume from a snapshot in Amazon S3, the gateway keeps the snapshot data in Amazon S3 where it becomes the primary data for the new volume in the case of cached volumes. In contrast, for stored volumes, the gateway downloads the data contained within the snapshot to your local hardware.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-11T16:47:02.337338"}}
{"question": "Why would you create a Snapshot schedule for your volumes?", "answer": "You can create a Snapshot schedule for each of your volumes to automate the process of taking regular Snapshots. This allows you to have multiple points-in-time copies of your data, ensuring data protection and enabling quick data recovery in case of data loss or corruption.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-24", "source_tokens": 481, "generated_at": "2026-02-11T16:47:02.338019"}}
{"question": "How does the size of a volume and Internet connection speed affect the time it takes to create a snapshot in AWS Storage Gateway?", "answer": "The time it takes to create a snapshot in AWS Storage Gateway is largely dependent upon the size of your volume and the speed of your Internet connection to AWS. The AWS Storage Gateway compresses all data prior to upload, reducing the time to take a snapshot.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-11T16:47:08.202626"}}
{"question": "Why would you use AWS Backup to manage Volume Gateway backups instead of using the Storage Gateway console directly?", "answer": "AWS Backup simplifies and centralizes backup management for Volume Gateway volumes. It allows you to set customizable scheduled backup policies, manage backup retention and expiration rules, and monitor backups across multiple Volume Gateways and other AWS resources from a central view.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-11T16:47:08.203033"}}
{"question": "How does managing backups for Volume Gateway volumes using AWS Backup compare to managing them using the Storage Gateway console directly?", "answer": "Using AWS Backup to manage backups for Volume Gateway volumes allows for centralized backup management, customizable scheduled backup policies, and easier backup monitoring across multiple Volume Gateways and other AWS resources. In contrast, managing backups using the Storage Gateway console directly does not offer these same features.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-25", "source_tokens": 474, "generated_at": "2026-02-11T16:47:08.203476"}}
{"question": "What regions support the use of AWS Storage Gateway's hardware appliance with AWS Backup for Volume Gateway?", "answer": "AWS Backup and the Volume Gateway feature of AWS Storage Gateway are supported in 16 regions including US East (Northern Virginia, Ohio), US West (Northern California, Oregon), Canada (Central), South America (SÃ£o Paulo), Europe (Ireland, Frankfurt, London, Paris, Stockholm), and Asia Pacific (Mumbai, Seoul, Singapore, Sydney, Tokyo).", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-11T16:47:15.279010"}}
{"question": "How does using AWS Backup with Volume Gateway differ from using Volume Gateway's snapshot capabilities?", "answer": "AWS Backup provides an additional way to centrally manage backup and retention policies, while Volume Gateway's snapshot capabilities are used to create Amazon EBS snapshots for restore purposes. AWS Backup's backup schedule operates independently from Volume Gateway's scheduled snapshots.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-11T16:47:15.279384"}}
{"question": "What are the main differences between using the AWS Storage Gateway hardware appliance and the virtual machine appliance for Volume Gateway?", "answer": "The hardware appliance simplifies deployment and management on-premises, especially for IT environments lacking virtual server infrastructure or adequate resources. It also avoids the need to procure additional infrastructure for the local Storage Gateway VM appliance. The hardware appliance offers 5 TB or 12 TB of local SSD cache and supports multiple interfaces including Amazon S3 File Gateway, Amazon FSx File Gateway, Volume Gateway, and Tape Gateway.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-26", "source_tokens": 444, "generated_at": "2026-02-11T16:47:15.279828"}}
{"question": "What IP address do I use in the AWS Storage Gateway console to activate my hardware appliance?", "answer": "You use the IP address configured through the local hardware appliance console for activation.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-11T16:47:19.478488"}}
{"question": "How can I change the gateway type on a hardware appliance?", "answer": "You can remove the existing gateway and then create a new one.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-11T16:47:19.478848"}}
{"question": "What is the difference in local cache capacity between the 5 TB and 12 TB models of the Storage Gateap Gateway Hardware Appliance when adding additional SSDs?", "answer": "The 5 TB model can be expanded to 12 TB by adding 5 additional SSDs, while the 12 TB model can tolerate failure of up to 2 SSDs.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-27", "source_tokens": 378, "generated_at": "2026-02-11T16:47:19.479306"}}
{"question": "What does Storage Gateway do to ensure high availability?", "answer": "Storage Gateway achieves high availability by running continuous health-checks against the operation of the gateway and triggering a restart on a new or existing host during a hardware, software, or network failure. Users and applications may experience up to 60 seconds of downtime during a restart, but connections will be automatically re-established and metrics will be sent to the cloud.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-11T16:47:25.431930"}}
{"question": "Why is it important to have Storage Gateway high availability enabled in VMware environments?", "answer": "Storage Gateway high availability is important because it enables the gateway to detect and recover from hardware failures, hypervisor failures, network failures, software issues, and unavailability of file-shares, volumes, or virtual tape libraries. It also allows users to configure the restart sensitivity of the Storage Gateway VM in the VMware vSphere control center.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-11T16:47:25.432193"}}
{"question": "How does the experience of NFS clients differ from SMB clients during a Storage Gateway restart?", "answer": "NFS clients may hang for up to 60 seconds on a read or write operation during a Storage Gateway restart, then retry. In contrast, SMB clients may reject a file read or write during a restart depending on client settings.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-28", "source_tokens": 455, "generated_at": "2026-02-11T16:47:25.432348"}}
{"question": "What health checks does Storage Gateway provide for the gateway service?", "answer": "Storage Gateway provides health checks for file system availability, SMB endpoint availability, and NFS endpoint availability.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-11T16:47:30.572143"}}
{"question": "How does Storage Gateway ensure the availability of the gateway service?", "answer": "Storage Gateway ensures the availability of the gateway service by monitoring all critical operations of the gateway and providing health checks. It also offers High Availability for use on VMware Cloud with no additional requirements.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-11T16:47:30.572536"}}
{"question": "What encryption methods does AWS Storage Gateway offer for data transfer and storage?", "answer": "AWS Storage Gateway encrypts all data transferred between any type of gateway appliance and AWS storage using SSL. By default, all data stored by AWS Storage Gateway in S3 is encrypted server-side with Amazon S3-Managed Encryption Keys (SSE-S3). Optionally, different gateway types can be configured to encrypt stored data with AWS Key Management Service (KMS) via the Storage Gateway API.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-29", "source_tokens": 423, "generated_at": "2026-02-11T16:47:30.573041"}}
{"question": "Which AWS regions support FIPS 140-2 compliant endpoints for AWS Storage Gateway?", "answer": "AWS Storage Gateway supports FIPS 140-2 compliant endpoints in the US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Canada (Central), AWS GovCloud (US-West), and AWS GovCloud (US-East) regions.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-11T16:47:38.638311"}}
{"question": "Why would you use AWS Storage Gateway for storing and managing sensitive data, like PHI and PCI DSS data?", "answer": "AWS Storage Gateway allows you to store, back up, and archive sensitive data on scalable, cost-effective, and secure AWS storage services, including Amazon S3, Amazon S3 Glacier, Amazon S3 Glacier Deep Archive, Amazon FSx for Windows File Server, and Amazon EBS, all of which are HIPAA, PCI DSS, and FedRAMP compliant. Existing customers can download the necessary reports, and prospective customers can request them through the AWS sales team.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-11T16:47:38.638699"}}
{"question": "What's the difference between AWS Storage Gateway's compliance with HIPAA and PCI DSS?", "answer": "AWS Storage Gateway is HIPAA eligible, meaning it can be used to store, back up, and archive protected health information (PHI) on AWS services that are also HIPAA eligible. AWS Storage Gateway is also PCI DSS compliant, allowing it to store and manage payment card industry data securely. The HIPAA eligibility applies to all gateway types (File, Volume, and Tape), while the PCI DSS compliance is based on recent assessments. Existing customers can download the HIPAA Compliance page and Attestation of Compliance (AOC) and PCI Responsibility Summary reports, while prospective customers need to work with the AWS sales team to obtain the reports.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-30", "source_tokens": 488, "generated_at": "2026-02-11T16:47:38.638921"}}
{"question": "Is AWS Storage Gateway Hardware Appliance FIPS 140-2 compliant?", "answer": "No.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-11T16:47:42.518587"}}
{"question": "What user operations are logged in File Gateway audit logs?", "answer": "File Gateway audit logs monitor and log user operations for open, delete, read, write, rename, change of permissions, and file operation success.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-11T16:47:42.518960"}}
{"question": "How does using a SOCKS5 proxy impact File Gateway compared to Volume and Tape Gateways?", "answer": "File Gateway supports configuration of a HyperText Transfer Protocol (HTTP) proxy, while Volume and Tape Gateways support a Socket Secure version 5 (SOCKS5) proxy.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-31", "source_tokens": 446, "generated_at": "2026-02-11T16:47:42.519173"}}
{"question": "What type of networks can Storage Gateway be deployed on through AWS PrivateLink?", "answer": "Storage Gateway can be deployed on private, non-routable networks if they are connected to your Amazon VPC via DX or VPN.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-11T16:47:47.318015"}}
{"question": "Why is a proxy server required to access S3 through File Gateway and PrivateLink?", "answer": "A proxy server is required to provide access to S3 over a private network through the VPC endpoint for S3, making it accessible to an on-premises File Gateway.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-11T16:47:47.318321"}}
{"question": "How does the traffic routing differ between the hardware appliance network interface and the gateway VM virtual interface for Volume and Tape Gateways?", "answer": "The hardware appliance network interface(s) must be able to communicate with AWS public endpoints for proper operation, while the gateway VM virtual interface(s) can be configured to use PrivateLink and communicate only with VPC endpoints.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-32", "source_tokens": 455, "generated_at": "2026-02-11T16:47:47.318500"}}
{"question": "What performance factors does the AWS Storage Gateway depend on when running on a virtual machine or Amazon EC2 instance?", "answer": "The performance of the AWS Storage Gateway on a virtual machine or Amazon EC2 instance depends on the network bandwidth between the iSCSI initiator or NFS client and gateway, the speed and configuration of the local disks, the configuration of the VM, the amount of local storage allocated to the gateway, and the bandwidth between the gateway and Amazon storage.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:47:52.803655"}}
{"question": "Why is data compression useful when using the AWS Storage Gateway?", "answer": "Data compression is useful when using the AWS Storage Gateway because it reduces both data transfer and storage charges by compressing data in-transit and at-rest.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:47:52.804025"}}
{"question": "How does the performance monitoring and throttling functionality of the AWS Storage Gateway compare to each other?", "answer": "The performance monitoring functionality of the AWS Storage Gateway allows users to monitor performance metrics and alarms for their gateway, while the throttling functionality allows users to specify network bandwidth rates for inbound and outbound traffic to synchronize data with AWS based on a schedule.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-33", "source_tokens": 478, "generated_at": "2026-02-11T16:47:52.804515"}}
{"question": "What console can you use to create CloudWatch alarms for your AWS Storage Gateway gateway?", "answer": "You can create CloudWatch alarms for your gateway in the Amazon CloudWatch console.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-11T16:47:57.661206"}}
{"question": "How is AWS Storage Gateway billing structured for gateway storage?", "answer": "You are billed for the amount of volume and virtual tape data you store in AWS Storage Gateway. You are only billed for the portion of volume or virtual tape capacity that you use, and all data is compressed before it is transferred to reduce storage charges.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-11T16:47:57.661648"}}
{"question": "How does billing for EBS snapshots taken from your Storage Gateway volumes compare to billing for your gateway storage?", "answer": "EBS snapshots taken from your Storage Gateway volumes are stored and billed by Amazon EBS. The billing structure for EBS snapshots is different from the billing structure for gateway storage, as only the changed data is stored when taking a new snapshot.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-34", "source_tokens": 428, "generated_at": "2026-02-11T16:47:57.662124"}}
{"question": "What is the charge for writing data to AWS from the gateway?", "answer": "$0.01 per GB of data written to AWS up to a monthly maximum of $125 per gateway.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-11T16:48:02.440412"}}
{"question": "How does the early deletion fee for virtual tapes in S3 Glacier and S3 Glacier Deep Archive differ?", "answer": "The early deletion fee for virtual tapes in S3 Glacier is $0.012 per GB deleted within three months, while in S3 Glacier Deep Archive, there is no charge for deletion if the virtual tape has been stored for the required period.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-11T16:48:02.440781"}}
{"question": "What factors determine the amount of data written to AWS from the gateway?", "answer": "The amount of data written to AWS from the gateway is influenced by the gateway's caching, bandwidth optimization, and compression capabilities, as well as the data requirements of your application.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-35", "source_tokens": 485, "generated_at": "2026-02-11T16:48:02.441267"}}
{"question": "What is the cost for moving a 100 GB virtual tape from S3 Glacier to S3 Glacier Deep Archive in the US East (N. Virginia) region?", "answer": "The cost for moving a 100 GB virtual tape from S3 Glacier to S3 Glacier Deep Archive in the US East (N. Virginia) region is $3.2.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:48:08.092774"}}
{"question": "How does billing for virtual tapes in AWS Storage Gateway Deep Archive differ between the monthly AWS bill and the Detailed Billing Reports?", "answer": "On the monthly AWS bill, virtual tapes stored in Deep Archive Pool are shown as an independent service line item under AWS Storage Gateway Deep Archive. In contrast, the Detailed Billing Reports include the usage and cost for virtual tapes under AWS Storage Gateway, with the separate Deep Archive Pool costs not broken out.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:48:08.093121"}}
{"question": "Which AWS services are you charged for when using File Gateway audit logs?", "answer": "You will be charged for standard rates for Amazon CloudWatch Logs, Amazon CloudWatch Events, and Amazon CloudWatch Metrics when configuring File Gateway audit logs.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-36", "source_tokens": 485, "generated_at": "2026-02-11T16:48:08.093337"}}
{"question": "What taxes and duties are included in AWS's prices, excluding Japanese Consumption Tax?", "answer": "Our prices are exclusive of applicable taxes and duties, including VAT and sales tax.", "question_type": "factual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-11T16:48:12.610542"}}
{"question": "How does AWS handle hardware support for the Storage Gateway?", "answer": "AWS Support provides software and service support for AWS Storage Gateway, and coordinates hardware-related cases with the hardware manufacturer's support team.", "question_type": "conceptual", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-11T16:48:12.610846"}}
{"question": "How does the hardware support for the AWS Storage Gateway appliance compare to AWS Premium Support?", "answer": "The hardware appliance comes with 3 years of warranty and next business day on-site service for parts replacement provided by the hardware manufacturer. AWS Premium Support, on the other hand, includes 24/7 phone support and next-business-day on-site service for hardware issues. Both provide support, but the duration and scope differ.", "question_type": "comparison", "metadata": {"service": "STORAGEGATEWAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "storagegateway-faq-37", "source_tokens": 286, "generated_at": "2026-02-11T16:48:12.611018"}}
{"question": "What tool does AWS Systems Manager provide for applying patches to nodes?", "answer": "Use Patch Manager to apply patches to nodes such as security updates.", "question_type": "factual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T16:48:18.107679"}}
{"question": "How does AWS Systems Manager help in managing nodes in hybrid and multicloud environments?", "answer": "AWS Systems Manager helps in managing nodes such as Amazon EC2 instances, Virtual Machines on other clouds, on-premises servers, and other devices with a CPU by providing tools for securely connecting to nodes, applying patches, automating operational commands, and gaining comprehensive visibility. This is achieved by installing the SSM Agent on the managed nodes and enabling them to communicate with the Systems Manager service.", "question_type": "conceptual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T16:48:18.108042"}}
{"question": "What is the difference between managing nodes on AWS and managing non-AWS nodes with AWS Systems Manager?", "answer": "Managing nodes on AWS involves using Systems Manager tools like Patch Manager, Session Manager, and Run Command to apply patches, securely connect, and manage configurations on Amazon EC2 instances. Managing non-AWS nodes with Systems Manager requires installing the SSM Agent on these nodes to enable communication with the Systems Manager service and accessing the full suite of Systems Manager tools.", "question_type": "comparison", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-0", "source_tokens": 445, "generated_at": "2026-02-11T16:48:18.108464"}}
{"question": "What account is used to manage nodes in AWS Systems Manager for an AWS Organizations?", "answer": "A delegated administrator account is used to manage nodes in AWS Systems Manager for an AWS Organizations.", "question_type": "factual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-11T16:48:22.094558"}}
{"question": "How does AWS Systems Manager enable managing nodes at scale in an AWS Organizations?", "answer": "AWS Systems Manager provides a comprehensive, centralized view to manage all types of nodes, including EC2 instances and hybrid servers, at scale for an AWS Organizations.", "question_type": "conceptual", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-11T16:48:22.094822"}}
{"question": "How does managing nodes with AWS Systems Manager in an AWS Organizations compare to managing them directly?", "answer": "Managing nodes with AWS Systems Manager in an AWS Organizations allows for a more centralized and comprehensive view of all nodes at scale, compared to managing them directly without the use of Systems Manager.", "question_type": "comparison", "metadata": {"service": "SYSTEMS", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "systems-faq-1", "source_tokens": 97, "generated_at": "2026-02-11T16:48:22.095100"}}
{"question": "What kinds of information can Amazon Textract extract from documents?", "answer": "Amazon Textract can extract printed text, handwriting, structured data (such as fields and their values), and tables from images and scans of documents. It can also extract specific or implied data such as names and addresses from identity documents.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-11T16:48:27.151237"}}
{"question": "How does Amazon Textract help in maintaining compliance in document archives?", "answer": "Amazon Textract can maintain compliance in document archives by automatically recognizing and processing documents for text extraction. It returns confidence scores for each element identified, allowing users to make informed decisions about the use of the results.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-11T16:48:27.151600"}}
{"question": "Which languages and document types can Amazon Textract extract printed text, forms, and tables from?", "answer": "Amazon Textract can extract printed text, forms, and tables from documents in English, German, French, Spanish, Italian, and Portuguese. It can also extract specific or implied data from invoices or receipts in English without templates or configuration.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-0", "source_tokens": 484, "generated_at": "2026-02-11T16:48:27.151828"}}
{"question": "In which file formats does Amazon Textract currently support?", "answer": "Amazon Textract currently supports PNG, JPEG, TIFF, and PDF formats.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-11T16:48:30.938635"}}
{"question": "How can I submit images to Amazon Textract for asynchronous APIs?", "answer": "You can submit S3 objects to Amazon Textract for asynchronous APIs.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-11T16:48:30.938936"}}
{"question": "Why should I avoid converting or downsampling documents before uploading to Amazon Textract?", "answer": "If your document is already in one of the file formats that Amazon Textract supports (PDF, TIFF, JPG, PNG), you should not convert or downsample it before uploading it to Amazon Textract.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-1", "source_tokens": 245, "generated_at": "2026-02-11T16:48:30.939345"}}
{"question": "What additional feature does Amazon Textract's Analyze Document API offer compared to the standard OCR process?", "answer": "Amazon Textract's Analyze Document API performs key-value pair detection in addition to OCR, allowing text extractions to remain organized in their intended structure.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-11T16:48:35.929806"}}
{"question": "What are some examples of documents that the Analyze Document API can extract structured data from?", "answer": "The Analyze Document API can extract structured data from various document types including tax forms, financial reports, medical records, and loan applications.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-11T16:48:35.930047"}}
{"question": "How does the Analyze Expense API improve data extraction accuracy in comparison to traditional methods for extracting data from invoices and receipts?", "answer": "The Analyze Expense API can find and extract item, quantity, and prices that are not labeled with column headers for line items, providing normalized key names and column headers when extracting data from invoices and receipts so that downstream applications can easily compare output from many documents.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-2", "source_tokens": 390, "generated_at": "2026-02-11T16:48:35.930417"}}
{"question": "What features does Analyze Document API offer for extracting data from documents?", "answer": "Analyze Document API offers the following features for extracting data from documents: Forms, Tables, Queries, Custom Queries, Signatures, and Layout.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-11T16:48:40.312237"}}
{"question": "How can Queries feature be used in Analyze Document API?", "answer": "Queries can be used in Analyze Document API to specify the information needed from a document in the form of natural language questions and receive the answer as part of the response.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-11T16:48:40.312502"}}
{"question": "What is the difference in the number of Queries supported between synchronous and asynchronous operations in Analyze Document API?", "answer": "For synchronous operations, a maximum of 15 Queries per page is supported, while for asynchronous operations, a maximum of 30 queries per page is supported.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-3", "source_tokens": 302, "generated_at": "2026-02-11T16:48:40.312656"}}
{"question": "Which languages is Amazon Textract currently able to process for text extraction?", "answer": "Amazon Textract currently supports English, Spanish, Italian, Portuguese, French, and German languages for text extraction.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T16:48:44.739917"}}
{"question": "How does Amazon Textract handle handwriting and tables in documents?", "answer": "Amazon Textract uses machine learning to extract handwriting and structured information from documents, including tables. For best results, ensure tables are visually separated from surrounding elements and the text within them is upright.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T16:48:44.740146"}}
{"question": "How does logging work for Amazon Textract API calls in CloudTrail, and which actions are supported?", "answer": "Amazon Textract logs DetectDocumentText, AnalyzeDocument, StartDocumentTextDetection, StartDocumentAnalysis, GetDocumentTextDetection, and GetDocumentAnalysis API calls as CloudTrail events for tracking and monitoring purposes.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-4", "source_tokens": 461, "generated_at": "2026-02-11T16:48:44.740292"}}
{"question": "Which regions support Amazon Textract currently?", "answer": "Amazon Textract is currently available in the US East (Northern Virginia), US East (Ohio), US West (Oregon), US West (N. California), AWS GovCloud (US-West), AWS GovCloud (US-East), Canada (Central), EU (Ireland), EU (London), EU (Frankfurt), EU (Paris), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Seoul), and Asia Pacific (Mumbai) Regions.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:48:50.287393"}}
{"question": "How can I estimate the quota requirements for my use case of Amazon Textract?", "answer": "You can estimate the quota requirements for your use case of Amazon Textract using the Textract Service Quota calculator.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:48:50.287778"}}
{"question": "How does the performance of Amazon Textract in US East (Northern Virginia) compare to that in US West (N. California)?", "answer": "The text passage does not provide enough information to make a comparison between the performance of Amazon Textract in US East (Northern Virginia) and US West (N. California).", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-5", "source_tokens": 473, "generated_at": "2026-02-11T16:48:50.288035"}}
{"question": "How many pages can new AWS customers analyze for free with the Detect Document Text API each month?", "answer": "New AWS customers can analyze up to 1,000 pages per month for free with the Detect Document Text API.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-11T16:48:56.000905"}}
{"question": "What features does Amazon Textract's Analyze Document API offer, and how many pages can new customers use each month for free?", "answer": "Amazon Textract's Analyze Document API offers Signatures only and Forms, Tables, and Layout features. New customers can analyze up to 1,000 pages per month for free when using Signatures only, but only 100 pages per month for free when using Forms, Tables, and Layout features.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-11T16:48:56.001275"}}
{"question": "What's the difference between the number of free pages allowed for Analyze Document API with Signatures only and Analyze Document API with Forms, Tables, and Layout features?", "answer": "New customers can analyze up to 1,000 pages per month for free with the Analyze Document API when using Signatures only. However, when using Forms, Tables, and Layout features, the free tier is limited to 100 pages per month.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-6", "source_tokens": 303, "generated_at": "2026-02-11T16:48:56.001757"}}
{"question": "What is the purpose of Amazon Textract storing and using document and image inputs?", "answer": "Amazon Textract stores and uses document and image inputs solely to provide and maintain the service and to improve and develop the quality of Amazon Textract and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-11T16:49:00.530564"}}
{"question": "How does Amazon Textract utilize customer data for improving the service?", "answer": "Amazon Textract uses customer content for continuous improvement of the Amazon Textract customer experience, including the development and training of related technologies. No personally identifiable information is used to target products, services or marketing.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-11T16:49:00.530957"}}
{"question": "What's the difference between how Amazon Textract uses and Securely stores customer data compared to using it for targeted marketing?", "answer": "Amazon Textract uses customer content solely for providing and maintaining the service and improving the technology, while no personally identifiable information is used for targeted marketing.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-7", "source_tokens": 261, "generated_at": "2026-02-11T16:49:00.531396"}}
{"question": "In which AWS region is encrypted content processed by Amazon Textract stored at rest?", "answer": "The encrypted content processed by Amazon Textract is stored at rest in the AWS region where you are using Amazon Textract.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:49:05.209336"}}
{"question": "Why is some portion of content processed by Amazon Textract stored in another AWS region?", "answer": "Some portion of content processed by Amazon Textract is stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Textract customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:49:05.209607"}}
{"question": "How does the storage and processing of content used for Amazon Textract adapter training compare?", "answer": "During the training, any content used for generating adapters is processed internally within Amazon Textract for the duration of the training, and is stored and processed in the AWS region where you are training the adapter. Once training completes, the content is deleted.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-8", "source_tokens": 486, "generated_at": "2026-02-11T16:49:05.209763"}}
{"question": "What compliance standards is Amazon Textract eligible and compliant with?", "answer": "Amazon Textract is HIPAA eligible and compliant with PCI, ISO, and SOC.", "question_type": "factual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-11T16:49:09.180166"}}
{"question": "How does Amazon Textract support secure API calls?", "answer": "Amazon Textract supports secure API calls by enabling customers to initiate them from within their Amazon Virtual Private Cloud (Amazon VPC) using AWS PrivateLink.", "question_type": "conceptual", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-11T16:49:09.180421"}}
{"question": "What is the difference between using Amazon Textract through the public internet and using AWS PrivateLink?", "answer": "Using the public internet to access Amazon Textract means using the standard internet connection, while using AWS PrivateLink within an Amazon Virtual Private Cloud (Amazon VPC) allows customers to securely initiate API calls and avoid using the public internet.", "question_type": "comparison", "metadata": {"service": "TEXTRACT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "textract-faq-9", "source_tokens": 111, "generated_at": "2026-02-11T16:49:09.180799"}}
{"question": "What is Amazon Transcribe and how does it work?", "answer": "Amazon Transcribe is an AWS Artificial Intelligence (AI) service that converts speech to text using Automatic Speech Recognition (ASR) technology. It is used for various business applications like transcribing voice-based customer service calls, generating subtitles, and conducting text-based content analysis on audio/video content. The service converts audio input into text, enabling text-based applications like sentiment analysis, entity extraction, or multilingual conversations using Amazon Comprehend, Amazon Translate, Amazon Polly, Amazon Kendra, or Amazon OpenSearch.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-11T16:49:15.244007"}}
{"question": "What are the pricing and availability details for Amazon Transcribe Call Analytics?", "answer": "Amazon Transcribe Call Analytics is a feature of Amazon Transcribe that is available for use. The specific pricing details for this feature are not mentioned in the context.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-11T16:49:15.244414"}}
{"question": "How does Amazon Transcribe Medical differ from Amazon Transcribe Call Analytics?", "answer": "Amazon Transcribe Medical is a variant of Amazon Transcribe, designed to handle medical terminology and phrases with high accuracy. It is not explicitly stated in the context how it differs from Amazon Transcribe Call Analytics regarding features or functionalities.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-0", "source_tokens": 472, "generated_at": "2026-02-11T16:49:15.244667"}}
{"question": "What media types are supported for batch transcriptions in Amazon Transcribe?", "answer": "The context mentions that the supported media types for batch transcriptions in Amazon Transcribe differ from those for streaming transcriptions, but it doesn't specify which media types are supported for batch transcriptions. To find this information, please refer to the documentation page.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-11T16:49:20.940471"}}
{"question": "How can you use Amazon Transcribe on different devices?", "answer": "Amazon Transcribe is device agnostic and works with any device that includes an on-device microphone, such as phones, PCs, tablets, and IoT devices. Developers can call Amazon Transcribe API through their applications to access speech-to-text conversion capability. The service can detect the quality of the audio stream being input at the device and select the appropriate acoustic models for converting speech to text.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-11T16:49:20.940834"}}
{"question": "What's the difference in API call limits between Amazon Transcribe's batch and real-time services?", "answer": "The context states that Amazon Transcribe batch service calls are limited to four hours (or 2 GB) per API call, while the real-time service can accommodate open connections up to four hours long.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-1", "source_tokens": 435, "generated_at": "2026-02-11T16:49:20.941283"}}
{"question": "What characters are permitted in the DisplayAs column for phrases, apart from tab character (\\t)?", "answer": "UTF-8 characters are permitted in the DisplayAs column for phrases.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T16:49:25.546040"}}
{"question": "Why would creating multiple phrase entries for the same word help in speech recognition output with AWS Transcribe?", "answer": "Creating multiple phrase entries for the same word with different pronunciations can help improve speech recognition accuracy in cases where the word is pronounced differently.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T16:49:25.546403"}}
{"question": "How does the use of large custom vocabularies impact the performance and accuracy of speech recognition in AWS Transcribe?", "answer": "Using large custom vocabularies may lead to over-generation of custom words, especially when they contain words that are short and sound similar to many other words. It is preferable to split the large vocabulary into separate lists for different use cases or combine similar words as hyphen-separated phrases.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-2", "source_tokens": 410, "generated_at": "2026-02-11T16:49:25.546898"}}
{"question": "What information does Amazon Transcribe Call Analytics remove from the source audio?", "answer": "Amazon Transcribe Call Analytics removes sensitive personal information from both the transcripts and the source audio.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-11T16:49:30.933943"}}
{"question": "How does automatic content redaction for Amazon Transcribe work for identifying and redacting PII?", "answer": "Automatic content redaction identifies and redacts personally identifiable information (PII) from the transcripts generated by the service. However, due to the predictive nature of machine learning, it may not identify and redact all instances of PII.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-11T16:49:30.934308"}}
{"question": "What are the differences in capabilities between automatic content redaction for Amazon Transcribe's batch and streaming APIs?", "answer": "Automatic content redaction for Amazon Transcribe's batch API identifies and redacts PII from the transcripts, but does not provide the ability to only identify or redact specific PII types. In contrast, the streaming API allows for this capability, as well as the option to only identify PII without redacting.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-3", "source_tokens": 473, "generated_at": "2026-02-11T16:49:30.934807"}}
{"question": "What languages can be specified for Amazon Transcribe to identify from a media file?", "answer": "A list of languages can be specified for Amazon Transcribe to identify the language of a media file from.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-11T16:49:35.028292"}}
{"question": "Why is it beneficial to provide a list of languages for Amazon Transcribe to use in language identification?", "answer": "Providing a list of languages for Amazon Transcribe to use in language identification improves the accuracy of the language identification process.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-11T16:49:35.028573"}}
{"question": "How does the language identification process using a specified list compare to the process without a list in Amazon Transcribe?", "answer": "The language identification process using a specified list results in improved accuracy compared to the process where no list is provided and the system selects the language from all supported languages.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-4", "source_tokens": 447, "generated_at": "2026-02-11T16:49:35.028753"}}
{"question": "What technical controls does Amazon Transcribe implement to prevent unauthorized access to user content?", "answer": "Amazon Transcribe implements encryption at rest and in transit, designed to prevent unauthorized access to user content.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-11T16:49:39.247996"}}
{"question": "Why won't Amazon Transcribe store user training data for future model improvements?", "answer": "Amazon Transcribe does not store user training data to ensure user privacy and to maintain the self-contained nature of custom language models.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-11T16:49:39.248284"}}
{"question": "How is the experience of training a new model different when Amazon Transcribe does not retain the original training data?", "answer": "Training a new model with Amazon Transcribe involves submitting the same data set again and the possibility of longer technical support response times due to the lack of convenient access to previous training assets.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-5", "source_tokens": 445, "generated_at": "2026-02-11T16:49:39.248468"}}
{"question": "In which AWS regions is content processed by Amazon Transcribe encrypted and stored at rest?", "answer": "Content processed by Amazon Transcribe is encrypted and stored at rest in the AWS region where Amazon Transcribe is being used.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:49:43.790263"}}
{"question": "How does Amazon Transcribe Call Analytics improve customer experience and agent productivity?", "answer": "Amazon Transcribe Call Analytics uses AI-powered APIs to provide rich call transcripts and actionable conversation insights, which can be added into call applications to improve customer experience and agent productivity.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:49:43.790568"}}
{"question": "What is the difference between Amazon Transcribe and Amazon Transcribe Call Analytics?", "answer": "Amazon Transcribe is a service that converts speech to text, while Amazon Transcribe Call Analytics is an API that provides rich call transcripts and actionable conversation insights using AI-powered technologies.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-6", "source_tokens": 511, "generated_at": "2026-02-11T16:49:43.791010"}}
{"question": "What regions support generative call summarization with Amazon Transcribe Call Analytics?", "answer": "Generative call summarization is currently available only in US East (N. Virginia) and US West (Oregon) with Amazon Transcribe Call Analytics.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:49:49.298748"}}
{"question": "How does Amazon Transcribe Call Analytics help in call analysis?", "answer": "Amazon Transcribe Call Analytics helps in call analysis by providing valuable intelligence such as customer and agent sentiment scores, call drivers, call categories, and call summarization as an API output, which can be used in various applications like agent assist, summarization, supervisor alerts, and call analytics.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:49:49.299124"}}
{"question": "What's the difference between Amazon Transcribe Call Analytics and Amazon Transcribe Medical?", "answer": "Amazon Transcribe Call Analytics is a service for call analytics, which includes features like real-time and post-call analytics, automated contact categorization, and generative call summarization (for post-call analytics). Amazon Transcribe Medical, on the other hand, is an automatic speech recognition (ASR) service specifically designed for medical speech-to-text capabilities.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-7", "source_tokens": 456, "generated_at": "2026-02-11T16:49:49.299646"}}
{"question": "What language does Amazon Transcribe Medical support for medical transcription?", "answer": "Amazon Transcribe Medical currently supports medical transcription in US English.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-11T16:49:53.846605"}}
{"question": "Which industries can benefit from using Amazon Transcribe Medical for speech-to-text transcription?", "answer": "Amazon Transcribe Medical supports a variety of use cases, including clinical documentation workflow, drug safety monitoring (pharmacovigilance), subtitling for telemedicine, and contact center analytics in the healthcare and life sciences domains.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-11T16:49:53.846954"}}
{"question": "How does Amazon Transcribe Medical compare to other transcription services regarding supported industries?", "answer": "Amazon Transcribe Medical caters to industries in the healthcare and life sciences domains, specifically for clinical documentation workflow, drug safety monitoring (pharmacovigilance), subtitling for telemedicine, and contact center analytics.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-8", "source_tokens": 422, "generated_at": "2026-02-11T16:49:53.847203"}}
{"question": "What is required for training a custom language model in Amazon Transcribe Medical?", "answer": "Users need to supply text data in an Amazon S3 bucket and use the Amazon Transcribe service console to load and process the data for training. The training process is automated and does not require much user intervention.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-11T16:49:58.788311"}}
{"question": "How does providing custom text data improve the accuracy of Amazon Transcribe Medical?", "answer": "Providing text data that is relevant to the audio being transcribed and contains domain-specific words, phrases, and combinations allows the custom language model to better understand and transcribe the audio.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-11T16:49:58.788681"}}
{"question": "What are the differences between training a custom language model for US English and Australian English in Amazon Transcribe Medical?", "answer": "The main difference is the language used in the text data. US English and Australian English have distinct vocabularies and grammar rules. This difference affects the accuracy and understanding of the custom language model when transcribing audio in each language.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-9", "source_tokens": 502, "generated_at": "2026-02-11T16:49:58.789115"}}
{"question": "How long does it take to train an Amazon Transcribe custom model?", "answer": "Model training usually takes between 6 and 10 hours.", "question_type": "factual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-11T16:50:02.529165"}}
{"question": "Why is the quality of training data important for Amazon Transcribe's transcription accuracy?", "answer": "The performance improvement in transcription accuracy depends on the quality of the training data and the use case. In some scenarios, improvements of up to 10% to 15% relative accuracy have been observed.", "question_type": "conceptual", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-11T16:50:02.529537"}}
{"question": "How does the training time for Amazon Transcribe custom models compare to the number of data sets provided?", "answer": "The length of training time depends on the size of the data set.", "question_type": "comparison", "metadata": {"service": "TRANSCRIBE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transcribe-faq-10", "source_tokens": 309, "generated_at": "2026-02-11T16:50:02.530060"}}
{"question": "What are the number of FAQ categories in the AWS Transit Gateway documentation?", "answer": "There are three categories: General, Performance and limits, and Security and compliance.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-11T16:50:06.669647"}}
{"question": "How does AWS Transit Gateway's Network Manager feature work in the context of content delivery?", "answer": "The exact functioning of AWS Transit Gateway's Network Manager feature in relation to content delivery is not explicitly stated in the context.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-11T16:50:06.669927"}}
{"question": "How does the number of FAQs in the 'Performance and limits' category compare to the 'Security and compliance' category in the AWS Transit Gateway documentation?", "answer": "The context does not provide enough information to make a comparison between the number of FAQs in the 'Performance and limits' and 'Security and compliance' categories.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-0", "source_tokens": 72, "generated_at": "2026-02-11T16:50:06.670103"}}
{"question": "In which AWS Regions is Transit Gateway available?", "answer": "AWS Transit Gateway is available in the following Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (Northern California), AWS GovCloud (US-East), AWS GovCloud (US-West), Canada (Central), South America (SÃ£o Paulo), Africa (Cape Town), EU (Ireland), EU (Frankfurt), EU (Paris), EU (London), EU (Stockholm), EU (Milan), Middle East (Bahrain), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Beijing), Asia Pacific (Ningxia), South America (Sao Paulo), Asia Pacific (Jakarta), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), and Canada West (Calgary).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-11T16:50:16.913438"}}
{"question": "What Regions support Transit Gateway Peering?", "answer": "Transit Gateway Peering is supported in the following Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), AWS GovCloud (US-East), AWS GovCloud (US-West), Canada (Central), EU (Ireland), EU (Frankfurt), EU (Paris), EU (London), EU (Stockholm), EU (Milan), Middle East (Bahrain), Africa (Cape Town), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Osaka), Asia Pacific (Beijing), Asia Pacific (Ningxia), South America (Sao Paulo), Asia Pacific (Jakarta), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), and Israel (Tel Aviv).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-11T16:50:16.913833"}}
{"question": "How does Transit Gateway peering differ from Transit Gateway in terms of availability?", "answer": "Both Transit Gateway and Transit Gateway Peering are available in the same AWS Regions. The difference lies in the feature itself, not in the availability.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-1", "source_tokens": 452, "generated_at": "2026-02-11T16:50:16.914265"}}
{"question": "Which AWS Regions support Transit Gateway Multicast with IGMP?", "answer": "Transit Gateway Multicast with IGMP is available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (London), Europe (Paris), Europe (Frankfurt), Europe (Stockholm), Europe (Milan), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Osaka), Asia Pacific (Jakarta), Canada (Central), South America (SÃ£o Paulo), Africa (Cape Town), Middle East (Bahrain), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), GovCloud (US-East), and GovCloud (US-West).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-11T16:50:25.475587"}}
{"question": "Why is IGMP support important for Transit Gateway Multicast?", "answer": "IGMP (Internet Group Management Protocol) support allows for efficient multicast delivery over IP networks by reducing the amount of control traffic. This can lead to cost savings and improved network performance. With IGMP support, Transit Gateway Multicast can automatically discover and join multicast groups, making it easier to scale multicast deployments.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-11T16:50:25.475894"}}
{"question": "How does Transit Gateway Multicast with IGMP compare to Transit Gateway Multicast without IGMP?", "answer": "Transit Gateway Multicast with IGMP allows for more efficient multicast delivery by reducing control traffic and automatically discovering and joining multicast groups. In contrast, Transit Gateway Multicast without IGMP does not have these features, making it less efficient and potentially more costly for large-scale multicast deployments.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-2", "source_tokens": 450, "generated_at": "2026-02-11T16:50:25.476069"}}
{"question": "Which AWS Regions support Transit Gateway Connect?", "answer": "Transit Gateway Connect is available in US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (London), Europe (Paris), Europe (Frankfurt), Europe (Stockholm), Europe (Milan), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Asia Pacific (Beijing), Asia Pacific (Ningxia), Asia Pacific (Osaka), Asia Pacific (Jakarta), Canada (Central), South America (SÃ£o Paulo), Africa (Cape Town), Middle East (Bahrain), Middle East (UAE), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), GovCloud (US-East), and GovCloud (US-West)", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-11T16:50:33.574443"}}
{"question": "Why is Transit Gateway Connect available in various AWS Regions?", "answer": "Transit Gateway Connect is available in multiple AWS Regions to provide users with local network connectivity and improve latency by keeping their traffic within the same region", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-11T16:50:33.574785"}}
{"question": "How does Transit Gateway Connect in US West (Oregon) compare to Transit Gateway Connect in US East (N. Virginia)?", "answer": "Both Transit Gateway Connect in US West (Oregon) and Transit Gateway Connect in US East (N. Virginia) provide network connectivity services. The main difference lies in their geographical locations, with US West (Oregon) being in the western part of the United States and US East (N. Virginia) being in the eastern part. Users in these regions may have different latency requirements and network traffic patterns, so choosing the right AWS Region for Transit Gateway Connect depends on their specific use case and location", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-3", "source_tokens": 219, "generated_at": "2026-02-11T16:50:33.575000"}}
{"question": "What can you use route tables for in an AWS Transit Gateway?", "answer": "You can use route tables in an AWS Transit Gateway to segment your network, create isolated networks, and control the routing of traffic between attached Amazon VPCs and VPNs.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-11T16:50:39.731886"}}
{"question": "What determines the next hop for traffic in an AWS Transit Gateway?", "answer": "The next hop for traffic in an AWS Transit Gateway is determined by the routes in the route tables, which point to an Amazon VPC, a VPN connection, a Direct Connect gateway, a Transit Gateway Connect, or a peered Transit Gateway based on the destination IP address of the packet.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-11T16:50:39.732254"}}
{"question": "What's the difference between the default route table and additional route tables in an AWS Transit Gateway?", "answer": "The default route table in an AWS Transit Gateway is the one that comes with the Transit Gateway and is used by Amazon VPCs, VPNs, Direct Connect gateways, Transit Gateway Connect, and peered Transit Gateways by default. Additional route tables are ones that you create and associate Amazon VPCs, Direct Connect gateways, VPNs, Transit Gateway Connect, and peered Transit Gateways with, allowing you to control the routing of traffic in a more granular way.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-4", "source_tokens": 241, "generated_at": "2026-02-11T16:50:39.732699"}}
{"question": "What method is used for propagating routes between an on-premises network and the AWS Transit Gateway?", "answer": "Routes are propagated between the AWS Transit Gateway and an on-premises router using Border Gateway Protocol (BGP).", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T16:50:46.713931"}}
{"question": "How does the propagation of routes to Amazon VPCs in the AWS Transit Gateway differ from the propagation of routes to on-premises networks?", "answer": "Routes to Amazon VPCs are propagated using internal APIs, not BGP. The VPC owner needs to create a static route to send traffic to the AWS Transit Gateway.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T16:50:46.714291"}}
{"question": "What are the two ways that routes get propagated in the AWS Transit Gateway and how does AWS Transit Gateway Connect simplify branch connectivity?", "answer": "The two ways that routes get propagated in the AWS Transit Gateway are: (1) routes propagated to/from on-premises networks using BGP and (2) routes propagated to/from Amazon VPCs using internal APIs. AWS Transit Gateway Connect simplifies branch connectivity through native integration of SD-WAN network virtual appliances into AWS Transit Gateway, providing a new logical attachment type called Connect attachment that utilizes the Amazon VPC or AWS Direct Connect attachments as the underlying network transport and supports standard protocols such as Generic Routing Encapsulation (GRE) and Border Gateway Protocol (BGP) over the Connect attachment.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-5", "source_tokens": 482, "generated_at": "2026-02-11T16:50:46.714508"}}
{"question": "Which protocols are required for AWS Transit Gateway Connect to work?", "answer": "AWS Transit Gateway Connect supports standard protocols such as GRE and BGP.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:50:50.808226"}}
{"question": "Can you create Connect attachments on an existing AWS Transit Gateway?", "answer": "Yes, you can create Connect attachments on an existing AWS Transit Gateway.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:50:50.808591"}}
{"question": "How does routing multicast traffic work between different VPC attachments to an AWS Transit Gateway?", "answer": "You can route multicast traffic within and between VPC attachments to a Transit Gateway. Multicast routing is not supported over AWS Direct Connect, AWS Site-to-Site VPN, and peering attachments.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-6", "source_tokens": 475, "generated_at": "2026-02-11T16:50:50.809111"}}
{"question": "What IP versions can be used for AWS Transit Gateway Connect's GRE tunnel and BGP addresses?", "answer": "Both the GRE tunnel and BGP addresses can be configured with IPv6 addresses.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-11T16:50:56.308335"}}
{"question": "How does AWS Transit Gateway Network Manager manage and monitor networking resources and connections?", "answer": "AWS Transit Gateway Network Manager is a feature of AWS Transit Gateway that centralizes management and monitoring of networking resources and connections to remote locations. It allows users to create a 'global network', register Transit Gateways from any AWS Region, add on-premises or cloud resources, and monitor the global network through Network Managerâ€™s visualizations, events, and metrics.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-11T16:50:56.308705"}}
{"question": "What are the differences between configuring the same and different address families for the GRE tunnel and BGP addresses in AWS Transit Gateway Connect?", "answer": "Both the GRE tunnel and BGP addresses can be configured with the same or different address families. For example, you can configure the GRE tunnel with an IPv4 address range and the BGP addresses with an IPv6 address range and vice versa.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-7", "source_tokens": 469, "generated_at": "2026-02-11T16:50:56.308931"}}
{"question": "What does the AWS Transit Gateway Network Manager service represent in AWS?", "answer": "An AWS Transit Gateway Network Manager object represents your private global network in AWS, including Transit Gateways, their attachments, AWS partner SD-WAN network virtual appliances, and on-premises devices, sites, links, and connections.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-11T16:51:02.287788"}}
{"question": "How can the AWS Transit Gateway Network Manager dashboard help you monitor your global network?", "answer": "The AWS Transit Gateway Network Manager dashboard provides a logical and geographic view of your network resources and connections, along with connection status. It also shows events and metrics, such as bytes in/out, packets in/out, packets dropped, and AWS Site-to-Site VPN up/down metrics. AWS Transit Gateway Network Manager also offers real-time network events and metrics through AWS CloudWatch.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-11T16:51:02.288105"}}
{"question": "What is the difference between the event notifications and metrics available in AWS Transit Gateway Network Manager?", "answer": "Event notifications are delivered through CloudWatch Events for network topology changes, routing updates, and connection status updates. Metrics include bytes in/out, packets in/out, packets dropped, and AWS Site-to-Site VPN up/down metrics.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-8", "source_tokens": 503, "generated_at": "2026-02-11T16:51:02.288543"}}
{"question": "What does AWS Route Analyzer verify in a Transit Gateway's routing configuration?", "answer": "AWS Route Analyzer verifies the configuration of Transit Gateway route tables between given source and destination.", "question_type": "factual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-11T16:51:06.129401"}}
{"question": "How does Route Analyzer in AWS Transit Gateway Network Manager help users?", "answer": "Route Analyzer is a feature that helps users to verify routing configurations of Transit Gateways across their global network.", "question_type": "conceptual", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-11T16:51:06.129699"}}
{"question": "What components of a Transit Gateway's routing configuration does Route Analyzer compare?", "answer": "Route Analyzer compares the Transit Gateway route table configuration between different Transit Gateways in a user's global network.", "question_type": "comparison", "metadata": {"service": "TRANSIT", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "transit-faq-9", "source_tokens": 239, "generated_at": "2026-02-11T16:51:06.130183"}}
{"question": "What languages does Amazon Translate support for text translation?", "answer": "Amazon Translate supports text translation between 75 languages including Afrikaans, Albanian, Amharic, Arabic, Armenian, Azerbaijani, Bengali, Bosnian, Bulgarian, Chinese (Simplified), Catalan, Chinese (Traditional), Croatian, Czech, Danish, Dari, Dutch, English, Estonian, Finnish, French, French (Canada), Georgian, German, Greek, Gujarati, Haitian Creole, Hausa, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Irish, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Malayalam, Maltese, Mongolian, Marathi, Norwegian, Farsi (Persian), Pashto, Polish, Portuguese, Portuguese (Portugal), Punjabi, Romanian, Russian, Serbian, Sinhala, Slovak, Slovenian, Somali, Spanish, Spanish (Mexico), Swahili, Swedish, Filipino Tagalog, Tamil, Telugu, Thai, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, and Welsh.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-11T16:51:15.488958"}}
{"question": "How does Amazon Translate's Neural Machine Translation service work?", "answer": "Amazon Translate is a Neural Machine Translation (MT) service that uses deep learning methods to provide high-quality, affordable, and customizable language translation. It can be used via an API to translate text from the source language to the target language, either in real-time or in batches.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-11T16:51:15.489263"}}
{"question": "How does Amazon Translate's Neural Machine Translation service compare to a traditional machine translation service?", "answer": "Amazon Translate's Neural Machine Translation (NMT) service uses deep learning methods for translation, while traditional machine translation services may use rule-based or statistical methods. The NMT service provides high-quality translations and can be used via an API for both real-time and batch translation. However, without additional context, it's impossible to determine if there are other differences in features, performance, or pricing between the two types of services.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-0", "source_tokens": 440, "generated_at": "2026-02-11T16:51:15.489710"}}
{"question": "What are some benefits of using Amazon Translate for businesses with large volumes of content?", "answer": "Amazon Translate helps businesses reach more customers, communicate effectively, and decrease their TCO by enabling them to translate large volumes of content in multiple languages quickly and cost-effectively. It also allows LSPs to increase productivity and protect IP by using Active Custom Translation.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-11T16:51:21.045332"}}
{"question": "Why would a business choose to use Amazon Translate over human translators for large volumes of content?", "answer": "Amazon Translate offers a cost-effective solution for businesses that need to translate large volumes of content. It allows them to translate content they could not before due to cost constraints, and also enables LSPs to increase productivity and focus on high-end creative content.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-11T16:51:21.045683"}}
{"question": "How does Amazon Translate compare to human translators for large volumes of content in terms of cost and productivity?", "answer": "Amazon Translate costs a fraction of the cost of human translators, at 0.05% at $15/1M characters versus $30K for human translation on average. It also allows LSPs to increase productivity by up to 50%.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-1", "source_tokens": 448, "generated_at": "2026-02-11T16:51:21.045903"}}
{"question": "What is the process of getting started with Amazon Translate using the console?", "answer": "You can get started with Amazon Translate using the console by translating some text. The console allows you to pass source text and indicate the source and target languages. Amazon Translate will return the text translated into the target language.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-11T16:51:26.262128"}}
{"question": "How does Amazon Translate identify the source language when it's unknown?", "answer": "Amazon Translate uses Amazon Comprehend behind the scenes to identify the source language when it's unknown. It will report the identified language back along with the translation to the target language.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-11T16:51:26.262393"}}
{"question": "What are the main ways to use Amazon Translate API for translating text?", "answer": "The main ways to use Amazon Translate API are: first, to integrate it into your application for localizing dynamic components such as multi-participant chat; second, to string it with other services for language-independent processing, like database services for website localization; and third, to translate batches of documents for industries like financial services, legal teams, and patent attorneys.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-2", "source_tokens": 359, "generated_at": "2026-02-11T16:51:26.262546"}}
{"question": "What is the limit for Amazon Translate real-time API call size?", "answer": "Amazon Translate real-time service calls are limited to 5,000 bytes per API call.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-11T16:51:31.348676"}}
{"question": "How can large documents be translated using Amazon Translate asynchronous Batch Translation?", "answer": "Amazon Translate asynchronous Batch Translation accepts a batch of up to 5 GB in size per API call, with each document not exceeding 20 MB in size, and containing no more than 1,000,000 characters. Customers can translate text of any length by breaking up large documents into sections and paragraphs.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-11T16:51:31.348964"}}
{"question": "How does the size limit for Amazon Translate asynchronous Batch Translation compare to real-time API calls?", "answer": "Amazon Translate real-time API calls have a limit of 5,000 bytes per call, while asynchronous Batch Translation accepts a batch of up to 5 GB in size per API call.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-3", "source_tokens": 404, "generated_at": "2026-02-11T16:51:31.349411"}}
{"question": "What is the purpose of storing and using text inputs processed by Amazon Translate?", "answer": "Amazon Translate stores and uses text inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Translate and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-11T16:51:36.617594"}}
{"question": "How does Amazon ensure the security and privacy of the content used in Amazon Translate?", "answer": "Amazon implements appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that their use complies with their commitments to you.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-11T16:51:36.617963"}}
{"question": "What is the difference in data handling between Amazon Translate and other machine-learning/artificial-intelligence technologies when it comes to user content?", "answer": "Amazon Translate stores and uses text inputs processed by the service for providing and maintaining the service and improving the quality of Amazon Translate, while other machine-learning/artificial-intelligence technologies may use the content for targeting products, services or marketing to users.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-4", "source_tokens": 389, "generated_at": "2026-02-11T16:51:36.618393"}}
{"question": "In which AWS regions is content processed by Amazon Translate encrypted and stored at rest?", "answer": "Content processed by Amazon Translate is encrypted and stored at rest in the AWS region where Amazon Translate is being used.", "question_type": "factual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-11T16:51:41.705580"}}
{"question": "Why is some content processed by Amazon Translate stored in another AWS region?", "answer": "Some content processed by Amazon Translate may be stored in another AWS region solely in connection with the continuous improvement and development of the Amazon Translate customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "conceptual", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-11T16:51:41.705969"}}
{"question": "How does the storage location of content processed by Amazon Translate in connection with continuous improvement and development compare to the storage location for regular use?", "answer": "Content processed by Amazon Translate is encrypted and stored at rest in the AWS region where Amazon Translate is being used for regular use. However, some portion of content may be stored in another AWS region solely in connection with the continuous improvement and development of the Amazon Translate customer experience and other Amazon machine-learning/artificial-intelligence technologies.", "question_type": "comparison", "metadata": {"service": "TRANSLATE", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "translate-faq-5", "source_tokens": 318, "generated_at": "2026-02-11T16:51:41.706194"}}
{"question": "What IP address ranges can I choose for my Amazon VPC?", "answer": "You can select your own IP address ranges for your Amazon VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:51:46.345850"}}
{"question": "How does Amazon VPC allow me to control access to my AWS resources?", "answer": "Amazon VPC lets you create a logically isolated section of the AWS cloud and configure security groups and network access control lists to help control access to Amazon EC2 instances in each subnet.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:51:46.346173"}}
{"question": "How does VPC Traffic Mirroring compare to Elastic Network Interfaces in terms of security and filtering?", "answer": "VPC Traffic Mirroring and Elastic Network Interfaces are both used for network traffic in Amazon VPC, but they serve different purposes. VPC Traffic Mirroring is used for traffic analysis and monitoring, while Elastic Network Interfaces are used to replace the primary network interface or to create additional network interfaces for a single instance.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-0", "source_tokens": 377, "generated_at": "2026-02-11T16:51:46.346350"}}
{"question": "What is a Subnet in an Amazon VPC?", "answer": "A Subnet is a segment of a Virtual Private Cloud's (VPC) IP address range where you can place groups of isolated resources.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-11T16:51:50.916862"}}
{"question": "How does a NAT Gateway work in an Amazon VPC?", "answer": "A NAT Gateway is a managed Network Address Translation (NAT) service in an Amazon VPC that allows resources in a private subnet to access the Internet while keeping their IP addresses private.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-11T16:51:50.917235"}}
{"question": "What's the difference between an Internet Gateway and a NAT Gateway in an Amazon VPC?", "answer": "An Internet Gateway is the Amazon VPC side of a connection to the public Internet, while a NAT Gateway is a managed Network Address Translation (NAT) service that allows resources in a private subnet to access the Internet while keeping their IP addresses private.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-1", "source_tokens": 353, "generated_at": "2026-02-11T16:51:50.917459"}}
{"question": "What are the four options for creating VPCs in AWS?", "answer": "The four options for creating VPCs in AWS are: Amazon VPC with a single public subnet only, Amazon VPC with public and private subnets, Amazon VPC with public and private subnets and AWS Site-to-Site VPN access, and Amazon VPC with a private subnet only and AWS Site-to-Site VPC access.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-11T16:51:56.521785"}}
{"question": "What is the difference between gateway type and interface type endpoints for VPC in AWS?", "answer": "Gateway type endpoints are available only for specific AWS services like S3 and DynamoDB, add an entry to your route table, and route the traffic to the supported services through Amazonâ€™s private network. Interface type endpoints provide private connectivity to services powered by AWS PrivateLink and support connectivity over Direct Connect.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-11T16:51:56.522045"}}
{"question": "Why would you choose to create an Amazon VPC with public and private subnets and AWS Site-to-Site VPN access?", "answer": "You would choose to create an Amazon VPC with public and private subnets and AWS Site-to-Site VPN access if you want to have a mix of publicly accessible and private resources, and also want to securely connect your VPC to your own network using VPN.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-2", "source_tokens": 428, "generated_at": "2026-02-11T16:51:56.522198"}}
{"question": "What are the charges for using an Internet gateway in an Amazon VPC?", "answer": "There are no additional charges for creating and using an Internet gateway in an Amazon VPC. Usage charges for other AWS services, including data transfer charges, still apply.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:52:02.569076"}}
{"question": "How does connecting an Amazon VPC to the internet via an Internet gateway differ from connecting to a corporate data center using a VPN connection?", "answer": "When you connect an Amazon VPC to the internet via an Internet gateway, there are no additional data transfer charges within the VPC for accessing AWS resources. However, if you access AWS resources via the VPN connection, you will incur Internet data transfer charges. Additionally, when you connect your VPC to the internet, you can use public IP addresses for instances to receive unsolicited inbound traffic, which is not possible with a VPN connection.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:52:02.569386"}}
{"question": "What's the difference in data transfer charges when using an Internet gateway versus a VPN connection to access AWS resources from an Amazon VPC?", "answer": "When accessing AWS resources within an Amazon VPC via an Internet gateway, there are no additional data transfer charges. However, when accessing AWS resources via a VPN connection from the VPC, you will incur Internet data transfer charges.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-3", "source_tokens": 509, "generated_at": "2026-02-11T16:52:02.569866"}}
{"question": "What type of IP addresses can be routed on the internet in a VPC?", "answer": "Only public IPv4 addresses, including Elastic IP addresses (EIPs) and IPv6 GUA can be routed on the internet in a VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:52:08.105786"}}
{"question": "How can instances without public IP addresses access the internet in a VPC?", "answer": "Instances without public IP addresses can access the internet in a VPC by routing their traffic through a NAT gateway or a NAT instance or by routing their Internet traffic down the virtual private gateway to your existing datacenter.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:52:08.106082"}}
{"question": "How does using a public IP address in a VPC affect communication between instances and services?", "answer": "When using a public IP address in a VPC, all communication between instances and services hosted in AWS use AWS's private network. Packets that originate from the AWS network with a destination on the AWS network stay on the AWS global network, except traffic to or from AWS China Regions. All data flowing across the AWS global network that interconnects data centers and Regions is automatically encrypted at the physical layer before it leaves secured facilities.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-4", "source_tokens": 506, "generated_at": "2026-02-11T16:52:08.106259"}}
{"question": "What IP address ranges can be used for the primary CIDR block when creating a VPC?", "answer": "Any IPv4 address range, including RFC 1918 or publicly routable IP ranges, can be used for the primary CIDR block when creating a VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T16:52:13.342357"}}
{"question": "Why are publicly routable IP blocks for secondary CIDR blocks restricted in AWS VPC?", "answer": "Publicly routable IP blocks for secondary CIDR blocks in AWS VPC are only reachable via the Virtual Private Gateway and cannot be accessed over the Internet through the Internet gateway due to security reasons.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T16:52:13.342662"}}
{"question": "How does one bring their public IPv4 addresses into AWS VPC and route traffic between VPC and on-premises network?", "answer": "To bring public IPv4 addresses into AWS VPC and route traffic between VPC and on-premises network, one needs to advertise these addresses to the Internet from their on-premises network and use AWS Direct Connect or VPN connection for routing.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-5", "source_tokens": 497, "generated_at": "2026-02-11T16:52:13.342917"}}
{"question": "What is the size range for each IPv4 secondary range in a VPC?", "answer": "Each secondary IPv4 range in a VPC can be between /28 (14 IP addresses) and /16 in size.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-11T16:52:17.925636"}}
{"question": "Why would you add secondary IPv4 ranges to a VPC?", "answer": "You can add secondary IPv4 ranges to a VPC to expand or shrink its size. Each range can be between /28 and /16 in size.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-11T16:52:17.926003"}}
{"question": "How does the size of a VPC subnet compare between IPv4 and IPv6?", "answer": "The size of an IPv4 subnet can range from /28 (14 IP addresses) to the size of the VPC itself, while an IPv6 subnet is fixed to be a /64 (65,536 IP addresses).", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-6", "source_tokens": 375, "generated_at": "2026-02-11T16:52:17.926445"}}
{"question": "What is the consequence of not specifying the primary private IPv4 address when launching an EC2 instance in a non-IPv6-only subnet?", "answer": "AWS will automatically assign an IP address from the subnet's IP address range.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-11T16:52:22.150452"}}
{"question": "How can you modify the IPv6 address assigned to an IPv6-only EC2 instance?", "answer": "You can modify the IPv6 address by associating a new IPv6 GUA and removing the existing IPv6 GUA.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-11T16:52:22.150816"}}
{"question": "What are the requirements for assigning a private IP address to an EC2 instance?", "answer": "The IP address must be part of the associated subnet's IP address range, not reserved by Amazon, and not currently assigned to another interface.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-7", "source_tokens": 449, "generated_at": "2026-02-11T16:52:22.151322"}}
{"question": "What number of secondary private IP addresses can be assigned to an EC2 instance depending on its type?", "answer": "The number of secondary private IP addresses that can be assigned to an EC2 instance depends on its instance type. For more information, refer to the EC2 User Guide.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-11T16:52:27.999561"}}
{"question": "How does Amazon VPC's Bring Your Own IP (BYOIP) feature differ from Elastic IP addresses?", "answer": "Amazon VPC's Bring Your Own IP (BYOIP) feature allows customers to move their existing publicly routable IPv4 or IPv6 address space to AWS for use with their resources. Customers continue to own the IP range and can create Elastic IPs or use Amazon-supplied IPs with their resources. Elastic IP addresses, on the other hand, are reachable from the Internet but cannot be used in subnets configured to use a NAT gateway or NAT instance.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-11T16:52:27.999820"}}
{"question": "Can Elastic IP addresses from BYOIP be used in subnets with a NAT gateway or NAT instance?", "answer": "No, Elastic IP addresses created from Bring Your Own IP (BYOIP) address space cannot be used in subnets configured to use a NAT gateway or a NAT instance to access the Internet.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-8", "source_tokens": 350, "generated_at": "2026-02-11T16:52:27.999976"}}
{"question": "What type of IP addresses can be brought to AWS through BYOIP for IP reputation reasons?", "answer": "Customers can bring IPv4 addresses to AWS through BYOIP for maintaining their existing sending success rate and preserving IP reputation.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-11T16:52:32.725642"}}
{"question": "Why might a customer choose to use Bring Your Own IPs (BYOIP) for workloads that rely on IP address whitelisting?", "answer": "Customers can use BYOIP to move workloads that rely on IP address whitelisting to AWS without the need to re-establish the whitelists with new IP addresses.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-11T16:52:32.726590"}}
{"question": "What's the difference between the maximum IPv4 and IPv6 prefix sizes that can be brought to AWS using BYOIP?", "answer": "The most specific IPv4 prefix you can bring through BYOIP is a /24 prefix, whereas the most specific IPv6 prefix is a /48 prefix.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-9", "source_tokens": 504, "generated_at": "2026-02-11T16:52:32.726856"}}
{"question": "What features does Amazon VPC IP Address Manager (IPAM) offer for IP address management?", "answer": "Amazon VPC IP Address Manager (IPAM) offers features such as automating IP address allocations across hundreds of accounts and VPCs based on configurable business rules, monitoring IP addresses and enabling alerts for potential issues like depleting IP addresses or overlapping IP addresses, troubleshooting network connectivity issues, and auditing IP addresses with historical data.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:52:38.740492"}}
{"question": "How does IPAM help with IP address management compared to using spreadsheets or homegrown tools?", "answer": "IPAM helps streamline IP address management by automating the allocation process and eliminating the need for manual work and maintenance that comes with spreadsheets or homegrown tools. It also provides features like detecting IP address overlaps and creating alarms for IPAM exhaustion or resource non-compliance.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:52:38.740784"}}
{"question": "What are the benefits of using Amazon VPC IP Address Manager (IPAM) for IP address management?", "answer": "Benefits of using Amazon VPC IP Address Manager (IPAM) include faster rollout of applications due to automated IP address allocations, quick identification and resolution of IP address-related network issues, and retrospective analysis and auditing capabilities.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-10", "source_tokens": 487, "generated_at": "2026-02-11T16:52:38.740960"}}
{"question": "What are the two default scopes in IPAM and what type of IP space do they represent?", "answer": "The two default scopes in IPAM are the private scope, which is intended for all private space, and the public scope, which is intended for all public space.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-11T16:52:42.978675"}}
{"question": "How can you organize IP addresses within IPAM pools?", "answer": "IPAM pools enable you to organize your IP addresses according to your routing and security needs. You can have multiple pools within a top-level pool.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-11T16:52:42.979080"}}
{"question": "What is the difference between IPAM pools and allocations?", "answer": "IPAM pools are collections of contiguous IP address ranges (or CIDRs). Allocations are CIDR assignments from an IPAM pool to another resource or IPAM pool.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-11", "source_tokens": 366, "generated_at": "2026-02-11T16:52:42.979665"}}
{"question": "What size increments are Amazon IPv6 CIDR blocks allocated in VPC?", "answer": "Amazon IPv6 CIDR blocks for VPC allocation start in /52 increments.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-11T16:52:47.133289"}}
{"question": "How can contiguous IPv6 CIDR blocks be used in Amazon VPC?", "answer": "Contiguous IPv6 CIDR blocks in Amazon VPC allow you to aggregate CIDRs in a single entry across various networking and security constructs, enhancing IP address management and usage.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-11T16:52:47.133647"}}
{"question": "What is the difference between security groups and network ACLs in Amazon VPC?", "answer": "Security groups are used to specify inbound and outbound network traffic allowed to or from an Amazon EC2 instance, while network ACLs operate at the subnet level and evaluate traffic entering and exiting a subnet, setting both Allow and Deny rules.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-12", "source_tokens": 490, "generated_at": "2026-02-11T16:52:47.134103"}}
{"question": "What is the difference between stateful and stateless filtering in terms of tracking requests and replies?", "answer": "Stateful filtering tracks the origin of a request and allows the reply to be returned to the originating computer, while stateless filtering only examines the source or destination IP address and port number, ignoring whether the traffic is a new request or a reply.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-11T16:52:52.257663"}}
{"question": "How does stateful filtering work in an Amazon VPC context?", "answer": "Stateful filtering in an Amazon VPC tracks the origin and destination port numbers and IP addresses, allowing the return traffic to pass through the stateful filter between the client and the webserver.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-11T16:52:52.257946"}}
{"question": "What ports need to be opened in a filtering device for a webserver that uses stateful filtering?", "answer": "Only one rule is required: Allow traffic inbound to the web server on TCP port 80. The filtering device maintains a state table that tracks the origin and destination port numbers and IP addresses, allowing the return traffic to pass through.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-13", "source_tokens": 403, "generated_at": "2026-02-11T16:52:52.258316"}}
{"question": "What communication option allows traffic to remain within Amazon's network when accessing Amazon S3?", "answer": "VPC Endpoint for S3", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-11T16:52:56.577637"}}
{"question": "How does using VPC flow logs help in monitoring network traffic in Amazon VPC?", "answer": "VPC flow logs enable users to capture information about IP traffic going to and from network interfaces in Amazon VPC. The data can be published to Amazon CloudWatch Logs or Amazon S3, and users can monitor it for operational visibility, detect anomalies, prevent data leakage, or troubleshoot network connectivity and configuration issues.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-11T16:52:56.577970"}}
{"question": "What are the main differences between using VPC Endpoint for S3 and an Internet gateway for accessing S3 from a VPC?", "answer": "VPC Endpoint for S3 keeps all traffic within Amazon's network, allowing users to apply additional access policies. An Internet gateway enables Internet access and allows instances in the VPC to communicate directly with Amazon S3.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-14", "source_tokens": 320, "generated_at": "2026-02-11T16:52:56.578286"}}
{"question": "What metadata fields can you choose to capture when creating a VPC flow log subscription?", "answer": "You can choose the metadata fields you wish to capture when creating a VPC flow log subscription.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-11T16:53:00.926037"}}
{"question": "How does creating a VPC flow log impact network performance?", "answer": "Creating or deleting flow logs does not affect network performance as data collection occurs outside the path of network traffic.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-11T16:53:00.926390"}}
{"question": "What are the differences between analyzing VPC flow logs in CloudWatch Logs and Amazon S3?", "answer": "You can use tools like CloudWatch Log Insights or CloudWatch Contributor Insights to analyze VPC flow logs delivered to CloudWatch Logs. Alternatively, you can use tools like Amazon Athena or AWS QuickSight to query and visualize your VPC flow logs delivered to Amazon S3.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-15", "source_tokens": 505, "generated_at": "2026-02-11T16:53:00.926891"}}
{"question": "Which level does Traffic mirroring support packet captures in EC2 instances?", "answer": "Traffic mirroring supports packet captures at the Elastic Network Interface (ENI) level for EC2 instances.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-11T16:53:06.511318"}}
{"question": "How does Traffic mirroring differ from Amazon VPC flow logs in terms of network traffic analysis?", "answer": "Traffic mirroring allows you to analyze actual traffic content, including payload, for use-cases when you need to determine the root cause of a performance issue, reverse-engineer a sophisticated network attack, or detect and stop insider abuse or compromised workloads. Amazon VPC flow logs, on the other hand, allow you to collect, store, and analyze network flow logs, which include information about allowed and denied traffic, source and destination IP addresses, ports, protocol number, packet and byte counts, and an action (accept or reject).", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-11T16:53:06.511684"}}
{"question": "What is the data transfer charge for instances residing in subnets in different Availability Zones?", "answer": "You will be charged $0.01 per GB for data transfer between instances residing in subnets in different Availability Zones.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-16", "source_tokens": 507, "generated_at": "2026-02-11T16:53:06.512089"}}
{"question": "What does DescribeInstances() return when it comes to EC2 instances in a VPC?", "answer": "DescribeInstances() returns all running Amazon EC2 instances. To differentiate EC2-Classic instances from EC2-VPC instances, check the subnet field. If there is a subnet ID listed, the instance is within a VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-11T16:53:12.373744"}}
{"question": "How does the size of a VPC impact the number of Amazon EC2 instances you can launch?", "answer": "The size of a VPC determines the number of Amazon EC2 instances you can launch based on IP address availability. A VPC of /16 size allows launching up to 65,536 IPv4 addressed instances at a time, while a VPC of /56 size enables launching virtually unlimited number of IPv6 only instances.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-11T16:53:12.374105"}}
{"question": "What happens to the IP address of an Amazon EC2 instance when it is launched in a VPC?", "answer": "When an Amazon EC2 instance is launched in a VPC using an Amazon EBS-backed AMI, it maintains the same IP address when stopped and restarted. In contrast, instances launched outside a VPC receive a new IP address upon being stopped and restarted.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-17", "source_tokens": 496, "generated_at": "2026-02-11T16:53:12.374517"}}
{"question": "What are the two types of hostnames that can be assigned to an AWS instance and how does one change between them?", "answer": "An AWS instance can have an IP-based hostname and a resource-based hostname. To change the hostname from IP-based to resource-based or vice versa, you need to stop the instance and then modify the resource-based naming options.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-11T16:53:18.339932"}}
{"question": "How does one benefit from using the default VPC when launching resources in AWS?", "answer": "The default VPC in AWS is a logically isolated virtual network that provides advanced networking functionalities such as changing security group membership on the fly, security group egress filtering, multiple IP addresses, and multiple network interfaces. It also allows for the ease of use of Amazon EC2 without having to explicitly create a VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-11T16:53:18.340287"}}
{"question": "Can an account launched before March 18, 2013 use the default VPC feature set in all regions?", "answer": "Accounts created before March 18, 2013 may utilize default VPCs in any default VPC enabled region in which they have not previously launched EC2 instances or provisioned Amazon Elastic Load Balancing, Amazon RDS, Amazon ElastiCache, or Amazon Redshift resources.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-18", "source_tokens": 448, "generated_at": "2026-02-11T16:53:18.340790"}}
{"question": "What is required to launch an instance into a non-default VPC?", "answer": "You must specify a subnet-ID during instance launch.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-11T16:53:22.384649"}}
{"question": "How does the default VPC in EC2-VPC differ from the default VPC in EC2-Classic?", "answer": "In EC2-VPC, the default VPC is attached to the Internet and instances automatically receive public IP addresses. In contrast, in EC2-Classic, there is no default VPC and instances are launched into a shared IP space.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-11T16:53:22.385161"}}
{"question": "What happens when you delete a default subnet in a default VPC?", "answer": "A new default subnet can be created in the availability zone by using the CLI or SDK.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-19", "source_tokens": 481, "generated_at": "2026-02-11T16:53:22.385430"}}
{"question": "What conditions must be met to enable an existing AWS account for a default VPC?", "answer": "An existing AWS account can be enabled for a default VPC only if the account has no EC2-Classic resources in that region and all non-VPC provisioned Elastic Load Balancers, Amazon RDS, Amazon ElastiCache, and Amazon Redshift resources are terminated.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-11T16:53:27.918385"}}
{"question": "How does Amazon VPC differ from EC2-Classic in terms of network isolation and usage?", "answer": "Amazon VPC allows you to run instances in a logically isolated virtual private cloud, while EC2-Classic is a flat network that you share with other customers. While a majority of AWS customers use Amazon VPC, some still use EC2-Classic.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-11T16:53:27.918688"}}
{"question": "What is the deadline for migrating from EC2-Classic to Amazon VPC, and what resources need to be moved?", "answer": "The deadline for migrating from EC2-Classic to Amazon VPC is August 15, 2022. Resources that need to be moved include EC2 instances and other AWS resources running on EC2-Classic.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-20", "source_tokens": 414, "generated_at": "2026-02-11T16:53:27.919067"}}
{"question": "What AWS regions require me to disable EC2-Classic by October 30, 2021 if I have no active resources running on it since January 1, 2021?", "answer": "Any AWS regions where you have not had any AWS resources (EC2 Instances, Amazon Relational Database, AWS Elastic Beanstalk, Amazon Redshift, AWS Data Pipeline, Amazon EMR, AWS OpsWorks) on EC2-Classic since January 1, 2021.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-11T16:53:34.122502"}}
{"question": "Why should I turn off EC2-Classic in a region if I don't have any active resources on it?", "answer": "Turning off EC2-Classic in a region allows you to launch Default VPC there and take advantage of the security features and additional functionalities offered by Amazon VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-11T16:53:34.122858"}}
{"question": "What's the difference between launching instances on EC2-Classic and Amazon VPC?", "answer": "EC2-Classic is the older Amazon Elastic Compute Cloud platform that does not include a built-in virtual private cloud (VPC). Amazon VPC, on the other hand, provides a logically isolated virtual network that you define and control. Launching instances in Amazon VPC provides enhanced network security and isolation, as well as additional features like custom network configurations.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-21", "source_tokens": 411, "generated_at": "2026-02-11T16:53:34.123289"}}
{"question": "What are the advantages of using Amazon VPC over the EC2-Classic environment in terms of network configuration?", "answer": "Amazon VPC offers several advantages over the EC2-Classic environment in terms of network configuration. It allows you to select your own IP address space, configure public and private subnets, and manage route tables and network gateways. In contrast, in the EC2-Classic environment, your workloads share a single flat network with other customers.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-11T16:53:39.778225"}}
{"question": "What can you control in your virtual network environment when using Amazon VPC on AWS?", "answer": "When using Amazon VPC on AWS, you have complete control over your virtual network environment, which is logically isolated to your AWS account.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-11T16:53:39.778524"}}
{"question": "Why would you use Amazon VPC instead of the EC2-Classic environment, and how does it differ in terms of instance availability?", "answer": "You would use Amazon VPC instead of the EC2-Classic environment due to its advantages in network configuration, such as the ability to select your own IP address space, configure public and private subnets, and manage route tables and network gateways. Additionally, Amazon VPC offers a much wider and latest generation of instances than EC2-Classic.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-22", "source_tokens": 149, "generated_at": "2026-02-11T16:53:39.778968"}}
{"question": "What resources can I identify using the script provided for EC2-Classic resources in all regions of an account?", "answer": "You can identify all resources provisioned in EC2-Classic across all regions in an account using the script provided.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-11T16:53:46.223167"}}
{"question": "What are the steps involved in manually migrating an EC2 instance from EC2-Classic to VPC using the runbook provided?", "answer": "The runbook provided, 'AWSSupport-MigrateEC2 ClassicToVPC' from 'AWS Systems Manager > Automation', automates the steps required to migrate an instance from EC2-Classic to VPC by creating an AMI of the instance in EC2-Classic, creating a new instance from the AMI in VPC, and optionally terminating the EC2-Classic instance.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-11T16:53:46.223482"}}
{"question": "How does the AWS Application Migration Service (AWS MGN) solution compare to using the Instances Migration Guide for migrating individual EC2 instances from EC2-Classic to VPC?", "answer": "The AWS Application Migration Service (AWS MGN) is a highly automated lift-and-shift (rehost) solution that simplifies, expedites, and reduces the cost of migrating applications compared to using the Instances Migration Guide for migrating individual EC2 instances from EC2-Classic to VPC.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-23", "source_tokens": 472, "generated_at": "2026-02-11T16:53:46.223772"}}
{"question": "What is the deadline for stopping the issuance of 3-year and 1-year reserved instances in the EC2-Classic environment?", "answer": "October 30, 2021", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-11T16:53:51.032698"}}
{"question": "Why can't we use multiple network interfaces for instances in the EC2-Classic environment?", "answer": "It is not a best practice to use multiple network interfaces for instances in the EC2-Classic environment. Instead, assign additional private IP addresses to the instance and then associate Elastic IP addresses (EIPs) to the private IPs as needed.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-11T16:53:51.033166"}}
{"question": "How does VPC peering affect data transfer charges compared to not using VPC peering?", "answer": "There is no charge for creating VPC peering connections, but data transfer across peering connections is charged. For data transfer rates, please refer to the Data Transfer section of the EC2 Pricing page.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-24", "source_tokens": 505, "generated_at": "2026-02-11T16:53:51.033457"}}
{"question": "What type of connection is an Inter-Region VPC Peering and how does it differ from a gateway or VPN connection?", "answer": "An Inter-Region VPC Peering is a connection that allows two Amazon Virtual Private Clouds (VPCs) in different regions to connect. It is not a gateway nor a VPN connection, and does not rely on a separate piece of physical hardware. The connection is horizontally scaled, redundant, and highly available, with no single point of failure for communication and no bandwidth bottleneck.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T16:53:55.617470"}}
{"question": "What happens if an Inter-Region peering connection goes down?", "answer": "If an Inter-Region peering connection goes down, the traffic will not be routed over the internet.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T16:53:55.617837"}}
{"question": "How does the bandwidth between instances in a peered VPC compare to the bandwidth between instances in the same VPC?", "answer": "The bandwidth between instances in a peered VPC is no different than the bandwidth between instances in the same VPC.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-25", "source_tokens": 436, "generated_at": "2026-02-11T16:53:55.618209"}}
{"question": "What IP addresses can be used for ClassicLink if the VPC has a CIDR that is not within the 10.0.0.0/8 range?", "answer": "ClassicLink cannot be used for a VPC that has a CIDR within the 10.0.0.0/8 range, except for 10.0.0.0/16 and 10.1.0.0/16.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-11T16:54:01.553580"}}
{"question": "What communication rules apply between an EC2-Classic instance and instances or resources within a VPC after ClassicLink is enabled?", "answer": "All the rules and references to the VPC Security Group apply to communication between instances in the EC2-Classic instance and resources within the VPC.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-11T16:54:01.553982"}}
{"question": "What are the differences between linking an EC2-Classic instance to a VPC using ClassicLink and becoming a member of the VPC?", "answer": "An EC2-Classic instance linked to a VPC using ClassicLink becomes a member of the VPC Security Group associated with the instance, while it does not become a member of the VPC itself. The EC2-Classic instance cannot be linked to more than one VPC at the same time.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-26", "source_tokens": 463, "generated_at": "2026-02-11T16:54:01.554507"}}
{"question": "What destinations will traffic from an EC2-Classic instance be routed to when using Traffic routing?", "answer": "Traffic from an EC2-Classic instance can only be routed to private IP addresses within the VPC.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-11T16:54:06.219361"}}
{"question": "How does AWS PrivateLink enable private access to services, compared to traditional Internet access?", "answer": "AWS PrivateLink keeps all network traffic within the AWS network, while traditional Internet access requires traffic to traverse across the Internet.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-11T16:54:06.219614"}}
{"question": "What are the main differences between EC2-Classic instance's ClassicLink and AWS PrivateLink in terms of instance connectivity and routing?", "answer": "EC2-Classic instances' ClassicLink allows access to private IP addresses within a VPC and does not persist through stop/start cycles, while AWS PrivateLink uses VPC endpoints with private IPs and registers Network Load Balancers to provide access to services.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-27", "source_tokens": 446, "generated_at": "2026-02-11T16:54:06.220004"}}
{"question": "Which AWS services support the feature mentioned in the text?", "answer": "Amazon Elastic Compute Cloud (EC2), Elastic Load Balancing (ELB), Kinesis Streams, Service Catalog, EC2 Systems Manager, Amazon SNS, and AWS DataSync.", "question_type": "factual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-11T16:54:10.214045"}}
{"question": "What are the ways to manage Amazon VPC objects besides ElasticFox?", "answer": "You can use the AWS Management Console, AWS APIs, command line tools, and a variety of third-party utilities.", "question_type": "conceptual", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-11T16:54:10.214453"}}
{"question": "How does managing Amazon VPC through the AWS Management Console compare to ElasticFox?", "answer": "The text does not provide enough information for a comparison between managing Amazon VPC through the AWS Management Console and ElasticFox.", "question_type": "comparison", "metadata": {"service": "VPC", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpc-faq-28", "source_tokens": 274, "generated_at": "2026-02-11T16:54:10.214723"}}
{"question": "What is the purpose of a target network in AWS Client VPN?", "answer": "A target network in AWS Client VPN is a network that you associate to the Client VPN endpoint. It enables secure access to AWS resources and on-premises networks.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-11T16:54:14.796410"}}
{"question": "How do you configure the authentication details for an AWS Client VPN endpoint?", "answer": "When setting up an AWS Client VPN endpoint, you specify the authentication details as part of the configuration process.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-11T16:54:14.796742"}}
{"question": "What is the difference between an AWS Site-to-Site VPN and an AWS Client VPN in terms of network connectivity?", "answer": "An AWS Site-to-Site VPN connects an on-premises network or branch office site to an Amazon Virtual Private Cloud (Amazon VPC), while an AWS Client VPN enables users to securely connect to AWS or on-premises networks.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-0", "source_tokens": 460, "generated_at": "2026-02-11T16:54:14.797082"}}
{"question": "What encryption functions can be used with statically-routed AWS Site-to-Site VPN connections?", "answer": "AES 128-bit, 256-bit, 128-bit-GCM-16, or 256-GCM-16 encryption functions can be used with statically-routed AWS Site-to-Site VPN connections.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T16:54:26.581626"}}
{"question": "Why would you use dynamically-routed Site-to-Site VPN connections instead of statically-routed ones in AWS?", "answer": "Dynamic Site-to-Site VPN connections can be used instead of statically-routed ones in AWS when you need to establish Border Gateway Protocol (BGP) peering, bind tunnels to logical interfaces, or utilize IPsec Dead Peer Detection.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T16:54:26.582030"}}
{"question": "What are the differences in the DH groups supported in Phase 1 and Phase 2 of AWS Site-to-Site VPN connections?", "answer": "Phase 1 supports DH groups 2, 14-24, while Phase 2 supports DH groups 2, 5, and 14-24.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-2", "source_tokens": 484, "generated_at": "2026-02-11T16:54:26.582459"}}
{"question": "What is the maximum throughput per tunnel for an AWS Site-to-Site VPN connection?", "answer": "Each tunnel supports a maximum throughput of up to 1.25 Gbps.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T16:54:31.224191"}}
{"question": "Why would you use AWS Transit Gateway to connect to multiple VPCs and achieve higher throughput limits?", "answer": "AWS Transit Gateway allows you to connect to multiple VPCs and achieve higher throughput limits compared to using a Virtual Private Gateway with multiple VPN connections.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T16:54:31.224559"}}
{"question": "How does the throughput for an AWS Site-to-Site VPN connection depend on various factors?", "answer": "The VPN connection throughput can depend on the capability of your customer gateway, the capacity of your connection, average packet size, the protocol being used, TCP vs. UDP, and the network latency between your customer gateway and the virtual private gateway.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-3", "source_tokens": 475, "generated_at": "2026-02-11T16:54:31.224970"}}
{"question": "What is the maximum number of routes that can be advertised to a VPN connection on an AWS Transit Gateway?", "answer": "A maximum of 1000 routes can be advertised to a VPN connection on an AWS Transit Gateway.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-11T16:54:36.302736"}}
{"question": "How does the number of routes that can be advertised to a VPN connection differ between a Virtual Private Gateway and an AWS Transit Gateway?", "answer": "For a VPN connection on a Virtual Private Gateway, a maximum of 100 routes can be advertised from the customer gateway device, and for a VPN connection on an AWS Transit Gateway, a maximum of 1000 routes can be advertised.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-11T16:54:36.303029"}}
{"question": "Explaining the concept of SA limitations in the context of AWS VPN, how does AWS handle this issue in a route-based solution versus a policy-based solution?", "answer": "In a route-based solution, AWS VPN does not impose SA limitations, allowing for an unlimited number of routes. In contrast, in a policy-based solution, a single SA must be used due to the service being a route-based solution.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-4", "source_tokens": 440, "generated_at": "2026-02-11T16:54:36.303548"}}
{"question": "What type of IP addresses are used for private IP Site-to-Site VPN connections over an AWS Transit Gateway?", "answer": "Private IP addresses are used for outside tunnel IP addresses while creating a new VPN connection over an AWS Transit Gateway.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-11T16:54:41.022382"}}
{"question": "How does the routing behavior differ for private IP VPN attachments compared to other Transit gateway attachments?", "answer": "The route-table association and propagation behavior for a private IP VPN attachment is the same as any other Transit gateway attachment.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-11T16:54:41.022794"}}
{"question": "What's the difference between setting up static routing vs. dynamic routing using BGP for a private IP VPN connection?", "answer": "Static routing is used when your customer gateway device does not support Border Gateway Protocol (BGP). Dynamic routing is used when your customer gateway device supports BGP, which offers robust liveness detection checks for failover.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-5", "source_tokens": 387, "generated_at": "2026-02-11T16:54:41.023321"}}
{"question": "What is the bandwidth supported by each private IP VPN connection?", "answer": "Each private IP VPN connection supports 1.25Gbps of bandwidth.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T16:54:45.598119"}}
{"question": "Can you explain how ECMP (Equal Cost Multi-path) works for private IP VPN connections?", "answer": "ECMP allows you to increase effective bandwidth by using multiple private IP VPN connections with private IP addresses and distributing traffic across them.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T16:54:45.598439"}}
{"question": "Comparing Accelerated Site-to-Site VPN and regular Site-to-Site VPN connections, what are the main differences in terms of availability and performance?", "answer": "Accelerated Site-to-Site VPN uses the AWS global network, ensuring higher availability and congestion-free performance, whereas regular Site-to-Site VPN connections traverse through multiple public networks which can introduce inconsistent availability and performance.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-6", "source_tokens": 477, "generated_at": "2026-02-11T16:54:45.598631"}}
{"question": "What regions support Accelerated Site-to-Site VPN?", "answer": "Accelerated Site-to-Site VPN is currently available in the following AWS Regions: US West (Oregon), US West (N. California), US East (Ohio), US East (N. Virginia), South America (Sao Paulo), Middle East (Bahrain), Europe (Stockholm), Europe (Paris), Europe (Milan), Europe (London), Europe (Ireland), Europe (Frankfurt), Canada (Central), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Seoul), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Africa (Cape Town).", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-11T16:54:54.939948"}}
{"question": "Why is NAT-T required for Accelerated Site-to-Site VPN?", "answer": "NAT-T is required for Accelerated Site-to-Site VPN because it enables IPsec communications to pass through a NAT device. It is enabled by default for Accelerated Site-to-Site VPN connections.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-11T16:54:54.940314"}}
{"question": "How does Accelerated Site-to-Site VPN compare to non-Accelerated Site-to-Site VPN in terms of available regions?", "answer": "Accelerated Site-to-Site VPN is available in more regions than non-Accelerated Site-to-Site VPN. Specifically, it is currently available in the following regions: US West (Oregon), US West (N. California), US East (Ohio), US East (N. Virginia), South America (Sao Paulo), Middle East (Bahrain), Europe (Stockholm), Europe (Paris), Europe (Milan), Europe (London), Europe (Ireland), Europe (Frankfurt), Canada (Central), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), Asia Pacific (Seoul), Asia Pacific (Mumbai), Asia Pacific (Hong Kong), Africa (Cape Town). In contrast, non-Accelerated Site-to-Site VPN is not specified in the text for availability in specific regions.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-7", "source_tokens": 499, "generated_at": "2026-02-11T16:54:54.940811"}}
{"question": "What type of logs can you enable for Site-to-Site VPN connections in AWS?", "answer": "You can enable Site-to-Site VPN logs for both Transit Gateway and Virtual Gateway based VPN connections.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T16:54:59.754361"}}
{"question": "How does the process of enabling Site-to-Site VPN logs impact the connectivity?", "answer": "When you enable Site-to-Site VPN logs for a VPN connection, the connectivity over the modified tunnel is interrupted for up to several minutes.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T16:54:59.754610"}}
{"question": "What are the differences in logging and connectivity between a Transit Gateway and Virtual Gateway VPN connection in AWS?", "answer": "Both Transit Gateway and Virtual Gateway VPN connections allow you to enable Site-to-Site VPN logs. However, enabling logs for a Transit Gateway connection may impact connectivity for up to several minutes, while the impact for Virtual Gateway connections is not specified in the text.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-8", "source_tokens": 494, "generated_at": "2026-02-11T16:54:59.754770"}}
{"question": "What happens to traffic routing if split tunnel is enabled in an AWS Client VPN endpoint?", "answer": "Traffic destined for routes configured on the endpoint will be routed via the VPN tunnel. All other traffic will be routed via the local network interface.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-11T16:55:03.914493"}}
{"question": "How does mutual authentication work in AWS Client VPN?", "answer": "Both the client and server have to upload their respective certificates for mutual authentication to take place. The client certificate is issued by the server's root certificate, and vice versa.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-11T16:55:03.914927"}}
{"question": "In what ways does AWS Client VPN differ from other AWS services that support posture assessment?", "answer": "AWS Client VPN does not support posture assessment. Services like Amazon Inspectors provide posture assessment capabilities.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-9", "source_tokens": 505, "generated_at": "2026-02-11T16:55:03.915103"}}
{"question": "What is required to access an application using the security groups associated with the subnet in AWS Client VPN?", "answer": "Access is limited to users connected via Client VPN.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-11T16:55:07.426526"}}
{"question": "How does updating metadata in the IAM identity provider for the Client VPN endpoint impact the service?", "answer": "Updated metadata are reflected in 2 to 4 hours.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-11T16:55:07.426781"}}
{"question": "What are the differences in logging between AWS Client VPN and Amazon VPC Flow Logs?", "answer": "AWS Client VPN exports connection logs to CloudWatch at 15 minute intervals, including created and terminated connection requests. Amazon VPC Flow Logs can be used in the associated VPC to capture IP traffic for Network Access Controls and security analysis.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-10", "source_tokens": 461, "generated_at": "2026-02-11T16:55:07.427113"}}
{"question": "Which authentication mechanisms are supported by the AWS Client VPN service?", "answer": "The AWS Client VPN service supports authentication with Active Directory using AWS Directory Services, Certificate-based authentication, and Federated Authentication using SAML-2.0.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-11T16:55:12.598678"}}
{"question": "Why can't I run multiple VPN clients on one device with the AWS Client VPN?", "answer": "Running multiple VPN clients on a device can cause conflicts or interfere with each other, potentially resulting in unsuccessful connections. However, the AWS Client VPN can be installed alongside another VPN client.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-11T16:55:12.598929"}}
{"question": "What are the ASNs assigned to the specific regions in AWS Client VPN?", "answer": "EU West (Dublin) has an ASN of 9059, Asia Pacific (Singapore) has an ASN of 17493, and Asia Pacific (Tokyo) has an ASN of 10124. All other regions use the 'legacy public ASN' of 7224.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-11", "source_tokens": 488, "generated_at": "2026-02-11T16:55:12.599071"}}
{"question": "What private ASN range can I use for my Amazon virtual gateway?", "answer": "You can use private ASNs ranging from 64512 to 65534 for 16-bit ASNs, or between 4200000000 and 4294967294 for 32-bit ASNs.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-11T16:55:18.448812"}}
{"question": "Why does Amazon limit the Amazon-side ASN to private ASNs for virtual gateways?", "answer": "Amazon is not validating ownership of the ASNs, and limiting the Amazon-side ASN to private ASNs is a measure to protect customers from BGP spoofing.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-11T16:55:18.449032"}}
{"question": "How does configuring a private ASN on the Amazon side of a virtual gateway compare to configuring a public ASN?", "answer": "Configuring a private ASN on the Amazon side of a virtual gateway allows you to use a public ASN on your side. This involves creating a new virtual gateway with the desired ASN, creating a new VIF, and updating your device configuration. For a new VPN connection, you will need to recreate it between your Customer Gateways and the newly created virtual gateway.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-12", "source_tokens": 475, "generated_at": "2026-02-11T16:55:18.449211"}}
{"question": "What ASN is Amazon using for new virtual gateways after June 30th, 2018?", "answer": "Amazon is using an ASN of 64512 for new virtual gateways after June 30th, 2018.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:55:23.638727"}}
{"question": "Why would you need to assign a specific ASN for the Amazon side when creating a new virtual gateway?", "answer": "You would need to assign a specific ASN for the Amazon side when creating a new virtual gateway if you want to use your own private ASN for the Amazon half of the BGP session.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:55:23.639027"}}
{"question": "What is the difference between the Amazon side ASN for a virtual gateway and a VIF/VPN connection?", "answer": "The Amazon side ASN for a virtual gateway is inherited from the existing virtual gateway and is used for all VIFs and VPN connections associated with that virtual gateway. In contrast, the Amazon side ASN for a VIF or VPN connection is inherited from the attached virtual gateway.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-13", "source_tokens": 511, "generated_at": "2026-02-11T16:55:23.639211"}}
{"question": "What ASN range can be used for a Customer Gateway in an AWS Site-to-Site VPN connection?", "answer": "ASNs in the range 1 â€“ 2147483647 can be used for a Customer Gateway in an AWS Site-to-Site VPN connection, with noted exceptions.", "question_type": "factual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-11T16:55:29.881842"}}
{"question": "Why can't private ASNs in the range of (4200000000 to 4294967294) be used for Customer Gateway configuration in an AWS Site-to-Site VPN connection?", "answer": "Private ASNs in the range of (4200000000 to 4294967294) are NOT currently supported for Customer Gateway configuration in an AWS Site-to-Site VPN connection.", "question_type": "conceptual", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-11T16:55:29.882192"}}
{"question": "How does the ASN range for Customer Gateways in an AWS Site-to-Site VPN connection compare to private ASNs?", "answer": "ASNs in the range 1 â€“ 2147483647 can be used for Customer Gateways in AWS Site-to-Site VPN connections, while private ASNs in the range of (4200000000 to 4294967294) are NOT currently supported for this purpose.", "question_type": "comparison", "metadata": {"service": "VPN", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "vpn-faq-14", "source_tokens": 137, "generated_at": "2026-02-11T16:55:29.882677"}}
{"question": "What are the three main features of AWS WAF?", "answer": "AWS WAF is a web application firewall that allows you to configure rules to allow, block, or monitor web requests based on conditions you define, such as IP addresses, HTTP headers, HTTP body, URI strings, SQL injection, and cross-site scripting. It also provides integration with Amazon CloudFront, Application Load Balancer, Amazon API Gateway, and AWS AppSync.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T16:55:37.328693"}}
{"question": "How does AWS WAF protect web applications from attacks?", "answer": "AWS WAF inspects incoming requests for your web applications against your defined rules. If a request meets a condition defined in your rules, AWS WAF instructs the underlying service to either block or allow the request based on the action you define. This helps protect web applications from attacks.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T16:55:37.329073"}}
{"question": "How does AWS WAF compare to other AWS services for web application security?", "answer": "AWS WAF is a web application firewall that integrates with Amazon CloudFront, Application Load Balancer, Amazon API Gateway, and AWS AppSync. It allows you to configure rules to allow, block, or monitor web requests based on conditions you define, such as IP addresses, HTTP headers, HTTP body, URI strings, SQL injection, and cross-site scripting. Amazon CloudFront is a content delivery network that supports custom origins outside of AWS and offers security features like Shield, which can help protect against common web exploits. Application Load Balancer, Amazon API Gateway, and AWS AppSync are other AWS services that can be used to deliver content for websites and applications, but they do not provide the same level of web application security as AWS WAF.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-0", "source_tokens": 471, "generated_at": "2026-02-11T16:55:37.329295"}}
{"question": "What types of attacks can AWS WAF help protect against?", "answer": "AWS WAF helps protect against common attack techniques like SQL injection and Cross-Site Scripting (XSS).", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-11T16:55:41.833968"}}
{"question": "How does Bot Control in AWS WAF help protect your applications?", "answer": "Bot Control in AWS WAF gives you visibility and control over common and pervasive bot traffic to your applications. You can monitor, block, or rate-limit specific bots, such as scrapers, scanners, and crawlers, and allow common bots, such as status monitors and search engines.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-11T16:55:41.834351"}}
{"question": "Can AWS WAF inspect HTTP/S requests coming from both IPv6 and IPv4 addresses?", "answer": "Yes, AWS WAF supports IPv6 and can inspect HTTP/S requests coming from both IPv6 and IPv4 addresses.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-1", "source_tokens": 510, "generated_at": "2026-02-11T16:55:41.834565"}}
{"question": "What does AWS charge for creating and using a Rate-based Rule in AWS WAF?", "answer": "AWS charges $1 per rule per WebACL per month for creating and using a Rate-based Rule in AWS WAF.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-11T16:55:46.801208"}}
{"question": "How does a Rate-based Rule in AWS WAF differ from a regular rule?", "answer": "A Rate-based Rule in AWS WAF is similar to a regular rule, but it allows you to configure a rate-based threshold, which blocks web requests from an IP address if the number of requests exceeds the configured limit in a 5-minute interval.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-11T16:55:46.801605"}}
{"question": "Which AWS services does the cost of a Rate-based Rule in AWS WAF include, and which services does it exclude?", "answer": "The cost of a Rate-based Rule in AWS WAF includes charges for the number of web requests received, but excludes charges for Amazon CloudFront pricing, Application Load Balancer (ALB) pricing, Amazon API Gateway pricing, and AWS AppSync pricing.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-2", "source_tokens": 393, "generated_at": "2026-02-11T16:55:46.801845"}}
{"question": "What is the threshold rate for Rate-based rules in terms of web requests per trailing 5-minute period?", "answer": "The threshold rate for Rate-based rules is configurable in web requests per trailing 5-minute period.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-11T16:55:51.303881"}}
{"question": "How do Rate-based rules help protect against certain use cases?", "answer": "Rate-based rules help protect against use cases such as web-layer DDoS attacks, brute force login attempts, and bad bots.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-11T16:55:51.304249"}}
{"question": "How can I limit requests to a specific page using Rate-based rules and what is required to implement it?", "answer": "To limit requests to a specific page using Rate-based rules, you can add a string match condition with a 'URI' part, 'Starts with' match type, and a 'Value to match' that identifies the login page. Additionally, specify a Rate Limit for the number of requests per 5 minutes. This will limit requests to the login page per IP address without affecting the rest of your site.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-3", "source_tokens": 479, "generated_at": "2026-02-11T16:55:51.304483"}}
{"question": "How long does it take to implement AWS WAF with the streamlined setup?", "answer": "The implementation time for AWS WAF can be reduced from hours to just 20 minutes with the streamlined setup.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:55:55.737402"}}
{"question": "What are Managed Rules in the context of AWS WAF and how do they differ?", "answer": "Managed Rules are pre-configured rules to protect applications against common threats in AWS WAF. AWS Managed Rules are managed by AWS, while Managed Rules from AWS Marketplace are managed by third-party security sellers.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:55:55.737787"}}
{"question": "How does adding a Managed Rule from AWS Marketplace to an existing web ACL impact the rule limit?", "answer": "Each Managed Rule added to your web ACL will count as 1 rule towards your limit, but the number of rules inside a Managed Rule does not count.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-4", "source_tokens": 476, "generated_at": "2026-02-11T16:55:55.738391"}}
{"question": "What action can be configured for a Managed Rule in AWS WAF for counting web requests?", "answer": "AWS WAF allows you to configure a â€˜countâ€™ action for a Managed Rule, which counts the number of web requests that are matched by the rules inside the Managed Rule.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-11T16:56:01.764949"}}
{"question": "How does AWS WAF Protection packs work and what are they used for?", "answer": "Protection packs in AWS WAF are a combination of managed rules and custom rules that provide protection based on the application type and source of traffic. They are part of AWS Managed Rules and are priced according to AWS WAF pricing. You can view rules and modify them within a protection pack and have full visibility and control over the rules they contain.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-11T16:56:01.765304"}}
{"question": "How does the propagation time for adding or changing rules in AWS WAF compare to seeing blocked requests in CloudWatch and Sampled Web Requests?", "answer": "After an initial setup, adding or changing to rules in AWS WAF typically takes around a minute to propagate worldwide. On the other hand, you can see which requests were blocked, allowed, or counted and what rule was matched on a given request in one-minute metrics in CloudWatch or Sampled Web Requests in the AWS WAF API or management console.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-5", "source_tokens": 462, "generated_at": "2026-02-11T16:56:01.765713"}}
{"question": "What is the time period for storing Real-Time Metrics in Amazon CloudWatch?", "answer": "The time period for storing Real-Time Metrics in Amazon CloudWatch can be configured by the user.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-11T16:56:06.855167"}}
{"question": "How does Account Takeover Prevention (ATP) in AWS WAF help prevent unauthorized access to user accounts?", "answer": "Account Takeover Prevention (ATP) in AWS WAF helps prevent unauthorized access to user accounts by monitoring traffic to your applicationâ€™s login page, checking for compromised credentials, and detecting and mitigating brute force attempts and credential stuffing attacks.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-11T16:56:06.855490"}}
{"question": "What's the difference between how AWS WAF handles user credentials and how it securers traffic between user devices and your application?", "answer": "AWS WAF hashes and discards user credentials once they reach AWS WAF and keeps them within the AWS network, while traffic between user devices and your application is secured by the SSL/TLS protocol that you configure for the AWS service you use to front your application.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-6", "source_tokens": 430, "generated_at": "2026-02-11T16:56:06.855896"}}
{"question": "What is the purpose of Bot Control in AWS WAF?", "answer": "Bot Control is a feature in AWS WAF that gives visibility and control over bot traffic, helping to prevent activities such as resource consumption, metric skewing, downtime, and undesired activities.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-11T16:56:11.428068"}}
{"question": "How does Account Takeover Prevention (ATP) in AWS WAF help protect against unauthorized access?", "answer": "Account Takeover Prevention (ATP) in AWS WAF helps protect against unauthorized access by detecting anomalous login attempts from bad actors using compromised credentials.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-11T16:56:11.428545"}}
{"question": "What's the difference between Bot Control and Account Takeover Prevention (ATP) in AWS WAF?", "answer": "Bot Control is used to detect and manage bot traffic, while Account Takeover Prevention (ATP) is used to detect and prevent unauthorized access using compromised credentials.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-7", "source_tokens": 465, "generated_at": "2026-02-11T16:56:11.428717"}}
{"question": "What information does Account Creation Fraud Prevention (ACFP) verify during account sign-up?", "answer": "ACFP verifies each credential (i.e., username and password) submitted, email domains used, and other information like phone numbers and address fields entered in real-time.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:56:16.578732"}}
{"question": "How does Account Creation Fraud Prevention (ACFP) differ from Account Takeover Prevention (ATP)?", "answer": "ACFP focuses on preventing automated fraud such as promotional or sign-up abuse, loyalty or rewards abuse and phishing, whereas ATP is focused on preventing credential stuffing and brute force attacks.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:56:16.579130"}}
{"question": "Which steps should be taken to configure Account Creation Fraud Prevention (ACFP) on the AWS WAF console?", "answer": "Create or modify a web ACL on the AWS WAF console, add managed rules, and indicate the URL of your applicationâ€™s account creation and registration page and the location of user name, password, address, and phone number form fields within the requestâ€™s body.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-8", "source_tokens": 463, "generated_at": "2026-02-11T16:56:16.579572"}}
{"question": "What information does WAF logging provide about requests analyzed by ACFP?", "answer": "WAF logging provides details such as rule actions, label information, and risk scoring for requests analyzed by ACFP.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-11T16:56:21.158708"}}
{"question": "Why is SDK integration mandatory for Single page applications (SPA) and Native Mobile apps when using ACFP?", "answer": "SDK integration is mandatory for Single page applications (SPA) and Native Mobile apps when using ACFP because Challenge action, which is an alternative to SDK integration, does not work well with these application types.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-11T16:56:21.159063"}}
{"question": "How does CloudWatch Metrics and WAF logging differ in the context of ACFP?", "answer": "CloudWatch Metrics allow customers to create alerts and notifications based on rule actions emitted from ACFP rule group, while WAF logging enables querying and analyzing logs for requests analyzed by ACFP using existing logging solutions.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-9", "source_tokens": 280, "generated_at": "2026-02-11T16:56:21.159576"}}
{"question": "What is the primary function of AWS WAF application layer (L7) DDoS protection?", "answer": "AWS WAF application layer (L7) DDoS protection is designed to automatically defend applications against distributed denial of service (DDoS) events within seconds.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T16:56:26.008996"}}
{"question": "How does AWS WAF application layer (L7) DDoS protection customize protection for specific applications?", "answer": "AWS WAF application layer (L7) DDoS protection allows for customization options such as configuring rule sensitivity settings and inspection of specific application URI paths.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T16:56:26.009246"}}
{"question": "How does the protective capability of AWS WAF application layer (L7) DDoS protection on Application Load Balancer (ALB) compare to its capability on Amazon CloudFront?", "answer": "Both Amazon CloudFront and Application Load Balancer (ALB) are currently protected by this feature, but for additional protection on ALB, an AWS Shield Advanced subscription is required.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-10", "source_tokens": 442, "generated_at": "2026-02-11T16:56:26.009445"}}
{"question": "What does enabling the AWS Managed Rule group for application layer (L7) DDoS protection do in the AWS WAF security dashboard?", "answer": "Enabling the AWS Managed Rule group for application layer (L7) DDoS protection in the AWS WAF security dashboard will make the anti-DDoS section appear, providing a detailed view into event detection and mitigation.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-11T16:56:32.108775"}}
{"question": "How does configuring sensitivity levels in AWS Managed Rules for application layer (L7) DDoS protection impact your applications?", "answer": "Configuring sensitivity levels (low, medium, high) in AWS Managed Rules for application layer (L7) DDoS protection allows you to adjust the rule's sensitivity to suit the needs of your applications to minimize traffic interference or to heighten protection during active events or for highly sensitive workloads.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-11T16:56:32.109120"}}
{"question": "What are the differences between AWS Shield Advanced and application layer (L7) DDoS protection in AWS WAF?", "answer": "AWS Shield Advanced responds to DDoS events by creating, evaluating, and deploying custom AWS WAF rules for protected resources. Application layer (L7) DDoS protection in AWS WAF works in conjunction with all your AWS WAF rules to enhance protection against DDoS events.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-11", "source_tokens": 496, "generated_at": "2026-02-11T16:56:32.109587"}}
{"question": "How many additional WCUs are required for AWS WAF with DDoS protection?", "answer": "An additional 50 WCUs are required.", "question_type": "factual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-11T16:56:35.409087"}}
{"question": "Why is there a difference in billing between AWS WAF and AWS Shield Advanced for DDoS protection?", "answer": "AWS WAF does not have any usage limits or commitments, while AWS Shield Advanced has fees and a 12-month commitment.", "question_type": "conceptual", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-11T16:56:35.409554"}}
{"question": "What is the monthly request limit for AWS WAF for non-Advanced customers and for AWS Shield Advanced customers?", "answer": "AWS WAF customers have no request limit, while AWS Shield Advanced customers are limited to 50 billion requests.", "question_type": "comparison", "metadata": {"service": "WAF", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "waf-faq-12", "source_tokens": 325, "generated_at": "2026-02-11T16:56:35.409713"}}
{"question": "What services does AWS Wavelength bring to communication service providers' networks?", "answer": "AWS Wavelength brings on-demand computing and storage services to communication service providersâ€™ networks.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-11T16:56:39.973848"}}
{"question": "Why would a customer choose to use AWS Wavelength?", "answer": "A customer might choose to use AWS Wavelength to meet their data residency requirements, reduce latency, and improve resiliency and availability.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-11T16:56:39.974174"}}
{"question": "How does AWS Wavelength compare to other AWS hybrid and edge infrastructure like AWS Outposts and Local Zones?", "answer": "AWS Wavelength, AWS Outposts, and Local Zones are all hybrid and edge infrastructure offerings from AWS. However, AWS Wavelength is specifically designed for embedding AWS compute and storage services within communication service providersâ€™ data centers, whereas AWS Outposts and Local Zones offer AWS services on-premises or at the edge of AWS's network.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-0", "source_tokens": 443, "generated_at": "2026-02-11T16:56:39.974578"}}
{"question": "What technology does AWS Wavelength Zones use for strong security?", "answer": "AWS Wavelength Zones use the AWS Nitro system, a first-of-a-kind innovation that provides a strong physical and logical security boundary and enforces restrictions to prevent anyone, including AWS, from accessing customer workloads on Amazon EC2.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-11T16:56:44.830295"}}
{"question": "How does AWS Nitro system ensure data security in Wavelength Zones?", "answer": "The AWS Nitro system, which is the foundation of AWS compute services, ensures data security in Wavelength Zones by providing a strong physical and logical security boundary and enforcing restrictions to restrict access to customer data.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-11T16:56:44.830661"}}
{"question": "What is the difference between AWS Wavelength Zones and other AWS services in terms of data security?", "answer": "AWS Wavelength Zones use the AWS Nitro system, which is designed to provide a strong physical and logical security boundary and restrict access to customer data, whereas other AWS services may not have this level of security control.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-1", "source_tokens": 150, "generated_at": "2026-02-11T16:56:44.831084"}}
{"question": "What type of AWS infrastructure is AWS Local Zones designed for?", "answer": "AWS Local Zones are designed for workloads requiring low-latency and running compute and storage resources closer to end-users, without the need for customers to own and operate their own data center infrastructure.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-11T16:56:50.746133"}}
{"question": "How does AWS Wavelength help developers build applications with low-latency requirements?", "answer": "AWS Wavelength embeds storage and compute inside telco providersâ€™ networks, enabling developers to build applications with end-users requiring low-latency, such as IoT devices, game streaming, autonomous vehicles, and live media production.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-11T16:56:50.746495"}}
{"question": "What are the main differences between AWS Local Zones and AWS Outposts?", "answer": "AWS Local Zones are designed for workloads requiring low-latency and running compute and storage resources closer to end-users, while AWS Outposts are for workloads that must remain on-premises due to latency requirements but where customers want the on-premises workload to run seamlessly with their AWS workloads. AWS Local Zones do not require customers to own and operate their own data center infrastructure, whereas AWS Outposts are fully managed and configurable compute and storage racks built with AWS-designed hardware.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-2", "source_tokens": 448, "generated_at": "2026-02-11T16:56:50.746982"}}
{"question": "What services can be used in AWS Wavelength Zones besides EC2, EBS, and VPC?", "answer": "Services such as Amazon EC2 Auto Scaling, Amazon EKS clusters, Amazon ECS clusters, Amazon EC2 Systems Manager, Amazon CloudWatch, AWS CloudTrail, and AWS CloudFormation can also be used in AWS Wavelength Zones.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:56:55.602203"}}
{"question": "How does using Amazon S3, RDS, or Network Load Balancer differ in AWS Wavelength Zones compared to an AWS Region?", "answer": "AWS Wavelength offers a suite of third-party products as alternatives for these services not available in the Wavelength Zone.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:56:55.602566"}}
{"question": "How does paying for Amazon EC2 instances differ between On-Demand and Savings Plans in Wavelength Zones?", "answer": "On-Demand is a pay-as-you-go model, while Savings Plans offer discounts in exchange for a commitment to a consistent usage level.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-3", "source_tokens": 497, "generated_at": "2026-02-11T16:56:55.603094"}}
{"question": "Which EC2 instance types are available for edge workloads on Wavelength?", "answer": "Wavelength supports t3.medium, t3.xlarge, r5.2xlarge for cost-effective general purpose compute, g4dn.2xlarge for GPU-enabled applications like game streaming and ML inference.", "question_type": "factual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-11T16:57:00.561459"}}
{"question": "Why would you use different EC2 instance types in AWS Wavelength?", "answer": "Customers can choose different EC2 instance types based on their application requirements and cost considerations. For example, t3 instances are cost-effective, g4dn instances offer GPU capabilities.", "question_type": "conceptual", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-11T16:57:00.561843"}}
{"question": "How does AWS Wavelength compare to other AWS services for improving workload resiliency?", "answer": "AWS Wavelength can be combined with other AWS services like Outposts, Local Zones, or on-premises deployments to improve workload resiliency. It can be considered a multi-tenant infrastructure in locations where there are no other AWS Regions or Local Zones.", "question_type": "comparison", "metadata": {"service": "WAVELENGTH", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wavelength-faq-4", "source_tokens": 274, "generated_at": "2026-02-11T16:57:00.562148"}}
{"question": "What are the six pillars of the AWS Well-Architected Framework?", "answer": "The six pillars of the AWS Well-Architected Framework are operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability.", "question_type": "factual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T16:57:05.702427"}}
{"question": "How does the AWS Well-Architected Tool help with improving workload designs?", "answer": "The AWS Well-Architected Tool lets you review your workloads against current AWS best practices, provides guidance on how to architect your workloads for the cloud, and delivers a list of potential issues found in your workloads along with step-by-step guidance to make improvements.", "question_type": "conceptual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T16:57:05.702719"}}
{"question": "What is the difference between a custom lens and an AWS-provided lens in the context of the AWS Well-Architected Tool?", "answer": "AWS-provided lenses are predefined sets of questions and best practices in the AWS Well-Architected Framework. Custom lenses, on the other hand, allow you to review your workloads using customized questions.", "question_type": "comparison", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-0", "source_tokens": 505, "generated_at": "2026-02-11T16:57:05.703108"}}
{"question": "What is required to access the AWS Well-Architected Tool?", "answer": "Accessing the AWS Well-Architected Tool requires signing in to the AWS Management Console with your AWS account.", "question_type": "factual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-11T16:57:09.829836"}}
{"question": "How does the AWS Well-Architected Tool assist in workload development?", "answer": "The AWS Well-Architected Tool helps in workload development by allowing users to define the workload for review, answer questions across each of the architectural pillars, and receive an improvement plan with a prioritized list of issues.", "question_type": "conceptual", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-11T16:57:09.830233"}}
{"question": "How does the use of the AWS Well-Architected Tool differ between different stages of development?", "answer": "It is recommended to perform a workload review at major milestones in the development cycle using the AWS Well-Architected Tool.", "question_type": "comparison", "metadata": {"service": "WELLARCHITECTED", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "wellarchitected-faq-1", "source_tokens": 207, "generated_at": "2026-02-11T16:57:09.830661"}}
{"question": "What is AWS X-Ray and how does it help developers?", "answer": "AWS X-Ray is a developer tool that helps analyze and debug production applications, providing an end-to-end view of requests as they travel through an application. It identifies and troubleshoots performance issues and errors by understanding how an application and its underlying services are performing. X-Ray collects data using a user-centric model, which enables creating a user-centric picture of requests as they travel across services and resources.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T16:57:15.848616"}}
{"question": "What are the core concepts of AWS X-Ray?", "answer": "The core concepts of AWS X-Ray include an end-to-end view of requests, understanding application performance, and troubleshooting issues. X-Ray provides a user-centric model for collecting data related to requests made to your application.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T16:57:15.848979"}}
{"question": "How does AWS X-Ray compare to a per-service or per-resource process for tracking requests?", "answer": "AWS X-Ray provides a user-centric model for collecting data related to requests, while traditional methods rely on a per-service or per-resource process. X-Ray's model enables creating a user-centric picture of requests as they travel across services and resources, making it easier to identify and troubleshoot issues.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-0", "source_tokens": 383, "generated_at": "2026-02-11T16:57:15.849396"}}
{"question": "What information does X-Ray provide for a single component in a distributed application?", "answer": "An X-Ray segment encapsulates all the data points for a single component of the distributed application. It includes system-defined and user-defined data in the form of annotations and is composed of one or more sub-segments that represent remote calls made from the service.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-11T16:57:20.442812"}}
{"question": "What is the difference between an X-Ray trace and a segment?", "answer": "An X-Ray trace is a set of data points that share the same trace ID, while an X-Ray segment encapsulates all the data points for a single component of the distributed application.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-11T16:57:20.443189"}}
{"question": "What can X-Ray be used to create in an application?", "answer": "X-Ray can be used to create a map of services used by an application, identify errors and bugs, and build your own analysis and visualization apps.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-1", "source_tokens": 417, "generated_at": "2026-02-11T16:57:20.443695"}}
{"question": "What should you do if you're using Elastic Beanstalk to implement X-Ray?", "answer": "Include the language-specific X-Ray libraries in your application code.", "question_type": "factual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-11T16:57:31.867938"}}
{"question": "How does X-Ray help in tracking requests across multiple regions?", "answer": "X-Ray automatically annotates region information for AWS services but requires customers to instrument custom services to take advantage of cross-region support.", "question_type": "conceptual", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-11T16:57:31.868526"}}
{"question": "What's the difference between logging data events and management events in X-Ray?", "answer": "Data events, not logged by default, contain data from PutTraceSegments and GetTimeSeriesServiceStatistics among other APIs. Management events are logs of all API calls.", "question_type": "comparison", "metadata": {"service": "XRAY", "doc_type": "Guide", "source_file": "faq.html", "chunk_id": "xray-faq-3", "source_tokens": 468, "generated_at": "2026-02-11T16:57:31.868738"}}
